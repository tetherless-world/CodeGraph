{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzed ../kaggle_json/sample555.py.json\n",
      "failed to analyze sample415.py with empty list\n",
      "num successes:1\n",
      "num failures1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import StaticAnalysisGraphBuilder\n",
    "import AI4MLTagReader\n",
    "import rdflib\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import setlr\n",
    "import rdflib\n",
    "\n",
    "\"\"\"\n",
    "  This class opens up a pandas dataframe of code from github, and calls WALA's apis to get control flow and data flow\n",
    "  for each class.  The class is broken down into a set of entry points that correspond to each function in the dataset.\n",
    "  Analysis starts at each entry point, and returns a graph of control flow and data flow edges.  These are \n",
    "  converted into an RDF graph and dumped in turtle.\n",
    "\"\"\"\n",
    "classes_to_superclasses = AI4MLTagReader.get_class_hierarchy()\n",
    "\n",
    "url = 'http://localhost:4567/analyze_code'\n",
    "\n",
    "SETL_FILE = 'codegraph.setl.ttl'\n",
    "\n",
    "prov = rdflib.Namespace('http://www.w3.org/ns/prov#')\n",
    "\n",
    "last_graph = None\n",
    "\n",
    "def main(inputdir, graphdir, jsondir, limit=-1):\n",
    "    fails = 0\n",
    "    success = 0\n",
    "    global last_graph\n",
    "    \n",
    "    for i, f in enumerate(os.listdir(inputdir)):\n",
    "        if limit >= 0 and i > limit:\n",
    "            break\n",
    "        if not f.startswith('sample'):\n",
    "            continue\n",
    "        with open(os.path.join(inputdir, f)) as sample_file:\n",
    "            source = sample_file.read()\n",
    "\n",
    "        json_data = handle_call_to_analysis(source, f)\n",
    "        if json_data:\n",
    "            json_file = os.path.join(jsondir, f + '.json')\n",
    "            with open(json_file,'w') as out:\n",
    "                out.write(json.dumps(json_data,indent=4))\n",
    "                \n",
    "            fn = os.path.join(graphdir, f + '.ttl')\n",
    "            \n",
    "            g = convert_to_rdf(json_file)\n",
    "            last_graph = g\n",
    "            with open(fn, 'wb') as out:\n",
    "                out.write(g.serialize(format='turtle'))\n",
    "            success += 1\n",
    "        else:\n",
    "            fails += 1\n",
    "\n",
    "    print(\"num successes:\" + str(success))\n",
    "    print('num failures' + str(fails))\n",
    "    \n",
    "    \n",
    "\n",
    "def print_infrequent_edges(edge_map, limit):\n",
    "    for key in edge_map:\n",
    "        if len(edge_map.get(key)) < limit:\n",
    "            print(key)\n",
    "\n",
    "\n",
    "def compute_average_degree(edge_map):\n",
    "    degree = []\n",
    "    for key in edge_map:\n",
    "        degree.append(len(edge_map.get(key)))\n",
    "    np_array = np.asarray(degree)\n",
    "    print(np.histogram(degree, density=False))\n",
    "    return np_array.mean(), np_array.std()\n",
    "\n",
    "\n",
    "def handle_call_to_analysis(source, file):\n",
    "    if not source:\n",
    "        return\n",
    "    source = source.encode('utf-8')\n",
    "    res = requests.post(url=url,\n",
    "                        data=source,\n",
    "                        headers={'Content-Type': 'application/octet-stream'})\n",
    "    if not res.text:\n",
    "        print(\"failed to analyze \" + file + \" with null result\")\n",
    "        return\n",
    "\n",
    "    if res.text == '<html><body><h2>500 Internal Server Error</h2></body></html>':\n",
    "        print(\"failed to analyze \" + file + \" with server error\")\n",
    "        return\n",
    "    if res.text == '[]':\n",
    "        print(\"failed to analyze \" + file + \" with empty list\")\n",
    "        return\n",
    "    json_data = json.loads(res.text)\n",
    "    if len(json_data) == 0:\n",
    "        print(\"failed to analyze \" + file + \" with no turtles\")\n",
    "        return\n",
    "    return json_data\n",
    "\n",
    "def convert_to_rdf(json_file):\n",
    "    setl_graph = rdflib.Graph()\n",
    "    setl_graph.parse(SETL_FILE,format=\"turtle\")\n",
    "    cwd = os.getcwd()\n",
    "    \n",
    "    extract = setl_graph.value(rdflib.URIRef('http://purl.org/twc/codegraph/setl/codegraph_json'), prov.wasGeneratedBy)\n",
    "    setl_graph.add((extract, prov.used,rdflib.URIRef('file://'+os.path.join(cwd,json_file))))\n",
    "    \n",
    "    results = setlr._setl(setl_graph)\n",
    "    \n",
    "    single_g = results[rdflib.URIRef('http://purl.org/twc/codegraph/setl/codegraph')]\n",
    "    print(\"analyzed \" + json_file)\n",
    "    return single_g\n",
    "    \n",
    "main('../kaggle/python_files','../kaggle_rdf','../kaggle_json',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in last_graph.subjects() if isinstance(x, rdflib.Literal) and isinstance(x.value, list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11, 4), (12, 4), (1, 3), (2, 3)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[[11,12],4],[[1,2],3]]\n",
    "\n",
    "import functools\n",
    "functools.reduce(lambda x,y: x + y, [[(node,position) for node in nodes] for nodes, position in x] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3, 2, 1]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed([1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dict'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = rdflib.URIRef(\"\")\n",
    "dict.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'URIRef' object has no attribute '__type__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-2797d6445eca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__type__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'URIRef' object has no attribute '__type__'"
     ]
    }
   ],
   "source": [
    "foo.__type__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdflib.term.URIRef"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.__class__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"  \\n  foo\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
