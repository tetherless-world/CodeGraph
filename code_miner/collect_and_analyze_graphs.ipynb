{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzed sample555.py\n",
      "../kaggle_rdf/sample555.py.ttl\n",
      "failed to analyze sample415.py with empty list\n",
      "failed to analyze sample784.py with empty list\n",
      "failed to analyze sample887.py with empty list\n",
      "analyzed sample996.py\n",
      "../kaggle_rdf/sample996.py.ttl\n",
      "analyzed sample504.py\n",
      "../kaggle_rdf/sample504.py.ttl\n",
      "analyzed sample695.py\n",
      "../kaggle_rdf/sample695.py.ttl\n",
      "failed to analyze sample444.py with empty list\n",
      "analyzed sample666.py\n",
      "../kaggle_rdf/sample666.py.ttl\n",
      "analyzed sample965.py\n",
      "../kaggle_rdf/sample965.py.ttl\n",
      "analyzed sample825.py\n",
      "../kaggle_rdf/sample825.py.ttl\n",
      "num successes:7\n",
      "num failures4\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import StaticAnalysisGraphBuilder\n",
    "import AI4MLTagReader\n",
    "import rdflib\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\"\"\"\n",
    "  This class opens up a pandas dataframe of code from github, and calls WALA's apis to get control flow and data flow\n",
    "  for each class.  The class is broken down into a set of entry points that correspond to each function in the dataset.\n",
    "  Analysis starts at each entry point, and returns a graph of control flow and data flow edges.  These are \n",
    "  converted into an RDF graph and dumped in turtle.\n",
    "\"\"\"\n",
    "classes_to_superclasses = AI4MLTagReader.get_class_hierarchy()\n",
    "\n",
    "url = 'http://localhost:4567/analyze_code'\n",
    "\n",
    "\n",
    "def main(inputdir, graphdir, limit=-1):\n",
    "    fails = 0\n",
    "    success = 0\n",
    "\n",
    "    for i, f in enumerate(os.listdir(inputdir)):\n",
    "        if limit >= 0 and i > limit:\n",
    "            break\n",
    "        if not f.startswith('sample'):\n",
    "            continue\n",
    "        with open(os.path.join(inputdir, f)) as sample_file:\n",
    "            source = sample_file.read()\n",
    "\n",
    "        graph_tuple = handle_call_to_analysis(source, f)\n",
    "        if graph_tuple:\n",
    "            single_g = rdflib.Graph()\n",
    "            StaticAnalysisGraphBuilder.addToGraph(single_g, graph_tuple)\n",
    "            fn = os.path.join(graphdir, f + '.ttl')\n",
    "            print(fn)\n",
    "            with open(fn, 'wb') as out:\n",
    "                out.write(single_g.serialize(format='turtle'))\n",
    "            success += 1\n",
    "        else:\n",
    "            fails += 1\n",
    "\n",
    "    print(\"num successes:\" + str(success))\n",
    "    print('num failures' + str(fails))\n",
    "\n",
    "\n",
    "def print_infrequent_edges(edge_map, limit):\n",
    "    for key in edge_map:\n",
    "        if len(edge_map.get(key)) < limit:\n",
    "            print(key)\n",
    "\n",
    "\n",
    "def compute_average_degree(edge_map):\n",
    "    degree = []\n",
    "    for key in edge_map:\n",
    "        degree.append(len(edge_map.get(key)))\n",
    "    np_array = np.asarray(degree)\n",
    "    print(np.histogram(degree, density=False))\n",
    "    return np_array.mean(), np_array.std()\n",
    "\n",
    "\n",
    "def handle_call_to_analysis(source, file):\n",
    "    if not source:\n",
    "        return\n",
    "    source = source.encode('utf-8')\n",
    "    res = requests.post(url=url,\n",
    "                        data=source,\n",
    "                        headers={'Content-Type': 'application/octet-stream'})\n",
    "    if not res.text:\n",
    "        print(\"failed to analyze \" + file + \" with null result\")\n",
    "        return\n",
    "\n",
    "    if res.text == '<html><body><h2>500 Internal Server Error</h2></body></html>':\n",
    "        print(\"failed to analyze \" + file + \" with server error\")\n",
    "        return\n",
    "    if res.text == '[]':\n",
    "        print(\"failed to analyze \" + file + \" with empty list\")\n",
    "        return\n",
    "    json_data = json.loads(res.text)\n",
    "    if len(json_data) == 0:\n",
    "        print(\"failed to analyze \" + file + \" with no turtles\")\n",
    "        return\n",
    "    # print(json.dumps(json_data, indent=4))\n",
    "    # print('************************')\n",
    "    nodes, data_flow_edges, control_flow_edges = StaticAnalysisGraphBuilder.parse_wala_into_graph(json_data,\n",
    "                                                                                               add_args=True)\n",
    "    # print(nodes)\n",
    "    print(\"analyzed \" + file)\n",
    "    return (nodes, data_flow_edges, control_flow_edges, file)\n",
    "    \n",
    "    \n",
    "main('../kaggle/python_files','../kaggle_rdf',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
