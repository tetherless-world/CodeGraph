#!/usr/bin/env python
# coding: utf-8

#  ## <div align="center">  10 Steps to Become a Data Scientist +20Q</div>
#  <div align="center">**quite practical and far from any theoretical concepts**</div>
# <div style="text-align:center">last update: <b>15/01/2019</b></div>
# <img src="http://s9.picofile.com/file/8338833934/DS.png"/>

# 
# 
# ---------------------------------------------------------------------
# Fork and Run this course on GitHub:
# > #### [ GitHub](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist)
# 
# 
# -------------------------------------------------------------------------------------------------------------
#  <b>I hope you find this kernel helpful and some <font color="red"> UPVOTES</font> would be very much appreciated</b>
#  
#  -----------
# 

#  <a id="top"></a> <br>
# **Notebook Content**
# 
#  [Introduction](#Introduction)
# 1. [Python](#Python)
# 1. [Python Packages](#PythonPackages)
# 1. [Mathematics and Linear Algebra](#Algebra)
# 1. [Programming & Analysis Tools](#Programming)
# 1. [Big Data](#BigData)
# 1. [Data visualization](#Datavisualization)
# 1. [Data Cleaning](#DataCleaning)
# 1. [How to solve Problem?](#Howto)
# 1. [Machine Learning](#MachineLearning)
# 1. [Deep Learning](#DeepLearning)

#  <a id="Introduction"></a> <br>
# # Introduction
# If you Read and Follow **Job Ads** to hire a machine learning expert or a data scientist, you find that some skills you should have to get the job. In this Kernel, I want to review **10 skills** that are essentials to get the job. In fact, this kernel is a reference for **10 other kernels**, which you can learn with them,  all of the skills that you need. 
# 
# we have used two well-known DataSets **Titanic** and **House prices** for starting but  when you learned python and python packages, you can start using other datasets too. 
# 
# **Ready to learn**! you will learn 10 skills as data scientist: 
# 
# 1. [Learn Python](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-1)
# 1. [Learn python packages](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-2) 
# 1. [Linear Algebra for Data Scientists](https://www.kaggle.com/mjbahmani/linear-algebra-for-data-scientists)
# 1. [Programming & Analysis Tools](https://www.kaggle.com/mjbahmani/machine-learning-workflow-for-house-prices)
# 1. [Big Data](https://www.kaggle.com/mjbahmani/a-data-science-framework-for-quora)
# 1. [Top 5 Data Visualization Libraries Tutorial](https://www.kaggle.com/mjbahmani/top-5-data-visualization-libraries-tutorial)
# 1. [How to solve Problem?](https://www.kaggle.com/mjbahmani/a-data-science-framework-for-quora)
# 1. [Data Cleaning](https://www.kaggle.com/mjbahmani/some-eda-for-elo)
# 1. [Machine Learning](https://www.kaggle.com/mjbahmani/a-comprehensive-ml-workflow-with-python)
# 1. [Deep Learning](https://www.kaggle.com/mjbahmani/top-5-deep-learning-frameworks-tutorial) 
# 
# Thanks to **Kaggle team** due to provide a great professional community for Data Scientists
# ###### [go to top](#top)

#  <a id="1"></a> <br>
# # 1-Python
# The first step in this course for beginners is Python's quick learning in three days
# Just take **10 hours** to learn Python.
# 
# for Reading this section **please** fork and run  the following kernel:
# 
# [Learn Python](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-1)
#  
#   ###### [go to top](#top)

# <a id="PythonPackages"></a> <br>
# # 2-Python Packages
# In the second step, we will learn  the necessary libraries that are essential for any specialist.
# 1. Numpy
# 1. Pandas
# 1. Matplotlib
# 1. Seaborn
# 1. TensorFlow
# 1. NLTK
# 1. Sklearn
# and so on
# 
# <img src="http://s8.picofile.com/file/8338227868/packages.png">
# 
# for Reading this section **please** fork and run  this kernel:
# 
# 
# 
# 1. [The data scientist's toolbox tutorial 1](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-1)
# 
# 1. [The data scientist's toolbox tutorial 2](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-2)
# 
# ###### [go to top](#top)

# <a id="Algebra"></a> <br>
# ##  3- Mathematics and Linear Algebra
# Linear algebra is the branch of mathematics that deals with vector spaces. good understanding of Linear Algebra is intrinsic to analyze Machine Learning algorithms, especially for Deep Learning where so much happens behind the curtain.you have my word that I will try to keep mathematical formulas & derivations out of this completely mathematical topic and I try to cover all of subject that you need as data scientist.
# 
# <img src=" https://s3.amazonaws.com/www.mathnasium.com/upload/824/images/algebra.jpg " height="300" width="300">
# 
# for Reading this section **please** fork and run  this kernel:
# 
# [Linear Algebra for Data Scientists](https://www.kaggle.com/mjbahmani/linear-algebra-for-data-scientists)
# ###### [go to top](#top)

# <a id="Programming"></a> <br>
# ## 4- Programming & Analysis Tools
# 
# It is not completed yet but For Reading an alternative for it **please** fork and run  this kernel:
# 
# [Programming & Analysis Tools](https://www.kaggle.com/mjbahmani/machine-learning-workflow-for-house-prices)
# 
# ###### [go to top](#top)

# <a id="BigData"></a> <br>
# ## 5- Big Data
# 
# It is not completed yet but For Reading an alternative for it **please** fork and run  this kernel:
# 
# [Big Data](https://www.kaggle.com/mjbahmani/a-data-science-framework-for-quora)
# 

# <a id="Datavisualization"></a> <br>
# ## 6- Data Visualization
# for Reading this section **please** fork and upvote  this kernel:
# 
# [Top 5 Data Visualization Libraries Tutorial](https://www.kaggle.com/mjbahmani/top-5-data-visualization-libraries-tutorial)

# <a id="DataCleaning"></a> <br>
# ## 7- Data Cleaning
# Certainly another important step in the way of specialization is learning how to clean the data.
# In this section, we will do this on Elo data set.
# for Reading this section **please** fork and upvote  this kernel:
# 
# [Data Cleaning](https://www.kaggle.com/mjbahmani/some-eda-for-elo)

# <a id="Howto"></a> <br>
# ## 8- How to solve Problem?
# If you have already read some [machine learning books](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist/tree/master/Ebooks). You have noticed that there are different ways to stream data into machine learning.
# 
# most of these books share the following steps (checklist):
# *   Define the Problem(Look at the big picture)
# *   Specify Inputs & Outputs
# *   Data Collection
# *   Exploratory data analysis
# *   Data Preprocessing
# *   Model Design, Training, and Offline Evaluation
# *   Model Deployment, Online Evaluation, and Monitoring
# *   Model Maintenance, Diagnosis, and Retraining
# 
# **You can see my workflow in the below image** :
#  <img src="http://s9.picofile.com/file/8338227634/workflow.png" />
# ## 8-1 Real world Application Vs Competitions
# Just a simple comparison between real-world apps with competitions:
# <img src="http://s9.picofile.com/file/8339956300/reallife.png" height="600" width="500" />
# **you should	feel free	to	adapt 	this	checklist 	to	your needs**
#  
# ## 8-2 Problem Definition
# I think one of the important things when you start a new machine learning project is Defining your problem. that means you should understand business problem.( **Problem Formalization**)
# 
# Problem Definition has four steps that have illustrated in the picture below:
# <img src="http://s8.picofile.com/file/8338227734/ProblemDefination.png">
#  
# ### 8-2-1 Problem Feature
# The sinking of the Titanic is one of the most infamous shipwrecks in history. **On April 15, 1912**, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing **1502 out of 2224** passengers and crew. That's why the name DieTanic. This is a very unforgetable disaster that no one in the world can forget.
# 
# It took about $7.5 million to build the Titanic and it sunk under the ocean due to collision. The Titanic Dataset is a very good dataset for begineers to start a journey in data science and participate in competitions in Kaggle.
# 
# we will use the classic titanic data set. This dataset contains information about **11 different variables**:
# <img src="http://s9.picofile.com/file/8340453092/Titanic_feature.png" height="500" width="500">
# 
# * Survival
# * Pclass
# * Name
# * Sex
# * Age
# * SibSp
# * Parch
# * Ticket
# * Fare
# * Cabin
# * Embarked
# 
# <font color='red'><b>Question</b></font>
# 1. It's your train what's House Price Data sets feature?
# 
# ### 8-2-2 Aim
# 
# It is your job to predict if a passenger survived the sinking of the Titanic or not.  For each PassengerId in the test set, you must predict a 0 or 1 value for the Survived variable.
# 
#  
# ### 8-2-3 Variables
# 
# 1.  **Age** ==>> Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5
# 
# 2. **Sibsp** ==>> The dataset defines family relations in this way...
# 
#     a. Sibling = brother, sister, stepbrother, stepsister
# 
#     b. Spouse = husband, wife (mistresses and fiancÃ©s were ignored)
# 
# 3. **Parch** ==>> The dataset defines family relations in this way...
# 
#     a. Parent = mother, father
# 
#     b. Child = daughter, son, stepdaughter, stepson
# 
#     c. Some children travelled only with a nanny, therefore parch=0 for them.
# 
# 4. **Pclass** ==>> A proxy for socio-economic status (SES)
# 
#     * 1st = Upper
#     * 2nd = Middle
#     * 3rd = Lower
#     
# 5. **Embarked** ==>> nominal datatype 
# 6. **Name** ==>> nominal datatype . It could be used in feature engineering to derive the gender from title
# 7. **Sex** ==>>  nominal datatype 
# 8. **Ticket** ==>> that have no impact on the outcome variable. Thus, they will be excluded from analysis
# 9. **Cabin** ==>>  is a nominal datatype that can be used in feature engineering
# 11. **Fare** ==>>  Indicating the fare
# 12. **PassengerID ** ==>> have no impact on the outcome variable. Thus, it will be excluded from analysis
# 11. **Survival** is ==>> **[dependent variable](http://www.dailysmarty.com/posts/difference-between-independent-and-dependent-variables-in-machine-learning)** , 0 or 1
# 
# 
# **<< Note >>**
# 
# > You must answer the following question:
# How does your company expact to use and benfit from your model.
# 
# for Reading this section **please** fork and upvote  this kernel:
# 
# [How to solve Problem?](https://www.kaggle.com/mjbahmani/a-data-science-framework-for-quora)
# ###### [Go to top](#top)

# <a id="MachineLearning"></a> <br>
# ## 9- Machine learning  
# for Reading this section **please** fork and upvote  this kernel:
# 
# [A Comprehensive ML Workflow with Python](https://www.kaggle.com/mjbahmani/a-comprehensive-ml-workflow-with-python)
# 
# 

# <a id="DeepLearning"></a> <br>
# ##  10- Deep Learning
# 
# for Reading this section **please** fork and upvote  this kernel:
# 
# [A-Comprehensive-Deep-Learning-Workflow-with-Python](https://www.kaggle.com/mjbahmani/a-comprehensive-deep-learning-workflow-with-python)
# 
# ---------------------------
# 

# #  <div align="center">  50 machine learning  questions & answers for Beginners </div>
# If you are studying this kernel,you're probably at beginning of this journey. Here are some useful Python codes you need to get started.

# In[ ]:


import matplotlib.animation as animation
from matplotlib.figure import Figure
import plotly.figure_factory as ff
import matplotlib.pylab as pylab
from ipywidgets import interact
import plotly.graph_objs as go
import plotly.offline as py
from random import randint
from plotly import tools
import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib
import warnings
import string
import numpy
import csv
import os

# ## 1-how to import your data?

# What you have in your data folder?

# In[ ]:


print(os.listdir("../input/"))

# import all of your data

# In[ ]:


titanic_train=pd.read_csv('../input/train.csv')
titanic_test=pd.read_csv('../input/test.csv')

# Or import just %10 of your data

# In[ ]:


titanic_train2=pd.read_csv('../input/train.csv',nrows=1000)
 

# How to see the size of your data:

# In[ ]:


print("Train: rows:{} columns:{}".format(titanic_train.shape[0], titanic_train.shape[1]))

# **For reading more about how to import your data you can visit: **[this Kernel](https://www.kaggle.com/dansbecker/finding-your-files-in-kaggle-kernels)

# ## 2- How to check missed data?

# In[ ]:


titanic_train.isna().sum()

# or you can use below code

# In[ ]:


total = titanic_train.isnull().sum().sort_values(ascending=False)
percent = (titanic_train.isnull().sum()/titanic_train.isnull().count()).sort_values(ascending=False)
missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])
missing_data.head(20)

# ## 3- How to view the statistical characteristics of the data?

# In[ ]:


titanic_train.describe()

# or just for one column

# In[ ]:


titanic_train['Age'].describe()

# with a another shape

# In[ ]:


titanic_train.Age.describe()

# ## 4- How check the column's name?

# In[ ]:


titanic_train.columns

# or you can the check the column name with another ways too

# In[ ]:


titanic_train.head()

# ## 5- how to view randomly your data set ?

# In[ ]:


titanic_train.sample(5)

# ## 6-How  random row selection in Pandas dataframe?

# In[ ]:


titanic_train.sample(frac=0.007)

# ## 7- How to copy a column and drop it ?

# In[ ]:


PassengerId=titanic_train['PassengerId'].copy()


# In[ ]:


PassengerId.head()

# In[ ]:


type(PassengerId)

# In[ ]:


titanic_train=titanic_train.drop('PassengerId',1)

# In[ ]:


titanic_train.head()

# In[ ]:


titanic_train=pd.read_csv('../input/train.csv')

# ## 8- How to check out last 5 row of the dataset?
# 

# we use tail() function

# In[ ]:


titanic_train.tail() 

# 
# # 9- How to concatenation operations along an axis?

# In[ ]:


all_data = pd.concat((titanic_train.loc[:,'Pclass':'Embarked'],
                      titanic_test.loc[:,'Pclass':'Embarked']))

# In[ ]:


all_data.head()

# In[ ]:


titanic_train.shape

# In[ ]:


titanic_test.shape

# In[ ]:


all_data.shape

# ## 10- How to see unique values for a culomns?

# In[ ]:


titanic_train['Sex'].unique()


# In[ ]:


titanic_train['Cabin'].unique()


# In[ ]:


titanic_train['Pclass'].unique()


# ## 11- How to perform some query on your datasets?

# In[ ]:


titanic_train[titanic_train['Age']>70]

# In[ ]:


titanic_train[titanic_train['Pclass']==1]

# ---------------------------------------------------------------------
# Fork and Run this kernel on GitHub:
# > ###### [ GitHub](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist)
# 
#  
# 
# -------------------------------------------------------------------------------------------------------------
#  <b>I hope you find this kernel helpful and some <font color="red">UPVOTES</font> would be very much appreciated</b>
#  
#  -----------
