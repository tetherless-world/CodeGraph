{
    "module": "sklearn",
    "function": "sklearn.linear_model.logistic.softmax",
    "stackoverflow": [
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8863",
            "_score": 14.370203,
            "_source": {
                "title": "MLPRegressor Output Range",
                "content": "MLPRegressor Output Range <p>I am using Scikit's <code>MLPRegressor</code> for a timeseries prediction task. </p>\n\n<p>My data is scaled between 0 and 1 using the <code>MinMaxScaler</code> and my model is initialized using the following parameters:</p>\n\n<pre><code>MLPRegressor(solver='lbfgs', hidden_layer_sizes=50,\n                           max_iter=10000, shuffle=False, random_state=9876,\n                           activation='relu')\n</code></pre>\n\n<p>I am expecting output between 0 and 1 but getting values outside the bound (both negative values as well as > 1).</p>\n\n<p>Non-normalized data has the same problem, I get predictions out of range! </p>\n\n<p>Any idea where I could be wrong?</p>\n\n<p><strong>UPDATE:</strong>\nBased on the answers below I played a bit with modifying the output activation layers and got some interesting results that I thought worth sharing. There are three scenarios, hope the captions convey the message clearly:\nLegend:</p>\n\n<p>Black solid line = Training Epoch</p>\n\n<p>Red solid line = Test Epoch</p>\n\n<p>Cyan dashed line = Network prediction over the entire data set</p>\n\n<ol>\n<li>Output when the network is trained using 'relu' activation layer but output_activation_ set to 'logistic</li>\n</ol>\n\n<p><a href=\"https://i.stack.imgur.com/4Vxbs.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/4Vxbs.png\" alt=\"Output when the network is trained using &#39;relu&#39; activation layer but output_activation_ set to &#39;logistic&#39;\"></a></p>\n\n<ol start=\"2\">\n<li>Output when the network is trained using 'relu' activation layer and output_activation_ set explicitly to 'relu'</li>\n</ol>\n\n<p><a href=\"https://i.stack.imgur.com/mXUr2.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/mXUr2.png\" alt=\"Output when the network is trained using &#39;relu&#39; activation layer and output_activation_ set explicitly to &#39;relu&#39;\"></a></p>\n\n<ol start=\"3\">\n<li>Output when the network is trained using 'relu' activation layer and output_activation is left alone\n<a href=\"https://i.stack.imgur.com/XRk2P.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/XRk2P.png\" alt=\"Output when the network is trained using &#39;relu&#39; activation layer and output_activation is left alone\"></a></li>\n</ol>\n <scikit-learn><mlp><p>The default output activation of the Scikit-Learn <code>MLPRegressor</code> is 'identity', which actually does nothing to the weights it receives.</p>\n\n<p>As was mentioned by @David Masip in his answer, changing the final activation layer would allow this. Doing so in frameworks such as Pytorch, Keras and Tensorflow is fairly straight-forward.</p>\n\n<p>Doing it in your code with the <code>MLPRegressor</code> means using an object attribute that isn't a standard parameter, namely <code>output_activation_</code>.</p>\n\n<p>Here are the built-in options that I can see in <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\" rel=\"nofollow noreferrer\">the documentation</a>:</p>\n\n<blockquote>\n<pre><code>activation : {\u2018identity\u2019, \u2018logistic\u2019, \u2018tanh\u2019, \u2018relu\u2019}, default \u2018relu\u2019\n\nActivation function for the hidden layer.\n\n\u2018identity\u2019, no-op activation, useful to implement linear bottleneck, returns f(x) = x\n\u2018logistic\u2019, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n\u2018tanh\u2019, the hyperbolic tan function, returns f(x) = tanh(x).\n\u2018relu\u2019, the rectified linear unit function, returns f(x) = max(0, x)\n</code></pre>\n</blockquote>\n\n<p>Setting it's value to <code>logistic</code> gives you the property you would like, values between 0 and 1.</p>\n\n<hr>\n\n<p><strong>EDIT</strong>\nAfter comments and update from OP: in their case, using <code>logistic</code> (sigmoid) as the final activation negatively affected results. So perhaps it is worth trying out all possible activation functions to investigate which activation best suits the model and data.</p>\n\n<p>One further remark, at least within the context of deep learning, it is common practice not to use an activation at the final output of a neural network - for some thoughts around that discussion, <a href=\"https://stats.stackexchange.com/questions/163695/non-linearity-before-final-softmax-layer-in-a-convolutional-neural-network\">see this thread</a>.</p>\n\n<hr>\n\n<p>That being said, below is a simple working example of a model that doesn't set it, and one that does. I use random numbers to make it work, but the take-away is that the predicted values for the altered model are always within the range from 0 to 1. Try changing the random seed and re-running the script.</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.neural_network import MLPRegressor\n\n# To see an example where output falls outside of the range of y\nnp.random.seed(1)\n\n# Create the default NN as you did\nnn = MLPRegressor(\n    solver='lbfgs',\n    hidden_layer_sizes=50,\n    max_iter=10000,\n    shuffle=False,\n    random_state=9876,\n    activation='relu')\n\n# Generate some fake data\nnum_train_samples = 50\nnum_test_samples = 50\nnum_vars = 2\n\nX = np.random.random((num_train_samples, num_vars)) * \\\n    100  # random numbers between 0 and 100\ny = np.random.uniform(0, 1, (num_train_samples, 1))  # uniform numbers between 0 and 1\n\nX_test = np.random.random((num_test_samples, num_vars)) * 100\ny_test = np.random.uniform(0, 1, (num_test_samples, 1))\n\n# Fit the network\nnn.fit(X, y)\n\nprint('*** Before scaling the output via final activation:\\n')\n\n# Now see that the output activation is (by default) simply linear i.e. 'identity'\nprint('Output activation by default: {}'.format(nn.out_activation_))\npredictions = nn.predict(X_test)\n\nprint('Prediction mean: {:.2f}'.format(predictions.mean()))\nprint('Prediction max: {:.2f}'.format(predictions.max()))\nprint('Prediction min: {:.2f}'.format(predictions.min()))\n\n\nprint('\\n*** After scaling the output via final activation:\\n')\n\n# Need to recreate the NN\nnn_logistic = MLPRegressor(\n    solver='lbfgs',\n    hidden_layer_sizes=50,\n    max_iter=10000,\n    shuffle=False,\n    random_state=9876,\n    activation='relu')\n\n# Fit the new network\nnn_logistic.fit(X, y)\n\n\n# --------------- #\n#  Crucial step!  #\n# --------------- #\n\n# before making predictions = alter the attribute: \"output_activation_\"\nnn_logistic.out_activation_ = 'logistic'\nprint('New output activation: {}'.format(nn_logistic.out_activation_))\n\nnew_predictions = nn_logistic.predict(X_test)\n\nprint('Prediction mean: {:.2f}'.format(new_predictions.mean()))\nprint('Prediction max: {:.2f}'.format(new_predictions.max()))\nprint('Prediction min: {:.2f}'.format(new_predictions.min()))\n</code></pre>\n\n<p>Tested using Python 3.5.2.</p>\n<p>Altough your data is between 0 and 1, the predictions can be outside of this range, as with any satistical model. This shows that you are not able to represent your data properly with your model. However, this is not the important point. If you want to ensure the outputs to be between 0 and 1, you have to change the relu activation for another one, such as sigmoid or softmax. These activations ensure that your outputs will be between 0 and 1, although they might lead to other problems, such as vanishing gradients. What is usually advised is to use relu layers until the last one, which has to be a sigmoid or a softmax.</p>\n",
                "codes": [
                    [
                        "activation : {\u2018identity\u2019, \u2018logistic\u2019, \u2018tanh\u2019, \u2018relu\u2019}, default \u2018relu\u2019\n\nActivation function for the hidden layer.\n\n\u2018identity\u2019, no-op activation, useful to implement linear bottleneck, returns f(x) = x\n\u2018logistic\u2019, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n\u2018tanh\u2019, the hyperbolic tan function, returns f(x) = tanh(x).\n\u2018relu\u2019, the rectified linear unit function, returns f(x) = max(0, x)\n",
                        "import pandas as pd\nimport numpy as np\nfrom sklearn.neural_network import MLPRegressor\n\n# To see an example where output falls outside of the range of y\nnp.random.seed(1)\n\n# Create the default NN as you did\nnn = MLPRegressor(\n    solver='lbfgs',\n    hidden_layer_sizes=50,\n    max_iter=10000,\n    shuffle=False,\n    random_state=9876,\n    activation='relu')\n\n# Generate some fake data\nnum_train_samples = 50\nnum_test_samples = 50\nnum_vars = 2\n\nX = np.random.random((num_train_samples, num_vars)) * \\\n    100  # random numbers between 0 and 100\ny = np.random.uniform(0, 1, (num_train_samples, 1))  # uniform numbers between 0 and 1\n\nX_test = np.random.random((num_test_samples, num_vars)) * 100\ny_test = np.random.uniform(0, 1, (num_test_samples, 1))\n\n# Fit the network\nnn.fit(X, y)\n\nprint('*** Before scaling the output via final activation:\\n')\n\n# Now see that the output activation is (by default) simply linear i.e. 'identity'\nprint('Output activation by default: {}'.format(nn.out_activation_))\npredictions = nn.predict(X_test)\n\nprint('Prediction mean: {:.2f}'.format(predictions.mean()))\nprint('Prediction max: {:.2f}'.format(predictions.max()))\nprint('Prediction min: {:.2f}'.format(predictions.min()))\n\n\nprint('\\n*** After scaling the output via final activation:\\n')\n\n# Need to recreate the NN\nnn_logistic = MLPRegressor(\n    solver='lbfgs',\n    hidden_layer_sizes=50,\n    max_iter=10000,\n    shuffle=False,\n    random_state=9876,\n    activation='relu')\n\n# Fit the new network\nnn_logistic.fit(X, y)\n\n\n# --------------- #\n#  Crucial step!  #\n# --------------- #\n\n# before making predictions = alter the attribute: \"output_activation_\"\nnn_logistic.out_activation_ = 'logistic'\nprint('New output activation: {}'.format(nn_logistic.out_activation_))\n\nnew_predictions = nn_logistic.predict(X_test)\n\nprint('Prediction mean: {:.2f}'.format(new_predictions.mean()))\nprint('Prediction max: {:.2f}'.format(new_predictions.max()))\nprint('Prediction min: {:.2f}'.format(new_predictions.min()))\n"
                    ],
                    []
                ],
                "question_id:": "31957",
                "question_votes:": "2",
                "question_text:": "<p>I am using Scikit's <code>MLPRegressor</code> for a timeseries prediction task. </p>\n\n<p>My data is scaled between 0 and 1 using the <code>MinMaxScaler</code> and my model is initialized using the following parameters:</p>\n\n<pre><code>MLPRegressor(solver='lbfgs', hidden_layer_sizes=50,\n                           max_iter=10000, shuffle=False, random_state=9876,\n                           activation='relu')\n</code></pre>\n\n<p>I am expecting output between 0 and 1 but getting values outside the bound (both negative values as well as > 1).</p>\n\n<p>Non-normalized data has the same problem, I get predictions out of range! </p>\n\n<p>Any idea where I could be wrong?</p>\n\n<p><strong>UPDATE:</strong>\nBased on the answers below I played a bit with modifying the output activation layers and got some interesting results that I thought worth sharing. There are three scenarios, hope the captions convey the message clearly:\nLegend:</p>\n\n<p>Black solid line = Training Epoch</p>\n\n<p>Red solid line = Test Epoch</p>\n\n<p>Cyan dashed line = Network prediction over the entire data set</p>\n\n<ol>\n<li>Output when the network is trained using 'relu' activation layer but output_activation_ set to 'logistic</li>\n</ol>\n\n<p><a href=\"https://i.stack.imgur.com/4Vxbs.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/4Vxbs.png\" alt=\"Output when the network is trained using &#39;relu&#39; activation layer but output_activation_ set to &#39;logistic&#39;\"></a></p>\n\n<ol start=\"2\">\n<li>Output when the network is trained using 'relu' activation layer and output_activation_ set explicitly to 'relu'</li>\n</ol>\n\n<p><a href=\"https://i.stack.imgur.com/mXUr2.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/mXUr2.png\" alt=\"Output when the network is trained using &#39;relu&#39; activation layer and output_activation_ set explicitly to &#39;relu&#39;\"></a></p>\n\n<ol start=\"3\">\n<li>Output when the network is trained using 'relu' activation layer and output_activation is left alone\n<a href=\"https://i.stack.imgur.com/XRk2P.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/XRk2P.png\" alt=\"Output when the network is trained using &#39;relu&#39; activation layer and output_activation is left alone\"></a></li>\n</ol>\n",
                "tags": "<scikit-learn><mlp>",
                "answers": [
                    [
                        "31974",
                        "2",
                        "31957",
                        "",
                        "",
                        "<p>The default output activation of the Scikit-Learn <code>MLPRegressor</code> is 'identity', which actually does nothing to the weights it receives.</p>\n\n<p>As was mentioned by @David Masip in his answer, changing the final activation layer would allow this. Doing so in frameworks such as Pytorch, Keras and Tensorflow is fairly straight-forward.</p>\n\n<p>Doing it in your code with the <code>MLPRegressor</code> means using an object attribute that isn't a standard parameter, namely <code>output_activation_</code>.</p>\n\n<p>Here are the built-in options that I can see in <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\" rel=\"nofollow noreferrer\">the documentation</a>:</p>\n\n<blockquote>\n<pre><code>activation : {\u2018identity\u2019, \u2018logistic\u2019, \u2018tanh\u2019, \u2018relu\u2019}, default \u2018relu\u2019\n\nActivation function for the hidden layer.\n\n\u2018identity\u2019, no-op activation, useful to implement linear bottleneck, returns f(x) = x\n\u2018logistic\u2019, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n\u2018tanh\u2019, the hyperbolic tan function, returns f(x) = tanh(x).\n\u2018relu\u2019, the rectified linear unit function, returns f(x) = max(0, x)\n</code></pre>\n</blockquote>\n\n<p>Setting it's value to <code>logistic</code> gives you the property you would like, values between 0 and 1.</p>\n\n<hr>\n\n<p><strong>EDIT</strong>\nAfter comments and update from OP: in their case, using <code>logistic</code> (sigmoid) as the final activation negatively affected results. So perhaps it is worth trying out all possible activation functions to investigate which activation best suits the model and data.</p>\n\n<p>One further remark, at least within the context of deep learning, it is common practice not to use an activation at the final output of a neural network - for some thoughts around that discussion, <a href=\"https://stats.stackexchange.com/questions/163695/non-linearity-before-final-softmax-layer-in-a-convolutional-neural-network\">see this thread</a>.</p>\n\n<hr>\n\n<p>That being said, below is a simple working example of a model that doesn't set it, and one that does. I use random numbers to make it work, but the take-away is that the predicted values for the altered model are always within the range from 0 to 1. Try changing the random seed and re-running the script.</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.neural_network import MLPRegressor\n\n# To see an example where output falls outside of the range of y\nnp.random.seed(1)\n\n# Create the default NN as you did\nnn = MLPRegressor(\n    solver='lbfgs',\n    hidden_layer_sizes=50,\n    max_iter=10000,\n    shuffle=False,\n    random_state=9876,\n    activation='relu')\n\n# Generate some fake data\nnum_train_samples = 50\nnum_test_samples = 50\nnum_vars = 2\n\nX = np.random.random((num_train_samples, num_vars)) * \\\n    100  # random numbers between 0 and 100\ny = np.random.uniform(0, 1, (num_train_samples, 1))  # uniform numbers between 0 and 1\n\nX_test = np.random.random((num_test_samples, num_vars)) * 100\ny_test = np.random.uniform(0, 1, (num_test_samples, 1))\n\n# Fit the network\nnn.fit(X, y)\n\nprint('*** Before scaling the output via final activation:\\n')\n\n# Now see that the output activation is (by default) simply linear i.e. 'identity'\nprint('Output activation by default: {}'.format(nn.out_activation_))\npredictions = nn.predict(X_test)\n\nprint('Prediction mean: {:.2f}'.format(predictions.mean()))\nprint('Prediction max: {:.2f}'.format(predictions.max()))\nprint('Prediction min: {:.2f}'.format(predictions.min()))\n\n\nprint('\\n*** After scaling the output via final activation:\\n')\n\n# Need to recreate the NN\nnn_logistic = MLPRegressor(\n    solver='lbfgs',\n    hidden_layer_sizes=50,\n    max_iter=10000,\n    shuffle=False,\n    random_state=9876,\n    activation='relu')\n\n# Fit the new network\nnn_logistic.fit(X, y)\n\n\n# --------------- #\n#  Crucial step!  #\n# --------------- #\n\n# before making predictions = alter the attribute: \"output_activation_\"\nnn_logistic.out_activation_ = 'logistic'\nprint('New output activation: {}'.format(nn_logistic.out_activation_))\n\nnew_predictions = nn_logistic.predict(X_test)\n\nprint('Prediction mean: {:.2f}'.format(new_predictions.mean()))\nprint('Prediction max: {:.2f}'.format(new_predictions.max()))\nprint('Prediction min: {:.2f}'.format(new_predictions.min()))\n</code></pre>\n\n<p>Tested using Python 3.5.2.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "31968",
                        "2",
                        "31957",
                        "",
                        "",
                        "<p>Altough your data is between 0 and 1, the predictions can be outside of this range, as with any satistical model. This shows that you are not able to represent your data properly with your model. However, this is not the important point. If you want to ensure the outputs to be between 0 and 1, you have to change the relu activation for another one, such as sigmoid or softmax. These activations ensure that your outputs will be between 0 and 1, although they might lead to other problems, such as vanishing gradients. What is usually advised is to use relu layers until the last one, which has to be a sigmoid or a softmax.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17395",
            "_score": 12.914572,
            "_source": {
                "title": "Multilabel classification for a learning to rank application",
                "content": "Multilabel classification for a learning to rank application <p>I am looking for some suggestions on Learning to Rank method for search engines. I created a dataset with the following data:</p>\n\n<pre><code>query_dependent_score, independent_score, (query_dependent_score*independent_score), classification_label\n</code></pre>\n\n<p><code>query_dependent_score</code> is the TF-IDF score i.e. similarity b/w query and a document.</p>\n\n<p><code>independent_score</code> is the viewing time of the document.</p>\n\n<p>There are going to be 3 classes:</p>\n\n<ul>\n<li>0 (not relevant),</li>\n<li>1 (kind of relevant),</li>\n<li>2 (most relevant)</li>\n</ul>\n\n<p>I have a total of 750 queries and I collected top 10 results of each, so I have a total of 7500 data points.</p>\n\n<p>I have been thinking of estimating a relevance function like:</p>\n\n<pre><code>w0 + w1*query_dependent_score + w2*independent_score + w3*(query_dependent_score*independent_score)\n</code></pre>\n\n<p>I can clearly see this is like a classification problem but I wanted some info on whether this is right way to approach this problem.</p>\n\n<p>I referred to <a href=\"https://datascience.stackexchange.com/questions/12101/machine-learning-technique-to-calculate-weighted-average-weights\">Machine learning technique to calculate weighted average weights?</a> for some ideas.</p>\n\n<p>Following is the code that I have written:</p>\n\n<pre><code>from sklearn.linear_model import LogisticRegression\nimport numpy as np\n\nDATASET_PATH = \"...\"\n\nsearch_data = np.genfromtxt(DATASET_PATH, delimiter=',', skip_header=1, usecols=(1, 2, 3, 4))\ndocument_grades = search_data[:, 3:4]\ndocument_signals = search_data[:, :3]  # This has 3 features.\n\ntotal_rows = np.shape(search_data)[0]\nsplit_point = int(total_rows * 0.8)\n\ntraining_data_X, test_data_X = document_signals[:split_point, :], document_signals[split_point:, :]\ntraining_data_y, test_data_y = document_grades[:split_point, :], document_grades[split_point:, :]\n\nclf = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n\nclf.fit(X=training_data_X, y=training_data_y.ravel())\n\nprint(clf.classes_)  # [0, 1, 2]\nprint(clf.coef_)  # This is a 3 x 3 matrix?\nprint(clf.intercept_)  # An array of 3 elements?\n</code></pre>\n\n<p>Based on the <code>sklearn</code>'s documentation <code>coef_</code> should give me the values of <code>w1</code>, <code>w2</code> and <code>w3</code>, and <code>intercept_</code> should give me the value of <code>w0</code>.</p>\n\n<p>But I have a matrix and an array for those weights. I am not sure how to get the values of the weights for the relevance function?</p>\n\n<p>I am looking into learning to rank for the first time, so any suggestions are welcome.</p>\n <scikit-learn><learning-to-rank><p>In the <code>multinomial</code> mode, the docs specify that the outputs of <code>coef_</code> and <code>intercept_</code> are as you are seeing them: one output for each target class. The underlying model is three logistic regressions, whose outputs are softmax'ed (or with mode <code>ovr</code>, simply normalized).</p>\n\n<p>As to the broader question, since your three output classes are ordered, you might benefit from using that information. Either just perform regression (assumes that the numeric 0,1,2 are meaningful) or use \"ordinal regression.\"</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "56129",
                "question_votes:": "1",
                "question_text:": "<p>I am looking for some suggestions on Learning to Rank method for search engines. I created a dataset with the following data:</p>\n\n<pre><code>query_dependent_score, independent_score, (query_dependent_score*independent_score), classification_label\n</code></pre>\n\n<p><code>query_dependent_score</code> is the TF-IDF score i.e. similarity b/w query and a document.</p>\n\n<p><code>independent_score</code> is the viewing time of the document.</p>\n\n<p>There are going to be 3 classes:</p>\n\n<ul>\n<li>0 (not relevant),</li>\n<li>1 (kind of relevant),</li>\n<li>2 (most relevant)</li>\n</ul>\n\n<p>I have a total of 750 queries and I collected top 10 results of each, so I have a total of 7500 data points.</p>\n\n<p>I have been thinking of estimating a relevance function like:</p>\n\n<pre><code>w0 + w1*query_dependent_score + w2*independent_score + w3*(query_dependent_score*independent_score)\n</code></pre>\n\n<p>I can clearly see this is like a classification problem but I wanted some info on whether this is right way to approach this problem.</p>\n\n<p>I referred to <a href=\"https://datascience.stackexchange.com/questions/12101/machine-learning-technique-to-calculate-weighted-average-weights\">Machine learning technique to calculate weighted average weights?</a> for some ideas.</p>\n\n<p>Following is the code that I have written:</p>\n\n<pre><code>from sklearn.linear_model import LogisticRegression\nimport numpy as np\n\nDATASET_PATH = \"...\"\n\nsearch_data = np.genfromtxt(DATASET_PATH, delimiter=',', skip_header=1, usecols=(1, 2, 3, 4))\ndocument_grades = search_data[:, 3:4]\ndocument_signals = search_data[:, :3]  # This has 3 features.\n\ntotal_rows = np.shape(search_data)[0]\nsplit_point = int(total_rows * 0.8)\n\ntraining_data_X, test_data_X = document_signals[:split_point, :], document_signals[split_point:, :]\ntraining_data_y, test_data_y = document_grades[:split_point, :], document_grades[split_point:, :]\n\nclf = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n\nclf.fit(X=training_data_X, y=training_data_y.ravel())\n\nprint(clf.classes_)  # [0, 1, 2]\nprint(clf.coef_)  # This is a 3 x 3 matrix?\nprint(clf.intercept_)  # An array of 3 elements?\n</code></pre>\n\n<p>Based on the <code>sklearn</code>'s documentation <code>coef_</code> should give me the values of <code>w1</code>, <code>w2</code> and <code>w3</code>, and <code>intercept_</code> should give me the value of <code>w0</code>.</p>\n\n<p>But I have a matrix and an array for those weights. I am not sure how to get the values of the weights for the relevance function?</p>\n\n<p>I am looking into learning to rank for the first time, so any suggestions are welcome.</p>\n",
                "tags": "<scikit-learn><learning-to-rank>",
                "answers": [
                    [
                        "56175",
                        "2",
                        "56129",
                        "",
                        "",
                        "<p>In the <code>multinomial</code> mode, the docs specify that the outputs of <code>coef_</code> and <code>intercept_</code> are as you are seeing them: one output for each target class. The underlying model is three logistic regressions, whose outputs are softmax'ed (or with mode <code>ovr</code>, simply normalized).</p>\n\n<p>As to the broader question, since your three output classes are ordered, you might benefit from using that information. Either just perform regression (assumes that the numeric 0,1,2 are meaningful) or use \"ordinal regression.\"</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        }
    ]
}