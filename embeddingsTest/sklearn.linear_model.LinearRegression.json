{
    "module": "sklearn",
    "klass": "sklearn.linear_model.LinearRegression",
    "stackoverflow": [
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4107",
            "_score": 17.729301,
            "_source": {
                "title": "Learning rate in logistic regression with sklearn",
                "content": "Learning rate in logistic regression with sklearn <p>In sklearn, for logistic regression, you can define the penalty, the regularization rate and other variables. Is there a way to set the learning rate?</p>\n <machine-learning><scikit-learn><logistic-regression><p><code>sklearn.linear_model.LogisticRegression</code> doesn't use SGD, so there's no learning rate.</p>\n\n<p>I think <code>sklearn.linear_model.SGDClassifier</code> is what you need, which is a linear classifier with SGD training.</p>\n\n<h2>References</h2>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</a></p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html</a></p>\n<p>According to <a href=\"https://github.com/scikit-learn/scikit-learn/blob/a24c8b46/sklearn/linear_model/logistic.py#L1176\" rel=\"nofollow noreferrer\">sklearn's Logistic source code</a>, the solver used to minimize the loss function is the SAG solver (Stochastic Average Gradient). <a href=\"https://hal.inria.fr/hal-00860051/document\" rel=\"nofollow noreferrer\">This paper</a> defines this method, and in <a href=\"https://github.com/scikit-learn/scikit-learn/blob/a24c8b464d094d2c468a16ea9f8bf8d42d949f84/sklearn/linear_model/sag.py\" rel=\"nofollow noreferrer\">this link</a> there is the implementation of the sag solver. This implementation of the solver uses a method to obtain the step size (learning rate), so there is not a way that you can change the learning rate (unless you want to change the source code).</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "16751",
                "question_votes:": "3",
                "question_text:": "<p>In sklearn, for logistic regression, you can define the penalty, the regularization rate and other variables. Is there a way to set the learning rate?</p>\n",
                "tags": "<machine-learning><scikit-learn><logistic-regression>",
                "answers": [
                    [
                        "16752",
                        "2",
                        "16751",
                        "",
                        "",
                        "<p><code>sklearn.linear_model.LogisticRegression</code> doesn't use SGD, so there's no learning rate.</p>\n\n<p>I think <code>sklearn.linear_model.SGDClassifier</code> is what you need, which is a linear classifier with SGD training.</p>\n\n<h2>References</h2>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</a></p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html</a></p>\n",
                        "",
                        "3"
                    ],
                    [
                        "30748",
                        "2",
                        "16751",
                        "",
                        "",
                        "<p>According to <a href=\"https://github.com/scikit-learn/scikit-learn/blob/a24c8b46/sklearn/linear_model/logistic.py#L1176\" rel=\"nofollow noreferrer\">sklearn's Logistic source code</a>, the solver used to minimize the loss function is the SAG solver (Stochastic Average Gradient). <a href=\"https://hal.inria.fr/hal-00860051/document\" rel=\"nofollow noreferrer\">This paper</a> defines this method, and in <a href=\"https://github.com/scikit-learn/scikit-learn/blob/a24c8b464d094d2c468a16ea9f8bf8d42d949f84/sklearn/linear_model/sag.py\" rel=\"nofollow noreferrer\">this link</a> there is the implementation of the sag solver. This implementation of the solver uses a method to obtain the step size (learning rate), so there is not a way that you can change the learning rate (unless you want to change the source code).</p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12649",
            "_score": 17.05789,
            "_source": {
                "title": "Predicting for future date",
                "content": "Predicting for future date <p>How do I predict a category of data for a future date ?\nExample: what will the Sales figure for region (or region wise) for a particular date in the future based on the sales person past data for a particular product and product category?\nwhich model will be the best for these kind of problem ? </p>\n <machine-learning><data-science-model><p>Linear regression works well for predictive analytics if you data is linear and doesn't contain outlier i.e In places where you want to predict future trend depending on the the past/current trend, Linear regression does a fine job. Linear equation is <code>w0 + (wT*X)</code> where X is your input, <code>w</code> is the slope of your regression line and <code>w0</code> is the y-intercept of your regression line. The objective function of linear regression is an optimization problem where we try to minimizes <code>w</code> and <code>w0</code>. \nCheck out: <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html</a></p>\n",
                "codes": [
                    []
                ],
                "question_id:": "44244",
                "question_votes:": "1",
                "question_text:": "<p>How do I predict a category of data for a future date ?\nExample: what will the Sales figure for region (or region wise) for a particular date in the future based on the sales person past data for a particular product and product category?\nwhich model will be the best for these kind of problem ? </p>\n",
                "tags": "<machine-learning><data-science-model>",
                "answers": [
                    [
                        "44245",
                        "2",
                        "44244",
                        "",
                        "",
                        "<p>Linear regression works well for predictive analytics if you data is linear and doesn't contain outlier i.e In places where you want to predict future trend depending on the the past/current trend, Linear regression does a fine job. Linear equation is <code>w0 + (wT*X)</code> where X is your input, <code>w</code> is the slope of your regression line and <code>w0</code> is the y-intercept of your regression line. The objective function of linear regression is an optimization problem where we try to minimizes <code>w</code> and <code>w0</code>. \nCheck out: <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html</a></p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "2075",
            "_score": 17.008347,
            "_source": {
                "title": "If my data looks like this, is linear regression just never gonna be useful?",
                "content": "If my data looks like this, is linear regression just never gonna be useful? <p><a href=\"https://i.stack.imgur.com/Nurw0.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Nurw0.png\" alt=\"These are 7 features in scatter plots across my output variable \"></a></p>\n\n<p>Clearly you can see that there is no linear relationship. If there was one it would be a vertical line which is not that useful. I need some type of regression rather than classification as the output is continuous. The only options I can think of are neural networks and SVR (support vector regressors). Is linear regression a waste of time here? What would you use?</p>\n\n<p>The use case is - I am trying to predict the rgb color of a polygon based on its area, length, index, complexity, #of lines, # of curves, and intensity (black and white). </p>\n\n<p>In this first step I am merely trying to predict the amount of red from 0 to 1. (scaled down from 255).</p>\n\n<p>Edit: </p>\n\n<p>here are the labels - rgb values: <a href=\"http://www.heypasteit.com/clip/2HZX\" rel=\"nofollow noreferrer\">http://www.heypasteit.com/clip/2HZX</a></p>\n\n<p>here is the data with the 7 features: <a href=\"http://www.heypasteit.com/clip/2HZY\" rel=\"nofollow noreferrer\">http://www.heypasteit.com/clip/2HZY</a></p>\n <neural-network><regression><linear-regression><p>I tried running a <a href=\"http://scikit-learn.org/stable/auto_examples/linear_model/plot_ransac.html\" rel=\"nofollow\">RANSAC model</a> on your data, but got worse results than a straight linear regressor. The ten-fold cross-validated mean absolute error over all three response variables (r,g,b) for the linear model was about 0.37. I also ran a random forest model for comparison, and got about the same score. This suggests that the linear model is not shabby, but it is up to you to decide if either is good enough.</p>\n\n<pre><code>import sklearn.linear_model, sklearn.cross_validation, sklearn.ensemble, pandas\n\nlabels = pandas.read_csv('labels.csv', header=None, names=['r', 'g', 'b'])\nfeatures = pandas.read_csv('features.csv', header=None, names=['area', 'length', 'index', 'complexity', 'lines', 'curves', 'intensity'])\n\nsklearn.cross_validation.cross_val_score(sklearn.linear_model.LinearRegression(), features, labels[:len(features)], 'mean_absolute_error', 10, -1).mean()\n</code></pre>\n\n<p>I also tried visualizing the data with the outliers clipped, but did not find it very enlightening, so I did not include it here.</p>\n",
                "codes": [
                    [
                        "import sklearn.linear_model, sklearn.cross_validation, sklearn.ensemble, pandas\n\nlabels = pandas.read_csv('labels.csv', header=None, names=['r', 'g', 'b'])\nfeatures = pandas.read_csv('features.csv', header=None, names=['area', 'length', 'index', 'complexity', 'lines', 'curves', 'intensity'])\n\nsklearn.cross_validation.cross_val_score(sklearn.linear_model.LinearRegression(), features, labels[:len(features)], 'mean_absolute_error', 10, -1).mean()\n"
                    ]
                ],
                "question_id:": "10517",
                "question_votes:": "2",
                "question_text:": "<p><a href=\"https://i.stack.imgur.com/Nurw0.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Nurw0.png\" alt=\"These are 7 features in scatter plots across my output variable \"></a></p>\n\n<p>Clearly you can see that there is no linear relationship. If there was one it would be a vertical line which is not that useful. I need some type of regression rather than classification as the output is continuous. The only options I can think of are neural networks and SVR (support vector regressors). Is linear regression a waste of time here? What would you use?</p>\n\n<p>The use case is - I am trying to predict the rgb color of a polygon based on its area, length, index, complexity, #of lines, # of curves, and intensity (black and white). </p>\n\n<p>In this first step I am merely trying to predict the amount of red from 0 to 1. (scaled down from 255).</p>\n\n<p>Edit: </p>\n\n<p>here are the labels - rgb values: <a href=\"http://www.heypasteit.com/clip/2HZX\" rel=\"nofollow noreferrer\">http://www.heypasteit.com/clip/2HZX</a></p>\n\n<p>here is the data with the 7 features: <a href=\"http://www.heypasteit.com/clip/2HZY\" rel=\"nofollow noreferrer\">http://www.heypasteit.com/clip/2HZY</a></p>\n",
                "tags": "<neural-network><regression><linear-regression>",
                "answers": [
                    [
                        "10533",
                        "2",
                        "10517",
                        "",
                        "",
                        "<p>I tried running a <a href=\"http://scikit-learn.org/stable/auto_examples/linear_model/plot_ransac.html\" rel=\"nofollow\">RANSAC model</a> on your data, but got worse results than a straight linear regressor. The ten-fold cross-validated mean absolute error over all three response variables (r,g,b) for the linear model was about 0.37. I also ran a random forest model for comparison, and got about the same score. This suggests that the linear model is not shabby, but it is up to you to decide if either is good enough.</p>\n\n<pre><code>import sklearn.linear_model, sklearn.cross_validation, sklearn.ensemble, pandas\n\nlabels = pandas.read_csv('labels.csv', header=None, names=['r', 'g', 'b'])\nfeatures = pandas.read_csv('features.csv', header=None, names=['area', 'length', 'index', 'complexity', 'lines', 'curves', 'intensity'])\n\nsklearn.cross_validation.cross_val_score(sklearn.linear_model.LinearRegression(), features, labels[:len(features)], 'mean_absolute_error', 10, -1).mean()\n</code></pre>\n\n<p>I also tried visualizing the data with the outliers clipped, but did not find it very enlightening, so I did not include it here.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7163",
            "_score": 16.883047,
            "_source": {
                "title": "ValueError while using linear regression",
                "content": "ValueError while using linear regression <p>I have loaded a dataset and converted into data frame while I am using linear regression I am receiving the following value error as shown in my code below. I am at the moment doing a tutorial and could not figure out how come the arrays are 1-D as the error shows.</p>\n\n<pre><code>from sklearn.datasets import load_boston\nboston_dataset=load_boston()\n\n#create a pandas dataframe and store the data\ndf_boston=pd.DataFrame(boston_dataset.data)\ndf_boston.columns=boston_dataset.feature_names\n\n#append price, target as a new column in the dataset\ndf_boston['Price']=boston_dataset.target\n\n#print first five observations\ndf_boston.head()\n\nCRIM    ZN  INDUS   CHAS    NOX RM  AGE DIS RAD TAX PTRATIO B   LSTAT   Price\n0   0.00632 18.0    2.31    0.0 0.538   6.575   65.2    4.0900  1.0 296.0   15.3    396.90  4.98    24.0\n1   0.02731 0.0 7.07    0.0 0.469   6.421   78.9    4.9671  2.0 242.0   17.8    396.90  9.14    21.6\n2   0.02729 0.0 7.07    0.0 0.469   7.185   61.1    4.9671  2.0 242.0   17.8    392.83  4.03    34.7\n3   0.03237 0.0 2.18    0.0 0.458   6.998   45.8    6.0622  3.0 222.0   18.7    394.63  2.94    33.4\n4   0.06905 0.0 2.18    0.0 0.458   7.147   54.2    6.0622  3.0 222.0   18.7    396.90  5.33    36.2\n\n\n#assign features on x-axis\nX_features=boston_dataset.data\n\n#assign target on y-axis\nY_target=boston_dataset.target\n\n#import linear model-the estimator\nfrom sklearn.linear_model import LinearRegression\nlineReg=LinearRegression()\n\n#fit data into the estimator\nlineReg.fit(X_features,Y_target)\n\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-16-4b5b068e587b&gt; in &lt;module&gt;()\n      1 #fit data into the estimator\n----&gt; 2 lineReg.fit(X_features,Y_target)\n\n/usr/local/lib/python3.4/dist-packages/sklearn/linear_model/base.py in fit(self, X, y, sample_weight)\n    480         n_jobs_ = self.n_jobs\n    481         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n--&gt; 482                          y_numeric=True, multi_output=True)\n    483 \n    484         if sample_weight is not None and np.atleast_1d(sample_weight).ndim &gt; 1:\n</code></pre>\n <machine-learning><scikit-learn><linear-regression><p>It seems in your code you build a pandas dataframe but you do not use it. I recreated your code line by line and was unable to get the same error. Try the following</p>\n\n<pre><code>from sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\nboston = load_boston()\nX = boston.data\nY = boston.target\n\nlineReg = LinearRegression()\nlineReg.fit(X, Y)\nlineReg.score(X, Y)\n</code></pre>\n\n<p>This results in an error of $0.7406$. Of course, this result is kind of meaningless because you should split your data into a training and testing set in order to accurately test your results. </p>\n\n<p>You should do the following</p>\n\n<pre><code>from sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nboston = load_boston()\nX = boston.data\nY = boston.target\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n\nlineReg = LinearRegression()\nlineReg.fit(X_train, y_train)\nlineReg.score(X_test, y_test )\n</code></pre>\n\n<p>This will always give a different score because the data is shuffled before being split into your two sets. You MUST separate your training data are the start of your algorithm and do not pollute your training set with the testing set otherwise you risk biasing your model! This is very important. </p>\n",
                "codes": [
                    [
                        "from sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\nboston = load_boston()\nX = boston.data\nY = boston.target\n\nlineReg = LinearRegression()\nlineReg.fit(X, Y)\nlineReg.score(X, Y)\n",
                        "from sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nboston = load_boston()\nX = boston.data\nY = boston.target\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n\nlineReg = LinearRegression()\nlineReg.fit(X_train, y_train)\nlineReg.score(X_test, y_test )\n"
                    ]
                ],
                "question_id:": "27071",
                "question_votes:": "",
                "question_text:": "<p>I have loaded a dataset and converted into data frame while I am using linear regression I am receiving the following value error as shown in my code below. I am at the moment doing a tutorial and could not figure out how come the arrays are 1-D as the error shows.</p>\n\n<pre><code>from sklearn.datasets import load_boston\nboston_dataset=load_boston()\n\n#create a pandas dataframe and store the data\ndf_boston=pd.DataFrame(boston_dataset.data)\ndf_boston.columns=boston_dataset.feature_names\n\n#append price, target as a new column in the dataset\ndf_boston['Price']=boston_dataset.target\n\n#print first five observations\ndf_boston.head()\n\nCRIM    ZN  INDUS   CHAS    NOX RM  AGE DIS RAD TAX PTRATIO B   LSTAT   Price\n0   0.00632 18.0    2.31    0.0 0.538   6.575   65.2    4.0900  1.0 296.0   15.3    396.90  4.98    24.0\n1   0.02731 0.0 7.07    0.0 0.469   6.421   78.9    4.9671  2.0 242.0   17.8    396.90  9.14    21.6\n2   0.02729 0.0 7.07    0.0 0.469   7.185   61.1    4.9671  2.0 242.0   17.8    392.83  4.03    34.7\n3   0.03237 0.0 2.18    0.0 0.458   6.998   45.8    6.0622  3.0 222.0   18.7    394.63  2.94    33.4\n4   0.06905 0.0 2.18    0.0 0.458   7.147   54.2    6.0622  3.0 222.0   18.7    396.90  5.33    36.2\n\n\n#assign features on x-axis\nX_features=boston_dataset.data\n\n#assign target on y-axis\nY_target=boston_dataset.target\n\n#import linear model-the estimator\nfrom sklearn.linear_model import LinearRegression\nlineReg=LinearRegression()\n\n#fit data into the estimator\nlineReg.fit(X_features,Y_target)\n\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-16-4b5b068e587b&gt; in &lt;module&gt;()\n      1 #fit data into the estimator\n----&gt; 2 lineReg.fit(X_features,Y_target)\n\n/usr/local/lib/python3.4/dist-packages/sklearn/linear_model/base.py in fit(self, X, y, sample_weight)\n    480         n_jobs_ = self.n_jobs\n    481         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n--&gt; 482                          y_numeric=True, multi_output=True)\n    483 \n    484         if sample_weight is not None and np.atleast_1d(sample_weight).ndim &gt; 1:\n</code></pre>\n",
                "tags": "<machine-learning><scikit-learn><linear-regression>",
                "answers": [
                    [
                        "27073",
                        "2",
                        "27071",
                        "",
                        "",
                        "<p>It seems in your code you build a pandas dataframe but you do not use it. I recreated your code line by line and was unable to get the same error. Try the following</p>\n\n<pre><code>from sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\nboston = load_boston()\nX = boston.data\nY = boston.target\n\nlineReg = LinearRegression()\nlineReg.fit(X, Y)\nlineReg.score(X, Y)\n</code></pre>\n\n<p>This results in an error of $0.7406$. Of course, this result is kind of meaningless because you should split your data into a training and testing set in order to accurately test your results. </p>\n\n<p>You should do the following</p>\n\n<pre><code>from sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nboston = load_boston()\nX = boston.data\nY = boston.target\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n\nlineReg = LinearRegression()\nlineReg.fit(X_train, y_train)\nlineReg.score(X_test, y_test )\n</code></pre>\n\n<p>This will always give a different score because the data is shuffled before being split into your two sets. You MUST separate your training data are the start of your algorithm and do not pollute your training set with the testing set otherwise you risk biasing your model! This is very important. </p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "2168",
            "_score": 16.81577,
            "_source": {
                "title": "Why logistic regression example code does not port to linear regression example?",
                "content": "Why logistic regression example code does not port to linear regression example? <p>I am looking at this tutorial: <a href=\"https://www.dataquest.io/mission/74/getting-started-with-kaggle\" rel=\"nofollow\">https://www.dataquest.io/mission/74/getting-started-with-kaggle</a></p>\n\n<p>Following is the code for linear regression to predict, based on some variables, the survival of the titanic passengers.</p>\n\n<pre><code># Import the linear regression class\nfrom sklearn.linear_model import LinearRegression\n# Sklearn also has a helper that makes it easy to do cross validation\nfrom sklearn.cross_validation import KFold\n\n# The columns we'll use to predict the target\npredictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n\n# Initialize our algorithm class\nalg = LinearRegression()\n# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.\n# We set random_state to ensure we get the same splits every time we run this.\nkf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n\npredictions = []\nfor train, test in kf:\n    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.\n    train_predictors = (titanic[predictors].iloc[train])\n    # The target we're using to train the algorithm.\n    train_target = titanic[\"Survived\"].iloc[train]\n    # Training the algorithm using the predictors and target.\n    alg.fit(train_predictors, train_target)\n    # We can now make predictions on the test fold\n    test_predictions = alg.predict(titanic[predictors].iloc[test])\n    predictions.append(test_predictions)\n\nimport numpy as np\n\n# The predictions are in three separate numpy arrays.  Concatenate them into one.  \n# We concatenate them on axis 0, as they only have one axis.\npredictions = np.concatenate(predictions, axis=0)\n\n# Map predictions to outcomes (only possible outcomes are 1 and 0)\npredictions[predictions &gt; .5] = 1\npredictions[predictions &lt;=.5] = 0\n\naccuracy = sum(titanic[\"Survived\"] == predictions)/len(predictions)\n\nprint (accuracy)\n</code></pre>\n\n<p>This is clear. For logistic regression is much easier:</p>\n\n<pre><code>from sklearn import cross_validation\n\n# Initialize our algorithm\nalg = LogisticRegression()\n# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\nscores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n# Take the mean of the scores (because we have one for each fold)\nprint(scores.mean())\n</code></pre>\n\n<p>Now, why can't I do just, for LinearRegression:</p>\n\n<pre><code>from sklearn import cross_validation\n\n# Initialize our algorithm\nalg = LinearRegression()\n# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\nscores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n# Take the mean of the scores (because we have one for each fold)\nprint(scores.mean())\n</code></pre>\n\n<p>This gives me a totally wrong result. Why is that? What is wrong in the last snippet of code?</p>\n <python><logistic-regression><linear-regression><scikit-learn><cross-validation><p>I suspect that you are missing this mapping:</p>\n\n<pre><code># Map predictions to outcomes (only possible outcomes are 1 and 0)\npredictions[predictions &gt; .5] = 1\npredictions[predictions &lt;=.5] = 0\n</code></pre>\n\n<p>Basically, what linear regression produces after a call to <code>predict</code> is a set of numbers (scores), then we need to manually map it back to class label. <code>cross_validation.cross_val_score</code> doesn't do the mapping for us, so what it ends up doing is comparing scores with class labels, which turns out to be bad.</p>\n\n<p>On the other hand, <code>predict</code> of logistic regression gives us the class label (<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict\" rel=\"nofollow\">Reference</a>)</p>\n",
                "codes": [
                    [
                        "# Map predictions to outcomes (only possible outcomes are 1 and 0)\npredictions[predictions > .5] = 1\npredictions[predictions <=.5] = 0\n"
                    ]
                ],
                "question_id:": "10763",
                "question_votes:": "",
                "question_text:": "<p>I am looking at this tutorial: <a href=\"https://www.dataquest.io/mission/74/getting-started-with-kaggle\" rel=\"nofollow\">https://www.dataquest.io/mission/74/getting-started-with-kaggle</a></p>\n\n<p>Following is the code for linear regression to predict, based on some variables, the survival of the titanic passengers.</p>\n\n<pre><code># Import the linear regression class\nfrom sklearn.linear_model import LinearRegression\n# Sklearn also has a helper that makes it easy to do cross validation\nfrom sklearn.cross_validation import KFold\n\n# The columns we'll use to predict the target\npredictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n\n# Initialize our algorithm class\nalg = LinearRegression()\n# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.\n# We set random_state to ensure we get the same splits every time we run this.\nkf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n\npredictions = []\nfor train, test in kf:\n    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.\n    train_predictors = (titanic[predictors].iloc[train])\n    # The target we're using to train the algorithm.\n    train_target = titanic[\"Survived\"].iloc[train]\n    # Training the algorithm using the predictors and target.\n    alg.fit(train_predictors, train_target)\n    # We can now make predictions on the test fold\n    test_predictions = alg.predict(titanic[predictors].iloc[test])\n    predictions.append(test_predictions)\n\nimport numpy as np\n\n# The predictions are in three separate numpy arrays.  Concatenate them into one.  \n# We concatenate them on axis 0, as they only have one axis.\npredictions = np.concatenate(predictions, axis=0)\n\n# Map predictions to outcomes (only possible outcomes are 1 and 0)\npredictions[predictions &gt; .5] = 1\npredictions[predictions &lt;=.5] = 0\n\naccuracy = sum(titanic[\"Survived\"] == predictions)/len(predictions)\n\nprint (accuracy)\n</code></pre>\n\n<p>This is clear. For logistic regression is much easier:</p>\n\n<pre><code>from sklearn import cross_validation\n\n# Initialize our algorithm\nalg = LogisticRegression()\n# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\nscores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n# Take the mean of the scores (because we have one for each fold)\nprint(scores.mean())\n</code></pre>\n\n<p>Now, why can't I do just, for LinearRegression:</p>\n\n<pre><code>from sklearn import cross_validation\n\n# Initialize our algorithm\nalg = LinearRegression()\n# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\nscores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n# Take the mean of the scores (because we have one for each fold)\nprint(scores.mean())\n</code></pre>\n\n<p>This gives me a totally wrong result. Why is that? What is wrong in the last snippet of code?</p>\n",
                "tags": "<python><logistic-regression><linear-regression><scikit-learn><cross-validation>",
                "answers": [
                    [
                        "10766",
                        "2",
                        "10763",
                        "",
                        "",
                        "<p>I suspect that you are missing this mapping:</p>\n\n<pre><code># Map predictions to outcomes (only possible outcomes are 1 and 0)\npredictions[predictions &gt; .5] = 1\npredictions[predictions &lt;=.5] = 0\n</code></pre>\n\n<p>Basically, what linear regression produces after a call to <code>predict</code> is a set of numbers (scores), then we need to manually map it back to class label. <code>cross_validation.cross_val_score</code> doesn't do the mapping for us, so what it ends up doing is comparing scores with class labels, which turns out to be bad.</p>\n\n<p>On the other hand, <code>predict</code> of logistic regression gives us the class label (<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict\" rel=\"nofollow\">Reference</a>)</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9900",
            "_score": 16.80254,
            "_source": {
                "title": "Predict the accuracy of Linear Regression",
                "content": "Predict the accuracy of Linear Regression <p>How do I test if the predicted values in Linear Regression model are matching with the actuals?</p>\n\n<p>I tried using - Confusion matrix, but I get this error -</p>\n\n<pre><code>#==============================================================================\n# Create confusion matrix to evaluate performance of data\n#==============================================================================\nfrom sklearn.metrics import confusion_matrix\nconfusionMatrix = confusion_matrix (dv_test, y_pred)\n\nprint(confusionMatrix)\n</code></pre>\n\n<p><code>ValueError: Can't handle mix of multiclass and continuous</code></p>\n\n<p>When I execute the below code -</p>\n\n<pre><code>##Performing Linear Regression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import model_selection\nregressor=LinearRegression()\n##Fit train\nregressor.fit(iv_train,dv_train)\ny_pred=regressor.predict(iv_test)\nprint('Accuracy of LR',mean_squared_error(y_pred,dv_test))\n</code></pre>\n\n<p>It results - Accuracy of LR 7837176694.18</p>\n\n<p>Which is incorrect.</p>\n\n<p>Below is my sample data set -</p>\n\n<pre><code>longitude   latitude    housing_median_age  total_rooms total_bedrooms  population  households  median_income   ocean_proximity median_house_value\n-122.23 37.88   41  880 129 322 126 8.3252  NEAR BAY    452600\n-122.22 37.86   21  7099    1106    2401    1138    8.3014  NEAR BAY    358500\n-122.24 37.85   52  1467    190 496 177 7.2574  NEAR BAY    352100\n-122.25 37.85   52  1274    235 558 219 5.6431  NEAR BAY    341300\n-122.25 37.85   52  1627    280 565 259 3.8462  NEAR BAY    342200\n-122.25 37.85   52  919 213 413 193 4.0368  NEAR BAY    269700\n-122.25 37.84   52  2535    489 1094    514 3.6591  NEAR BAY    299200\n</code></pre>\n <scikit-learn><linear-regression><p>There are several ways to check your Linear Regression model accuracy. Usually, you may use <strong>Root mean squared error</strong>. You may train several Linear Regression models, adding or removing features to your dataset, and see which one has the lowest <strong>RMSE</strong> - the best one in your case. Also try to normalize your data before fitting into Linear Regression model. </p>\n\n<p>The confusion matrix is used to check discrete results, but Linear Regression model returns predicted result as a continuous values. That is why you get the error: your <code>dv_test</code> data likely is integer, but <code>y_pred</code> is float.</p>\n\n<p>You may try using classification model if it is suitable for the problem you try to solve - depends on what you try to predict. But for regression problem it would be better to use metric mentioned above. </p>\n",
                "codes": [
                    []
                ],
                "question_id:": "36083",
                "question_votes:": "2",
                "question_text:": "<p>How do I test if the predicted values in Linear Regression model are matching with the actuals?</p>\n\n<p>I tried using - Confusion matrix, but I get this error -</p>\n\n<pre><code>#==============================================================================\n# Create confusion matrix to evaluate performance of data\n#==============================================================================\nfrom sklearn.metrics import confusion_matrix\nconfusionMatrix = confusion_matrix (dv_test, y_pred)\n\nprint(confusionMatrix)\n</code></pre>\n\n<p><code>ValueError: Can't handle mix of multiclass and continuous</code></p>\n\n<p>When I execute the below code -</p>\n\n<pre><code>##Performing Linear Regression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import model_selection\nregressor=LinearRegression()\n##Fit train\nregressor.fit(iv_train,dv_train)\ny_pred=regressor.predict(iv_test)\nprint('Accuracy of LR',mean_squared_error(y_pred,dv_test))\n</code></pre>\n\n<p>It results - Accuracy of LR 7837176694.18</p>\n\n<p>Which is incorrect.</p>\n\n<p>Below is my sample data set -</p>\n\n<pre><code>longitude   latitude    housing_median_age  total_rooms total_bedrooms  population  households  median_income   ocean_proximity median_house_value\n-122.23 37.88   41  880 129 322 126 8.3252  NEAR BAY    452600\n-122.22 37.86   21  7099    1106    2401    1138    8.3014  NEAR BAY    358500\n-122.24 37.85   52  1467    190 496 177 7.2574  NEAR BAY    352100\n-122.25 37.85   52  1274    235 558 219 5.6431  NEAR BAY    341300\n-122.25 37.85   52  1627    280 565 259 3.8462  NEAR BAY    342200\n-122.25 37.85   52  919 213 413 193 4.0368  NEAR BAY    269700\n-122.25 37.84   52  2535    489 1094    514 3.6591  NEAR BAY    299200\n</code></pre>\n",
                "tags": "<scikit-learn><linear-regression>",
                "answers": [
                    [
                        "36086",
                        "2",
                        "36083",
                        "",
                        "",
                        "<p>There are several ways to check your Linear Regression model accuracy. Usually, you may use <strong>Root mean squared error</strong>. You may train several Linear Regression models, adding or removing features to your dataset, and see which one has the lowest <strong>RMSE</strong> - the best one in your case. Also try to normalize your data before fitting into Linear Regression model. </p>\n\n<p>The confusion matrix is used to check discrete results, but Linear Regression model returns predicted result as a continuous values. That is why you get the error: your <code>dv_test</code> data likely is integer, but <code>y_pred</code> is float.</p>\n\n<p>You may try using classification model if it is suitable for the problem you try to solve - depends on what you try to predict. But for regression problem it would be better to use metric mentioned above. </p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10704",
            "_score": 16.792477,
            "_source": {
                "title": "Recreating sklearn linear regression from coefficients and intercept",
                "content": "Recreating sklearn linear regression from coefficients and intercept <p>I am attempting to write my own linear regression function using the coefficients and intercept achieved using the <code>sklearn LinearRegression</code> model. I have 11 features. I am using <code>model.coef_[0]</code> to extract the coefficient for feature 1 etc.. When I recreate the regression function the results are vastly different.</p>\n\n<p>Does <code>model.coef_[0]</code> always correspond to the coefficient for feature 1 etc or do I need to do something to check this? Any tips on this would be greatly appreciated</p>\n\n<p><strong>Update</strong></p>\n\n<p>This was my mistake. I copy and pasted the values directly from <code>print(coef_)</code> and this resulted in a rounding error!</p>\n <python><scikit-learn><linear-regression>",
                "codes": [],
                "question_id:": "38196",
                "question_votes:": "3",
                "question_text:": "<p>I am attempting to write my own linear regression function using the coefficients and intercept achieved using the <code>sklearn LinearRegression</code> model. I have 11 features. I am using <code>model.coef_[0]</code> to extract the coefficient for feature 1 etc.. When I recreate the regression function the results are vastly different.</p>\n\n<p>Does <code>model.coef_[0]</code> always correspond to the coefficient for feature 1 etc or do I need to do something to check this? Any tips on this would be greatly appreciated</p>\n\n<p><strong>Update</strong></p>\n\n<p>This was my mistake. I copy and pasted the values directly from <code>print(coef_)</code> and this resulted in a rounding error!</p>\n",
                "tags": "<python><scikit-learn><linear-regression>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8239",
            "_score": 16.68599,
            "_source": {
                "title": "Regression coefficients vs feature_importances_ vs none",
                "content": "Regression coefficients vs feature_importances_ vs none <p>On looking at various machine learning methods at the scikit-learn site <a href=\"http://scikit-learn.org/stable/modules/classes.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/classes.html</a> , it appears that some modules such as linear regression ( <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html</a> ) provide coefficients (<code>coef_</code>), others such as AdaBoostRegressor ( <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html</a> ) provide <code>feature_importances_</code> while some e.g. BaggingRegressor ( <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html</a> ) do not provide either of these. </p>\n\n<p>Why this difference? Are <code>coefficients</code> similar to <code>feature_importances_</code> to assess the contribution of a variable in prediction? How to assess the feature importance for modules where neither of these is available e.g. in BaggingRegressor (link above) and BernoulliNB ( <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html</a> )? </p>\n <machine-learning><scikit-learn><feature-selection><p>The main difference between Linear Regression and Tree-based methods is that Linear Regression is parametric: it can be writen with a mathematical closed expression depending on some parameters. Therefore, the coefficients are the parameters of the model, and should not be taken as any kind of importances unless the data is normalized. </p>\n\n<p>On the other hand, non-parametric methods have very different ways of measure the importance. In layman terms, measuring the importance of variables on a tree can be done by checking how close they appear to the root node. In ensembling methods, like bagging, one can compute the importance of a variable as the average among the ensemble, like in this <a href=\"https://stackoverflow.com/questions/44333573/feature-importances-bagging-scikit-learn\">stackoverflow answer.</a></p>\n\n<p>The main difference is, then, the fact that parametric models have, through their parameters, a way of showing the importance of the variables, while non parametric models need some extra work.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "30312",
                "question_votes:": "2",
                "question_text:": "<p>On looking at various machine learning methods at the scikit-learn site <a href=\"http://scikit-learn.org/stable/modules/classes.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/classes.html</a> , it appears that some modules such as linear regression ( <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html</a> ) provide coefficients (<code>coef_</code>), others such as AdaBoostRegressor ( <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html</a> ) provide <code>feature_importances_</code> while some e.g. BaggingRegressor ( <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html</a> ) do not provide either of these. </p>\n\n<p>Why this difference? Are <code>coefficients</code> similar to <code>feature_importances_</code> to assess the contribution of a variable in prediction? How to assess the feature importance for modules where neither of these is available e.g. in BaggingRegressor (link above) and BernoulliNB ( <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html</a> )? </p>\n",
                "tags": "<machine-learning><scikit-learn><feature-selection>",
                "answers": [
                    [
                        "30894",
                        "2",
                        "30312",
                        "",
                        "",
                        "<p>The main difference between Linear Regression and Tree-based methods is that Linear Regression is parametric: it can be writen with a mathematical closed expression depending on some parameters. Therefore, the coefficients are the parameters of the model, and should not be taken as any kind of importances unless the data is normalized. </p>\n\n<p>On the other hand, non-parametric methods have very different ways of measure the importance. In layman terms, measuring the importance of variables on a tree can be done by checking how close they appear to the root node. In ensembling methods, like bagging, one can compute the importance of a variable as the average among the ensemble, like in this <a href=\"https://stackoverflow.com/questions/44333573/feature-importances-bagging-scikit-learn\">stackoverflow answer.</a></p>\n\n<p>The main difference is, then, the fact that parametric models have, through their parameters, a way of showing the importance of the variables, while non parametric models need some extra work.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11442",
            "_score": 16.645678,
            "_source": {
                "title": "Linear Regression in python with multiple outputs",
                "content": "Linear Regression in python with multiple outputs <p>I have a time series dataset which represented as following: </p>\n\n<pre><code>x=[ \n       [12.19047619,  18.28571429,   6.0952381 ] ,\n\n       [ 80.98765432,  14.17283951,  11.13580247 ] ,\n\n       [ 50.82644628,  16.26446281,   9.14876033 ] , .... ]\n\n\nand to predicted --&gt;\n Y  = [13.9,  18,   14.987]\n</code></pre>\n\n<p>How I can use LASSO and SVR linear regression models in python to predict Y (which represented as a vector as shown in the above example) </p>\n <python><linear-regression><p>Both Lasso and SVM are available in sklearn library. Lasso: <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\" rel=\"nofollow noreferrer\">sklearn.linear_model.Lasso</a>. SVM: <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\" rel=\"nofollow noreferrer\">sklearn.svm.SVT</a></p>\n\n<p>An example from Lasso page:</p>\n\n<pre><code>&gt;&gt;&gt; from sklearn import linear_model\n&gt;&gt;&gt; clf = linear_model.Lasso(alpha=0.1)\n&gt;&gt;&gt; clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\nLasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000, normalize=False, positive=False, precompute=False, random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n&gt;&gt;&gt; print(clf.coef_)\n[0.85 0. ]\n&gt;&gt;&gt; print(clf.intercept_)\n0.15...\n</code></pre>\n\n<p>In your case clf.fit looks like this:</p>\n\n<pre><code>clf.fit(X, Y)\n</code></pre>\n\n<p>X should be the size (nn,n)<br>\nY should be the size nn<br>\nWhere nn is the number of observations (points) and n is the number of variables. So rows in X are observations and columns are different variables.</p>\n\n<p>If you have more variables than observations then you should read <a href=\"https://stats.stackexchange.com/questions/223486/modelling-with-more-variables-than-data-points\">this post</a> about the problems you can have with it and how to solve them. </p>\n",
                "codes": [
                    [
                        ">>> from sklearn import linear_model\n>>> clf = linear_model.Lasso(alpha=0.1)\n>>> clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\nLasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000, normalize=False, positive=False, precompute=False, random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n>>> print(clf.coef_)\n[0.85 0. ]\n>>> print(clf.intercept_)\n0.15...\n",
                        "clf.fit(X, Y)\n"
                    ]
                ],
                "question_id:": "40394",
                "question_votes:": "1",
                "question_text:": "<p>I have a time series dataset which represented as following: </p>\n\n<pre><code>x=[ \n       [12.19047619,  18.28571429,   6.0952381 ] ,\n\n       [ 80.98765432,  14.17283951,  11.13580247 ] ,\n\n       [ 50.82644628,  16.26446281,   9.14876033 ] , .... ]\n\n\nand to predicted --&gt;\n Y  = [13.9,  18,   14.987]\n</code></pre>\n\n<p>How I can use LASSO and SVR linear regression models in python to predict Y (which represented as a vector as shown in the above example) </p>\n",
                "tags": "<python><linear-regression>",
                "answers": [
                    [
                        "40400",
                        "2",
                        "40394",
                        "",
                        "",
                        "<p>Both Lasso and SVM are available in sklearn library. Lasso: <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\" rel=\"nofollow noreferrer\">sklearn.linear_model.Lasso</a>. SVM: <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\" rel=\"nofollow noreferrer\">sklearn.svm.SVT</a></p>\n\n<p>An example from Lasso page:</p>\n\n<pre><code>&gt;&gt;&gt; from sklearn import linear_model\n&gt;&gt;&gt; clf = linear_model.Lasso(alpha=0.1)\n&gt;&gt;&gt; clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\nLasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000, normalize=False, positive=False, precompute=False, random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n&gt;&gt;&gt; print(clf.coef_)\n[0.85 0. ]\n&gt;&gt;&gt; print(clf.intercept_)\n0.15...\n</code></pre>\n\n<p>In your case clf.fit looks like this:</p>\n\n<pre><code>clf.fit(X, Y)\n</code></pre>\n\n<p>X should be the size (nn,n)<br>\nY should be the size nn<br>\nWhere nn is the number of observations (points) and n is the number of variables. So rows in X are observations and columns are different variables.</p>\n\n<p>If you have more variables than observations then you should read <a href=\"https://stats.stackexchange.com/questions/223486/modelling-with-more-variables-than-data-points\">this post</a> about the problems you can have with it and how to solve them. </p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7329",
            "_score": 16.592613,
            "_source": {
                "title": "Find the order of importance of random variables in their ability to explain a variance of Y",
                "content": "Find the order of importance of random variables in their ability to explain a variance of Y <p>Problem statement:\nGiven a set of random variables Xs, give the order of importance of their ability to explain variance in target variable Y. Assumes all Xs are normalised to have 0 mean and std dev of 1.</p>\n\n<p>Can treat this as regression problem(normal or ordinal)</p>\n\n<p>Solution for 2 cases:\nCase 1: When the calculated covariance matrix is diagonal, I know that random variables Xs are independent wrt each other. Then I can fit a linear regression model and order Xs by their weights.</p>\n\n<p>Case 2: Or If I know that Xs are independent(<a href=\"https://en.wikipedia.org/wiki/Independence_(probability_theory)\" rel=\"nofollow noreferrer\">https://en.wikipedia.org/wiki/Independence_(probability_theory)</a>\neven though their covariance in non zero, I can fit linear regression model and order Xs by weights.</p>\n\n<p>How do I solve this problem when I know that random variable Xs are not independent and have non zero covariance?</p>\n\n<p>Also how can I use a non linear model such as random forest to get variable importance? scikit provides feature_importances_ api for random forest.... Is there an gotcha with this api such as results are not meaningful when variables are dependent or covariant?</p>\n\n<p>Found this question elsewhere: <a href=\"https://stats.stackexchange.com/questions/202221/for-linear-classifiers-do-larger-coefficients-imply-more-important-features/202846\">https://stats.stackexchange.com/questions/202221/for-linear-classifiers-do-larger-coefficients-imply-more-important-features/202846</a></p>\n <scikit-learn><random-forest><linear-regression><p><strong>Decision trees</strong> are by nature immune to multi-collinearity. So by that principal so is <strong>Random Forest</strong>. For example, if you have 2 features which are 99% correlated, when deciding upon a split the tree will choose only one of them. Other models such as Logistic regression would use both the features. - follow <a href=\"https://datascience.stackexchange.com/a/12597/30578\">this link</a> to know more.</p>\n\n<p>For other models, solutions can be many, but here are the popular choices - </p>\n\n<p><strong>Regularization</strong></p>\n\n<p>This is an automatic way of handling high correlations in your Xs. It decreases the value of the co-efficients by penalizing them against the loss function and introduces bias in the system. Popular implementations are <code>L1</code>, <code>L2</code> and <code>Elastic Net</code>(in case of linear and logistic models), <code>Pruning</code>(in case of Decision Trees), <code>Dropout</code> and <code>max pooling</code> in case of deep learning. </p>\n\n<p>Almost all <code>sklearn</code> implementations support a regularization parameter in 1 way or the other. Depends on the algorithm you are using.</p>\n\n<p><strong>Using VIF to detect multi-collinearity</strong></p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Variance_inflation_factor\" rel=\"nofollow noreferrer\">Variance Inflation Factor</a> is a metric that you can use with all your Xs and then start dropping variables with the highest VIF <em>one by one</em> (usually the variable with the highest VIF is dropped and then the exercise is repeated till there is no multi-collinearity left or domain experts come in and choose what important variables to keep/drop)</p>\n\n<p><strong>Principal Component Analysis</strong></p>\n\n<p>Although the model might lose its interpretability (you won't be able to tell exactly what feature is how important), <code>PCA</code> has been another effective way of removing multi-collinearity. Basically it projects the data in a way that the output columns are orthogonal (independent)</p>\n\n<p><strong>Some Examples</strong></p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\" rel=\"nofollow noreferrer\">Ridge Regression</a></p>\n\n<pre><code> from sklearn.linear_model import Ridge\n import numpy as np\n n_samples, n_features = 10, 5\n np.random.seed(0)\n y = np.random.randn(n_samples)\n X = np.random.randn(n_samples, n_features)\n clf = Ridge(alpha=1.0)\n clf.fit(X, y) \n</code></pre>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\" rel=\"nofollow noreferrer\">Lasso Regression</a></p>\n\n<pre><code> from sklearn import linear_model\n clf = linear_model.Lasso(alpha=0.1)\n clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\n</code></pre>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\" rel=\"nofollow noreferrer\">Elastic Net</a></p>\n\n<pre><code> from sklearn.linear_model import ElasticNet\n from sklearn.datasets import make_regression\n\n X, y = make_regression(n_features=2, random_state=0)\n regr = ElasticNet(random_state=0)\n regr.fit(X, y)\n</code></pre>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" rel=\"nofollow noreferrer\">Random Forest</a>\n - Almost all parameters in scikit-learn can account for regularization here</p>\n\n<p><a href=\"http://www.statsmodels.org/dev/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html\" rel=\"nofollow noreferrer\">Statsmodels</a> has a rather good implementation of VIF</p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\" rel=\"nofollow noreferrer\">PCA</a></p>\n\n<pre><code>import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\n\nX = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\npca = PCA(n_components=2) # adjust yourself\npca.fit(X)\n\nX_t_train = pca.transform(X)\nclf = SVC()\nclf.fit(X_t_train, y)\n</code></pre>\n",
                "codes": [
                    [
                        " from sklearn.linear_model import Ridge\n import numpy as np\n n_samples, n_features = 10, 5\n np.random.seed(0)\n y = np.random.randn(n_samples)\n X = np.random.randn(n_samples, n_features)\n clf = Ridge(alpha=1.0)\n clf.fit(X, y) \n",
                        " from sklearn import linear_model\n clf = linear_model.Lasso(alpha=0.1)\n clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\n",
                        " from sklearn.linear_model import ElasticNet\n from sklearn.datasets import make_regression\n\n X, y = make_regression(n_features=2, random_state=0)\n regr = ElasticNet(random_state=0)\n regr.fit(X, y)\n",
                        "import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\n\nX = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\npca = PCA(n_components=2) # adjust yourself\npca.fit(X)\n\nX_t_train = pca.transform(X)\nclf = SVC()\nclf.fit(X_t_train, y)\n"
                    ]
                ],
                "question_id:": "27542",
                "question_votes:": "",
                "question_text:": "<p>Problem statement:\nGiven a set of random variables Xs, give the order of importance of their ability to explain variance in target variable Y. Assumes all Xs are normalised to have 0 mean and std dev of 1.</p>\n\n<p>Can treat this as regression problem(normal or ordinal)</p>\n\n<p>Solution for 2 cases:\nCase 1: When the calculated covariance matrix is diagonal, I know that random variables Xs are independent wrt each other. Then I can fit a linear regression model and order Xs by their weights.</p>\n\n<p>Case 2: Or If I know that Xs are independent(<a href=\"https://en.wikipedia.org/wiki/Independence_(probability_theory)\" rel=\"nofollow noreferrer\">https://en.wikipedia.org/wiki/Independence_(probability_theory)</a>\neven though their covariance in non zero, I can fit linear regression model and order Xs by weights.</p>\n\n<p>How do I solve this problem when I know that random variable Xs are not independent and have non zero covariance?</p>\n\n<p>Also how can I use a non linear model such as random forest to get variable importance? scikit provides feature_importances_ api for random forest.... Is there an gotcha with this api such as results are not meaningful when variables are dependent or covariant?</p>\n\n<p>Found this question elsewhere: <a href=\"https://stats.stackexchange.com/questions/202221/for-linear-classifiers-do-larger-coefficients-imply-more-important-features/202846\">https://stats.stackexchange.com/questions/202221/for-linear-classifiers-do-larger-coefficients-imply-more-important-features/202846</a></p>\n",
                "tags": "<scikit-learn><random-forest><linear-regression>",
                "answers": [
                    [
                        "27543",
                        "2",
                        "27542",
                        "",
                        "",
                        "<p><strong>Decision trees</strong> are by nature immune to multi-collinearity. So by that principal so is <strong>Random Forest</strong>. For example, if you have 2 features which are 99% correlated, when deciding upon a split the tree will choose only one of them. Other models such as Logistic regression would use both the features. - follow <a href=\"https://datascience.stackexchange.com/a/12597/30578\">this link</a> to know more.</p>\n\n<p>For other models, solutions can be many, but here are the popular choices - </p>\n\n<p><strong>Regularization</strong></p>\n\n<p>This is an automatic way of handling high correlations in your Xs. It decreases the value of the co-efficients by penalizing them against the loss function and introduces bias in the system. Popular implementations are <code>L1</code>, <code>L2</code> and <code>Elastic Net</code>(in case of linear and logistic models), <code>Pruning</code>(in case of Decision Trees), <code>Dropout</code> and <code>max pooling</code> in case of deep learning. </p>\n\n<p>Almost all <code>sklearn</code> implementations support a regularization parameter in 1 way or the other. Depends on the algorithm you are using.</p>\n\n<p><strong>Using VIF to detect multi-collinearity</strong></p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Variance_inflation_factor\" rel=\"nofollow noreferrer\">Variance Inflation Factor</a> is a metric that you can use with all your Xs and then start dropping variables with the highest VIF <em>one by one</em> (usually the variable with the highest VIF is dropped and then the exercise is repeated till there is no multi-collinearity left or domain experts come in and choose what important variables to keep/drop)</p>\n\n<p><strong>Principal Component Analysis</strong></p>\n\n<p>Although the model might lose its interpretability (you won't be able to tell exactly what feature is how important), <code>PCA</code> has been another effective way of removing multi-collinearity. Basically it projects the data in a way that the output columns are orthogonal (independent)</p>\n\n<p><strong>Some Examples</strong></p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\" rel=\"nofollow noreferrer\">Ridge Regression</a></p>\n\n<pre><code> from sklearn.linear_model import Ridge\n import numpy as np\n n_samples, n_features = 10, 5\n np.random.seed(0)\n y = np.random.randn(n_samples)\n X = np.random.randn(n_samples, n_features)\n clf = Ridge(alpha=1.0)\n clf.fit(X, y) \n</code></pre>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\" rel=\"nofollow noreferrer\">Lasso Regression</a></p>\n\n<pre><code> from sklearn import linear_model\n clf = linear_model.Lasso(alpha=0.1)\n clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\n</code></pre>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\" rel=\"nofollow noreferrer\">Elastic Net</a></p>\n\n<pre><code> from sklearn.linear_model import ElasticNet\n from sklearn.datasets import make_regression\n\n X, y = make_regression(n_features=2, random_state=0)\n regr = ElasticNet(random_state=0)\n regr.fit(X, y)\n</code></pre>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" rel=\"nofollow noreferrer\">Random Forest</a>\n - Almost all parameters in scikit-learn can account for regularization here</p>\n\n<p><a href=\"http://www.statsmodels.org/dev/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html\" rel=\"nofollow noreferrer\">Statsmodels</a> has a rather good implementation of VIF</p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\" rel=\"nofollow noreferrer\">PCA</a></p>\n\n<pre><code>import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\n\nX = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\npca = PCA(n_components=2) # adjust yourself\npca.fit(X)\n\nX_t_train = pca.transform(X)\nclf = SVC()\nclf.fit(X_t_train, y)\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "1446",
            "_score": 16.545776,
            "_source": {
                "title": "Multivariate linear regression in Python",
                "content": "Multivariate linear regression in Python <p>I'm looking for a Python package that implements multivariate linear regression.</p>\n\n<p>(Terminological note: <em>multivariate</em> regression deals with the case where there are more than one dependent variables while <em>multiple</em> regression deals with the case where there is one dependent variable but more than one independent variables.)</p>\n <python><regression><library><software-recommendation><p>You can still use <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression\" rel=\"noreferrer\">sklearn.linear_model.LinearRegression</a>.  Simply make the output <code>y</code> a matrix with as many columns as you have dependent variables.  If you want something <a href=\"http://scikit-learn.org/stable/modules/linear_model.html#polynomial-regression-extending-linear-models-with-basis-functions\" rel=\"noreferrer\">non-linear</a>, you can try different basis functions, use polynomial features, or use a different method for regression (like a NN).</p>\n<p>Just for fun you can compute the feature by hand by forming tuples $seq =(d_1,...,d_N)$ such that $Sum(seq) = \\sum^N_{i=1} \\leq D$. Once you form those tuples each entry indicates the power the current raw feature should be raised by. So say $(1,2,3)$ would map to the monomial $x_1 x_2^2 x_3^3$.</p>\n\n<p>The code to get the tuples is:</p>\n\n<pre><code>def generate_all_tuples_for_monomials(N,D):\n    if D == 0:\n        seq0 = N*[0]\n        sequences_degree_0 = [seq0]\n        S_0 = {0:sequences_degree_0}\n        return S_0\n    else:\n        # S_all = [ k-&gt;S_D ] ~ [ k-&gt;[seq0,...,seqK]]\n        S_all = generate_all_tuples_for_monomials(N,D-1)# S^* = (S^*_D-1) U S_D\n        print(S_all)\n        #\n        S_D_current = []\n        # for every prev set of degree tuples\n        #for d in range(len(S_all.items())): # d \\in [0,...,D_current]\n        d = D-1\n        d_new = D - d # get new valid degree number\n        # for each sequences, create the new valid degree tuple\n        S_all_seq_for_deg_d = S_all[d]\n        for seq in S_all[d]:\n            for pos in range(N):\n                seq_new = seq[:]\n                seq_new[pos] = seq_new[pos] + d_new # seq elements dd to D\n                if seq_new not in S_D_current:\n                    S_D_current.append(seq_new)\n        S_all[D] = S_D_current\n        return S_all\n</code></pre>\n\n<p>then it should be easy to do regression if you know linear algebra.</p>\n\n<pre><code>c = pseudo_inverse(X_poly)*y\n</code></pre>\n\n<p>example. Probably better to do regularized linear regression though if your interested in generalization.</p>\n\n<hr>\n\n<p>Acknowledgements to <a href=\"https://cs.stackexchange.com/questions/80549/how-does-one-generate-all-the-terms-of-a-multivariate-polynomial-algorithmically/80550#comment171459_80550\">Yuval is CS exchange</a> for the help. </p>\n",
                "codes": [
                    [],
                    [
                        "def generate_all_tuples_for_monomials(N,D):\n    if D == 0:\n        seq0 = N*[0]\n        sequences_degree_0 = [seq0]\n        S_0 = {0:sequences_degree_0}\n        return S_0\n    else:\n        # S_all = [ k->S_D ] ~ [ k->[seq0,...,seqK]]\n        S_all = generate_all_tuples_for_monomials(N,D-1)# S^* = (S^*_D-1) U S_D\n        print(S_all)\n        #\n        S_D_current = []\n        # for every prev set of degree tuples\n        #for d in range(len(S_all.items())): # d \\in [0,...,D_current]\n        d = D-1\n        d_new = D - d # get new valid degree number\n        # for each sequences, create the new valid degree tuple\n        S_all_seq_for_deg_d = S_all[d]\n        for seq in S_all[d]:\n            for pos in range(N):\n                seq_new = seq[:]\n                seq_new[pos] = seq_new[pos] + d_new # seq elements dd to D\n                if seq_new not in S_D_current:\n                    S_D_current.append(seq_new)\n        S_all[D] = S_D_current\n        return S_all\n",
                        "c = pseudo_inverse(X_poly)*y\n"
                    ]
                ],
                "question_id:": "8625",
                "question_votes:": "9",
                "question_text:": "<p>I'm looking for a Python package that implements multivariate linear regression.</p>\n\n<p>(Terminological note: <em>multivariate</em> regression deals with the case where there are more than one dependent variables while <em>multiple</em> regression deals with the case where there is one dependent variable but more than one independent variables.)</p>\n",
                "tags": "<python><regression><library><software-recommendation>",
                "answers": [
                    [
                        "8632",
                        "2",
                        "8625",
                        "",
                        "",
                        "<p>You can still use <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression\" rel=\"noreferrer\">sklearn.linear_model.LinearRegression</a>.  Simply make the output <code>y</code> a matrix with as many columns as you have dependent variables.  If you want something <a href=\"http://scikit-learn.org/stable/modules/linear_model.html#polynomial-regression-extending-linear-models-with-basis-functions\" rel=\"noreferrer\">non-linear</a>, you can try different basis functions, use polynomial features, or use a different method for regression (like a NN).</p>\n",
                        "",
                        "9"
                    ],
                    [
                        "22663",
                        "2",
                        "8625",
                        "",
                        "",
                        "<p>Just for fun you can compute the feature by hand by forming tuples $seq =(d_1,...,d_N)$ such that $Sum(seq) = \\sum^N_{i=1} \\leq D$. Once you form those tuples each entry indicates the power the current raw feature should be raised by. So say $(1,2,3)$ would map to the monomial $x_1 x_2^2 x_3^3$.</p>\n\n<p>The code to get the tuples is:</p>\n\n<pre><code>def generate_all_tuples_for_monomials(N,D):\n    if D == 0:\n        seq0 = N*[0]\n        sequences_degree_0 = [seq0]\n        S_0 = {0:sequences_degree_0}\n        return S_0\n    else:\n        # S_all = [ k-&gt;S_D ] ~ [ k-&gt;[seq0,...,seqK]]\n        S_all = generate_all_tuples_for_monomials(N,D-1)# S^* = (S^*_D-1) U S_D\n        print(S_all)\n        #\n        S_D_current = []\n        # for every prev set of degree tuples\n        #for d in range(len(S_all.items())): # d \\in [0,...,D_current]\n        d = D-1\n        d_new = D - d # get new valid degree number\n        # for each sequences, create the new valid degree tuple\n        S_all_seq_for_deg_d = S_all[d]\n        for seq in S_all[d]:\n            for pos in range(N):\n                seq_new = seq[:]\n                seq_new[pos] = seq_new[pos] + d_new # seq elements dd to D\n                if seq_new not in S_D_current:\n                    S_D_current.append(seq_new)\n        S_all[D] = S_D_current\n        return S_all\n</code></pre>\n\n<p>then it should be easy to do regression if you know linear algebra.</p>\n\n<pre><code>c = pseudo_inverse(X_poly)*y\n</code></pre>\n\n<p>example. Probably better to do regularized linear regression though if your interested in generalization.</p>\n\n<hr>\n\n<p>Acknowledgements to <a href=\"https://cs.stackexchange.com/questions/80549/how-does-one-generate-all-the-terms-of-a-multivariate-polynomial-algorithmically/80550#comment171459_80550\">Yuval is CS exchange</a> for the help. </p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "18147",
            "_score": 16.510948,
            "_source": {
                "title": "How to combine nlp and numeric data for a linear regression problem",
                "content": "How to combine nlp and numeric data for a linear regression problem <p>I'm very new to data science (this is my hello world project), and I have a data set made up of a combination of review text and numerical data such as number of tables. There is also a column for reviews which is a float (avg of all user reviews for that restaurant). So a row of data could be like:</p>\n\n<pre><code>{ \n    rating: 3.765, \n    review: `Food was great, staff was friendly`, \n    tables: 30, \n    staff: 15, \n    parking: 20\n    ... \n}\n</code></pre>\n\n<p>So following tutorials, I have been able to do the following:</p>\n\n<ol>\n<li>Created a linear regression model to predict rating with the inputs being all the numerical data columns.</li>\n<li>Created a regression model to predict rating based on review text using sklearn.TfidfVectorizer.</li>\n</ol>\n\n<p>But now I'd like to combine models or combine the data from both into one to create a linear regression model. So how can I utilize the vectorized text data in my linear regression model?</p>\n <scikit-learn><nlp><linear-regression><tfidf><p>It sounds like you could use <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html\" rel=\"nofollow noreferrer\">FeatureUnion</a> for this. Here's an <a href=\"https://scikit-learn.org/stable/auto_examples/compose/plot_feature_union.html\" rel=\"nofollow noreferrer\">example</a>:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import SelectKBest\n\niris = load_iris()\n\nX, y = iris.data, iris.target\n\n# This dataset is way too high-dimensional. Better do PCA:\npca = PCA(n_components=2)\n\n# Maybe some original features where good, too?\nselection = SelectKBest(k=1)\n\n# Build estimator from PCA and Univariate selection:\n\ncombined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n\n# Use combined features to transform dataset:\nX_features = combined_features.fit(X, y).transform(X)\nprint(\"Combined space has\", X_features.shape[1], \"features\")\n\nsvm = SVC(kernel=\"linear\")\n\n# Do grid search over k, n_components and C:\n\npipeline = Pipeline([(\"features\", combined_features), (\"svm\", svm)])\n\nparam_grid = dict(features__pca__n_components=[1, 2, 3],\n                  features__univ_select__k=[1, 2],\n                  svm__C=[0.1, 1, 10])\n\ngrid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, verbose=10)\ngrid_search.fit(X, y)\nprint(grid_search.best_estimator_)\n</code></pre>\n\n<p>Hopefully it is clear from that example how you could use this to merge your TfidfVectorizer results with your original features.</p>\n",
                "codes": [
                    [
                        "from sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import SelectKBest\n\niris = load_iris()\n\nX, y = iris.data, iris.target\n\n# This dataset is way too high-dimensional. Better do PCA:\npca = PCA(n_components=2)\n\n# Maybe some original features where good, too?\nselection = SelectKBest(k=1)\n\n# Build estimator from PCA and Univariate selection:\n\ncombined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n\n# Use combined features to transform dataset:\nX_features = combined_features.fit(X, y).transform(X)\nprint(\"Combined space has\", X_features.shape[1], \"features\")\n\nsvm = SVC(kernel=\"linear\")\n\n# Do grid search over k, n_components and C:\n\npipeline = Pipeline([(\"features\", combined_features), (\"svm\", svm)])\n\nparam_grid = dict(features__pca__n_components=[1, 2, 3],\n                  features__univ_select__k=[1, 2],\n                  svm__C=[0.1, 1, 10])\n\ngrid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, verbose=10)\ngrid_search.fit(X, y)\nprint(grid_search.best_estimator_)\n"
                    ]
                ],
                "question_id:": "57764",
                "question_votes:": "",
                "question_text:": "<p>I'm very new to data science (this is my hello world project), and I have a data set made up of a combination of review text and numerical data such as number of tables. There is also a column for reviews which is a float (avg of all user reviews for that restaurant). So a row of data could be like:</p>\n\n<pre><code>{ \n    rating: 3.765, \n    review: `Food was great, staff was friendly`, \n    tables: 30, \n    staff: 15, \n    parking: 20\n    ... \n}\n</code></pre>\n\n<p>So following tutorials, I have been able to do the following:</p>\n\n<ol>\n<li>Created a linear regression model to predict rating with the inputs being all the numerical data columns.</li>\n<li>Created a regression model to predict rating based on review text using sklearn.TfidfVectorizer.</li>\n</ol>\n\n<p>But now I'd like to combine models or combine the data from both into one to create a linear regression model. So how can I utilize the vectorized text data in my linear regression model?</p>\n",
                "tags": "<scikit-learn><nlp><linear-regression><tfidf>",
                "answers": [
                    [
                        "57765",
                        "2",
                        "57764",
                        "",
                        "",
                        "<p>It sounds like you could use <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html\" rel=\"nofollow noreferrer\">FeatureUnion</a> for this. Here's an <a href=\"https://scikit-learn.org/stable/auto_examples/compose/plot_feature_union.html\" rel=\"nofollow noreferrer\">example</a>:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import SelectKBest\n\niris = load_iris()\n\nX, y = iris.data, iris.target\n\n# This dataset is way too high-dimensional. Better do PCA:\npca = PCA(n_components=2)\n\n# Maybe some original features where good, too?\nselection = SelectKBest(k=1)\n\n# Build estimator from PCA and Univariate selection:\n\ncombined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n\n# Use combined features to transform dataset:\nX_features = combined_features.fit(X, y).transform(X)\nprint(\"Combined space has\", X_features.shape[1], \"features\")\n\nsvm = SVC(kernel=\"linear\")\n\n# Do grid search over k, n_components and C:\n\npipeline = Pipeline([(\"features\", combined_features), (\"svm\", svm)])\n\nparam_grid = dict(features__pca__n_components=[1, 2, 3],\n                  features__univ_select__k=[1, 2],\n                  svm__C=[0.1, 1, 10])\n\ngrid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, verbose=10)\ngrid_search.fit(X, y)\nprint(grid_search.best_estimator_)\n</code></pre>\n\n<p>Hopefully it is clear from that example how you could use this to merge your TfidfVectorizer results with your original features.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11573",
            "_score": 16.396244,
            "_source": {
                "title": "What the good general regression technqiue for a problem with 50 independent varaibles",
                "content": "What the good general regression technqiue for a problem with 50 independent varaibles <p>I am a newbie to data science and statistics. I came across this problem, which has 50 independent variables and one dependent variable and trying to identify the good regression technique to start with. The following is the flow chart that I executed:</p>\n\n<p>Data Exploration -> Correlational matrix -> dimension reduction -> PCA (Dimension reduction) -> Basic Linear Regression technique. </p>\n\n<p>Can someone guide me, if there is any other better technique or procedure. </p>\n <regression><statistics><data-science-model><p>In no way is this going to be an exhaustive answer, but it will definitely give you a starting point in <code>Python</code> - </p>\n\n<p><strong>Data Exploration</strong></p>\n\n<p>Start with <a href=\"https://github.com/pandas-profiling/pandas-profiling\" rel=\"nofollow noreferrer\"><code>Pandas Profiling</code></a>. It will give you HTML reports of your variables. If the quality of the data is good, it will provide some insights into the fill rate, depending upon the variable type some statistics for each variable</p>\n\n<p><strong>Correlational matrix</strong></p>\n\n<p>The pandas profiling report includes the coorelation matrix. But if you are looking to compute by hand, use <a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html\" rel=\"nofollow noreferrer\"><code>pd.corr()</code></a>. You can vary parameters to get different correlation metrics like <code>\u2018pearson\u2019, \u2018kendall\u2019, \u2018spearman\u2019</code></p>\n\n<p><strong>Dimension Reduction -> PCA (Dimension reduction)</strong></p>\n\n<p>There are many ways to do this. Keep in mind if you are looking for accuracies only and don't care about how <code>X</code> is influencing <code>y</code>, (1) is an optional step (applies to (2) as well). </p>\n\n<ol>\n<li>Analyse the correlation matrix and use <code>VIF</code> to dump variables with high correlation</li>\n<li>Factor Analysis / <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\" rel=\"nofollow noreferrer\">PCA</a> for dimensionality reduction</li>\n<li>Use <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\" rel=\"nofollow noreferrer\">LASSO</a> to fit a model, check the coefficients and the ones that are <code>0</code> or going to <code>0</code> can be thought of as weak indicators and can be eliminated.</li>\n<li>Keep all 50, and use <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\" rel=\"nofollow noreferrer\">Ridge Regression</a> and vary the alpha parameter to fine-tune accuracy (or whatever metric you are trying to optimize)</li>\n<li>If the model still doesn't seem to be stable, try to cook non-linear features with sklearn's <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\" rel=\"nofollow noreferrer\">Polynomial Features</a>, regularize and repeat.</li>\n<li>Probably the most important in the real world, ask the domain expert on what he/she thinks might be the important variables</li>\n</ol>\n\n<p><strong>Basic Linear Regression technique</strong></p>\n\n<ol>\n<li>Playing with hyperparamters to get good cross-validation/test score is the key here for a basic <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" rel=\"nofollow noreferrer\">Linear Regression</a> model. </li>\n<li>Try as many techniques as you can from <a href=\"http://scikit-learn.org/stable/modules/linear_model.html\" rel=\"nofollow noreferrer\">here</a> and <a href=\"http://scikit-learn.org/stable/supervised_learning.html\" rel=\"nofollow noreferrer\">here</a></li>\n</ol>\n",
                "codes": [
                    []
                ],
                "question_id:": "40843",
                "question_votes:": "1",
                "question_text:": "<p>I am a newbie to data science and statistics. I came across this problem, which has 50 independent variables and one dependent variable and trying to identify the good regression technique to start with. The following is the flow chart that I executed:</p>\n\n<p>Data Exploration -> Correlational matrix -> dimension reduction -> PCA (Dimension reduction) -> Basic Linear Regression technique. </p>\n\n<p>Can someone guide me, if there is any other better technique or procedure. </p>\n",
                "tags": "<regression><statistics><data-science-model>",
                "answers": [
                    [
                        "40846",
                        "2",
                        "40843",
                        "",
                        "",
                        "<p>In no way is this going to be an exhaustive answer, but it will definitely give you a starting point in <code>Python</code> - </p>\n\n<p><strong>Data Exploration</strong></p>\n\n<p>Start with <a href=\"https://github.com/pandas-profiling/pandas-profiling\" rel=\"nofollow noreferrer\"><code>Pandas Profiling</code></a>. It will give you HTML reports of your variables. If the quality of the data is good, it will provide some insights into the fill rate, depending upon the variable type some statistics for each variable</p>\n\n<p><strong>Correlational matrix</strong></p>\n\n<p>The pandas profiling report includes the coorelation matrix. But if you are looking to compute by hand, use <a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html\" rel=\"nofollow noreferrer\"><code>pd.corr()</code></a>. You can vary parameters to get different correlation metrics like <code>\u2018pearson\u2019, \u2018kendall\u2019, \u2018spearman\u2019</code></p>\n\n<p><strong>Dimension Reduction -> PCA (Dimension reduction)</strong></p>\n\n<p>There are many ways to do this. Keep in mind if you are looking for accuracies only and don't care about how <code>X</code> is influencing <code>y</code>, (1) is an optional step (applies to (2) as well). </p>\n\n<ol>\n<li>Analyse the correlation matrix and use <code>VIF</code> to dump variables with high correlation</li>\n<li>Factor Analysis / <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\" rel=\"nofollow noreferrer\">PCA</a> for dimensionality reduction</li>\n<li>Use <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\" rel=\"nofollow noreferrer\">LASSO</a> to fit a model, check the coefficients and the ones that are <code>0</code> or going to <code>0</code> can be thought of as weak indicators and can be eliminated.</li>\n<li>Keep all 50, and use <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\" rel=\"nofollow noreferrer\">Ridge Regression</a> and vary the alpha parameter to fine-tune accuracy (or whatever metric you are trying to optimize)</li>\n<li>If the model still doesn't seem to be stable, try to cook non-linear features with sklearn's <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\" rel=\"nofollow noreferrer\">Polynomial Features</a>, regularize and repeat.</li>\n<li>Probably the most important in the real world, ask the domain expert on what he/she thinks might be the important variables</li>\n</ol>\n\n<p><strong>Basic Linear Regression technique</strong></p>\n\n<ol>\n<li>Playing with hyperparamters to get good cross-validation/test score is the key here for a basic <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" rel=\"nofollow noreferrer\">Linear Regression</a> model. </li>\n<li>Try as many techniques as you can from <a href=\"http://scikit-learn.org/stable/modules/linear_model.html\" rel=\"nofollow noreferrer\">here</a> and <a href=\"http://scikit-learn.org/stable/supervised_learning.html\" rel=\"nofollow noreferrer\">here</a></li>\n</ol>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9777",
            "_score": 16.296007,
            "_source": {
                "title": "Why should re-sampling change the value of model's coefficients?",
                "content": "Why should re-sampling change the value of model's coefficients? <p>I have the code below in python to create LinearRegression model. When I train the model with re-sampled data, I get different values for its coefficients. I can't understand why that happens. Can you help me in this please? </p>\n\n<p>[Update]</p>\n\n<ul>\n<li>I assume that resampling is the same as shuffling. And that means the order of the data is changed but not the data itself.</li>\n<li>In the use case presented, the number of rows are are the same as I inspected it and as I understand the order of the data is changed.</li>\n</ul>\n\n<p>Thanks!</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.utils import resample\n\nmodel = LinearRegression(fit_intercept=False)\n\nmodel.fit(X, y)\nprint('model.coef_',model.coef_)\n\nmodel.fit(*resample(X, y))\nprint('model.coef_',model.coef_)\n\nmodel.fit(*resample(X, y))\nprint('model.coef_',model.coef_)\n</code></pre>\n <machine-learning><scikit-learn><statistics><linear-regression><p>In each sampling, your data is going to be different from the previous sampling. For each sampling, you are going to find the best line which describes your sample with the least error value. Consequently, for each sample you are going to find a model which may be different due to the fact that it reduces the cost for each sample.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "35684",
                "question_votes:": "1",
                "question_text:": "<p>I have the code below in python to create LinearRegression model. When I train the model with re-sampled data, I get different values for its coefficients. I can't understand why that happens. Can you help me in this please? </p>\n\n<p>[Update]</p>\n\n<ul>\n<li>I assume that resampling is the same as shuffling. And that means the order of the data is changed but not the data itself.</li>\n<li>In the use case presented, the number of rows are are the same as I inspected it and as I understand the order of the data is changed.</li>\n</ul>\n\n<p>Thanks!</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.utils import resample\n\nmodel = LinearRegression(fit_intercept=False)\n\nmodel.fit(X, y)\nprint('model.coef_',model.coef_)\n\nmodel.fit(*resample(X, y))\nprint('model.coef_',model.coef_)\n\nmodel.fit(*resample(X, y))\nprint('model.coef_',model.coef_)\n</code></pre>\n",
                "tags": "<machine-learning><scikit-learn><statistics><linear-regression>",
                "answers": [
                    [
                        "35687",
                        "2",
                        "35684",
                        "",
                        "",
                        "<p>In each sampling, your data is going to be different from the previous sampling. For each sampling, you are going to find the best line which describes your sample with the least error value. Consequently, for each sample you are going to find a model which may be different due to the fact that it reduces the cost for each sample.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12332",
            "_score": 16.282635,
            "_source": {
                "title": "How can I get my trained model ready for production",
                "content": "How can I get my trained model ready for production <p>I successfully trained my model using the sklearn's multiple linear regression. This is the code I used:</p>\n\n<pre><code>import pandas as pd\n\ndataset = pd.read_csv('C:\\\\mylocation\\\\myfile.csv')\ndataset2 = pd.get_dummies(dataset)\ny = dataset.iloc[:, 31:32].values\ndataset2.pop('Target')\nX = dataset2.iloc[:, :180].values\n\n#Split the dataset\nfrom sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)\n\n#Feature Scaling\n#from sklearn.preprocessing import StandardScaler\n\n#sc_X = StandardScaler()\n#X_train = sc_X.fit_transform(X_train)\n#X_test = sc_X.transform(X_test)\n\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n\n#Predicting the Test set results\ny_pred = regressor.predict(X_test)\n</code></pre>\n\n<p>According to validation results my y_pred is a reasonable predictor. Now, I would like to take into production this model and I am wondering what are reasonable steps to apply this model to the whole dataset I have stored and future datasets if needed.</p>\n <python><scikit-learn><p>You should first cross validate your pipeline, making sure that you get an homogeneous <code>y_pred</code> result.</p>\n\n<p>Then you can retrain a model with the same parameters on your full dataset. Pickle the model as well as any preprocessor tools, and reuse them to predict on new data.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "43338",
                "question_votes:": "",
                "question_text:": "<p>I successfully trained my model using the sklearn's multiple linear regression. This is the code I used:</p>\n\n<pre><code>import pandas as pd\n\ndataset = pd.read_csv('C:\\\\mylocation\\\\myfile.csv')\ndataset2 = pd.get_dummies(dataset)\ny = dataset.iloc[:, 31:32].values\ndataset2.pop('Target')\nX = dataset2.iloc[:, :180].values\n\n#Split the dataset\nfrom sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)\n\n#Feature Scaling\n#from sklearn.preprocessing import StandardScaler\n\n#sc_X = StandardScaler()\n#X_train = sc_X.fit_transform(X_train)\n#X_test = sc_X.transform(X_test)\n\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n\n#Predicting the Test set results\ny_pred = regressor.predict(X_test)\n</code></pre>\n\n<p>According to validation results my y_pred is a reasonable predictor. Now, I would like to take into production this model and I am wondering what are reasonable steps to apply this model to the whole dataset I have stored and future datasets if needed.</p>\n",
                "tags": "<python><scikit-learn>",
                "answers": [
                    [
                        "43339",
                        "2",
                        "43338",
                        "",
                        "",
                        "<p>You should first cross validate your pipeline, making sure that you get an homogeneous <code>y_pred</code> result.</p>\n\n<p>Then you can retrain a model with the same parameters on your full dataset. Pickle the model as well as any preprocessor tools, and reuse them to predict on new data.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10381",
            "_score": 16.228441,
            "_source": {
                "title": "Newbie in ML - how to",
                "content": "Newbie in ML - how to <p>We have a data set of n variables (profile attributes) and want to feed through a model, and classify into M buckets (functionally signifying some action to be performed) .  Which MLmodel/ algorithm is best suited for this. Can someone point me some code.</p>\n <machine-learning><machine-learning-model><p>I'm writing an example code in python:</p>\n\n<pre><code>import sklearn\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nX, y = whatever your data (X are the input variables, y are the output)\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n\nlr = LinearRegression().fit(X_train, y_train)\n\nprint(\"Training set accuracy: {:.2f}\".format(lr.score(X_train, y_train))\nprint(\"Test set accuracy: {:.2f}\".format(lr.score(X_test, y_test))\n</code></pre>\n\n<ol>\n<li>Imported necessary packages.</li>\n<li>Defined your input (X) and output data (y).</li>\n<li>Shuffled the data into the training set (75%) and the test set (25%).</li>\n<li>Defined the linear regression model and fitted the training data.</li>\n<li>Printed training and test set accuracies.</li>\n</ol>\n\n<p>Hope that helps!</p>\n<p>This is quite a broad question so it is difficult to answer correctly. The correct model really depends on a multitude of things. Given the fact that you seem to have n-features per data point and M possible outcomes, perhaps you should try a multivariate regression model first?</p>\n",
                "codes": [
                    [
                        "import sklearn\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nX, y = whatever your data (X are the input variables, y are the output)\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n\nlr = LinearRegression().fit(X_train, y_train)\n\nprint(\"Training set accuracy: {:.2f}\".format(lr.score(X_train, y_train))\nprint(\"Test set accuracy: {:.2f}\".format(lr.score(X_test, y_test))\n"
                    ],
                    []
                ],
                "question_id:": "37322",
                "question_votes:": "1",
                "question_text:": "<p>We have a data set of n variables (profile attributes) and want to feed through a model, and classify into M buckets (functionally signifying some action to be performed) .  Which MLmodel/ algorithm is best suited for this. Can someone point me some code.</p>\n",
                "tags": "<machine-learning><machine-learning-model>",
                "answers": [
                    [
                        "37336",
                        "2",
                        "37322",
                        "",
                        "",
                        "<p>I'm writing an example code in python:</p>\n\n<pre><code>import sklearn\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nX, y = whatever your data (X are the input variables, y are the output)\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n\nlr = LinearRegression().fit(X_train, y_train)\n\nprint(\"Training set accuracy: {:.2f}\".format(lr.score(X_train, y_train))\nprint(\"Test set accuracy: {:.2f}\".format(lr.score(X_test, y_test))\n</code></pre>\n\n<ol>\n<li>Imported necessary packages.</li>\n<li>Defined your input (X) and output data (y).</li>\n<li>Shuffled the data into the training set (75%) and the test set (25%).</li>\n<li>Defined the linear regression model and fitted the training data.</li>\n<li>Printed training and test set accuracies.</li>\n</ol>\n\n<p>Hope that helps!</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "37323",
                        "2",
                        "37322",
                        "",
                        "",
                        "<p>This is quite a broad question so it is difficult to answer correctly. The correct model really depends on a multitude of things. Given the fact that you seem to have n-features per data point and M possible outcomes, perhaps you should try a multivariate regression model first?</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11795",
            "_score": 16.17214,
            "_source": {
                "title": "Difference between sklearn\u2019s \u201clog_loss\u201d and \u201cLogisticRegression\u201d?",
                "content": "Difference between sklearn\u2019s \u201clog_loss\u201d and \u201cLogisticRegression\u201d? <p>I am a newbie currently learning data science from scratch and I have a rather stupid question to ask. I\u2019m currently learning about binary classification, and I understand that the logistic function is a useful tool for this. I looked up the documentation and noticed that there are two logistic related functions I can import, i.e. <code>sklearn.metric.log_loss</code> and <code>sklearn.linear_model.LogisticRegression</code>. When and where should I use them, and what\u2019s the difference?</p>\n\n<p>On a broader note, what\u2019s the difference between a metric and a model, and why is the log loss function a metric? Apologies if this question sounds completely nonsensical, but this is a genuine source of confusion for me!</p>\n <machine-learning><python><classification><scikit-learn><logistic-regression><p>The <a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html\" rel=\"nofollow noreferrer\">metrics</a> module by Scikit-learn implements functions assessing prediction error for specific purposes (<a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics\" rel=\"nofollow noreferrer\">Regression</a>, <a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics\" rel=\"nofollow noreferrer\">classification</a>, etc.). Model is the algorithm that actually does the <em>classification/regression/clustering</em> (as per need) for you.</p>\n\n<p><a href=\"http://wiki.fast.ai/index.php/Log_Loss\" rel=\"nofollow noreferrer\">Log-loss</a> measures the accuracy of, say a classifier. It is used when the model outputs a probability for each class, rather than just the most likely class.</p>\n\n<p><strong>EDIT:</strong> Thanks to @mapto for suggesting documentation reference:</p>\n\n<ul>\n<li><p><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html\" rel=\"nofollow noreferrer\">sklearn.metrics.log_loss</a>,\nand</p></li>\n<li><p><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">sklearn.linear_model.LogisticRegression</a></p></li>\n</ul>\n",
                "codes": [
                    []
                ],
                "question_id:": "41531",
                "question_votes:": "",
                "question_text:": "<p>I am a newbie currently learning data science from scratch and I have a rather stupid question to ask. I\u2019m currently learning about binary classification, and I understand that the logistic function is a useful tool for this. I looked up the documentation and noticed that there are two logistic related functions I can import, i.e. <code>sklearn.metric.log_loss</code> and <code>sklearn.linear_model.LogisticRegression</code>. When and where should I use them, and what\u2019s the difference?</p>\n\n<p>On a broader note, what\u2019s the difference between a metric and a model, and why is the log loss function a metric? Apologies if this question sounds completely nonsensical, but this is a genuine source of confusion for me!</p>\n",
                "tags": "<machine-learning><python><classification><scikit-learn><logistic-regression>",
                "answers": [
                    [
                        "41534",
                        "2",
                        "41531",
                        "",
                        "",
                        "<p>The <a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html\" rel=\"nofollow noreferrer\">metrics</a> module by Scikit-learn implements functions assessing prediction error for specific purposes (<a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics\" rel=\"nofollow noreferrer\">Regression</a>, <a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics\" rel=\"nofollow noreferrer\">classification</a>, etc.). Model is the algorithm that actually does the <em>classification/regression/clustering</em> (as per need) for you.</p>\n\n<p><a href=\"http://wiki.fast.ai/index.php/Log_Loss\" rel=\"nofollow noreferrer\">Log-loss</a> measures the accuracy of, say a classifier. It is used when the model outputs a probability for each class, rather than just the most likely class.</p>\n\n<p><strong>EDIT:</strong> Thanks to @mapto for suggesting documentation reference:</p>\n\n<ul>\n<li><p><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html\" rel=\"nofollow noreferrer\">sklearn.metrics.log_loss</a>,\nand</p></li>\n<li><p><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">sklearn.linear_model.LogisticRegression</a></p></li>\n</ul>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12183",
            "_score": 16.136364,
            "_source": {
                "title": "Methods of building machine learning models",
                "content": "Methods of building machine learning models <p>I have seen pages where they mention 5 methods of building models.</p>\n\n<pre><code>1) All-in\n2) Backward Elimination\n3) Forward Selection\n4) Bidirectional Elimination\n5) Score Comparision\n</code></pre>\n\n<p>I usually implement a linear regression or any algorithm using <code>sklearn</code></p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X, y)\ny_pred = lr.predict(X_test)\n</code></pre>\n\n<p>How can one implement those 5 methods of building models? </p>\n\n<p>Can anyone explain the importance of this and What is most commonly used one out of these?</p>\n <machine-learning><python><p>Strictly speaking, those are not methods of \"building\" models, they are <a href=\"https://en.wikipedia.org/wiki/Feature_selection\" rel=\"nofollow noreferrer\">feature selection</a> strategies.</p>\n\n<p>Most of them are implemented in <a href=\"https://scikit-learn.org/stable/modules/feature_selection.html\" rel=\"nofollow noreferrer\">Scikit-learn</a>.</p>\n<p>As Qusai said in his answer, these are not methods to build models, these are selection mechanisms. There are others as well, like feature engineering (for instance dimensionality reduction can be seen as feature engineering).</p>\n\n<p>Starting from your example, and assuming that <code>X</code> is your full data:</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X, y)\ny_pred = lr.predict(X_test)\n</code></pre>\n\n<p>This is the all-in. From this, backward elimination is removing one of the columns and keeping the <code>n-1</code> with the best result.</p>\n\n<p>Then forward is starting from 0 and adding 1 feature, so just one column at a time, comparing all potential ones.</p>\n\n<p>The bidirectional is to try adding or removing at each step (because non linear models may sometimes be better without one feature, but better with two of them).</p>\n\n<p>Each time, compare the score, and more precisely, compare the cross-validated score. In a way, only step 5 is what you ALWAYS do.</p>\n",
                "codes": [
                    [],
                    [
                        "from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X, y)\ny_pred = lr.predict(X_test)\n"
                    ]
                ],
                "question_id:": "42857",
                "question_votes:": "2",
                "question_text:": "<p>I have seen pages where they mention 5 methods of building models.</p>\n\n<pre><code>1) All-in\n2) Backward Elimination\n3) Forward Selection\n4) Bidirectional Elimination\n5) Score Comparision\n</code></pre>\n\n<p>I usually implement a linear regression or any algorithm using <code>sklearn</code></p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X, y)\ny_pred = lr.predict(X_test)\n</code></pre>\n\n<p>How can one implement those 5 methods of building models? </p>\n\n<p>Can anyone explain the importance of this and What is most commonly used one out of these?</p>\n",
                "tags": "<machine-learning><python>",
                "answers": [
                    [
                        "42904",
                        "2",
                        "42857",
                        "",
                        "",
                        "<p>Strictly speaking, those are not methods of \"building\" models, they are <a href=\"https://en.wikipedia.org/wiki/Feature_selection\" rel=\"nofollow noreferrer\">feature selection</a> strategies.</p>\n\n<p>Most of them are implemented in <a href=\"https://scikit-learn.org/stable/modules/feature_selection.html\" rel=\"nofollow noreferrer\">Scikit-learn</a>.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "42906",
                        "2",
                        "42857",
                        "",
                        "",
                        "<p>As Qusai said in his answer, these are not methods to build models, these are selection mechanisms. There are others as well, like feature engineering (for instance dimensionality reduction can be seen as feature engineering).</p>\n\n<p>Starting from your example, and assuming that <code>X</code> is your full data:</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X, y)\ny_pred = lr.predict(X_test)\n</code></pre>\n\n<p>This is the all-in. From this, backward elimination is removing one of the columns and keeping the <code>n-1</code> with the best result.</p>\n\n<p>Then forward is starting from 0 and adding 1 feature, so just one column at a time, comparing all potential ones.</p>\n\n<p>The bidirectional is to try adding or removing at each step (because non linear models may sometimes be better without one feature, but better with two of them).</p>\n\n<p>Each time, compare the score, and more precisely, compare the cross-validated score. In a way, only step 5 is what you ALWAYS do.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8980",
            "_score": 16.0098,
            "_source": {
                "title": "Simple Linear Regression-----How to make my model more efficient??",
                "content": "Simple Linear Regression-----How to make my model more efficient?? <p>I am working on a simple linear regression model,</p>\n\n<blockquote>\n  <p>This is my Python code : </p>\n</blockquote>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndataset=pd.read_csv('sample.csv')\nX=dataset.iloc[:,:-1].values\nY=dataset.iloc[:,1].values\n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=1/3)\n\nfrom sklearn.linear_model import LinearRegression\nregressor=LinearRegression()\nregressor.fit(X_train,Y_train)\n\nplt.scatter(X_train,Y_train,color='red')\nplt.plot(X_train,regressor.predict(X_train),color='blue')\nplt.title('X vs Y(Training Set)')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\n\nplt.scatter(X_test,Y_test,color='red')\nplt.plot(X_train,regressor.predict(X_train),color='blue')\nplt.title('X vs Y(Test Set)')\nplt.xlabel('X')[enter image description here][1]\nplt.ylabel('Y')\nplt.show()`\n</code></pre>\n\n<blockquote>\n  <p>This is my plot of Training Set <a href=\"https://i.stack.imgur.com/dybyT.png\" rel=\"nofollow noreferrer\">Training Set </a>\n  This is my plot of Test Set <a href=\"https://i.stack.imgur.com/LnPT9.png\" rel=\"nofollow noreferrer\">Test Set</a></p>\n</blockquote>\n\n<p>How can I increase the efficiency of my ML model???\nThis is my first ML model, so all suggestions are welcome.\nThanks in Advance</p>\n <python><linear-regression><p>You cannot really do much: the fit of the regressor is optimum, therefore it is the best that the algorithm can do given these points. What you can do, is change the weights of individual points of the dataset using the <strong>sample weight</strong> parameter of </p>\n\n<pre><code>LinearRegression.fit(X, y, sample_weight)\n</code></pre>\n\n<p>method, to \"attract\" the line towards them and see how this affects the accuracy.</p>\n\n<p>I would <strong>not expect</strong> notable difference because your data do not follow a linear pattern.</p>\n<p>Your data does not follow a linear trend. For this reason, your linear model has clear limitations. In order to overcome them, you can build a nonlinear model. With the few data that you have, I advise you to do <a href=\"https://en.wikipedia.org/wiki/Local_regression\" rel=\"nofollow noreferrer\">LOESS</a>. As your training data seems to be able to follow a cubic trend, you can also try with polynomial regression of degree 3.</p>\n\n<p>Bear in mind that the distribution of your train and test data is very different, so you are very likely to overfit. For this reason, it might not be the best data to get started with ML.</p>\n",
                "codes": [
                    [
                        "LinearRegression.fit(X, y, sample_weight)\n"
                    ],
                    []
                ],
                "question_id:": "32238",
                "question_votes:": "1",
                "question_text:": "<p>I am working on a simple linear regression model,</p>\n\n<blockquote>\n  <p>This is my Python code : </p>\n</blockquote>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndataset=pd.read_csv('sample.csv')\nX=dataset.iloc[:,:-1].values\nY=dataset.iloc[:,1].values\n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=1/3)\n\nfrom sklearn.linear_model import LinearRegression\nregressor=LinearRegression()\nregressor.fit(X_train,Y_train)\n\nplt.scatter(X_train,Y_train,color='red')\nplt.plot(X_train,regressor.predict(X_train),color='blue')\nplt.title('X vs Y(Training Set)')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\n\nplt.scatter(X_test,Y_test,color='red')\nplt.plot(X_train,regressor.predict(X_train),color='blue')\nplt.title('X vs Y(Test Set)')\nplt.xlabel('X')[enter image description here][1]\nplt.ylabel('Y')\nplt.show()`\n</code></pre>\n\n<blockquote>\n  <p>This is my plot of Training Set <a href=\"https://i.stack.imgur.com/dybyT.png\" rel=\"nofollow noreferrer\">Training Set </a>\n  This is my plot of Test Set <a href=\"https://i.stack.imgur.com/LnPT9.png\" rel=\"nofollow noreferrer\">Test Set</a></p>\n</blockquote>\n\n<p>How can I increase the efficiency of my ML model???\nThis is my first ML model, so all suggestions are welcome.\nThanks in Advance</p>\n",
                "tags": "<python><linear-regression>",
                "answers": [
                    [
                        "32270",
                        "2",
                        "32238",
                        "",
                        "",
                        "<p>You cannot really do much: the fit of the regressor is optimum, therefore it is the best that the algorithm can do given these points. What you can do, is change the weights of individual points of the dataset using the <strong>sample weight</strong> parameter of </p>\n\n<pre><code>LinearRegression.fit(X, y, sample_weight)\n</code></pre>\n\n<p>method, to \"attract\" the line towards them and see how this affects the accuracy.</p>\n\n<p>I would <strong>not expect</strong> notable difference because your data do not follow a linear pattern.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "32247",
                        "2",
                        "32238",
                        "",
                        "",
                        "<p>Your data does not follow a linear trend. For this reason, your linear model has clear limitations. In order to overcome them, you can build a nonlinear model. With the few data that you have, I advise you to do <a href=\"https://en.wikipedia.org/wiki/Local_regression\" rel=\"nofollow noreferrer\">LOESS</a>. As your training data seems to be able to follow a cubic trend, you can also try with polynomial regression of degree 3.</p>\n\n<p>Bear in mind that the distribution of your train and test data is very different, so you are very likely to overfit. For this reason, it might not be the best data to get started with ML.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9608",
            "_score": 16.006376,
            "_source": {
                "title": "Mean error (not squared) in scikit-learn cross_val_score",
                "content": "Mean error (not squared) in scikit-learn cross_val_score <p>I need to know if the values generated by each fold of <code>cross_val_score</code> have a distribution which is centered on zero.  Something as simple as the median or mean of <code>y_true - y_predicted</code> would suffice.  All I see in the available options are absolute and squared.  I've looked into make scorer but can't see how to code the simple mean error and then call it as the scoring argument in <code>cross_val_score</code>.</p>\n <scikit-learn><cross-validation><pre><code>from sklearn.datasets import load_diabetes\nfrom sklearn.metrics import make_scorer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\n\ndef mean_error(y, y_pred):\n    # assuming y and y_pred are numpy arrays\n    return np.mean(y_pred - y)\n\nX, y = load_diabetes(return_X_y=True)\nmean_error_scorer = make_scorer(mean_error, greater_is_better=False)\n\nregr = LinearRegression()\ncross_val_score(regr, X, y, scoring=mean_error_scorer)\n</code></pre>\n",
                "codes": [
                    [
                        "from sklearn.datasets import load_diabetes\nfrom sklearn.metrics import make_scorer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\n\ndef mean_error(y, y_pred):\n    # assuming y and y_pred are numpy arrays\n    return np.mean(y_pred - y)\n\nX, y = load_diabetes(return_X_y=True)\nmean_error_scorer = make_scorer(mean_error, greater_is_better=False)\n\nregr = LinearRegression()\ncross_val_score(regr, X, y, scoring=mean_error_scorer)\n"
                    ]
                ],
                "question_id:": "34141",
                "question_votes:": "1",
                "question_text:": "<p>I need to know if the values generated by each fold of <code>cross_val_score</code> have a distribution which is centered on zero.  Something as simple as the median or mean of <code>y_true - y_predicted</code> would suffice.  All I see in the available options are absolute and squared.  I've looked into make scorer but can't see how to code the simple mean error and then call it as the scoring argument in <code>cross_val_score</code>.</p>\n",
                "tags": "<scikit-learn><cross-validation>",
                "answers": [
                    [
                        "34147",
                        "2",
                        "34141",
                        "",
                        "",
                        "<pre><code>from sklearn.datasets import load_diabetes\nfrom sklearn.metrics import make_scorer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\n\ndef mean_error(y, y_pred):\n    # assuming y and y_pred are numpy arrays\n    return np.mean(y_pred - y)\n\nX, y = load_diabetes(return_X_y=True)\nmean_error_scorer = make_scorer(mean_error, greater_is_better=False)\n\nregr = LinearRegression()\ncross_val_score(regr, X, y, scoring=mean_error_scorer)\n</code></pre>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10322",
            "_score": 15.994286,
            "_source": {
                "title": "Should highly correlated features be omitted before applying Lasso?",
                "content": "Should highly correlated features be omitted before applying Lasso? <p>I would greatly appreciate if you could let me know whether I should omit highly correlated features before using Lasso logistic regression (<code>L1</code>) to do feature selection.</p>\n\n<p>In fact, I want to use logistic regression with <code>L1</code> to do prediction as well as feature selection. However, some of my features are highly correlated e.g., -1 or 0.9. Should I omit them before applying Lasso or let the Lasso decide it?</p>\n\n<p>Really, I read in Mr. Raschka\u2019s book <a href=\"https://books.google.com/books/about/Python_Machine_Learning.html?id=GOVOCwAAQBAJ&amp;printsec=frontcover&amp;source=kp_read_button#v=onepage&amp;q&amp;f=false\" rel=\"nofollow noreferrer\">(Python Machine Learning</a>) that </p>\n\n<blockquote>\n  <p>regularization is a very useful method to handle collinearity (high\n  correlation among features).</p>\n</blockquote>\n\n<p>However, this <a href=\"https://www.kaggle.com/leeclemmer/exploratory-data-analysis-of-housing-in-ames-iowa\" rel=\"nofollow noreferrer\">kernel</a>  (by referring to <a href=\"https://en.wikipedia.org/wiki/Multicollinearity\" rel=\"nofollow noreferrer\">Wikipedia</a>) states that keeping correlated features in the model would adversely affect the feature selection but it doesn't impair the predictions. </p>\n <machine-learning><python><logistic-regression><regularization><collinearity><p>Use scikit-learn package.\nIn your case you need find <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">sklearn.linear_model.LogisticRegression</a> </p>\n\n<p>and <a href=\"http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\" rel=\"nofollow noreferrer\">User guide</a></p>\n\n<p>It's clear enough for understanding. You needn't special actions to win collinearity. But instead of linear method you can use non parametric algorithm like random forest <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" rel=\"nofollow noreferrer\">sklearn.ensemble.RandomForestClassifier</a>.</p>\n\n<p>\u0421ompare the results of the logistic regression &amp; random forest on the test data</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "37181",
                "question_votes:": "",
                "question_text:": "<p>I would greatly appreciate if you could let me know whether I should omit highly correlated features before using Lasso logistic regression (<code>L1</code>) to do feature selection.</p>\n\n<p>In fact, I want to use logistic regression with <code>L1</code> to do prediction as well as feature selection. However, some of my features are highly correlated e.g., -1 or 0.9. Should I omit them before applying Lasso or let the Lasso decide it?</p>\n\n<p>Really, I read in Mr. Raschka\u2019s book <a href=\"https://books.google.com/books/about/Python_Machine_Learning.html?id=GOVOCwAAQBAJ&amp;printsec=frontcover&amp;source=kp_read_button#v=onepage&amp;q&amp;f=false\" rel=\"nofollow noreferrer\">(Python Machine Learning</a>) that </p>\n\n<blockquote>\n  <p>regularization is a very useful method to handle collinearity (high\n  correlation among features).</p>\n</blockquote>\n\n<p>However, this <a href=\"https://www.kaggle.com/leeclemmer/exploratory-data-analysis-of-housing-in-ames-iowa\" rel=\"nofollow noreferrer\">kernel</a>  (by referring to <a href=\"https://en.wikipedia.org/wiki/Multicollinearity\" rel=\"nofollow noreferrer\">Wikipedia</a>) states that keeping correlated features in the model would adversely affect the feature selection but it doesn't impair the predictions. </p>\n",
                "tags": "<machine-learning><python><logistic-regression><regularization><collinearity>",
                "answers": [
                    [
                        "37183",
                        "2",
                        "37181",
                        "",
                        "",
                        "<p>Use scikit-learn package.\nIn your case you need find <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">sklearn.linear_model.LogisticRegression</a> </p>\n\n<p>and <a href=\"http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\" rel=\"nofollow noreferrer\">User guide</a></p>\n\n<p>It's clear enough for understanding. You needn't special actions to win collinearity. But instead of linear method you can use non parametric algorithm like random forest <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" rel=\"nofollow noreferrer\">sklearn.ensemble.RandomForestClassifier</a>.</p>\n\n<p>\u0421ompare the results of the logistic regression &amp; random forest on the test data</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14350",
            "_score": 15.987672,
            "_source": {
                "title": "Machine learning with sklearn vs. scipy stats",
                "content": "Machine learning with sklearn vs. scipy stats <p>I've created 50 random x and y points (with slope of y = 2x-1).</p>\n\n<p>First, I used Linear Regression from sklearn to fit the model onto my dataset where I got a slope of <code>2.0066...</code> and intercept of <code>-0.535...</code></p>\n\n<p>My Question: is fitting the model to our dataset considered training? For each given x value, since it has a y-value (supervised), does our machine go through each x,y match and create line of best fit based upon that? Thus, is our model trained?</p>\n\n<p>Second, I used <code>stats.linregress(x,y)</code> from scipy to get slope and intercept (which seem really close if not the same to the slope and intercept I've got from using sklearn Linear Regression).</p>\n\n<p>My Question: If both methods give the same result, why not just use scipy to get formula for the best fit line to make predictions? What is the benefit of using machine learning?</p>\n <machine-learning><python><scikit-learn><numpy><scipy><ol>\n<li>Yes fitting the data and finding the best fitting line is called training the model. </li>\n<li>If you look at the source code of scikit-learn linear regression you can find the its using scipy linalg.lstsq module for finding the coefficients and intercept (most cases). <a href=\"https://github.com/scikit-learn/scikit-learn/blob/7b136e9/sklearn/linear_model/base.py#L362\" rel=\"nofollow noreferrer\">See the source code for more details </a>. Machine learning is fancy word for Application of  mathematics (on data mostly) using computers (machines)</li>\n</ol>\n",
                "codes": [
                    []
                ],
                "question_id:": "48308",
                "question_votes:": "",
                "question_text:": "<p>I've created 50 random x and y points (with slope of y = 2x-1).</p>\n\n<p>First, I used Linear Regression from sklearn to fit the model onto my dataset where I got a slope of <code>2.0066...</code> and intercept of <code>-0.535...</code></p>\n\n<p>My Question: is fitting the model to our dataset considered training? For each given x value, since it has a y-value (supervised), does our machine go through each x,y match and create line of best fit based upon that? Thus, is our model trained?</p>\n\n<p>Second, I used <code>stats.linregress(x,y)</code> from scipy to get slope and intercept (which seem really close if not the same to the slope and intercept I've got from using sklearn Linear Regression).</p>\n\n<p>My Question: If both methods give the same result, why not just use scipy to get formula for the best fit line to make predictions? What is the benefit of using machine learning?</p>\n",
                "tags": "<machine-learning><python><scikit-learn><numpy><scipy>",
                "answers": [
                    [
                        "48310",
                        "2",
                        "48308",
                        "",
                        "",
                        "<ol>\n<li>Yes fitting the data and finding the best fitting line is called training the model. </li>\n<li>If you look at the source code of scikit-learn linear regression you can find the its using scipy linalg.lstsq module for finding the coefficients and intercept (most cases). <a href=\"https://github.com/scikit-learn/scikit-learn/blob/7b136e9/sklearn/linear_model/base.py#L362\" rel=\"nofollow noreferrer\">See the source code for more details </a>. Machine learning is fancy word for Application of  mathematics (on data mostly) using computers (machines)</li>\n</ol>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3458",
            "_score": 15.939966,
            "_source": {
                "title": "Why after adding categorical data the Linear Regression fails?",
                "content": "Why after adding categorical data the Linear Regression fails? <p>Based on a training set we applied a simple Linear Regression on some attributes that all were numeric.</p>\n\n<p>Now we have more attributes in terms of categories and of course we applied one-hot-encoding to transform the categories to binary attributes</p>\n\n<p>Take for example this simple python code:</p>\n\n<pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size=0.2)\n\nmodel = LinearRegression(normalize=True).fit(X_train, y_train)\n\nprintErrorMetrics(trueTargets=y_test, predictions=model.predict(X_test))\n</code></pre>\n\n<p>When the table X has only the original numeric attributes the scores from the printErrorMetrics function (RMSE, etc.) are all good enough</p>\n\n<p>We were expecting better results after adding the one-hot-encoded categories but the results are so worse that the method does not seem to work.</p>\n\n<p>Are we missing anything?</p>\n\n<p>Do we need to preprocess the data after adding the one-hot-encoded columns/attributes?</p>\n <python><linear-regression><categorical-data><p>One possible reason is that when you use one-hot-encoding for categorical data, you should set the intercept property in the function to be False:</p>\n\n<pre><code>model = LinearRegression(fit_intercept=False, normalize=True).fit(X_train, y_train)\n</code></pre>\n\n<p>This will avoid the dummy variable trap:\n<a href=\"http://www.algosome.com/articles/dummy-variable-trap-regression.html\">http://www.algosome.com/articles/dummy-variable-trap-regression.html</a></p>\n\n<p>You could also use dummy encoding to avoid this problem:\n<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\">http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html</a></p>\n",
                "codes": [
                    [
                        "model = LinearRegression(fit_intercept=False, normalize=True).fit(X_train, y_train)\n"
                    ]
                ],
                "question_id:": "14666",
                "question_votes:": "6",
                "question_text:": "<p>Based on a training set we applied a simple Linear Regression on some attributes that all were numeric.</p>\n\n<p>Now we have more attributes in terms of categories and of course we applied one-hot-encoding to transform the categories to binary attributes</p>\n\n<p>Take for example this simple python code:</p>\n\n<pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size=0.2)\n\nmodel = LinearRegression(normalize=True).fit(X_train, y_train)\n\nprintErrorMetrics(trueTargets=y_test, predictions=model.predict(X_test))\n</code></pre>\n\n<p>When the table X has only the original numeric attributes the scores from the printErrorMetrics function (RMSE, etc.) are all good enough</p>\n\n<p>We were expecting better results after adding the one-hot-encoded categories but the results are so worse that the method does not seem to work.</p>\n\n<p>Are we missing anything?</p>\n\n<p>Do we need to preprocess the data after adding the one-hot-encoded columns/attributes?</p>\n",
                "tags": "<python><linear-regression><categorical-data>",
                "answers": [
                    [
                        "14667",
                        "2",
                        "14666",
                        "",
                        "",
                        "<p>One possible reason is that when you use one-hot-encoding for categorical data, you should set the intercept property in the function to be False:</p>\n\n<pre><code>model = LinearRegression(fit_intercept=False, normalize=True).fit(X_train, y_train)\n</code></pre>\n\n<p>This will avoid the dummy variable trap:\n<a href=\"http://www.algosome.com/articles/dummy-variable-trap-regression.html\">http://www.algosome.com/articles/dummy-variable-trap-regression.html</a></p>\n\n<p>You could also use dummy encoding to avoid this problem:\n<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\">http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html</a></p>\n",
                        "",
                        "8"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15699",
            "_score": 15.926999,
            "_source": {
                "title": "Using logistic Regression with multi_class='multinomial' for binary classification",
                "content": "Using logistic Regression with multi_class='multinomial' for binary classification <p>I have built a binary classifier and I have tested the results with multi_class='multinomial' and multi_class='ovr'. The results are relatively better using multinomial option. I understand that multi_class should be multinomial for the multi-classes problem (more than two classes) (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</a>); however, I would like to understand theoretically if the multinomial option is used, how this affects the binary classifier?</p>\n <scikit-learn><logistic-regression>",
                "codes": [],
                "question_id:": "52450",
                "question_votes:": "",
                "question_text:": "<p>I have built a binary classifier and I have tested the results with multi_class='multinomial' and multi_class='ovr'. The results are relatively better using multinomial option. I understand that multi_class should be multinomial for the multi-classes problem (more than two classes) (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</a>); however, I would like to understand theoretically if the multinomial option is used, how this affects the binary classifier?</p>\n",
                "tags": "<scikit-learn><logistic-regression>",
                "answers": []
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14940",
            "_score": 15.905264,
            "_source": {
                "title": "Any efficient way to build non-linear regression model for polynomial features?",
                "content": "Any efficient way to build non-linear regression model for polynomial features? <p>I am trying to understand how crime frequency affect house price in certain area. To do so, I started with Chicago crime data and zillow real estate data. I want to understand the relation between house price and crime frequency and top 5 crimes in certain areas. Initially, I build up model for this specification, but it wasn't very meaningful to me. Can anyone enlighten me what should I do? any efficient approach to train regression model for potential relation between house price and crime frequency in certain areas? any heuristic idea to move forward?</p>\n\n<p><strong>example data snippet:</strong></p>\n\n<p>here is the merged data that includes annual house price and top crime type in certain areas:</p>\n\n<p><a href=\"https://i.stack.imgur.com/YrbrF.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/YrbrF.png\" alt=\"example data\"></a></p>\n\n<p>Here is reproducible <a href=\"https://filebin.net/ml0sjn455gr8pvh3\" rel=\"nofollow noreferrer\">example data snippet</a></p>\n\n<p><strong>my attempt</strong></p>\n\n<p>so here is my attempt to fit regression model with above reproducible example data:</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\nregDF = pd.read_csv('exampleDF')\n\nX_feats = regDF.drop(['Avg_Price_2012'], axis=1)\ny_label = regDF['Avg_Price_2012'].values\n\nsc_x = StandardScaler()\nsc_y = StandardScaler()\nX = sc_x.fit_transform(X_feats)\n#y= sc_y.fit_transform(y_label)\ny = sc_y.fit_transform(y_label .reshape(-1,1)).flatten()\nregModel = LinearRegression()\nregModel.fit(X, y)\nregModel.coef_\n</code></pre>\n\n<p>but to me, above model wasn't that efficient and needs to be done something more. I think I have to use non linear regression model for those polynomial features, and I am not sure to get this done.</p>\n\n<p>Can anyone point me out how to build correct model for house price prediction over type of crimes and frequencies in certain areas? any idea? Thanks</p>\n\n<p><strong>Goal</strong>:</p>\n\n<p>I want to build regression model to predict house price based on crime frequencies and types in certain areas. How can I get modeling the relationship between house price and crimes in certain areas? any thoughts?</p>\n <machine-learning><python><p>You are probably finding yourself in one of the most interesting problems in data science, the part which is more art than science.</p>\n\n<p>I will give you some ideas that can give you hints on how to solve this problem:</p>\n\n<ol>\n<li><p>Prices, Salaries and other variables who have information on \"accumulables\" many times have a distribution which is skewed to the left (many individuals have a little, a few have a lot), what is reccomended to do is to take logarithm of it. Your new variable should be <span class=\"math-container\">$Ln(Y)$</span>, with this, you will close the gap between areas with greater avg_price and areas with lower avg_price. When that happens you find a less-skewed-normal-like distribution of your <span class=\"math-container\">$Y$</span> variable.</p></li>\n<li><p>The idea of taking Logarithm also applies to the <span class=\"math-container\">$X$</span> variables you have (because crimes also accumulate in certain areas).</p></li>\n<li>The Standard Scalling is not necessary when you run a linear regression, because the relativeness of the variable is not influencial in the regression:</li>\n</ol>\n\n<p>The regression <span class=\"math-container\">$Y = \\alpha_0 + \\alpha_1X_1+...+\\alpha_nX_n$</span> (no\n    scalled) is mathematically equivalent to <span class=\"math-container\">$Y = \\beta_0 +\n\\beta_1Z_1+...+\\beta_nZ_n$</span> (scalled)</p>\n\n<ol start=\"4\">\n<li>If you want to use other models, you data seems suitable for it, maybe a regression tree or XGBoost might work well on your problem.</li>\n</ol>\n\n<p>I would bet that getting Logarithm in the avg_price, in some exogenous variables and not scalling would get better results for you.</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\nregDF = pd.read_csv('exampleDF')\n\nX_feats = regDF.drop(['Avg_Price_2012'], axis=1)\ny_label = regDF['Avg_Price_2012'].values\n\nX = log(X_feats)\ny = log(y_label.reshape(-1,1)).flatten()\nregModel = LinearRegression()\nregModel.fit(X, y)\nregModel.coef_\n</code></pre>\n",
                "codes": [
                    [
                        "from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\nregDF = pd.read_csv('exampleDF')\n\nX_feats = regDF.drop(['Avg_Price_2012'], axis=1)\ny_label = regDF['Avg_Price_2012'].values\n\nX = log(X_feats)\ny = log(y_label.reshape(-1,1)).flatten()\nregModel = LinearRegression()\nregModel.fit(X, y)\nregModel.coef_\n"
                    ]
                ],
                "question_id:": "50816",
                "question_votes:": "1",
                "question_text:": "<p>I am trying to understand how crime frequency affect house price in certain area. To do so, I started with Chicago crime data and zillow real estate data. I want to understand the relation between house price and crime frequency and top 5 crimes in certain areas. Initially, I build up model for this specification, but it wasn't very meaningful to me. Can anyone enlighten me what should I do? any efficient approach to train regression model for potential relation between house price and crime frequency in certain areas? any heuristic idea to move forward?</p>\n\n<p><strong>example data snippet:</strong></p>\n\n<p>here is the merged data that includes annual house price and top crime type in certain areas:</p>\n\n<p><a href=\"https://i.stack.imgur.com/YrbrF.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/YrbrF.png\" alt=\"example data\"></a></p>\n\n<p>Here is reproducible <a href=\"https://filebin.net/ml0sjn455gr8pvh3\" rel=\"nofollow noreferrer\">example data snippet</a></p>\n\n<p><strong>my attempt</strong></p>\n\n<p>so here is my attempt to fit regression model with above reproducible example data:</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\nregDF = pd.read_csv('exampleDF')\n\nX_feats = regDF.drop(['Avg_Price_2012'], axis=1)\ny_label = regDF['Avg_Price_2012'].values\n\nsc_x = StandardScaler()\nsc_y = StandardScaler()\nX = sc_x.fit_transform(X_feats)\n#y= sc_y.fit_transform(y_label)\ny = sc_y.fit_transform(y_label .reshape(-1,1)).flatten()\nregModel = LinearRegression()\nregModel.fit(X, y)\nregModel.coef_\n</code></pre>\n\n<p>but to me, above model wasn't that efficient and needs to be done something more. I think I have to use non linear regression model for those polynomial features, and I am not sure to get this done.</p>\n\n<p>Can anyone point me out how to build correct model for house price prediction over type of crimes and frequencies in certain areas? any idea? Thanks</p>\n\n<p><strong>Goal</strong>:</p>\n\n<p>I want to build regression model to predict house price based on crime frequencies and types in certain areas. How can I get modeling the relationship between house price and crimes in certain areas? any thoughts?</p>\n",
                "tags": "<machine-learning><python>",
                "answers": [
                    [
                        "50865",
                        "2",
                        "50816",
                        "",
                        "",
                        "<p>You are probably finding yourself in one of the most interesting problems in data science, the part which is more art than science.</p>\n\n<p>I will give you some ideas that can give you hints on how to solve this problem:</p>\n\n<ol>\n<li><p>Prices, Salaries and other variables who have information on \"accumulables\" many times have a distribution which is skewed to the left (many individuals have a little, a few have a lot), what is reccomended to do is to take logarithm of it. Your new variable should be <span class=\"math-container\">$Ln(Y)$</span>, with this, you will close the gap between areas with greater avg_price and areas with lower avg_price. When that happens you find a less-skewed-normal-like distribution of your <span class=\"math-container\">$Y$</span> variable.</p></li>\n<li><p>The idea of taking Logarithm also applies to the <span class=\"math-container\">$X$</span> variables you have (because crimes also accumulate in certain areas).</p></li>\n<li>The Standard Scalling is not necessary when you run a linear regression, because the relativeness of the variable is not influencial in the regression:</li>\n</ol>\n\n<p>The regression <span class=\"math-container\">$Y = \\alpha_0 + \\alpha_1X_1+...+\\alpha_nX_n$</span> (no\n    scalled) is mathematically equivalent to <span class=\"math-container\">$Y = \\beta_0 +\n\\beta_1Z_1+...+\\beta_nZ_n$</span> (scalled)</p>\n\n<ol start=\"4\">\n<li>If you want to use other models, you data seems suitable for it, maybe a regression tree or XGBoost might work well on your problem.</li>\n</ol>\n\n<p>I would bet that getting Logarithm in the avg_price, in some exogenous variables and not scalling would get better results for you.</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\nregDF = pd.read_csv('exampleDF')\n\nX_feats = regDF.drop(['Avg_Price_2012'], axis=1)\ny_label = regDF['Avg_Price_2012'].values\n\nX = log(X_feats)\ny = log(y_label.reshape(-1,1)).flatten()\nregModel = LinearRegression()\nregModel.fit(X, y)\nregModel.coef_\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4429",
            "_score": 15.89395,
            "_source": {
                "title": "scoring argument in scikit-learn LassoCV, LassoLarsCV, ElasticNetCV",
                "content": "scoring argument in scikit-learn LassoCV, LassoLarsCV, ElasticNetCV <p>I was looking at the arguments in the linear regularization methods with cross validation within scikit-learn. RidgeCV has an argument scoring which is None by default but one can use a custom scorer (e.g. RMSE). I noticed that no such option is given for the rest of the classes (LassoCV, LassoLarsCV, ElasticNetCV). Why is this? Is MSE used by default in all of them?</p>\n <regression><scikit-learn><p><code>RidgeCV</code> implements CV by <code>GridSearchCV</code>, which supports custom scorer.</p>\n\n<p>However, <code>LassoCV</code> and <code>ElasticNetCV</code> implement CV by <code>LinearModelCV</code>, with MSE as scoring hard-coded. <code>LassoLarsCV</code> impletments CV by <code>LarsCV</code>, with MSE as scoring hard-coded too.</p>\n\n<p>If you want to use other scorers, maybe you can use <code>GridSearchCV</code> directly.</p>\n\n<h2>References</h2>\n\n<p><a href=\"https://github.com/scikit-learn/scikit-learn/blob/14031f6/sklearn/linear_model/ridge.py#L1092\" rel=\"nofollow noreferrer\">https://github.com/scikit-learn/scikit-learn/blob/14031f6/sklearn/linear_model/ridge.py#L1092</a></p>\n\n<p><a href=\"https://github.com/scikit-learn/scikit-learn/blob/14031f6/sklearn/linear_model/coordinate_descent.py#L1181\" rel=\"nofollow noreferrer\">https://github.com/scikit-learn/scikit-learn/blob/14031f6/sklearn/linear_model/coordinate_descent.py#L1181</a></p>\n\n<p><a href=\"https://github.com/scikit-learn/scikit-learn/blob/14031f6/sklearn/linear_model/least_angle.py#L1143\" rel=\"nofollow noreferrer\">https://github.com/scikit-learn/scikit-learn/blob/14031f6/sklearn/linear_model/least_angle.py#L1143</a></p>\n",
                "codes": [
                    []
                ],
                "question_id:": "17620",
                "question_votes:": "1",
                "question_text:": "<p>I was looking at the arguments in the linear regularization methods with cross validation within scikit-learn. RidgeCV has an argument scoring which is None by default but one can use a custom scorer (e.g. RMSE). I noticed that no such option is given for the rest of the classes (LassoCV, LassoLarsCV, ElasticNetCV). Why is this? Is MSE used by default in all of them?</p>\n",
                "tags": "<regression><scikit-learn>",
                "answers": [
                    [
                        "17656",
                        "2",
                        "17620",
                        "",
                        "",
                        "<p><code>RidgeCV</code> implements CV by <code>GridSearchCV</code>, which supports custom scorer.</p>\n\n<p>However, <code>LassoCV</code> and <code>ElasticNetCV</code> implement CV by <code>LinearModelCV</code>, with MSE as scoring hard-coded. <code>LassoLarsCV</code> impletments CV by <code>LarsCV</code>, with MSE as scoring hard-coded too.</p>\n\n<p>If you want to use other scorers, maybe you can use <code>GridSearchCV</code> directly.</p>\n\n<h2>References</h2>\n\n<p><a href=\"https://github.com/scikit-learn/scikit-learn/blob/14031f6/sklearn/linear_model/ridge.py#L1092\" rel=\"nofollow noreferrer\">https://github.com/scikit-learn/scikit-learn/blob/14031f6/sklearn/linear_model/ridge.py#L1092</a></p>\n\n<p><a href=\"https://github.com/scikit-learn/scikit-learn/blob/14031f6/sklearn/linear_model/coordinate_descent.py#L1181\" rel=\"nofollow noreferrer\">https://github.com/scikit-learn/scikit-learn/blob/14031f6/sklearn/linear_model/coordinate_descent.py#L1181</a></p>\n\n<p><a href=\"https://github.com/scikit-learn/scikit-learn/blob/14031f6/sklearn/linear_model/least_angle.py#L1143\" rel=\"nofollow noreferrer\">https://github.com/scikit-learn/scikit-learn/blob/14031f6/sklearn/linear_model/least_angle.py#L1143</a></p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5366",
            "_score": 15.803513,
            "_source": {
                "title": "Why Decision Tree boundary forms a square shape and SVM a circular/oval one?",
                "content": "Why Decision Tree boundary forms a square shape and SVM a circular/oval one? <p>I was going through a Udacity tutorial wherein a few data points were given and the exercise was to test which of the following models best fit the data: linear regression, decision tree, or SVM. Using <code>sklearn</code>, I was able to determine that that SVM is the best fit followed by decision tree. I got a very distinct decision boundary when these two algorithms were applied:</p>\n\n<p><a href=\"https://i.stack.imgur.com/06jWu.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/06jWu.png\" alt=\"enter image description here\"></a></p>\n\n<p>Is there any specific reason for the said shapes or does it just depend on the data sets?</p>\n\n<p>The code was quite straightforward; just reading the CSV, separating the features and then applying the algorithms as shown below:</p>\n\n<pre><code>from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\n\nimport pandas\nimport numpy\n\n# Read the data\ndata = pandas.read_csv('data.csv')\n\n# Split the data into X and y\nX = numpy.array(data[['x1', 'x2']])\ny = numpy.array(data['y'])\n\n# import statements for the classification algorithms\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\n\n    # Logistic Regression Classifier\n    classifier = LogisticRegression()\n    classifier.fit(X,y)\n\n    # Decision Tree Classifier\n    classifier = GradientBoostingClassifier()\n    classifier.fit(X,y)\n\n    # Support Vector Machine Classifier\n    classifier = SVC()\n    classifier.fit(X,y)\n</code></pre>\n <machine-learning><classification><svm><decision-trees><p>Shape of the SVM decision boundary depends on the kernel (similarity function) used. The \"standard\" version of SVM has linear decision boundary. The one displayed could be using Gaussian kernel.</p>\n\n<p>Decision boundary of a decision tree is determined by overlapping orthogonal half-planes (representing the result of each subsequent decision) and can end up as displayed on the pictures.</p>\n\n<p>See more here:</p>\n\n<p><a href=\"https://shapeofdata.wordpress.com/2013/07/02/decision-trees/\" rel=\"nofollow noreferrer\">https://shapeofdata.wordpress.com/2013/07/02/decision-trees/</a></p>\n\n<p><a href=\"https://www.quora.com/What-are-Kernels-in-Machine-Learning-and-SVM\" rel=\"nofollow noreferrer\">https://www.quora.com/What-are-Kernels-in-Machine-Learning-and-SVM</a></p>\n",
                "codes": [
                    []
                ],
                "question_id:": "20548",
                "question_votes:": "4",
                "question_text:": "<p>I was going through a Udacity tutorial wherein a few data points were given and the exercise was to test which of the following models best fit the data: linear regression, decision tree, or SVM. Using <code>sklearn</code>, I was able to determine that that SVM is the best fit followed by decision tree. I got a very distinct decision boundary when these two algorithms were applied:</p>\n\n<p><a href=\"https://i.stack.imgur.com/06jWu.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/06jWu.png\" alt=\"enter image description here\"></a></p>\n\n<p>Is there any specific reason for the said shapes or does it just depend on the data sets?</p>\n\n<p>The code was quite straightforward; just reading the CSV, separating the features and then applying the algorithms as shown below:</p>\n\n<pre><code>from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\n\nimport pandas\nimport numpy\n\n# Read the data\ndata = pandas.read_csv('data.csv')\n\n# Split the data into X and y\nX = numpy.array(data[['x1', 'x2']])\ny = numpy.array(data['y'])\n\n# import statements for the classification algorithms\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\n\n    # Logistic Regression Classifier\n    classifier = LogisticRegression()\n    classifier.fit(X,y)\n\n    # Decision Tree Classifier\n    classifier = GradientBoostingClassifier()\n    classifier.fit(X,y)\n\n    # Support Vector Machine Classifier\n    classifier = SVC()\n    classifier.fit(X,y)\n</code></pre>\n",
                "tags": "<machine-learning><classification><svm><decision-trees>",
                "answers": [
                    [
                        "20549",
                        "2",
                        "20548",
                        "",
                        "",
                        "<p>Shape of the SVM decision boundary depends on the kernel (similarity function) used. The \"standard\" version of SVM has linear decision boundary. The one displayed could be using Gaussian kernel.</p>\n\n<p>Decision boundary of a decision tree is determined by overlapping orthogonal half-planes (representing the result of each subsequent decision) and can end up as displayed on the pictures.</p>\n\n<p>See more here:</p>\n\n<p><a href=\"https://shapeofdata.wordpress.com/2013/07/02/decision-trees/\" rel=\"nofollow noreferrer\">https://shapeofdata.wordpress.com/2013/07/02/decision-trees/</a></p>\n\n<p><a href=\"https://www.quora.com/What-are-Kernels-in-Machine-Learning-and-SVM\" rel=\"nofollow noreferrer\">https://www.quora.com/What-are-Kernels-in-Machine-Learning-and-SVM</a></p>\n",
                        "",
                        "5"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14947",
            "_score": 15.670748,
            "_source": {
                "title": "Predicting yearly income with linear regression using Python",
                "content": "Predicting yearly income with linear regression using Python <p>How to predict the per capita income of Pakistan in 2020 by using linear regression model in Python. The training data is: </p>\n\n<pre><code>Year    Income\n1970    3399.299037\n1971    3768.297935\n1972    4251.175484\n1973    4804.463248\n1974    5576.514583\n1975    5998.144346\n1976    7062.131392\n1977    7100.12617\n1978    7247.967035\n1979    7602.912681\n1980    8355.96812\n1981    9434.390652\n1982    9619.438377\n1983    10416.53659\n1984    10790.32872\n1985    11018.95585\n1986    11482.89153\n1987    12974.80662\n1988    15080.28345\n1989    16426.72548\n1990    16838.6732\n1991    17266.09769\n1992    16412.08309\n1993    15875.58673\n1994    15755.82027\n1995    16369.31725\n1996    16699.82668\n1997    17310.75775\n1998    16622.67187\n1999    17581.02414\n2000    18987.38241\n2001    18601.39724\n2002    19232.17556\n2003    22739.42628\n2004    25719.14715\n2005    29198.05569\n2006    32738.2629\n2007    36144.48122\n2008    37446.48609\n2009    32755.17682\n2010    38420.52289\n2011    42334.71121\n2012    42665.25597\n2013    42676.46837\n2014    41039.8936\n2015    35175.18898\n2016    34229.19363\n</code></pre>\n <machine-learning><python><linear-regression><machine-learning-model><p>Try following this tutorial. \n<a href=\"https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2\" rel=\"nofollow noreferrer\">https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2</a></p>\n\n<p>Here years will be your input variable and income will be the target you are trying to predict. You can use R^2 as an evaluation measure to see how well your model is predicting. Keep the last 10 years for testing to check how well it performs on test set</p>\n<p>Try:</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nimport numpy as np\nregression_model = LinearRegression()\nYear = np.array([[1970], [1971], [1972]]) #your data\nIncome = np.array([3399.299037, 3768.297935, 4251.175484]) #your data\nregression_model.fit(Year, Income)\nregression_model.predict([[1973]]) #make predictions\n</code></pre>\n",
                "codes": [
                    [],
                    [
                        "from sklearn.linear_model import LinearRegression\nimport numpy as np\nregression_model = LinearRegression()\nYear = np.array([[1970], [1971], [1972]]) #your data\nIncome = np.array([3399.299037, 3768.297935, 4251.175484]) #your data\nregression_model.fit(Year, Income)\nregression_model.predict([[1973]]) #make predictions\n"
                    ]
                ],
                "question_id:": "50829",
                "question_votes:": "2",
                "question_text:": "<p>How to predict the per capita income of Pakistan in 2020 by using linear regression model in Python. The training data is: </p>\n\n<pre><code>Year    Income\n1970    3399.299037\n1971    3768.297935\n1972    4251.175484\n1973    4804.463248\n1974    5576.514583\n1975    5998.144346\n1976    7062.131392\n1977    7100.12617\n1978    7247.967035\n1979    7602.912681\n1980    8355.96812\n1981    9434.390652\n1982    9619.438377\n1983    10416.53659\n1984    10790.32872\n1985    11018.95585\n1986    11482.89153\n1987    12974.80662\n1988    15080.28345\n1989    16426.72548\n1990    16838.6732\n1991    17266.09769\n1992    16412.08309\n1993    15875.58673\n1994    15755.82027\n1995    16369.31725\n1996    16699.82668\n1997    17310.75775\n1998    16622.67187\n1999    17581.02414\n2000    18987.38241\n2001    18601.39724\n2002    19232.17556\n2003    22739.42628\n2004    25719.14715\n2005    29198.05569\n2006    32738.2629\n2007    36144.48122\n2008    37446.48609\n2009    32755.17682\n2010    38420.52289\n2011    42334.71121\n2012    42665.25597\n2013    42676.46837\n2014    41039.8936\n2015    35175.18898\n2016    34229.19363\n</code></pre>\n",
                "tags": "<machine-learning><python><linear-regression><machine-learning-model>",
                "answers": [
                    [
                        "50834",
                        "2",
                        "50829",
                        "",
                        "",
                        "<p>Try following this tutorial. \n<a href=\"https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2\" rel=\"nofollow noreferrer\">https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2</a></p>\n\n<p>Here years will be your input variable and income will be the target you are trying to predict. You can use R^2 as an evaluation measure to see how well your model is predicting. Keep the last 10 years for testing to check how well it performs on test set</p>\n",
                        "",
                        ""
                    ],
                    [
                        "50861",
                        "2",
                        "50829",
                        "",
                        "",
                        "<p>Try:</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nimport numpy as np\nregression_model = LinearRegression()\nYear = np.array([[1970], [1971], [1972]]) #your data\nIncome = np.array([3399.299037, 3768.297935, 4251.175484]) #your data\nregression_model.fit(Year, Income)\nregression_model.predict([[1973]]) #make predictions\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3315",
            "_score": 15.670591,
            "_source": {
                "title": "Feature selection with L1 regularization on sklearn's LogisticRegression",
                "content": "Feature selection with L1 regularization on sklearn's LogisticRegression <p>I'm using sklearn's LogisticRegression with <code>penaly=l1</code> (lasso regularization, as opposed to ridge regularization l2). Lasso is causing the optimization function to do implicit feature selection by setting some of the feature weights to zero (as opposed to ridge regularization, which will preserve all features with some non zero weight). Is it possible to extract this weight information (feature selection) from sklearn somehow?</p>\n <scikit-learn><feature-selection><regularization><p>Yes, as demonstrated in the documentation: <a href=\"http://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_path.html\" rel=\"nofollow\">http://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_path.html</a></p>\n\n<p>Welcome to DataScience.SE</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "14198",
                "question_votes:": "1",
                "question_text:": "<p>I'm using sklearn's LogisticRegression with <code>penaly=l1</code> (lasso regularization, as opposed to ridge regularization l2). Lasso is causing the optimization function to do implicit feature selection by setting some of the feature weights to zero (as opposed to ridge regularization, which will preserve all features with some non zero weight). Is it possible to extract this weight information (feature selection) from sklearn somehow?</p>\n",
                "tags": "<scikit-learn><feature-selection><regularization>",
                "answers": [
                    [
                        "14199",
                        "2",
                        "14198",
                        "",
                        "",
                        "<p>Yes, as demonstrated in the documentation: <a href=\"http://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_path.html\" rel=\"nofollow\">http://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_path.html</a></p>\n\n<p>Welcome to DataScience.SE</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12435",
            "_score": 15.668538,
            "_source": {
                "title": "How can someone avoid over fitting or data leak in ridge and lasso regression when the training score is high and test score is low?",
                "content": "How can someone avoid over fitting or data leak in ridge and lasso regression when the training score is high and test score is low? <p>I used the code provided here:\n<a href=\"https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b\" rel=\"nofollow noreferrer\">https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b</a></p>\n\n<p>The only difference is that i used StandardScalar on my data given below:</p>\n\n<pre><code>from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform (X_test)\nprint len(X_test), len(y_test)\n</code></pre>\n\n<p>Here are my ridge regression results:\n<code>linear regression train score: 1.0\nlinear regression test score: -0.07550729376673715\nridge regression train score low alpha: 0.9999999970240117\nridge regression test score low alpha: -0.07532716978805554\nridge regression train score high alpha: 0.8659167364307487\nridge regression test score high alpha: 0.013702748149851396</code></p>\n\n<p>My Lasso results:\n<code>training score: 0.48725444995774625\ntest score:  -0.3393210376146986\nnumber of features used:  4\ntraining score for alpha=0.01: 0.9998352085084429\ntest score for alpha =0.01:  -0.6995903332119675\nnumber of features used: for alpha =0.01: 24\ntraining score for alpha=0.0001: 0.9999999830932269\ntest score for alpha =0.0001:  -0.7189894474663594\nnumber of features used: for alpha =0.0001: 25\nLR training score: 1.0\nLR test score:  -0.7217224228737649</code></p>\n\n<p>I am not able to understand why am i getting such results!\nAny help is highly appreciated.</p>\n\n<p>Edit: The code is below</p>\n\n<pre><code>    #Importing modules\n\n        import sys\n        import math \n        import itertools\n        import numpy as np\n        import pandas as pd\n        from numpy import genfromtxt\n        from matplotlib import style\n        import matplotlib.pyplot as plt\n        from sklearn import linear_model\n        from matplotlib import style, figure\n        from sklearn.linear_model import Lasso\n        from sklearn.linear_model import Ridge\n        from sklearn.linear_model import LinearRegression\n        from sklearn.cross_validation import train_test_split\n\n    #Importing data\n    df = np.genfromtxt('/Users/pfc.csv', delimiter=',')\n\n    X = df[0:,1:298]\n    y = df[0:,0]\n    print (X).shape\n    print (y).shape\n    display (X)\n    display (y)\n    print (y)\n\n\n\n#print type(newY)# pandas core frame\n    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=4)\n\n  #Apply StandardScaler for feature scaling\n        from sklearn.preprocessing import StandardScaler\n        sc = StandardScaler()\n        X_train = sc.fit_transform(X_train)\n        X_test = sc.transform (X_test)\n        print len(X_test), len(y_test)\n\n    lr = LinearRegression()\n    lr.fit(X_train, y_train)\n    rr = Ridge(alpha=0.01) # higher the alpha value, more restriction on the coefficients; low alpha &gt; more generalization, coefficients are barely restricted and in this case linear and ridge regression resembles\n\n    from sklearn.metrics import mean_squared_error\n    from math import sqrt\n    rr.fit(X_train, y_train)\n    rr100 = Ridge(alpha=115.5) #  comparison with alpha value\n    rr100.fit(X_train, y_train)\n    train_score=lr.score(X_train, y_train)\n    test_score=lr.score(X_test, y_test)\n    Ridge_train_score = rr.score(X_train,y_train)\n    Ridge_test_score = rr.score(X_test, y_test)\n    Ridge_train_score100 = rr100.score(X_train,y_train)\n    Ridge_test_score100 = rr100.score(X_test, y_test)\n\n    print \"linear regression train score:\", train_score\n    print \"linear regression test score:\", test_score\n    print \"ridge regression train score low alpha:\", Ridge_train_score\n    print \"ridge regression test score low alpha:\", Ridge_test_score\n    print \"ridge regression train score high alpha:\", Ridge_train_score100\n    print \"ridge regression test score high alpha:\", Ridge_test_score100\n    plt.figure (figsize= (12.8,9.6), dpi =100)\n    plt.plot(rr.coef_,alpha=0.7,linestyle='none',marker='*',markersize=5,color='red',label=r'Ridge; <span class=\"math-container\">$\\alpha = 0.01$</span>',zorder=7) # zorder for ordering the markers\n    plt.plot(rr100.coef_,alpha=0.5,linestyle='none',marker='d',markersize=6,color='blue',label=r'Ridge; <span class=\"math-container\">$\\alpha = 100$</span>') # alpha here is for transparency\n    plt.plot(lr.coef_,alpha=0.4,linestyle='none',marker='o',markersize=7,color='green',label='Linear Regression')\n    plt.xlabel('Coefficient Index',fontsize=16)\n    plt.ylabel('Coefficient Magnitude',fontsize=16)\n    plt.legend(fontsize=13,loc=4)\n    plt.show()\n\n    # difference of lasso and ridge regression is that some of the coefficients can be zero i.e. some of the features are \n    # completely neglected\n    lasso = Lasso()\n    lasso.fit(X_train,y_train)\n    train_score=lasso.score(X_train,y_train)\n    test_score=lasso.score(X_test,y_test)\n    coeff_used = np.sum(lasso.coef_!=0)\n    print \"training score:\", train_score \n    print \"test score: \", test_score\n    print \"number of features used: \", coeff_used\n    lasso001 = Lasso(alpha=0.01, max_iter=10e5)\n    lasso001.fit(X_train,y_train)\n    train_score001=lasso001.score(X_train,y_train)\n    test_score001=lasso001.score(X_test,y_test)\n    coeff_used001 = np.sum(lasso001.coef_!=0)\n    print \"training score for alpha=0.01:\", train_score001 \n    print \"test score for alpha =0.01: \", test_score001\n    print \"number of features used: for alpha =0.01:\", coeff_used001\n    lasso00001 = Lasso(alpha=0.0001, max_iter=10e5)\n    lasso00001.fit(X_train,y_train)\n    train_score00001=lasso00001.score(X_train,y_train)\n    test_score00001=lasso00001.score(X_test,y_test)\n    coeff_used00001 = np.sum(lasso00001.coef_!=0)\n    print \"training score for alpha=0.0001:\", train_score00001 \n    print \"test score for alpha =0.0001: \", test_score00001\n    print \"number of features used: for alpha =0.0001:\", coeff_used00001\n    lr = LinearRegression()\n    lr.fit(X_train,y_train)\n    lr_train_score=lr.score(X_train,y_train)\n    lr_test_score=lr.score(X_test,y_test)\n    print \"LR training score:\", lr_train_score \n    print \"LR test score: \", lr_test_score\n    plt.figure (figsize= (12.8,9.6), dpi =100)\n    plt.subplot(1,2,1)\n    plt.plot(lasso.coef_,alpha=0.7,linestyle='none',marker='*',markersize=5,color='red',label=r'Lasso; <span class=\"math-container\">$\\alpha = 1$</span>',zorder=7) # alpha here is for transparency\n    plt.plot(lasso001.coef_,alpha=0.5,linestyle='none',marker='d',markersize=6,color='blue',label=r'Lasso; <span class=\"math-container\">$\\alpha = 0.01$</span>') # alpha here is for transparency\n    plt.xlabel('Coefficient Index',fontsize=16)\n    plt.ylabel('Coefficient Magnitude',fontsize=16)\n    plt.legend(fontsize=13,loc=4)\n    plt.subplot(1,2,2)\n    plt.plot(lasso.coef_,alpha=0.7,linestyle='none',marker='*',markersize=5,color='red',label=r'Lasso; <span class=\"math-container\">$\\alpha = 1$</span>',zorder=7) # alpha here is for transparency\n    plt.plot(lasso001.coef_,alpha=0.5,linestyle='none',marker='d',markersize=6,color='blue',label=r'Lasso; <span class=\"math-container\">$\\alpha = 0.01$</span>') # alpha here is for transparency\n    plt.plot(lasso00001.coef_,alpha=0.8,linestyle='none',marker='v',markersize=6,color='black',label=r'Lasso; <span class=\"math-container\">$\\alpha = 0.00001$</span>') # alpha here is for transparency\n    plt.plot(lr.coef_,alpha=0.7,linestyle='none',marker='o',markersize=5,color='green',label='Linear Regression',zorder=2)\n    plt.xlabel('Coefficient Index',fontsize=16)\n    plt.ylabel('Coefficient Magnitude',fontsize=16)\n    plt.legend(fontsize=13,loc=4)\n    plt.tight_layout()\n    plt.show()\n</code></pre>\n\n<p>PS: Please ignore the indentation.</p>\n <machine-learning><regression><machine-learning-model><overfitting><p>You should probably post your code, since you have a negative score which is not possible if the score is R-squared.</p>\n\n<p>The code on the link you provided uses sklearn's .score() function which computes R-squared of the fit. The R-squared metric ranges from 0 to 1 and shows the percentage of the variation explained by the model. This means that an R-squared of 1 means your model perfectly fits the data. After you fix the code so that there is no negative values, taking a look at the R-square should give you enough to understand when it is over-fitting and under-fitting.</p>\n\n<p><strong>Hint:</strong> if you have significantly higher R-squared on your training data than test data, it means that the model is ovefitting. Good luck!</p>\n\n<p>Edit: turns out, R-squared can be negative, it means that it performs very poorly! If you just aim to find the best alpha, i suggest you use LassoCV which finds the alpha that optimises the model using cross validation, there is sk-learn implementation.</p>\n<p>I found this to be a good answer to my question. \n<a href=\"http://www.fairlynerdy.com/what-is-r-squared/\" rel=\"nofollow noreferrer\">http://www.fairlynerdy.com/what-is-r-squared/</a></p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "43661",
                "question_votes:": "1",
                "question_text:": "<p>I used the code provided here:\n<a href=\"https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b\" rel=\"nofollow noreferrer\">https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b</a></p>\n\n<p>The only difference is that i used StandardScalar on my data given below:</p>\n\n<pre><code>from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform (X_test)\nprint len(X_test), len(y_test)\n</code></pre>\n\n<p>Here are my ridge regression results:\n<code>linear regression train score: 1.0\nlinear regression test score: -0.07550729376673715\nridge regression train score low alpha: 0.9999999970240117\nridge regression test score low alpha: -0.07532716978805554\nridge regression train score high alpha: 0.8659167364307487\nridge regression test score high alpha: 0.013702748149851396</code></p>\n\n<p>My Lasso results:\n<code>training score: 0.48725444995774625\ntest score:  -0.3393210376146986\nnumber of features used:  4\ntraining score for alpha=0.01: 0.9998352085084429\ntest score for alpha =0.01:  -0.6995903332119675\nnumber of features used: for alpha =0.01: 24\ntraining score for alpha=0.0001: 0.9999999830932269\ntest score for alpha =0.0001:  -0.7189894474663594\nnumber of features used: for alpha =0.0001: 25\nLR training score: 1.0\nLR test score:  -0.7217224228737649</code></p>\n\n<p>I am not able to understand why am i getting such results!\nAny help is highly appreciated.</p>\n\n<p>Edit: The code is below</p>\n\n<pre><code>    #Importing modules\n\n        import sys\n        import math \n        import itertools\n        import numpy as np\n        import pandas as pd\n        from numpy import genfromtxt\n        from matplotlib import style\n        import matplotlib.pyplot as plt\n        from sklearn import linear_model\n        from matplotlib import style, figure\n        from sklearn.linear_model import Lasso\n        from sklearn.linear_model import Ridge\n        from sklearn.linear_model import LinearRegression\n        from sklearn.cross_validation import train_test_split\n\n    #Importing data\n    df = np.genfromtxt('/Users/pfc.csv', delimiter=',')\n\n    X = df[0:,1:298]\n    y = df[0:,0]\n    print (X).shape\n    print (y).shape\n    display (X)\n    display (y)\n    print (y)\n\n\n\n#print type(newY)# pandas core frame\n    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=4)\n\n  #Apply StandardScaler for feature scaling\n        from sklearn.preprocessing import StandardScaler\n        sc = StandardScaler()\n        X_train = sc.fit_transform(X_train)\n        X_test = sc.transform (X_test)\n        print len(X_test), len(y_test)\n\n    lr = LinearRegression()\n    lr.fit(X_train, y_train)\n    rr = Ridge(alpha=0.01) # higher the alpha value, more restriction on the coefficients; low alpha &gt; more generalization, coefficients are barely restricted and in this case linear and ridge regression resembles\n\n    from sklearn.metrics import mean_squared_error\n    from math import sqrt\n    rr.fit(X_train, y_train)\n    rr100 = Ridge(alpha=115.5) #  comparison with alpha value\n    rr100.fit(X_train, y_train)\n    train_score=lr.score(X_train, y_train)\n    test_score=lr.score(X_test, y_test)\n    Ridge_train_score = rr.score(X_train,y_train)\n    Ridge_test_score = rr.score(X_test, y_test)\n    Ridge_train_score100 = rr100.score(X_train,y_train)\n    Ridge_test_score100 = rr100.score(X_test, y_test)\n\n    print \"linear regression train score:\", train_score\n    print \"linear regression test score:\", test_score\n    print \"ridge regression train score low alpha:\", Ridge_train_score\n    print \"ridge regression test score low alpha:\", Ridge_test_score\n    print \"ridge regression train score high alpha:\", Ridge_train_score100\n    print \"ridge regression test score high alpha:\", Ridge_test_score100\n    plt.figure (figsize= (12.8,9.6), dpi =100)\n    plt.plot(rr.coef_,alpha=0.7,linestyle='none',marker='*',markersize=5,color='red',label=r'Ridge; <span class=\"math-container\">$\\alpha = 0.01$</span>',zorder=7) # zorder for ordering the markers\n    plt.plot(rr100.coef_,alpha=0.5,linestyle='none',marker='d',markersize=6,color='blue',label=r'Ridge; <span class=\"math-container\">$\\alpha = 100$</span>') # alpha here is for transparency\n    plt.plot(lr.coef_,alpha=0.4,linestyle='none',marker='o',markersize=7,color='green',label='Linear Regression')\n    plt.xlabel('Coefficient Index',fontsize=16)\n    plt.ylabel('Coefficient Magnitude',fontsize=16)\n    plt.legend(fontsize=13,loc=4)\n    plt.show()\n\n    # difference of lasso and ridge regression is that some of the coefficients can be zero i.e. some of the features are \n    # completely neglected\n    lasso = Lasso()\n    lasso.fit(X_train,y_train)\n    train_score=lasso.score(X_train,y_train)\n    test_score=lasso.score(X_test,y_test)\n    coeff_used = np.sum(lasso.coef_!=0)\n    print \"training score:\", train_score \n    print \"test score: \", test_score\n    print \"number of features used: \", coeff_used\n    lasso001 = Lasso(alpha=0.01, max_iter=10e5)\n    lasso001.fit(X_train,y_train)\n    train_score001=lasso001.score(X_train,y_train)\n    test_score001=lasso001.score(X_test,y_test)\n    coeff_used001 = np.sum(lasso001.coef_!=0)\n    print \"training score for alpha=0.01:\", train_score001 \n    print \"test score for alpha =0.01: \", test_score001\n    print \"number of features used: for alpha =0.01:\", coeff_used001\n    lasso00001 = Lasso(alpha=0.0001, max_iter=10e5)\n    lasso00001.fit(X_train,y_train)\n    train_score00001=lasso00001.score(X_train,y_train)\n    test_score00001=lasso00001.score(X_test,y_test)\n    coeff_used00001 = np.sum(lasso00001.coef_!=0)\n    print \"training score for alpha=0.0001:\", train_score00001 \n    print \"test score for alpha =0.0001: \", test_score00001\n    print \"number of features used: for alpha =0.0001:\", coeff_used00001\n    lr = LinearRegression()\n    lr.fit(X_train,y_train)\n    lr_train_score=lr.score(X_train,y_train)\n    lr_test_score=lr.score(X_test,y_test)\n    print \"LR training score:\", lr_train_score \n    print \"LR test score: \", lr_test_score\n    plt.figure (figsize= (12.8,9.6), dpi =100)\n    plt.subplot(1,2,1)\n    plt.plot(lasso.coef_,alpha=0.7,linestyle='none',marker='*',markersize=5,color='red',label=r'Lasso; <span class=\"math-container\">$\\alpha = 1$</span>',zorder=7) # alpha here is for transparency\n    plt.plot(lasso001.coef_,alpha=0.5,linestyle='none',marker='d',markersize=6,color='blue',label=r'Lasso; <span class=\"math-container\">$\\alpha = 0.01$</span>') # alpha here is for transparency\n    plt.xlabel('Coefficient Index',fontsize=16)\n    plt.ylabel('Coefficient Magnitude',fontsize=16)\n    plt.legend(fontsize=13,loc=4)\n    plt.subplot(1,2,2)\n    plt.plot(lasso.coef_,alpha=0.7,linestyle='none',marker='*',markersize=5,color='red',label=r'Lasso; <span class=\"math-container\">$\\alpha = 1$</span>',zorder=7) # alpha here is for transparency\n    plt.plot(lasso001.coef_,alpha=0.5,linestyle='none',marker='d',markersize=6,color='blue',label=r'Lasso; <span class=\"math-container\">$\\alpha = 0.01$</span>') # alpha here is for transparency\n    plt.plot(lasso00001.coef_,alpha=0.8,linestyle='none',marker='v',markersize=6,color='black',label=r'Lasso; <span class=\"math-container\">$\\alpha = 0.00001$</span>') # alpha here is for transparency\n    plt.plot(lr.coef_,alpha=0.7,linestyle='none',marker='o',markersize=5,color='green',label='Linear Regression',zorder=2)\n    plt.xlabel('Coefficient Index',fontsize=16)\n    plt.ylabel('Coefficient Magnitude',fontsize=16)\n    plt.legend(fontsize=13,loc=4)\n    plt.tight_layout()\n    plt.show()\n</code></pre>\n\n<p>PS: Please ignore the indentation.</p>\n",
                "tags": "<machine-learning><regression><machine-learning-model><overfitting>",
                "answers": [
                    [
                        "43716",
                        "2",
                        "43661",
                        "",
                        "",
                        "<p>You should probably post your code, since you have a negative score which is not possible if the score is R-squared.</p>\n\n<p>The code on the link you provided uses sklearn's .score() function which computes R-squared of the fit. The R-squared metric ranges from 0 to 1 and shows the percentage of the variation explained by the model. This means that an R-squared of 1 means your model perfectly fits the data. After you fix the code so that there is no negative values, taking a look at the R-square should give you enough to understand when it is over-fitting and under-fitting.</p>\n\n<p><strong>Hint:</strong> if you have significantly higher R-squared on your training data than test data, it means that the model is ovefitting. Good luck!</p>\n\n<p>Edit: turns out, R-squared can be negative, it means that it performs very poorly! If you just aim to find the best alpha, i suggest you use LassoCV which finds the alpha that optimises the model using cross validation, there is sk-learn implementation.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "43808",
                        "2",
                        "43661",
                        "",
                        "",
                        "<p>I found this to be a good answer to my question. \n<a href=\"http://www.fairlynerdy.com/what-is-r-squared/\" rel=\"nofollow noreferrer\">http://www.fairlynerdy.com/what-is-r-squared/</a></p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15766",
            "_score": 15.605627,
            "_source": {
                "title": "How to import statsmodels module to use OLS class?",
                "content": "How to import statsmodels module to use OLS class? <p>I am trying multiple Regression</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Importing Dataset\ndataset = pd.read_csv(\n    'C:/Users/Rupali Singh/Desktop/ML A-Z/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 5 - Multiple Linear Regression/50_Startups.csv')\nprint(dataset)\nX = dataset.iloc[:, :-1].values\nY = dataset.iloc[:, 4].values\n\n# Categorical Data\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\nlabelencoder = LabelEncoder()\nX[:, 3] = labelencoder.fit_transform(X[:, 3])\nonehotencoder = OneHotEncoder(categorical_features=[3])\nX = onehotencoder.fit_transform(X).toarray()\n\n# Splitting the dataset into training set and test set\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\nprint(Y_train)\n\n# Fitting Multiple Linear Regression\n\nfrom sklearn.linear_model import LinearRegression\n\nregressor = LinearRegression()\nregressor.fit(X_train, Y_train)\n\n# predicting the test result\nY_pred = regressor.predict(X_test)\n</code></pre>\n\n<p>This is the part where error is occuring</p>\n\n<pre><code># Building the optimal model with Backward Elimination\nimport statsmodels.formula.api as sm\n\nX = np.append(arr=np.ones((50, 1)).astype(int), values=X, axis=1)\nprint(X)\nX_opt = X[:, [0, 1, 2, 3, 4, 5]]\nregressor_ols = sm.OLS(endog=Y, exog=X_opt).fit()\nprint(regressor_ols.summary())\n</code></pre>\n\n<p>This is the error message</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"C:/Users/Rupali Singh/PycharmProjects/Machine_Learning/Muliple_Linear_Regression.py\", line 39, in &lt;module&gt;\n    import statsmodels.formula.api as sm\n  File \"C:\\Users\\Rupali Singh\\PycharmProjects\\Machine_Learning\\venv\\lib\\site-packages\\statsmodels\\formula\\api.py\", line 15, in &lt;module&gt;\n    from statsmodels.discrete.discrete_model import MNLogit\n  File \"C:\\Users\\Rupali Singh\\PycharmProjects\\Machine_Learning\\venv\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\", line 45, in &lt;module&gt;\n    from statsmodels.distributions import genpoisson_p\n  File \"C:\\Users\\Rupali Singh\\PycharmProjects\\Machine_Learning\\venv\\lib\\site-packages\\statsmodels\\distributions\\__init__.py\", line 2, in &lt;module&gt;\n    from .edgeworth import ExpandedNormal\n  File \"C:\\Users\\Rupali Singh\\PycharmProjects\\Machine_Learning\\venv\\lib\\site-packages\\statsmodels\\distributions\\edgeworth.py\", line 7, in &lt;module&gt;\n    from scipy.misc import factorial\nImportError: cannot import name 'factorial'\n\nProcess finished with exit code 1\n</code></pre>\n <machine-learning><regression><linear-regression><p>See <a href=\"https://stackoverflow.com/a/56284155/9524424\">https://stackoverflow.com/a/56284155/9524424</a></p>\n\n<p>You need to have a matching scipy version (1.2 instead of 1.3)</p>\n<p>This is essentially an incompatibility in statsmodels with the version of scipy that it uses: statsmodels 0.9 is not compatible with scipy 1.3.0. I would call that a bug. It has <a href=\"https://github.com/statsmodels/statsmodels/issues/5759\" rel=\"nofollow noreferrer\">been reported already</a>. If you upgrade to the latest development version of statsmodels, the problem will disappear:</p>\n\n<pre><code>pip install --upgrade Cython\npip install --upgrade git+https://github.com/statsmodels/statsmodels\n</code></pre>\n\n<p>For me, this fixed the problem. An alternative would be to downgrade scipy to version 1.2.</p>\n",
                "codes": [
                    [],
                    [
                        "pip install --upgrade Cython\npip install --upgrade git+https://github.com/statsmodels/statsmodels\n"
                    ]
                ],
                "question_id:": "52615",
                "question_votes:": "1",
                "question_text:": "<p>I am trying multiple Regression</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Importing Dataset\ndataset = pd.read_csv(\n    'C:/Users/Rupali Singh/Desktop/ML A-Z/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 5 - Multiple Linear Regression/50_Startups.csv')\nprint(dataset)\nX = dataset.iloc[:, :-1].values\nY = dataset.iloc[:, 4].values\n\n# Categorical Data\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\nlabelencoder = LabelEncoder()\nX[:, 3] = labelencoder.fit_transform(X[:, 3])\nonehotencoder = OneHotEncoder(categorical_features=[3])\nX = onehotencoder.fit_transform(X).toarray()\n\n# Splitting the dataset into training set and test set\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\nprint(Y_train)\n\n# Fitting Multiple Linear Regression\n\nfrom sklearn.linear_model import LinearRegression\n\nregressor = LinearRegression()\nregressor.fit(X_train, Y_train)\n\n# predicting the test result\nY_pred = regressor.predict(X_test)\n</code></pre>\n\n<p>This is the part where error is occuring</p>\n\n<pre><code># Building the optimal model with Backward Elimination\nimport statsmodels.formula.api as sm\n\nX = np.append(arr=np.ones((50, 1)).astype(int), values=X, axis=1)\nprint(X)\nX_opt = X[:, [0, 1, 2, 3, 4, 5]]\nregressor_ols = sm.OLS(endog=Y, exog=X_opt).fit()\nprint(regressor_ols.summary())\n</code></pre>\n\n<p>This is the error message</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"C:/Users/Rupali Singh/PycharmProjects/Machine_Learning/Muliple_Linear_Regression.py\", line 39, in &lt;module&gt;\n    import statsmodels.formula.api as sm\n  File \"C:\\Users\\Rupali Singh\\PycharmProjects\\Machine_Learning\\venv\\lib\\site-packages\\statsmodels\\formula\\api.py\", line 15, in &lt;module&gt;\n    from statsmodels.discrete.discrete_model import MNLogit\n  File \"C:\\Users\\Rupali Singh\\PycharmProjects\\Machine_Learning\\venv\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\", line 45, in &lt;module&gt;\n    from statsmodels.distributions import genpoisson_p\n  File \"C:\\Users\\Rupali Singh\\PycharmProjects\\Machine_Learning\\venv\\lib\\site-packages\\statsmodels\\distributions\\__init__.py\", line 2, in &lt;module&gt;\n    from .edgeworth import ExpandedNormal\n  File \"C:\\Users\\Rupali Singh\\PycharmProjects\\Machine_Learning\\venv\\lib\\site-packages\\statsmodels\\distributions\\edgeworth.py\", line 7, in &lt;module&gt;\n    from scipy.misc import factorial\nImportError: cannot import name 'factorial'\n\nProcess finished with exit code 1\n</code></pre>\n",
                "tags": "<machine-learning><regression><linear-regression>",
                "answers": [
                    [
                        "52618",
                        "2",
                        "52615",
                        "",
                        "",
                        "<p>See <a href=\"https://stackoverflow.com/a/56284155/9524424\">https://stackoverflow.com/a/56284155/9524424</a></p>\n\n<p>You need to have a matching scipy version (1.2 instead of 1.3)</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "52619",
                        "2",
                        "52615",
                        "",
                        "",
                        "<p>This is essentially an incompatibility in statsmodels with the version of scipy that it uses: statsmodels 0.9 is not compatible with scipy 1.3.0. I would call that a bug. It has <a href=\"https://github.com/statsmodels/statsmodels/issues/5759\" rel=\"nofollow noreferrer\">been reported already</a>. If you upgrade to the latest development version of statsmodels, the problem will disappear:</p>\n\n<pre><code>pip install --upgrade Cython\npip install --upgrade git+https://github.com/statsmodels/statsmodels\n</code></pre>\n\n<p>For me, this fixed the problem. An alternative would be to downgrade scipy to version 1.2.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9669",
            "_score": 15.585018,
            "_source": {
                "title": "Value error array with 0 features in linear regression scikit",
                "content": "Value error array with 0 features in linear regression scikit <p>My input and output data are written in an 6xn row-column excel file,thatI read them using pandas</p>\n\n<p>using this code :</p>\n\n<pre><code>from sklearn import linear_model\nimport os\nimport pandas as pd\nimport numpy as np\nimport openpyxl as pyx\nimport numpy as np\nimport matplotlib.pyplot as plt\n\npath = r\"E:\\\"\nos.chdir( path )\n\ndata1 = pd.read_excel(\"input.xlsx\", header=None,index=False)\ndata2 = pd.read_excel(\"target.xlsx\", header=None,index=False)\n\n# print df.head()\n\nle= 20;lg=len(data1)\nx_train=[];x_t=[];y_train=[];y_t=[];x_test=[];x_ts=[];y_test=[];y_ts=[];\nfor i in range(le):    \n    x_t = data1.iloc[i,:]\n    x_train.append(x_t)\n    y_t = data2.iloc[i,:]\n    y_train.append(y_t)\n    if i &gt; le :\n        x_ts = data1.iloc[lg-i,:]\n        x_test.append(x_ts)\n        y_ts = data2.iloc[lg-i,:]\n        y_test.append(y_ts)\n\n\n\nols = linear_model.LinearRegression()\nmodel = ols.fit(x_train, y_train)\n\nprint (model.predict(x_test)[0:5]) \n</code></pre>\n\n<p>I get this error :</p>\n\n<blockquote>\n  <p>File\n  \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\",\n  line 880, in runfile\n      execfile(filename, namespace)</p>\n  \n  <p>File\n  \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\",\n  line 102, in execfile\n      exec(compile(f.read(), filename, 'exec'), namespace)</p>\n  \n  <p>File \"E:/Scikit-Learn.py\", line 46, in \n      print (model.predict(x_test)[0:5])</p>\n  \n  <p>File\n  \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\",\n  line 268, in predict\n      return self._decision_function(X)</p>\n  \n  <p>File\n  \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\",\n  line 251, in _decision_function\n      X = check_array(X, accept_sparse=['csr', 'csc', 'coo'])</p>\n  \n  <p>File\n  \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\",\n  line 424, in check_array\n      context))</p>\n  \n  <p>ValueError: Found array with 0 feature(s) (shape=(1, 0)) while a\n  minimum of 1 is required.</p>\n</blockquote>\n <machine-learning><scikit-learn><linear-regression><p>The error says that the array you feed into <code>predict</code> has <code>shape=(1,0)</code> meaning that it must be an empty iterable.</p>\n\n<p>And by looking at your code, it's easy to see why. <code>x_test</code> starts of as empty, and in your code, the only way to add things to it is if <code>i &gt; le</code>. But since your loop is defined as <code>for i in range(le)</code>, by definition <code>i</code> will never be greater than <code>le</code> since the last value of <code>range</code> is <code>le-1</code></p>\n",
                "codes": [
                    []
                ],
                "question_id:": "34325",
                "question_votes:": "1",
                "question_text:": "<p>My input and output data are written in an 6xn row-column excel file,thatI read them using pandas</p>\n\n<p>using this code :</p>\n\n<pre><code>from sklearn import linear_model\nimport os\nimport pandas as pd\nimport numpy as np\nimport openpyxl as pyx\nimport numpy as np\nimport matplotlib.pyplot as plt\n\npath = r\"E:\\\"\nos.chdir( path )\n\ndata1 = pd.read_excel(\"input.xlsx\", header=None,index=False)\ndata2 = pd.read_excel(\"target.xlsx\", header=None,index=False)\n\n# print df.head()\n\nle= 20;lg=len(data1)\nx_train=[];x_t=[];y_train=[];y_t=[];x_test=[];x_ts=[];y_test=[];y_ts=[];\nfor i in range(le):    \n    x_t = data1.iloc[i,:]\n    x_train.append(x_t)\n    y_t = data2.iloc[i,:]\n    y_train.append(y_t)\n    if i &gt; le :\n        x_ts = data1.iloc[lg-i,:]\n        x_test.append(x_ts)\n        y_ts = data2.iloc[lg-i,:]\n        y_test.append(y_ts)\n\n\n\nols = linear_model.LinearRegression()\nmodel = ols.fit(x_train, y_train)\n\nprint (model.predict(x_test)[0:5]) \n</code></pre>\n\n<p>I get this error :</p>\n\n<blockquote>\n  <p>File\n  \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\",\n  line 880, in runfile\n      execfile(filename, namespace)</p>\n  \n  <p>File\n  \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\",\n  line 102, in execfile\n      exec(compile(f.read(), filename, 'exec'), namespace)</p>\n  \n  <p>File \"E:/Scikit-Learn.py\", line 46, in \n      print (model.predict(x_test)[0:5])</p>\n  \n  <p>File\n  \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\",\n  line 268, in predict\n      return self._decision_function(X)</p>\n  \n  <p>File\n  \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\",\n  line 251, in _decision_function\n      X = check_array(X, accept_sparse=['csr', 'csc', 'coo'])</p>\n  \n  <p>File\n  \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\",\n  line 424, in check_array\n      context))</p>\n  \n  <p>ValueError: Found array with 0 feature(s) (shape=(1, 0)) while a\n  minimum of 1 is required.</p>\n</blockquote>\n",
                "tags": "<machine-learning><scikit-learn><linear-regression>",
                "answers": [
                    [
                        "34372",
                        "2",
                        "34325",
                        "",
                        "",
                        "<p>The error says that the array you feed into <code>predict</code> has <code>shape=(1,0)</code> meaning that it must be an empty iterable.</p>\n\n<p>And by looking at your code, it's easy to see why. <code>x_test</code> starts of as empty, and in your code, the only way to add things to it is if <code>i &gt; le</code>. But since your loop is defined as <code>for i in range(le)</code>, by definition <code>i</code> will never be greater than <code>le</code> since the last value of <code>range</code> is <code>le-1</code></p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8787",
            "_score": 15.583609,
            "_source": {
                "title": "Query data dimension",
                "content": "Query data dimension <pre><code>import numpy as np\nfrom sklearn import preprocessing, cross_validation, neighbors\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndf = pd.read_csv('Downloads/breast-cancer-wisconsin.data.txt',skiprows=1)\ndf.replace('?', -99999, inplace=True)\ndf.drop('id', 1, inplace=True )\n\nX= np.array(df.drop(['class'],1))\ny= np.array(df['class'])\n\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.2)\n\n#clf = neighbors.KNeighborsClassifier()\nclf = LinearRegression(normalize=True)\nclf.fit(X_train, y_train)\n\naccuracy= clf.score(X_test, y_test)\nprint(accuracy)\n\nexample_measures = np.array([[4,2,1,1,1,2,3,2,1],[4,2,1,2,2,2,3,2,1]])\nexample_measures = example_measures.reshape(1,-1)\n\nprediction = clf.predict(example_measures)     ##(example_measures)\n\nprint(prediction)\n</code></pre>\n\n<p>Problem arises when  I run the above command line at Ubuntu or Anaconda:</p>\n\n<blockquote>\n  <p>ValueError: query data dimension must match training data dimension</p>\n</blockquote>\n\n<p>How to solve that problem ? I am sure that by method of isolating individual commandline-- and find it appears Error at :</p>\n\n<pre><code>prediction = clf.predict(example_measures)\n</code></pre>\n\n<p>I try to use : </p>\n\n<pre><code>prediction = clf.predict(X_test).\n</code></pre>\n\n<p>It is ok.\nI really want to predict the example I create. How can I change the code?</p>\n <machine-learning-model><p>How many columns do <code>X_train</code> and <code>X_test</code> have? </p>\n\n<p>I'd imagine (though can't confirm, as I don't have access to your data) that they have fewer (or more) than 18 columns.</p>\n\n<p>This is because your code </p>\n\n<pre><code>example_measures = np.array([[4,2,1,1,1,2,3,2,1],[4,2,1,2,2,2,3,2,1]])\nexample_measures = example_measures.reshape(1,-1)\n</code></pre>\n\n<p>produces an array of shape <code>(1, 18)</code>.</p>\n\n<p>EDIT: I've tried matching your dataset, and got the following:</p>\n\n<pre><code>import numpy as np\nfrom sklearn import preprocessing, cross_validation, neighbors\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.datasets import load_breast_cancer\n\nX= load_breast_cancer().data\ny= load_breast_cancer().target\n\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.2)\n\nclf = LinearRegression(normalize=True)\nclf.fit(X_train, y_train)\n\naccuracy= clf.score(X_test, y_test)\nprint(accuracy)\n</code></pre>\n\n<p>If I call <code>X.shape</code>, I get <code>(569, 30)</code>. So, if you want to make your own array to pass to <code>clf</code>, it needs to have 30 columns (one for each feature).</p>\n",
                "codes": [
                    [
                        "example_measures = np.array([[4,2,1,1,1,2,3,2,1],[4,2,1,2,2,2,3,2,1]])\nexample_measures = example_measures.reshape(1,-1)\n",
                        "import numpy as np\nfrom sklearn import preprocessing, cross_validation, neighbors\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.datasets import load_breast_cancer\n\nX= load_breast_cancer().data\ny= load_breast_cancer().target\n\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.2)\n\nclf = LinearRegression(normalize=True)\nclf.fit(X_train, y_train)\n\naccuracy= clf.score(X_test, y_test)\nprint(accuracy)\n"
                    ]
                ],
                "question_id:": "31795",
                "question_votes:": "3",
                "question_text:": "<pre><code>import numpy as np\nfrom sklearn import preprocessing, cross_validation, neighbors\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndf = pd.read_csv('Downloads/breast-cancer-wisconsin.data.txt',skiprows=1)\ndf.replace('?', -99999, inplace=True)\ndf.drop('id', 1, inplace=True )\n\nX= np.array(df.drop(['class'],1))\ny= np.array(df['class'])\n\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.2)\n\n#clf = neighbors.KNeighborsClassifier()\nclf = LinearRegression(normalize=True)\nclf.fit(X_train, y_train)\n\naccuracy= clf.score(X_test, y_test)\nprint(accuracy)\n\nexample_measures = np.array([[4,2,1,1,1,2,3,2,1],[4,2,1,2,2,2,3,2,1]])\nexample_measures = example_measures.reshape(1,-1)\n\nprediction = clf.predict(example_measures)     ##(example_measures)\n\nprint(prediction)\n</code></pre>\n\n<p>Problem arises when  I run the above command line at Ubuntu or Anaconda:</p>\n\n<blockquote>\n  <p>ValueError: query data dimension must match training data dimension</p>\n</blockquote>\n\n<p>How to solve that problem ? I am sure that by method of isolating individual commandline-- and find it appears Error at :</p>\n\n<pre><code>prediction = clf.predict(example_measures)\n</code></pre>\n\n<p>I try to use : </p>\n\n<pre><code>prediction = clf.predict(X_test).\n</code></pre>\n\n<p>It is ok.\nI really want to predict the example I create. How can I change the code?</p>\n",
                "tags": "<machine-learning-model>",
                "answers": [
                    [
                        "31805",
                        "2",
                        "31795",
                        "",
                        "",
                        "<p>How many columns do <code>X_train</code> and <code>X_test</code> have? </p>\n\n<p>I'd imagine (though can't confirm, as I don't have access to your data) that they have fewer (or more) than 18 columns.</p>\n\n<p>This is because your code </p>\n\n<pre><code>example_measures = np.array([[4,2,1,1,1,2,3,2,1],[4,2,1,2,2,2,3,2,1]])\nexample_measures = example_measures.reshape(1,-1)\n</code></pre>\n\n<p>produces an array of shape <code>(1, 18)</code>.</p>\n\n<p>EDIT: I've tried matching your dataset, and got the following:</p>\n\n<pre><code>import numpy as np\nfrom sklearn import preprocessing, cross_validation, neighbors\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.datasets import load_breast_cancer\n\nX= load_breast_cancer().data\ny= load_breast_cancer().target\n\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.2)\n\nclf = LinearRegression(normalize=True)\nclf.fit(X_train, y_train)\n\naccuracy= clf.score(X_test, y_test)\nprint(accuracy)\n</code></pre>\n\n<p>If I call <code>X.shape</code>, I get <code>(569, 30)</code>. So, if you want to make your own array to pass to <code>clf</code>, it needs to have 30 columns (one for each feature).</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13636",
            "_score": 15.527085,
            "_source": {
                "title": "model.score and r2_score giving different values for a regression model",
                "content": "model.score and r2_score giving different values for a regression model <p>I am build a linear regression model and a decision tree model using sklearn. I want to compare the performance of these two models, I have calculated the r2_score for both the models. I have calculated the model.score for both the values. I am confused which is a better metric to compare the performance of these models. Also what does model.score gives?</p>\n\n<pre><code>from sklearn.metrics import r2_score\nscore_DT = r2_score(y_pred_DT,y_test)\n\ndt_score = regressorDT.score(X_test,y_test)\n</code></pre>\n <machine-learning><scikit-learn><regression><decision-trees><linear-regression><p>Both functions are the same r2 metric and should produce the same results.</p>\n\n<p>Your usage of the r2_score function is wrong. The first argument should be the ground truth values and not the predicted values, so in your case it should be:</p>\n\n<pre><code>score_DT = r2_score(y_test, y_pred_DT)\n</code></pre>\n",
                "codes": [
                    [
                        "score_DT = r2_score(y_test, y_pred_DT)\n"
                    ]
                ],
                "question_id:": "46444",
                "question_votes:": "1",
                "question_text:": "<p>I am build a linear regression model and a decision tree model using sklearn. I want to compare the performance of these two models, I have calculated the r2_score for both the models. I have calculated the model.score for both the values. I am confused which is a better metric to compare the performance of these models. Also what does model.score gives?</p>\n\n<pre><code>from sklearn.metrics import r2_score\nscore_DT = r2_score(y_pred_DT,y_test)\n\ndt_score = regressorDT.score(X_test,y_test)\n</code></pre>\n",
                "tags": "<machine-learning><scikit-learn><regression><decision-trees><linear-regression>",
                "answers": [
                    [
                        "46447",
                        "2",
                        "46444",
                        "",
                        "",
                        "<p>Both functions are the same r2 metric and should produce the same results.</p>\n\n<p>Your usage of the r2_score function is wrong. The first argument should be the ground truth values and not the predicted values, so in your case it should be:</p>\n\n<pre><code>score_DT = r2_score(y_test, y_pred_DT)\n</code></pre>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17936",
            "_score": 15.507138,
            "_source": {
                "title": "I am trying to replace a nan value in my dataset using numpy or imputer class, but am unable to do so!",
                "content": "I am trying to replace a nan value in my dataset using numpy or imputer class, but am unable to do so! <pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n#importing dataset\ntrain = pd.read_csv(\"train.csv\")\ntest = pd.read_csv(\"test.csv\")\ntrain_X = train.iloc[:, :-1].values\ntrain_Y = train.iloc[:,1].values\ntest_X = test.iloc[:, :-1].values\ntest_Y = test.iloc[:,1].values\n\n\n#getting column names in dataset\n\nnp.isnan(train_Y).sum()\nnp.where(np.isnan(train_Y))\nnp.nan_to_num(train_Y)\ntrain_Y.reshape(-1,1)\n#replace null values\nfrom sklearn.preprocessing import Imputer\nimputer = Imputer(missing_values = 0,strategy = \"mean\", axis = 0)\nimputer = imputer.fit(train_Y)\ntrain_Y = imputer.transform(train_Y)\n\n\n#plotting train dataset\nplt.scatter(train['x'],train['y'], color = \"red\")\n\n#madelling the train dataset\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression()\nreg.fit(train_X,train_Y)\n\n# predicting test dataset\ny_pred = reg.predict(test_X)\n</code></pre>\n\n<p>I am not getting any errors but just that the nan value is not getting replaced.\nThanks in advance!</p>\n <machine-learning><linear-regression>",
                "codes": [],
                "question_id:": "57328",
                "question_votes:": "",
                "question_text:": "<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n#importing dataset\ntrain = pd.read_csv(\"train.csv\")\ntest = pd.read_csv(\"test.csv\")\ntrain_X = train.iloc[:, :-1].values\ntrain_Y = train.iloc[:,1].values\ntest_X = test.iloc[:, :-1].values\ntest_Y = test.iloc[:,1].values\n\n\n#getting column names in dataset\n\nnp.isnan(train_Y).sum()\nnp.where(np.isnan(train_Y))\nnp.nan_to_num(train_Y)\ntrain_Y.reshape(-1,1)\n#replace null values\nfrom sklearn.preprocessing import Imputer\nimputer = Imputer(missing_values = 0,strategy = \"mean\", axis = 0)\nimputer = imputer.fit(train_Y)\ntrain_Y = imputer.transform(train_Y)\n\n\n#plotting train dataset\nplt.scatter(train['x'],train['y'], color = \"red\")\n\n#madelling the train dataset\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression()\nreg.fit(train_X,train_Y)\n\n# predicting test dataset\ny_pred = reg.predict(test_X)\n</code></pre>\n\n<p>I am not getting any errors but just that the nan value is not getting replaced.\nThanks in advance!</p>\n",
                "tags": "<machine-learning><linear-regression>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "1159",
            "_score": 15.500707,
            "_source": {
                "title": "Scikit-learn: Getting SGDClassifier to predict as well as a Logistic Regression",
                "content": "Scikit-learn: Getting SGDClassifier to predict as well as a Logistic Regression <p>A way to train a Logistic Regression is by using stochastic gradient descent, which scikit-learn offers an interface to.</p>\n\n<p>What I would like to do is take a scikit-learn's <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\" rel=\"noreferrer\">SGDClassifier</a> and have it score the same as a Logistic Regression <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"noreferrer\">here</a>. However, I must be missing some machine learning enhancements, since my scores are not equivalent.</p>\n\n<p>This is my current code. What am I missing on the SGDClassifier which would have it produce the same results as a Logistic Regression?</p>\n\n<pre><code>from sklearn import datasets\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import SGDClassifier\nimport numpy as np\nimport pandas as pd\nfrom sklearn.cross_validation import KFold\nfrom sklearn.metrics import accuracy_score\n\n# Note that the iris dataset is available in sklearn by default.\n# This data is also conveniently preprocessed.\niris = datasets.load_iris()\nX = iris[\"data\"]\nY = iris[\"target\"]\n\nnumFolds = 10\nkf = KFold(len(X), numFolds, shuffle=True)\n\n# These are \"Class objects\". For each Class, find the AUC through\n# 10 fold cross validation.\nModels = [LogisticRegression, SGDClassifier]\nparams = [{}, {\"loss\": \"log\", \"penalty\": \"l2\"}]\nfor param, Model in zip(params, Models):\n    total = 0\n    for train_indices, test_indices in kf:\n\n        train_X = X[train_indices, :]; train_Y = Y[train_indices]\n        test_X = X[test_indices, :]; test_Y = Y[test_indices]\n\n        reg = Model(**param)\n        reg.fit(train_X, train_Y)\n        predictions = reg.predict(test_X)\n        total += accuracy_score(test_Y, predictions)\n    accuracy = total / numFolds\n    print \"Accuracy score of {0}: {1}\".format(Model.__name__, accuracy)\n</code></pre>\n\n<p>My output:</p>\n\n<pre><code>Accuracy score of LogisticRegression: 0.946666666667\nAccuracy score of SGDClassifier: 0.76\n</code></pre>\n <python><logistic-regression><scikit-learn><gradient-descent><p>SGDClassifier, as the name suggests, uses Stochastic Gradient descent as its optimization algorithm.</p>\n\n<p>If you look at the implementation of LogisiticRegression in Sklearn there are five optimization techniques(solver) provided and by default it is 'LibLinear' that uses Coordinate Descent(CD) to converge.</p>\n\n<p>Other than number of iterations, optimization, type of regularization(penalty) and its magnitude(C) also affect the performance of the algorithm.</p>\n\n<p>If you are running it on Iris data-set tuning all these hyper-parameters may not bring significant change but for complex data set they do play a meaningful role.</p>\n\n<p>For more, you can refer the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">Sklearn Logistic Regression Documentation</a>.</p>\n<p><strong>TL;DR</strong>: You could specify a grid of <em>alpha</em> and <em>n_iter</em>(or <em>max_iter</em>) and use <a href=\"https://github.com/jmcarpenter2/parfit\" rel=\"nofollow noreferrer\">parfit</a> for hyper-optimization on SGDClassifier</p>\n\n<p>My colleague, Vinay Patlolla, wrote an excellent blog post on <a href=\"https://medium.com/@vinnsvinay/how-to-make-sgd-classifier-perform-as-well-as-logistic-regression-using-parfit-cc10bca2d3c4\" rel=\"nofollow noreferrer\">How to make SGD Classifier perform as well as Logistic Regression using parfit</a>.</p>\n\n<p><a href=\"https://github.com/jmcarpenter2/parfit\" rel=\"nofollow noreferrer\">Parfit</a> is a hyper-parameter optimization package that he utilized to find the appropriate combination of parameters which served to optimize SGDClassifier to perform as well as Logistic Regression on his example data set in much less time.</p>\n\n<p>In summary, the two key parameters for SGDClassifier are <em>alpha</em> and <em>n_iter</em>. To quote Vinay directly:</p>\n\n<blockquote>\n  <p>n_iter in sklearn is None by default. We are setting it here to a sufficiently large amount(1000). An alternative parameter to n_iter, which has been recently added, is max_iter. The same advice should apply for max_iter.</p>\n  \n  <p>The alpha hyper-parameter serves a dual purpose. It is both a regularisation parameter and the initial learning rate under the default schedule. This means that, in addition to regularising the Logistic Regression coefficients, the output of the model is dependent on an interaction between alpha and the number of epochs (n_iter) that the fitting routine performs. Specifically, as alpha becomes very small, n_iter must be increased to compensate for the slow learning rate. This is why it is safer (but slower) to specify n_iter sufficiently large, e.g. 1000, when searching over a wide range of alphas.</p>\n</blockquote>\n<p>You should also do a grid search for the \"alpha\" hyperparameter for the SGDClassifier. It is explicitly mentioned in the sklearn documentation and from my experience has a big impact on accuracy. \nSecond hyperparameter you should look at is \"n_iter\" - however I saw a smaller effect with my data.</p>\n<p>The comments about iteration number are spot on. The default <code>SGDClassifier</code> <code>n_iter</code> is <code>5</code> meaning you do <code>5 * num_rows</code> steps in weight space. The <a href=\"http://scikit-learn.org/stable/modules/sgd.html#tips-on-practical-use\" rel=\"noreferrer\">sklearn rule of thumb</a> is ~ 1 million steps for typical data. For your example, just set it to 1000 and it might reach tolerance first. Your accuracy is lower with <code>SGDClassifier</code> because it's hitting iteration limit before tolerance so you are \"early stopping\"</p>\n\n<p>Modifying your code quick and dirty I get:</p>\n\n\n\n<pre><code># Added n_iter here\nparams = [{}, {\"loss\": \"log\", \"penalty\": \"l2\", 'n_iter':1000}]\n\nfor param, Model in zip(params, Models):\n    total = 0\n    for train_indices, test_indices in kf:\n        train_X = X[train_indices, :]; train_Y = Y[train_indices]\n        test_X = X[test_indices, :]; test_Y = Y[test_indices]\n        reg = Model(**param)\n        reg.fit(train_X, train_Y)\n        predictions = reg.predict(test_X)\n        total += accuracy_score(test_Y, predictions)\n\n    accuracy = total / numFolds\n    print \"Accuracy score of {0}: {1}\".format(Model.__name__, accuracy)\n\nAccuracy score of LogisticRegression: 0.96\nAccuracy score of SGDClassifier: 0.96\n</code></pre>\n",
                "codes": [
                    [],
                    [],
                    [],
                    [
                        "# Added n_iter here\nparams = [{}, {\"loss\": \"log\", \"penalty\": \"l2\", 'n_iter':1000}]\n\nfor param, Model in zip(params, Models):\n    total = 0\n    for train_indices, test_indices in kf:\n        train_X = X[train_indices, :]; train_Y = Y[train_indices]\n        test_X = X[test_indices, :]; test_Y = Y[test_indices]\n        reg = Model(**param)\n        reg.fit(train_X, train_Y)\n        predictions = reg.predict(test_X)\n        total += accuracy_score(test_Y, predictions)\n\n    accuracy = total / numFolds\n    print \"Accuracy score of {0}: {1}\".format(Model.__name__, accuracy)\n\nAccuracy score of LogisticRegression: 0.96\nAccuracy score of SGDClassifier: 0.96\n"
                    ]
                ],
                "question_id:": "6676",
                "question_votes:": "24",
                "question_text:": "<p>A way to train a Logistic Regression is by using stochastic gradient descent, which scikit-learn offers an interface to.</p>\n\n<p>What I would like to do is take a scikit-learn's <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\" rel=\"noreferrer\">SGDClassifier</a> and have it score the same as a Logistic Regression <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"noreferrer\">here</a>. However, I must be missing some machine learning enhancements, since my scores are not equivalent.</p>\n\n<p>This is my current code. What am I missing on the SGDClassifier which would have it produce the same results as a Logistic Regression?</p>\n\n<pre><code>from sklearn import datasets\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import SGDClassifier\nimport numpy as np\nimport pandas as pd\nfrom sklearn.cross_validation import KFold\nfrom sklearn.metrics import accuracy_score\n\n# Note that the iris dataset is available in sklearn by default.\n# This data is also conveniently preprocessed.\niris = datasets.load_iris()\nX = iris[\"data\"]\nY = iris[\"target\"]\n\nnumFolds = 10\nkf = KFold(len(X), numFolds, shuffle=True)\n\n# These are \"Class objects\". For each Class, find the AUC through\n# 10 fold cross validation.\nModels = [LogisticRegression, SGDClassifier]\nparams = [{}, {\"loss\": \"log\", \"penalty\": \"l2\"}]\nfor param, Model in zip(params, Models):\n    total = 0\n    for train_indices, test_indices in kf:\n\n        train_X = X[train_indices, :]; train_Y = Y[train_indices]\n        test_X = X[test_indices, :]; test_Y = Y[test_indices]\n\n        reg = Model(**param)\n        reg.fit(train_X, train_Y)\n        predictions = reg.predict(test_X)\n        total += accuracy_score(test_Y, predictions)\n    accuracy = total / numFolds\n    print \"Accuracy score of {0}: {1}\".format(Model.__name__, accuracy)\n</code></pre>\n\n<p>My output:</p>\n\n<pre><code>Accuracy score of LogisticRegression: 0.946666666667\nAccuracy score of SGDClassifier: 0.76\n</code></pre>\n",
                "tags": "<python><logistic-regression><scikit-learn><gradient-descent>",
                "answers": [
                    [
                        "27878",
                        "2",
                        "6676",
                        "",
                        "",
                        "<p>SGDClassifier, as the name suggests, uses Stochastic Gradient descent as its optimization algorithm.</p>\n\n<p>If you look at the implementation of LogisiticRegression in Sklearn there are five optimization techniques(solver) provided and by default it is 'LibLinear' that uses Coordinate Descent(CD) to converge.</p>\n\n<p>Other than number of iterations, optimization, type of regularization(penalty) and its magnitude(C) also affect the performance of the algorithm.</p>\n\n<p>If you are running it on Iris data-set tuning all these hyper-parameters may not bring significant change but for complex data set they do play a meaningful role.</p>\n\n<p>For more, you can refer the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">Sklearn Logistic Regression Documentation</a>.</p>\n",
                        "",
                        "4"
                    ],
                    [
                        "25226",
                        "2",
                        "6676",
                        "",
                        "",
                        "<p><strong>TL;DR</strong>: You could specify a grid of <em>alpha</em> and <em>n_iter</em>(or <em>max_iter</em>) and use <a href=\"https://github.com/jmcarpenter2/parfit\" rel=\"nofollow noreferrer\">parfit</a> for hyper-optimization on SGDClassifier</p>\n\n<p>My colleague, Vinay Patlolla, wrote an excellent blog post on <a href=\"https://medium.com/@vinnsvinay/how-to-make-sgd-classifier-perform-as-well-as-logistic-regression-using-parfit-cc10bca2d3c4\" rel=\"nofollow noreferrer\">How to make SGD Classifier perform as well as Logistic Regression using parfit</a>.</p>\n\n<p><a href=\"https://github.com/jmcarpenter2/parfit\" rel=\"nofollow noreferrer\">Parfit</a> is a hyper-parameter optimization package that he utilized to find the appropriate combination of parameters which served to optimize SGDClassifier to perform as well as Logistic Regression on his example data set in much less time.</p>\n\n<p>In summary, the two key parameters for SGDClassifier are <em>alpha</em> and <em>n_iter</em>. To quote Vinay directly:</p>\n\n<blockquote>\n  <p>n_iter in sklearn is None by default. We are setting it here to a sufficiently large amount(1000). An alternative parameter to n_iter, which has been recently added, is max_iter. The same advice should apply for max_iter.</p>\n  \n  <p>The alpha hyper-parameter serves a dual purpose. It is both a regularisation parameter and the initial learning rate under the default schedule. This means that, in addition to regularising the Logistic Regression coefficients, the output of the model is dependent on an interaction between alpha and the number of epochs (n_iter) that the fitting routine performs. Specifically, as alpha becomes very small, n_iter must be increased to compensate for the slow learning rate. This is why it is safer (but slower) to specify n_iter sufficiently large, e.g. 1000, when searching over a wide range of alphas.</p>\n</blockquote>\n",
                        "",
                        "1"
                    ],
                    [
                        "9781",
                        "2",
                        "6676",
                        "",
                        "",
                        "<p>You should also do a grid search for the \"alpha\" hyperparameter for the SGDClassifier. It is explicitly mentioned in the sklearn documentation and from my experience has a big impact on accuracy. \nSecond hyperparameter you should look at is \"n_iter\" - however I saw a smaller effect with my data.</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "9794",
                        "2",
                        "6676",
                        "",
                        "",
                        "<p>The comments about iteration number are spot on. The default <code>SGDClassifier</code> <code>n_iter</code> is <code>5</code> meaning you do <code>5 * num_rows</code> steps in weight space. The <a href=\"http://scikit-learn.org/stable/modules/sgd.html#tips-on-practical-use\" rel=\"noreferrer\">sklearn rule of thumb</a> is ~ 1 million steps for typical data. For your example, just set it to 1000 and it might reach tolerance first. Your accuracy is lower with <code>SGDClassifier</code> because it's hitting iteration limit before tolerance so you are \"early stopping\"</p>\n\n<p>Modifying your code quick and dirty I get:</p>\n\n\n\n<pre><code># Added n_iter here\nparams = [{}, {\"loss\": \"log\", \"penalty\": \"l2\", 'n_iter':1000}]\n\nfor param, Model in zip(params, Models):\n    total = 0\n    for train_indices, test_indices in kf:\n        train_X = X[train_indices, :]; train_Y = Y[train_indices]\n        test_X = X[test_indices, :]; test_Y = Y[test_indices]\n        reg = Model(**param)\n        reg.fit(train_X, train_Y)\n        predictions = reg.predict(test_X)\n        total += accuracy_score(test_Y, predictions)\n\n    accuracy = total / numFolds\n    print \"Accuracy score of {0}: {1}\".format(Model.__name__, accuracy)\n\nAccuracy score of LogisticRegression: 0.96\nAccuracy score of SGDClassifier: 0.96\n</code></pre>\n",
                        "",
                        "24"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10173",
            "_score": 15.4720545,
            "_source": {
                "title": "Other types of regression models in sklearn",
                "content": "Other types of regression models in sklearn <p>I want to make full and interaction model in python using sklearn. Is there any way to make such models. Because sklearn only provides library for Linear, polynomial regressions and not for full and interaction models</p>\n <regression>",
                "codes": [],
                "question_id:": "36796",
                "question_votes:": "2",
                "question_text:": "<p>I want to make full and interaction model in python using sklearn. Is there any way to make such models. Because sklearn only provides library for Linear, polynomial regressions and not for full and interaction models</p>\n",
                "tags": "<regression>",
                "answers": []
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6564",
            "_score": 15.4601,
            "_source": {
                "title": "Why Liblinear performs drastically better than libsvm linear kernel?",
                "content": "Why Liblinear performs drastically better than libsvm linear kernel? <p>l have a dataset of dim=(200,2000) 200 examples and 2000 features. l have 10 classes.</p>\n\n<p>l used sklearn  for both cases :</p>\n\n<pre><code>svm.svc(kernel=linear)\nLinearSVC()\n</code></pre>\n\n<p>However LinearSVC() performs drastically better than svm with linear kernel. 60% against 23%.\nl'm supposed to get the same or comparable results since they are fed with same parameters and data.</p>\n\n<p>What's wrong ?</p>\n\n<p>Thank you</p>\n <machine-learning><scikit-learn><svm><libsvm><p>Here is just a guess, but according to me, the linearSVC might perfoms better than SVM with linear kernel because of regularization.</p>\n\n<p>Because linearSVC is based on liblinear rather than libsvm, it has more flexibility and it gives you the possibility to use regularization with your SVM (default is L2-Ridge regularization).</p>\n\n<p>Because you have more features than observations, it exists multiple solutions to your classification model. Some of them are more \"robust\" than other ones. L2 regularization will help you reduce the ampltitude of your model coefficients and maybe lead to a more stable solution.</p>\n\n<p>More on LinearSVC in the documentation : </p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html</a></p>\n\n<p>More on Ridge regression benefits when working with a lot of features (and so multicollinearity) : </p>\n\n<p><a href=\"https://stats.stackexchange.com/questions/118712/why-does-ridge-estimate-become-better-than-ols-by-adding-a-constant-to-the-diago\">https://stats.stackexchange.com/questions/118712/why-does-ridge-estimate-become-better-than-ols-by-adding-a-constant-to-the-diago</a></p>\n",
                "codes": [
                    []
                ],
                "question_id:": "25420",
                "question_votes:": "2",
                "question_text:": "<p>l have a dataset of dim=(200,2000) 200 examples and 2000 features. l have 10 classes.</p>\n\n<p>l used sklearn  for both cases :</p>\n\n<pre><code>svm.svc(kernel=linear)\nLinearSVC()\n</code></pre>\n\n<p>However LinearSVC() performs drastically better than svm with linear kernel. 60% against 23%.\nl'm supposed to get the same or comparable results since they are fed with same parameters and data.</p>\n\n<p>What's wrong ?</p>\n\n<p>Thank you</p>\n",
                "tags": "<machine-learning><scikit-learn><svm><libsvm>",
                "answers": [
                    [
                        "25452",
                        "2",
                        "25420",
                        "",
                        "",
                        "<p>Here is just a guess, but according to me, the linearSVC might perfoms better than SVM with linear kernel because of regularization.</p>\n\n<p>Because linearSVC is based on liblinear rather than libsvm, it has more flexibility and it gives you the possibility to use regularization with your SVM (default is L2-Ridge regularization).</p>\n\n<p>Because you have more features than observations, it exists multiple solutions to your classification model. Some of them are more \"robust\" than other ones. L2 regularization will help you reduce the ampltitude of your model coefficients and maybe lead to a more stable solution.</p>\n\n<p>More on LinearSVC in the documentation : </p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html</a></p>\n\n<p>More on Ridge regression benefits when working with a lot of features (and so multicollinearity) : </p>\n\n<p><a href=\"https://stats.stackexchange.com/questions/118712/why-does-ridge-estimate-become-better-than-ols-by-adding-a-constant-to-the-diago\">https://stats.stackexchange.com/questions/118712/why-does-ridge-estimate-become-better-than-ols-by-adding-a-constant-to-the-diago</a></p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11242",
            "_score": 15.336309,
            "_source": {
                "title": "Linear Regression Coefficient Calculation",
                "content": "Linear Regression Coefficient Calculation <pre><code>class LR:\n\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n        self.xmean = np.mean(x)\n        self.ymean = np.mean(y)\n        self.x_xmean = self.x - self.xmean\n        self.y_ymean = self.y - self.ymean\n        self.covariance = sum(self.x_xmean * self.y_ymean)\n        self.variance = sum(self.x_xmean * self.x_xmean)\n\n    def getYhat(self, input_x):\n        input_x = np.array(input_x)\n        return self.intercept + self.slope * input_x    \n\n    def getCoefficients(self):\n        self.slope = self.covariance/self.variance\n        self.intercept = self.ymean - (self.xmean * self.slope)\n        return self.intercept, self.slope\n</code></pre>\n\n<p>I am using the above class to calculate intercept and slope for a Simple Linear Regression.  However, I would like to tweak it to make it work for Multiple Linear Regression as well, but WITHOUT using matrix formula <span class=\"math-container\">$(XX^T)^{-1}X^TY$</span>.</p>\n\n<p>Please suggest.</p>\n <linear-regression><p>While I am not sure if you need the calculations done within the class specifically, there is a relatively more simple way to extract the intercept and slope coefficients using the <strong>linear_model</strong> from sklearn and pandas if it is of use to you.</p>\n\n<p>Suppose we have the following variables:</p>\n\n<pre><code>y: [-0.006,-0.001,0.015,0.017,-0.0019,-0.005]\nx1: [-0.018,-0.008,0.011,0.017,-0.008,-0.002]\nx2: [-0.04,-0.003,0.012,0.011,-0.004,-0.009]\nx3: [-0.06,-0.007,0.3,0.09,-0.005,-0.006]\n</code></pre>\n\n<p>Now, let's run a linear regression using sklearn:</p>\n\n<pre><code>from pandas import DataFrame\nfrom sklearn import linear_model\nimport statsmodels.api as sm\n\ndataset = {'y': [-0.006,-0.001,0.015,0.017,-0.0019,-0.005],\n                'x1': [-0.018,-0.008,0.011,0.017,-0.008,-0.002],\n                'x2': [-0.04,-0.003,0.012,0.011,-0.004,-0.009],\n                'x3': [-0.06,-0.007,0.3,0.09,-0.005,-0.006]       \n                }\n\ndf = DataFrame(dataset,columns=['y','x1','x2','x3'])\n\n\nX = df[['x1','x2','x3']]\nY = df['y']\n\n# Regression Model\nregr = linear_model.LinearRegression()\nregr.fit(X, Y)\n\nprint('Intercept: \\n', regr.intercept_)\nprint('Coefficients: \\n', regr.coef_)\n</code></pre>\n\n<p>Once we do this, our intercept and slope coefficients are then printed:</p>\n\n<pre><code>&gt;&gt;&gt; print('Intercept: \\n', regr.intercept_)\nIntercept: \n 0.0022491408670789535\n&gt;&gt;&gt; print('Coefficients: \\n', regr.coef_)\nCoefficients: \n [ 0.62742415 -0.06618899  0.02384715]\n</code></pre>\n\n<p>Hope you find this of use if you are simply looking to extract the intercept and slope coefficients.</p>\n<p>What I have found with this kind of exercise is that it is very beneficial to code it directly in numpy at least once and really try to understand what is going on.</p>\n\n<p>I solved that (for my own learning) in a <a href=\"https://www.kaggle.com/moriano/linear-regression-101\" rel=\"nofollow noreferrer\">kaggle kernel</a>. </p>\n\n<p>The code that I used is </p>\n\n<pre><code>def predict(my_X, my_W, my_B):\n    return np.dot(my_W, my_X) + my_B\n\n\ndef error(y, y_hat):\n    diff = sum(y - y_hat)\n    squared_diff = diff ** 2\n    error = (1/n) * squared_diff\n    return error\n\ndef derivative(X, w, b, y):\n    n = len(y)\n    y_hat = predict(X, w, b)\n    diff_sum = sum(y-y_hat)\n\n    w_derivative = (2/n) * sum((y_hat - y) * X)\n    b_derivative = (2/n) * sum(y_hat-y)\n\n    return w_derivative, b_derivative\n\n\nlr = 0.01\nfor iteration in range(0, 100):\n    y_hat = predict(X, w, b)\n\n    if iteration % 10 == 0:\n        print(\"Iteration \", iteration, \"Error\", error(y, y_hat))\n\n    W_derivative, b_derivative = derivative(X, w, b, y)\n\n    w = w - (lr * W_derivative)\n    b = b - (lr * b_derivative)\n</code></pre>\n\n<p>Then you can inspect the <code>W</code> and <code>b</code> variables and see for yourself what is going on :)</p>\n",
                "codes": [
                    [
                        "y: [-0.006,-0.001,0.015,0.017,-0.0019,-0.005]\nx1: [-0.018,-0.008,0.011,0.017,-0.008,-0.002]\nx2: [-0.04,-0.003,0.012,0.011,-0.004,-0.009]\nx3: [-0.06,-0.007,0.3,0.09,-0.005,-0.006]\n",
                        "from pandas import DataFrame\nfrom sklearn import linear_model\nimport statsmodels.api as sm\n\ndataset = {'y': [-0.006,-0.001,0.015,0.017,-0.0019,-0.005],\n                'x1': [-0.018,-0.008,0.011,0.017,-0.008,-0.002],\n                'x2': [-0.04,-0.003,0.012,0.011,-0.004,-0.009],\n                'x3': [-0.06,-0.007,0.3,0.09,-0.005,-0.006]       \n                }\n\ndf = DataFrame(dataset,columns=['y','x1','x2','x3'])\n\n\nX = df[['x1','x2','x3']]\nY = df['y']\n\n# Regression Model\nregr = linear_model.LinearRegression()\nregr.fit(X, Y)\n\nprint('Intercept: \\n', regr.intercept_)\nprint('Coefficients: \\n', regr.coef_)\n",
                        ">>> print('Intercept: \\n', regr.intercept_)\nIntercept: \n 0.0022491408670789535\n>>> print('Coefficients: \\n', regr.coef_)\nCoefficients: \n [ 0.62742415 -0.06618899  0.02384715]\n"
                    ],
                    [
                        "def predict(my_X, my_W, my_B):\n    return np.dot(my_W, my_X) + my_B\n\n\ndef error(y, y_hat):\n    diff = sum(y - y_hat)\n    squared_diff = diff ** 2\n    error = (1/n) * squared_diff\n    return error\n\ndef derivative(X, w, b, y):\n    n = len(y)\n    y_hat = predict(X, w, b)\n    diff_sum = sum(y-y_hat)\n\n    w_derivative = (2/n) * sum((y_hat - y) * X)\n    b_derivative = (2/n) * sum(y_hat-y)\n\n    return w_derivative, b_derivative\n\n\nlr = 0.01\nfor iteration in range(0, 100):\n    y_hat = predict(X, w, b)\n\n    if iteration % 10 == 0:\n        print(\"Iteration \", iteration, \"Error\", error(y, y_hat))\n\n    W_derivative, b_derivative = derivative(X, w, b, y)\n\n    w = w - (lr * W_derivative)\n    b = b - (lr * b_derivative)\n"
                    ]
                ],
                "question_id:": "39658",
                "question_votes:": "",
                "question_text:": "<pre><code>class LR:\n\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n        self.xmean = np.mean(x)\n        self.ymean = np.mean(y)\n        self.x_xmean = self.x - self.xmean\n        self.y_ymean = self.y - self.ymean\n        self.covariance = sum(self.x_xmean * self.y_ymean)\n        self.variance = sum(self.x_xmean * self.x_xmean)\n\n    def getYhat(self, input_x):\n        input_x = np.array(input_x)\n        return self.intercept + self.slope * input_x    \n\n    def getCoefficients(self):\n        self.slope = self.covariance/self.variance\n        self.intercept = self.ymean - (self.xmean * self.slope)\n        return self.intercept, self.slope\n</code></pre>\n\n<p>I am using the above class to calculate intercept and slope for a Simple Linear Regression.  However, I would like to tweak it to make it work for Multiple Linear Regression as well, but WITHOUT using matrix formula <span class=\"math-container\">$(XX^T)^{-1}X^TY$</span>.</p>\n\n<p>Please suggest.</p>\n",
                "tags": "<linear-regression>",
                "answers": [
                    [
                        "39662",
                        "2",
                        "39658",
                        "",
                        "",
                        "<p>While I am not sure if you need the calculations done within the class specifically, there is a relatively more simple way to extract the intercept and slope coefficients using the <strong>linear_model</strong> from sklearn and pandas if it is of use to you.</p>\n\n<p>Suppose we have the following variables:</p>\n\n<pre><code>y: [-0.006,-0.001,0.015,0.017,-0.0019,-0.005]\nx1: [-0.018,-0.008,0.011,0.017,-0.008,-0.002]\nx2: [-0.04,-0.003,0.012,0.011,-0.004,-0.009]\nx3: [-0.06,-0.007,0.3,0.09,-0.005,-0.006]\n</code></pre>\n\n<p>Now, let's run a linear regression using sklearn:</p>\n\n<pre><code>from pandas import DataFrame\nfrom sklearn import linear_model\nimport statsmodels.api as sm\n\ndataset = {'y': [-0.006,-0.001,0.015,0.017,-0.0019,-0.005],\n                'x1': [-0.018,-0.008,0.011,0.017,-0.008,-0.002],\n                'x2': [-0.04,-0.003,0.012,0.011,-0.004,-0.009],\n                'x3': [-0.06,-0.007,0.3,0.09,-0.005,-0.006]       \n                }\n\ndf = DataFrame(dataset,columns=['y','x1','x2','x3'])\n\n\nX = df[['x1','x2','x3']]\nY = df['y']\n\n# Regression Model\nregr = linear_model.LinearRegression()\nregr.fit(X, Y)\n\nprint('Intercept: \\n', regr.intercept_)\nprint('Coefficients: \\n', regr.coef_)\n</code></pre>\n\n<p>Once we do this, our intercept and slope coefficients are then printed:</p>\n\n<pre><code>&gt;&gt;&gt; print('Intercept: \\n', regr.intercept_)\nIntercept: \n 0.0022491408670789535\n&gt;&gt;&gt; print('Coefficients: \\n', regr.coef_)\nCoefficients: \n [ 0.62742415 -0.06618899  0.02384715]\n</code></pre>\n\n<p>Hope you find this of use if you are simply looking to extract the intercept and slope coefficients.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "42586",
                        "2",
                        "39658",
                        "",
                        "",
                        "<p>What I have found with this kind of exercise is that it is very beneficial to code it directly in numpy at least once and really try to understand what is going on.</p>\n\n<p>I solved that (for my own learning) in a <a href=\"https://www.kaggle.com/moriano/linear-regression-101\" rel=\"nofollow noreferrer\">kaggle kernel</a>. </p>\n\n<p>The code that I used is </p>\n\n<pre><code>def predict(my_X, my_W, my_B):\n    return np.dot(my_W, my_X) + my_B\n\n\ndef error(y, y_hat):\n    diff = sum(y - y_hat)\n    squared_diff = diff ** 2\n    error = (1/n) * squared_diff\n    return error\n\ndef derivative(X, w, b, y):\n    n = len(y)\n    y_hat = predict(X, w, b)\n    diff_sum = sum(y-y_hat)\n\n    w_derivative = (2/n) * sum((y_hat - y) * X)\n    b_derivative = (2/n) * sum(y_hat-y)\n\n    return w_derivative, b_derivative\n\n\nlr = 0.01\nfor iteration in range(0, 100):\n    y_hat = predict(X, w, b)\n\n    if iteration % 10 == 0:\n        print(\"Iteration \", iteration, \"Error\", error(y, y_hat))\n\n    W_derivative, b_derivative = derivative(X, w, b, y)\n\n    w = w - (lr * W_derivative)\n    b = b - (lr * b_derivative)\n</code></pre>\n\n<p>Then you can inspect the <code>W</code> and <code>b</code> variables and see for yourself what is going on :)</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14032",
            "_score": 15.261696,
            "_source": {
                "title": "Linear regression load model doesn't predict as expected",
                "content": "Linear regression load model doesn't predict as expected <p>I have trained a linear regression model, with sklearn, for a 5 star rating and it's good enough. I have used Doc2vec to create my vectors, and saved that model. Then I save the linear regression model to another file. What I'm trying to do is load the Doc2vec model and linear regression model and try to predict a new review.</p>\n\n<p>There is something very strange about this prediction: whatever the input it always predicts around 2.1-3.0.</p>\n\n<p>Thing is, I have a suggestion that it predicts around the average of 5 (which is 2.5 +/-) but this is not the case. I have printed when training the model the prediction value and the actual value of the test data and they range normally 1-5. So my idea is, that there is something wrong with the loading part of the code (or even the reshape of the new vector). This is my load code:</p>\n\n<pre><code>from gensim.models.doc2vec import Doc2Vec, TaggedDocument\nfrom bs4 import BeautifulSoup\nfrom joblib import dump, load\nimport pickle\nimport re\n\nmodel = Doc2Vec.load('../vectors/750000/doc2vec_model')\n\ndef cleanText(text):\n    text = BeautifulSoup(text, \"lxml\").text\n    text = re.sub(r'\\|\\|\\|', r' ', text) \n    text = re.sub(r'http\\S+', r'&lt;URL&gt;', text)\n    text = re.sub(r'[^\\w\\s]','',text)\n    text = text.lower()\n    text = text.replace('x', '')\n    return text\n\nreview = cleanText(\"Horrible movie! I don't recommend it to anyone!\").split()\nvector = model.infer_vector(review)\n\npkl_filename = \"../vectors/750000/linear_regression_model.joblib\"\nwith open(pkl_filename, 'rb') as file:  \n    linreg = pickle.load(file)\n\nreview_vector = vector.reshape(1,-1)\npredict_star = linreg.predict(review_vector)\nprint(predict_star)\n</code></pre>\n <machine-learning><python><scikit-learn><linear-regression><word-embeddings>",
                "codes": [],
                "question_id:": "47478",
                "question_votes:": "1",
                "question_text:": "<p>I have trained a linear regression model, with sklearn, for a 5 star rating and it's good enough. I have used Doc2vec to create my vectors, and saved that model. Then I save the linear regression model to another file. What I'm trying to do is load the Doc2vec model and linear regression model and try to predict a new review.</p>\n\n<p>There is something very strange about this prediction: whatever the input it always predicts around 2.1-3.0.</p>\n\n<p>Thing is, I have a suggestion that it predicts around the average of 5 (which is 2.5 +/-) but this is not the case. I have printed when training the model the prediction value and the actual value of the test data and they range normally 1-5. So my idea is, that there is something wrong with the loading part of the code (or even the reshape of the new vector). This is my load code:</p>\n\n<pre><code>from gensim.models.doc2vec import Doc2Vec, TaggedDocument\nfrom bs4 import BeautifulSoup\nfrom joblib import dump, load\nimport pickle\nimport re\n\nmodel = Doc2Vec.load('../vectors/750000/doc2vec_model')\n\ndef cleanText(text):\n    text = BeautifulSoup(text, \"lxml\").text\n    text = re.sub(r'\\|\\|\\|', r' ', text) \n    text = re.sub(r'http\\S+', r'&lt;URL&gt;', text)\n    text = re.sub(r'[^\\w\\s]','',text)\n    text = text.lower()\n    text = text.replace('x', '')\n    return text\n\nreview = cleanText(\"Horrible movie! I don't recommend it to anyone!\").split()\nvector = model.infer_vector(review)\n\npkl_filename = \"../vectors/750000/linear_regression_model.joblib\"\nwith open(pkl_filename, 'rb') as file:  \n    linreg = pickle.load(file)\n\nreview_vector = vector.reshape(1,-1)\npredict_star = linreg.predict(review_vector)\nprint(predict_star)\n</code></pre>\n",
                "tags": "<machine-learning><python><scikit-learn><linear-regression><word-embeddings>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13477",
            "_score": 15.259231,
            "_source": {
                "title": "Continuous variable not supported in confusion matrix",
                "content": "Continuous variable not supported in confusion matrix <p>I am using linear regression algorithm for a data set. And trying to compute confusion matrix between y_pred and y_test. I am getting <code>\"ValueError : continuous is not supported\"</code> error. </p>\n\n<p>I have included the code below. Help to solve this problem.</p>\n\n<pre><code>x = data_set.iloc[:, :-1].values\ny = data_set.iloc[:, 7].values\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0) \n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import confusion_matrix\n\nregression = LinearRegression()\nregression.fit(x_train, y_train)\n\ny_pred = regression.predict(x_test)\n\ncm = confusion_matrix(y_test, y_pred)\n</code></pre>\n <python><scikit-learn><regression><confusion-matrix><p>The confusion matrix is used to tell you how many predictions were <strong>classified</strong> correctly or incorrectly. You are looking at a regression model, which gives you a continous output (not classification).</p>\n\n<p>So when you run <code>confusion_matrix(y_test, y_pred)</code> it will throw the <code>ValueError</code> because it expected class predictions, not floating point numbers.</p>\n\n<p>Are you trying to predict classes, or really just a number output? If not, then you should not be using the confusion matrix.</p>\n\n<hr>\n\n<p>If you want to predict e.g. <strong>1</strong> or <strong>0</strong> for your <code>y</code> values, then you would have to convert your linear regression predictions to either of these classes. You could say any value in <code>y_pred</code> above <code>0.7</code> is a <code>1</code> and anything below is <code>0</code>.</p>\n\n<pre><code>cutoff = 0.7                              # decide on a cutoff limit\ny_pred_classes = np.zeros_like(y_pred)    # initialise a matrix full with zeros\ny_pred_classes[y_pred &gt; cutoff] = 1       # add a 1 if the cutoff was breached\n</code></pre>\n\n<p>you have to do the same for the actual values too:</p>\n\n<pre><code>y_test_classes = np.zeros_like(y_pred)\ny_test_classes[y_test &gt; cutoff] = 1\n</code></pre>\n\n<p>Now run the confusion matrix as before:</p>\n\n<pre><code>confusion_matrix(y_test_classes, y_pred_classes)\n</code></pre>\n\n<p>which gives output:</p>\n\n<pre><code>array([[2, 3],\n       [0, 0]])\n</code></pre>\n",
                "codes": [
                    [
                        "cutoff = 0.7                              # decide on a cutoff limit\ny_pred_classes = np.zeros_like(y_pred)    # initialise a matrix full with zeros\ny_pred_classes[y_pred > cutoff] = 1       # add a 1 if the cutoff was breached\n",
                        "y_test_classes = np.zeros_like(y_pred)\ny_test_classes[y_test > cutoff] = 1\n",
                        "confusion_matrix(y_test_classes, y_pred_classes)\n",
                        "array([[2, 3],\n       [0, 0]])\n"
                    ]
                ],
                "question_id:": "46019",
                "question_votes:": "1",
                "question_text:": "<p>I am using linear regression algorithm for a data set. And trying to compute confusion matrix between y_pred and y_test. I am getting <code>\"ValueError : continuous is not supported\"</code> error. </p>\n\n<p>I have included the code below. Help to solve this problem.</p>\n\n<pre><code>x = data_set.iloc[:, :-1].values\ny = data_set.iloc[:, 7].values\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0) \n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import confusion_matrix\n\nregression = LinearRegression()\nregression.fit(x_train, y_train)\n\ny_pred = regression.predict(x_test)\n\ncm = confusion_matrix(y_test, y_pred)\n</code></pre>\n",
                "tags": "<python><scikit-learn><regression><confusion-matrix>",
                "answers": [
                    [
                        "46021",
                        "2",
                        "46019",
                        "",
                        "",
                        "<p>The confusion matrix is used to tell you how many predictions were <strong>classified</strong> correctly or incorrectly. You are looking at a regression model, which gives you a continous output (not classification).</p>\n\n<p>So when you run <code>confusion_matrix(y_test, y_pred)</code> it will throw the <code>ValueError</code> because it expected class predictions, not floating point numbers.</p>\n\n<p>Are you trying to predict classes, or really just a number output? If not, then you should not be using the confusion matrix.</p>\n\n<hr>\n\n<p>If you want to predict e.g. <strong>1</strong> or <strong>0</strong> for your <code>y</code> values, then you would have to convert your linear regression predictions to either of these classes. You could say any value in <code>y_pred</code> above <code>0.7</code> is a <code>1</code> and anything below is <code>0</code>.</p>\n\n<pre><code>cutoff = 0.7                              # decide on a cutoff limit\ny_pred_classes = np.zeros_like(y_pred)    # initialise a matrix full with zeros\ny_pred_classes[y_pred &gt; cutoff] = 1       # add a 1 if the cutoff was breached\n</code></pre>\n\n<p>you have to do the same for the actual values too:</p>\n\n<pre><code>y_test_classes = np.zeros_like(y_pred)\ny_test_classes[y_test &gt; cutoff] = 1\n</code></pre>\n\n<p>Now run the confusion matrix as before:</p>\n\n<pre><code>confusion_matrix(y_test_classes, y_pred_classes)\n</code></pre>\n\n<p>which gives output:</p>\n\n<pre><code>array([[2, 3],\n       [0, 0]])\n</code></pre>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16366",
            "_score": 15.244677,
            "_source": {
                "title": "Accuracy of machine learning models",
                "content": "Accuracy of machine learning models <p>I started learning ML and I have some problems with evaluating / finding the accuracy of regression and classification models.\nTill now I used <code>.score()</code> in both cases but people told me that Its not the accuracy.\nThen I tried to use this:</p>\n\n<pre><code>from sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\n\nvar_train, var_test, res_train, res_test = train_test_split(variables, results, test_size = 0.2, random_state = 4)\n\nregression = linear_model.LinearRegression()\nregression.fit(var_train, res_train)\n\ninput_values = [14, 2]\n\nprediction = regression.predict([input_values])\naccuracy_regression = mean_squared_error(var_test, prediction)\n</code></pre>\n\n<p>But I always get this error:</p>\n\n<pre><code>ValueError: Found input variables with inconsistent numbers of samples: [2, 1]\n</code></pre>\n\n<p>I have looked all over the udemy and youtube, and a lot of people are calculating accuracy like <code>.score()</code>. Then I looked all over <code>scikit-learn</code> website and  stackoverflow and I saw the other solution with metrics but I keep getting the same error.\nWhat am I doing wrong?</p>\n\n<p>More about the problem:</p>\n\n<p><a href=\"https://stackoverflow.com/questions/56622349/accuracy-of-multivariate-classification-and-regression-models-with-scikit-learn\">https://stackoverflow.com/questions/56622349/accuracy-of-multivariate-classification-and-regression-models-with-scikit-learn</a></p>\n <machine-learning><python><scikit-learn><p>Linear regressions are incompatible with accuracy measures. Accuracy is a metric for <strong><em>classification tasks only</em></strong> - it represents the percentage of observations that your model was able to classify correctly.</p>\n\n<p>In case of Linear regression instead, you are predicting a <strong>continuous output</strong>. No accuracy can be computed on this. You need other metrics, such as MSE (the one you used), that can be interpreted as \"<em>how distant you are from perfect prediction</em>\". Sometimes statisticians use the <strong>R-squared</strong> metric, which represents the percentage of the dependent variable's variance that your model is able to explain (i.e.: when all your data are on a straight line, the R-squared is = 1).</p>\n\n<p>The fact that you are getting an error at <code>mean_squared_error()</code> is suggesting me that your input objects (<code>input_values</code> and <code>var_test</code>) must have either: different shapes, and/or contain missing values. In particular, you are only feeding two observations as <code>input_values</code>: <code>[14, 2]</code>. Is <code>var_test</code> a vector of length 2 ?</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "53931",
                "question_votes:": "1",
                "question_text:": "<p>I started learning ML and I have some problems with evaluating / finding the accuracy of regression and classification models.\nTill now I used <code>.score()</code> in both cases but people told me that Its not the accuracy.\nThen I tried to use this:</p>\n\n<pre><code>from sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\n\nvar_train, var_test, res_train, res_test = train_test_split(variables, results, test_size = 0.2, random_state = 4)\n\nregression = linear_model.LinearRegression()\nregression.fit(var_train, res_train)\n\ninput_values = [14, 2]\n\nprediction = regression.predict([input_values])\naccuracy_regression = mean_squared_error(var_test, prediction)\n</code></pre>\n\n<p>But I always get this error:</p>\n\n<pre><code>ValueError: Found input variables with inconsistent numbers of samples: [2, 1]\n</code></pre>\n\n<p>I have looked all over the udemy and youtube, and a lot of people are calculating accuracy like <code>.score()</code>. Then I looked all over <code>scikit-learn</code> website and  stackoverflow and I saw the other solution with metrics but I keep getting the same error.\nWhat am I doing wrong?</p>\n\n<p>More about the problem:</p>\n\n<p><a href=\"https://stackoverflow.com/questions/56622349/accuracy-of-multivariate-classification-and-regression-models-with-scikit-learn\">https://stackoverflow.com/questions/56622349/accuracy-of-multivariate-classification-and-regression-models-with-scikit-learn</a></p>\n",
                "tags": "<machine-learning><python><scikit-learn>",
                "answers": [
                    [
                        "53939",
                        "2",
                        "53931",
                        "",
                        "",
                        "<p>Linear regressions are incompatible with accuracy measures. Accuracy is a metric for <strong><em>classification tasks only</em></strong> - it represents the percentage of observations that your model was able to classify correctly.</p>\n\n<p>In case of Linear regression instead, you are predicting a <strong>continuous output</strong>. No accuracy can be computed on this. You need other metrics, such as MSE (the one you used), that can be interpreted as \"<em>how distant you are from perfect prediction</em>\". Sometimes statisticians use the <strong>R-squared</strong> metric, which represents the percentage of the dependent variable's variance that your model is able to explain (i.e.: when all your data are on a straight line, the R-squared is = 1).</p>\n\n<p>The fact that you are getting an error at <code>mean_squared_error()</code> is suggesting me that your input objects (<code>input_values</code> and <code>var_test</code>) must have either: different shapes, and/or contain missing values. In particular, you are only feeding two observations as <code>input_values</code>: <code>[14, 2]</code>. Is <code>var_test</code> a vector of length 2 ?</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17451",
            "_score": 15.216873,
            "_source": {
                "title": "How to Interpret output Coefficients with python sklearn Support Vector Regression?",
                "content": "How to Interpret output Coefficients with python sklearn Support Vector Regression? <p>I'm looking to interpret the output coefficients from my SVR model. For my case, the <code>rbf</code> kernel has the highest in-sample and out-of-sample performance. However, when I try to get the regression coefficients by running <code>regressor_svr.coef_</code>, I get an Error: <code>AttributeError: coef_ is only available when using a linear kernel</code>. </p>\n\n<p>From the error message, it seems quite obvious that I can only obtain the coefficients if I use a <code>linear</code> kernel. </p>\n\n<p>With that said, is there any way for me to interpret the SVR regression results from the <code>rbf</code> kernel or must I use the <code>linear</code> kernel?</p>\n <machine-learning><regression><svm><svr>",
                "codes": [],
                "question_id:": "56246",
                "question_votes:": "1",
                "question_text:": "<p>I'm looking to interpret the output coefficients from my SVR model. For my case, the <code>rbf</code> kernel has the highest in-sample and out-of-sample performance. However, when I try to get the regression coefficients by running <code>regressor_svr.coef_</code>, I get an Error: <code>AttributeError: coef_ is only available when using a linear kernel</code>. </p>\n\n<p>From the error message, it seems quite obvious that I can only obtain the coefficients if I use a <code>linear</code> kernel. </p>\n\n<p>With that said, is there any way for me to interpret the SVR regression results from the <code>rbf</code> kernel or must I use the <code>linear</code> kernel?</p>\n",
                "tags": "<machine-learning><regression><svm><svr>",
                "answers": []
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11810",
            "_score": 15.166582,
            "_source": {
                "title": "Single machine learning algorithm for multiple classes of data : One hot encoder",
                "content": "Single machine learning algorithm for multiple classes of data : One hot encoder <p>I have data of the following kind:</p>\n\n<pre><code>   x1  x2  y\n0  0   1  1\n1  0   2  2\n2  0   3  3\n3  0   4  4\n4  1   1  4\n5  1   2  8\n6  1   3  12\n7  1   4  16\n</code></pre>\n\n<p>Is it possible to construct a single machine learning algorithm in python/scikit-learn by defining column <code>x1</code> in such a way that a simple linear regression should give <code>predict(x1=0, x2=5) = 5</code> and <code>predict(x1=1, x2=5) = 20</code>. My actual problem has multiple values of <code>x1</code>. </p>\n\n<p>To illustrate the problem better: I have the following code with one hot encoder and it doesn't seem to give the accuracy of training the data separately. </p>\n\n<pre><code>import pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\n# Dataframe with x1 = 0 and linear regression gives a slope of 1 as expected\n\ndf = pd.DataFrame(data=[{'x1': 0, 'x2': 1, 'y': 1},\n                        {'x1': 0, 'x2': 2, 'y': 2},\n                        {'x1': 0, 'x2': 3, 'y': 3},\n                        {'x1': 0, 'x2': 4, 'y': 4}\n                        ],\n                  columns=['x1', 'x2', 'y'])\n\nX = df[['x1', 'x2']]\ny = df['y']\nreg = LinearRegression().fit(X, y)\nprint(reg.predict(np.array([[0, 5]]))) # Output is 5 as expected\n\n# Dataframe with x1 = 1 and linear regression gives a slope of 5 as expected\n\ndf = pd.DataFrame(data=[{'x1': 1, 'x2': 1, 'y': 4},\n                        {'x1': 1, 'x2': 2, 'y': 8},\n                        {'x1': 1, 'x2': 3, 'y': 12},\n                        {'x1': 1, 'x2': 4, 'y': 16}\n                        ],\n                  columns=['x1', 'x2', 'y'])\n\nX = df[['x1', 'x2']]\ny = df['y']\nreg = LinearRegression().fit(X, y)\nprint(reg.predict(np.array([[1, 5]]))) # Output is 20 as expected \n\n# Combine the two data frames x1 = 0 and x1 = 1 \n\ndf = pd.DataFrame(data=[{'x1': 0, 'x2': 1, 'y': 1},\n                        {'x1': 0, 'x2': 2, 'y': 2},\n                        {'x1': 0, 'x2': 3, 'y': 3},\n                        {'x1': 0, 'x2': 4, 'y': 4},\n                        {'x1': 1, 'x2': 1, 'y': 4},\n                        {'x1': 1, 'x2': 2, 'y': 8},\n                        {'x1': 1, 'x2': 3, 'y': 12},\n                        {'x1': 1, 'x2': 4, 'y': 16}\n                        ],\n                  columns=['x1', 'x2', 'y'])\n\nX = df[['x1', 'x2']]\ny = df['y']\nreg = LinearRegression().fit(X, y)\nprint(reg.predict(np.array([[0, 5]]))) # Output is 8.75 \nprint(reg.predict(np.array([[1, 5]]))) # Output is 16.25\n\n# use one hot encoder\n\ndf = pd.get_dummies(df, columns=[\"x1\"], prefix=[\"x1\"])\nX = df[['x1_0', 'x1_1', 'x2']]\ny = df['y']\nreg = LinearRegression().fit(X, y)\nprint(reg.predict(np.array([[1, 0, 5]]))) # Output is 8.75\nprint(reg.predict(np.array([[0, 1, 5]]))) # Output is 16.25\n</code></pre>\n\n<p>How can I use pandas and sklearn for the combined data to get the same accuracy using one machine learning model?</p>\n <machine-learning><python><scikit-learn><p>You can have x1 as a categorical variable, convert it to dummy variables (one hot encoder) and then run linear regression (or any other algorithm). </p>\n<p>I know this is late, but the question got bumped by Community, so...</p>\n\n<p>Your discussion and data suggest that what you want to produce is the model\n<span class=\"math-container\">$$y = (3x_1+1)x_2,$$</span>\nbut <em>that is not a linear model</em> and so linear regression will not find it.  You can try any number of other nonlinear models, the best type depending on your real use-case.  For instance, </p>\n\n<ol>\n<li><p>If you really just want a linear model for each value of <span class=\"math-container\">$x_1$</span>, then it's probably best just to split the data along <span class=\"math-container\">$x_1$</span> as you started with.  You might need to examine your motivation behind wanting just \"one machine learning model\".</p></li>\n<li><p>You could introduce a new feature, equal to <span class=\"math-container\">$x_1 x_2$</span>.  This loses some information from option (1) when <span class=\"math-container\">$x_1$</span> has more than two values, but it might be suitable.</p></li>\n<li>You could use a tree-based model with linear regression done at each leaf, as in  <a href=\"https://stats.stackexchange.com/questions/78563/regression-tree-algorithm-with-linear-regression-models-in-each-leaf\">https://stats.stackexchange.com/questions/78563/regression-tree-algorithm-with-linear-regression-models-in-each-leaf</a> .  If the model fitting procedure decides to split only on <span class=\"math-container\">$x_1$</span> and regress only on <span class=\"math-container\">$x_2$</span>, it mostly recovers option (1), though there's no reason to necessarily expect that.</li>\n</ol>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "41606",
                "question_votes:": "",
                "question_text:": "<p>I have data of the following kind:</p>\n\n<pre><code>   x1  x2  y\n0  0   1  1\n1  0   2  2\n2  0   3  3\n3  0   4  4\n4  1   1  4\n5  1   2  8\n6  1   3  12\n7  1   4  16\n</code></pre>\n\n<p>Is it possible to construct a single machine learning algorithm in python/scikit-learn by defining column <code>x1</code> in such a way that a simple linear regression should give <code>predict(x1=0, x2=5) = 5</code> and <code>predict(x1=1, x2=5) = 20</code>. My actual problem has multiple values of <code>x1</code>. </p>\n\n<p>To illustrate the problem better: I have the following code with one hot encoder and it doesn't seem to give the accuracy of training the data separately. </p>\n\n<pre><code>import pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\n# Dataframe with x1 = 0 and linear regression gives a slope of 1 as expected\n\ndf = pd.DataFrame(data=[{'x1': 0, 'x2': 1, 'y': 1},\n                        {'x1': 0, 'x2': 2, 'y': 2},\n                        {'x1': 0, 'x2': 3, 'y': 3},\n                        {'x1': 0, 'x2': 4, 'y': 4}\n                        ],\n                  columns=['x1', 'x2', 'y'])\n\nX = df[['x1', 'x2']]\ny = df['y']\nreg = LinearRegression().fit(X, y)\nprint(reg.predict(np.array([[0, 5]]))) # Output is 5 as expected\n\n# Dataframe with x1 = 1 and linear regression gives a slope of 5 as expected\n\ndf = pd.DataFrame(data=[{'x1': 1, 'x2': 1, 'y': 4},\n                        {'x1': 1, 'x2': 2, 'y': 8},\n                        {'x1': 1, 'x2': 3, 'y': 12},\n                        {'x1': 1, 'x2': 4, 'y': 16}\n                        ],\n                  columns=['x1', 'x2', 'y'])\n\nX = df[['x1', 'x2']]\ny = df['y']\nreg = LinearRegression().fit(X, y)\nprint(reg.predict(np.array([[1, 5]]))) # Output is 20 as expected \n\n# Combine the two data frames x1 = 0 and x1 = 1 \n\ndf = pd.DataFrame(data=[{'x1': 0, 'x2': 1, 'y': 1},\n                        {'x1': 0, 'x2': 2, 'y': 2},\n                        {'x1': 0, 'x2': 3, 'y': 3},\n                        {'x1': 0, 'x2': 4, 'y': 4},\n                        {'x1': 1, 'x2': 1, 'y': 4},\n                        {'x1': 1, 'x2': 2, 'y': 8},\n                        {'x1': 1, 'x2': 3, 'y': 12},\n                        {'x1': 1, 'x2': 4, 'y': 16}\n                        ],\n                  columns=['x1', 'x2', 'y'])\n\nX = df[['x1', 'x2']]\ny = df['y']\nreg = LinearRegression().fit(X, y)\nprint(reg.predict(np.array([[0, 5]]))) # Output is 8.75 \nprint(reg.predict(np.array([[1, 5]]))) # Output is 16.25\n\n# use one hot encoder\n\ndf = pd.get_dummies(df, columns=[\"x1\"], prefix=[\"x1\"])\nX = df[['x1_0', 'x1_1', 'x2']]\ny = df['y']\nreg = LinearRegression().fit(X, y)\nprint(reg.predict(np.array([[1, 0, 5]]))) # Output is 8.75\nprint(reg.predict(np.array([[0, 1, 5]]))) # Output is 16.25\n</code></pre>\n\n<p>How can I use pandas and sklearn for the combined data to get the same accuracy using one machine learning model?</p>\n",
                "tags": "<machine-learning><python><scikit-learn>",
                "answers": [
                    [
                        "41618",
                        "2",
                        "41606",
                        "",
                        "",
                        "<p>You can have x1 as a categorical variable, convert it to dummy variables (one hot encoder) and then run linear regression (or any other algorithm). </p>\n",
                        "",
                        ""
                    ],
                    [
                        "50812",
                        "2",
                        "41606",
                        "",
                        "",
                        "<p>I know this is late, but the question got bumped by Community, so...</p>\n\n<p>Your discussion and data suggest that what you want to produce is the model\n<span class=\"math-container\">$$y = (3x_1+1)x_2,$$</span>\nbut <em>that is not a linear model</em> and so linear regression will not find it.  You can try any number of other nonlinear models, the best type depending on your real use-case.  For instance, </p>\n\n<ol>\n<li><p>If you really just want a linear model for each value of <span class=\"math-container\">$x_1$</span>, then it's probably best just to split the data along <span class=\"math-container\">$x_1$</span> as you started with.  You might need to examine your motivation behind wanting just \"one machine learning model\".</p></li>\n<li><p>You could introduce a new feature, equal to <span class=\"math-container\">$x_1 x_2$</span>.  This loses some information from option (1) when <span class=\"math-container\">$x_1$</span> has more than two values, but it might be suitable.</p></li>\n<li>You could use a tree-based model with linear regression done at each leaf, as in  <a href=\"https://stats.stackexchange.com/questions/78563/regression-tree-algorithm-with-linear-regression-models-in-each-leaf\">https://stats.stackexchange.com/questions/78563/regression-tree-algorithm-with-linear-regression-models-in-each-leaf</a> .  If the model fitting procedure decides to split only on <span class=\"math-container\">$x_1$</span> and regress only on <span class=\"math-container\">$x_2$</span>, it mostly recovers option (1), though there's no reason to necessarily expect that.</li>\n</ol>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13171",
            "_score": 15.054613,
            "_source": {
                "title": "Predicting Intent to do X with a confidence score or intent percentage score?",
                "content": "Predicting Intent to do X with a confidence score or intent percentage score? <p>I have a data set like:</p>\n\n<pre><code>did_purchase  action_1_30d action_2_20d action_2_10d ....\n   False            10          20            100\n   True            ....etc\n</code></pre>\n\n<p>Where <code>did_purchase</code> shows whether the customer purchased or not, and the columns indicate the volume of actions taken before the purchase (or non-purchase) event. </p>\n\n<p>So, for the first row the customer did 10 of action_1 within 30 days of the purchase event, but didn't purchase in the end.</p>\n\n<p>I have been using sklearn's LogisticRegression to predict the <code>did_purchase</code> false/true, and can get about 89% accuracy, which is nice. </p>\n\n<p>However, I'd like a percentage intent score instead. So it could say <code>user-321 has a 46% chance of purchasing in the next 10 days.</code></p>\n\n<p>What would be a good algo/approach for this?</p>\n <logistic-regression><p>You could use the probabilities output by <code>LogisticRegression</code>s <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba\" rel=\"nofollow noreferrer\"><code>predict_proba</code> method</a>.</p>\n\n<p>Almost all classifiers give you a probability in sklearn. One exception is the support vector classifier which will give you a points distance to the decision hyperplane, which can be interpreted as a confidence (you can get probabilities for the support vector classifier, but it is through a computationally costly cross validation process).</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "45405",
                "question_votes:": "2",
                "question_text:": "<p>I have a data set like:</p>\n\n<pre><code>did_purchase  action_1_30d action_2_20d action_2_10d ....\n   False            10          20            100\n   True            ....etc\n</code></pre>\n\n<p>Where <code>did_purchase</code> shows whether the customer purchased or not, and the columns indicate the volume of actions taken before the purchase (or non-purchase) event. </p>\n\n<p>So, for the first row the customer did 10 of action_1 within 30 days of the purchase event, but didn't purchase in the end.</p>\n\n<p>I have been using sklearn's LogisticRegression to predict the <code>did_purchase</code> false/true, and can get about 89% accuracy, which is nice. </p>\n\n<p>However, I'd like a percentage intent score instead. So it could say <code>user-321 has a 46% chance of purchasing in the next 10 days.</code></p>\n\n<p>What would be a good algo/approach for this?</p>\n",
                "tags": "<logistic-regression>",
                "answers": [
                    [
                        "45406",
                        "2",
                        "45405",
                        "",
                        "",
                        "<p>You could use the probabilities output by <code>LogisticRegression</code>s <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba\" rel=\"nofollow noreferrer\"><code>predict_proba</code> method</a>.</p>\n\n<p>Almost all classifiers give you a probability in sklearn. One exception is the support vector classifier which will give you a points distance to the decision hyperplane, which can be interpreted as a confidence (you can get probabilities for the support vector classifier, but it is through a computationally costly cross validation process).</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11517",
            "_score": 15.044402,
            "_source": {
                "title": "logistic regression score is negative",
                "content": "logistic regression score is negative <p>I am trying to implement logistic regression algorithm.<br>\nI am using sklearn for this purpose.When I am printing the accuracy its printing negative value.</p>\n\n<p>code:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nimport scipy\nfrom scipy.stats import spearmanr\nimport sklearn\nfrom sklearn.preprocessing import scale\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn import preprocessing\n\n#load data and see\naddress=(\"ex2data2.txt\")\nstudent=pd.read_csv(address)\nstudent.columns=['score1','score2','res']\n#print(student.head())\n\n#seperate input and output data\nX=student.ix[:,(0,1)].values\nstudent_data_names=['score1','score2']\n\ny=student.ix[:,2].values\n#print(\"all done\")\n\n#check missing values\n#print(student.isnull().sum())\n\n#check if output contains other than 0 or 1\n#plt.show(sb.countplot(x='res', data=student))\n\n#print(student.info())\n\nX = scale(X)\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n\nLogReg=LogisticRegression(C=2.0)\nLogReg.fit(X_train,y_train)\ndat1=LogReg.predict(X_test)\n\nprint(r2_score(y_test,dat1))\n</code></pre>\n\n<p>output:</p>\n\n<pre><code>-1.1818181818181817\n</code></pre>\n\n<p>Each time the output is different but everytime it is negative.<br>\nHow can i get best and correct accuracy result.</p>\n\n<p><a href=\"https://i.stack.imgur.com/QP7Rq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/QP7Rq.png\" alt=\"image of dataset\"></a></p>\n <python><scikit-learn><logistic-regression><p>Perhaps try a different algorithm/ model or tune the parameters.</p>\n\n<p>It is possible for r2_score to be negative. </p>\n\n<p>As mentioned in wikipedia page of <a href=\"https://en.wikipedia.org/wiki/Coefficient_of_determination\" rel=\"nofollow noreferrer\">coefficient of determination</a></p>\n\n<blockquote>\n  <p>There are cases where the computational definition of <span class=\"math-container\">$R^2$</span> can yield negative values, depending on the definition used. This can arise when the predictions that are being compared to the corresponding outcomes have not been derived from a model-fitting procedure using those data. Even if a model-fitting procedure has been used, <span class=\"math-container\">$R^2$</span> may still be negative, for example when linear regression is conducted without including an intercept, or when a non-linear function is used to fit the data. In cases where negative values arise, the mean of the data provides a better fit to the outcomes than do the fitted function values, according to this particular criterion. Since the most general definition of the coefficient of determination is also known as the Nash\u2013Sutcliffe model efficiency coefficient, this last notation is preferred in many fields, because denoting a goodness-of-fit indicator that can vary from <span class=\"math-container\">$-\\infty$</span> to <span class=\"math-container\">$1$</span> (i.e., it can yield negative values) with a squared letter is confusing.</p>\n</blockquote>\n",
                "codes": [
                    []
                ],
                "question_id:": "40670",
                "question_votes:": "",
                "question_text:": "<p>I am trying to implement logistic regression algorithm.<br>\nI am using sklearn for this purpose.When I am printing the accuracy its printing negative value.</p>\n\n<p>code:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nimport scipy\nfrom scipy.stats import spearmanr\nimport sklearn\nfrom sklearn.preprocessing import scale\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn import preprocessing\n\n#load data and see\naddress=(\"ex2data2.txt\")\nstudent=pd.read_csv(address)\nstudent.columns=['score1','score2','res']\n#print(student.head())\n\n#seperate input and output data\nX=student.ix[:,(0,1)].values\nstudent_data_names=['score1','score2']\n\ny=student.ix[:,2].values\n#print(\"all done\")\n\n#check missing values\n#print(student.isnull().sum())\n\n#check if output contains other than 0 or 1\n#plt.show(sb.countplot(x='res', data=student))\n\n#print(student.info())\n\nX = scale(X)\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n\nLogReg=LogisticRegression(C=2.0)\nLogReg.fit(X_train,y_train)\ndat1=LogReg.predict(X_test)\n\nprint(r2_score(y_test,dat1))\n</code></pre>\n\n<p>output:</p>\n\n<pre><code>-1.1818181818181817\n</code></pre>\n\n<p>Each time the output is different but everytime it is negative.<br>\nHow can i get best and correct accuracy result.</p>\n\n<p><a href=\"https://i.stack.imgur.com/QP7Rq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/QP7Rq.png\" alt=\"image of dataset\"></a></p>\n",
                "tags": "<python><scikit-learn><logistic-regression>",
                "answers": [
                    [
                        "40674",
                        "2",
                        "40670",
                        "",
                        "",
                        "<p>Perhaps try a different algorithm/ model or tune the parameters.</p>\n\n<p>It is possible for r2_score to be negative. </p>\n\n<p>As mentioned in wikipedia page of <a href=\"https://en.wikipedia.org/wiki/Coefficient_of_determination\" rel=\"nofollow noreferrer\">coefficient of determination</a></p>\n\n<blockquote>\n  <p>There are cases where the computational definition of <span class=\"math-container\">$R^2$</span> can yield negative values, depending on the definition used. This can arise when the predictions that are being compared to the corresponding outcomes have not been derived from a model-fitting procedure using those data. Even if a model-fitting procedure has been used, <span class=\"math-container\">$R^2$</span> may still be negative, for example when linear regression is conducted without including an intercept, or when a non-linear function is used to fit the data. In cases where negative values arise, the mean of the data provides a better fit to the outcomes than do the fitted function values, according to this particular criterion. Since the most general definition of the coefficient of determination is also known as the Nash\u2013Sutcliffe model efficiency coefficient, this last notation is preferred in many fields, because denoting a goodness-of-fit indicator that can vary from <span class=\"math-container\">$-\\infty$</span> to <span class=\"math-container\">$1$</span> (i.e., it can yield negative values) with a squared letter is confusing.</p>\n</blockquote>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13290",
            "_score": 14.998814,
            "_source": {
                "title": "Why I am getting prediction score 1 i.e. 100%",
                "content": "Why I am getting prediction score 1 i.e. 100% <p>I am reading few parameters and trying to predict target value using Linear regression and GB. Surpicingly I am getting score = 1 on test data. How come? Can anyone tell me whats wrong with this code?</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\ndataset = pd.read_csv(\"prod_data_for_ML.csv\",header = 0)\n\n#Data Pre-processing\ndata = dataset.drop('organization_id',1)\ndata = data.drop('status',1)\ndata = data.drop('city',1)\n\n#Find median for features having NaN\nmedian_zip, median_role_id, median_specialty_id, median_latitude, median_longitude = data['zip'].median(),data['role_id'].median(),data['specialty_id'].median(),data['latitude'].median(),data['longitude'].median() \ndata['zip'].fillna(median_zip, inplace=True)\ndata['role_id'].fillna(median_role_id, inplace=True)\ndata['specialty_id'].fillna(median_specialty_id, inplace=True)\ndata['latitude'].fillna(median_latitude, inplace=True)\ndata['longitude'].fillna(median_longitude, inplace=True)\n\n#Fill YearOFExp with 0\ndata['years_of_experience'].fillna(0, inplace=True)\n\n#Start training\n\nlabels = dataset.location_id\ntrain1 = data\nreg = LinearRegression()\nx_train , x_test , y_train , y_test = train_test_split(train1 , labels , test_size = 0.20,random_state =1)\n\n# x_train.to_csv(\"x_train.csv\", sep=',', encoding='utf-8')\n# x_test.to_csv(\"x_test.csv\", sep=',', encoding='utf-8')\n\nreg.fit(x_train,y_train)\nreg.score(x_test,y_test)\n<span class=\"math-container\">```</span>\n</code></pre>\n <machine-learning><python><scikit-learn><regression><pandas><p>You are using your target variable <code>location_id</code> as a feature. You need to remove it from <code>data</code>/<code>train1</code>/ X variables.</p>\n\n<p>In other words, you are trying to predict <code>location_id</code> by <code>location_id</code>.</p>\n\n<p>If you use <code>reg.feature_importances_</code> you will see, that <code>location_id</code> affects your prediction 100% and others have no effect on prediction result.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "45627",
                "question_votes:": "3",
                "question_text:": "<p>I am reading few parameters and trying to predict target value using Linear regression and GB. Surpicingly I am getting score = 1 on test data. How come? Can anyone tell me whats wrong with this code?</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\ndataset = pd.read_csv(\"prod_data_for_ML.csv\",header = 0)\n\n#Data Pre-processing\ndata = dataset.drop('organization_id',1)\ndata = data.drop('status',1)\ndata = data.drop('city',1)\n\n#Find median for features having NaN\nmedian_zip, median_role_id, median_specialty_id, median_latitude, median_longitude = data['zip'].median(),data['role_id'].median(),data['specialty_id'].median(),data['latitude'].median(),data['longitude'].median() \ndata['zip'].fillna(median_zip, inplace=True)\ndata['role_id'].fillna(median_role_id, inplace=True)\ndata['specialty_id'].fillna(median_specialty_id, inplace=True)\ndata['latitude'].fillna(median_latitude, inplace=True)\ndata['longitude'].fillna(median_longitude, inplace=True)\n\n#Fill YearOFExp with 0\ndata['years_of_experience'].fillna(0, inplace=True)\n\n#Start training\n\nlabels = dataset.location_id\ntrain1 = data\nreg = LinearRegression()\nx_train , x_test , y_train , y_test = train_test_split(train1 , labels , test_size = 0.20,random_state =1)\n\n# x_train.to_csv(\"x_train.csv\", sep=',', encoding='utf-8')\n# x_test.to_csv(\"x_test.csv\", sep=',', encoding='utf-8')\n\nreg.fit(x_train,y_train)\nreg.score(x_test,y_test)\n<span class=\"math-container\">```</span>\n</code></pre>\n",
                "tags": "<machine-learning><python><scikit-learn><regression><pandas>",
                "answers": [
                    [
                        "46400",
                        "2",
                        "45627",
                        "",
                        "",
                        "<p>You are using your target variable <code>location_id</code> as a feature. You need to remove it from <code>data</code>/<code>train1</code>/ X variables.</p>\n\n<p>In other words, you are trying to predict <code>location_id</code> by <code>location_id</code>.</p>\n\n<p>If you use <code>reg.feature_importances_</code> you will see, that <code>location_id</code> affects your prediction 100% and others have no effect on prediction result.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16265",
            "_score": 14.946385,
            "_source": {
                "title": "Reproduce Linear Regression Classification Masking Graph of ESL",
                "content": "Reproduce Linear Regression Classification Masking Graph of ESL <p>I would like to reproduce the following graph from the Elements of Statistical Learning Chapter 4 Linear Methods for Classification. It shows the classification masking problem if using linear regression, in which the decision boundaries coincide into one line.  <a href=\"https://i.stack.imgur.com/QzdfDm.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/QzdfDm.png\" alt=\"Classification masking from ESL\"></a> </p>\n\n<p>To reproduce the graph, I generated a dataset using 'make_blobs' from 'sklearn'. Unfortunately, I get the following graph instead, where the decision boundaries don't coincide. The decision boundary between class <span class=\"math-container\">$i$</span> and <span class=\"math-container\">$j$</span> is the line <span class=\"math-container\">$(x_1, x_2)$</span> satisfying \n<span class=\"math-container\">\\begin{equation}\nb_{0,i} + b^T_i (x_1,x_2) = b_{0,j} + b^T_j(x_1,x_2)\n\\end{equation}</span> \nTo make the decision boundaries coincide, we must have \n<span class=\"math-container\">\\begin{align}\nb_2 - b_1 &amp;= b_3 - b_2 \\\\\nb_{0,2} - b_{0,1} &amp;= b_{0,3} - b_{0,2}\n\\end{align}</span></p>\n\n<p>We know that in linear regression, the coefficients <span class=\"math-container\">$B = (X^TX)^{-1}X^TY$</span>. Does it mean I can't simply use 'make_blobs' to randomly generate some datasets? What kind of conditions must the dataset satisfy, in order to make the decision boundaries coincide? </p>\n\n<p>I paste my python code below. How should I modify my code to reproduce the graph in ESL?</p>\n\n<p><a href=\"https://i.stack.imgur.com/mKa5Ym.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/mKa5Ym.png\" alt=\"My re-produce work\"></a></p>\n\n<pre><code>import numpy as np\n\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\n\nimport matplotlib.pyplot as  plt\nfrom matplotlib import cm\n\nn_samples = 3000\ncenters = ((-5,-5), (0,0), (5,5))\nX, y = make_blobs(n_samples=n_samples, n_features=2, centers=centers, cluster_std=1,\n                  random_state=0)    \n\n\n# =============================================================================\n# Transform Y into one-hot-vector    \n# =============================================================================\ny_unique = np.unique(y)\nenc = OneHotEncoder(categories=[y_unique], sparse=True)\nY = enc.fit_transform(y.reshape(-1,1))\n\nlr = LinearRegression().fit(X,Y.todense())\nB0 = lr.intercept_\nB = lr.coef_\n# =============================================================================\n# Compute the decision boundaries\n# =============================================================================\nx_plt = np.arange(-8,8,0.1)\n\ndef get_boundary_y_values( x_plt, B0, B, class1, class2):\n    c = B0[class1] - B0[class2]\n    b = B[class2] - B[class1]\n    if b[1] != 0 :\n        return (c - b[0]*x_plt)/b[1]\n    else:\n        print(\"y is 0\")\n        return 0\n\ny1_plt = get_boundary_y_values(x_plt, B0, B, 0, 1)\ny2_plt = get_boundary_y_values(x_plt, B0, B, 0, 2)    \ny3_plt = get_boundary_y_values(x_plt, B0, B, 1, 2)    \n\n#=============================================================================\n# Plotting the output\n# =============================================================================\n\ncolors = cm.rainbow(np.linspace(0,1,y_unique.size))\nfor this_y, color in zip(y_unique, colors):\n    this_x = X[y==this_y]\n    plt.scatter(this_x[:,0], this_x[:,1], marker='.', color=color, \n                label=\"Class %s\" %this_y) \n\nplt.plot(x_plt, y1_plt, 'r')\nplt.plot(x_plt, y2_plt, 'b')\nplt.plot(x_plt, y3_plt, 'm')\n</code></pre>\n <machine-learning><python><classification><linear-regression>",
                "codes": [],
                "question_id:": "53700",
                "question_votes:": "",
                "question_text:": "<p>I would like to reproduce the following graph from the Elements of Statistical Learning Chapter 4 Linear Methods for Classification. It shows the classification masking problem if using linear regression, in which the decision boundaries coincide into one line.  <a href=\"https://i.stack.imgur.com/QzdfDm.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/QzdfDm.png\" alt=\"Classification masking from ESL\"></a> </p>\n\n<p>To reproduce the graph, I generated a dataset using 'make_blobs' from 'sklearn'. Unfortunately, I get the following graph instead, where the decision boundaries don't coincide. The decision boundary between class <span class=\"math-container\">$i$</span> and <span class=\"math-container\">$j$</span> is the line <span class=\"math-container\">$(x_1, x_2)$</span> satisfying \n<span class=\"math-container\">\\begin{equation}\nb_{0,i} + b^T_i (x_1,x_2) = b_{0,j} + b^T_j(x_1,x_2)\n\\end{equation}</span> \nTo make the decision boundaries coincide, we must have \n<span class=\"math-container\">\\begin{align}\nb_2 - b_1 &amp;= b_3 - b_2 \\\\\nb_{0,2} - b_{0,1} &amp;= b_{0,3} - b_{0,2}\n\\end{align}</span></p>\n\n<p>We know that in linear regression, the coefficients <span class=\"math-container\">$B = (X^TX)^{-1}X^TY$</span>. Does it mean I can't simply use 'make_blobs' to randomly generate some datasets? What kind of conditions must the dataset satisfy, in order to make the decision boundaries coincide? </p>\n\n<p>I paste my python code below. How should I modify my code to reproduce the graph in ESL?</p>\n\n<p><a href=\"https://i.stack.imgur.com/mKa5Ym.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/mKa5Ym.png\" alt=\"My re-produce work\"></a></p>\n\n<pre><code>import numpy as np\n\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\n\nimport matplotlib.pyplot as  plt\nfrom matplotlib import cm\n\nn_samples = 3000\ncenters = ((-5,-5), (0,0), (5,5))\nX, y = make_blobs(n_samples=n_samples, n_features=2, centers=centers, cluster_std=1,\n                  random_state=0)    \n\n\n# =============================================================================\n# Transform Y into one-hot-vector    \n# =============================================================================\ny_unique = np.unique(y)\nenc = OneHotEncoder(categories=[y_unique], sparse=True)\nY = enc.fit_transform(y.reshape(-1,1))\n\nlr = LinearRegression().fit(X,Y.todense())\nB0 = lr.intercept_\nB = lr.coef_\n# =============================================================================\n# Compute the decision boundaries\n# =============================================================================\nx_plt = np.arange(-8,8,0.1)\n\ndef get_boundary_y_values( x_plt, B0, B, class1, class2):\n    c = B0[class1] - B0[class2]\n    b = B[class2] - B[class1]\n    if b[1] != 0 :\n        return (c - b[0]*x_plt)/b[1]\n    else:\n        print(\"y is 0\")\n        return 0\n\ny1_plt = get_boundary_y_values(x_plt, B0, B, 0, 1)\ny2_plt = get_boundary_y_values(x_plt, B0, B, 0, 2)    \ny3_plt = get_boundary_y_values(x_plt, B0, B, 1, 2)    \n\n#=============================================================================\n# Plotting the output\n# =============================================================================\n\ncolors = cm.rainbow(np.linspace(0,1,y_unique.size))\nfor this_y, color in zip(y_unique, colors):\n    this_x = X[y==this_y]\n    plt.scatter(this_x[:,0], this_x[:,1], marker='.', color=color, \n                label=\"Class %s\" %this_y) \n\nplt.plot(x_plt, y1_plt, 'r')\nplt.plot(x_plt, y2_plt, 'b')\nplt.plot(x_plt, y3_plt, 'm')\n</code></pre>\n",
                "tags": "<machine-learning><python><classification><linear-regression>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4632",
            "_score": 14.934258,
            "_source": {
                "title": "How to force weights to be non-negative in Linear regression",
                "content": "How to force weights to be non-negative in Linear regression <p>I am using a standard linear regression using scikit-learn in python.\nHowever, I would like to force the weights to be all positive for every feature (not negative), is there any way I can accomplish that? I was looking in the documentation but could not find a way to accomplish that.\nI understand I may not get the best solution, but I need the weights to be non-negative.</p>\n <python><scikit-learn><linear-regression><p>I use a workaround with Lasso on Scikit Learn (It is definitely not the best way to do things but it works well). Lasso has a parameter <code>positive</code> which can be set to <code>True</code> and force the coefficients to be positive. Further, setting the Regularization coefficient <code>alpha</code> to lie close to 0 makes the Lasso mimic Linear Regression with no regularization. Here's the code:</p>\n\n<pre><code>from sklearn.linear_model import Lasso\nlin = Lasso(alpha=0.0001,precompute=True,max_iter=1000,\n            positive=True, random_state=9999, selection='random')\nlin.fit(X,y)\n</code></pre>\n<p>Here is an example of why you would want to do it (and approximately how).</p>\n\n<p>I have 3 predictive models of housing prices: linear, gradient boosting, neural network.</p>\n\n<p>I want to blend them into a weighted average and find the best weights.</p>\n\n<p>I run linear regression, and I get a solution with weights like -3.1, 2.5, 1.5, and some intercept. </p>\n\n<p>So what I do instead using sklearn is </p>\n\n<pre><code>blendlasso = LassoCV(alphas=np.logspace(-6, -3, 7),\n                     max_iter=100000,\n                     cv=5,\n                     fit_intercept=False,\n                     positive=True)\n</code></pre>\n\n<p>And I get positive weights that sum (very close) to 1. In my example I want the alpha that works best out-of-sample so I use LassoCV with cross-validation. </p>\n\n<p>The sklearn docs state that you shouldn't set alpha to 0 for numerical reasons, however you can also use straight Lasso() and set the alpha parameter as low as you can get away with to get a reasonable answer.</p>\n<p>What you are looking for, is the <a href=\"https://en.wikipedia.org/wiki/Non-negative_least_squares\" rel=\"noreferrer\">Non-negative least square regression</a>.\nIt is a simple optimization problem in quadratic programming where your constraint is that all the coefficients(a.k.a weights) should be positive.</p>\n\n<p>Having said that, there is <a href=\"https://github.com/scikit-learn/scikit-learn/issues/8191\" rel=\"noreferrer\">no standard implementation</a> of Non-negative least squares in Scikit-Learn. <a href=\"https://github.com/scikit-learn/scikit-learn/pull/8428\" rel=\"noreferrer\">The pull request is still open</a>.</p>\n\n<p>But, looks like <a href=\"https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.optimize.nnls.html\" rel=\"noreferrer\">Scipy has implemented the same</a>. </p>\n\n<p><strong>PS:</strong> I haven't tried the scipy version. I found it solely by googling around.</p>\n",
                "codes": [
                    [
                        "from sklearn.linear_model import Lasso\nlin = Lasso(alpha=0.0001,precompute=True,max_iter=1000,\n            positive=True, random_state=9999, selection='random')\nlin.fit(X,y)\n"
                    ],
                    [
                        "blendlasso = LassoCV(alphas=np.logspace(-6, -3, 7),\n                     max_iter=100000,\n                     cv=5,\n                     fit_intercept=False,\n                     positive=True)\n"
                    ],
                    []
                ],
                "question_id:": "18258",
                "question_votes:": "24",
                "question_text:": "<p>I am using a standard linear regression using scikit-learn in python.\nHowever, I would like to force the weights to be all positive for every feature (not negative), is there any way I can accomplish that? I was looking in the documentation but could not find a way to accomplish that.\nI understand I may not get the best solution, but I need the weights to be non-negative.</p>\n",
                "tags": "<python><scikit-learn><linear-regression>",
                "answers": [
                    [
                        "19791",
                        "2",
                        "18258",
                        "",
                        "",
                        "<p>I use a workaround with Lasso on Scikit Learn (It is definitely not the best way to do things but it works well). Lasso has a parameter <code>positive</code> which can be set to <code>True</code> and force the coefficients to be positive. Further, setting the Regularization coefficient <code>alpha</code> to lie close to 0 makes the Lasso mimic Linear Regression with no regularization. Here's the code:</p>\n\n<pre><code>from sklearn.linear_model import Lasso\nlin = Lasso(alpha=0.0001,precompute=True,max_iter=1000,\n            positive=True, random_state=9999, selection='random')\nlin.fit(X,y)\n</code></pre>\n",
                        "",
                        "14"
                    ],
                    [
                        "52277",
                        "2",
                        "18258",
                        "",
                        "",
                        "<p>Here is an example of why you would want to do it (and approximately how).</p>\n\n<p>I have 3 predictive models of housing prices: linear, gradient boosting, neural network.</p>\n\n<p>I want to blend them into a weighted average and find the best weights.</p>\n\n<p>I run linear regression, and I get a solution with weights like -3.1, 2.5, 1.5, and some intercept. </p>\n\n<p>So what I do instead using sklearn is </p>\n\n<pre><code>blendlasso = LassoCV(alphas=np.logspace(-6, -3, 7),\n                     max_iter=100000,\n                     cv=5,\n                     fit_intercept=False,\n                     positive=True)\n</code></pre>\n\n<p>And I get positive weights that sum (very close) to 1. In my example I want the alpha that works best out-of-sample so I use LassoCV with cross-validation. </p>\n\n<p>The sklearn docs state that you shouldn't set alpha to 0 for numerical reasons, however you can also use straight Lasso() and set the alpha parameter as low as you can get away with to get a reasonable answer.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "18259",
                        "2",
                        "18258",
                        "",
                        "",
                        "<p>What you are looking for, is the <a href=\"https://en.wikipedia.org/wiki/Non-negative_least_squares\" rel=\"noreferrer\">Non-negative least square regression</a>.\nIt is a simple optimization problem in quadratic programming where your constraint is that all the coefficients(a.k.a weights) should be positive.</p>\n\n<p>Having said that, there is <a href=\"https://github.com/scikit-learn/scikit-learn/issues/8191\" rel=\"noreferrer\">no standard implementation</a> of Non-negative least squares in Scikit-Learn. <a href=\"https://github.com/scikit-learn/scikit-learn/pull/8428\" rel=\"noreferrer\">The pull request is still open</a>.</p>\n\n<p>But, looks like <a href=\"https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.optimize.nnls.html\" rel=\"noreferrer\">Scipy has implemented the same</a>. </p>\n\n<p><strong>PS:</strong> I haven't tried the scipy version. I found it solely by googling around.</p>\n",
                        "",
                        "26"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9550",
            "_score": 14.914346,
            "_source": {
                "title": "Linear Regression + KFold cross validation",
                "content": "Linear Regression + KFold cross validation <p>I have a prepossessed data set ready and the corresponding labels (8 classes).\nI've already done KFold cross validation with  K=10 with some classifiers such as DT,KNN,NB and SVM and now I want to do a linear regression model, but not sure how it goes with the KFold , is it even possible or for the regression I should just divide the set on my own to a training and testing sets ?</p>\n\n<p>The 8 classes are ages (for NLP problem) , so I want to check both options of classification and regression. </p>\n <machine-learning><classification><scikit-learn><linear-regression><cross-validation><h1>Cross-validation</h1>\n\n<p>An extremely important concept to understand is that:</p>\n\n<p><strong>Cross-validation works independently of the model you use.</strong></p>\n\n<p>Cross-validation is just the process of splitting your data into multiple pairs of training and test sets. Once this is done, you can train that data using whatever model you like. In sklearn, which I assume you are using given your tags, you can use <a href=\"http://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics\" rel=\"nofollow noreferrer\">cross-validation</a> with any classifier/regressor you'd like.</p>\n\n<p><strong>Cross-validation is way to evaluate how well the model will perform on data that it hasn't seen before.</strong> When you train your model on all your data, you do not have any data that the model hasn't seen before to test on. This is why you cross-validate so that you can get multiple estimates of what the performance might be. This is more robust than just splitting your data once between a training and test set because in this case, it might happen that your test set is easier very difficult or very hard. By cross-validating, you smooth this out.</p>\n\n<h1>Linear vs Logistic regression</h1>\n\n<p>Apparently, your output is ages, and therefore, you could use linear or logistic regression. If you use linear regression, you will try to guess the age directly. If you use logistic regression, you could round the output to the closest integer to obtain the proper target classes.</p>\n\n<p>I would advise you to use logistic regression because it will allow your model to learn better. If you use linear regression, your classes are all as different as each other (from a mathematical point of view). However, my guess is that the <code>13</code> class is closer to <code>14</code> than it is to <code>20+</code>.</p>\n<p>Till now you have done classification using DT, KNN, NB and SVM. Your task is of classification as you have 8 output classes. Linear regression is not for classification problems, if you want you can go for Logistic Regression (that too, in the same way with K fold CV as you did for other methods).</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "33977",
                "question_votes:": "2",
                "question_text:": "<p>I have a prepossessed data set ready and the corresponding labels (8 classes).\nI've already done KFold cross validation with  K=10 with some classifiers such as DT,KNN,NB and SVM and now I want to do a linear regression model, but not sure how it goes with the KFold , is it even possible or for the regression I should just divide the set on my own to a training and testing sets ?</p>\n\n<p>The 8 classes are ages (for NLP problem) , so I want to check both options of classification and regression. </p>\n",
                "tags": "<machine-learning><classification><scikit-learn><linear-regression><cross-validation>",
                "answers": [
                    [
                        "33983",
                        "2",
                        "33977",
                        "",
                        "",
                        "<h1>Cross-validation</h1>\n\n<p>An extremely important concept to understand is that:</p>\n\n<p><strong>Cross-validation works independently of the model you use.</strong></p>\n\n<p>Cross-validation is just the process of splitting your data into multiple pairs of training and test sets. Once this is done, you can train that data using whatever model you like. In sklearn, which I assume you are using given your tags, you can use <a href=\"http://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics\" rel=\"nofollow noreferrer\">cross-validation</a> with any classifier/regressor you'd like.</p>\n\n<p><strong>Cross-validation is way to evaluate how well the model will perform on data that it hasn't seen before.</strong> When you train your model on all your data, you do not have any data that the model hasn't seen before to test on. This is why you cross-validate so that you can get multiple estimates of what the performance might be. This is more robust than just splitting your data once between a training and test set because in this case, it might happen that your test set is easier very difficult or very hard. By cross-validating, you smooth this out.</p>\n\n<h1>Linear vs Logistic regression</h1>\n\n<p>Apparently, your output is ages, and therefore, you could use linear or logistic regression. If you use linear regression, you will try to guess the age directly. If you use logistic regression, you could round the output to the closest integer to obtain the proper target classes.</p>\n\n<p>I would advise you to use logistic regression because it will allow your model to learn better. If you use linear regression, your classes are all as different as each other (from a mathematical point of view). However, my guess is that the <code>13</code> class is closer to <code>14</code> than it is to <code>20+</code>.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "33978",
                        "2",
                        "33977",
                        "",
                        "",
                        "<p>Till now you have done classification using DT, KNN, NB and SVM. Your task is of classification as you have 8 output classes. Linear regression is not for classification problems, if you want you can go for Logistic Regression (that too, in the same way with K fold CV as you did for other methods).</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11039",
            "_score": 14.8656025,
            "_source": {
                "title": "How to train ML model with multiple variables?",
                "content": "How to train ML model with multiple variables? <p>I am trying to learn Machine Learning concepts these days. I understand in a traditional ML data, we will have <em>features</em> and <em>labels</em>. I have following toy data in my mind where I have features like 'units_sold' and 'num_employees' and a label of 'cost_$'. I would like to train the model to learn these features and label for a particular 'city' and 'store'. For example if I perform Linear Regression, the model learn intercept and coefficient for the city and store it relates to. When I input units_sold and num_employees for next year, I get the prediction.</p>\n\n<pre><code>city        store   units_sold  num_employees   cost_$\nNew York    A       10          4               11000\nNew York    B       12          4               11890\nNew York    C       14          5               15260\nNew York    D       17          6               17340\nLondon      A       23          5               22770\nLondon      B       27          6               25650\nLondon      C       22          3               21450\nParis       A       4           2               5200\nParis       B       7           3               9590\n</code></pre>\n\n<p>I'm trying to brainstorm about it and would like to know how to approach this problem?</p>\n <machine-learning><python><scikit-learn><p>This is very little data so doing much with it is very difficult. especially considering you expect to get 'next year' estimates without having any historical data to base yourself from. </p>\n\n<p>However, if you want to be able to estimate a cost given your input features which are city, store, units_sold and num_employees then this problem setup is very standard in machine learning. </p>\n\n<p>First I will put your data into a pandas DataFrame and I will encode your categorical features using numerical values. I did this randomly, but I think you can get better results by getting the latitude and longitude of the stores, as well as some data about the neighborhood (density, wealth, etc.). </p>\n\n<pre><code>import pandas as pd\n\ndata = {'city': ['New York', 'New York', 'New York', 'New York', 'London', 'London', 'London', 'Paris', 'Paris'],\n        'store': ['A', 'B', 'C', 'D', 'A', 'B', 'C', 'A', 'B'],\n        'units_sold': [10, 12, 14, 17, 23, 27, 22, 4, 7],\n        'num_employees': [4,4,5,6,5,6,3,2,3],\n        'cost': [11000, 11890, 15260, 17340, 22770, 25650, 21450, 5200, 9560]}\n\ndf = pd.DataFrame(data)\n\ndf['store'] =df['store'].astype('category').cat.codes\ndf['city'] =df['city'].astype('category').cat.codes\n</code></pre>\n\n<p>When I am working with very little data I always like to pull some visualizations to give me some intuition about the data. Let's first see how the features are correlated. </p>\n\n<pre><code>import matplotlib.pyplot as plt\n\nplt.matshow(df.corr())\nplt.xticks(np.arange(5), df.columns, rotation=90)\nplt.yticks(np.arange(5), df.columns, rotation=0)\nplt.colorbar()\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/vJf61.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/vJf61.png\" alt=\"enter image description here\"></a></p>\n\n<p>We can see that the cost is associated directly with units_sold. That is not much of a surprise I guess. But it also correlates with the num_employees and is strongly inversely correlated with the city. </p>\n\n<p>If we plot the num_employees and units_sold we can see that the correlations observed above more clearly. </p>\n\n<p><a href=\"https://i.stack.imgur.com/Y8uNI.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/Y8uNI.png\" alt=\"enter image description here\"></a></p>\n\n<h1>A predictive model</h1>\n\n<p>Now we want to be able to give a model our inputs and get an estimation of the cost. </p>\n\n<p>Let's first put our data into a training and testing set. This is very problematic with such a small dataset because you have a very high probability of ending up with a training set that omits a city, or a store type. This will significantly affect the abiltiy of the model to predict an output for data it has never seen. </p>\n\n<p>The labels of the data are the cost. </p>\n\n<pre><code>import numpy as np\nfrom sklearn.model_selection import train_test_split\n\nX = np.asarray(df[['city', 'num_employees', 'store', 'units_sold']])\nY = np.asarray(df['cost'])\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n</code></pre>\n\n<p>Let's start with a standard linear regression</p>\n\n<p>from sklearn.linear_model import LinearRegression</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\n\nlineReg = LinearRegression()\nlineReg.fit(X_train, y_train)\nprint('Score: ', lineReg.score(X_test, y_test))\nprint('Weights: ', lineReg.coef_)\n\nplt.plot(lineReg.predict(X_test))\nplt.plot(y_test)\nplt.show()\n</code></pre>\n\n<blockquote>\n  <p>Score:  0.963554136721 <br/>\n  Weights:  [ 506.87136393  -15.48157725  376.79379444  920.01939237]</p>\n</blockquote>\n\n<p><a href=\"https://i.stack.imgur.com/oCGGe.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/oCGGe.png\" alt=\"enter image description here\"></a></p>\n\n<p>A better alternative is to use ridge regression. </p>\n\n<pre><code>from sklearn import linear_model\nreg = linear_model.Ridge (alpha = .5)\nreg.fit(X_train, y_train)\nprint('Score: ', reg.score(X_test, y_test))\nprint('Weights: ', reg.coef_)\n\nplt.plot(reg.predict(X_test))\nplt.plot(y_test)\nplt.show()\n</code></pre>\n\n<blockquote>\n  <p>Score:  0.971197683706 <br/>Weights:  [ 129.78467277    2.034588<br>\n  97.11724313  877.73906409]</p>\n</blockquote>\n\n<p><a href=\"https://i.stack.imgur.com/XXspr.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/XXspr.png\" alt=\"enter image description here\"></a></p>\n\n<p>If you do another split and rerun both these models you will see that the performance varies greatly for both of them as we expected due to the limited data. However, the effect is much more pronounced for the simple linear regression. </p>\n\n<p>To get a better idea of the actual results, let's do something a bit naughty. We will split the data over and over again to get different models and get the average of their scores.</p>\n\n<pre><code>scores = []\ncoefs = []\nfor i in range(1000):\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n    lineReg = LinearRegression()\n    lineReg.fit(X_train, y_train)\n    scores.append(lineReg.score(X_test, y_test))\n    coefs.append(lineReg.coef_)\nprint('Linear Regression')\nprint(np.mean(scores))\nprint(np.mean(coefs, axis=0))\n\nscores = []\ncoefs = []\nfor i in range(1000):\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n    lineReg = linear_model.Ridge (alpha = .5)\n    lineReg.fit(X_train, y_train)\n    scores.append(lineReg.score(X_test, y_test))\n    coefs.append(lineReg.coef_)\nprint('\\nRidge Regression')\nprint(np.mean(scores))\nprint(np.mean(coefs, axis=0))\n</code></pre>\n\n<blockquote>\n  <p>Linear Regression <br/>\n  -1.43683760609 <br/>\n  [ 1284.47358731  1251.8762943   -706.31897708   846.5465552 ] <br/>\n  <br/>\n  Ridge Regression <br/>\n  0.900877146134 <br/>\n  [ 228.05312491   95.33306385  123.49517018  873.49803782]</p>\n</blockquote>\n\n<p>We can see that across 1000 trials the ridge regression was by far the superior model. </p>\n\n<p>Now you can use this model to estimate costs by passing the model a vector with the features in the same order as the dataset as follows</p>\n\n<pre><code>reg.predict([[2,  4,  1,  12]])\n</code></pre>\n\n<p>The resulting score is</p>\n\n<blockquote>\n  <p>array([ 12853.2132658])</p>\n</blockquote>\n\n<hr>\n\n<p>This is not enough data to do any machine learning regression reliably. However you can get some insight into what factors affect your cost the most.</p>\n",
                "codes": [
                    [
                        "import pandas as pd\n\ndata = {'city': ['New York', 'New York', 'New York', 'New York', 'London', 'London', 'London', 'Paris', 'Paris'],\n        'store': ['A', 'B', 'C', 'D', 'A', 'B', 'C', 'A', 'B'],\n        'units_sold': [10, 12, 14, 17, 23, 27, 22, 4, 7],\n        'num_employees': [4,4,5,6,5,6,3,2,3],\n        'cost': [11000, 11890, 15260, 17340, 22770, 25650, 21450, 5200, 9560]}\n\ndf = pd.DataFrame(data)\n\ndf['store'] =df['store'].astype('category').cat.codes\ndf['city'] =df['city'].astype('category').cat.codes\n",
                        "import matplotlib.pyplot as plt\n\nplt.matshow(df.corr())\nplt.xticks(np.arange(5), df.columns, rotation=90)\nplt.yticks(np.arange(5), df.columns, rotation=0)\nplt.colorbar()\nplt.show()\n",
                        "import numpy as np\nfrom sklearn.model_selection import train_test_split\n\nX = np.asarray(df[['city', 'num_employees', 'store', 'units_sold']])\nY = np.asarray(df['cost'])\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n",
                        "from sklearn.linear_model import LinearRegression\n\nlineReg = LinearRegression()\nlineReg.fit(X_train, y_train)\nprint('Score: ', lineReg.score(X_test, y_test))\nprint('Weights: ', lineReg.coef_)\n\nplt.plot(lineReg.predict(X_test))\nplt.plot(y_test)\nplt.show()\n",
                        "from sklearn import linear_model\nreg = linear_model.Ridge (alpha = .5)\nreg.fit(X_train, y_train)\nprint('Score: ', reg.score(X_test, y_test))\nprint('Weights: ', reg.coef_)\n\nplt.plot(reg.predict(X_test))\nplt.plot(y_test)\nplt.show()\n",
                        "scores = []\ncoefs = []\nfor i in range(1000):\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n    lineReg = LinearRegression()\n    lineReg.fit(X_train, y_train)\n    scores.append(lineReg.score(X_test, y_test))\n    coefs.append(lineReg.coef_)\nprint('Linear Regression')\nprint(np.mean(scores))\nprint(np.mean(coefs, axis=0))\n\nscores = []\ncoefs = []\nfor i in range(1000):\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n    lineReg = linear_model.Ridge (alpha = .5)\n    lineReg.fit(X_train, y_train)\n    scores.append(lineReg.score(X_test, y_test))\n    coefs.append(lineReg.coef_)\nprint('\\nRidge Regression')\nprint(np.mean(scores))\nprint(np.mean(coefs, axis=0))\n",
                        "reg.predict([[2,  4,  1,  12]])\n"
                    ]
                ],
                "question_id:": "39034",
                "question_votes:": "5",
                "question_text:": "<p>I am trying to learn Machine Learning concepts these days. I understand in a traditional ML data, we will have <em>features</em> and <em>labels</em>. I have following toy data in my mind where I have features like 'units_sold' and 'num_employees' and a label of 'cost_$'. I would like to train the model to learn these features and label for a particular 'city' and 'store'. For example if I perform Linear Regression, the model learn intercept and coefficient for the city and store it relates to. When I input units_sold and num_employees for next year, I get the prediction.</p>\n\n<pre><code>city        store   units_sold  num_employees   cost_$\nNew York    A       10          4               11000\nNew York    B       12          4               11890\nNew York    C       14          5               15260\nNew York    D       17          6               17340\nLondon      A       23          5               22770\nLondon      B       27          6               25650\nLondon      C       22          3               21450\nParis       A       4           2               5200\nParis       B       7           3               9590\n</code></pre>\n\n<p>I'm trying to brainstorm about it and would like to know how to approach this problem?</p>\n",
                "tags": "<machine-learning><python><scikit-learn>",
                "answers": [
                    [
                        "39041",
                        "2",
                        "39034",
                        "",
                        "",
                        "<p>This is very little data so doing much with it is very difficult. especially considering you expect to get 'next year' estimates without having any historical data to base yourself from. </p>\n\n<p>However, if you want to be able to estimate a cost given your input features which are city, store, units_sold and num_employees then this problem setup is very standard in machine learning. </p>\n\n<p>First I will put your data into a pandas DataFrame and I will encode your categorical features using numerical values. I did this randomly, but I think you can get better results by getting the latitude and longitude of the stores, as well as some data about the neighborhood (density, wealth, etc.). </p>\n\n<pre><code>import pandas as pd\n\ndata = {'city': ['New York', 'New York', 'New York', 'New York', 'London', 'London', 'London', 'Paris', 'Paris'],\n        'store': ['A', 'B', 'C', 'D', 'A', 'B', 'C', 'A', 'B'],\n        'units_sold': [10, 12, 14, 17, 23, 27, 22, 4, 7],\n        'num_employees': [4,4,5,6,5,6,3,2,3],\n        'cost': [11000, 11890, 15260, 17340, 22770, 25650, 21450, 5200, 9560]}\n\ndf = pd.DataFrame(data)\n\ndf['store'] =df['store'].astype('category').cat.codes\ndf['city'] =df['city'].astype('category').cat.codes\n</code></pre>\n\n<p>When I am working with very little data I always like to pull some visualizations to give me some intuition about the data. Let's first see how the features are correlated. </p>\n\n<pre><code>import matplotlib.pyplot as plt\n\nplt.matshow(df.corr())\nplt.xticks(np.arange(5), df.columns, rotation=90)\nplt.yticks(np.arange(5), df.columns, rotation=0)\nplt.colorbar()\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/vJf61.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/vJf61.png\" alt=\"enter image description here\"></a></p>\n\n<p>We can see that the cost is associated directly with units_sold. That is not much of a surprise I guess. But it also correlates with the num_employees and is strongly inversely correlated with the city. </p>\n\n<p>If we plot the num_employees and units_sold we can see that the correlations observed above more clearly. </p>\n\n<p><a href=\"https://i.stack.imgur.com/Y8uNI.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/Y8uNI.png\" alt=\"enter image description here\"></a></p>\n\n<h1>A predictive model</h1>\n\n<p>Now we want to be able to give a model our inputs and get an estimation of the cost. </p>\n\n<p>Let's first put our data into a training and testing set. This is very problematic with such a small dataset because you have a very high probability of ending up with a training set that omits a city, or a store type. This will significantly affect the abiltiy of the model to predict an output for data it has never seen. </p>\n\n<p>The labels of the data are the cost. </p>\n\n<pre><code>import numpy as np\nfrom sklearn.model_selection import train_test_split\n\nX = np.asarray(df[['city', 'num_employees', 'store', 'units_sold']])\nY = np.asarray(df['cost'])\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n</code></pre>\n\n<p>Let's start with a standard linear regression</p>\n\n<p>from sklearn.linear_model import LinearRegression</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\n\nlineReg = LinearRegression()\nlineReg.fit(X_train, y_train)\nprint('Score: ', lineReg.score(X_test, y_test))\nprint('Weights: ', lineReg.coef_)\n\nplt.plot(lineReg.predict(X_test))\nplt.plot(y_test)\nplt.show()\n</code></pre>\n\n<blockquote>\n  <p>Score:  0.963554136721 <br/>\n  Weights:  [ 506.87136393  -15.48157725  376.79379444  920.01939237]</p>\n</blockquote>\n\n<p><a href=\"https://i.stack.imgur.com/oCGGe.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/oCGGe.png\" alt=\"enter image description here\"></a></p>\n\n<p>A better alternative is to use ridge regression. </p>\n\n<pre><code>from sklearn import linear_model\nreg = linear_model.Ridge (alpha = .5)\nreg.fit(X_train, y_train)\nprint('Score: ', reg.score(X_test, y_test))\nprint('Weights: ', reg.coef_)\n\nplt.plot(reg.predict(X_test))\nplt.plot(y_test)\nplt.show()\n</code></pre>\n\n<blockquote>\n  <p>Score:  0.971197683706 <br/>Weights:  [ 129.78467277    2.034588<br>\n  97.11724313  877.73906409]</p>\n</blockquote>\n\n<p><a href=\"https://i.stack.imgur.com/XXspr.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/XXspr.png\" alt=\"enter image description here\"></a></p>\n\n<p>If you do another split and rerun both these models you will see that the performance varies greatly for both of them as we expected due to the limited data. However, the effect is much more pronounced for the simple linear regression. </p>\n\n<p>To get a better idea of the actual results, let's do something a bit naughty. We will split the data over and over again to get different models and get the average of their scores.</p>\n\n<pre><code>scores = []\ncoefs = []\nfor i in range(1000):\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n    lineReg = LinearRegression()\n    lineReg.fit(X_train, y_train)\n    scores.append(lineReg.score(X_test, y_test))\n    coefs.append(lineReg.coef_)\nprint('Linear Regression')\nprint(np.mean(scores))\nprint(np.mean(coefs, axis=0))\n\nscores = []\ncoefs = []\nfor i in range(1000):\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n    lineReg = linear_model.Ridge (alpha = .5)\n    lineReg.fit(X_train, y_train)\n    scores.append(lineReg.score(X_test, y_test))\n    coefs.append(lineReg.coef_)\nprint('\\nRidge Regression')\nprint(np.mean(scores))\nprint(np.mean(coefs, axis=0))\n</code></pre>\n\n<blockquote>\n  <p>Linear Regression <br/>\n  -1.43683760609 <br/>\n  [ 1284.47358731  1251.8762943   -706.31897708   846.5465552 ] <br/>\n  <br/>\n  Ridge Regression <br/>\n  0.900877146134 <br/>\n  [ 228.05312491   95.33306385  123.49517018  873.49803782]</p>\n</blockquote>\n\n<p>We can see that across 1000 trials the ridge regression was by far the superior model. </p>\n\n<p>Now you can use this model to estimate costs by passing the model a vector with the features in the same order as the dataset as follows</p>\n\n<pre><code>reg.predict([[2,  4,  1,  12]])\n</code></pre>\n\n<p>The resulting score is</p>\n\n<blockquote>\n  <p>array([ 12853.2132658])</p>\n</blockquote>\n\n<hr>\n\n<p>This is not enough data to do any machine learning regression reliably. However you can get some insight into what factors affect your cost the most.</p>\n",
                        "",
                        "6"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17184",
            "_score": 14.846258,
            "_source": {
                "title": "Regression Algorithms in Production",
                "content": "Regression Algorithms in Production <p>I am interested in predicting if a doctor would prescribe a specific drug and have chosen Logistic Regression as a starting point.</p>\n\n<p>I have a few questions:</p>\n\n<ol>\n<li>Is feature selection the first step to take to choose relevant\nvariables?</li>\n<li>Is Logistic Regression only for binary output? For each doctor, can I get probability of drug prescription (e.g. doctor 1 = 0.87, doctor 2 = 0.56)?</li>\n<li>How can my model be deployed into production? Is it a huge task? </li>\n</ol>\n <machine-learning><python><regression><feature-selection><logistic-regression><p>I would not start with (manual) feature selection. Use Lasso instead to \"automatically\" shrink/select features (this is Logit with shrinking of features basically). <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">Logit</a> (or Logit with Lasso as here) is for binary cases, but you can also do \"Multinominal Logit\" (option <code>multi_class='multinomial'</code> in sklearn), which is for more than two classes. Usually you use <code>sklearn</code> in Python for such things. Also see the examples in the <code>sklearn</code> docs.</p>\n\n<p>Make sure you have a test and trainings set. Also make sure that you do not use data from your test set for training. Train on the train set only and use the test set to see how your model performs on data <strong>NOT</strong> seen during training. </p>\n\n<p>It is not clear what you mean when you say \"move to production\". This depends on your problem. You simply need to make predictions here, but the implementation is of course contingent on the environment. </p>\n\n<p>It is okay to play around with data. However, if you really want to go for serious data science, you should have a look at the methods behind all this magic. I recommend \"<a href=\"http://faculty.marshall.usc.edu/gareth-james/ISL/\" rel=\"nofollow noreferrer\">Introduction to Statistical Learning</a>\". It is a really good book with many code examples and it is not very technical.</p>\n\n<p>Note that there is no silver bullet. Lasso or Logit may be okay, but other methods may be better. This really depends on the problem/data.  </p>\n\n<p>Here is a little sample code for Lasso:</p>\n\n<pre><code># Split test/train\nfrom sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.20, random_state=7)\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\n\n# Perform lasso CV to get the best parameter alpha for regulation\nlasso = Lasso(max_iter=10000)\nlassocv = LassoCV(alphas=None, cv=10, max_iter=10000)\nlassocv.fit(xtrain, ytrain.values.ravel())\n\n# Fit lasso using the best alpha\nlasso.set_params(alpha=lassocv.alpha_)\nlasso.fit(xtrain, ytrain)\n\n# Look at results (coefficients)\nla1 = pd.Series(abs(lasso.coef_), name=\"lasso\")\nla2 = pd.Series(X.columns, name=\"names\")\ndflasso = pd.concat([la2,la1], axis=1)\ndflasso = dflasso.sort_values(by=['lasso'], ascending=False)\nprint(dflasso)\n\n# Look at AUC\nprint(\"AUC Lasso: %.3f\" %roc_auc_score(ytest.values, lasso.predict(xtest)))\n\n# Predict probs \nlasspreds0 = lasso.predict(xtest)\n# Classes\nlasspreds = np.round(lasspreds0)\n\n# Confusion matrix\ntnlog, fplog, fnlog, tplog = confusion_matrix(ytest, lasspreds).ravel() #y_true, y_pred\nprint(\"True negative: %s, False positive: %s, False negative: %s, True positive %s\" %(tnlog, fplog, fnlog, tplog))\nprint(\"Share false %.2f\" %(((fplog+fnlog)/(fplog+fnlog+tplog+tnlog))))\n\n# Look at probs\nprint(\"Min. prob. of belonging to class 0: %.3f\" %lasspreds0.min())\nprint(\"Max. prob. of belonging to class 0: %.3f\" %lasspreds0.max())\n</code></pre>\n\n<p><strong>EDIT:</strong></p>\n\n<p>Please note that the sklearn Lasso as described above does not do a logistic regression, which means predictions can be smaller zero or larger one. To use Lasso with Logit (ensuring predictions are zero or one), one can use <code>LogisticRegression</code>:</p>\n\n<pre><code>from sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import load_iris\nX, y = load_iris(return_X_y=True)\nlog = LogisticRegression(penalty='l1', solver='liblinear')\nlog.fit(X, y)\n</code></pre>\n<p>To add on @Peter's answer, you can use the method: <code>classifier.predict_proba(X_test)</code> to get the probability of <code>X_test</code> belonging to each class.</p>\n\n<p>This is called a <strong>soft prediction</strong> and would most likely need something called <a href=\"https://scikit-learn.org/stable/modules/calibration.html\" rel=\"nofollow noreferrer\">probability calibration</a> to get <em>usable</em> probabilities. <strong>Hard prediction</strong> is what the <code>classifier.predict()</code> method does. It takes the class with the <em>highest probability</em> and assigns its label to your <code>X_test</code>.</p>\n\n<p>PS : If you are sticking with Logistic Regression you won't need probability calibration since LR automatically optimizes logloss probabilities. However just in case you opted for another classifier, you will need to calibrate it.</p>\n",
                "codes": [
                    [
                        "# Split test/train\nfrom sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.20, random_state=7)\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\n\n# Perform lasso CV to get the best parameter alpha for regulation\nlasso = Lasso(max_iter=10000)\nlassocv = LassoCV(alphas=None, cv=10, max_iter=10000)\nlassocv.fit(xtrain, ytrain.values.ravel())\n\n# Fit lasso using the best alpha\nlasso.set_params(alpha=lassocv.alpha_)\nlasso.fit(xtrain, ytrain)\n\n# Look at results (coefficients)\nla1 = pd.Series(abs(lasso.coef_), name=\"lasso\")\nla2 = pd.Series(X.columns, name=\"names\")\ndflasso = pd.concat([la2,la1], axis=1)\ndflasso = dflasso.sort_values(by=['lasso'], ascending=False)\nprint(dflasso)\n\n# Look at AUC\nprint(\"AUC Lasso: %.3f\" %roc_auc_score(ytest.values, lasso.predict(xtest)))\n\n# Predict probs \nlasspreds0 = lasso.predict(xtest)\n# Classes\nlasspreds = np.round(lasspreds0)\n\n# Confusion matrix\ntnlog, fplog, fnlog, tplog = confusion_matrix(ytest, lasspreds).ravel() #y_true, y_pred\nprint(\"True negative: %s, False positive: %s, False negative: %s, True positive %s\" %(tnlog, fplog, fnlog, tplog))\nprint(\"Share false %.2f\" %(((fplog+fnlog)/(fplog+fnlog+tplog+tnlog))))\n\n# Look at probs\nprint(\"Min. prob. of belonging to class 0: %.3f\" %lasspreds0.min())\nprint(\"Max. prob. of belonging to class 0: %.3f\" %lasspreds0.max())\n",
                        "from sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import load_iris\nX, y = load_iris(return_X_y=True)\nlog = LogisticRegression(penalty='l1', solver='liblinear')\nlog.fit(X, y)\n"
                    ],
                    []
                ],
                "question_id:": "55699",
                "question_votes:": "1",
                "question_text:": "<p>I am interested in predicting if a doctor would prescribe a specific drug and have chosen Logistic Regression as a starting point.</p>\n\n<p>I have a few questions:</p>\n\n<ol>\n<li>Is feature selection the first step to take to choose relevant\nvariables?</li>\n<li>Is Logistic Regression only for binary output? For each doctor, can I get probability of drug prescription (e.g. doctor 1 = 0.87, doctor 2 = 0.56)?</li>\n<li>How can my model be deployed into production? Is it a huge task? </li>\n</ol>\n",
                "tags": "<machine-learning><python><regression><feature-selection><logistic-regression>",
                "answers": [
                    [
                        "55702",
                        "2",
                        "55699",
                        "",
                        "",
                        "<p>I would not start with (manual) feature selection. Use Lasso instead to \"automatically\" shrink/select features (this is Logit with shrinking of features basically). <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">Logit</a> (or Logit with Lasso as here) is for binary cases, but you can also do \"Multinominal Logit\" (option <code>multi_class='multinomial'</code> in sklearn), which is for more than two classes. Usually you use <code>sklearn</code> in Python for such things. Also see the examples in the <code>sklearn</code> docs.</p>\n\n<p>Make sure you have a test and trainings set. Also make sure that you do not use data from your test set for training. Train on the train set only and use the test set to see how your model performs on data <strong>NOT</strong> seen during training. </p>\n\n<p>It is not clear what you mean when you say \"move to production\". This depends on your problem. You simply need to make predictions here, but the implementation is of course contingent on the environment. </p>\n\n<p>It is okay to play around with data. However, if you really want to go for serious data science, you should have a look at the methods behind all this magic. I recommend \"<a href=\"http://faculty.marshall.usc.edu/gareth-james/ISL/\" rel=\"nofollow noreferrer\">Introduction to Statistical Learning</a>\". It is a really good book with many code examples and it is not very technical.</p>\n\n<p>Note that there is no silver bullet. Lasso or Logit may be okay, but other methods may be better. This really depends on the problem/data.  </p>\n\n<p>Here is a little sample code for Lasso:</p>\n\n<pre><code># Split test/train\nfrom sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.20, random_state=7)\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\n\n# Perform lasso CV to get the best parameter alpha for regulation\nlasso = Lasso(max_iter=10000)\nlassocv = LassoCV(alphas=None, cv=10, max_iter=10000)\nlassocv.fit(xtrain, ytrain.values.ravel())\n\n# Fit lasso using the best alpha\nlasso.set_params(alpha=lassocv.alpha_)\nlasso.fit(xtrain, ytrain)\n\n# Look at results (coefficients)\nla1 = pd.Series(abs(lasso.coef_), name=\"lasso\")\nla2 = pd.Series(X.columns, name=\"names\")\ndflasso = pd.concat([la2,la1], axis=1)\ndflasso = dflasso.sort_values(by=['lasso'], ascending=False)\nprint(dflasso)\n\n# Look at AUC\nprint(\"AUC Lasso: %.3f\" %roc_auc_score(ytest.values, lasso.predict(xtest)))\n\n# Predict probs \nlasspreds0 = lasso.predict(xtest)\n# Classes\nlasspreds = np.round(lasspreds0)\n\n# Confusion matrix\ntnlog, fplog, fnlog, tplog = confusion_matrix(ytest, lasspreds).ravel() #y_true, y_pred\nprint(\"True negative: %s, False positive: %s, False negative: %s, True positive %s\" %(tnlog, fplog, fnlog, tplog))\nprint(\"Share false %.2f\" %(((fplog+fnlog)/(fplog+fnlog+tplog+tnlog))))\n\n# Look at probs\nprint(\"Min. prob. of belonging to class 0: %.3f\" %lasspreds0.min())\nprint(\"Max. prob. of belonging to class 0: %.3f\" %lasspreds0.max())\n</code></pre>\n\n<p><strong>EDIT:</strong></p>\n\n<p>Please note that the sklearn Lasso as described above does not do a logistic regression, which means predictions can be smaller zero or larger one. To use Lasso with Logit (ensuring predictions are zero or one), one can use <code>LogisticRegression</code>:</p>\n\n<pre><code>from sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import load_iris\nX, y = load_iris(return_X_y=True)\nlog = LogisticRegression(penalty='l1', solver='liblinear')\nlog.fit(X, y)\n</code></pre>\n",
                        "",
                        "2"
                    ],
                    [
                        "55782",
                        "2",
                        "55699",
                        "",
                        "",
                        "<p>To add on @Peter's answer, you can use the method: <code>classifier.predict_proba(X_test)</code> to get the probability of <code>X_test</code> belonging to each class.</p>\n\n<p>This is called a <strong>soft prediction</strong> and would most likely need something called <a href=\"https://scikit-learn.org/stable/modules/calibration.html\" rel=\"nofollow noreferrer\">probability calibration</a> to get <em>usable</em> probabilities. <strong>Hard prediction</strong> is what the <code>classifier.predict()</code> method does. It takes the class with the <em>highest probability</em> and assigns its label to your <code>X_test</code>.</p>\n\n<p>PS : If you are sticking with Logistic Regression you won't need probability calibration since LR automatically optimizes logloss probabilities. However just in case you opted for another classifier, you will need to calibrate it.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8680",
            "_score": 14.829609,
            "_source": {
                "title": "Predicting household energy consumption?",
                "content": "Predicting household energy consumption? <p>I have a fairly simple dataset of energy consumption values generated every half hour. I want to train a model to predict the energy consumption at a particular time. </p>\n\n<p><a href=\"https://i.stack.imgur.com/y2Lbq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/y2Lbq.png\" alt=\"enter image description here\"></a></p>\n\n<p>How do I model time values?</p>\n <predictive-modeling><time-series><energy><p>At first sight, the total acumulated energy consumption seems to have a linear relation with time, so I suggest to try a <a href=\"https://en.wikipedia.org/wiki/Linear_regression\" rel=\"nofollow noreferrer\"><strong>linear regression</strong></a> at first. There are several libraries you can use to code it. I recommend you do it with <a href=\"https://pandas.pydata.org/\" rel=\"nofollow noreferrer\">pandas</a> and <a href=\"http://scikit-learn.org/\" rel=\"nofollow noreferrer\">sklearn</a>, here is an answer related to this: <a href=\"https://stackoverflow.com/questions/29934083/linear-regression-on-pandas-dataframe-using-sci-kit-learn\">answer</a>.</p>\n\n<p>If the relation is not linear, so I could try with a more complex model (but I suggest to keep simplicity at first). Since you are trying to predict a temporal serie, I would try with an <a href=\"https://en.wikipedia.org/wiki/Long_short-term_memory\" rel=\"nofollow noreferrer\"><strong>LSTM</strong></a> model. <a href=\"http://adventuresinmachinelearning.com/keras-lstm-tutorial/\" rel=\"nofollow noreferrer\">Here</a> is a tutorial to implement an LSTM neural network with <a href=\"https://keras.io\" rel=\"nofollow noreferrer\">keras</a>.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "31534",
                "question_votes:": "4",
                "question_text:": "<p>I have a fairly simple dataset of energy consumption values generated every half hour. I want to train a model to predict the energy consumption at a particular time. </p>\n\n<p><a href=\"https://i.stack.imgur.com/y2Lbq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/y2Lbq.png\" alt=\"enter image description here\"></a></p>\n\n<p>How do I model time values?</p>\n",
                "tags": "<predictive-modeling><time-series><energy>",
                "answers": [
                    [
                        "31539",
                        "2",
                        "31534",
                        "",
                        "",
                        "<p>At first sight, the total acumulated energy consumption seems to have a linear relation with time, so I suggest to try a <a href=\"https://en.wikipedia.org/wiki/Linear_regression\" rel=\"nofollow noreferrer\"><strong>linear regression</strong></a> at first. There are several libraries you can use to code it. I recommend you do it with <a href=\"https://pandas.pydata.org/\" rel=\"nofollow noreferrer\">pandas</a> and <a href=\"http://scikit-learn.org/\" rel=\"nofollow noreferrer\">sklearn</a>, here is an answer related to this: <a href=\"https://stackoverflow.com/questions/29934083/linear-regression-on-pandas-dataframe-using-sci-kit-learn\">answer</a>.</p>\n\n<p>If the relation is not linear, so I could try with a more complex model (but I suggest to keep simplicity at first). Since you are trying to predict a temporal serie, I would try with an <a href=\"https://en.wikipedia.org/wiki/Long_short-term_memory\" rel=\"nofollow noreferrer\"><strong>LSTM</strong></a> model. <a href=\"http://adventuresinmachinelearning.com/keras-lstm-tutorial/\" rel=\"nofollow noreferrer\">Here</a> is a tutorial to implement an LSTM neural network with <a href=\"https://keras.io\" rel=\"nofollow noreferrer\">keras</a>.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "978",
            "_score": 14.756989,
            "_source": {
                "title": "Implementing sklearn.linear_model.SGDClassifier using python",
                "content": "Implementing sklearn.linear_model.SGDClassifier using python <p>I have an excel file that contains details related to determining the quality of a wine and I want to implement the linear model concept using the function <strong>sklearn.linear_model.SGDClassifier(SVM => Hinge loss) and (Logarithmic regression =>log loss)</strong> using python. I learned the basics about these function through the <em>scikit learn</em> website and I am not able to implement the model using excel file. I am very new to python and machine learning and I finding it hard to implement the model. I opened the excel file in python and tried to take two columns [randomly] from the file and use that as an input to call the <strong>fit</strong> function available in the model. But, I got an error stating <strong>Unknown label type: array</strong>. I tried a couple of other methods too, but, nothing worked. Can someone guide me with the implementation process? </p>\n\n<pre><code>from xlrd import open_workbook\nfrom sklearn import linear_model\ni = 0\nfa = []\nph = []\n\nbook = open_workbook('F:/BIG DATA/winequality.xlsx')\nsheet = book.sheet_by_name('Sheet1')\nnum_rows = sheet.nrows - 1\nnum_cols = sheet.ncols - 1\ncurr_row = 0\nwhile curr_row &lt;num_rows:\n    curr_row += 1\n    cell_val = sheet.cell_value(curr_row,0)\n    cell_val1 = sheet.cell_value(curr_row,10)\n\n    fa.append([float(cell_val),float(cell_val1)])\n    cell_val2 = sheet.cell_value(curr_row,8)\n    ph.append(float(cell_val2))\n\nmodel = linear_model.SGDClassifier()\nprint(model.fit(fa,ph))\n</code></pre>\n\n<p><img src=\"https://i.stack.imgur.com/I9J8u.png\" alt=\"Screenshot\"></p>\n\n<p>The error message screenshot:</p>\n\n<p><img src=\"https://i.stack.imgur.com/lCJTu.png\" alt=\"ERROR\"></p>\n <machine-learning><classification><python><svm><regression><p>I think that this is the same issue as in this question: <a href=\"https://stackoverflow.com/questions/24923143/x-and-y-have-incompatible-shapes\">https://stackoverflow.com/questions/24923143/x-and-y-have-incompatible-shapes</a></p>\n\n<pre><code>The shape of X must be (n_samples, n_features) as explained in the SVC.fit\ndocstring. A 1-d array is interpreted as a single sample (for convenience when      \ndoing predictions on single samples). Reshape your X to (n_samples, 1).\n</code></pre>\n\n<p>That means you should use numpy.reshape to reshape the X column. If the data frame has n rows, you should use</p>\n\n<pre><code>X_new = X.reshape(n, 1)\n</code></pre>\n\n<p>Then use the fit method with X_new. Note: you probably don't need to do this if you use two or more X columns for your model fitting.</p>\n",
                "codes": [
                    [
                        "The shape of X must be (n_samples, n_features) as explained in the SVC.fit\ndocstring. A 1-d array is interpreted as a single sample (for convenience when      \ndoing predictions on single samples). Reshape your X to (n_samples, 1).\n",
                        "X_new = X.reshape(n, 1)\n"
                    ]
                ],
                "question_id:": "6123",
                "question_votes:": "2",
                "question_text:": "<p>I have an excel file that contains details related to determining the quality of a wine and I want to implement the linear model concept using the function <strong>sklearn.linear_model.SGDClassifier(SVM => Hinge loss) and (Logarithmic regression =>log loss)</strong> using python. I learned the basics about these function through the <em>scikit learn</em> website and I am not able to implement the model using excel file. I am very new to python and machine learning and I finding it hard to implement the model. I opened the excel file in python and tried to take two columns [randomly] from the file and use that as an input to call the <strong>fit</strong> function available in the model. But, I got an error stating <strong>Unknown label type: array</strong>. I tried a couple of other methods too, but, nothing worked. Can someone guide me with the implementation process? </p>\n\n<pre><code>from xlrd import open_workbook\nfrom sklearn import linear_model\ni = 0\nfa = []\nph = []\n\nbook = open_workbook('F:/BIG DATA/winequality.xlsx')\nsheet = book.sheet_by_name('Sheet1')\nnum_rows = sheet.nrows - 1\nnum_cols = sheet.ncols - 1\ncurr_row = 0\nwhile curr_row &lt;num_rows:\n    curr_row += 1\n    cell_val = sheet.cell_value(curr_row,0)\n    cell_val1 = sheet.cell_value(curr_row,10)\n\n    fa.append([float(cell_val),float(cell_val1)])\n    cell_val2 = sheet.cell_value(curr_row,8)\n    ph.append(float(cell_val2))\n\nmodel = linear_model.SGDClassifier()\nprint(model.fit(fa,ph))\n</code></pre>\n\n<p><img src=\"https://i.stack.imgur.com/I9J8u.png\" alt=\"Screenshot\"></p>\n\n<p>The error message screenshot:</p>\n\n<p><img src=\"https://i.stack.imgur.com/lCJTu.png\" alt=\"ERROR\"></p>\n",
                "tags": "<machine-learning><classification><python><svm><regression>",
                "answers": [
                    [
                        "6124",
                        "2",
                        "6123",
                        "",
                        "",
                        "<p>I think that this is the same issue as in this question: <a href=\"https://stackoverflow.com/questions/24923143/x-and-y-have-incompatible-shapes\">https://stackoverflow.com/questions/24923143/x-and-y-have-incompatible-shapes</a></p>\n\n<pre><code>The shape of X must be (n_samples, n_features) as explained in the SVC.fit\ndocstring. A 1-d array is interpreted as a single sample (for convenience when      \ndoing predictions on single samples). Reshape your X to (n_samples, 1).\n</code></pre>\n\n<p>That means you should use numpy.reshape to reshape the X column. If the data frame has n rows, you should use</p>\n\n<pre><code>X_new = X.reshape(n, 1)\n</code></pre>\n\n<p>Then use the fit method with X_new. Note: you probably don't need to do this if you use two or more X columns for your model fitting.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5333",
            "_score": 14.754501,
            "_source": {
                "title": "Logistic regression prediction changed after executed couple of time",
                "content": "Logistic regression prediction changed after executed couple of time <p>I noticed that after each time I execute the following lines of code, my results are different. Any idea why?\nI think  that the main issue here is this line of code\nBut I dont understand why?</p>\n\n<p>test_data['prediction']=sentiment_model.predict_proba(test_matrix)[:,0]</p>\n\n<p>What is the best way to add new column with .predict_prob()?</p>\n\n<pre><code>test_data['prediction'] = sentiment_model.predict_proba(test_matrix)[:,0]\ntest_data['prediction_label'] = sentiment_model.predict(test_matrix) \ntest_data['prediction'] = test_data['prediction'].apply(lambda x: round(x,2)) \ntest_data.sort_values(by='prediction', ascending=False, inplace=True) \ntest_data[test_data['name'] == 'Britax Decathlon Convertible Car Seat, Tiffany']\ntest_data.head() \n</code></pre>\n <python><scikit-learn><logistic-regression><pandas><probability><p>My guess - the order of labels entered as training set is different.<br>\nFrom the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba\" rel=\"nofollow noreferrer\">docs</a> -</p>\n\n<p>The returned estimates for all classes are ordered by the label of classes.</p>\n\n<p>So make sure you know which class prediction probability your slicing when using the [:, 0] in the first row. </p>\n<p>There is some randomness in the results from selecting/shuffling data that is used in the model.</p>\n\n<p>If you don't want that, you could set a fixed random_state (seed) in your model.</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "20430",
                "question_votes:": "1",
                "question_text:": "<p>I noticed that after each time I execute the following lines of code, my results are different. Any idea why?\nI think  that the main issue here is this line of code\nBut I dont understand why?</p>\n\n<p>test_data['prediction']=sentiment_model.predict_proba(test_matrix)[:,0]</p>\n\n<p>What is the best way to add new column with .predict_prob()?</p>\n\n<pre><code>test_data['prediction'] = sentiment_model.predict_proba(test_matrix)[:,0]\ntest_data['prediction_label'] = sentiment_model.predict(test_matrix) \ntest_data['prediction'] = test_data['prediction'].apply(lambda x: round(x,2)) \ntest_data.sort_values(by='prediction', ascending=False, inplace=True) \ntest_data[test_data['name'] == 'Britax Decathlon Convertible Car Seat, Tiffany']\ntest_data.head() \n</code></pre>\n",
                "tags": "<python><scikit-learn><logistic-regression><pandas><probability>",
                "answers": [
                    [
                        "20545",
                        "2",
                        "20430",
                        "",
                        "",
                        "<p>My guess - the order of labels entered as training set is different.<br>\nFrom the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba\" rel=\"nofollow noreferrer\">docs</a> -</p>\n\n<p>The returned estimates for all classes are ordered by the label of classes.</p>\n\n<p>So make sure you know which class prediction probability your slicing when using the [:, 0] in the first row. </p>\n",
                        "",
                        "1"
                    ],
                    [
                        "20433",
                        "2",
                        "20430",
                        "",
                        "",
                        "<p>There is some randomness in the results from selecting/shuffling data that is used in the model.</p>\n\n<p>If you don't want that, you could set a fixed random_state (seed) in your model.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4036",
            "_score": 14.743952,
            "_source": {
                "title": "What should I use if I have millions of categories for a sklearn predictive model?",
                "content": "What should I use if I have millions of categories for a sklearn predictive model? <p>I am trying to create a large model. One of the features is categorical, and it has almost 100 million entries.</p>\n\n<p>I have looked at sklearn LabelEncoder, but I am concerned that it will still create an ordering in my labels which I would like to avoid. If I use one hot encoding I would end up with really large vectors with 100 million dimensions. What are my options?</p>\n <python><scikit-learn><categorical-data><p>Unfortunately, AFAIK no sklearn model supports categorical variables.</p>\n\n<p>For instance, sklearn <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\" rel=\"nofollow noreferrer\">decision trees</a> only support rules such as <code>X&lt;n</code>, not <code>X==n</code> which would be desirable here.</p>\n\n<p>Also, the decision tree algorithm they implement only produces local one-look-ahead optimization. What this means is that, it may not produce rules such as <code>X&lt;n</code> followed by <code>X&gt;n-1</code>, even if such rule would be highly desirable.</p>\n\n<p>In the end you will end up with non-sense things like: <code>Car &gt; 1</code> and then <code>Car &lt; 6</code> where 1 is Volkswagen and 6 is Ferrari.</p>\n\n<p>The typical workaround is to use one-hot encoding, which might be a pain in the ass in your case. And then, it might not: sklearn decision tree supports sparse matrices, so the memory penalty would be low. You can use <a href=\"https://docs.scipy.org/doc/scipy-0.18.1/reference/sparse.html\" rel=\"nofollow noreferrer\">scipy</a> for this. (Sparse matrices stores data differently than regular matrices. Instead of requiring $n\\times m$ size, the memory requirement is proportional to the number of non-zeros in your matrix.) In terms of speed, it should not be any different than if the algorithm natively supported categorical variables.</p>\n\n<p>This being said, your data may not allow for use of sparse, if the rest of the features are non-sparse. I don't think scipy has support for a sparse-dense hybrid matrix.</p>\n\n<p>Another workaround I can think of would be to produce an Euclidean distance matrix between observations of the various categories (you may want to normalize first). Then group categories that are close together. Then build a hierarchical model, where you predict the final category for each category. In python, this is easier than it seems. You can create a class for your model using sklearn base classes.</p>\n\n<p>I love Python and sklearn. But I believe in using the right tool for each job. I would use R which has native support for categorial variables (they call them <code>factors</code>) and has a plethora of <a href=\"http://www.statmethods.net/advstats/cart.html\" rel=\"nofollow noreferrer\">decision tree packages.</a> (Note: xgboost for R does not support categorial variables, it ignores the factor class-type.) Weka could also be a good tool, which also has very powerful decision tree algorithms.</p>\n<p>You can use <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder\" rel=\"nofollow noreferrer\"><code>sklearn.preprocessing.OneHotEncoder</code></a> with <code>sparse=True</code>. It will return a a <code>scipy.sparse</code> matrix <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.fit\" rel=\"nofollow noreferrer\">some models</a> can work with. Your matrix will indeed be 100e6 columns wide, but not densely populated won't take a lot of RAM.</p>\n<p>An elastic net (also known as L1 and L2 regression) model can be an effective technique for dealing with very high dimensional problems. It's often used for dealing with genomic data. Elastic net documentation for sklearn can be found <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\" rel=\"nofollow noreferrer\" title=\"abc\">here</a>. Elastic net differentiates between variables that have predictive value and those that don't, and it often sets useless variables' coefficients to zero. This can dramatically reduce the number of categories in your problem.  </p>\n\n<p>You can take advantage of sklearn by creating \"dummy\" variables out of your categories. If one of your levels/columns were \"color\", and your categories were red, green and blue, then you would make two columns, e.g. for one for red and another for green (blue is not necessary by process of elimination). </p>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "16510",
                "question_votes:": "1",
                "question_text:": "<p>I am trying to create a large model. One of the features is categorical, and it has almost 100 million entries.</p>\n\n<p>I have looked at sklearn LabelEncoder, but I am concerned that it will still create an ordering in my labels which I would like to avoid. If I use one hot encoding I would end up with really large vectors with 100 million dimensions. What are my options?</p>\n",
                "tags": "<python><scikit-learn><categorical-data>",
                "answers": [
                    [
                        "16522",
                        "2",
                        "16510",
                        "",
                        "",
                        "<p>Unfortunately, AFAIK no sklearn model supports categorical variables.</p>\n\n<p>For instance, sklearn <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\" rel=\"nofollow noreferrer\">decision trees</a> only support rules such as <code>X&lt;n</code>, not <code>X==n</code> which would be desirable here.</p>\n\n<p>Also, the decision tree algorithm they implement only produces local one-look-ahead optimization. What this means is that, it may not produce rules such as <code>X&lt;n</code> followed by <code>X&gt;n-1</code>, even if such rule would be highly desirable.</p>\n\n<p>In the end you will end up with non-sense things like: <code>Car &gt; 1</code> and then <code>Car &lt; 6</code> where 1 is Volkswagen and 6 is Ferrari.</p>\n\n<p>The typical workaround is to use one-hot encoding, which might be a pain in the ass in your case. And then, it might not: sklearn decision tree supports sparse matrices, so the memory penalty would be low. You can use <a href=\"https://docs.scipy.org/doc/scipy-0.18.1/reference/sparse.html\" rel=\"nofollow noreferrer\">scipy</a> for this. (Sparse matrices stores data differently than regular matrices. Instead of requiring $n\\times m$ size, the memory requirement is proportional to the number of non-zeros in your matrix.) In terms of speed, it should not be any different than if the algorithm natively supported categorical variables.</p>\n\n<p>This being said, your data may not allow for use of sparse, if the rest of the features are non-sparse. I don't think scipy has support for a sparse-dense hybrid matrix.</p>\n\n<p>Another workaround I can think of would be to produce an Euclidean distance matrix between observations of the various categories (you may want to normalize first). Then group categories that are close together. Then build a hierarchical model, where you predict the final category for each category. In python, this is easier than it seems. You can create a class for your model using sklearn base classes.</p>\n\n<p>I love Python and sklearn. But I believe in using the right tool for each job. I would use R which has native support for categorial variables (they call them <code>factors</code>) and has a plethora of <a href=\"http://www.statmethods.net/advstats/cart.html\" rel=\"nofollow noreferrer\">decision tree packages.</a> (Note: xgboost for R does not support categorial variables, it ignores the factor class-type.) Weka could also be a good tool, which also has very powerful decision tree algorithms.</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "16534",
                        "2",
                        "16510",
                        "",
                        "",
                        "<p>You can use <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder\" rel=\"nofollow noreferrer\"><code>sklearn.preprocessing.OneHotEncoder</code></a> with <code>sparse=True</code>. It will return a a <code>scipy.sparse</code> matrix <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.fit\" rel=\"nofollow noreferrer\">some models</a> can work with. Your matrix will indeed be 100e6 columns wide, but not densely populated won't take a lot of RAM.</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "16533",
                        "2",
                        "16510",
                        "",
                        "",
                        "<p>An elastic net (also known as L1 and L2 regression) model can be an effective technique for dealing with very high dimensional problems. It's often used for dealing with genomic data. Elastic net documentation for sklearn can be found <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\" rel=\"nofollow noreferrer\" title=\"abc\">here</a>. Elastic net differentiates between variables that have predictive value and those that don't, and it often sets useless variables' coefficients to zero. This can dramatically reduce the number of categories in your problem.  </p>\n\n<p>You can take advantage of sklearn by creating \"dummy\" variables out of your categories. If one of your levels/columns were \"color\", and your categories were red, green and blue, then you would make two columns, e.g. for one for red and another for green (blue is not necessary by process of elimination). </p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10817",
            "_score": 14.714028,
            "_source": {
                "title": "The test of randomness was a logistic regression predicting missingness from all other variables",
                "content": "The test of randomness was a logistic regression predicting missingness from all other variables <pre><code> from sklearn.linear_model import LogisticRegression\n classifier = LogisticRegression()\n classifier.fit(X_train, y_train)\n\n # the overall equation was not significant\n (p &lt; .47) and all 95% confidence intervals for the odds ratios for the three\n variables included 1.00, indicating no significant relationship between \n missingness and any of the other variables.\n</code></pre>\n\n<p>I checked the online resources. I wonder how do I use sklearn package to achieve it, especially the overall significance of the equation.</p>\n <logistic-regression><missing-data>",
                "codes": [],
                "question_id:": "38473",
                "question_votes:": "1",
                "question_text:": "<pre><code> from sklearn.linear_model import LogisticRegression\n classifier = LogisticRegression()\n classifier.fit(X_train, y_train)\n\n # the overall equation was not significant\n (p &lt; .47) and all 95% confidence intervals for the odds ratios for the three\n variables included 1.00, indicating no significant relationship between \n missingness and any of the other variables.\n</code></pre>\n\n<p>I checked the online resources. I wonder how do I use sklearn package to achieve it, especially the overall significance of the equation.</p>\n",
                "tags": "<logistic-regression><missing-data>",
                "answers": []
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13743",
            "_score": 14.676489,
            "_source": {
                "title": "How to improve Regression Model with High Training Performance and Low Test Performance",
                "content": "How to improve Regression Model with High Training Performance and Low Test Performance <p>I am performing regression analysis on some data. I keep getting very high training score and low test score. My code is below, what can i do to enhance it? Thank you in advance.</p>\n\n<pre><code># coding: utf-8\n\n# In[1]:\n\n#Importing modules\nimport sys\nimport math \nimport itertools\nimport numpy as np\nimport pandas as pd\nfrom numpy import genfromtxt\nfrom matplotlib import style\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model\nfrom matplotlib import style, figure\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_validation import train_test_split\n\n\n# In[2]:\n\n\n#Importing data\ndf = np.genfromtxt('/Users/Studies/Machine_learning/reactivity/main_us.csv', delimiter=',')\n#To skip the header ad skiprpws=0\n\n\n# In[3]:\n\n\nX = df[0:,1:306]\ny = df[0:,0]\n\n\n# In[4]:\n\n\nprint (X).shape\nprint (y).shape\ndisplay (X)\ndisplay (y)\nprint (y)\n\n\n# In[5]:\n\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=4)\n\n\n# In[6]:\n\n\n#Apply StandardScaler for feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform (X_test)\nprint len(X_test), len(y_test)\n\n\n# In[7]:\n\n\n#Applying PCA for dimnetionality reduction\n\nfrom sklearn.decomposition import PCA\npca = PCA()\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\n\n#Checking shape after scaling\nprint (\"Checking shape after scaling\")\nprint (X_train.shape)\nprint (X_test.shape)\n\n\n#Variance/Values\nprint(\"Explained_variance_ratio\")\nprint(pca.explained_variance_ratio_)\nprint(\"Singular_values\")\nprint(pca.singular_values_)\n\n\n#Plotting\nprint (\"Graph\")\nplt.scatter (X_train[:,0], X_train[:,1], c=y_train, edgecolor='none', alpha=0.5, cmap=plt.cm.get_cmap('rainbow',6))\nplt.xlabel('Component 1')\nplt.ylabel('Component 2')\nplt.colorbar();\n\nprint ('You are looking at a high dimentional data explained by 2 components')\nprint ('Eeven though these components hold some information, but this to seperate the components apart')\n\n\nprint(pca.explained_variance_ratio_)\nprint(pca.singular_values_)\n\n#Checking shape after scaling \nprint (X_train.shape)\nprint (y_train.shape)\nprint (X_train.shape)\n\n\n# In[8]:\n\n\nalphas = 10**np.linspace(10,-2,100)*0.5\nalphas\n\n\n# In[9]:\n\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import Ridge, Lasso\n\nfor Model in [Ridge, Lasso]:\n    model = Model()\n    print('%s: %s' % (Model.__name__,\n                      cross_val_score(model, X, y).mean()))\n\n# Out[9]:\n\nRidge: -1.3841312374053019\nLasso: -1.164517926682712\n\n# In[10]:\n\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nalphas = np.logspace(-3, -1, 30)\n\nplt.figure(figsize=(5, 3))\n\nfor Model in [Lasso, Ridge]:\n    scores = [cross_val_score(Model(alpha), X, y, cv=3).mean()\n            for alpha in alphas]\n    plt.plot(alphas, scores, label=Model.__name__)\n\nplt.legend(loc='lower left')\nplt.xlabel('alpha')\nplt.ylabel('cross validation score')\nplt.tight_layout()\nplt.show()\n\n\n# In[11]:\n\n\n# alpha = 0.1\nmodel = Ridge(alpha = 0.1)\nmodel.fit(X_train,y_train)\nprint model.score(X_train,y_train)   \nprint model.score(X_test,y_test)\n\n# alpha = 0.01\nmodel1 = Ridge(alpha = 0.01)\nmodel.fit(X_train,y_train)\nprint model.score(X_train,y_train)   \nprint model.score(X_test,y_test)\n\n# alpha = 0.001\nmodel2 = Ridge(alpha = 0.001)\nmodel.fit(X_train,y_train)\nprint model.score(X_train,y_train)   \nprint model.score(X_test,y_test)\n\n# alpha = 0.0001\nmodel3 = Ridge(alpha = 0.0001)\nmodel.fit(X_train,y_train)\nprint model.score(X_train,y_train)   \nprint model.score(X_test,y_test)\n\n# Out[11]:\n\n0.9999996833724945\n-0.4120322763917558\n0.9999996833724945\n-0.4120322763917558\n0.9999996833724945\n-0.4120322763917558\n0.9999996833724945\n-0.4120322763917558\n\n\n# In[12]:\n\n\nmodelCV = RidgeCV(alphas = [0.1, 0.01, 0.001,0.0001], store_cv_values = True)\nmodelCV.fit(X_train,y_train)\nmodelCV.alpha_  #giving 0.1\nprint modelCV.score(X_train,y_train)  # giving 0.36898424479812919 which is the same score as ridge regression with alpha = 0.1\nprint modelCV.score(X_test,y_test) \n\n# Out[12]:\n\n0.9999996833724951\n-0.41203227638984496\n</code></pre>\n <machine-learning><scikit-learn><regression><machine-learning-model><ridge-regression><p>I am not going to much of your code as i can see you have only imported all the libraries:\nYou are facing with Over-fitting issue, The below are few of things when i come accross the same situation:</p>\n\n<ol>\n<li>Build multiple models and check Goodness of fit and then implement.</li>\n<li>Cross-validation is something which you should look into to make sure you have choosen the right model.</li>\n</ol>\n\n<p>How to deal with it:\n1. Train with more data:(It won\u2019t work every time, but training with more data can help \n   algorithms detect the signal better.)\n2. Remove features.(because every variable will have variance so even if it is not \n   significant it will try to explain the variance of an dependent variable during \n   training but in test, it will fail because it is not significant enough)\n3. Early stopping: (Early stopping refers stopping the training process before the \n   learner passes that point.)\n4. Regularization:(It is a way to get a stable model)\n5. Ensembling:(My favorite)\n   Ensembles are machine learning methods for combining predictions from multiple \n   separate models. There are a few different methods for ensembling, but the two most \n   common are:</p>\n\n<p>Bagging attempts to reduce the chance of overfitting complex models.</p>\n\n<p>It trains a large number of \"strong\" learners in parallel.\nA strong learner is a model that's relatively unconstrained.\nBagging then combines all the strong learners together in order to \"smooth out\" their predictions.\nBoosting attempts to improve the predictive flexibility of simple models.\nIt trains a large number of \"weak\" learners in sequence.\nA weak learner is a constrained model (i.e. you could limit the max depth of each decision tree).\nEach one in the sequence focuses on learning from the mistakes of the one before it.\nBoosting then combines all the weak learners into a single strong learner.\nWhile bagging and boosting are both ensemble methods, they approach the problem from opposite directions.\nBagging uses complex base models and tries to \"smooth out\" their predictions while boosting uses simple base models and tries to \"boost\" their aggregate complexity.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "46740",
                "question_votes:": "1",
                "question_text:": "<p>I am performing regression analysis on some data. I keep getting very high training score and low test score. My code is below, what can i do to enhance it? Thank you in advance.</p>\n\n<pre><code># coding: utf-8\n\n# In[1]:\n\n#Importing modules\nimport sys\nimport math \nimport itertools\nimport numpy as np\nimport pandas as pd\nfrom numpy import genfromtxt\nfrom matplotlib import style\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model\nfrom matplotlib import style, figure\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_validation import train_test_split\n\n\n# In[2]:\n\n\n#Importing data\ndf = np.genfromtxt('/Users/Studies/Machine_learning/reactivity/main_us.csv', delimiter=',')\n#To skip the header ad skiprpws=0\n\n\n# In[3]:\n\n\nX = df[0:,1:306]\ny = df[0:,0]\n\n\n# In[4]:\n\n\nprint (X).shape\nprint (y).shape\ndisplay (X)\ndisplay (y)\nprint (y)\n\n\n# In[5]:\n\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=4)\n\n\n# In[6]:\n\n\n#Apply StandardScaler for feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform (X_test)\nprint len(X_test), len(y_test)\n\n\n# In[7]:\n\n\n#Applying PCA for dimnetionality reduction\n\nfrom sklearn.decomposition import PCA\npca = PCA()\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\n\n#Checking shape after scaling\nprint (\"Checking shape after scaling\")\nprint (X_train.shape)\nprint (X_test.shape)\n\n\n#Variance/Values\nprint(\"Explained_variance_ratio\")\nprint(pca.explained_variance_ratio_)\nprint(\"Singular_values\")\nprint(pca.singular_values_)\n\n\n#Plotting\nprint (\"Graph\")\nplt.scatter (X_train[:,0], X_train[:,1], c=y_train, edgecolor='none', alpha=0.5, cmap=plt.cm.get_cmap('rainbow',6))\nplt.xlabel('Component 1')\nplt.ylabel('Component 2')\nplt.colorbar();\n\nprint ('You are looking at a high dimentional data explained by 2 components')\nprint ('Eeven though these components hold some information, but this to seperate the components apart')\n\n\nprint(pca.explained_variance_ratio_)\nprint(pca.singular_values_)\n\n#Checking shape after scaling \nprint (X_train.shape)\nprint (y_train.shape)\nprint (X_train.shape)\n\n\n# In[8]:\n\n\nalphas = 10**np.linspace(10,-2,100)*0.5\nalphas\n\n\n# In[9]:\n\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import Ridge, Lasso\n\nfor Model in [Ridge, Lasso]:\n    model = Model()\n    print('%s: %s' % (Model.__name__,\n                      cross_val_score(model, X, y).mean()))\n\n# Out[9]:\n\nRidge: -1.3841312374053019\nLasso: -1.164517926682712\n\n# In[10]:\n\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nalphas = np.logspace(-3, -1, 30)\n\nplt.figure(figsize=(5, 3))\n\nfor Model in [Lasso, Ridge]:\n    scores = [cross_val_score(Model(alpha), X, y, cv=3).mean()\n            for alpha in alphas]\n    plt.plot(alphas, scores, label=Model.__name__)\n\nplt.legend(loc='lower left')\nplt.xlabel('alpha')\nplt.ylabel('cross validation score')\nplt.tight_layout()\nplt.show()\n\n\n# In[11]:\n\n\n# alpha = 0.1\nmodel = Ridge(alpha = 0.1)\nmodel.fit(X_train,y_train)\nprint model.score(X_train,y_train)   \nprint model.score(X_test,y_test)\n\n# alpha = 0.01\nmodel1 = Ridge(alpha = 0.01)\nmodel.fit(X_train,y_train)\nprint model.score(X_train,y_train)   \nprint model.score(X_test,y_test)\n\n# alpha = 0.001\nmodel2 = Ridge(alpha = 0.001)\nmodel.fit(X_train,y_train)\nprint model.score(X_train,y_train)   \nprint model.score(X_test,y_test)\n\n# alpha = 0.0001\nmodel3 = Ridge(alpha = 0.0001)\nmodel.fit(X_train,y_train)\nprint model.score(X_train,y_train)   \nprint model.score(X_test,y_test)\n\n# Out[11]:\n\n0.9999996833724945\n-0.4120322763917558\n0.9999996833724945\n-0.4120322763917558\n0.9999996833724945\n-0.4120322763917558\n0.9999996833724945\n-0.4120322763917558\n\n\n# In[12]:\n\n\nmodelCV = RidgeCV(alphas = [0.1, 0.01, 0.001,0.0001], store_cv_values = True)\nmodelCV.fit(X_train,y_train)\nmodelCV.alpha_  #giving 0.1\nprint modelCV.score(X_train,y_train)  # giving 0.36898424479812919 which is the same score as ridge regression with alpha = 0.1\nprint modelCV.score(X_test,y_test) \n\n# Out[12]:\n\n0.9999996833724951\n-0.41203227638984496\n</code></pre>\n",
                "tags": "<machine-learning><scikit-learn><regression><machine-learning-model><ridge-regression>",
                "answers": [
                    [
                        "46767",
                        "2",
                        "46740",
                        "",
                        "",
                        "<p>I am not going to much of your code as i can see you have only imported all the libraries:\nYou are facing with Over-fitting issue, The below are few of things when i come accross the same situation:</p>\n\n<ol>\n<li>Build multiple models and check Goodness of fit and then implement.</li>\n<li>Cross-validation is something which you should look into to make sure you have choosen the right model.</li>\n</ol>\n\n<p>How to deal with it:\n1. Train with more data:(It won\u2019t work every time, but training with more data can help \n   algorithms detect the signal better.)\n2. Remove features.(because every variable will have variance so even if it is not \n   significant it will try to explain the variance of an dependent variable during \n   training but in test, it will fail because it is not significant enough)\n3. Early stopping: (Early stopping refers stopping the training process before the \n   learner passes that point.)\n4. Regularization:(It is a way to get a stable model)\n5. Ensembling:(My favorite)\n   Ensembles are machine learning methods for combining predictions from multiple \n   separate models. There are a few different methods for ensembling, but the two most \n   common are:</p>\n\n<p>Bagging attempts to reduce the chance of overfitting complex models.</p>\n\n<p>It trains a large number of \"strong\" learners in parallel.\nA strong learner is a model that's relatively unconstrained.\nBagging then combines all the strong learners together in order to \"smooth out\" their predictions.\nBoosting attempts to improve the predictive flexibility of simple models.\nIt trains a large number of \"weak\" learners in sequence.\nA weak learner is a constrained model (i.e. you could limit the max depth of each decision tree).\nEach one in the sequence focuses on learning from the mistakes of the one before it.\nBoosting then combines all the weak learners into a single strong learner.\nWhile bagging and boosting are both ensemble methods, they approach the problem from opposite directions.\nBagging uses complex base models and tries to \"smooth out\" their predictions while boosting uses simple base models and tries to \"boost\" their aggregate complexity.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "2185",
            "_score": 14.646408,
            "_source": {
                "title": "Does scikit-learn use regularization by default?",
                "content": "Does scikit-learn use regularization by default? <p>I just fitted a logistic curve to some fake data. I made the data essentially a step function. </p>\n\n<pre><code>data = -------------++++++++++++++\n</code></pre>\n\n<p>But when I look at the fitted curve, the slope is very small. The function that best minimizes the cost function, assuming cross entropy, is the step function. Why does it not look like a step function? Is there some regularization, L1 or L2, done by default?</p>\n\n<p><a href=\"https://i.stack.imgur.com/cDRXN.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/cDRXN.png\" alt=\"Logistic regression using scikit-learn\"></a></p>\n <logistic-regression><scikit-learn><p>Yes, there is regularization by default. It appears to be L2 regularization with a constant of 1. </p>\n\n<p>I played around with this and found out that L2 regularization with a constant of 1 gives me a fit that looks exactly like what sci-kit learn gives me without specifying regularization.</p>\n\n\n\n<pre><code>from sklearn.linear_model import LogisticRegression    \nmodel = LogisticRegression()\nmodel.fit(X, y)\n</code></pre>\n\n<p>is the same as</p>\n\n\n\n<pre><code>model = LogisticRegression(penalty=\"l2\", C=1)\nmodel.fit(X, y)\n</code></pre>\n\n<p>When I chose <code>C=10000</code>, I got something that looked a lot more like step function. </p>\n<p>Please take a look at the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow\">documentation</a>. The first line shows the default parameters, which include <code>penalty='l2'</code> and <code>C=1.0</code>.</p>\n\n<p>You actually cannot disable regularization completely, you can only regularize less... try setting <code>C=1e10</code> for example.</p>\n",
                "codes": [
                    [
                        "from sklearn.linear_model import LogisticRegression    \nmodel = LogisticRegression()\nmodel.fit(X, y)\n",
                        "model = LogisticRegression(penalty=\"l2\", C=1)\nmodel.fit(X, y)\n"
                    ],
                    []
                ],
                "question_id:": "10805",
                "question_votes:": "7",
                "question_text:": "<p>I just fitted a logistic curve to some fake data. I made the data essentially a step function. </p>\n\n<pre><code>data = -------------++++++++++++++\n</code></pre>\n\n<p>But when I look at the fitted curve, the slope is very small. The function that best minimizes the cost function, assuming cross entropy, is the step function. Why does it not look like a step function? Is there some regularization, L1 or L2, done by default?</p>\n\n<p><a href=\"https://i.stack.imgur.com/cDRXN.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/cDRXN.png\" alt=\"Logistic regression using scikit-learn\"></a></p>\n",
                "tags": "<logistic-regression><scikit-learn>",
                "answers": [
                    [
                        "10806",
                        "2",
                        "10805",
                        "",
                        "",
                        "<p>Yes, there is regularization by default. It appears to be L2 regularization with a constant of 1. </p>\n\n<p>I played around with this and found out that L2 regularization with a constant of 1 gives me a fit that looks exactly like what sci-kit learn gives me without specifying regularization.</p>\n\n\n\n<pre><code>from sklearn.linear_model import LogisticRegression    \nmodel = LogisticRegression()\nmodel.fit(X, y)\n</code></pre>\n\n<p>is the same as</p>\n\n\n\n<pre><code>model = LogisticRegression(penalty=\"l2\", C=1)\nmodel.fit(X, y)\n</code></pre>\n\n<p>When I chose <code>C=10000</code>, I got something that looked a lot more like step function. </p>\n",
                        "",
                        "5"
                    ],
                    [
                        "10807",
                        "2",
                        "10805",
                        "",
                        "",
                        "<p>Please take a look at the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow\">documentation</a>. The first line shows the default parameters, which include <code>penalty='l2'</code> and <code>C=1.0</code>.</p>\n\n<p>You actually cannot disable regularization completely, you can only regularize less... try setting <code>C=1e10</code> for example.</p>\n",
                        "",
                        "6"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10205",
            "_score": 14.62216,
            "_source": {
                "title": "Plotting in Multiple Linear Regression in Python 3",
                "content": "Plotting in Multiple Linear Regression in Python 3 <p>So I'm working on linear regression. So far I've managed to plot in linear regression, but currently I'm on Multiple Linear Regression and I couldn't manage to plot it, I can get some results if I enter the values manually, but I couldn't manage to plot it. Below is my code block and dataset and error, what can i change to plot it?</p>\n\n<p>Dataset: </p>\n\n<pre><code>deneyim maas    yas\n0.5 2500    22\n0   2250    21\n1   2750    23\n5   8000    25\n8   9000    28\n4   6900    23\n15  20000   35\n7   8500    29\n3   6000    22\n2   3500    23\n12  15000   32\n10  13000   30\n14  18000   34\n6   7500    27\n</code></pre>\n\n<p>Code block:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndataset = pd.read_csv(\"multiple-linear-regression-dataset.csv\",sep = \";\")\n\nx = dataset.iloc[:,[0,2]].values\ny = dataset.maas.values.reshape(-1,1)\n\nmultiple_lr = LinearRegression()\nmultiple_lr.fit(x,y)\n\nb0 = multiple_lr.intercept_\nb1 = multiple_lr.coef_\nb2 = b1\n\nmultiple_lr.predict(np.array([[10,35],[5,35]]))\n\narray = np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]).reshape(-1,1)\ny_head = multiple_lr.predict(array)\n\nplt.scatter(x,y)\nplt.plot(array, y_head, color = \"red\")\nplt.show()\n</code></pre>\n\n<p>It says <code>ValueError: shapes (16,1) and (2,1) not aligned: 1 (dim 1) != 2 (dim 0)</code> when I try to compile it.</p>\n <machine-learning><python><numpy><matplotlib><p>You cannot plot graph for multiple regression like that. Multiple regression yields graph with many dimensions. The dimension of the graph increases as your features increases. In your case, X has two features. Scatter plot takes argument with only one feature in X and only one class in y.Try taking only one feature for X and plot a scatter plot. By doing so you will be able to study the effect of each feature on the dependent variable (which i think is more easy to comprehend than multidimensional plots).I think your issue should resolve.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "36874",
                "question_votes:": "3",
                "question_text:": "<p>So I'm working on linear regression. So far I've managed to plot in linear regression, but currently I'm on Multiple Linear Regression and I couldn't manage to plot it, I can get some results if I enter the values manually, but I couldn't manage to plot it. Below is my code block and dataset and error, what can i change to plot it?</p>\n\n<p>Dataset: </p>\n\n<pre><code>deneyim maas    yas\n0.5 2500    22\n0   2250    21\n1   2750    23\n5   8000    25\n8   9000    28\n4   6900    23\n15  20000   35\n7   8500    29\n3   6000    22\n2   3500    23\n12  15000   32\n10  13000   30\n14  18000   34\n6   7500    27\n</code></pre>\n\n<p>Code block:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndataset = pd.read_csv(\"multiple-linear-regression-dataset.csv\",sep = \";\")\n\nx = dataset.iloc[:,[0,2]].values\ny = dataset.maas.values.reshape(-1,1)\n\nmultiple_lr = LinearRegression()\nmultiple_lr.fit(x,y)\n\nb0 = multiple_lr.intercept_\nb1 = multiple_lr.coef_\nb2 = b1\n\nmultiple_lr.predict(np.array([[10,35],[5,35]]))\n\narray = np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]).reshape(-1,1)\ny_head = multiple_lr.predict(array)\n\nplt.scatter(x,y)\nplt.plot(array, y_head, color = \"red\")\nplt.show()\n</code></pre>\n\n<p>It says <code>ValueError: shapes (16,1) and (2,1) not aligned: 1 (dim 1) != 2 (dim 0)</code> when I try to compile it.</p>\n",
                "tags": "<machine-learning><python><numpy><matplotlib>",
                "answers": [
                    [
                        "36887",
                        "2",
                        "36874",
                        "",
                        "",
                        "<p>You cannot plot graph for multiple regression like that. Multiple regression yields graph with many dimensions. The dimension of the graph increases as your features increases. In your case, X has two features. Scatter plot takes argument with only one feature in X and only one class in y.Try taking only one feature for X and plot a scatter plot. By doing so you will be able to study the effect of each feature on the dependent variable (which i think is more easy to comprehend than multidimensional plots).I think your issue should resolve.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12127",
            "_score": 14.602347,
            "_source": {
                "title": "Linear Regression Error",
                "content": "Linear Regression Error <p>I tried creating a simple linear regression model on just 30 rows of data. I got this error while trying to fit the model:</p>\n\n<pre><code>dataset = pd.read_csv('Salary_Data.csv')\nx=dataset.iloc[:, :-1]\ny=dataset.iloc[:, 1]\n\nfrom sklearn.cross_validation import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/3, random_state = 0)\nregressor = LinearRegression()\nregressor.fit(x_train, y_test)\n</code></pre>\n\n<p>Here is the error message I got:</p>\n\n<pre><code>ValueError                                Traceback (most recent call last)\n&lt;ipython-input-53-8dc82dc6fe8b&gt; in &lt;module&gt;()\n----&gt; 1 regressor.fit(x_train, y_test)\n\n~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py in fit(self, X, y, sample_weight)\n    480         n_jobs_ = self.n_jobs\n    481         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n--&gt; 482                          y_numeric=True, multi_output=True)\n    483 \n    484         if sample_weight is not None and np.atleast_1d(sample_weight).ndim &gt; 1:\n\n~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_X_y(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\n    581         y = y.astype(np.float64)\n    582 \n--&gt; 583     check_consistent_length(X, y)\n    584 \n    585     return X, y\n\n~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_consistent_length(*arrays)\n    202     if len(uniques) &gt; 1:\n    203         raise ValueError(\"Found input variables with inconsistent numbers of\"\n--&gt; 204                          \" samples: %r\" % [int(l) for l in lengths])\n    205 \n    206 \n\nValueError: Found input variables with inconsistent numbers of samples: [20, 10]\n</code></pre>\n <linear-regression><p>Your code has two typos:</p>\n\n<p><strong>1. Error when selecting data for the target variables.</strong> </p>\n\n<p>In the second line, you are using <code>[:, :-1]</code> which means that you select all rows, and all columns except the last one.</p>\n\n<p>In the third line, you are using <code>[:, 1]</code> which means that you select all rows, and only the first column instead of the last.\nInstead, you want to select the columns of your target variable, i.e. the last one:</p>\n\n<pre><code>y=dataset.iloc[:, -1]\n</code></pre>\n\n<p><strong>2. Error when fitting the model</strong></p>\n\n<p>You are fitting your model using the X <em>training</em> set and the Y <em>validation</em> set. They have different length. Use this instead:</p>\n\n<pre><code>regressor.fit(x_train, y_train)\n</code></pre>\n<p>It seems there is a problem in the way you did split X variable. You can use the below format</p>\n\n<pre><code>X = df.loc[:, df.columns != 'Dependent Variable']\ny = df.loc[:, df.columns == 'Dependent Variable']\n</code></pre>\n<p><strong>x=dataset.iloc[:, :-1]  :</strong>: It should be the Y actually, because you are selecting all rows and throwing one column out that is your target Y which is last column(-1).</p>\n\n<p><strong>Y=dataset.iloc[:, 1]</strong>  :: Here again you are choosing second column only, i don't know why?</p>\n\n<p>In X you need all rows &amp; columns exceplt last column which is actually your target variable. Please revisit these two code-lines. </p>\n\n<p>To choose columns &amp; rows together :: use this. </p>\n\n<p><strong>x= data.iloc[:, 0:2]</strong> # first two columns of data frame with all rows</p>\n\n<p><strong>finally, thes two code line will be like:</strong> </p>\n\n<p>x= data.iloc[:, 0:2]<br>\ny= dataset.iloc[:, :-1]</p>\n",
                "codes": [
                    [
                        "y=dataset.iloc[:, -1]\n",
                        "regressor.fit(x_train, y_train)\n"
                    ],
                    [
                        "X = df.loc[:, df.columns != 'Dependent Variable']\ny = df.loc[:, df.columns == 'Dependent Variable']\n"
                    ],
                    []
                ],
                "question_id:": "42665",
                "question_votes:": "",
                "question_text:": "<p>I tried creating a simple linear regression model on just 30 rows of data. I got this error while trying to fit the model:</p>\n\n<pre><code>dataset = pd.read_csv('Salary_Data.csv')\nx=dataset.iloc[:, :-1]\ny=dataset.iloc[:, 1]\n\nfrom sklearn.cross_validation import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/3, random_state = 0)\nregressor = LinearRegression()\nregressor.fit(x_train, y_test)\n</code></pre>\n\n<p>Here is the error message I got:</p>\n\n<pre><code>ValueError                                Traceback (most recent call last)\n&lt;ipython-input-53-8dc82dc6fe8b&gt; in &lt;module&gt;()\n----&gt; 1 regressor.fit(x_train, y_test)\n\n~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py in fit(self, X, y, sample_weight)\n    480         n_jobs_ = self.n_jobs\n    481         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n--&gt; 482                          y_numeric=True, multi_output=True)\n    483 \n    484         if sample_weight is not None and np.atleast_1d(sample_weight).ndim &gt; 1:\n\n~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_X_y(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\n    581         y = y.astype(np.float64)\n    582 \n--&gt; 583     check_consistent_length(X, y)\n    584 \n    585     return X, y\n\n~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_consistent_length(*arrays)\n    202     if len(uniques) &gt; 1:\n    203         raise ValueError(\"Found input variables with inconsistent numbers of\"\n--&gt; 204                          \" samples: %r\" % [int(l) for l in lengths])\n    205 \n    206 \n\nValueError: Found input variables with inconsistent numbers of samples: [20, 10]\n</code></pre>\n",
                "tags": "<linear-regression>",
                "answers": [
                    [
                        "42677",
                        "2",
                        "42665",
                        "",
                        "",
                        "<p>Your code has two typos:</p>\n\n<p><strong>1. Error when selecting data for the target variables.</strong> </p>\n\n<p>In the second line, you are using <code>[:, :-1]</code> which means that you select all rows, and all columns except the last one.</p>\n\n<p>In the third line, you are using <code>[:, 1]</code> which means that you select all rows, and only the first column instead of the last.\nInstead, you want to select the columns of your target variable, i.e. the last one:</p>\n\n<pre><code>y=dataset.iloc[:, -1]\n</code></pre>\n\n<p><strong>2. Error when fitting the model</strong></p>\n\n<p>You are fitting your model using the X <em>training</em> set and the Y <em>validation</em> set. They have different length. Use this instead:</p>\n\n<pre><code>regressor.fit(x_train, y_train)\n</code></pre>\n",
                        "",
                        "1"
                    ],
                    [
                        "42667",
                        "2",
                        "42665",
                        "",
                        "",
                        "<p>It seems there is a problem in the way you did split X variable. You can use the below format</p>\n\n<pre><code>X = df.loc[:, df.columns != 'Dependent Variable']\ny = df.loc[:, df.columns == 'Dependent Variable']\n</code></pre>\n",
                        "",
                        ""
                    ],
                    [
                        "44051",
                        "2",
                        "42665",
                        "",
                        "",
                        "<p><strong>x=dataset.iloc[:, :-1]  :</strong>: It should be the Y actually, because you are selecting all rows and throwing one column out that is your target Y which is last column(-1).</p>\n\n<p><strong>Y=dataset.iloc[:, 1]</strong>  :: Here again you are choosing second column only, i don't know why?</p>\n\n<p>In X you need all rows &amp; columns exceplt last column which is actually your target variable. Please revisit these two code-lines. </p>\n\n<p>To choose columns &amp; rows together :: use this. </p>\n\n<p><strong>x= data.iloc[:, 0:2]</strong> # first two columns of data frame with all rows</p>\n\n<p><strong>finally, thes two code line will be like:</strong> </p>\n\n<p>x= data.iloc[:, 0:2]<br>\ny= dataset.iloc[:, :-1]</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "1805",
            "_score": 14.600713,
            "_source": {
                "title": "Using machine learning specifically for feature analysis, not predictions",
                "content": "Using machine learning specifically for feature analysis, not predictions <p>I'm new to machine learning and have spent the last couple months having a blast using Sci-Kit Learn to try to understand the basics of building feature sets and predictive models.</p>\n\n<p>Now I'm trying to use ML on a data set not to predict future values but to understand the importance and direction (positive or negative) of each feature.</p>\n\n<p>My features (X) are boolean and integer values that describe a product. My target (y) is the sales of the product. I have ~15,000 observations with 16 features a piece.</p>\n\n<p>With my limited ML knowledge to this point, I'm confident that I can predict (with some level of accuracy) a new y based on a new set of features X. However I'm struggling to coherently identify, report on and present <em>the importance and direction of each feature that makes up X</em>.</p>\n\n<p>Thus far, I've taken a two-step approach:</p>\n\n<ol>\n<li>Use a linear regression to observe coefficients</li>\n<li>Use a random forest to observe feature importance</li>\n</ol>\n\n<p><strong>The code</strong></p>\n\n<p>First, I try to get the directional impact of each feature:</p>\n\n<pre><code>from sklearn import linear_model\nlinreg = linear_model.LinearRegression()\nlinreg.fit(X, y)\ncoef = linreg.coef_\n...\n</code></pre>\n\n<p>Second, I try to get the importance of each feature:</p>\n\n<pre><code>from sklearn import ensemble\nforest = ensemble.RandomForestRegressor()\nforest.fit(X, y)\nimportance = forest.feature_importances_\n...\n</code></pre>\n\n<p>Then I multiply the two derived values together for each feature and end up with some value that maybe perhaps could be the information I'm looking for!</p>\n\n<p>I'd love to know if I'm on the right track with any of this. Is this a common use case for ML? Are there tools, ideas, packages I should focus on to help guide me?</p>\n\n<p>Thank you very much.</p>\n <machine-learning><scikit-learn><p>You don't need the linear regression to understand the effect of features in your random forest, you're better off looking at the partial dependence plots directly, this what you get when you hold all the variables fixed, and you vary one at a time. You can plot these using <code>sklearn.ensemble.partial_depence.plot_partial_dependence</code>. Take a look at the <a href=\"http://scikit-learn.org/stable/modules/ensemble.html#partial-dependence\" rel=\"noreferrer\">documentation</a> for an example of how to use it.</p>\n\n<p>Another type of model that can be useful for exploratory data analysis is a <code>DecisionTreeClassifier</code>, you can produce a graphical representation of this using <code>export_graphviz</code></p>\n",
                "codes": [
                    []
                ],
                "question_id:": "9783",
                "question_votes:": "4",
                "question_text:": "<p>I'm new to machine learning and have spent the last couple months having a blast using Sci-Kit Learn to try to understand the basics of building feature sets and predictive models.</p>\n\n<p>Now I'm trying to use ML on a data set not to predict future values but to understand the importance and direction (positive or negative) of each feature.</p>\n\n<p>My features (X) are boolean and integer values that describe a product. My target (y) is the sales of the product. I have ~15,000 observations with 16 features a piece.</p>\n\n<p>With my limited ML knowledge to this point, I'm confident that I can predict (with some level of accuracy) a new y based on a new set of features X. However I'm struggling to coherently identify, report on and present <em>the importance and direction of each feature that makes up X</em>.</p>\n\n<p>Thus far, I've taken a two-step approach:</p>\n\n<ol>\n<li>Use a linear regression to observe coefficients</li>\n<li>Use a random forest to observe feature importance</li>\n</ol>\n\n<p><strong>The code</strong></p>\n\n<p>First, I try to get the directional impact of each feature:</p>\n\n<pre><code>from sklearn import linear_model\nlinreg = linear_model.LinearRegression()\nlinreg.fit(X, y)\ncoef = linreg.coef_\n...\n</code></pre>\n\n<p>Second, I try to get the importance of each feature:</p>\n\n<pre><code>from sklearn import ensemble\nforest = ensemble.RandomForestRegressor()\nforest.fit(X, y)\nimportance = forest.feature_importances_\n...\n</code></pre>\n\n<p>Then I multiply the two derived values together for each feature and end up with some value that maybe perhaps could be the information I'm looking for!</p>\n\n<p>I'd love to know if I'm on the right track with any of this. Is this a common use case for ML? Are there tools, ideas, packages I should focus on to help guide me?</p>\n\n<p>Thank you very much.</p>\n",
                "tags": "<machine-learning><scikit-learn>",
                "answers": [
                    [
                        "9787",
                        "2",
                        "9783",
                        "",
                        "",
                        "<p>You don't need the linear regression to understand the effect of features in your random forest, you're better off looking at the partial dependence plots directly, this what you get when you hold all the variables fixed, and you vary one at a time. You can plot these using <code>sklearn.ensemble.partial_depence.plot_partial_dependence</code>. Take a look at the <a href=\"http://scikit-learn.org/stable/modules/ensemble.html#partial-dependence\" rel=\"noreferrer\">documentation</a> for an example of how to use it.</p>\n\n<p>Another type of model that can be useful for exploratory data analysis is a <code>DecisionTreeClassifier</code>, you can produce a graphical representation of this using <code>export_graphviz</code></p>\n",
                        "",
                        "6"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "528",
            "_score": 14.600261,
            "_source": {
                "title": "What cost function and penalty are suitable for imbalanced datasets?",
                "content": "What cost function and penalty are suitable for imbalanced datasets? <p>For an imbalanced data set, is it better to choose an L1 or L2 regularization?</p>\n\n<p>Is there a cost function more suitable for imbalanced datasets to improve the model score (<code>log_loss</code> in particular)? </p>\n <machine-learning><classification><deep-learning><scikit-learn><logistic-regression><p>So you ask <strong>how does class imbalance affect classifier performance under different losses?</strong> \nYou can make a numeric experiment. </p>\n\n<p>I do binary classification by logistic regression. However, the intuition extends on the broader class of models, in particular, neural networks. I measure performance by cross-validated ROC AUC, because it is insensitive to class imbalance. I use an inner loop of cross validation to find the optimal penalties for L1 and L2 regularization on each dataset.</p>\n\n<pre><code>from sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nimport matplotlib.pyplot as plt\n\ncvs_no_reg = []\ncvs_lasso = []\ncvs_ridge = []\nimb = [0.5, 0.4, 0.3, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005, 0.002, 0.001]\nCs = [1e-5, 3e-5, 1e-4, 3e-4, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1]\nfor w in imb:\n    X, y = make_classification(random_state=1, weights=[w, 1-w], n_samples=10000)\n    cvs_no_reg.append(cross_val_score(LogisticRegression(C=1e10), X, y, scoring='roc_auc').mean())\n    cvs_ridge.append(cross_val_score(LogisticRegressionCV(Cs=Cs, penalty='l2'), X, y, scoring='roc_auc').mean())\n    cvs_lasso.append(cross_val_score(LogisticRegressionCV(Cs=Cs, solver='liblinear', penalty='l1'), X, y, scoring='roc_auc').mean())\n\nplt.plot(imb, cvs_no_reg)\nplt.plot(imb, cvs_ridge)\nplt.plot(imb, cvs_lasso)\nplt.xscale('log')\nplt.xlabel('fraction of the rare class')\nplt.ylabel('cross-validated ROC AUC')\nplt.legend(['no penalty', 'ridge', 'lasso'])\nplt.title('Sensitivity to imbalance under different penalties')\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/be35G.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/be35G.png\" alt=\"enter image description here\"></a></p>\n\n<p>You can see that under high imbalance (left-hand side of the picture) <strong>L1 regularization performs better</strong> than L2, and both better than no regularization. </p>\n\n<p>But if the imbalance is not so serious (the smallest class share is 0.03 and higher), all the 3 models perform equally well.</p>\n\n<p>As for the second question, <strong>what is a good loss function for imbalanced datasets</strong>, I will answer that <strong>log loss is good enough</strong>. Its useful property is that it doesn't make your model turn the probability of a rare class to zero, even if it is <em>very very</em> rare.</p>\n<p>If you have an imbalanced dataset you usually want to make it balanced to begin with, since that will artificially affect your scores.</p>\n\n<p>Now, you want to be measuring precision and recall, since those can capture a bit better the imbalanced dataset biases.</p>\n\n<p>L1 or L2 won't perform particularly better in a balanced or unbalanced dataset, what you want to do is call elastic nets (which is a combination of the two) and do cross validation over the coefficients of each of the regularizers. </p>\n\n<p>Also, doing grid search is very odd, you are better using just cross validation and see what parameters work better.</p>\n\n<p>They even have ElasticNetCV, which does that part for you (<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV\" rel=\"nofollow\">http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV</a>)</p>\n<p>If you have unbalanced data, at first I recommend you try to have real data. I mean do not replicate your data by hand if you don't have balanced data. You should never ever change the distribution of your data. Although it may seem that you reduce the Bayse error, your classifier won't do well in your specified application. I have two suggestions for imbalanced data:</p>\n\n<ul>\n<li>Use class weights to improve your cost function. For the rare class use a much larger value than the dominant class.</li>\n<li>Use <code>F1</code> score to evaluate your classifier</li>\n</ul>\n\n<blockquote>\n  <p>For an imbalanced set of data is it better to choose an L1 or L2 regularization</p>\n</blockquote>\n\n<p>These are for dealing with over-fitting problem. First of all you have to learn the training data to solve high bias problem. The latter is more common in usual tasks. They are just fine for imbalanced data set but consider the point that first you have to deal with high bias problem, learning the data, then deal with high variance problem, avoiding over-fitting.</p>\n",
                "codes": [
                    [
                        "from sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nimport matplotlib.pyplot as plt\n\ncvs_no_reg = []\ncvs_lasso = []\ncvs_ridge = []\nimb = [0.5, 0.4, 0.3, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005, 0.002, 0.001]\nCs = [1e-5, 3e-5, 1e-4, 3e-4, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1]\nfor w in imb:\n    X, y = make_classification(random_state=1, weights=[w, 1-w], n_samples=10000)\n    cvs_no_reg.append(cross_val_score(LogisticRegression(C=1e10), X, y, scoring='roc_auc').mean())\n    cvs_ridge.append(cross_val_score(LogisticRegressionCV(Cs=Cs, penalty='l2'), X, y, scoring='roc_auc').mean())\n    cvs_lasso.append(cross_val_score(LogisticRegressionCV(Cs=Cs, solver='liblinear', penalty='l1'), X, y, scoring='roc_auc').mean())\n\nplt.plot(imb, cvs_no_reg)\nplt.plot(imb, cvs_ridge)\nplt.plot(imb, cvs_lasso)\nplt.xscale('log')\nplt.xlabel('fraction of the rare class')\nplt.ylabel('cross-validated ROC AUC')\nplt.legend(['no penalty', 'ridge', 'lasso'])\nplt.title('Sensitivity to imbalance under different penalties')\nplt.show()\n"
                    ],
                    [],
                    []
                ],
                "question_id:": "3699",
                "question_votes:": "4",
                "question_text:": "<p>For an imbalanced data set, is it better to choose an L1 or L2 regularization?</p>\n\n<p>Is there a cost function more suitable for imbalanced datasets to improve the model score (<code>log_loss</code> in particular)? </p>\n",
                "tags": "<machine-learning><classification><deep-learning><scikit-learn><logistic-regression>",
                "answers": [
                    [
                        "26710",
                        "2",
                        "3699",
                        "",
                        "",
                        "<p>So you ask <strong>how does class imbalance affect classifier performance under different losses?</strong> \nYou can make a numeric experiment. </p>\n\n<p>I do binary classification by logistic regression. However, the intuition extends on the broader class of models, in particular, neural networks. I measure performance by cross-validated ROC AUC, because it is insensitive to class imbalance. I use an inner loop of cross validation to find the optimal penalties for L1 and L2 regularization on each dataset.</p>\n\n<pre><code>from sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nimport matplotlib.pyplot as plt\n\ncvs_no_reg = []\ncvs_lasso = []\ncvs_ridge = []\nimb = [0.5, 0.4, 0.3, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005, 0.002, 0.001]\nCs = [1e-5, 3e-5, 1e-4, 3e-4, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1]\nfor w in imb:\n    X, y = make_classification(random_state=1, weights=[w, 1-w], n_samples=10000)\n    cvs_no_reg.append(cross_val_score(LogisticRegression(C=1e10), X, y, scoring='roc_auc').mean())\n    cvs_ridge.append(cross_val_score(LogisticRegressionCV(Cs=Cs, penalty='l2'), X, y, scoring='roc_auc').mean())\n    cvs_lasso.append(cross_val_score(LogisticRegressionCV(Cs=Cs, solver='liblinear', penalty='l1'), X, y, scoring='roc_auc').mean())\n\nplt.plot(imb, cvs_no_reg)\nplt.plot(imb, cvs_ridge)\nplt.plot(imb, cvs_lasso)\nplt.xscale('log')\nplt.xlabel('fraction of the rare class')\nplt.ylabel('cross-validated ROC AUC')\nplt.legend(['no penalty', 'ridge', 'lasso'])\nplt.title('Sensitivity to imbalance under different penalties')\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/be35G.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/be35G.png\" alt=\"enter image description here\"></a></p>\n\n<p>You can see that under high imbalance (left-hand side of the picture) <strong>L1 regularization performs better</strong> than L2, and both better than no regularization. </p>\n\n<p>But if the imbalance is not so serious (the smallest class share is 0.03 and higher), all the 3 models perform equally well.</p>\n\n<p>As for the second question, <strong>what is a good loss function for imbalanced datasets</strong>, I will answer that <strong>log loss is good enough</strong>. Its useful property is that it doesn't make your model turn the probability of a rare class to zero, even if it is <em>very very</em> rare.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "5031",
                        "2",
                        "3699",
                        "",
                        "",
                        "<p>If you have an imbalanced dataset you usually want to make it balanced to begin with, since that will artificially affect your scores.</p>\n\n<p>Now, you want to be measuring precision and recall, since those can capture a bit better the imbalanced dataset biases.</p>\n\n<p>L1 or L2 won't perform particularly better in a balanced or unbalanced dataset, what you want to do is call elastic nets (which is a combination of the two) and do cross validation over the coefficients of each of the regularizers. </p>\n\n<p>Also, doing grid search is very odd, you are better using just cross validation and see what parameters work better.</p>\n\n<p>They even have ElasticNetCV, which does that part for you (<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV\" rel=\"nofollow\">http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV</a>)</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "26730",
                        "2",
                        "3699",
                        "",
                        "",
                        "<p>If you have unbalanced data, at first I recommend you try to have real data. I mean do not replicate your data by hand if you don't have balanced data. You should never ever change the distribution of your data. Although it may seem that you reduce the Bayse error, your classifier won't do well in your specified application. I have two suggestions for imbalanced data:</p>\n\n<ul>\n<li>Use class weights to improve your cost function. For the rare class use a much larger value than the dominant class.</li>\n<li>Use <code>F1</code> score to evaluate your classifier</li>\n</ul>\n\n<blockquote>\n  <p>For an imbalanced set of data is it better to choose an L1 or L2 regularization</p>\n</blockquote>\n\n<p>These are for dealing with over-fitting problem. First of all you have to learn the training data to solve high bias problem. The latter is more common in usual tasks. They are just fine for imbalanced data set but consider the point that first you have to deal with high bias problem, learning the data, then deal with high variance problem, avoiding over-fitting.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15957",
            "_score": 14.549325,
            "_source": {
                "title": "Expected 2D array, got scalar array instead",
                "content": "Expected 2D array, got scalar array instead <p>Can anyone help me with this error. I did the following code but it does not work and I am getting the following error:</p>\n\n<pre><code>ValueError: Expected 2D array, got scalar array instead:\narray=6.5. Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample. \n</code></pre>\n\n<p>My code:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport pandas\ndataset = pandas.read_excel('PEG RATIOS.xlsx')\n\nX = dataset.iloc[:, 2].values\nX =X.reshape(-1,1)\ny = dataset.iloc[:, 3].values\ny = y.reshape (-1,1)\n\n\nfrom sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\nfrom sklearn.preprocessing import PolynomialFeatures\npoly_reg = PolynomialFeatures(degree = 4)\nX_poly = poly_reg.fit_transform(X)\npoly_reg.fit(X_poly, y)\nlin_reg_2 = LinearRegression()\nlin_reg_2.fit(X_poly, y)\n\nX_grid = np.arange(min(X), max(X), 0.1)\nX_grid = X_grid.reshape((len(X_grid), 1))\nplt.scatter(X, y, color = 'red')\nplt.plot(X_grid, lin_reg_2.predict(poly_reg.fit_transform(X_grid)), color = 'blue')\nplt.title('PEG Ratios verrus Exoected Growth: Semiconductor Firms')\nplt.xlabel('Expected Growth rate')\nplt.ylabel('PEGH Ratio')\nplt.show()\nlin_reg_2.predict(poly_reg.fit_transform(6.5))\n</code></pre>\n <machine-learning><python><p>The error itself solves your problem. Just follow what it says. The predict() method takes a 2d array of values you want to predict on. Each item in the array is a \"point\" you want your model to predict on. So try,</p>\n\n<pre><code>lin_reg_2.predict(poly_reg.fit_transform([[6.5]]))\n</code></pre>\n\n<p>Here the input is a 2D array of shape <code>(1,1)</code>.</p>\n\n<p>Or as the error suggest try:</p>\n\n<pre><code>lin_reg_2.predict(np.array([6.5]).reshape(1, 1))\n</code></pre>\n",
                "codes": [
                    [
                        "lin_reg_2.predict(poly_reg.fit_transform([[6.5]]))\n",
                        "lin_reg_2.predict(np.array([6.5]).reshape(1, 1))\n"
                    ]
                ],
                "question_id:": "53048",
                "question_votes:": "2",
                "question_text:": "<p>Can anyone help me with this error. I did the following code but it does not work and I am getting the following error:</p>\n\n<pre><code>ValueError: Expected 2D array, got scalar array instead:\narray=6.5. Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample. \n</code></pre>\n\n<p>My code:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport pandas\ndataset = pandas.read_excel('PEG RATIOS.xlsx')\n\nX = dataset.iloc[:, 2].values\nX =X.reshape(-1,1)\ny = dataset.iloc[:, 3].values\ny = y.reshape (-1,1)\n\n\nfrom sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\nfrom sklearn.preprocessing import PolynomialFeatures\npoly_reg = PolynomialFeatures(degree = 4)\nX_poly = poly_reg.fit_transform(X)\npoly_reg.fit(X_poly, y)\nlin_reg_2 = LinearRegression()\nlin_reg_2.fit(X_poly, y)\n\nX_grid = np.arange(min(X), max(X), 0.1)\nX_grid = X_grid.reshape((len(X_grid), 1))\nplt.scatter(X, y, color = 'red')\nplt.plot(X_grid, lin_reg_2.predict(poly_reg.fit_transform(X_grid)), color = 'blue')\nplt.title('PEG Ratios verrus Exoected Growth: Semiconductor Firms')\nplt.xlabel('Expected Growth rate')\nplt.ylabel('PEGH Ratio')\nplt.show()\nlin_reg_2.predict(poly_reg.fit_transform(6.5))\n</code></pre>\n",
                "tags": "<machine-learning><python>",
                "answers": [
                    [
                        "53054",
                        "2",
                        "53048",
                        "",
                        "",
                        "<p>The error itself solves your problem. Just follow what it says. The predict() method takes a 2d array of values you want to predict on. Each item in the array is a \"point\" you want your model to predict on. So try,</p>\n\n<pre><code>lin_reg_2.predict(poly_reg.fit_transform([[6.5]]))\n</code></pre>\n\n<p>Here the input is a 2D array of shape <code>(1,1)</code>.</p>\n\n<p>Or as the error suggest try:</p>\n\n<pre><code>lin_reg_2.predict(np.array([6.5]).reshape(1, 1))\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7414",
            "_score": 14.533277,
            "_source": {
                "title": "Is linear regression fit for this data",
                "content": "Is linear regression fit for this data <p>I am predicting number of vehicles in 4 traffic junctions.</p>\n\n<p>So, I have following columns in my dataset :</p>\n\n<ol>\n<li>DateTime</li>\n<li>Junction_ID</li>\n<li>Number_of_vehicles</li>\n</ol>\n\n<p>At the first glance , this problem may look like Time series regression. But, the data given seems like Linear Regression problem.</p>\n\n<p>So, I have applied linear regression in the following manner :</p>\n\n<ul>\n<li>Used <a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html\" rel=\"nofollow noreferrer\">get_dummies</a> extensively for all the columns. I used dummy variables for 31 days,24 hours ,7 days of weeks and 4 Junction Ids.</li>\n<li><p>Then applied Linear Regression model </p>\n\n<pre><code>from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(train_data,train_vehicles)\n\nclf.fit(x_train,y_train)\n\nimport math\n\npred=clf.predict(x_test)\n\npred.shape #got result as (12030,)\n\nresult = []\nfor x in pred:\nresult.append(math.ceil(x))\n\nfrom sklearn.metrics import mean_squared_error\n\nscore=mean_squared_error(y_test, result)\nrmse=math.sqrt(score)\nprint('RMSE is :', rmse)\n</code></pre></li>\n</ul>\n\n<p>I am getting RMSE value as 10.636853077462394</p>\n\n<p>My questions are :</p>\n\n<ul>\n<li>Since RMSE value is on lower side , can I say this model is decent ?</li>\n<li>Is there any other approach which I can use on this dataset ?</li>\n<li>Do I need to check for colinearity ?</li>\n<li>How can I check if multiple variables are interrelated ?</li>\n<li>Should I go for non-linear regression on this dataset ?</li>\n</ul>\n <machine-learning><regression><linear-regression><p>There is a misconception about RMSE and other measurements for prediction quality, if you look at them standalone. In statistics you actually work with different models to compare RMSE's (using other approaches or other input variables) to have insights about prediction quality.</p>\n\n<p>Moreover, to conclude if a model is appropiate given your data you test the model assumptions. In linear Regression:</p>\n\n<ul>\n<li>Estimation Error follows a Normal distribution with E(mean) = 0, and sigma\u00b2</li>\n<li>Errors and input data are not autocorrelated (Find Beusch Godfrey - test, or ACF-Plot)</li>\n<li>No multicollinearity (Your dependent variables are not too strongly correlated - Pearson Correlation)</li>\n<li>Homoscedasticity (implied by normal distribution and independent error - Find White's test)</li>\n</ul>\n\n<p>However, good estimation doesn't necessarily lead to better predictions</p>\n<p>Welcome to the site! You could also ask yourself, \"Is <em>data science</em> fit for this data?\"</p>\n\n<p>Not all datasets require some sort of algorithmic approach. Depending on what you're going after, this may not be a data science problem. In traffic studies, a good number of problems are solved with \"plain\" statistics. For example, you could use the Poisson Distribution to solve any number of issues with your current dataset and that can be very effective even though it has relatively little to do with data science.</p>\n<p>For the first question, it is important to recall that RMSE has the same unit as the dependent variable. It means that there is no absolute good or bad threshold, however you can define it based on your DV. For a datum which ranges from 0 to 1000, an RMSE of 0.7 is small, but if the range goes from 0 to 1, it is not small.</p>\n\n<p>I would do some feature engineering (Create more variables: Time of Day, Day of Week, Month etc...) and run it through a Neural Network and then check for accuracy.  You may want to check if there is any correlation between the 4 junctions as well but if you run a NN, you don't have to.</p>\n<ul>\n<li>Is the target variable likely to be linearly, or additively dependent on the inputs? This means Monday will always have, say 10 more vehicles than Tuesday. If it is more intuitive to say that Monday will have 10% more vehicles than Tuesday, you can consider a log-linear model: transform the target variable by taking a log.</li>\n<li>In addition to measuring RMSE, you may want to visualize the data and predictions. Plot the actual and predicted vehicles on y-axis and date on x-axis, separately for each junction. This should tell you something about how good your model is, and potentially where it is going wrong.</li>\n<li>Based on the method of defining the time variables, the features are not likely to correlated to each other.</li>\n</ul>\n",
                "codes": [
                    [],
                    [],
                    [],
                    []
                ],
                "question_id:": "27744",
                "question_votes:": "1",
                "question_text:": "<p>I am predicting number of vehicles in 4 traffic junctions.</p>\n\n<p>So, I have following columns in my dataset :</p>\n\n<ol>\n<li>DateTime</li>\n<li>Junction_ID</li>\n<li>Number_of_vehicles</li>\n</ol>\n\n<p>At the first glance , this problem may look like Time series regression. But, the data given seems like Linear Regression problem.</p>\n\n<p>So, I have applied linear regression in the following manner :</p>\n\n<ul>\n<li>Used <a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html\" rel=\"nofollow noreferrer\">get_dummies</a> extensively for all the columns. I used dummy variables for 31 days,24 hours ,7 days of weeks and 4 Junction Ids.</li>\n<li><p>Then applied Linear Regression model </p>\n\n<pre><code>from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(train_data,train_vehicles)\n\nclf.fit(x_train,y_train)\n\nimport math\n\npred=clf.predict(x_test)\n\npred.shape #got result as (12030,)\n\nresult = []\nfor x in pred:\nresult.append(math.ceil(x))\n\nfrom sklearn.metrics import mean_squared_error\n\nscore=mean_squared_error(y_test, result)\nrmse=math.sqrt(score)\nprint('RMSE is :', rmse)\n</code></pre></li>\n</ul>\n\n<p>I am getting RMSE value as 10.636853077462394</p>\n\n<p>My questions are :</p>\n\n<ul>\n<li>Since RMSE value is on lower side , can I say this model is decent ?</li>\n<li>Is there any other approach which I can use on this dataset ?</li>\n<li>Do I need to check for colinearity ?</li>\n<li>How can I check if multiple variables are interrelated ?</li>\n<li>Should I go for non-linear regression on this dataset ?</li>\n</ul>\n",
                "tags": "<machine-learning><regression><linear-regression>",
                "answers": [
                    [
                        "57862",
                        "2",
                        "27744",
                        "",
                        "",
                        "<p>There is a misconception about RMSE and other measurements for prediction quality, if you look at them standalone. In statistics you actually work with different models to compare RMSE's (using other approaches or other input variables) to have insights about prediction quality.</p>\n\n<p>Moreover, to conclude if a model is appropiate given your data you test the model assumptions. In linear Regression:</p>\n\n<ul>\n<li>Estimation Error follows a Normal distribution with E(mean) = 0, and sigma\u00b2</li>\n<li>Errors and input data are not autocorrelated (Find Beusch Godfrey - test, or ACF-Plot)</li>\n<li>No multicollinearity (Your dependent variables are not too strongly correlated - Pearson Correlation)</li>\n<li>Homoscedasticity (implied by normal distribution and independent error - Find White's test)</li>\n</ul>\n\n<p>However, good estimation doesn't necessarily lead to better predictions</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "57869",
                        "2",
                        "27744",
                        "",
                        "",
                        "<p>Welcome to the site! You could also ask yourself, \"Is <em>data science</em> fit for this data?\"</p>\n\n<p>Not all datasets require some sort of algorithmic approach. Depending on what you're going after, this may not be a data science problem. In traffic studies, a good number of problems are solved with \"plain\" statistics. For example, you could use the Poisson Distribution to solve any number of issues with your current dataset and that can be very effective even though it has relatively little to do with data science.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "27746",
                        "2",
                        "27744",
                        "",
                        "",
                        "<p>For the first question, it is important to recall that RMSE has the same unit as the dependent variable. It means that there is no absolute good or bad threshold, however you can define it based on your DV. For a datum which ranges from 0 to 1000, an RMSE of 0.7 is small, but if the range goes from 0 to 1, it is not small.</p>\n\n<p>I would do some feature engineering (Create more variables: Time of Day, Day of Week, Month etc...) and run it through a Neural Network and then check for accuracy.  You may want to check if there is any correlation between the 4 junctions as well but if you run a NN, you don't have to.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "27773",
                        "2",
                        "27744",
                        "",
                        "",
                        "<ul>\n<li>Is the target variable likely to be linearly, or additively dependent on the inputs? This means Monday will always have, say 10 more vehicles than Tuesday. If it is more intuitive to say that Monday will have 10% more vehicles than Tuesday, you can consider a log-linear model: transform the target variable by taking a log.</li>\n<li>In addition to measuring RMSE, you may want to visualize the data and predictions. Plot the actual and predicted vehicles on y-axis and date on x-axis, separately for each junction. This should tell you something about how good your model is, and potentially where it is going wrong.</li>\n<li>Based on the method of defining the time variables, the features are not likely to correlated to each other.</li>\n</ul>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10714",
            "_score": 14.526337,
            "_source": {
                "title": "Timestamps in Ridge Regression Scikit Learn",
                "content": "Timestamps in Ridge Regression Scikit Learn <p>I am trying to transform data for use in regression, most likely the Ridge or Lasso technique implemented in <code>sklearn.linear_model</code>. </p>\n\n<p>My training data contains time stamps , which I believe may have predictive power. The time stamps reflect the time that a user placed an order for pizza. Here is an example:</p>\n\n<p><strong>Edit:</strong> Including labels in field <code>elapsed_time</code>, which is in seconds.</p>\n\n<pre><code>import pandas as pd\nimport sklearn.linear_model as linear_model\n\ndelivery_data = {\n    'order_time' : ['2018-09-12 21:43:08', '2018-09-13 06:33:04', '2018-09-13 09:12:18'],\n    'price' : [34.54, 8.63, 21.24],\n    'miles' : [6, 3, 7],\n    'home_type' : ['apartment', 'house', 'apartment'],\n    'elapsed_time' : [2023, 1610, 1918]\n}\n\ndf = pd.DataFrame(delivery_data)\ndf['order_time'] = pd.to_datetime(df['order_time'])\n</code></pre>\n\n<p>The resulting DataFrame looks like this:</p>\n\n<pre><code>           order_time  price  miles  home_type  elapsed_time\n0 2018-09-12 21:43:08  34.54      6  apartment          2023\n1 2018-09-13 06:33:04   8.63      3      house          1610\n2 2018-09-13 09:12:18  21.24      7  apartment          1918\n</code></pre>\n\n<p>I am trying to predict the time to deliver pizza (elapsed_time) given timestamp, quantitative, and categorical data.</p>\n\n<p>I suspect that time of day is predictive but that date is less predictive.</p>\n\n<p>So far, I am considering extracting only the hour from the time stamp. In this example, <code>order_time</code> would become [21, 6, 9]. My first concern is that 23:59 has an hour of 23 and 00:01 has an hour of 0. The two values are far apart, even though the order times are two minutes apart. </p>\n\n<p>Is there a better way to transform this <code>datetime</code> data?</p>\n\n<p>Does it make a difference that the dataset contains other quantitative data (price, miles_from_store) and categorical data (home_type)?</p>\n <scikit-learn><predictive-modeling><time-series><regression><feature-extraction><p>The <code>datetime</code> type has arithmetic operations available. If you have two <code>datetime</code> types, you can find the delta between them - the result will be a <code>datetime.timedelta</code> class. The other quantitative data is easily incorporated into a linear regression model, either lasso or ridge. Pretty much all those scikit-learn models can use a vector of features.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "38221",
                "question_votes:": "1",
                "question_text:": "<p>I am trying to transform data for use in regression, most likely the Ridge or Lasso technique implemented in <code>sklearn.linear_model</code>. </p>\n\n<p>My training data contains time stamps , which I believe may have predictive power. The time stamps reflect the time that a user placed an order for pizza. Here is an example:</p>\n\n<p><strong>Edit:</strong> Including labels in field <code>elapsed_time</code>, which is in seconds.</p>\n\n<pre><code>import pandas as pd\nimport sklearn.linear_model as linear_model\n\ndelivery_data = {\n    'order_time' : ['2018-09-12 21:43:08', '2018-09-13 06:33:04', '2018-09-13 09:12:18'],\n    'price' : [34.54, 8.63, 21.24],\n    'miles' : [6, 3, 7],\n    'home_type' : ['apartment', 'house', 'apartment'],\n    'elapsed_time' : [2023, 1610, 1918]\n}\n\ndf = pd.DataFrame(delivery_data)\ndf['order_time'] = pd.to_datetime(df['order_time'])\n</code></pre>\n\n<p>The resulting DataFrame looks like this:</p>\n\n<pre><code>           order_time  price  miles  home_type  elapsed_time\n0 2018-09-12 21:43:08  34.54      6  apartment          2023\n1 2018-09-13 06:33:04   8.63      3      house          1610\n2 2018-09-13 09:12:18  21.24      7  apartment          1918\n</code></pre>\n\n<p>I am trying to predict the time to deliver pizza (elapsed_time) given timestamp, quantitative, and categorical data.</p>\n\n<p>I suspect that time of day is predictive but that date is less predictive.</p>\n\n<p>So far, I am considering extracting only the hour from the time stamp. In this example, <code>order_time</code> would become [21, 6, 9]. My first concern is that 23:59 has an hour of 23 and 00:01 has an hour of 0. The two values are far apart, even though the order times are two minutes apart. </p>\n\n<p>Is there a better way to transform this <code>datetime</code> data?</p>\n\n<p>Does it make a difference that the dataset contains other quantitative data (price, miles_from_store) and categorical data (home_type)?</p>\n",
                "tags": "<scikit-learn><predictive-modeling><time-series><regression><feature-extraction>",
                "answers": [
                    [
                        "38223",
                        "2",
                        "38221",
                        "",
                        "",
                        "<p>The <code>datetime</code> type has arithmetic operations available. If you have two <code>datetime</code> types, you can find the delta between them - the result will be a <code>datetime.timedelta</code> class. The other quantitative data is easily incorporated into a linear regression model, either lasso or ridge. Pretty much all those scikit-learn models can use a vector of features.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6346",
            "_score": 14.511312,
            "_source": {
                "title": "Forecast Model recognize future trend",
                "content": "Forecast Model recognize future trend <p>I set up a forecasting model that predicts call data. The forecast model uses a random forest regression model.</p>\n\n<p>Data:\nI have call data about every day in 15 minutes intervals of a year since 2013.</p>\n\n<p>Here is a plot of the accumulated values over months:</p>\n\n<p><a href=\"https://i.stack.imgur.com/pg0Z6.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/pg0Z6.png\" alt=\"Calldata\"></a></p>\n\n<p>It can be clearly seen that call data has almost doubled in 2017 over 2016. This trend should also be observable for the next few years.</p>\n\n<p>features:</p>\n\n<p>First, the format of my data:</p>\n\n<pre><code> DATE                     CALL\n ....\n 2017-10-23 10:15:00.000    259\n 2017-10-23 10:30:00.000    292\n 2017-10-23 10:45:00.000    309\n ....\n</code></pre>\n\n<p>From this I extracted the following features:\nI have extracted the following features to predict my target variable Y (call data):</p>\n\n<pre><code>-Weekday\n-Month\n-Holiday (yes / no)\n-Interval of the day\n\nSo I ask my model:\n\nWhat is the call volume of a day and interval with the following features?\n</code></pre>\n\n<p>I have used the years 2015-2016-2017 to train the model. However, the model does not give the desired prognosis. </p>\n\n<p>He even predicts the days for 2017 wrong. Although I gave him the data as training data.</p>\n\n<p>Questions:</p>\n\n<pre><code>- Should I work on my features?\n\n- How do I show my forecasting model that the data will double year by year \n  as observable since 2016?\n</code></pre>\n <machine-learning><predictive-modeling><regression><feature-selection><p>Random forest, and tree-based models in general, do not handle trends well. </p>\n\n<p>The reason is simple: inside any decision tree, there are discrete rules such as:\n$$\ny = \\begin{cases} y_1, &amp; \\text{if } x &gt; c \\\\ y_2, &amp; \\text{if } x &lt;= c \\end{cases}\n$$\nThis is a tree of depth 1 (so-called \"stem\"), but deeper trees obey the same logic. The variable $x$ and constants, $y_1$, $y_2$, $c$ are fit to the train data. And this is the problem: if in the training data $y$ was never higher than $y_1$, your tree will never predict $y&gt;y_1$, even if $y$ is clearly increasing.</p>\n\n<p>On the other hand, linear models (such as XARIMA and its special cases) catch trends very well. But they are poor with non-linearities and feature interplay in your data. In my own experience, the following stacking approach works best:</p>\n\n<ol>\n<li>Fit a simple time-based linear model to your data.</li>\n<li>Fit a tree-based model (random forest or boosting) to the residuals of your linear model.</li>\n</ol>\n\n<p>If the linear model is specified correctly, it will catch and remove the non-stationarities in the data. Thus, the tree-based model will be predicting stationary residuals and find finer dependencies that the linear model.</p>\n\n<p>This Python example illustrates the issue:</p>\n\n<pre><code>import numpy as np\nfrom sklearn.datasets import make_friedman2\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import HuberRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_val_predict\n\n# make a difficult dataset with a linear trend\nX, y = make_friedman2(n_samples=1000, random_state=1, noise=10)\ntime = np.arange(1000)\ny += time * 1.5\nX = np.hstack([X, time[:, np.newaxis]])\nX_train, y_train = X[:700], y[:700]\nX_test, y_test = X[700:], y[700:]\n\n# build a pure Random Forest\nrf = RandomForestRegressor(random_state=1, n_jobs=-1).fit(X_train, y_train)\ny_rf = rf.predict(X_test)\n\n# build a pure linear model\nlinear = HuberRegressor().fit(X_train, y_train)\ny_lin = linear.predict(X_test)\n\n# build a stack of two models\nlin_resid = y_train - cross_val_predict(linear, X_train, y_train)\nrf.fit(X_train, lin_resid)\ny_stack = y_lin + rf.predict(X_test)\n\nprint(r2_score(y_test, y_rf))    # R2 on test data is only 0.34\nprint(r2_score(y_test, y_lin))   # R2 due to time trend is 0.86 \nprint(r2_score(y_test, y_stack)) # R2 of combined model is 0.95\n</code></pre>\n<p>Before going into modelling, I guess you can do a bit more of exploratory analysis(month by month, year by year). If you find any trend or seasonality and so on.</p>\n\n<p>Why did you go to RF directly without using basing Techniques like <strong>ARIMA, ARMA, Exponential Smoothening</strong> and <strong>AR</strong> so on.</p>\n\n<p>Sometime RF might not give you as good results as Base models, I think you don't have trend, this is from your graph(but not certain). If you can try doing some research and see if there are some external factors which are effecting your demand. Why did that happen and what is the root case for it.</p>\n\n<p>To your model to understand, it needs some feature which explains its spikes somehow, it can achieved by doing feature engg/ research</p>\n<p>Considering your data (The sample you show above) I would suggest <code>tbats()</code> function from forecast package in R. Because your data might have hourly as well as daily seasonality which suggests us to use \"TBATS model (Exponential smoothing state space model with Box-Cox\ntransformation, ARMA errors, Trend and Seasonal components)\"</p>\n\n<p>References:\nDe Livera, A.M., Hyndman, R.J., &amp; Snyder, R. D. (2011), Forecasting time series with complex\nseasonal patterns using exponential smoothing, Journal of the American Statistical Association,\n106(496)</p>\n\n<p>Or you could use Dynamic harmonic regression. Reference and examples <a href=\"https://otexts.org/fpp2/complexseasonality.html\" rel=\"nofollow noreferrer\">https://otexts.org/fpp2/complexseasonality.html</a></p>\n",
                "codes": [
                    [
                        "import numpy as np\nfrom sklearn.datasets import make_friedman2\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import HuberRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_val_predict\n\n# make a difficult dataset with a linear trend\nX, y = make_friedman2(n_samples=1000, random_state=1, noise=10)\ntime = np.arange(1000)\ny += time * 1.5\nX = np.hstack([X, time[:, np.newaxis]])\nX_train, y_train = X[:700], y[:700]\nX_test, y_test = X[700:], y[700:]\n\n# build a pure Random Forest\nrf = RandomForestRegressor(random_state=1, n_jobs=-1).fit(X_train, y_train)\ny_rf = rf.predict(X_test)\n\n# build a pure linear model\nlinear = HuberRegressor().fit(X_train, y_train)\ny_lin = linear.predict(X_test)\n\n# build a stack of two models\nlin_resid = y_train - cross_val_predict(linear, X_train, y_train)\nrf.fit(X_train, lin_resid)\ny_stack = y_lin + rf.predict(X_test)\n\nprint(r2_score(y_test, y_rf))    # R2 on test data is only 0.34\nprint(r2_score(y_test, y_lin))   # R2 due to time trend is 0.86 \nprint(r2_score(y_test, y_stack)) # R2 of combined model is 0.95\n"
                    ],
                    [],
                    []
                ],
                "question_id:": "24804",
                "question_votes:": "2",
                "question_text:": "<p>I set up a forecasting model that predicts call data. The forecast model uses a random forest regression model.</p>\n\n<p>Data:\nI have call data about every day in 15 minutes intervals of a year since 2013.</p>\n\n<p>Here is a plot of the accumulated values over months:</p>\n\n<p><a href=\"https://i.stack.imgur.com/pg0Z6.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/pg0Z6.png\" alt=\"Calldata\"></a></p>\n\n<p>It can be clearly seen that call data has almost doubled in 2017 over 2016. This trend should also be observable for the next few years.</p>\n\n<p>features:</p>\n\n<p>First, the format of my data:</p>\n\n<pre><code> DATE                     CALL\n ....\n 2017-10-23 10:15:00.000    259\n 2017-10-23 10:30:00.000    292\n 2017-10-23 10:45:00.000    309\n ....\n</code></pre>\n\n<p>From this I extracted the following features:\nI have extracted the following features to predict my target variable Y (call data):</p>\n\n<pre><code>-Weekday\n-Month\n-Holiday (yes / no)\n-Interval of the day\n\nSo I ask my model:\n\nWhat is the call volume of a day and interval with the following features?\n</code></pre>\n\n<p>I have used the years 2015-2016-2017 to train the model. However, the model does not give the desired prognosis. </p>\n\n<p>He even predicts the days for 2017 wrong. Although I gave him the data as training data.</p>\n\n<p>Questions:</p>\n\n<pre><code>- Should I work on my features?\n\n- How do I show my forecasting model that the data will double year by year \n  as observable since 2016?\n</code></pre>\n",
                "tags": "<machine-learning><predictive-modeling><regression><feature-selection>",
                "answers": [
                    [
                        "24810",
                        "2",
                        "24804",
                        "",
                        "",
                        "<p>Random forest, and tree-based models in general, do not handle trends well. </p>\n\n<p>The reason is simple: inside any decision tree, there are discrete rules such as:\n$$\ny = \\begin{cases} y_1, &amp; \\text{if } x &gt; c \\\\ y_2, &amp; \\text{if } x &lt;= c \\end{cases}\n$$\nThis is a tree of depth 1 (so-called \"stem\"), but deeper trees obey the same logic. The variable $x$ and constants, $y_1$, $y_2$, $c$ are fit to the train data. And this is the problem: if in the training data $y$ was never higher than $y_1$, your tree will never predict $y&gt;y_1$, even if $y$ is clearly increasing.</p>\n\n<p>On the other hand, linear models (such as XARIMA and its special cases) catch trends very well. But they are poor with non-linearities and feature interplay in your data. In my own experience, the following stacking approach works best:</p>\n\n<ol>\n<li>Fit a simple time-based linear model to your data.</li>\n<li>Fit a tree-based model (random forest or boosting) to the residuals of your linear model.</li>\n</ol>\n\n<p>If the linear model is specified correctly, it will catch and remove the non-stationarities in the data. Thus, the tree-based model will be predicting stationary residuals and find finer dependencies that the linear model.</p>\n\n<p>This Python example illustrates the issue:</p>\n\n<pre><code>import numpy as np\nfrom sklearn.datasets import make_friedman2\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import HuberRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_val_predict\n\n# make a difficult dataset with a linear trend\nX, y = make_friedman2(n_samples=1000, random_state=1, noise=10)\ntime = np.arange(1000)\ny += time * 1.5\nX = np.hstack([X, time[:, np.newaxis]])\nX_train, y_train = X[:700], y[:700]\nX_test, y_test = X[700:], y[700:]\n\n# build a pure Random Forest\nrf = RandomForestRegressor(random_state=1, n_jobs=-1).fit(X_train, y_train)\ny_rf = rf.predict(X_test)\n\n# build a pure linear model\nlinear = HuberRegressor().fit(X_train, y_train)\ny_lin = linear.predict(X_test)\n\n# build a stack of two models\nlin_resid = y_train - cross_val_predict(linear, X_train, y_train)\nrf.fit(X_train, lin_resid)\ny_stack = y_lin + rf.predict(X_test)\n\nprint(r2_score(y_test, y_rf))    # R2 on test data is only 0.34\nprint(r2_score(y_test, y_lin))   # R2 due to time trend is 0.86 \nprint(r2_score(y_test, y_stack)) # R2 of combined model is 0.95\n</code></pre>\n",
                        "",
                        "2"
                    ],
                    [
                        "24807",
                        "2",
                        "24804",
                        "",
                        "",
                        "<p>Before going into modelling, I guess you can do a bit more of exploratory analysis(month by month, year by year). If you find any trend or seasonality and so on.</p>\n\n<p>Why did you go to RF directly without using basing Techniques like <strong>ARIMA, ARMA, Exponential Smoothening</strong> and <strong>AR</strong> so on.</p>\n\n<p>Sometime RF might not give you as good results as Base models, I think you don't have trend, this is from your graph(but not certain). If you can try doing some research and see if there are some external factors which are effecting your demand. Why did that happen and what is the root case for it.</p>\n\n<p>To your model to understand, it needs some feature which explains its spikes somehow, it can achieved by doing feature engg/ research</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "36476",
                        "2",
                        "24804",
                        "",
                        "",
                        "<p>Considering your data (The sample you show above) I would suggest <code>tbats()</code> function from forecast package in R. Because your data might have hourly as well as daily seasonality which suggests us to use \"TBATS model (Exponential smoothing state space model with Box-Cox\ntransformation, ARMA errors, Trend and Seasonal components)\"</p>\n\n<p>References:\nDe Livera, A.M., Hyndman, R.J., &amp; Snyder, R. D. (2011), Forecasting time series with complex\nseasonal patterns using exponential smoothing, Journal of the American Statistical Association,\n106(496)</p>\n\n<p>Or you could use Dynamic harmonic regression. Reference and examples <a href=\"https://otexts.org/fpp2/complexseasonality.html\" rel=\"nofollow noreferrer\">https://otexts.org/fpp2/complexseasonality.html</a></p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13158",
            "_score": 14.4792185,
            "_source": {
                "title": "Does Gradient Boosting detect non-linear relationships?",
                "content": "Does Gradient Boosting detect non-linear relationships? <p>I wish to train some data using the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn-ensemble-gradientboostingregressor\" rel=\"nofollow noreferrer\">the Gradient Boosting Regressor of Scikit-Learn</a>.</p>\n\n<p>My questions are:</p>\n\n<p>1) Is the algorithm able to capture non-linear relationships? For example, in the case of y=x^2, y increases as x approaches negative infinity and positive infinity. What if the graph looks like y=sin(x)?</p>\n\n<p>2) Is the algorithm able to detect interactions/relationships among the features? Specifically, should I add features that are the sums/differences of the raw features to the training set?</p>\n <scikit-learn><regression><linear-regression><gradient-descent><boosting><p>GB method works by minimizing a loss function and by splitting each node in a fashion that produces high pure leaves. there is no population formula being estimated and therefore you can estimate all types of relations between the target and the features.<br>\nHowever I wouldn't put in the model correlated variables as:  </p>\n\n<blockquote>\n  <p>For gradient boosted trees, there's generally no strong need to check\n  for multicollinearity because of its robustness. But practically\n  speaking, you still should do some basic checks. For example, if you\n  discover that two variables are 100% the same, then of course there's\n  no point in keeping both. Even if it's 98% correlated, it's usually\n  okay to drop one variable without degrading the overall model.<br>\n  Source: <a href=\"https://www.quora.com/Is-multicollinearity-a-problem-with-gradient-boosted-trees\" rel=\"nofollow noreferrer\">Quora</a></p>\n</blockquote>\n",
                "codes": [
                    []
                ],
                "question_id:": "45371",
                "question_votes:": "4",
                "question_text:": "<p>I wish to train some data using the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn-ensemble-gradientboostingregressor\" rel=\"nofollow noreferrer\">the Gradient Boosting Regressor of Scikit-Learn</a>.</p>\n\n<p>My questions are:</p>\n\n<p>1) Is the algorithm able to capture non-linear relationships? For example, in the case of y=x^2, y increases as x approaches negative infinity and positive infinity. What if the graph looks like y=sin(x)?</p>\n\n<p>2) Is the algorithm able to detect interactions/relationships among the features? Specifically, should I add features that are the sums/differences of the raw features to the training set?</p>\n",
                "tags": "<scikit-learn><regression><linear-regression><gradient-descent><boosting>",
                "answers": [
                    [
                        "45374",
                        "2",
                        "45371",
                        "",
                        "",
                        "<p>GB method works by minimizing a loss function and by splitting each node in a fashion that produces high pure leaves. there is no population formula being estimated and therefore you can estimate all types of relations between the target and the features.<br>\nHowever I wouldn't put in the model correlated variables as:  </p>\n\n<blockquote>\n  <p>For gradient boosted trees, there's generally no strong need to check\n  for multicollinearity because of its robustness. But practically\n  speaking, you still should do some basic checks. For example, if you\n  discover that two variables are 100% the same, then of course there's\n  no point in keeping both. Even if it's 98% correlated, it's usually\n  okay to drop one variable without degrading the overall model.<br>\n  Source: <a href=\"https://www.quora.com/Is-multicollinearity-a-problem-with-gradient-boosted-trees\" rel=\"nofollow noreferrer\">Quora</a></p>\n</blockquote>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7344",
            "_score": 14.455984,
            "_source": {
                "title": "Unable to Use The K-Fold Validation Sklearn Python",
                "content": "Unable to Use The K-Fold Validation Sklearn Python <p>I have an <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\" rel=\"nofollow noreferrer\">dataset</a>.</p>\n\n<p>I am unable to use the K-Fold Validation. I am getting the error raised:</p>\n\n<blockquote>\n  <p>ValueError(\"{0} is not supported\".format(y_type))</p>\n  \n  <p>ValueError: continuous is not supported .</p>\n</blockquote>\n\n<p>I do not want to do encoding to int, since it may affect the data, and also I want to understand why K-fold is not working.</p>\n\n<p>Below is my python code.</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import cross_validation, metrics\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn import svm\nfrom sklearn import preprocessing\n\n - `List item`\n\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\"\nnames=['Relative Compactness','Surface Area','Wall Area','Roof Area','Overall Height','Orientation','Glazing Area','Glazing Area Distribution','Heating Load','Cooling Load']\ndf = pd.read_excel(url,names=names)\n\n#Feature selection\ntrain=df.sample(frac=0.8,random_state=150)\ntest=df.drop(train.index)\n\n#save the original values in a dataframe so we can compare later\ntest_loads=test[[\"Cooling Load\"]]\n\n#Create 2 lists of response values to train our model\nY1=np.array(train['Heating Load'])\nY2=np.array(train['Cooling Load'])\n\n#Select the features\ntrain_corr=train[['Overall Height','Relative Compactness','Roof Area','Surface Area']]\ntest_corr=test[['Overall Height','Relative Compactness','Roof Area','Surface Area']]\nseed = 7\nscoring = 'accuracy'\nX_train,X_test,y_train,y_test=cross_validation.train_test_split(train_corr,Y1,test_size=0.2)\nkfold = model_selection.KFold(n_splits=10, random_state=seed) \ncv_results = model_selection.cross_val_score(RandomForestRegressor(), X_train, y_train, cv=kfold, scoring=scoring)\nprint (cv_results.mean())\n</code></pre>\n <machine-learning><python><deep-learning><scikit-learn><regression><p>Based on the answer <a href=\"https://stackoverflow.com/a/48551629/5120235\">here</a>, <em>Since you are doing a classification task, you should be using the metric R-squared (co-effecient of determination) instead of accuracy score (accuracy score is used for classification purposes).</em> You should use something like <code>score</code> for evaluation because your task is regression.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "27581",
                "question_votes:": "3",
                "question_text:": "<p>I have an <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\" rel=\"nofollow noreferrer\">dataset</a>.</p>\n\n<p>I am unable to use the K-Fold Validation. I am getting the error raised:</p>\n\n<blockquote>\n  <p>ValueError(\"{0} is not supported\".format(y_type))</p>\n  \n  <p>ValueError: continuous is not supported .</p>\n</blockquote>\n\n<p>I do not want to do encoding to int, since it may affect the data, and also I want to understand why K-fold is not working.</p>\n\n<p>Below is my python code.</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import cross_validation, metrics\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn import svm\nfrom sklearn import preprocessing\n\n - `List item`\n\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\"\nnames=['Relative Compactness','Surface Area','Wall Area','Roof Area','Overall Height','Orientation','Glazing Area','Glazing Area Distribution','Heating Load','Cooling Load']\ndf = pd.read_excel(url,names=names)\n\n#Feature selection\ntrain=df.sample(frac=0.8,random_state=150)\ntest=df.drop(train.index)\n\n#save the original values in a dataframe so we can compare later\ntest_loads=test[[\"Cooling Load\"]]\n\n#Create 2 lists of response values to train our model\nY1=np.array(train['Heating Load'])\nY2=np.array(train['Cooling Load'])\n\n#Select the features\ntrain_corr=train[['Overall Height','Relative Compactness','Roof Area','Surface Area']]\ntest_corr=test[['Overall Height','Relative Compactness','Roof Area','Surface Area']]\nseed = 7\nscoring = 'accuracy'\nX_train,X_test,y_train,y_test=cross_validation.train_test_split(train_corr,Y1,test_size=0.2)\nkfold = model_selection.KFold(n_splits=10, random_state=seed) \ncv_results = model_selection.cross_val_score(RandomForestRegressor(), X_train, y_train, cv=kfold, scoring=scoring)\nprint (cv_results.mean())\n</code></pre>\n",
                "tags": "<machine-learning><python><deep-learning><scikit-learn><regression>",
                "answers": [
                    [
                        "27582",
                        "2",
                        "27581",
                        "",
                        "",
                        "<p>Based on the answer <a href=\"https://stackoverflow.com/a/48551629/5120235\">here</a>, <em>Since you are doing a classification task, you should be using the metric R-squared (co-effecient of determination) instead of accuracy score (accuracy score is used for classification purposes).</em> You should use something like <code>score</code> for evaluation because your task is regression.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5044",
            "_score": 14.444339,
            "_source": {
                "title": "Linear Regression and k-fold cross validation",
                "content": "Linear Regression and k-fold cross validation <p>I am totally new to the topic of Data Science. With the help of the following sources, I <em>think</em> I have managed to do a very <strong>simple and basic Linear regression</strong> on a <a href=\"https://www.kaggle.com/c/house-prices-advanced-regression-techniques/download/train.csv\" rel=\"nofollow noreferrer\">train dataset</a>:</p>\n\n<ul>\n<li><a href=\"http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html\" rel=\"nofollow noreferrer\">SkLearn documentation - Linear regression</a></li>\n<li><a href=\"https://www.kaggle.com/eliekawerk/regression-to-predict-house-prices\" rel=\"nofollow noreferrer\">Some Kernel, that I percieved as intuitive</a></li>\n<li><a href=\"https://www.kaggle.com/c/house-prices-advanced-regression-techniques/download/test.csv\" rel=\"nofollow noreferrer\">the test dataset</a></li>\n</ul>\n\n<p>My <strong>Python code</strong> (written as an iPython notebook) that actually does the computation looks like this:</p>\n\n<pre><code>### Stage 0: \"Import some stuff\"\n%matplotlib inline\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import datasets, linear_model\nfrom sklearn.linear_model import LinearRegression\n\n### Stage 1: \"Prepare train dataset\"\nmy_train_dataset = pd.read_csv(\"../train.csv\")\n\n### remove categorical cols\nonly_numerical_train_dataset = my_train_dataset.loc[:, my_train_dataset.dtypes!=object]\n\n### remove 'Id' and 'SalePrice' columns\nmy_train_dataset_X = only_numerical_train_dataset.drop(['Id','SalePrice'], axis = 1)\n\n### insert median into cells with missing values\nprint(\"Before: Number of cells with missing values in train data: \" + str(np.sum(np.sum(my_train_dataset_X.isnull()))))\nnull_values_per_col = np.sum(my_train_dataset_X.isnull(), axis=0)\ncols_to_impute = []\nfor key in null_values_per_col.keys():\n    if null_values_per_col.get(key) != 0: \n        cols_to_impute.append(key)\nprint(\"Before: Need to replace values in the columns in train data: \" + str(cols_to_impute) + \"\\n\")\nimputation_val_for_na_cols = dict()\nfor col in cols_to_impute:\n    if (my_train_dataset_X[col].dtype == 'float64' ) or  (my_train_dataset_X[col].dtype == 'int64'):\n        #numerical col\n        imputation_val_for_na_cols[col] = np.nanmedian(my_train_dataset_X[col]) #with median\nfor key, val in imputation_val_for_na_cols.items():\n    my_train_dataset_X[key].fillna(value= val, inplace = True)\nprint(\"After: Number of cells with missing values in train data: \" + str(np.sum(np.sum(my_train_dataset_X.isnull()))))\nnull_values_per_col = np.sum(my_train_dataset_X.isnull(), axis=0)\ncols_to_impute = []\nfor key in null_values_per_col.keys():\n    if null_values_per_col.get(key) != 0: \n        cols_to_impute.append(key)\nprint(\"After: Need to replace values in the columns in train data: \" + str(cols_to_impute) + \"\\n\")\n\n### Stage 2: \"Sanity Check - the better the quality, the higher the price?\"\nplt.scatter(my_train_dataset.OverallQual, my_train_dataset.SalePrice)\nplt.xlabel(\"Overall Quality of the house\")\nplt.ylabel(\"Price of the house\")\nplt.title(\"Relationship between Price and Quality\")\nplt.show()\n\n### Stage 3: \"Prepare the test dataset\"\nmy_test_dataset = pd.read_csv(\"../test.csv\")\n\n### remove categorical cols\nonly_numerical_test_dataset = my_test_dataset.loc[:, my_test_dataset.dtypes!=object]\n\n### remove 'Id' column\nmy_test_dataset_X = only_numerical_test_dataset.drop(['Id'], axis = 1)\n\n### insert median into cells with missing values\nprint(\"Before: Number of cells with missing values in test data: \" + str(np.sum(np.sum(my_test_dataset_X.isnull()))))\nnull_values_per_col = np.sum(my_test_dataset_X.isnull(), axis=0)\ncols_to_impute = []\nfor key in null_values_per_col.keys():\n    if null_values_per_col.get(key) != 0: \n        cols_to_impute.append(key)\nprint(\"Before: Need to replace values in the columns in test data: \" + str(cols_to_impute) + \"\\n\")\nimputation_val_for_na_cols = dict()\nfor col in cols_to_impute:\n    if (my_test_dataset_X[col].dtype == 'float64' ) or  (my_test_dataset_X[col].dtype == 'int64'):\n        #numerical col\n        imputation_val_for_na_cols[col] = np.nanmedian(my_test_dataset_X[col]) #with median\nfor key, val in imputation_val_for_na_cols.items():\n    my_test_dataset_X[key].fillna(value= val, inplace = True)\nprint(\"After: Number of cells with missing values in test data: \" + str(np.sum(np.sum(my_test_dataset_X.isnull()))))\nnull_values_per_col = np.sum(my_test_dataset_X.isnull(), axis=0)\ncols_to_impute = []\nfor key in null_values_per_col.keys():\n    if null_values_per_col.get(key) != 0: \n        cols_to_impute.append(key)\nprint(\"After: Need to replace values in the columns in test data: \" + str(cols_to_impute) + \"\\n\")\n\n### Stage 4: \"Apply the model\"\nlm = LinearRegression()\nlm.fit(my_train_dataset_X, my_train_dataset.SalePrice)\n\n### Stage 5: \"Sanity Check - the better the quality, the higher the predicted SalesPrice?\"\nplt.scatter(my_test_dataset.OverallQual, lm.predict(my_test_dataset_X))\nplt.xlabel(\"Overall Quality of the house in test data\")\nplt.ylabel(\"Price of the house in test data\")\nplt.title(\"Relationship between Price and Quality in test data\")\nplt.show()\n\n### Stage 6: \"Check the performance of the Prediction\"\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(lm, my_train_dataset_X,  lm.predict(my_test_dataset_X), cv=10)\nprint(\"scores = \" + str(scores))\n</code></pre>\n\n<h2>My questions are:</h2>\n\n<p><strong>1. Why am I getting an error in Stage 6 and how to fix it?</strong></p>\n\n<hr>\n\n<pre><code>ValueError Traceback (most recent call last)\n&lt;ipython-input-2-700c31f0d410&gt; in &lt;module&gt;()\n     85 ### test the performance of the model\n     86 from sklearn.model_selection import cross_val_score\n---&gt; 87 scores = cross_val_score(lm, my_train_dataset_X,  lm.predict(my_test_dataset_X), cv=10)\n     88 print(\"scores = \" + str(scores))\n     89 \nValueError: Found input variables with inconsistent numbers of samples: [1460, 1459]\n</code></pre>\n\n<p><strong>2. Is there something <em>fundamentally wrong</em> with my approach to a simple and basic Linear Regression?</strong></p>\n\n<hr>\n\n<h2>Edits for comments:</h2>\n\n<p><strong>@CalZ - First comment:</strong></p>\n\n<pre><code>my_test_dataset_X.shape = (1459, 36)\nmy_train_dataset_X.shape = (1460, 36)\n</code></pre>\n\n<p><strong>@CalZ - Second comment:</strong>\nI will consider refactoring the code as soon as I am sure that my approach is not fundamentally wrong.</p>\n\n<hr>\n <python><scikit-learn><linear-regression><cross-validation><ol>\n<li><p>As the error message states, the invocation to <code>cross_val_score</code> fails because the shape arguments differ in their first dimension (1460 vs. 1459). This is consistent with the number of lines in the CSV files. However, the underlying problem is that you are mixing the test and the training sets. You should invoke it only with the test set: <code>cross_val_score(lm, my_test_dataset_X,  lm.predict(my_test_dataset_X), cv=10)</code>. <strong>Update</strong>: My initial suggestion was NOT correct, you cannot use your own predictions to validate! You should leave a subset of the labeled data for hold out on which to compute the cross validation.</p></li>\n<li><p>Yours is not only a linear regression. The bulk of your code is in charge of data manipulation (feature selection, data imputation) and not linear regression. Actually, you are reusing scikit-learn's implementation of linear regresion, not coding your own. If you want a code review of your snippet, maybe you should try in <a href=\"http://codereview.stackexchange.com\">http://codereview.stackexchange.com</a> (I don't know if this fits there either, you'd better check their <a href=\"https://codereview.stackexchange.com/help\">help center</a>).</p></li>\n</ol>\n\n<p>UPDATE: About whether your code is sound from a data science point of view, it seems to me (after only a quick review) that you are doing reasonable things. There are some things that could be improved, like only handling float64 and int64 (while you can do as described <a href=\"https://stackoverflow.com/q/25039626/674487\">here</a>), only imputing NaNs and Nones (while there can be other values that should be imputed in certain cases, like outliers),  or imputing blindly with the median (which is a <em>safe</em> decision but should be assessed taking into account the nature of each variable). But generally speaking seems Ok.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "19586",
                "question_votes:": "1",
                "question_text:": "<p>I am totally new to the topic of Data Science. With the help of the following sources, I <em>think</em> I have managed to do a very <strong>simple and basic Linear regression</strong> on a <a href=\"https://www.kaggle.com/c/house-prices-advanced-regression-techniques/download/train.csv\" rel=\"nofollow noreferrer\">train dataset</a>:</p>\n\n<ul>\n<li><a href=\"http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html\" rel=\"nofollow noreferrer\">SkLearn documentation - Linear regression</a></li>\n<li><a href=\"https://www.kaggle.com/eliekawerk/regression-to-predict-house-prices\" rel=\"nofollow noreferrer\">Some Kernel, that I percieved as intuitive</a></li>\n<li><a href=\"https://www.kaggle.com/c/house-prices-advanced-regression-techniques/download/test.csv\" rel=\"nofollow noreferrer\">the test dataset</a></li>\n</ul>\n\n<p>My <strong>Python code</strong> (written as an iPython notebook) that actually does the computation looks like this:</p>\n\n<pre><code>### Stage 0: \"Import some stuff\"\n%matplotlib inline\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import datasets, linear_model\nfrom sklearn.linear_model import LinearRegression\n\n### Stage 1: \"Prepare train dataset\"\nmy_train_dataset = pd.read_csv(\"../train.csv\")\n\n### remove categorical cols\nonly_numerical_train_dataset = my_train_dataset.loc[:, my_train_dataset.dtypes!=object]\n\n### remove 'Id' and 'SalePrice' columns\nmy_train_dataset_X = only_numerical_train_dataset.drop(['Id','SalePrice'], axis = 1)\n\n### insert median into cells with missing values\nprint(\"Before: Number of cells with missing values in train data: \" + str(np.sum(np.sum(my_train_dataset_X.isnull()))))\nnull_values_per_col = np.sum(my_train_dataset_X.isnull(), axis=0)\ncols_to_impute = []\nfor key in null_values_per_col.keys():\n    if null_values_per_col.get(key) != 0: \n        cols_to_impute.append(key)\nprint(\"Before: Need to replace values in the columns in train data: \" + str(cols_to_impute) + \"\\n\")\nimputation_val_for_na_cols = dict()\nfor col in cols_to_impute:\n    if (my_train_dataset_X[col].dtype == 'float64' ) or  (my_train_dataset_X[col].dtype == 'int64'):\n        #numerical col\n        imputation_val_for_na_cols[col] = np.nanmedian(my_train_dataset_X[col]) #with median\nfor key, val in imputation_val_for_na_cols.items():\n    my_train_dataset_X[key].fillna(value= val, inplace = True)\nprint(\"After: Number of cells with missing values in train data: \" + str(np.sum(np.sum(my_train_dataset_X.isnull()))))\nnull_values_per_col = np.sum(my_train_dataset_X.isnull(), axis=0)\ncols_to_impute = []\nfor key in null_values_per_col.keys():\n    if null_values_per_col.get(key) != 0: \n        cols_to_impute.append(key)\nprint(\"After: Need to replace values in the columns in train data: \" + str(cols_to_impute) + \"\\n\")\n\n### Stage 2: \"Sanity Check - the better the quality, the higher the price?\"\nplt.scatter(my_train_dataset.OverallQual, my_train_dataset.SalePrice)\nplt.xlabel(\"Overall Quality of the house\")\nplt.ylabel(\"Price of the house\")\nplt.title(\"Relationship between Price and Quality\")\nplt.show()\n\n### Stage 3: \"Prepare the test dataset\"\nmy_test_dataset = pd.read_csv(\"../test.csv\")\n\n### remove categorical cols\nonly_numerical_test_dataset = my_test_dataset.loc[:, my_test_dataset.dtypes!=object]\n\n### remove 'Id' column\nmy_test_dataset_X = only_numerical_test_dataset.drop(['Id'], axis = 1)\n\n### insert median into cells with missing values\nprint(\"Before: Number of cells with missing values in test data: \" + str(np.sum(np.sum(my_test_dataset_X.isnull()))))\nnull_values_per_col = np.sum(my_test_dataset_X.isnull(), axis=0)\ncols_to_impute = []\nfor key in null_values_per_col.keys():\n    if null_values_per_col.get(key) != 0: \n        cols_to_impute.append(key)\nprint(\"Before: Need to replace values in the columns in test data: \" + str(cols_to_impute) + \"\\n\")\nimputation_val_for_na_cols = dict()\nfor col in cols_to_impute:\n    if (my_test_dataset_X[col].dtype == 'float64' ) or  (my_test_dataset_X[col].dtype == 'int64'):\n        #numerical col\n        imputation_val_for_na_cols[col] = np.nanmedian(my_test_dataset_X[col]) #with median\nfor key, val in imputation_val_for_na_cols.items():\n    my_test_dataset_X[key].fillna(value= val, inplace = True)\nprint(\"After: Number of cells with missing values in test data: \" + str(np.sum(np.sum(my_test_dataset_X.isnull()))))\nnull_values_per_col = np.sum(my_test_dataset_X.isnull(), axis=0)\ncols_to_impute = []\nfor key in null_values_per_col.keys():\n    if null_values_per_col.get(key) != 0: \n        cols_to_impute.append(key)\nprint(\"After: Need to replace values in the columns in test data: \" + str(cols_to_impute) + \"\\n\")\n\n### Stage 4: \"Apply the model\"\nlm = LinearRegression()\nlm.fit(my_train_dataset_X, my_train_dataset.SalePrice)\n\n### Stage 5: \"Sanity Check - the better the quality, the higher the predicted SalesPrice?\"\nplt.scatter(my_test_dataset.OverallQual, lm.predict(my_test_dataset_X))\nplt.xlabel(\"Overall Quality of the house in test data\")\nplt.ylabel(\"Price of the house in test data\")\nplt.title(\"Relationship between Price and Quality in test data\")\nplt.show()\n\n### Stage 6: \"Check the performance of the Prediction\"\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(lm, my_train_dataset_X,  lm.predict(my_test_dataset_X), cv=10)\nprint(\"scores = \" + str(scores))\n</code></pre>\n\n<h2>My questions are:</h2>\n\n<p><strong>1. Why am I getting an error in Stage 6 and how to fix it?</strong></p>\n\n<hr>\n\n<pre><code>ValueError Traceback (most recent call last)\n&lt;ipython-input-2-700c31f0d410&gt; in &lt;module&gt;()\n     85 ### test the performance of the model\n     86 from sklearn.model_selection import cross_val_score\n---&gt; 87 scores = cross_val_score(lm, my_train_dataset_X,  lm.predict(my_test_dataset_X), cv=10)\n     88 print(\"scores = \" + str(scores))\n     89 \nValueError: Found input variables with inconsistent numbers of samples: [1460, 1459]\n</code></pre>\n\n<p><strong>2. Is there something <em>fundamentally wrong</em> with my approach to a simple and basic Linear Regression?</strong></p>\n\n<hr>\n\n<h2>Edits for comments:</h2>\n\n<p><strong>@CalZ - First comment:</strong></p>\n\n<pre><code>my_test_dataset_X.shape = (1459, 36)\nmy_train_dataset_X.shape = (1460, 36)\n</code></pre>\n\n<p><strong>@CalZ - Second comment:</strong>\nI will consider refactoring the code as soon as I am sure that my approach is not fundamentally wrong.</p>\n\n<hr>\n",
                "tags": "<python><scikit-learn><linear-regression><cross-validation>",
                "answers": [
                    [
                        "19590",
                        "2",
                        "19586",
                        "",
                        "",
                        "<ol>\n<li><p>As the error message states, the invocation to <code>cross_val_score</code> fails because the shape arguments differ in their first dimension (1460 vs. 1459). This is consistent with the number of lines in the CSV files. However, the underlying problem is that you are mixing the test and the training sets. You should invoke it only with the test set: <code>cross_val_score(lm, my_test_dataset_X,  lm.predict(my_test_dataset_X), cv=10)</code>. <strong>Update</strong>: My initial suggestion was NOT correct, you cannot use your own predictions to validate! You should leave a subset of the labeled data for hold out on which to compute the cross validation.</p></li>\n<li><p>Yours is not only a linear regression. The bulk of your code is in charge of data manipulation (feature selection, data imputation) and not linear regression. Actually, you are reusing scikit-learn's implementation of linear regresion, not coding your own. If you want a code review of your snippet, maybe you should try in <a href=\"http://codereview.stackexchange.com\">http://codereview.stackexchange.com</a> (I don't know if this fits there either, you'd better check their <a href=\"https://codereview.stackexchange.com/help\">help center</a>).</p></li>\n</ol>\n\n<p>UPDATE: About whether your code is sound from a data science point of view, it seems to me (after only a quick review) that you are doing reasonable things. There are some things that could be improved, like only handling float64 and int64 (while you can do as described <a href=\"https://stackoverflow.com/q/25039626/674487\">here</a>), only imputing NaNs and Nones (while there can be other values that should be imputed in certain cases, like outliers),  or imputing blindly with the median (which is a <em>safe</em> decision but should be assessed taking into account the nature of each variable). But generally speaking seems Ok.</p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9680",
            "_score": 14.409143,
            "_source": {
                "title": "How do I plot linear regression results if input and target have different sizes?",
                "content": "How do I plot linear regression results if input and target have different sizes? <p>For a linear regression model that I conducted, I'd like to review the regression plot of results. But since I have an input of size 6 parameters and target (output therefore) of 4, I get error when I use this code : <a href=\"https://www.google.it/url?sa=t&amp;source=web&amp;rct=j&amp;url=https://stackoverflow.com/questions/46382550/plot-sklearn-linearregression-output-with-matplotlib&amp;ved=2ahUKEwi4667ppJncAhXGkSwKHVPEAb0QFjAAegQIBhAB&amp;usg=AOvVaw3ecBTfVKDS90iW0g6qbWAM\" rel=\"nofollow noreferrer\">source code</a> </p>\n\n<pre><code>pyplot.scatter(x_train, y_train)\npyplot.plot(np.sort(x_values, axis=0,prediction)\npyplot.show()\n</code></pre>\n <scikit-learn><regression><linear-regression><p>You can plot your residuals. I am sorry I can't write it in Python but in R you would do it like this:</p>\n\n<pre><code>plot(my.model$residuals)\n</code></pre>\n\n<p>This will give you a scatterplot that you WANT to look like a null plot. Any curve or pattern in the points means that your model is not a good fit.</p>\n\n<p>If you are interested in assessing each variable's prediction power I recommend (because you only have six) doing 1 regression model on each variable <em>by itself</em> and then plotting the residuals of those models, again looking for a null plot. You can also look at the correlation of each predictor variable vs your response variable. Those with higher correlation will be better predictors.</p>\n",
                "codes": [
                    [
                        "plot(my.model$residuals)\n"
                    ]
                ],
                "question_id:": "34362",
                "question_votes:": "1",
                "question_text:": "<p>For a linear regression model that I conducted, I'd like to review the regression plot of results. But since I have an input of size 6 parameters and target (output therefore) of 4, I get error when I use this code : <a href=\"https://www.google.it/url?sa=t&amp;source=web&amp;rct=j&amp;url=https://stackoverflow.com/questions/46382550/plot-sklearn-linearregression-output-with-matplotlib&amp;ved=2ahUKEwi4667ppJncAhXGkSwKHVPEAb0QFjAAegQIBhAB&amp;usg=AOvVaw3ecBTfVKDS90iW0g6qbWAM\" rel=\"nofollow noreferrer\">source code</a> </p>\n\n<pre><code>pyplot.scatter(x_train, y_train)\npyplot.plot(np.sort(x_values, axis=0,prediction)\npyplot.show()\n</code></pre>\n",
                "tags": "<scikit-learn><regression><linear-regression>",
                "answers": [
                    [
                        "35617",
                        "2",
                        "34362",
                        "",
                        "",
                        "<p>You can plot your residuals. I am sorry I can't write it in Python but in R you would do it like this:</p>\n\n<pre><code>plot(my.model$residuals)\n</code></pre>\n\n<p>This will give you a scatterplot that you WANT to look like a null plot. Any curve or pattern in the points means that your model is not a good fit.</p>\n\n<p>If you are interested in assessing each variable's prediction power I recommend (because you only have six) doing 1 regression model on each variable <em>by itself</em> and then plotting the residuals of those models, again looking for a null plot. You can also look at the correlation of each predictor variable vs your response variable. Those with higher correlation will be better predictors.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17901",
            "_score": 14.363738,
            "_source": {
                "title": "Sklearn ValueError: X has 2 features per sample; expecting 11",
                "content": "Sklearn ValueError: X has 2 features per sample; expecting 11 <p>I try to visualizing multiple logistic regression but I get the above error. </p>\n\n<p>I'm practicing on <a href=\"https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009\" rel=\"nofollow noreferrer\">red wine quality</a> data set from kaggle.</p>\n\n<p>Here is a full traceback:</p>\n\n<pre><code>---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-88-230199fd3a97&gt; in &lt;module&gt;\n      4 X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n      5                      np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n----&gt; 6 plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n      7              alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n      8 plt.xlim(X1.min(), X1.max())\n\n/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/base.py in predict(self, X)\n    287             Predicted class label per sample.\n    288         \"\"\"\n--&gt; 289         scores = self.decision_function(X)\n    290         if len(scores.shape) == 1:\n    291             indices = (scores &gt; 0).astype(np.int)\n\n/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/base.py in decision_function(self, X)\n    268         if X.shape[1] != n_features:\n    269             raise ValueError(\"X has %d features per sample; expecting %d\"\n--&gt; 270                              % (X.shape[1], n_features))\n    271 \n    272         scores = safe_sparse_dot(X, self.coef_.T,\n\nValueError: X has 2 features per sample; expecting 11\n</code></pre>\n\n<p>Here is the code:</p>\n\n<pre><code>#Split the variables\nX = dataset.iloc[:, :11].values\ny = dataset.iloc[:, -1].values\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# Fitting Logistic Regression to the Training set\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nacc_score = accuracy_score(y_test, y_pred)\nprint(acc_score*100)\n</code></pre>\n\n<p>Below is the visualization code:</p>\n\n<pre><code># Visualising the Training set results\nfrom matplotlib.colors import ListedColormap\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('Logistic Regression (Training set)')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\nplt.legend()\nplt.show()\n</code></pre>\n\n<p>I know that the error is that the model has been trained using 11 functions, but it is envisaged to use 2 functions, but I do not know exactly what to change.</p>\n <python><scikit-learn>",
                "codes": [],
                "question_id:": "57243",
                "question_votes:": "",
                "question_text:": "<p>I try to visualizing multiple logistic regression but I get the above error. </p>\n\n<p>I'm practicing on <a href=\"https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009\" rel=\"nofollow noreferrer\">red wine quality</a> data set from kaggle.</p>\n\n<p>Here is a full traceback:</p>\n\n<pre><code>---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-88-230199fd3a97&gt; in &lt;module&gt;\n      4 X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n      5                      np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n----&gt; 6 plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n      7              alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n      8 plt.xlim(X1.min(), X1.max())\n\n/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/base.py in predict(self, X)\n    287             Predicted class label per sample.\n    288         \"\"\"\n--&gt; 289         scores = self.decision_function(X)\n    290         if len(scores.shape) == 1:\n    291             indices = (scores &gt; 0).astype(np.int)\n\n/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/base.py in decision_function(self, X)\n    268         if X.shape[1] != n_features:\n    269             raise ValueError(\"X has %d features per sample; expecting %d\"\n--&gt; 270                              % (X.shape[1], n_features))\n    271 \n    272         scores = safe_sparse_dot(X, self.coef_.T,\n\nValueError: X has 2 features per sample; expecting 11\n</code></pre>\n\n<p>Here is the code:</p>\n\n<pre><code>#Split the variables\nX = dataset.iloc[:, :11].values\ny = dataset.iloc[:, -1].values\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# Fitting Logistic Regression to the Training set\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nacc_score = accuracy_score(y_test, y_pred)\nprint(acc_score*100)\n</code></pre>\n\n<p>Below is the visualization code:</p>\n\n<pre><code># Visualising the Training set results\nfrom matplotlib.colors import ListedColormap\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('Logistic Regression (Training set)')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\nplt.legend()\nplt.show()\n</code></pre>\n\n<p>I know that the error is that the model has been trained using 11 functions, but it is envisaged to use 2 functions, but I do not know exactly what to change.</p>\n",
                "tags": "<python><scikit-learn>",
                "answers": []
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17017",
            "_score": 14.343251,
            "_source": {
                "title": "Suggestion of a model for these type of data?",
                "content": "Suggestion of a model for these type of data? <p>I've got a data set that looks like this</p>\n\n<pre><code>physical_data1   physical_data2  switch1   switch2   state\n400              500             1         0         Normal\n400              500             1         1         Normal\n500              650             0         0         Normal\n600              700             1         0         Normal\n1000             300             1         1         Anomaly!\n</code></pre>\n\n<p>where physical_data are data that are from 0 to 1000 and switch are switches that are binary (1 means on 0 means off).</p>\n\n<p>I am still relatively new to machine-learning and so I am wondering what kind of machine-learning algorithm is best suited for these kinds of data to detect anomalies, where my data has mixed features of physical and binary quantities.</p>\n\n<p>Things that i have done are, normalizing to [0,1], however i am not quite sure if applying PCA to this kind of data will result in a loss of detection rate because it requires all features to determine if a particular reading is normal or an anomaly.</p>\n\n<p>One other question I have is that what if in my data set i do not have the Anomaly data, instead, only have normal data. In that case what kind of model can i use?</p>\n <machine-learning><data><machine-learning-model><pca><p>Try <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\" rel=\"nofollow noreferrer\">Naive bayes</a>. It's simple and can be used, if the features are independent of each others.</p>\n<p>Any kind of classification algorithm should be alright for your data.</p>\n\n<p>Logistic Regression is probably the first thing you will learn in a ML tutorial.</p>\n\n<p><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</a></p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "55334",
                "question_votes:": "",
                "question_text:": "<p>I've got a data set that looks like this</p>\n\n<pre><code>physical_data1   physical_data2  switch1   switch2   state\n400              500             1         0         Normal\n400              500             1         1         Normal\n500              650             0         0         Normal\n600              700             1         0         Normal\n1000             300             1         1         Anomaly!\n</code></pre>\n\n<p>where physical_data are data that are from 0 to 1000 and switch are switches that are binary (1 means on 0 means off).</p>\n\n<p>I am still relatively new to machine-learning and so I am wondering what kind of machine-learning algorithm is best suited for these kinds of data to detect anomalies, where my data has mixed features of physical and binary quantities.</p>\n\n<p>Things that i have done are, normalizing to [0,1], however i am not quite sure if applying PCA to this kind of data will result in a loss of detection rate because it requires all features to determine if a particular reading is normal or an anomaly.</p>\n\n<p>One other question I have is that what if in my data set i do not have the Anomaly data, instead, only have normal data. In that case what kind of model can i use?</p>\n",
                "tags": "<machine-learning><data><machine-learning-model><pca>",
                "answers": [
                    [
                        "55337",
                        "2",
                        "55334",
                        "",
                        "",
                        "<p>Try <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\" rel=\"nofollow noreferrer\">Naive bayes</a>. It's simple and can be used, if the features are independent of each others.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "55357",
                        "2",
                        "55334",
                        "",
                        "",
                        "<p>Any kind of classification algorithm should be alright for your data.</p>\n\n<p>Logistic Regression is probably the first thing you will learn in a ML tutorial.</p>\n\n<p><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</a></p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "2367",
            "_score": 14.286113,
            "_source": {
                "title": "Use of cross validation for Polynomial Regression",
                "content": "Use of cross validation for Polynomial Regression <p>I've two text files which contains my data.\nOne text file on X axis another text file on Y axis\nThen using scatter function from python I did the data visualization\nAfter that, I used polyfit function from python to get the curve which will fit my data\nIn that polyfit function we need to write degree of the polynomial we want eg. 2 or 3\nNow let's consider I got 4 such a equations of degrees 2,3,4,5 respectively.\nNow here comes my problem.\nAmong all those equations I got, how can I select the best equation which fits my data. I want to use cross validation here. Any high level library function can be use. My language is Python. </p>\n <machine-learning><python><regression><scikit-learn><cross-validation><p>I think that you want this:</p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html#sklearn.cross_validation.KFold\" rel=\"nofollow\">K-fold</a></p>\n\n<p>If you want say MSE of each check out section 3.1.1 here:</p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics\" rel=\"nofollow\">cross validated metrics</a></p>\n<p>If instead of Numpy's polyfit function, you use one of <a href=\"http://scikit-learn.org/stable/auto_examples/linear_model/plot_polynomial_interpolation.html\" rel=\"nofollow\">Scikit's generalized linear models with polynomial features</a>, you can then apply  <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html#sklearn.grid_search.GridSearchCV\" rel=\"nofollow\">GridSearch with Cross Validation</a> and pass in degrees as a parameter. It will find the best model based on the input features (i.e. 2,3,4,5). </p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "11346",
                "question_votes:": "",
                "question_text:": "<p>I've two text files which contains my data.\nOne text file on X axis another text file on Y axis\nThen using scatter function from python I did the data visualization\nAfter that, I used polyfit function from python to get the curve which will fit my data\nIn that polyfit function we need to write degree of the polynomial we want eg. 2 or 3\nNow let's consider I got 4 such a equations of degrees 2,3,4,5 respectively.\nNow here comes my problem.\nAmong all those equations I got, how can I select the best equation which fits my data. I want to use cross validation here. Any high level library function can be use. My language is Python. </p>\n",
                "tags": "<machine-learning><python><regression><scikit-learn><cross-validation>",
                "answers": [
                    [
                        "11348",
                        "2",
                        "11346",
                        "",
                        "",
                        "<p>I think that you want this:</p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html#sklearn.cross_validation.KFold\" rel=\"nofollow\">K-fold</a></p>\n\n<p>If you want say MSE of each check out section 3.1.1 here:</p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics\" rel=\"nofollow\">cross validated metrics</a></p>\n",
                        "",
                        "2"
                    ],
                    [
                        "11352",
                        "2",
                        "11346",
                        "",
                        "",
                        "<p>If instead of Numpy's polyfit function, you use one of <a href=\"http://scikit-learn.org/stable/auto_examples/linear_model/plot_polynomial_interpolation.html\" rel=\"nofollow\">Scikit's generalized linear models with polynomial features</a>, you can then apply  <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html#sklearn.grid_search.GridSearchCV\" rel=\"nofollow\">GridSearch with Cross Validation</a> and pass in degrees as a parameter. It will find the best model based on the input features (i.e. 2,3,4,5). </p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7855",
            "_score": 14.226035,
            "_source": {
                "title": "feature names in LogisticRegression()",
                "content": "feature names in LogisticRegression() <p>I want to know feature names that a LogisticRegression() Model has used along with their corresponding weights in scikit-learn. I can access to weights using <code>coef_</code>, but i did not know how can pair them with their corresponding weights. </p>\n <python><scikit-learn><logistic-regression><p>I made a scenario:</p>\n\n<pre><code>from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model.logistic import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nmax_features = 100\ntfidf = TfidfVectorizer(max_features=max_features)#stop_words='english',)# norm = None)#)\n\n#Simple\ntexts_train = ['positive sample', 'again positive', 'negative sample', 'again negative']\ntarget_train = [1,1,0,0]\ntexts_test = ['negative', 'positive']\ntarget_test = [0,1]\ntexts_train1 = tfidf.fit_transform(texts_train)\ntexts_test1 = tfidf.transform(texts_test)\nclassifier = LogisticRegression()\nclassifier.fit(texts_train1, target_train)\npredictions = classifier.predict(texts_test1)\n\nprint('accuracy (simple):', accuracy_score(target_test, predictions))\ntfidf.get_feature_names()\n</code></pre>\n\n<p>['again', 'negative', 'positive', 'sample']</p>\n\n<pre><code>classifier.coef_\n</code></pre>\n\n<p>array([[ 0.        , -0.56718183,  0.56718183,  0.        ]])\nthat makes sense!</p>\n",
                "codes": [
                    [
                        "from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model.logistic import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nmax_features = 100\ntfidf = TfidfVectorizer(max_features=max_features)#stop_words='english',)# norm = None)#)\n\n#Simple\ntexts_train = ['positive sample', 'again positive', 'negative sample', 'again negative']\ntarget_train = [1,1,0,0]\ntexts_test = ['negative', 'positive']\ntarget_test = [0,1]\ntexts_train1 = tfidf.fit_transform(texts_train)\ntexts_test1 = tfidf.transform(texts_test)\nclassifier = LogisticRegression()\nclassifier.fit(texts_train1, target_train)\npredictions = classifier.predict(texts_test1)\n\nprint('accuracy (simple):', accuracy_score(target_test, predictions))\ntfidf.get_feature_names()\n",
                        "classifier.coef_\n"
                    ]
                ],
                "question_id:": "29131",
                "question_votes:": "1",
                "question_text:": "<p>I want to know feature names that a LogisticRegression() Model has used along with their corresponding weights in scikit-learn. I can access to weights using <code>coef_</code>, but i did not know how can pair them with their corresponding weights. </p>\n",
                "tags": "<python><scikit-learn><logistic-regression>",
                "answers": [
                    [
                        "29137",
                        "2",
                        "29131",
                        "",
                        "",
                        "<p>I made a scenario:</p>\n\n<pre><code>from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model.logistic import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nmax_features = 100\ntfidf = TfidfVectorizer(max_features=max_features)#stop_words='english',)# norm = None)#)\n\n#Simple\ntexts_train = ['positive sample', 'again positive', 'negative sample', 'again negative']\ntarget_train = [1,1,0,0]\ntexts_test = ['negative', 'positive']\ntarget_test = [0,1]\ntexts_train1 = tfidf.fit_transform(texts_train)\ntexts_test1 = tfidf.transform(texts_test)\nclassifier = LogisticRegression()\nclassifier.fit(texts_train1, target_train)\npredictions = classifier.predict(texts_test1)\n\nprint('accuracy (simple):', accuracy_score(target_test, predictions))\ntfidf.get_feature_names()\n</code></pre>\n\n<p>['again', 'negative', 'positive', 'sample']</p>\n\n<pre><code>classifier.coef_\n</code></pre>\n\n<p>array([[ 0.        , -0.56718183,  0.56718183,  0.        ]])\nthat makes sense!</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7237",
            "_score": 14.156542,
            "_source": {
                "title": "Please help me out with this Python error - 'invalid syntax'",
                "content": "Please help me out with this Python error - 'invalid syntax' <h3>Code:</h3>\n\n<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import datasets, linear_model\nhouse_price = [245, 312, 279, 308, 199, 219, 405, 324, 319, 255]\nsize = [1400, 1600, 1700, 1875, 1100, 1550, 2350, 2450, 1425, 1700]\nsize2 = np.array(size).reshape((-1, 1))\n#fitting into the model\nregr = linear_model.LinearRegression()\nregr.fit(size2, house_price)\nprint(\"Coefficients: \\n\", regr.coef_)\nprint(\"intercept: \\n\", regr.intercept_)\n#############################\n#formula obtained for the trained model\ndef graph(formula, x_range):\n   x = np.array(x_range)\n   y = eval(formula)\n   plt.plot(x, y)\n#plotting the prediction line \ngraph('regr.coef_*x + regr.intercept_', range(1000, 2700))\nprint(regr.score(size2, house_price))\nplt.scatter (size,house_price, color='black')\nplt.ylabel('house price')\nplt.xlabel('size of house')\nplt.show()\n</code></pre>\n\n<h3>Error</h3>\n\n<blockquote>\n<pre><code>**Error Line:print regr.predict([2000])**\nError: File \"&lt;ipython-input-4-9afa91ca7f9e&gt;\", line 1\n    print regr.predict([2000])\n             ^\nSyntaxError: invalid syntax\n</code></pre>\n</blockquote>\n <machine-learning><python><linear-regression><p>In your current line </p>\n\n<pre><code>print regr.predict([2000])\n</code></pre>\n\n<p>This will not work. The first error is the lack of brackets around the contents of your print statement which is required in Python 3. Change this first to</p>\n\n<pre><code>print(regr.predict([2000]))\n</code></pre>\n\n<p>However, you will see that this does not work either. I suspect you are attempting to evaluate the price for a new $size = 2000$. You will need to reshape the input to your regression for this to work. </p>\n\n<pre><code>new_size = np.array([2000]).reshape((-1, 1))\nprint(regr.predict(new_size))\n</code></pre>\n\n<blockquote>\n  <p>[ 317.78380528]</p>\n</blockquote>\n",
                "codes": [
                    [
                        "print regr.predict([2000])\n",
                        "print(regr.predict([2000]))\n",
                        "new_size = np.array([2000]).reshape((-1, 1))\nprint(regr.predict(new_size))\n"
                    ]
                ],
                "question_id:": "27278",
                "question_votes:": "1",
                "question_text:": "<h3>Code:</h3>\n\n<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import datasets, linear_model\nhouse_price = [245, 312, 279, 308, 199, 219, 405, 324, 319, 255]\nsize = [1400, 1600, 1700, 1875, 1100, 1550, 2350, 2450, 1425, 1700]\nsize2 = np.array(size).reshape((-1, 1))\n#fitting into the model\nregr = linear_model.LinearRegression()\nregr.fit(size2, house_price)\nprint(\"Coefficients: \\n\", regr.coef_)\nprint(\"intercept: \\n\", regr.intercept_)\n#############################\n#formula obtained for the trained model\ndef graph(formula, x_range):\n   x = np.array(x_range)\n   y = eval(formula)\n   plt.plot(x, y)\n#plotting the prediction line \ngraph('regr.coef_*x + regr.intercept_', range(1000, 2700))\nprint(regr.score(size2, house_price))\nplt.scatter (size,house_price, color='black')\nplt.ylabel('house price')\nplt.xlabel('size of house')\nplt.show()\n</code></pre>\n\n<h3>Error</h3>\n\n<blockquote>\n<pre><code>**Error Line:print regr.predict([2000])**\nError: File \"&lt;ipython-input-4-9afa91ca7f9e&gt;\", line 1\n    print regr.predict([2000])\n             ^\nSyntaxError: invalid syntax\n</code></pre>\n</blockquote>\n",
                "tags": "<machine-learning><python><linear-regression>",
                "answers": [
                    [
                        "27281",
                        "2",
                        "27278",
                        "",
                        "",
                        "<p>In your current line </p>\n\n<pre><code>print regr.predict([2000])\n</code></pre>\n\n<p>This will not work. The first error is the lack of brackets around the contents of your print statement which is required in Python 3. Change this first to</p>\n\n<pre><code>print(regr.predict([2000]))\n</code></pre>\n\n<p>However, you will see that this does not work either. I suspect you are attempting to evaluate the price for a new $size = 2000$. You will need to reshape the input to your regression for this to work. </p>\n\n<pre><code>new_size = np.array([2000]).reshape((-1, 1))\nprint(regr.predict(new_size))\n</code></pre>\n\n<blockquote>\n  <p>[ 317.78380528]</p>\n</blockquote>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "2947",
            "_score": 14.154314,
            "_source": {
                "title": "How to move forward on Regression problem",
                "content": "How to move forward on Regression problem <p>I'm an undergrad interested in machine learning, and I'm playing around with some data in order to get a better understanding of the field.</p>\n\n<p><strong>DATA</strong></p>\n\n<p>I'm working with the following data:</p>\n\n<p><a href=\"https://i.stack.imgur.com/0QCyG.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/0QCyG.png\" alt=\"Regression plot\"></a></p>\n\n<p>To give you an idea of what you're looking at (sorry for the unlabeled axes) -- each data point corresponds to a basketball player's points per game (y-values) over a one-week period (x-values).</p>\n\n<p><strong>END GOAL</strong></p>\n\n<p>I want to predict progress throughout the year, so in order to test/train, I start with the first two points, fit a regression model, and then predict the third point. I then add the actual value of the third point to the set, re-train, and predict the fourth point, etc.</p>\n\n<p><strong>ISSUES</strong></p>\n\n<p>As you can see, the data is all over the place, and the predictions are just as messy (sometimes getting up to ~200 points per game, which is totally impossible).</p>\n\n<p>I've tested different degrees of linear regression (quadratic, cubic, etc.) and degree=1 is always the best predictor because of how wonky the data is.</p>\n\n<p><strong>IDEAS</strong></p>\n\n<p>I have thought of the following ways to get more accurate predictions:</p>\n\n<ul>\n<li>Smoothing the data, maybe using a moving average or some variant</li>\n<li>Set an upper limit for predictions </li>\n<li>Non-linear regression </li>\n</ul>\n\n<p>But outside of smoothing the data, I'm not sure if the rest are even possible in a regression model (upper limit) or applicable to this situation (non-linear).</p>\n\n<p><strong>QUESTION</strong></p>\n\n<p>Are any of the ideas I had above worth pursuing? If not, is there anything I should look into that might help me solve this problem?</p>\n\n<p>Thanks!</p>\n <machine-learning><regression><linear-regression><p>You have little features (as in none hehe). Your data reminds me a lot of stock market predictions, where you know nothing about what you're studying except for price. Furthermore, price behaves chaotically, because if it was easily predictable, then everybody would be predicting it, thus removing its predictability.</p>\n\n<p>Therefore, if you are serious about studying that data, you may want to look up literature on stock market prediction.</p>\n\n<p>I suggested in a comment that one approach could be to see this as a classification problem rather than a regression problem. This is in fact what many people do in the stock market. Instead of predicting actual price, people study whether the price will go up or down (and therefore whether they should buy or sell).</p>\n\n<p>Here is an example of what I mean, implemented in sklearn:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cross_validation import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\n\n# random signal\nn = 100\nt = np.arange(n)\nx = np.random.rand(n)\nplt.plot(t, x)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/waavw.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/waavw.png\" alt=\"random signal\"></a></p>\n\n<pre><code># model ups and downs: convert to 0s (down) and 1s (up)\nt = t[1:]\ny = ((np.sign(x[1:] - x[:-1])+1)/2).astype(int)\nplt.plot(t, y)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/Gu42l.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Gu42l.png\" alt=\"ups and downs\"></a></p>\n\n<pre><code># one look-ahead model using the four previous observations\nX = np.c_[y[:-4], y[1:-3], y[2:-2], y[3:-1]]\ny = y[4:]\nscores = cross_val_score(LogisticRegression(), X, y, cv=10, n_jobs=-1)\nprint('Acc: %.2f (%.2f)' % (np.mean(scores), np.std(scores)))\n</code></pre>\n\n<p>My results:</p>\n\n<pre><code>Acc: 0.75 (0.17)\n</code></pre>\n\n<p>One advantage of this approach is that it gives you probabilities of going up or down. Remember, a logistic regression is a probabilistic model $P(y|x)$, and here we are taking $P(y|x)&lt;0.5$ to mean down and $P(y|x)&gt;0.5$ to mean up. But if the probability is close to 0.5, you could have your model say \"I don't know\". This way you only take action when the model reports down or up with high confidence (close to 0 (down) or 1 (up)). A colleague of mine wrote <a href=\"https://sigarra.up.pt/flup/pt/pub_geral.show_file?pi_gdoc_id=91387\" rel=\"nofollow noreferrer\">his thesis</a> on this kind of thing. Are you trying to model sports in order to place bets? If so, this is a pretty simple but effective model of choosing when it is worthy to place bets.</p>\n\n<p>But if the idea is to learn about data mining, then I would try another dataset.</p>\n\n<ul>\n<li>sklearn comes with a bunch of <a href=\"http://scikit-learn.org/stable/datasets/\" rel=\"nofollow noreferrer\">nice datasets</a></li>\n<li>kaggle has a lot of 101 training competitions <a href=\"https://www.kaggle.com/competitions\" rel=\"nofollow noreferrer\">rich in tutorials</a></li>\n</ul>\n",
                "codes": [
                    [
                        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cross_validation import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\n\n# random signal\nn = 100\nt = np.arange(n)\nx = np.random.rand(n)\nplt.plot(t, x)\nplt.show()\n",
                        "# model ups and downs: convert to 0s (down) and 1s (up)\nt = t[1:]\ny = ((np.sign(x[1:] - x[:-1])+1)/2).astype(int)\nplt.plot(t, y)\nplt.show()\n",
                        "# one look-ahead model using the four previous observations\nX = np.c_[y[:-4], y[1:-3], y[2:-2], y[3:-1]]\ny = y[4:]\nscores = cross_val_score(LogisticRegression(), X, y, cv=10, n_jobs=-1)\nprint('Acc: %.2f (%.2f)' % (np.mean(scores), np.std(scores)))\n",
                        "Acc: 0.75 (0.17)\n"
                    ]
                ],
                "question_id:": "13040",
                "question_votes:": "",
                "question_text:": "<p>I'm an undergrad interested in machine learning, and I'm playing around with some data in order to get a better understanding of the field.</p>\n\n<p><strong>DATA</strong></p>\n\n<p>I'm working with the following data:</p>\n\n<p><a href=\"https://i.stack.imgur.com/0QCyG.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/0QCyG.png\" alt=\"Regression plot\"></a></p>\n\n<p>To give you an idea of what you're looking at (sorry for the unlabeled axes) -- each data point corresponds to a basketball player's points per game (y-values) over a one-week period (x-values).</p>\n\n<p><strong>END GOAL</strong></p>\n\n<p>I want to predict progress throughout the year, so in order to test/train, I start with the first two points, fit a regression model, and then predict the third point. I then add the actual value of the third point to the set, re-train, and predict the fourth point, etc.</p>\n\n<p><strong>ISSUES</strong></p>\n\n<p>As you can see, the data is all over the place, and the predictions are just as messy (sometimes getting up to ~200 points per game, which is totally impossible).</p>\n\n<p>I've tested different degrees of linear regression (quadratic, cubic, etc.) and degree=1 is always the best predictor because of how wonky the data is.</p>\n\n<p><strong>IDEAS</strong></p>\n\n<p>I have thought of the following ways to get more accurate predictions:</p>\n\n<ul>\n<li>Smoothing the data, maybe using a moving average or some variant</li>\n<li>Set an upper limit for predictions </li>\n<li>Non-linear regression </li>\n</ul>\n\n<p>But outside of smoothing the data, I'm not sure if the rest are even possible in a regression model (upper limit) or applicable to this situation (non-linear).</p>\n\n<p><strong>QUESTION</strong></p>\n\n<p>Are any of the ideas I had above worth pursuing? If not, is there anything I should look into that might help me solve this problem?</p>\n\n<p>Thanks!</p>\n",
                "tags": "<machine-learning><regression><linear-regression>",
                "answers": [
                    [
                        "13103",
                        "2",
                        "13040",
                        "",
                        "",
                        "<p>You have little features (as in none hehe). Your data reminds me a lot of stock market predictions, where you know nothing about what you're studying except for price. Furthermore, price behaves chaotically, because if it was easily predictable, then everybody would be predicting it, thus removing its predictability.</p>\n\n<p>Therefore, if you are serious about studying that data, you may want to look up literature on stock market prediction.</p>\n\n<p>I suggested in a comment that one approach could be to see this as a classification problem rather than a regression problem. This is in fact what many people do in the stock market. Instead of predicting actual price, people study whether the price will go up or down (and therefore whether they should buy or sell).</p>\n\n<p>Here is an example of what I mean, implemented in sklearn:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cross_validation import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\n\n# random signal\nn = 100\nt = np.arange(n)\nx = np.random.rand(n)\nplt.plot(t, x)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/waavw.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/waavw.png\" alt=\"random signal\"></a></p>\n\n<pre><code># model ups and downs: convert to 0s (down) and 1s (up)\nt = t[1:]\ny = ((np.sign(x[1:] - x[:-1])+1)/2).astype(int)\nplt.plot(t, y)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/Gu42l.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Gu42l.png\" alt=\"ups and downs\"></a></p>\n\n<pre><code># one look-ahead model using the four previous observations\nX = np.c_[y[:-4], y[1:-3], y[2:-2], y[3:-1]]\ny = y[4:]\nscores = cross_val_score(LogisticRegression(), X, y, cv=10, n_jobs=-1)\nprint('Acc: %.2f (%.2f)' % (np.mean(scores), np.std(scores)))\n</code></pre>\n\n<p>My results:</p>\n\n<pre><code>Acc: 0.75 (0.17)\n</code></pre>\n\n<p>One advantage of this approach is that it gives you probabilities of going up or down. Remember, a logistic regression is a probabilistic model $P(y|x)$, and here we are taking $P(y|x)&lt;0.5$ to mean down and $P(y|x)&gt;0.5$ to mean up. But if the probability is close to 0.5, you could have your model say \"I don't know\". This way you only take action when the model reports down or up with high confidence (close to 0 (down) or 1 (up)). A colleague of mine wrote <a href=\"https://sigarra.up.pt/flup/pt/pub_geral.show_file?pi_gdoc_id=91387\" rel=\"nofollow noreferrer\">his thesis</a> on this kind of thing. Are you trying to model sports in order to place bets? If so, this is a pretty simple but effective model of choosing when it is worthy to place bets.</p>\n\n<p>But if the idea is to learn about data mining, then I would try another dataset.</p>\n\n<ul>\n<li>sklearn comes with a bunch of <a href=\"http://scikit-learn.org/stable/datasets/\" rel=\"nofollow noreferrer\">nice datasets</a></li>\n<li>kaggle has a lot of 101 training competitions <a href=\"https://www.kaggle.com/competitions\" rel=\"nofollow noreferrer\">rich in tutorials</a></li>\n</ul>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3718",
            "_score": 14.143361,
            "_source": {
                "title": "Which algorithm to use to predict the duration of some task",
                "content": "Which algorithm to use to predict the duration of some task <p>I have a data set of 36K processes each with 7 features. Each set represents a task and I know how long it took to complete each of the tasks. <strong>I want to build a model which will be able to predict the duration of the future tasks.</strong></p>\n\n<p>I've only learned about Decision Tree (DT) and tried to apply it to my problem. The resulting accuracy score is 0.03. I believe DT is not suitable because the time is continuous and DT is meant for categorization.</p>\n\n<p><strong>Which algorithm is suitable for duration prediction?</strong></p>\n\n<p>My environment: Python with sklearn, if that matters.</p>\n <machine-learning><algorithms><p>What others have said is accurate, that you need to build a regression model of some sort. Depending on the scale of the duration of your task, you will have to model it slightly differently. </p>\n\n<p>In fact, there's an entire class of models that try to predict duration. These are called survival models. <a href=\"https://github.com/sashaostr/sklearn-lifelines\" rel=\"nofollow noreferrer\">Here's a Python library on survival analysis.</a></p>\n\n<p>But these models are fairly academic. A typical hack is to use Gamma, Poison, or Log-Normal regression which works out nicely because these models predict non-negative values. </p>\n<p>You are facing a <strong>regression</strong> problem: your aim is to predict the value of a continuous variable given the value of a set of input variables (these input variables can be of any type: numbers, categories, etc.) A decision tree is usually applied to classification problems, in which you are aiming at predicting a discrete value. </p>\n\n<p>There are several regression methods in sklearn that you could use. The simplest ones, and maybe the ones you should start from, are linear models: <a href=\"http://scikit-learn.org/stable/modules/linear_model.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/linear_model.html</a>. </p>\n\n<p>Notice that you may need to transform your input data. For instance, if one of the features is categorical, you may need to transform it into a set of <a href=\"https://en.wikipedia.org/wiki/Dummy_variable_(statistics)\" rel=\"nofollow noreferrer\">binary variables</a>. Other processes, like data normalisation, may also be advisable in order to get better results. </p>\n\n<p><strong>Edit</strong>: as stated in the comments, Decision Trees can also be applied to regression problems. However, and in my own experience, the output curve that you obtain by means of this algorithm usually has a step-wise shape that may affect the final bias (see, for instance <a href=\"http://scikit-learn.org/stable/modules/tree.html\" rel=\"nofollow noreferrer\">the example in the scikit-learn docs.</a>). I would suggest not to constraint yourself and try different types of algorithms. </p>\n<p>You might want to look into scikit's <a href=\"http://scikit-learn.org/stable/modules/tree.html#tree-regression\" rel=\"nofollow noreferrer\">DecisionTreeRegressor() class</a>. A decision tree regressor will predict a real number. The decision tree classifier, by contrast, will predict a discrete class for an observation. A more advanced version would be the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\" rel=\"nofollow noreferrer\">RandomForestRegressor() class</a>, which builds a <a href=\"https://en.wikipedia.org/wiki/Random_forest\" rel=\"nofollow noreferrer\">random forest</a> of regression trees. A third option to consider might be a <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor\" rel=\"nofollow noreferrer\">GradientBoostedRegressor()</a>.</p>\n\n<p>I would also recommend <a href=\"http://scikit-learn.org/stable/tutorial/machine_learning_map/\" rel=\"nofollow noreferrer\">this flow chart</a> from Scikit that can help you choose an estimator.</p>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "15472",
                "question_votes:": "3",
                "question_text:": "<p>I have a data set of 36K processes each with 7 features. Each set represents a task and I know how long it took to complete each of the tasks. <strong>I want to build a model which will be able to predict the duration of the future tasks.</strong></p>\n\n<p>I've only learned about Decision Tree (DT) and tried to apply it to my problem. The resulting accuracy score is 0.03. I believe DT is not suitable because the time is continuous and DT is meant for categorization.</p>\n\n<p><strong>Which algorithm is suitable for duration prediction?</strong></p>\n\n<p>My environment: Python with sklearn, if that matters.</p>\n",
                "tags": "<machine-learning><algorithms>",
                "answers": [
                    [
                        "15502",
                        "2",
                        "15472",
                        "",
                        "",
                        "<p>What others have said is accurate, that you need to build a regression model of some sort. Depending on the scale of the duration of your task, you will have to model it slightly differently. </p>\n\n<p>In fact, there's an entire class of models that try to predict duration. These are called survival models. <a href=\"https://github.com/sashaostr/sklearn-lifelines\" rel=\"nofollow noreferrer\">Here's a Python library on survival analysis.</a></p>\n\n<p>But these models are fairly academic. A typical hack is to use Gamma, Poison, or Log-Normal regression which works out nicely because these models predict non-negative values. </p>\n",
                        "",
                        "4"
                    ],
                    [
                        "15479",
                        "2",
                        "15472",
                        "",
                        "",
                        "<p>You are facing a <strong>regression</strong> problem: your aim is to predict the value of a continuous variable given the value of a set of input variables (these input variables can be of any type: numbers, categories, etc.) A decision tree is usually applied to classification problems, in which you are aiming at predicting a discrete value. </p>\n\n<p>There are several regression methods in sklearn that you could use. The simplest ones, and maybe the ones you should start from, are linear models: <a href=\"http://scikit-learn.org/stable/modules/linear_model.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/linear_model.html</a>. </p>\n\n<p>Notice that you may need to transform your input data. For instance, if one of the features is categorical, you may need to transform it into a set of <a href=\"https://en.wikipedia.org/wiki/Dummy_variable_(statistics)\" rel=\"nofollow noreferrer\">binary variables</a>. Other processes, like data normalisation, may also be advisable in order to get better results. </p>\n\n<p><strong>Edit</strong>: as stated in the comments, Decision Trees can also be applied to regression problems. However, and in my own experience, the output curve that you obtain by means of this algorithm usually has a step-wise shape that may affect the final bias (see, for instance <a href=\"http://scikit-learn.org/stable/modules/tree.html\" rel=\"nofollow noreferrer\">the example in the scikit-learn docs.</a>). I would suggest not to constraint yourself and try different types of algorithms. </p>\n",
                        "",
                        ""
                    ],
                    [
                        "15473",
                        "2",
                        "15472",
                        "",
                        "",
                        "<p>You might want to look into scikit's <a href=\"http://scikit-learn.org/stable/modules/tree.html#tree-regression\" rel=\"nofollow noreferrer\">DecisionTreeRegressor() class</a>. A decision tree regressor will predict a real number. The decision tree classifier, by contrast, will predict a discrete class for an observation. A more advanced version would be the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\" rel=\"nofollow noreferrer\">RandomForestRegressor() class</a>, which builds a <a href=\"https://en.wikipedia.org/wiki/Random_forest\" rel=\"nofollow noreferrer\">random forest</a> of regression trees. A third option to consider might be a <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor\" rel=\"nofollow noreferrer\">GradientBoostedRegressor()</a>.</p>\n\n<p>I would also recommend <a href=\"http://scikit-learn.org/stable/tutorial/machine_learning_map/\" rel=\"nofollow noreferrer\">this flow chart</a> from Scikit that can help you choose an estimator.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12554",
            "_score": 14.12201,
            "_source": {
                "title": "Dealing with normalized regression output",
                "content": "Dealing with normalized regression output <p>I have a regression model that is trained on a bunch of features and normalized targets so naturally when I use the model to predict on a new input, the output is also normalized (well not normalized per se but not what I expect to see). How should I deal with this? I tried using the <code>inverse_transform</code> function in sklearn that is in most scalers but it's not giving me correct results. This is probably because it wasn't already fitted on this data and therefore doesn't know how to inverse it. What can I do?</p>\n <machine-learning><regression><feature-scaling><p>In linear regression, you don't have to normalize the output variable. This is actually why, for example, <code>StandardScaler</code> ignores <code>y</code> input even if you had entered. Also, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.inverse_transform\" rel=\"nofollow noreferrer\"><code>inverse_transform</code></a> is for the input variable. The prediction you get should be in your actual output domain.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "44036",
                "question_votes:": "",
                "question_text:": "<p>I have a regression model that is trained on a bunch of features and normalized targets so naturally when I use the model to predict on a new input, the output is also normalized (well not normalized per se but not what I expect to see). How should I deal with this? I tried using the <code>inverse_transform</code> function in sklearn that is in most scalers but it's not giving me correct results. This is probably because it wasn't already fitted on this data and therefore doesn't know how to inverse it. What can I do?</p>\n",
                "tags": "<machine-learning><regression><feature-scaling>",
                "answers": [
                    [
                        "44040",
                        "2",
                        "44036",
                        "",
                        "",
                        "<p>In linear regression, you don't have to normalize the output variable. This is actually why, for example, <code>StandardScaler</code> ignores <code>y</code> input even if you had entered. Also, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.inverse_transform\" rel=\"nofollow noreferrer\"><code>inverse_transform</code></a> is for the input variable. The prediction you get should be in your actual output domain.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5054",
            "_score": 14.091292,
            "_source": {
                "title": "Large mean squared error in sklearn regressors",
                "content": "Large mean squared error in sklearn regressors <p>I'm a beginner in machine learning and I want to build a model to predict the price of houses. I prepared a dataset by crawling a local housing website and it consists 1000 samples and only 4 features (latitude, longitude, area and number of rooms).</p>\n\n<p>I tried RandomForestRegressorand LinearSVR models in sklearn, but I can't train the model properly and the MSE is super high.</p>\n\n<p>MSE almost equals 90,000,000 (the true values of prices' range are between 5,000,000 - 900,000,000)</p>\n\n<p>Here is my code:</p>\n\n<pre><code>import numpy as np\nfrom sklearn.svm import LinearSVR\nimport pandas as pd\nimport csv\nfrom sklearn.preprocessing import normalize\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv('dataset.csv', index_col=False)\nX = df.drop('price', axis=1)\n\nX_data = X.values\nY_data = df.price.values\nX_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=5)\n\nrgr = RandomForestRegressor(n_estimators=100)\nsvr = LinearSVR()\n\nrgr.fit(X_train, Y_train)\nsvr.fit(X_train, Y_train)\n\nMSEs = cross_val_score(estimator=rgr,\n                         X=X_train,\n                         y=Y_train,\n                         scoring='mean_squared_error',\n                         cv=5)\n\nMSEsSVR = cross_val_score(estimator=svr,\n                         X=X_train,\n                         y=Y_train,\n                         scoring='mean_squared_error',\n                         cv=5)\n\nMSEs *= -1\nRMSEs = np.sqrt(MSEs)\n\nprint(\"Root mean squared error with 95% confidence interval:\")\nprint(\"{:.3f} (+/- {:.3f})\".format(RMSEs.mean(), RMSEs.std()*2))\nprint(\"\")\n</code></pre>\n\n<p>Is the problem with my dataset and count of features? How can I build a prediction model with this type of dataset?</p>\n <machine-learning><python><regression><scikit-learn><p>I removed 20 percent of most expensive houses from dataset and divided the prices by 1.000.000 and the result got much better.</p>\n<p>that's possibly due to poor parameter tuning. <br>\nTry reducing C for SVR and increasing n_estimators for RFR. <br></p>\n\n<p>A nice approach is to gridsearch through the parameter, and plot the metric result. <br></p>\n\n<p>Another thing that might help is to normalize the parameters (sklearn.preprocessing.StandardScaler) and to remove the skew from the target (usually log transform or 1/target transform works better)</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "19615",
                "question_votes:": "3",
                "question_text:": "<p>I'm a beginner in machine learning and I want to build a model to predict the price of houses. I prepared a dataset by crawling a local housing website and it consists 1000 samples and only 4 features (latitude, longitude, area and number of rooms).</p>\n\n<p>I tried RandomForestRegressorand LinearSVR models in sklearn, but I can't train the model properly and the MSE is super high.</p>\n\n<p>MSE almost equals 90,000,000 (the true values of prices' range are between 5,000,000 - 900,000,000)</p>\n\n<p>Here is my code:</p>\n\n<pre><code>import numpy as np\nfrom sklearn.svm import LinearSVR\nimport pandas as pd\nimport csv\nfrom sklearn.preprocessing import normalize\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv('dataset.csv', index_col=False)\nX = df.drop('price', axis=1)\n\nX_data = X.values\nY_data = df.price.values\nX_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=5)\n\nrgr = RandomForestRegressor(n_estimators=100)\nsvr = LinearSVR()\n\nrgr.fit(X_train, Y_train)\nsvr.fit(X_train, Y_train)\n\nMSEs = cross_val_score(estimator=rgr,\n                         X=X_train,\n                         y=Y_train,\n                         scoring='mean_squared_error',\n                         cv=5)\n\nMSEsSVR = cross_val_score(estimator=svr,\n                         X=X_train,\n                         y=Y_train,\n                         scoring='mean_squared_error',\n                         cv=5)\n\nMSEs *= -1\nRMSEs = np.sqrt(MSEs)\n\nprint(\"Root mean squared error with 95% confidence interval:\")\nprint(\"{:.3f} (+/- {:.3f})\".format(RMSEs.mean(), RMSEs.std()*2))\nprint(\"\")\n</code></pre>\n\n<p>Is the problem with my dataset and count of features? How can I build a prediction model with this type of dataset?</p>\n",
                "tags": "<machine-learning><python><regression><scikit-learn>",
                "answers": [
                    [
                        "19746",
                        "2",
                        "19615",
                        "",
                        "",
                        "<p>I removed 20 percent of most expensive houses from dataset and divided the prices by 1.000.000 and the result got much better.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "19702",
                        "2",
                        "19615",
                        "",
                        "",
                        "<p>that's possibly due to poor parameter tuning. <br>\nTry reducing C for SVR and increasing n_estimators for RFR. <br></p>\n\n<p>A nice approach is to gridsearch through the parameter, and plot the metric result. <br></p>\n\n<p>Another thing that might help is to normalize the parameters (sklearn.preprocessing.StandardScaler) and to remove the skew from the target (usually log transform or 1/target transform works better)</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12524",
            "_score": 14.085685,
            "_source": {
                "title": "C parameter error in pipeline",
                "content": "C parameter error in pipeline <p>I'm trying to build a classifier for my dataset and I'm having an issue with using my gridsearchCV and pipeline together. Here is my code:</p>\n\n<pre><code>from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Imputer, StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimp = Imputer()\nscaler = StandardScaler()\nclf = LogisticRegression(multi_class='multinomial')\n\nXtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=42)\n\npipeline = make_pipeline(imp, scaler, clf)\n\nparam_grid = {'penalty':[\"l1\",\"l2\"], 'C':np.arange(0.001, 1, 0.01),\n                  'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n\nsearch = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5)\n</code></pre>\n\n<p>Once I call the method on search, I get the following error. </p>\n\n<pre><code>search.fit(Xtrain, ytrain)\n\nValueError: Invalid parameter C for estimator Pipeline(memory=None,\n steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n      intercept_scaling=1, max_iter=100, multi_class='multinomial',\n      n_jobs=1, penalty='l2', random_state=None, solver='liblinear',\n      tol=0.0001, verbose=0, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n</code></pre>\n\n<p>I'm not sure how my C parameters are invalid. Does anyone know what I'm doing wrong?</p>\n <machine-learning><classification><logistic-regression><multiclass-classification><p>I have already posted it here:</p>\n\n<p><a href=\"https://stackoverflow.com/questions/43366561/use-sklearns-gridsearchcv-with-a-pipeline-preprocessing-just-once/55401454#55401454\">https://stackoverflow.com/questions/43366561/use-sklearns-gridsearchcv-with-a-pipeline-preprocessing-just-once/55401454#55401454</a></p>\n\n<p>Suppose you have this pipeline:</p>\n\n<pre><code>classifier = Pipeline([\n    ('vectorizer', CountVectorizer(max_features=100000, ngram_range=(1, 3))),\n    ('clf', RandomForestClassifier(n_estimators=10, random_state=SEED, n_jobs=-1))])\n</code></pre>\n\n<p>Then, when specifying parameters you need to include this 'clf_' name that you used for your estimator. So the parameters grid is going to be:</p>\n\n<pre><code>params={'clf__max_features':[0.3, 0.5, 0.7],\n        'clf__min_samples_leaf':[1, 2, 3],\n        'clf__max_depth':[None]\n        }\n</code></pre>\n<p>The reason is that you are doing grid search on <code>pipeline</code>, but  <code>sklearn.pipeline.Pipeline</code> does not take a parameter <code>C</code>. Therefore the error message tells you <code>Invalid parameter C for estimator Pipeline</code></p>\n\n<p>Solution: do grid search on your <code>clf</code> because <code>sklearn.linear_model.LogisticRegression</code> does take parameters <code>penalty</code>, <code>C</code> and <code>solver</code>. Build your pipeline somewhere else.</p>\n",
                "codes": [
                    [
                        "classifier = Pipeline([\n    ('vectorizer', CountVectorizer(max_features=100000, ngram_range=(1, 3))),\n    ('clf', RandomForestClassifier(n_estimators=10, random_state=SEED, n_jobs=-1))])\n",
                        "params={'clf__max_features':[0.3, 0.5, 0.7],\n        'clf__min_samples_leaf':[1, 2, 3],\n        'clf__max_depth':[None]\n        }\n"
                    ],
                    []
                ],
                "question_id:": "43947",
                "question_votes:": "",
                "question_text:": "<p>I'm trying to build a classifier for my dataset and I'm having an issue with using my gridsearchCV and pipeline together. Here is my code:</p>\n\n<pre><code>from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Imputer, StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimp = Imputer()\nscaler = StandardScaler()\nclf = LogisticRegression(multi_class='multinomial')\n\nXtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=42)\n\npipeline = make_pipeline(imp, scaler, clf)\n\nparam_grid = {'penalty':[\"l1\",\"l2\"], 'C':np.arange(0.001, 1, 0.01),\n                  'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n\nsearch = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5)\n</code></pre>\n\n<p>Once I call the method on search, I get the following error. </p>\n\n<pre><code>search.fit(Xtrain, ytrain)\n\nValueError: Invalid parameter C for estimator Pipeline(memory=None,\n steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n      intercept_scaling=1, max_iter=100, multi_class='multinomial',\n      n_jobs=1, penalty='l2', random_state=None, solver='liblinear',\n      tol=0.0001, verbose=0, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n</code></pre>\n\n<p>I'm not sure how my C parameters are invalid. Does anyone know what I'm doing wrong?</p>\n",
                "tags": "<machine-learning><classification><logistic-regression><multiclass-classification>",
                "answers": [
                    [
                        "48155",
                        "2",
                        "43947",
                        "",
                        "",
                        "<p>I have already posted it here:</p>\n\n<p><a href=\"https://stackoverflow.com/questions/43366561/use-sklearns-gridsearchcv-with-a-pipeline-preprocessing-just-once/55401454#55401454\">https://stackoverflow.com/questions/43366561/use-sklearns-gridsearchcv-with-a-pipeline-preprocessing-just-once/55401454#55401454</a></p>\n\n<p>Suppose you have this pipeline:</p>\n\n<pre><code>classifier = Pipeline([\n    ('vectorizer', CountVectorizer(max_features=100000, ngram_range=(1, 3))),\n    ('clf', RandomForestClassifier(n_estimators=10, random_state=SEED, n_jobs=-1))])\n</code></pre>\n\n<p>Then, when specifying parameters you need to include this 'clf_' name that you used for your estimator. So the parameters grid is going to be:</p>\n\n<pre><code>params={'clf__max_features':[0.3, 0.5, 0.7],\n        'clf__min_samples_leaf':[1, 2, 3],\n        'clf__max_depth':[None]\n        }\n</code></pre>\n",
                        "",
                        ""
                    ],
                    [
                        "43948",
                        "2",
                        "43947",
                        "",
                        "",
                        "<p>The reason is that you are doing grid search on <code>pipeline</code>, but  <code>sklearn.pipeline.Pipeline</code> does not take a parameter <code>C</code>. Therefore the error message tells you <code>Invalid parameter C for estimator Pipeline</code></p>\n\n<p>Solution: do grid search on your <code>clf</code> because <code>sklearn.linear_model.LogisticRegression</code> does take parameters <code>penalty</code>, <code>C</code> and <code>solver</code>. Build your pipeline somewhere else.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "1297",
            "_score": 14.079483,
            "_source": {
                "title": "SKNN regression problem",
                "content": "SKNN regression problem <p>I am trying to learn <code>scikit-learn</code> <code>neuralnetwork</code> and am coming up against the same problem in regression where no matter the dataset I getting a horizontal straight line for my fit. </p>\n\n<p>here is an example using the Linear regression example from <code>scikit-learn</code> and then using the <code>SKNN</code> regressor , simple example code from the docs.</p>\n\n<pre># -*- coding: utf-8 -*-\n\n# Code source: Jaques Grobler\n# http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html\n# License: BSD 3 clause\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import datasets, linear_model\n\n# Load the diabetes dataset\ndiabetes = datasets.load_diabetes()\n\n\n# Use only one feature\ndiabetes_X = diabetes.data[:, np.newaxis]\ndiabetes_X_temp = diabetes_X[:, :, 2]\n\n# Split the data into training/testing sets\ndiabetes_X_train = diabetes_X_temp[:-20]\ndiabetes_X_test = diabetes_X_temp[-20:]\n\n# Split the targets into training/testing sets\ndiabetes_y_train = diabetes.target[:-20]\ndiabetes_y_test = diabetes.target[-20:]\n\n# Create linear regression object\nregr = linear_model.LinearRegression()\n\n# Train the model using the training sets\nregr.fit(diabetes_X_train, diabetes_y_train)\n\nprint \"Results of Linear Regression....\"\nprint \"================================\\n\"\n# The coefficients\nprint('Coefficients: ', regr.coef_)\n# The mean square error\nprint(\"Residual sum of squares: %.2f\"\n      % np.mean((regr.predict(diabetes_X_test) - diabetes_y_test) ** 2))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % regr.score(diabetes_X_test, diabetes_y_test))\n\n# Plot outputs\nplt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\nplt.plot(diabetes_X_test, regr.predict(diabetes_X_test), color='blue',\n         linewidth=3)\n\nplt.xticks(())\nplt.yticks(())\n\nplt.show()\n\n# Now using the sknn regressor\n# http://scikit-neuralnetwork.readthedocs.org/en/latest/guide_beginners.html\n#\n\nfrom sknn.mlp import Regressor, Layer\n\nnn = Regressor(\n    layers=[\n        Layer(\"Rectifier\", units=200),\n        Layer(\"Linear\")],\n    learning_rate=0.02,\n    n_iter=10)\n\nnn.fit(diabetes_X_train, diabetes_y_train)\nprint \"Results of SKNN Regression....\"\nprint \"==============================\\n\"\n\n\n# The coefficients\nprint('Coefficients: ', regr.coef_)\n# The mean square error\nprint(\"Residual sum of squares: %.2f\"\n      % np.mean((nn.predict(diabetes_X_test) - diabetes_y_test) ** 2))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % nn.score(diabetes_X_test, diabetes_y_test))\n\n# Plot outputs\nplt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\nplt.plot(diabetes_X_test, nn.predict(diabetes_X_test), color='blue',\n         linewidth=3)\n\nplt.xticks(())\nplt.yticks(())\n\nplt.show()\n\n</pre>\n\n<p>Results of Linear Regression:</p>\n\n<pre><code>('Coefficients: ', array([ 938.23786125]))\nResidual sum of squares: 2548.07\nVariance score: 0.47\n</code></pre>\n\n<p>\ufffc\nResults of SKNN Regression:</p>\n\n<pre><code>('Coefficients: ', array([ 938.23786125]))\nResidual sum of squares: 5737.52\nVariance score: -0.19\n</code></pre>\n\n<p>Changing the number of iterations to 1000 results in a score of -0.15</p>\n <python><neural-network><regression><p>My best guess here is that your learning rate is <em>way</em> too high for the problem. You also probably have far more neurons in your hidden network than you need, seeing as you're using just one feature. </p>\n\n<p>Recall that learning rate is controlling the \"step size\" in gradient descent and that for your dataset, it is likely far too high. I made some minor changes to your code and got better results than linear regression. Notice the use of 2 hidden neurons, a 0.001 learning rate, and 20 iterations.</p>\n\n<pre><code># Now using the sknn regressor\n# http://scikit-neuralnetwork.readthedocs.org/en/latest/guide_beginners.html\n\n\nfrom sknn.mlp import Regressor, Layer\n\nnn = Regressor(\n    layers=[\n        Layer(\"Rectifier\", units=2),\n        Layer(\"Linear\")],\n    learning_rate=0.001,\n    n_iter=20)\n\nnn.fit(diabetes_X_train, diabetes_y_train)\nprint(\"Results of SKNN Regression....\")\n\n\n# The coefficients\nprint('Coefficients: ', regr.coef_)\n# The mean square error\nprint(\"Residual sum of squares: %.2f\"\n      % np.mean((nn.predict(diabetes_X_test) - diabetes_y_test) ** 2))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % nn.score(diabetes_X_test, diabetes_y_test))\n\n# Plot outputs\nplt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\nplt.plot(diabetes_X_test, nn.predict(diabetes_X_test), color='blue',\n         linewidth=3)\n\nplt.xticks(())\nplt.yticks(())\n\nplt.show()\n</code></pre>\n\n<p>SKNN regression: </p>\n\n<pre><code>Results of SKNN Regression....\nCoefficients:  [ 938.23786125]\nResidual sum of squares: 6123.67\nVariance score: 0.50\n</code></pre>\n",
                "codes": [
                    [
                        "# Now using the sknn regressor\n# http://scikit-neuralnetwork.readthedocs.org/en/latest/guide_beginners.html\n\n\nfrom sknn.mlp import Regressor, Layer\n\nnn = Regressor(\n    layers=[\n        Layer(\"Rectifier\", units=2),\n        Layer(\"Linear\")],\n    learning_rate=0.001,\n    n_iter=20)\n\nnn.fit(diabetes_X_train, diabetes_y_train)\nprint(\"Results of SKNN Regression....\")\n\n\n# The coefficients\nprint('Coefficients: ', regr.coef_)\n# The mean square error\nprint(\"Residual sum of squares: %.2f\"\n      % np.mean((nn.predict(diabetes_X_test) - diabetes_y_test) ** 2))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % nn.score(diabetes_X_test, diabetes_y_test))\n\n# Plot outputs\nplt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\nplt.plot(diabetes_X_test, nn.predict(diabetes_X_test), color='blue',\n         linewidth=3)\n\nplt.xticks(())\nplt.yticks(())\n\nplt.show()\n",
                        "Results of SKNN Regression....\nCoefficients:  [ 938.23786125]\nResidual sum of squares: 6123.67\nVariance score: 0.50\n"
                    ]
                ],
                "question_id:": "8113",
                "question_votes:": "1",
                "question_text:": "<p>I am trying to learn <code>scikit-learn</code> <code>neuralnetwork</code> and am coming up against the same problem in regression where no matter the dataset I getting a horizontal straight line for my fit. </p>\n\n<p>here is an example using the Linear regression example from <code>scikit-learn</code> and then using the <code>SKNN</code> regressor , simple example code from the docs.</p>\n\n<pre># -*- coding: utf-8 -*-\n\n# Code source: Jaques Grobler\n# http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html\n# License: BSD 3 clause\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import datasets, linear_model\n\n# Load the diabetes dataset\ndiabetes = datasets.load_diabetes()\n\n\n# Use only one feature\ndiabetes_X = diabetes.data[:, np.newaxis]\ndiabetes_X_temp = diabetes_X[:, :, 2]\n\n# Split the data into training/testing sets\ndiabetes_X_train = diabetes_X_temp[:-20]\ndiabetes_X_test = diabetes_X_temp[-20:]\n\n# Split the targets into training/testing sets\ndiabetes_y_train = diabetes.target[:-20]\ndiabetes_y_test = diabetes.target[-20:]\n\n# Create linear regression object\nregr = linear_model.LinearRegression()\n\n# Train the model using the training sets\nregr.fit(diabetes_X_train, diabetes_y_train)\n\nprint \"Results of Linear Regression....\"\nprint \"================================\\n\"\n# The coefficients\nprint('Coefficients: ', regr.coef_)\n# The mean square error\nprint(\"Residual sum of squares: %.2f\"\n      % np.mean((regr.predict(diabetes_X_test) - diabetes_y_test) ** 2))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % regr.score(diabetes_X_test, diabetes_y_test))\n\n# Plot outputs\nplt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\nplt.plot(diabetes_X_test, regr.predict(diabetes_X_test), color='blue',\n         linewidth=3)\n\nplt.xticks(())\nplt.yticks(())\n\nplt.show()\n\n# Now using the sknn regressor\n# http://scikit-neuralnetwork.readthedocs.org/en/latest/guide_beginners.html\n#\n\nfrom sknn.mlp import Regressor, Layer\n\nnn = Regressor(\n    layers=[\n        Layer(\"Rectifier\", units=200),\n        Layer(\"Linear\")],\n    learning_rate=0.02,\n    n_iter=10)\n\nnn.fit(diabetes_X_train, diabetes_y_train)\nprint \"Results of SKNN Regression....\"\nprint \"==============================\\n\"\n\n\n# The coefficients\nprint('Coefficients: ', regr.coef_)\n# The mean square error\nprint(\"Residual sum of squares: %.2f\"\n      % np.mean((nn.predict(diabetes_X_test) - diabetes_y_test) ** 2))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % nn.score(diabetes_X_test, diabetes_y_test))\n\n# Plot outputs\nplt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\nplt.plot(diabetes_X_test, nn.predict(diabetes_X_test), color='blue',\n         linewidth=3)\n\nplt.xticks(())\nplt.yticks(())\n\nplt.show()\n\n</pre>\n\n<p>Results of Linear Regression:</p>\n\n<pre><code>('Coefficients: ', array([ 938.23786125]))\nResidual sum of squares: 2548.07\nVariance score: 0.47\n</code></pre>\n\n<p>\ufffc\nResults of SKNN Regression:</p>\n\n<pre><code>('Coefficients: ', array([ 938.23786125]))\nResidual sum of squares: 5737.52\nVariance score: -0.19\n</code></pre>\n\n<p>Changing the number of iterations to 1000 results in a score of -0.15</p>\n",
                "tags": "<python><neural-network><regression>",
                "answers": [
                    [
                        "8121",
                        "2",
                        "8113",
                        "",
                        "",
                        "<p>My best guess here is that your learning rate is <em>way</em> too high for the problem. You also probably have far more neurons in your hidden network than you need, seeing as you're using just one feature. </p>\n\n<p>Recall that learning rate is controlling the \"step size\" in gradient descent and that for your dataset, it is likely far too high. I made some minor changes to your code and got better results than linear regression. Notice the use of 2 hidden neurons, a 0.001 learning rate, and 20 iterations.</p>\n\n<pre><code># Now using the sknn regressor\n# http://scikit-neuralnetwork.readthedocs.org/en/latest/guide_beginners.html\n\n\nfrom sknn.mlp import Regressor, Layer\n\nnn = Regressor(\n    layers=[\n        Layer(\"Rectifier\", units=2),\n        Layer(\"Linear\")],\n    learning_rate=0.001,\n    n_iter=20)\n\nnn.fit(diabetes_X_train, diabetes_y_train)\nprint(\"Results of SKNN Regression....\")\n\n\n# The coefficients\nprint('Coefficients: ', regr.coef_)\n# The mean square error\nprint(\"Residual sum of squares: %.2f\"\n      % np.mean((nn.predict(diabetes_X_test) - diabetes_y_test) ** 2))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % nn.score(diabetes_X_test, diabetes_y_test))\n\n# Plot outputs\nplt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\nplt.plot(diabetes_X_test, nn.predict(diabetes_X_test), color='blue',\n         linewidth=3)\n\nplt.xticks(())\nplt.yticks(())\n\nplt.show()\n</code></pre>\n\n<p>SKNN regression: </p>\n\n<pre><code>Results of SKNN Regression....\nCoefficients:  [ 938.23786125]\nResidual sum of squares: 6123.67\nVariance score: 0.50\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16705",
            "_score": 14.074955,
            "_source": {
                "title": "Unexpected results from scikit learn regression decision tree",
                "content": "Unexpected results from scikit learn regression decision tree <p>Apologies for this newbie question. I have a scikit learn <code>DecisionTreeRegressor</code> with muti-variable output. If the output is in the format  [ output_var1, output_var2 ], where each variable is a continuous number not an integer, why the result is [1, 1] instead of [1.5, 1.5] ? What needs to be changed in this model to get [1.5, 1.5] ?</p>\n\n<pre><code>from sklearn.tree import DecisionTreeRegressor\n\nX = [ [1,1], [2,2], [3,3] ]\ny = [ [1,1], [2,2], [3,3] ]\n\nprint('X:' , X)\nprint('-----------------------------')\nprint('y:' , y)\nprint('-----------------------------')\n\nregr = DecisionTreeRegressor()\nregr.fit(X, y)\n\nX_test = [ [1.5, 1.5] ]\nprint('X_test:' , X_test)\nprint('-----------------------------')\n\ny_result = regr.predict(X_test)\nprint('y_result:' , y_result )\n</code></pre>\n\n<p>Result:</p>\n\n<pre><code>X: [[1, 1], [2, 2], [3, 3]]\n-----------------------------\ny: [[1, 1], [2, 2], [3, 3]]\n-----------------------------\nX_test: [[1.5, 1.5]]\n-----------------------------\ny_result: [[1. 1.]]\n</code></pre>\n <machine-learning><scikit-learn><regression><decision-trees><p>I afraid that Decision Tree does not suitable. I recommend read about linear regression.</p>\n\n<p><a href=\"https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py</a></p>\n<p>The data is being overfitting by the model, the model is memorizing the training data. Given the very few training samples, the decision tree can not learn the general pattern. If the model is given more training data with greater variation, it can learn the general pattern.</p>\n\n<p>One approach is not to change the model but change the data. You can simulate a lot of random data and get the approximately correct results:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from sklearn.tree import DecisionTreeRegressor\nimport numpy as np\n\nnums = np.random.random(size=100_000)*3\nX = list(zip(nums, nums))\ny = list(zip(nums, nums))\nregr = DecisionTreeRegressor()\nregr.fit(X, y)\nX_test = [ [1.5, 1.5] ]\ny_result = regr.predict(X_test)\nassert np.isclose(y_result, X_test, atol=.001)\n</code></pre>\n<p>This is the visualization for the inducted tree from your data:</p>\n\n<p><a href=\"https://i.stack.imgur.com/FzFU2.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/FzFU2.png\" alt=\"Regressor\"></a></p>\n\n<p>As you can see, it can never predict <code>[[1.5, 1.5]]</code>. Your data is just too pure, the inducted tree will fit it perfectly, having all leaf nodes with only one sample. If a leaf node has more than one sample in it, then the predicted value is the mean of the y values for those samples.</p>\n\n<p>Furthermore, trees are not the best model to induct the identity function (<span class=\"math-container\">$y = f(x) = x$</span>). Trees work by creating rules and dividing the feature space orthogonally (i.e. only vertical or horizontal lines in the feature space).</p>\n\n<p>In other words, your model didn't learn that <code>f(1.5, 1.5) = (1.5, 1.5)</code> because a) there's not enough data, b) trees are not good at doing that anyway.</p>\n",
                "codes": [
                    [],
                    [
                        "from sklearn.tree import DecisionTreeRegressor\nimport numpy as np\n\nnums = np.random.random(size=100_000)*3\nX = list(zip(nums, nums))\ny = list(zip(nums, nums))\nregr = DecisionTreeRegressor()\nregr.fit(X, y)\nX_test = [ [1.5, 1.5] ]\ny_result = regr.predict(X_test)\nassert np.isclose(y_result, X_test, atol=.001)\n"
                    ],
                    []
                ],
                "question_id:": "54684",
                "question_votes:": "4",
                "question_text:": "<p>Apologies for this newbie question. I have a scikit learn <code>DecisionTreeRegressor</code> with muti-variable output. If the output is in the format  [ output_var1, output_var2 ], where each variable is a continuous number not an integer, why the result is [1, 1] instead of [1.5, 1.5] ? What needs to be changed in this model to get [1.5, 1.5] ?</p>\n\n<pre><code>from sklearn.tree import DecisionTreeRegressor\n\nX = [ [1,1], [2,2], [3,3] ]\ny = [ [1,1], [2,2], [3,3] ]\n\nprint('X:' , X)\nprint('-----------------------------')\nprint('y:' , y)\nprint('-----------------------------')\n\nregr = DecisionTreeRegressor()\nregr.fit(X, y)\n\nX_test = [ [1.5, 1.5] ]\nprint('X_test:' , X_test)\nprint('-----------------------------')\n\ny_result = regr.predict(X_test)\nprint('y_result:' , y_result )\n</code></pre>\n\n<p>Result:</p>\n\n<pre><code>X: [[1, 1], [2, 2], [3, 3]]\n-----------------------------\ny: [[1, 1], [2, 2], [3, 3]]\n-----------------------------\nX_test: [[1.5, 1.5]]\n-----------------------------\ny_result: [[1. 1.]]\n</code></pre>\n",
                "tags": "<machine-learning><scikit-learn><regression><decision-trees>",
                "answers": [
                    [
                        "54986",
                        "2",
                        "54684",
                        "",
                        "",
                        "<p>I afraid that Decision Tree does not suitable. I recommend read about linear regression.</p>\n\n<p><a href=\"https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py</a></p>\n",
                        "",
                        "1"
                    ],
                    [
                        "54918",
                        "2",
                        "54684",
                        "",
                        "",
                        "<p>The data is being overfitting by the model, the model is memorizing the training data. Given the very few training samples, the decision tree can not learn the general pattern. If the model is given more training data with greater variation, it can learn the general pattern.</p>\n\n<p>One approach is not to change the model but change the data. You can simulate a lot of random data and get the approximately correct results:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from sklearn.tree import DecisionTreeRegressor\nimport numpy as np\n\nnums = np.random.random(size=100_000)*3\nX = list(zip(nums, nums))\ny = list(zip(nums, nums))\nregr = DecisionTreeRegressor()\nregr.fit(X, y)\nX_test = [ [1.5, 1.5] ]\ny_result = regr.predict(X_test)\nassert np.isclose(y_result, X_test, atol=.001)\n</code></pre>\n",
                        "",
                        "2"
                    ],
                    [
                        "54795",
                        "2",
                        "54684",
                        "",
                        "",
                        "<p>This is the visualization for the inducted tree from your data:</p>\n\n<p><a href=\"https://i.stack.imgur.com/FzFU2.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/FzFU2.png\" alt=\"Regressor\"></a></p>\n\n<p>As you can see, it can never predict <code>[[1.5, 1.5]]</code>. Your data is just too pure, the inducted tree will fit it perfectly, having all leaf nodes with only one sample. If a leaf node has more than one sample in it, then the predicted value is the mean of the y values for those samples.</p>\n\n<p>Furthermore, trees are not the best model to induct the identity function (<span class=\"math-container\">$y = f(x) = x$</span>). Trees work by creating rules and dividing the feature space orthogonally (i.e. only vertical or horizontal lines in the feature space).</p>\n\n<p>In other words, your model didn't learn that <code>f(1.5, 1.5) = (1.5, 1.5)</code> because a) there's not enough data, b) trees are not good at doing that anyway.</p>\n",
                        "",
                        "5"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9153",
            "_score": 14.071509,
            "_source": {
                "title": "Automated Function (python)",
                "content": "Automated Function (python) <p>I am trying to create a function that automates the process of taking a CSV file, splits in the data in features and responses, apply different models (regression) to the data and score them according to some metric such as MAE, RSME, etc. Model parameter should be easily interchangeable. Here is a little of what I have so far. </p>\n\n<pre><code>import numpy as np\nimport pandas as pd\n\ndef get_data(file_name):\n\ndata = pd.read_csv(file_name)\n\npara = int(raw_input('Enter the no of parameters to be used '))\nprint(para)\n\nparam= []\n\nfor k in range(0,para-1):\n    param[k]= raw_input('Enter the parameter')\n\nrec = int(raw_input('Enter the no of records in the dataset '))\nprint(rec)\nx_parameter = []\ny_parameter = []\nx1= []\nfor i in range(0,para):\n    for x1[i] in data[i]:\n        x_parameter[i].append(x1[i])\n\nfor j in range(0,rec):\n    print x_parameter[j]\n    print y_parameter[j]\n\nget_data('C:\\Users\\Douglas\\Desktop\\trainingset.csv')\n\nfrom sklearn import model_selection\nfrom sklearn import linear_model\nfrom sklearn import SGDRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressors\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.svm import SVR\n\ndataframe = getdata(file_name)\narray = dataframe.values\nX = array[]\n#confirguartion for cross validation\nseed = 7\n#prepare models\nmodels = []\nmodels.append(('LR', LinearRegression()))\nmodels.append(('SGDR', SGDRegressor()))\nmodels.append(('KNR', KNeighborsRegressor()))\nmodels.append(('DTR', DecisionTreeRegressor()))\nmodels.append(('GBR', GradientBoostingRegressor()))\nmodels.append(('SVR', SVR()))\n#evaluate each model in turn\nresults = []\nnames = []\nscoring = 'neg_mean_absolute_error'\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n    cv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=sc)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print msg\n</code></pre>\n <machine-learning><python><p>Your code looks decent, although this is not really the place to ask these types of questions. You're looking to write a wrapper around SK-Learn,</p>\n\n<p>What I would try to do is to write a method to handle different types of datasets(json or csv) and then call it on a filepath and then have a function which reads in a set of models and applies each of them to the dataset in question, and finally uses metrics present in sklearn to get some results.</p>\n\n<p>There is auto-sklearn which does this for you and they have a pretty solid codebase that is well documented. Here is a link for your convenience (<a href=\"https://automl.github.io/auto-sklearn/stable/\" rel=\"nofollow noreferrer\">https://automl.github.io/auto-sklearn/stable/</a>)</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "32703",
                "question_votes:": "",
                "question_text:": "<p>I am trying to create a function that automates the process of taking a CSV file, splits in the data in features and responses, apply different models (regression) to the data and score them according to some metric such as MAE, RSME, etc. Model parameter should be easily interchangeable. Here is a little of what I have so far. </p>\n\n<pre><code>import numpy as np\nimport pandas as pd\n\ndef get_data(file_name):\n\ndata = pd.read_csv(file_name)\n\npara = int(raw_input('Enter the no of parameters to be used '))\nprint(para)\n\nparam= []\n\nfor k in range(0,para-1):\n    param[k]= raw_input('Enter the parameter')\n\nrec = int(raw_input('Enter the no of records in the dataset '))\nprint(rec)\nx_parameter = []\ny_parameter = []\nx1= []\nfor i in range(0,para):\n    for x1[i] in data[i]:\n        x_parameter[i].append(x1[i])\n\nfor j in range(0,rec):\n    print x_parameter[j]\n    print y_parameter[j]\n\nget_data('C:\\Users\\Douglas\\Desktop\\trainingset.csv')\n\nfrom sklearn import model_selection\nfrom sklearn import linear_model\nfrom sklearn import SGDRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressors\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.svm import SVR\n\ndataframe = getdata(file_name)\narray = dataframe.values\nX = array[]\n#confirguartion for cross validation\nseed = 7\n#prepare models\nmodels = []\nmodels.append(('LR', LinearRegression()))\nmodels.append(('SGDR', SGDRegressor()))\nmodels.append(('KNR', KNeighborsRegressor()))\nmodels.append(('DTR', DecisionTreeRegressor()))\nmodels.append(('GBR', GradientBoostingRegressor()))\nmodels.append(('SVR', SVR()))\n#evaluate each model in turn\nresults = []\nnames = []\nscoring = 'neg_mean_absolute_error'\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n    cv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=sc)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print msg\n</code></pre>\n",
                "tags": "<machine-learning><python>",
                "answers": [
                    [
                        "32704",
                        "2",
                        "32703",
                        "",
                        "",
                        "<p>Your code looks decent, although this is not really the place to ask these types of questions. You're looking to write a wrapper around SK-Learn,</p>\n\n<p>What I would try to do is to write a method to handle different types of datasets(json or csv) and then call it on a filepath and then have a function which reads in a set of models and applies each of them to the dataset in question, and finally uses metrics present in sklearn to get some results.</p>\n\n<p>There is auto-sklearn which does this for you and they have a pretty solid codebase that is well documented. Here is a link for your convenience (<a href=\"https://automl.github.io/auto-sklearn/stable/\" rel=\"nofollow noreferrer\">https://automl.github.io/auto-sklearn/stable/</a>)</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "18337",
            "_score": 14.018154,
            "_source": {
                "title": "ValueError: Found input variables with inconsistent numbers of samples: [60000, 10000]",
                "content": "ValueError: Found input variables with inconsistent numbers of samples: [60000, 10000] <p>My code:</p>\n\n<pre><code>dtrain, dtest = data[:60000], data[60000:]  \ntartrain, tartest = target[:60000], target[60000:]  \nshuffling = np.random.permutation(6000)  \ndtrain, tartrain = dtrain[shuffling], tartrain[shuffling]  \ntartrain, tartest = tartrain[shuffling], tartest[shuffling]  \ntartrain = tartrain.astype(np.int)  \ntartest  = tartest.astype(np.int)  \ntartrain_2 = (tartrain==2)  \ntartest_2 = (tartest==2)  \nfrom sklearn.linear_model import LogisticRegression  \nclf = LogisticRegression()  \nclf.fit(dtrain, tartest_2)\n</code></pre>\n\n<p>The last line is showing the value error.</p>\n <machine-learning-model>",
                "codes": [],
                "question_id:": "58153",
                "question_votes:": "",
                "question_text:": "<p>My code:</p>\n\n<pre><code>dtrain, dtest = data[:60000], data[60000:]  \ntartrain, tartest = target[:60000], target[60000:]  \nshuffling = np.random.permutation(6000)  \ndtrain, tartrain = dtrain[shuffling], tartrain[shuffling]  \ntartrain, tartest = tartrain[shuffling], tartest[shuffling]  \ntartrain = tartrain.astype(np.int)  \ntartest  = tartest.astype(np.int)  \ntartrain_2 = (tartrain==2)  \ntartest_2 = (tartest==2)  \nfrom sklearn.linear_model import LogisticRegression  \nclf = LogisticRegression()  \nclf.fit(dtrain, tartest_2)\n</code></pre>\n\n<p>The last line is showing the value error.</p>\n",
                "tags": "<machine-learning-model>",
                "answers": []
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8684",
            "_score": 13.954987,
            "_source": {
                "title": "How to evaluate the \"betterness\" of competitive good models?",
                "content": "How to evaluate the \"betterness\" of competitive good models? <p>How to evaluate the \"betterness\" of competitive good models?</p>\n\n<p>Lets say I could get good models (> 90% prediction rate) with e.g.:</p>\n\n<ul>\n<li>LinearSVC</li>\n<li>F-test based sklearn.feature_selection.f_regression</li>\n<li>mutual info -based sklearn.feature_selection.mutual_info_regression</li>\n</ul>\n\n<p>But since these treat e.g. the independence/dependence of features differently, particularly e.g. LinearSVC assumes \"relatively independent\" features, where as mutual info particularly measure dependence between variables, then</p>\n\n<p>How can I compare these models to each other?</p>\n\n<p>Tests? Knowledge of the data a priori? Something else?</p>\n <model-selection><p>The typical approach would be to compare (cross-)validation performance of the models, at least if accuracy is the selection criterion. </p>\n\n<p>Other criteria could be</p>\n\n<ul>\n<li>simplicity/ease to interpret </li>\n<li>how easy the models could be implemented and/or updated in a productive environment</li>\n</ul>\n<p>This is a very general question, and the answer is that it depends on what you're doing, what your application is.  </p>\n\n<p>What is the reason you're building the model in the first place? You want to evaluate the performance, as Fadi Bakoura states, with a generalization error on a test set, but what error measure you choose depends on what you're doing, how balanced your dataset is, whether you care more about false positives or false negatives, or a number of other concerns.</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "31541",
                "question_votes:": "2",
                "question_text:": "<p>How to evaluate the \"betterness\" of competitive good models?</p>\n\n<p>Lets say I could get good models (> 90% prediction rate) with e.g.:</p>\n\n<ul>\n<li>LinearSVC</li>\n<li>F-test based sklearn.feature_selection.f_regression</li>\n<li>mutual info -based sklearn.feature_selection.mutual_info_regression</li>\n</ul>\n\n<p>But since these treat e.g. the independence/dependence of features differently, particularly e.g. LinearSVC assumes \"relatively independent\" features, where as mutual info particularly measure dependence between variables, then</p>\n\n<p>How can I compare these models to each other?</p>\n\n<p>Tests? Knowledge of the data a priori? Something else?</p>\n",
                "tags": "<model-selection>",
                "answers": [
                    [
                        "31544",
                        "2",
                        "31541",
                        "",
                        "",
                        "<p>The typical approach would be to compare (cross-)validation performance of the models, at least if accuracy is the selection criterion. </p>\n\n<p>Other criteria could be</p>\n\n<ul>\n<li>simplicity/ease to interpret </li>\n<li>how easy the models could be implemented and/or updated in a productive environment</li>\n</ul>\n",
                        "",
                        "1"
                    ],
                    [
                        "36714",
                        "2",
                        "31541",
                        "",
                        "",
                        "<p>This is a very general question, and the answer is that it depends on what you're doing, what your application is.  </p>\n\n<p>What is the reason you're building the model in the first place? You want to evaluate the performance, as Fadi Bakoura states, with a generalization error on a test set, but what error measure you choose depends on what you're doing, how balanced your dataset is, whether you care more about false positives or false negatives, or a number of other concerns.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17920",
            "_score": 13.910753,
            "_source": {
                "title": "what are effects of working with categorical dataset",
                "content": "what are effects of working with categorical dataset <p>I am working on classification problem where the dataset contains 90% of features as categorical. It is binary classification problem, and the class is heavily imbalanced. I performed Smote over sample and created a model. I also tried similar approach with undersampling. Both the method with logistic regression performs mediocre. I want to know how having too many categorical variables impacts the model and possible efficient way to approach the problem</p>\n\n<pre><code>feature1:1-3\nfeature2:0-1\nfeature3:0-3\nfeature4: 1-4\nfeature5: 0-2\nfeature6: 0-5\nfeature7: 1-4\nfeature8: continuous( max 10)\nfeature9 continuous( max 10)\nclass: 0-1\n</code></pre>\n <machine-learning><classification><data><p>You can try to use CatBoost (<a href=\"https://catboost.ai\" rel=\"nofollow noreferrer\">https://catboost.ai</a>). This library is developed specially for categorical features support and is based on gradient boosting on decision trees. Hope, it will help</p>\n<p>You need to distinguish a few problems here. How well can your data classify some outcome, what features should be used, how to deal with imbalanced classes.</p>\n\n<p>Categorical features are not a problem per se. In the current stage, feature selection might be an issue. Thus, use logit with lasso or ridge to shrink features which are not too helpful (happens automatically). Also dummy/one-hot encoding would be worth a try (jointly with lasso).</p>\n\n<p><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html</a></p>\n\n<p><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html</a></p>\n<p>As already specified by @Peter, categorical features are not a problem per se provided that you encode them in the \"right way\" (problem specific). I see that you are already starting with integer encoding, but you are not satisfied with the results. Given your small number of categorical features and levels of each feature as a first step I'd try with one-hot encoding. Also notice that with integer encoding you are giving a natural order to your levels, e.g. feature3 = 3 is greater than feature3 = 1, so be careful about it.</p>\n\n<p>Other than categorical features encoding and feature selection, your poor performance might also be caused by over and undersampling techniques that have not been tuned properly to preserve the original data distribution. I suggest to try weighting of the loss function as well to counteract imbalance.</p>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "57289",
                "question_votes:": "",
                "question_text:": "<p>I am working on classification problem where the dataset contains 90% of features as categorical. It is binary classification problem, and the class is heavily imbalanced. I performed Smote over sample and created a model. I also tried similar approach with undersampling. Both the method with logistic regression performs mediocre. I want to know how having too many categorical variables impacts the model and possible efficient way to approach the problem</p>\n\n<pre><code>feature1:1-3\nfeature2:0-1\nfeature3:0-3\nfeature4: 1-4\nfeature5: 0-2\nfeature6: 0-5\nfeature7: 1-4\nfeature8: continuous( max 10)\nfeature9 continuous( max 10)\nclass: 0-1\n</code></pre>\n",
                "tags": "<machine-learning><classification><data>",
                "answers": [
                    [
                        "57290",
                        "2",
                        "57289",
                        "",
                        "",
                        "<p>You can try to use CatBoost (<a href=\"https://catboost.ai\" rel=\"nofollow noreferrer\">https://catboost.ai</a>). This library is developed specially for categorical features support and is based on gradient boosting on decision trees. Hope, it will help</p>\n",
                        "",
                        ""
                    ],
                    [
                        "57293",
                        "2",
                        "57289",
                        "",
                        "",
                        "<p>You need to distinguish a few problems here. How well can your data classify some outcome, what features should be used, how to deal with imbalanced classes.</p>\n\n<p>Categorical features are not a problem per se. In the current stage, feature selection might be an issue. Thus, use logit with lasso or ridge to shrink features which are not too helpful (happens automatically). Also dummy/one-hot encoding would be worth a try (jointly with lasso).</p>\n\n<p><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html</a></p>\n\n<p><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html</a></p>\n",
                        "",
                        "3"
                    ],
                    [
                        "57295",
                        "2",
                        "57289",
                        "",
                        "",
                        "<p>As already specified by @Peter, categorical features are not a problem per se provided that you encode them in the \"right way\" (problem specific). I see that you are already starting with integer encoding, but you are not satisfied with the results. Given your small number of categorical features and levels of each feature as a first step I'd try with one-hot encoding. Also notice that with integer encoding you are giving a natural order to your levels, e.g. feature3 = 3 is greater than feature3 = 1, so be careful about it.</p>\n\n<p>Other than categorical features encoding and feature selection, your poor performance might also be caused by over and undersampling techniques that have not been tuned properly to preserve the original data distribution. I suggest to try weighting of the loss function as well to counteract imbalance.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6409",
            "_score": 13.907007,
            "_source": {
                "title": "What are suitable predictive analytics models for data from multiple sensors?",
                "content": "What are suitable predictive analytics models for data from multiple sensors? <p>I am a newbie in the field of AI/ML. I am trying to implement predictive analytics model on the data generated every minute from a device with sensors.</p>\n\n<p>I have two questions: </p>\n\n<ol>\n<li>What are various ML algorithms I can use to predict the number of people in a room given temperature, humidity, luminosity, and motion { 0 | 1 }?</li>\n<li>What other things can we predict using the above data from the sensor that is deployed in a closed room?</li>\n</ol>\n\n<p><strong>Context:</strong></p>\n\n<p>The device sends temperature, humidity, luminosity, and motion(yes/no) in real-time. I deployed this device in a closed room and started collecting data. Now I want to use this data to predict the number of people in the room using the data collected. I believe a multiple (linear/poly) regression model will help me in achieving this but, wanted to know if there are any other algorithms or any other use cases I can look into.</p>\n\n<p><strong>Sensor Specifications:</strong>\n<a href=\"https://www.elsys.se/en/ers/\" rel=\"nofollow noreferrer\">click for more details</a></p>\n\n<ul>\n<li>LoRa Alliance Certified</li>\n<li>Temperature (Accuracy: \u00b1 0.5\u00b0C, Resolution: 0.1\u00b0C)</li>\n<li>Humidity (Accuracy: \u00b12%rh, Resolution: 0.1%rh)</li>\n<li>Light</li>\n<li>Motion (PIR)</li>\n<li>NFC for easy configuration</li>\n<li>Size : 86x86x26mm</li>\n<li>US902-928, EU863-870, AS923, AU915-928, KR920-923</li>\n<li>2 x 3.6V AA lithium battery</li>\n</ul>\n <machine-learning><scikit-learn><regression><p>First, to answer your questions directly</p>\n\n<p>1) What M/L algorithms to try: Since number of people can be treated as a continuous variable, if you are using python, you can try everything from </p>\n\n<ul>\n<li><p>multiple linear regression </p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\n</code></pre></li>\n<li><p>polynominal regression, first create polynomial features using sklearn.preprocessing library, then fit the model using linear regression again</p>\n\n<pre><code>from sklearn.preprocessing import PolynomialFeatures\n</code></pre></li>\n<li><p>support vector machine</p>\n\n<pre><code>from sklearn.svm import SVR\n</code></pre></li>\n<li><p>decision tree regressor</p>\n\n<pre><code>from sklearn.tree import DecisionTreeRegressor\n</code></pre></li>\n<li><p>random forest regressor</p>\n\n<pre><code>from sklearn.ensemble import RandomForestRegressor\n</code></pre></li>\n<li><p>AdaBoost regressor</p>\n\n<pre><code>from sklearn.ensemble import AdaBoostRegressor\n</code></pre></li>\n<li><p>XGBoost, this one needs to be installed separately, following the instructions on this link: <a href=\"http://xgboost.readthedocs.io/en/latest/build.html#\" rel=\"nofollow noreferrer\">http://xgboost.readthedocs.io/en/latest/build.html#</a></p>\n\n<pre><code>from xgboost import XGBClassifier\n</code></pre></li>\n<li><p>Deep neural network, I wouldn't recommend trying this in the beginning since it can be constructed into very flexible and complex models with way too many choices on the network layout. But if you feel adventurous, this one can be quite fun. Simplest way to get started on this is probably using the keras wrapper for TensorFlow. Here're just some of the most commonly used models and layers</p>\n\n<pre><code>import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\n</code></pre></li>\n<li><p>Recurrent neural network, since you do have time series sensor data, you can potentially use RNN to predict future occupancy based on the past sensor data. You would combine the above keras models, then add LSTM layers to get the 'memory' effect</p>\n\n<pre><code>from keras.layers import LSTM\n</code></pre></li>\n</ul>\n\n<p>2) This one is very difficult to answer as it depends on the configuration of the sensors, setup of the room, how the sensor is placed, is the motion detector a PIR, if PIR, is it dual or quad sensor, what is the shape of the PIR lens, is there an ultrasound sensor, how many channels on the luminosity sensor module, does it read RGB ... etc. This one would require experience, tons of experimentation and ingenuity. You can maybe consult with someone with physics, electronics or electrical engineering background. Some wild ideas: </p>\n\n<ul>\n<li><p>if you know how many people are in the room (through your prediction), and you know the room setup, size and thermal characteristics, using temperature and humidity sensor, you can probably estimate the average mass of the individuals in the room. This one is interesting in that it combines a physics model and a machine learning model</p></li>\n<li><p>the luminosity sensor can probably tell you if the room has natural light or artificial light (looking at rate of illuminance change, does it follow diurnal patterns)</p></li>\n<li><p>motion sensor can probably tell you (other than yes or no motion), whether the motion is large, small, fast or slow, depending on the sensor setup</p></li>\n</ul>\n\n<p>Finally, some thoughts on training this model. Before starting to play with all the ML algorithms, it's probably good to spend a good week or two figuring out the 'preprocessing' of the sensor time series. The model accuracy is highly dependent on the preprocessing steps and feature selection / engineering, probably even more so than the choice of the algorithms. If you feed most algorithms with enough data and do a good job on cross-validation, you can get similar accuracy results (at least for simple regression-type applications). Some preprocessing issues to consider</p>\n\n<ul>\n<li><p>What is your window frame size? Will you simply take moving average, or combine some other statistics within each data window?</p></li>\n<li><p>How do you remove or reduce the noise from the sensors? e.g., how do you know the signal you are looking at results from actual physical phenomenon v.s. electronic noise?</p></li>\n<li><p>Does it help to do fourier transform and filtering? Is it better to use frequency-domain features or time-domain features? Or wavelets?</p></li>\n<li><p>What about dimensionality reduction techniques like PCA, LDA?</p></li>\n</ul>\n\n<p>Lots of things to consider, which is also why machine learning is both challenging and really fun.</p>\n",
                "codes": [
                    [
                        "from sklearn.linear_model import LinearRegression\n",
                        "from sklearn.preprocessing import PolynomialFeatures\n",
                        "from sklearn.svm import SVR\n",
                        "from sklearn.tree import DecisionTreeRegressor\n",
                        "from sklearn.ensemble import RandomForestRegressor\n",
                        "from sklearn.ensemble import AdaBoostRegressor\n",
                        "from xgboost import XGBClassifier\n",
                        "import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\n",
                        "from keras.layers import LSTM\n"
                    ]
                ],
                "question_id:": "24998",
                "question_votes:": "",
                "question_text:": "<p>I am a newbie in the field of AI/ML. I am trying to implement predictive analytics model on the data generated every minute from a device with sensors.</p>\n\n<p>I have two questions: </p>\n\n<ol>\n<li>What are various ML algorithms I can use to predict the number of people in a room given temperature, humidity, luminosity, and motion { 0 | 1 }?</li>\n<li>What other things can we predict using the above data from the sensor that is deployed in a closed room?</li>\n</ol>\n\n<p><strong>Context:</strong></p>\n\n<p>The device sends temperature, humidity, luminosity, and motion(yes/no) in real-time. I deployed this device in a closed room and started collecting data. Now I want to use this data to predict the number of people in the room using the data collected. I believe a multiple (linear/poly) regression model will help me in achieving this but, wanted to know if there are any other algorithms or any other use cases I can look into.</p>\n\n<p><strong>Sensor Specifications:</strong>\n<a href=\"https://www.elsys.se/en/ers/\" rel=\"nofollow noreferrer\">click for more details</a></p>\n\n<ul>\n<li>LoRa Alliance Certified</li>\n<li>Temperature (Accuracy: \u00b1 0.5\u00b0C, Resolution: 0.1\u00b0C)</li>\n<li>Humidity (Accuracy: \u00b12%rh, Resolution: 0.1%rh)</li>\n<li>Light</li>\n<li>Motion (PIR)</li>\n<li>NFC for easy configuration</li>\n<li>Size : 86x86x26mm</li>\n<li>US902-928, EU863-870, AS923, AU915-928, KR920-923</li>\n<li>2 x 3.6V AA lithium battery</li>\n</ul>\n",
                "tags": "<machine-learning><scikit-learn><regression>",
                "answers": [
                    [
                        "25003",
                        "2",
                        "24998",
                        "",
                        "",
                        "<p>First, to answer your questions directly</p>\n\n<p>1) What M/L algorithms to try: Since number of people can be treated as a continuous variable, if you are using python, you can try everything from </p>\n\n<ul>\n<li><p>multiple linear regression </p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\n</code></pre></li>\n<li><p>polynominal regression, first create polynomial features using sklearn.preprocessing library, then fit the model using linear regression again</p>\n\n<pre><code>from sklearn.preprocessing import PolynomialFeatures\n</code></pre></li>\n<li><p>support vector machine</p>\n\n<pre><code>from sklearn.svm import SVR\n</code></pre></li>\n<li><p>decision tree regressor</p>\n\n<pre><code>from sklearn.tree import DecisionTreeRegressor\n</code></pre></li>\n<li><p>random forest regressor</p>\n\n<pre><code>from sklearn.ensemble import RandomForestRegressor\n</code></pre></li>\n<li><p>AdaBoost regressor</p>\n\n<pre><code>from sklearn.ensemble import AdaBoostRegressor\n</code></pre></li>\n<li><p>XGBoost, this one needs to be installed separately, following the instructions on this link: <a href=\"http://xgboost.readthedocs.io/en/latest/build.html#\" rel=\"nofollow noreferrer\">http://xgboost.readthedocs.io/en/latest/build.html#</a></p>\n\n<pre><code>from xgboost import XGBClassifier\n</code></pre></li>\n<li><p>Deep neural network, I wouldn't recommend trying this in the beginning since it can be constructed into very flexible and complex models with way too many choices on the network layout. But if you feel adventurous, this one can be quite fun. Simplest way to get started on this is probably using the keras wrapper for TensorFlow. Here're just some of the most commonly used models and layers</p>\n\n<pre><code>import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\n</code></pre></li>\n<li><p>Recurrent neural network, since you do have time series sensor data, you can potentially use RNN to predict future occupancy based on the past sensor data. You would combine the above keras models, then add LSTM layers to get the 'memory' effect</p>\n\n<pre><code>from keras.layers import LSTM\n</code></pre></li>\n</ul>\n\n<p>2) This one is very difficult to answer as it depends on the configuration of the sensors, setup of the room, how the sensor is placed, is the motion detector a PIR, if PIR, is it dual or quad sensor, what is the shape of the PIR lens, is there an ultrasound sensor, how many channels on the luminosity sensor module, does it read RGB ... etc. This one would require experience, tons of experimentation and ingenuity. You can maybe consult with someone with physics, electronics or electrical engineering background. Some wild ideas: </p>\n\n<ul>\n<li><p>if you know how many people are in the room (through your prediction), and you know the room setup, size and thermal characteristics, using temperature and humidity sensor, you can probably estimate the average mass of the individuals in the room. This one is interesting in that it combines a physics model and a machine learning model</p></li>\n<li><p>the luminosity sensor can probably tell you if the room has natural light or artificial light (looking at rate of illuminance change, does it follow diurnal patterns)</p></li>\n<li><p>motion sensor can probably tell you (other than yes or no motion), whether the motion is large, small, fast or slow, depending on the sensor setup</p></li>\n</ul>\n\n<p>Finally, some thoughts on training this model. Before starting to play with all the ML algorithms, it's probably good to spend a good week or two figuring out the 'preprocessing' of the sensor time series. The model accuracy is highly dependent on the preprocessing steps and feature selection / engineering, probably even more so than the choice of the algorithms. If you feed most algorithms with enough data and do a good job on cross-validation, you can get similar accuracy results (at least for simple regression-type applications). Some preprocessing issues to consider</p>\n\n<ul>\n<li><p>What is your window frame size? Will you simply take moving average, or combine some other statistics within each data window?</p></li>\n<li><p>How do you remove or reduce the noise from the sensors? e.g., how do you know the signal you are looking at results from actual physical phenomenon v.s. electronic noise?</p></li>\n<li><p>Does it help to do fourier transform and filtering? Is it better to use frequency-domain features or time-domain features? Or wavelets?</p></li>\n<li><p>What about dimensionality reduction techniques like PCA, LDA?</p></li>\n</ul>\n\n<p>Lots of things to consider, which is also why machine learning is both challenging and really fun.</p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4149",
            "_score": 13.845867,
            "_source": {
                "title": "Neural Network for Multiple Output Regression",
                "content": "Neural Network for Multiple Output Regression <p>I have a dataset containing 34 input columns and 8 output columns.</p>\n\n<p>One way to solve the problem is to take the 34 inputs and build individual regression model for each output column.</p>\n\n<p>I am wondering if this problem can be solved using just one model particularly using Neural Network.</p>\n\n<p>I have used Multilayer Perceptron but that needs multiple models just like linear regression. Can Sequence to Sequence be a viable option? </p>\n\n<p>I am using TensorFlow. I have code but I think it is more important to understand what I am missing out in terms of the multilayer perceptron theory. </p>\n\n<p>I understand that in MLP if you have one output node it will provide one output. If you have 10 output nodes then it is a multi class problem. You pick the class with the highest probability out of the 10 outputs. But in my case it is certain there will be 8 outputs for same input. </p>\n\n<p>Lets say, for a set of inputs you will get the 3D coordinate of something (X,Y,Z). Like, Inputs = {1,10,5,7} Output = {1,2,1}. So for the same input {1,10,5,7} I need to make models for X value Y value and Z. One solution is to have 3 different models using MLP. But I would like to see if I can have one model. So I thought about using seq2seq. Because the encoder takes a series of input and the decoder provides series of output. But it seems seq2seq in tensorflow cannot handle float values. I can be wrong about this though.</p>\n <neural-network><regression><tensorflow><p>What you are describing is a normal multidimiensional linear regression. This type of problem is normally addressed with a feedforward network, either MLP or any other architecture that suits the nature of the problem. </p>\n\n<p>Any neural network framework is able to do something like that.</p>\n\n<p>The key to do that is to remember that the last layer should have linear activations (i.e. no activation at all).</p>\n\n<p>As per your requirements, the shape of the input layer would be a vector (34,) and the output (8,).</p>\n\n<p>Update: the usual loss function used for regression problems is mean squared error (MSE). <a href=\"https://github.com/fchollet/keras/issues/1874#issuecomment-193083902\" rel=\"noreferrer\">Here</a>'s an example of multidimensional regression using <a href=\"https://keras.io/\" rel=\"noreferrer\">Keras</a>; the network is not an MLP but it should be Ok to illustrate the idea.</p>\n<p>You can implement this very simply in Python.<br>\nYour X will be the collection of training x,y,z coordinates.<br>\nYour Y will be the collection of testing x,y,z coordinates.</p>\n\n<pre><code>from sklearn import cross_validation                     \nfrom sklearn.neural_network import MLPRegressor   \n\nmodel = MLPRegressor(solver='lbfgs',alpha=0.001,hidden_layer_sizes=(150,))\ncross_validation.cross_val_score(model, X, Y,scoring='mean_squared_error')\n</code></pre>\n<p>This is much easier than you would think - you can simply set your output layer to be a vector instead of a single scalar.\nOf course there's no magic around here and I advice you to prep your data (perform batch normalization so all outputs will be values between 0 and 1).</p>\n\n<p>If you're using Keras, the way for doing this is by adding a dense layer as the final output layer:\n<code>model.add(Dense(8, activation='linear'))</code></p>\n",
                "codes": [
                    [],
                    [
                        "from sklearn import cross_validation                     \nfrom sklearn.neural_network import MLPRegressor   \n\nmodel = MLPRegressor(solver='lbfgs',alpha=0.001,hidden_layer_sizes=(150,))\ncross_validation.cross_val_score(model, X, Y,scoring='mean_squared_error')\n"
                    ],
                    []
                ],
                "question_id:": "16890",
                "question_votes:": "20",
                "question_text:": "<p>I have a dataset containing 34 input columns and 8 output columns.</p>\n\n<p>One way to solve the problem is to take the 34 inputs and build individual regression model for each output column.</p>\n\n<p>I am wondering if this problem can be solved using just one model particularly using Neural Network.</p>\n\n<p>I have used Multilayer Perceptron but that needs multiple models just like linear regression. Can Sequence to Sequence be a viable option? </p>\n\n<p>I am using TensorFlow. I have code but I think it is more important to understand what I am missing out in terms of the multilayer perceptron theory. </p>\n\n<p>I understand that in MLP if you have one output node it will provide one output. If you have 10 output nodes then it is a multi class problem. You pick the class with the highest probability out of the 10 outputs. But in my case it is certain there will be 8 outputs for same input. </p>\n\n<p>Lets say, for a set of inputs you will get the 3D coordinate of something (X,Y,Z). Like, Inputs = {1,10,5,7} Output = {1,2,1}. So for the same input {1,10,5,7} I need to make models for X value Y value and Z. One solution is to have 3 different models using MLP. But I would like to see if I can have one model. So I thought about using seq2seq. Because the encoder takes a series of input and the decoder provides series of output. But it seems seq2seq in tensorflow cannot handle float values. I can be wrong about this though.</p>\n",
                "tags": "<neural-network><regression><tensorflow>",
                "answers": [
                    [
                        "16906",
                        "2",
                        "16890",
                        "",
                        "",
                        "<p>What you are describing is a normal multidimiensional linear regression. This type of problem is normally addressed with a feedforward network, either MLP or any other architecture that suits the nature of the problem. </p>\n\n<p>Any neural network framework is able to do something like that.</p>\n\n<p>The key to do that is to remember that the last layer should have linear activations (i.e. no activation at all).</p>\n\n<p>As per your requirements, the shape of the input layer would be a vector (34,) and the output (8,).</p>\n\n<p>Update: the usual loss function used for regression problems is mean squared error (MSE). <a href=\"https://github.com/fchollet/keras/issues/1874#issuecomment-193083902\" rel=\"noreferrer\">Here</a>'s an example of multidimensional regression using <a href=\"https://keras.io/\" rel=\"noreferrer\">Keras</a>; the network is not an MLP but it should be Ok to illustrate the idea.</p>\n",
                        "",
                        "14"
                    ],
                    [
                        "25229",
                        "2",
                        "16890",
                        "",
                        "",
                        "<p>You can implement this very simply in Python.<br>\nYour X will be the collection of training x,y,z coordinates.<br>\nYour Y will be the collection of testing x,y,z coordinates.</p>\n\n<pre><code>from sklearn import cross_validation                     \nfrom sklearn.neural_network import MLPRegressor   \n\nmodel = MLPRegressor(solver='lbfgs',alpha=0.001,hidden_layer_sizes=(150,))\ncross_validation.cross_val_score(model, X, Y,scoring='mean_squared_error')\n</code></pre>\n",
                        "",
                        "3"
                    ],
                    [
                        "56314",
                        "2",
                        "16890",
                        "",
                        "",
                        "<p>This is much easier than you would think - you can simply set your output layer to be a vector instead of a single scalar.\nOf course there's no magic around here and I advice you to prep your data (perform batch normalization so all outputs will be values between 0 and 1).</p>\n\n<p>If you're using Keras, the way for doing this is by adding a dense layer as the final output layer:\n<code>model.add(Dense(8, activation='linear'))</code></p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11879",
            "_score": 13.840904,
            "_source": {
                "title": "During a regression task, I am getting low R^2 values, but elementwise difference between test set and prediction values is huge",
                "content": "During a regression task, I am getting low R^2 values, but elementwise difference between test set and prediction values is huge <p>I am doing a random forest regression on my dataset (which has abut 15 input features and 1 target feature). I am getting a decently low R^2 of &lt;1 for both the train and test sets (please do let me know if &lt;1 is not a good-enough R^2 score).</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\n\n# load dataset\ndf = pd.read_csv('Dataset.csv')\n\n# split into input (X) and output (Y) variables\nX = df.drop(['ID_COLUMN', 'TARGET_COLUMN'], axis=1)\nY = df.TARGET_COLUMN\n\n# Split the data into 67% for training and 33% for testing\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33)\n\n# Fitting the regression model to the dataset\nregressor = RandomForestRegressor(n_estimators = 100, random_state = 50)\nregressor.fit(X_train, Y_train.ravel()) # Using ravel() to avoid getting 'DataConversionWarning' warning message\n\n\nprint(\"Predicting Values:\")\ny_pred = regressor.predict(X_test)\n\nprint(\"Getting Model Performance...\")\n\n# Get regression scores\nprint(\"R^2 train = \", regressor.score(X_train, Y_train))\nprint(\"R^2 test = \", regressor.score(X_test, Y_test))\n</code></pre>\n\n<p>This outputs the following:</p>\n\n<pre><code>Predicting Values:\nGetting Model Performance...\nR^2 train =  0.9791000275450427\nR^2 test = 0.8577464692386905\n</code></pre>\n\n<p>Then, I checked the difference between the actual target column values in the test dataset versus the predicted values, like so:</p>\n\n<pre><code>diff = []\nfor i in range(len(y_pred)):\n    if Y_test.values[i]!=0: # a few values were 0 which was causing the corresponding diff value to become inf\n        diff.append(100*np.abs(y_pred[i]-Y_test.values[i])/Y_test.values[i]) # element-wise percentage error\n</code></pre>\n\n<p>I found that <strong>the majority of the element-wise differences were between 40-60% and their mean was almost 50%!</strong></p>\n\n<pre><code>np.mean(diff)\n&gt;&gt;&gt; 49.07580695857447\n</code></pre>\n\n<p>So, which one is correct? Is the regression score correct and my model is good for this data, or is the element-wise error I calculated correct and the model didn't do well for this data? If its the latter, please advise on how to increase the prediction accuracy.</p>\n\n<hr>\n\n<p>I also checked the rmse score:</p>\n\n<pre><code>import math\nrmse = math.sqrt(np.mean((np.array(Y_test) - y_pred)**2))\nrmse\n&gt;&gt;&gt; 3.67328471827293\n</code></pre>\n\n<p>This seems quite high for the model to have done a good job, but please correct me if I'm wrong.</p>\n\n<p>And I also checked the R^2 scores for different number of estimators:</p>\n\n<pre><code>import matplotlib.pyplot as plt\nmodel = RandomForestRegressor(n_jobs=-1)\n# Try different numbers of n_estimators\nestimators = np.arange(10, 200, 10)\nscores = []\nfor n in estimators:\n    model.set_params(n_estimators=n)\n    model.fit(X_train, Y_train)\n    scores.append(model.score(X_test, Y_test))\nplt.title(\"Effect of n_estimators\")\nplt.xlabel(\"n_estimator\")\nplt.ylabel(\"score\")\nplt.plot(estimators, scores)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/MbQtn.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/MbQtn.png\" alt=\"enter image description here\"></a></p>\n\n<p>Please advise.</p>\n\n<hr>\n\n<p>I tried using linear regression first, and got a very high MSE (which is why I was trying out random forest):</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\n\n# The coefficients\nprint('Coefficients: \\n', lr.coef_)\n# The mean squared error\nprint(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % r2_score(y_test, y_pred))\n\n\nCoefficients: \n [ 1.93829229e-01 -4.68738825e-01  2.01635420e-01  6.35902010e-01\n  6.57354434e-03  5.13180293e-03  2.84015810e-01 -1.31469084e-06\n  1.95335035e+00]\nMean squared error: 86.92\nVariance score: 0.08\n</code></pre>\n <machine-learning><python><predictive-modeling><regression><random-forest><p>This line looks wrong to me:</p>\n\n<pre><code>diff.append(100*np.abs(y_pred[i]-Y_test.values[i])/Y_test.values[i])\n</code></pre>\n\n<p>Shouldn't the abs be around the entire calculation?</p>\n\n<pre><code>diff.append(100*np.abs((y_pred[i]-Y_test.values[i])/Y_test.values[i]))\n</code></pre>\n\n<p>That aside, the RMSE calculation looks accurate and is in the scale of the error, and the <span class=\"math-container\">$R^2$</span> is great, so all things being equal, I would lean towards looking for something you did wrong in assessing the errors.  That's why I was focused on your calculation.</p>\n\n<p>One other thought, have you checked for outliers?  This could affect some measures and not others as drastically.</p>\n",
                "codes": [
                    [
                        "diff.append(100*np.abs(y_pred[i]-Y_test.values[i])/Y_test.values[i])\n",
                        "diff.append(100*np.abs((y_pred[i]-Y_test.values[i])/Y_test.values[i]))\n"
                    ]
                ],
                "question_id:": "41842",
                "question_votes:": "",
                "question_text:": "<p>I am doing a random forest regression on my dataset (which has abut 15 input features and 1 target feature). I am getting a decently low R^2 of &lt;1 for both the train and test sets (please do let me know if &lt;1 is not a good-enough R^2 score).</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\n\n# load dataset\ndf = pd.read_csv('Dataset.csv')\n\n# split into input (X) and output (Y) variables\nX = df.drop(['ID_COLUMN', 'TARGET_COLUMN'], axis=1)\nY = df.TARGET_COLUMN\n\n# Split the data into 67% for training and 33% for testing\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33)\n\n# Fitting the regression model to the dataset\nregressor = RandomForestRegressor(n_estimators = 100, random_state = 50)\nregressor.fit(X_train, Y_train.ravel()) # Using ravel() to avoid getting 'DataConversionWarning' warning message\n\n\nprint(\"Predicting Values:\")\ny_pred = regressor.predict(X_test)\n\nprint(\"Getting Model Performance...\")\n\n# Get regression scores\nprint(\"R^2 train = \", regressor.score(X_train, Y_train))\nprint(\"R^2 test = \", regressor.score(X_test, Y_test))\n</code></pre>\n\n<p>This outputs the following:</p>\n\n<pre><code>Predicting Values:\nGetting Model Performance...\nR^2 train =  0.9791000275450427\nR^2 test = 0.8577464692386905\n</code></pre>\n\n<p>Then, I checked the difference between the actual target column values in the test dataset versus the predicted values, like so:</p>\n\n<pre><code>diff = []\nfor i in range(len(y_pred)):\n    if Y_test.values[i]!=0: # a few values were 0 which was causing the corresponding diff value to become inf\n        diff.append(100*np.abs(y_pred[i]-Y_test.values[i])/Y_test.values[i]) # element-wise percentage error\n</code></pre>\n\n<p>I found that <strong>the majority of the element-wise differences were between 40-60% and their mean was almost 50%!</strong></p>\n\n<pre><code>np.mean(diff)\n&gt;&gt;&gt; 49.07580695857447\n</code></pre>\n\n<p>So, which one is correct? Is the regression score correct and my model is good for this data, or is the element-wise error I calculated correct and the model didn't do well for this data? If its the latter, please advise on how to increase the prediction accuracy.</p>\n\n<hr>\n\n<p>I also checked the rmse score:</p>\n\n<pre><code>import math\nrmse = math.sqrt(np.mean((np.array(Y_test) - y_pred)**2))\nrmse\n&gt;&gt;&gt; 3.67328471827293\n</code></pre>\n\n<p>This seems quite high for the model to have done a good job, but please correct me if I'm wrong.</p>\n\n<p>And I also checked the R^2 scores for different number of estimators:</p>\n\n<pre><code>import matplotlib.pyplot as plt\nmodel = RandomForestRegressor(n_jobs=-1)\n# Try different numbers of n_estimators\nestimators = np.arange(10, 200, 10)\nscores = []\nfor n in estimators:\n    model.set_params(n_estimators=n)\n    model.fit(X_train, Y_train)\n    scores.append(model.score(X_test, Y_test))\nplt.title(\"Effect of n_estimators\")\nplt.xlabel(\"n_estimator\")\nplt.ylabel(\"score\")\nplt.plot(estimators, scores)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/MbQtn.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/MbQtn.png\" alt=\"enter image description here\"></a></p>\n\n<p>Please advise.</p>\n\n<hr>\n\n<p>I tried using linear regression first, and got a very high MSE (which is why I was trying out random forest):</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\n\n# The coefficients\nprint('Coefficients: \\n', lr.coef_)\n# The mean squared error\nprint(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % r2_score(y_test, y_pred))\n\n\nCoefficients: \n [ 1.93829229e-01 -4.68738825e-01  2.01635420e-01  6.35902010e-01\n  6.57354434e-03  5.13180293e-03  2.84015810e-01 -1.31469084e-06\n  1.95335035e+00]\nMean squared error: 86.92\nVariance score: 0.08\n</code></pre>\n",
                "tags": "<machine-learning><python><predictive-modeling><regression><random-forest>",
                "answers": [
                    [
                        "41870",
                        "2",
                        "41842",
                        "",
                        "",
                        "<p>This line looks wrong to me:</p>\n\n<pre><code>diff.append(100*np.abs(y_pred[i]-Y_test.values[i])/Y_test.values[i])\n</code></pre>\n\n<p>Shouldn't the abs be around the entire calculation?</p>\n\n<pre><code>diff.append(100*np.abs((y_pred[i]-Y_test.values[i])/Y_test.values[i]))\n</code></pre>\n\n<p>That aside, the RMSE calculation looks accurate and is in the scale of the error, and the <span class=\"math-container\">$R^2$</span> is great, so all things being equal, I would lean towards looking for something you did wrong in assessing the errors.  That's why I was focused on your calculation.</p>\n\n<p>One other thought, have you checked for outliers?  This could affect some measures and not others as drastically.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6495",
            "_score": 13.820911,
            "_source": {
                "title": "sklearn: SGDClassifier yields lower accuracy than LogisticRegression",
                "content": "sklearn: SGDClassifier yields lower accuracy than LogisticRegression <p>I'm participating in the kaggle <a href=\"https://www.kaggle.com/c/statoil-iceberg-classifier-challenge\" rel=\"nofollow noreferrer\">Iceberg Classifier Challenge</a>, where the idea is to classify whether an object present in a radar image is an iceberg or a ship. I am currently trying to implement stochastic gradient descent to get a better idea for how mini batch training works, since the data set won't fit in memory after I perform data augmentation. </p>\n\n<p>SKLearn has the following two libraries for implementing logistic regression, <code>sklearn.LogisticRegression</code> and <code>sklearn.SGDClassifier</code>. After experimenting for a while, I've noticed that the SGD classifier never performs better than the logistic regression classifier, and that there are some other behaviors in the results of the SGD classifier that make me question whether I've implemented it properly or whether it's innately buggy (I'm sure it's the former).</p>\n\n<p>The following plot summarizes the performance of the <code>SGDClassifier</code> model versus <code>LogisticRegression</code> on the iceberg data set.</p>\n\n<p><a href=\"https://i.stack.imgur.com/bjCnz.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/bjCnz.png\" alt=\"sgd-vs-logreg\"></a></p>\n\n<p>The color curves are <code>SGDClassifier</code> training runs with different numbers of mini-batches ranging from 50 to 1604 (the total number of training samples in the data set). Each was trained for 50 passes using <code>SGDClassifier.partial_fit()</code>. The straight horizontal lines represent the base accuracy when only 1s are predicted, the logistic regression score, and the SGD score when all 1604 training samples are fit over a single pass.</p>\n\n<p>I'm having a hard time understanding the following:</p>\n\n<ol>\n<li><p>Why does <code>LogisticRegression</code> so significantly outperform <code>SGDClassifier</code> even though both should be training in the same way on the same data?</p></li>\n<li><p>Why does the performance so greatly decreases when passing over the data 50 times instead of just once? The latter makes sense to me if it's\nsimply a matter of overfitting to the data set when making multiple\nruns over the data, though it would be good to understand how to\nprevent this with mini-batch training.</p></li>\n<li><p>Why do the results so wildly vary with the mini-batch size in a\nnon-monotonic way, even after 50 passes through the data? Since the\ndata is shuffled in between runs I would expect any noisiness in the\nfits to be smoothed over after such a large number of iterations.</p></li>\n</ol>\n\n<p>Here's the code used to generate the results:</p>\n\n<pre><code># Load training date\ndf_train = pd.read_csv('train_data.csv', sep = ',', header = 0, index_col = 0)\n\n\n# Set input names; 'band_i_j' is pixel j from input image i\nimg_size = 75*75\ninputs = ['inc_angle'] + ['band_1_' + str(i) for i in range(img_size)] + ['band_2_' + str(i) for i in range(img_size)]\n\n# Set output name\noutput = 'is_iceberg'\n\n# Set na values to mean of column\ninc_angle_mean = df_train['inc_angle'].mean()\ndf_train['inc_angle'].fillna(inc_angle_mean, inplace = True)\n\n# Get num training samples\nN_train = len(df_train)\n\n# Calculate mean, max, min of each column; standardize inputs\ntrain_means = df_train[inputs].mean()\ntrain_maxes = df_train[inputs].max()\ntrain_mins = df_train[inputs].min()\ndf_train[inputs] = (df_train[inputs] - train_means)/(train_maxes - train_mins)\n\n# Set 80% of data to belong to training set; reserve the rest for validation set\ntrain_indices = list(range(int(0.8*N_train)))\nvalid_indices = list(range(int(0.8*N_train), N_train))\n\n# Base score\nprint('base score', len(df_train[df_train[output]==1])/N_train)\n\n# SGD full-batch\nmodel = sklearn.linear_model.SGDClassifier(loss= 'log', alpha = 1, tol = 0.00001, max_iter = 1000, shuffle = False, random_state = 0)\nmodel.fit(df_train[inputs].iloc[train_indices], df_train[output].iloc[train_indices])\nprint('SGD full-batch', model.score(df_train[inputs].iloc[valid_indices], df_train[output].iloc[valid_indices]))\n\n# Log reg\nmodel = sklearn.linear_model.LogisticRegression(C = 1, tol = 0.00001, random_state = 0)\nmodel.fit(df_train[inputs].iloc[train_indices], df_train[output].iloc[train_indices])\nprint('Log reg', model.score(df_train[inputs].iloc[valid_indices], df_train[output].iloc[valid_indices]))\n\n\n# SGD mini-batch\nnum_passes = 50\nbatch_size = N_train\nmodel = sklearn.linear_model.SGDClassifier(loss= 'log', alpha = 1, tol = 0.00001, shuffle = False, random_state = 0)\n\nsgd_minibatch_scores = []\nfor i in range(num_passes):\n    np.random.shuffle(train_indices)\n    for j in range(int(len(train_indices)/batch_size + 1)):\n\n        if j == int(len(train_indices)/batch_size+1):\n            batch_train_indices = train_indices[j*batch_size:]\n        else:\n            batch_train_indices = train_indices[j*batch_size:(j+1)*batch_size]\n\n        model.partial_fit(df_train[inputs].iloc[batch_train_indices], df_train[output].iloc[batch_train_indices], classes = [0,1])\n\n    sgd_minibatch_scores.append(model.score(df_train[inputs].iloc[valid_indices], df_train[output].iloc[valid_indices]))\n</code></pre>\n <python><scikit-learn><logistic-regression><mini-batch-gradient-descent><p>I found a related post here that suggests that a larger number of iterations are needed for convergence with <code>sklearn.SGDClassifier()</code>. After 3000 passes with <code>sklearn.SGDClassifier()</code> I was able to achieve around the same accuracy as <code>sklearn.LogisticRegression()</code>. I still find it strange that <code>SGDLearn.fit()</code> and <code>LogisticRegression.fit()</code> are not equivalent when training on the exact same samples and with the same arguments, but they must fundamentally train differently.</p>\n\n<p><a href=\"https://i.stack.imgur.com/kjbNK.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/kjbNK.png\" alt=\"sgd-vs-logreg\"></a></p>\n",
                "codes": [
                    []
                ],
                "question_id:": "25235",
                "question_votes:": "5",
                "question_text:": "<p>I'm participating in the kaggle <a href=\"https://www.kaggle.com/c/statoil-iceberg-classifier-challenge\" rel=\"nofollow noreferrer\">Iceberg Classifier Challenge</a>, where the idea is to classify whether an object present in a radar image is an iceberg or a ship. I am currently trying to implement stochastic gradient descent to get a better idea for how mini batch training works, since the data set won't fit in memory after I perform data augmentation. </p>\n\n<p>SKLearn has the following two libraries for implementing logistic regression, <code>sklearn.LogisticRegression</code> and <code>sklearn.SGDClassifier</code>. After experimenting for a while, I've noticed that the SGD classifier never performs better than the logistic regression classifier, and that there are some other behaviors in the results of the SGD classifier that make me question whether I've implemented it properly or whether it's innately buggy (I'm sure it's the former).</p>\n\n<p>The following plot summarizes the performance of the <code>SGDClassifier</code> model versus <code>LogisticRegression</code> on the iceberg data set.</p>\n\n<p><a href=\"https://i.stack.imgur.com/bjCnz.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/bjCnz.png\" alt=\"sgd-vs-logreg\"></a></p>\n\n<p>The color curves are <code>SGDClassifier</code> training runs with different numbers of mini-batches ranging from 50 to 1604 (the total number of training samples in the data set). Each was trained for 50 passes using <code>SGDClassifier.partial_fit()</code>. The straight horizontal lines represent the base accuracy when only 1s are predicted, the logistic regression score, and the SGD score when all 1604 training samples are fit over a single pass.</p>\n\n<p>I'm having a hard time understanding the following:</p>\n\n<ol>\n<li><p>Why does <code>LogisticRegression</code> so significantly outperform <code>SGDClassifier</code> even though both should be training in the same way on the same data?</p></li>\n<li><p>Why does the performance so greatly decreases when passing over the data 50 times instead of just once? The latter makes sense to me if it's\nsimply a matter of overfitting to the data set when making multiple\nruns over the data, though it would be good to understand how to\nprevent this with mini-batch training.</p></li>\n<li><p>Why do the results so wildly vary with the mini-batch size in a\nnon-monotonic way, even after 50 passes through the data? Since the\ndata is shuffled in between runs I would expect any noisiness in the\nfits to be smoothed over after such a large number of iterations.</p></li>\n</ol>\n\n<p>Here's the code used to generate the results:</p>\n\n<pre><code># Load training date\ndf_train = pd.read_csv('train_data.csv', sep = ',', header = 0, index_col = 0)\n\n\n# Set input names; 'band_i_j' is pixel j from input image i\nimg_size = 75*75\ninputs = ['inc_angle'] + ['band_1_' + str(i) for i in range(img_size)] + ['band_2_' + str(i) for i in range(img_size)]\n\n# Set output name\noutput = 'is_iceberg'\n\n# Set na values to mean of column\ninc_angle_mean = df_train['inc_angle'].mean()\ndf_train['inc_angle'].fillna(inc_angle_mean, inplace = True)\n\n# Get num training samples\nN_train = len(df_train)\n\n# Calculate mean, max, min of each column; standardize inputs\ntrain_means = df_train[inputs].mean()\ntrain_maxes = df_train[inputs].max()\ntrain_mins = df_train[inputs].min()\ndf_train[inputs] = (df_train[inputs] - train_means)/(train_maxes - train_mins)\n\n# Set 80% of data to belong to training set; reserve the rest for validation set\ntrain_indices = list(range(int(0.8*N_train)))\nvalid_indices = list(range(int(0.8*N_train), N_train))\n\n# Base score\nprint('base score', len(df_train[df_train[output]==1])/N_train)\n\n# SGD full-batch\nmodel = sklearn.linear_model.SGDClassifier(loss= 'log', alpha = 1, tol = 0.00001, max_iter = 1000, shuffle = False, random_state = 0)\nmodel.fit(df_train[inputs].iloc[train_indices], df_train[output].iloc[train_indices])\nprint('SGD full-batch', model.score(df_train[inputs].iloc[valid_indices], df_train[output].iloc[valid_indices]))\n\n# Log reg\nmodel = sklearn.linear_model.LogisticRegression(C = 1, tol = 0.00001, random_state = 0)\nmodel.fit(df_train[inputs].iloc[train_indices], df_train[output].iloc[train_indices])\nprint('Log reg', model.score(df_train[inputs].iloc[valid_indices], df_train[output].iloc[valid_indices]))\n\n\n# SGD mini-batch\nnum_passes = 50\nbatch_size = N_train\nmodel = sklearn.linear_model.SGDClassifier(loss= 'log', alpha = 1, tol = 0.00001, shuffle = False, random_state = 0)\n\nsgd_minibatch_scores = []\nfor i in range(num_passes):\n    np.random.shuffle(train_indices)\n    for j in range(int(len(train_indices)/batch_size + 1)):\n\n        if j == int(len(train_indices)/batch_size+1):\n            batch_train_indices = train_indices[j*batch_size:]\n        else:\n            batch_train_indices = train_indices[j*batch_size:(j+1)*batch_size]\n\n        model.partial_fit(df_train[inputs].iloc[batch_train_indices], df_train[output].iloc[batch_train_indices], classes = [0,1])\n\n    sgd_minibatch_scores.append(model.score(df_train[inputs].iloc[valid_indices], df_train[output].iloc[valid_indices]))\n</code></pre>\n",
                "tags": "<python><scikit-learn><logistic-regression><mini-batch-gradient-descent>",
                "answers": [
                    [
                        "25302",
                        "2",
                        "25235",
                        "",
                        "",
                        "<p>I found a related post here that suggests that a larger number of iterations are needed for convergence with <code>sklearn.SGDClassifier()</code>. After 3000 passes with <code>sklearn.SGDClassifier()</code> I was able to achieve around the same accuracy as <code>sklearn.LogisticRegression()</code>. I still find it strange that <code>SGDLearn.fit()</code> and <code>LogisticRegression.fit()</code> are not equivalent when training on the exact same samples and with the same arguments, but they must fundamentally train differently.</p>\n\n<p><a href=\"https://i.stack.imgur.com/kjbNK.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/kjbNK.png\" alt=\"sgd-vs-logreg\"></a></p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9282",
            "_score": 13.7813,
            "_source": {
                "title": "Piece-wise regression by clustering",
                "content": "Piece-wise regression by clustering <p>I was wondering about the possibilities of clustering numerical data (more than 3 dimensions) into different clusters and doing curve fitting on each cluster to get much higher accuracy than using a single model. </p>\n\n<p>Since linear regression is preferred, is there any way to cluster the data points based on their linear fitting?</p>\n\n<p>This is because I need a result matching the input data and do not care about unseen data. I cannot hard code the data and use a lookup mechanism. Instead an approximate math function would be preferable.</p>\n\n<p>Is there an existing implementation ? (Preferably in Python)</p>\n <python><regression><linear-regression><p>You can do this in a pretty straightforward way.  The clustering ends up being a form of unsupervised feature engineering, where you are assuming that group membership alters the underlying linear relationship.  </p>\n\n<p>For example, suppose your initial fit is </p>\n\n<pre><code>y = b0 + b1*x1 + ... + bn*xn\n</code></pre>\n\n<p>You then create 3 clusters k1, k2, k3.  Create 2 binary variables, is_k2 &amp; is_k3 (zeros for both imply k1 membership).  Fitting for just this, you'd have</p>\n\n<pre><code>y = (b0 + bn+1*is_k2 + bn+2*is_k3) + b1*x1 + ... + bn*xn\n</code></pre>\n\n<p>Here bn+1 and bn+2 are simply deviations from the original intercept, however, we don't have separate slopes.  In order for the slopes to be independent, we need to continue feature engineering to create the products of the x1..xn variables and the is_k2 &amp; is_k3 variables.  The resulting coefficients can be thought of as changes to the slope from the default class:</p>\n\n<pre><code>y = (b0 + bn+1*is_k2 + bn+2*is_k3) + (b1 + bn+3*is_k2 + bn+4*is_k3)*x1 + ...\n</code></pre>\n\n<p>The problem you're probably anticipating is that you're creating a large number of features, so you'll probably want to use lasso to tame your feature space.</p>\n<p>If you use these 2 packages:</p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html</a></p>\n\n<p><a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html\" rel=\"nofollow noreferrer\">https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html</a></p>\n\n<p>you will get what you want :)</p>\n",
                "codes": [
                    [
                        "y = b0 + b1*x1 + ... + bn*xn\n",
                        "y = (b0 + bn+1*is_k2 + bn+2*is_k3) + b1*x1 + ... + bn*xn\n",
                        "y = (b0 + bn+1*is_k2 + bn+2*is_k3) + (b1 + bn+3*is_k2 + bn+4*is_k3)*x1 + ...\n"
                    ],
                    []
                ],
                "question_id:": "33147",
                "question_votes:": "2",
                "question_text:": "<p>I was wondering about the possibilities of clustering numerical data (more than 3 dimensions) into different clusters and doing curve fitting on each cluster to get much higher accuracy than using a single model. </p>\n\n<p>Since linear regression is preferred, is there any way to cluster the data points based on their linear fitting?</p>\n\n<p>This is because I need a result matching the input data and do not care about unseen data. I cannot hard code the data and use a lookup mechanism. Instead an approximate math function would be preferable.</p>\n\n<p>Is there an existing implementation ? (Preferably in Python)</p>\n",
                "tags": "<python><regression><linear-regression>",
                "answers": [
                    [
                        "36950",
                        "2",
                        "33147",
                        "",
                        "",
                        "<p>You can do this in a pretty straightforward way.  The clustering ends up being a form of unsupervised feature engineering, where you are assuming that group membership alters the underlying linear relationship.  </p>\n\n<p>For example, suppose your initial fit is </p>\n\n<pre><code>y = b0 + b1*x1 + ... + bn*xn\n</code></pre>\n\n<p>You then create 3 clusters k1, k2, k3.  Create 2 binary variables, is_k2 &amp; is_k3 (zeros for both imply k1 membership).  Fitting for just this, you'd have</p>\n\n<pre><code>y = (b0 + bn+1*is_k2 + bn+2*is_k3) + b1*x1 + ... + bn*xn\n</code></pre>\n\n<p>Here bn+1 and bn+2 are simply deviations from the original intercept, however, we don't have separate slopes.  In order for the slopes to be independent, we need to continue feature engineering to create the products of the x1..xn variables and the is_k2 &amp; is_k3 variables.  The resulting coefficients can be thought of as changes to the slope from the default class:</p>\n\n<pre><code>y = (b0 + bn+1*is_k2 + bn+2*is_k3) + (b1 + bn+3*is_k2 + bn+4*is_k3)*x1 + ...\n</code></pre>\n\n<p>The problem you're probably anticipating is that you're creating a large number of features, so you'll probably want to use lasso to tame your feature space.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "33156",
                        "2",
                        "33147",
                        "",
                        "",
                        "<p>If you use these 2 packages:</p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html</a></p>\n\n<p><a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html\" rel=\"nofollow noreferrer\">https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html</a></p>\n\n<p>you will get what you want :)</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7917",
            "_score": 13.781212,
            "_source": {
                "title": "high root mean square error in regression model",
                "content": "high root mean square error in regression model <p>I am applying regression to a data of 110 rows and 7 columns ,each having targets. When I applied Lasso to the data and calculated the RMSE value ,the RMSE value is coming to be 13.11.I think the RMSE value should be close to zero.What is the permissible values of RMSE in a regression model.What could have gone wrong in the computation.</p>\n\n<pre><code>from sklearn import linear_model\nreg = linear_model.Lasso(alpha = .00001)\nreg.fit(Xt,Yt)\nans=reg.predict(Xts)\nprint(ans)\nfrom sklearn.metrics import mean_squared_error\nprint(mean_squared_error(Yts, ans))\n</code></pre>\n\n<p>whereas when I try cross validation the MSE scores are way below 0.35</p>\n\n<pre><code>kfold = KFold(n_splits=10)\nresults = cross_val_score(reg, full_data, target, cv=kfold)\nprint(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\nresults\nResults: -0.13 (0.45) MSE\n</code></pre>\n <machine-learning><scikit-learn><regression><p>RMSE doesn't work that way. An RMSE of 13 might actually great, it completely depends on how your target variable is scaled. For example, if your target variable was in the range [0,1e9], than an RMSE of 13 is spectacular. On the other hand, if your target is in the range [0,1], an RMSE of 0.5 is terrible. If you want to try a metric that can be more readily interpretable as having a \"good\" or \"bad\" score, try Mean Average Percent Error (MAPE).</p>\n\n<p>As far as why you get a lower MSE when you cross validate: you don't show us how you constructed your training and test sets, but my guess is that you basically just got unlucky and ended up with a training/test split that performed poorly on your holdout set. Your CV-MSE is clearly better than your single holdout MSE, but you should also check the spread of CV scores as well. In any event, for a dataset as small as yours I'd recommend using bootstrap cross validation instead of k-fold.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "29293",
                "question_votes:": "2",
                "question_text:": "<p>I am applying regression to a data of 110 rows and 7 columns ,each having targets. When I applied Lasso to the data and calculated the RMSE value ,the RMSE value is coming to be 13.11.I think the RMSE value should be close to zero.What is the permissible values of RMSE in a regression model.What could have gone wrong in the computation.</p>\n\n<pre><code>from sklearn import linear_model\nreg = linear_model.Lasso(alpha = .00001)\nreg.fit(Xt,Yt)\nans=reg.predict(Xts)\nprint(ans)\nfrom sklearn.metrics import mean_squared_error\nprint(mean_squared_error(Yts, ans))\n</code></pre>\n\n<p>whereas when I try cross validation the MSE scores are way below 0.35</p>\n\n<pre><code>kfold = KFold(n_splits=10)\nresults = cross_val_score(reg, full_data, target, cv=kfold)\nprint(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\nresults\nResults: -0.13 (0.45) MSE\n</code></pre>\n",
                "tags": "<machine-learning><scikit-learn><regression>",
                "answers": [
                    [
                        "29294",
                        "2",
                        "29293",
                        "",
                        "",
                        "<p>RMSE doesn't work that way. An RMSE of 13 might actually great, it completely depends on how your target variable is scaled. For example, if your target variable was in the range [0,1e9], than an RMSE of 13 is spectacular. On the other hand, if your target is in the range [0,1], an RMSE of 0.5 is terrible. If you want to try a metric that can be more readily interpretable as having a \"good\" or \"bad\" score, try Mean Average Percent Error (MAPE).</p>\n\n<p>As far as why you get a lower MSE when you cross validate: you don't show us how you constructed your training and test sets, but my guess is that you basically just got unlucky and ended up with a training/test split that performed poorly on your holdout set. Your CV-MSE is clearly better than your single holdout MSE, but you should also check the spread of CV scores as well. In any event, for a dataset as small as yours I'd recommend using bootstrap cross validation instead of k-fold.</p>\n",
                        "",
                        "5"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12507",
            "_score": 13.772593,
            "_source": {
                "title": "LinearRegression with multiple binary features sometimes performs poorly",
                "content": "LinearRegression with multiple binary features sometimes performs poorly <p>I have a dataset comprising a number of binary features which are the dummies (as in, <code>pd.get_dummies()</code>) of categorical features. SalePrice is my target variable. </p>\n\n<p><a href=\"https://i.stack.imgur.com/bZNDX.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/bZNDX.png\" alt=\"My dataset\"></a></p>\n\n<p>I'm literally just fitting a sklearn LinearRegression model with that data a thousand times to get an average of the score, and I'm getting a weird result. The relevant bit of my code looks like this:</p>\n\n<pre><code>import numpy as np\nscores = np.array([])\n\nfor i in range(1000):\n\n    x3_train, x3_test, y3_train, y3_test = train_test_split(\n            df3.drop('SalePrice', axis=1),\n            df3.SalePrice,\n            test_size=0.33\n    )\n\n    lr3 = LinearRegression()\n    lr3.fit(x3_train, y3_train)\n\n    scores = np.insert(scores, 0, lr3.score(x3_test, y3_test))\n\nprint(scores.mean())\n</code></pre>\n\n<p>Now the weird result is that the average result is super poor, because every so often the model just tanks completely but most of the time performs \"reasonably\" (still terrible but that's not a surprise as it's incredibly basic and not tuned at all, I'm just comparing the effect of treating a set of features in different ways). For example the first 30 runs generated these scores:</p>\n\n<pre><code>0     5.907010e-01\n1     6.044523e-01\n2     5.178049e-01\n3     5.622240e-01\n4     5.810432e-01\n5     5.131722e-01\n6     5.772946e-01\n7     4.674152e-01\n8     4.962015e-01\n9     4.887872e-01\n10    5.144772e-01\n11    5.676829e-01\n12    5.122566e-01\n13    5.453985e-01\n14    5.355022e-01\n15    5.888459e-01\n16    5.552912e-01\n17    5.615658e-01\n18    5.472429e-01\n19    5.810185e-01\n20    5.334900e-01\n21    5.493619e-01\n22    5.567195e-01\n23    5.514374e-01\n24    4.916478e-01\n25    4.580718e-01\n26    5.286095e-01\n27    5.761865e-01\n28    5.638573e-01\n29   -1.809208e+24\nName: lr3, dtype: float64\n</code></pre>\n\n<p>I guess my question is what is likely to be happening on that 30th run through such that the model performs so poorly? I'm comparing this model to others that treat the data differently (e.g. simply encode using <code>.astype('category').cat.codes</code>) and whilst there's relatively minor variations in the \"usual\" range of scores (they're all sort of 0.44 - 0.63) those other models don't have this occasional complete tanking.</p>\n <python><scikit-learn><linear-regression><p>Prior to jumping to any conclusions, some questions that immediately comes to my mind:</p>\n\n<ul>\n<li>What is the correlation between your features and target? </li>\n<li>Do you have any numerical features too? </li>\n<li>How large is your feature space (how many independent variables)? </li>\n<li>How about cardinality of your categorical features (levels)? </li>\n<li>Intuitively, are your features are good indicators for predicting SalePrice?</li>\n<li>How your regressor performs, in terms of the distributions of residual? </li>\n<li>Last but not least, have you tried any other regressors? </li>\n</ul>\n\n<p><strong>Initial Guess</strong>: It would be that a simple Linear Regression won't work because there is no linear correlation between your features and target (see <a href=\"https://datascience.stackexchange.com/questions/32295/assumptions-of-linear-regression/32297#32297\">Assumptions of Linear Regressions</a>). </p>\n\n<p><strong>Practical Suggestion</strong>: I would suggest trying a quick and dirty Gradient Boosting Trees for Regression (either sklearn or XGboost or Catboost implementation) and see if you notice any immediate improvement. From your explanation I see that you have quick a few categorical features that you encoded using One-Hot-Encoding (OHE) method via pd.get_dummies() in pandas. I have personally experienced that OHE is not a good idea for most of problems esp. when your have a lot of categorical features and they present high cardinality (i.e. many levels in each categorical feature), and if you search you find such examples that people struggle using OHE. Anyways, here are two very quick implementation of Catboost Regressor in Kaggle <a href=\"https://www.kaggle.com/nicapotato/simple-catboost\" rel=\"nofollow noreferrer\">1</a>, <a href=\"https://www.kaggle.com/miloofcroton/house-prices-regression-using-catboost-2/log\" rel=\"nofollow noreferrer\">2</a> to have a quick start. Good thing about Catboost is that one does not need to encode categorical features, you can pass then as it is, you only need to give the column index of your categorical features (let me know if you have struggle make Catboost up and running!).</p>\n<p>You should always consider normalizing your output to some predefined range, otherwise there is a possibility of the gradients exploding as the loss will be of high magnitudes. It also becomes hard to output such a wide range. Try transforming your output using some StandardScaler, or a RobustScaler if there are significant outliers, and try again. </p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "43897",
                "question_votes:": "",
                "question_text:": "<p>I have a dataset comprising a number of binary features which are the dummies (as in, <code>pd.get_dummies()</code>) of categorical features. SalePrice is my target variable. </p>\n\n<p><a href=\"https://i.stack.imgur.com/bZNDX.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/bZNDX.png\" alt=\"My dataset\"></a></p>\n\n<p>I'm literally just fitting a sklearn LinearRegression model with that data a thousand times to get an average of the score, and I'm getting a weird result. The relevant bit of my code looks like this:</p>\n\n<pre><code>import numpy as np\nscores = np.array([])\n\nfor i in range(1000):\n\n    x3_train, x3_test, y3_train, y3_test = train_test_split(\n            df3.drop('SalePrice', axis=1),\n            df3.SalePrice,\n            test_size=0.33\n    )\n\n    lr3 = LinearRegression()\n    lr3.fit(x3_train, y3_train)\n\n    scores = np.insert(scores, 0, lr3.score(x3_test, y3_test))\n\nprint(scores.mean())\n</code></pre>\n\n<p>Now the weird result is that the average result is super poor, because every so often the model just tanks completely but most of the time performs \"reasonably\" (still terrible but that's not a surprise as it's incredibly basic and not tuned at all, I'm just comparing the effect of treating a set of features in different ways). For example the first 30 runs generated these scores:</p>\n\n<pre><code>0     5.907010e-01\n1     6.044523e-01\n2     5.178049e-01\n3     5.622240e-01\n4     5.810432e-01\n5     5.131722e-01\n6     5.772946e-01\n7     4.674152e-01\n8     4.962015e-01\n9     4.887872e-01\n10    5.144772e-01\n11    5.676829e-01\n12    5.122566e-01\n13    5.453985e-01\n14    5.355022e-01\n15    5.888459e-01\n16    5.552912e-01\n17    5.615658e-01\n18    5.472429e-01\n19    5.810185e-01\n20    5.334900e-01\n21    5.493619e-01\n22    5.567195e-01\n23    5.514374e-01\n24    4.916478e-01\n25    4.580718e-01\n26    5.286095e-01\n27    5.761865e-01\n28    5.638573e-01\n29   -1.809208e+24\nName: lr3, dtype: float64\n</code></pre>\n\n<p>I guess my question is what is likely to be happening on that 30th run through such that the model performs so poorly? I'm comparing this model to others that treat the data differently (e.g. simply encode using <code>.astype('category').cat.codes</code>) and whilst there's relatively minor variations in the \"usual\" range of scores (they're all sort of 0.44 - 0.63) those other models don't have this occasional complete tanking.</p>\n",
                "tags": "<python><scikit-learn><linear-regression>",
                "answers": [
                    [
                        "53622",
                        "2",
                        "43897",
                        "",
                        "",
                        "<p>Prior to jumping to any conclusions, some questions that immediately comes to my mind:</p>\n\n<ul>\n<li>What is the correlation between your features and target? </li>\n<li>Do you have any numerical features too? </li>\n<li>How large is your feature space (how many independent variables)? </li>\n<li>How about cardinality of your categorical features (levels)? </li>\n<li>Intuitively, are your features are good indicators for predicting SalePrice?</li>\n<li>How your regressor performs, in terms of the distributions of residual? </li>\n<li>Last but not least, have you tried any other regressors? </li>\n</ul>\n\n<p><strong>Initial Guess</strong>: It would be that a simple Linear Regression won't work because there is no linear correlation between your features and target (see <a href=\"https://datascience.stackexchange.com/questions/32295/assumptions-of-linear-regression/32297#32297\">Assumptions of Linear Regressions</a>). </p>\n\n<p><strong>Practical Suggestion</strong>: I would suggest trying a quick and dirty Gradient Boosting Trees for Regression (either sklearn or XGboost or Catboost implementation) and see if you notice any immediate improvement. From your explanation I see that you have quick a few categorical features that you encoded using One-Hot-Encoding (OHE) method via pd.get_dummies() in pandas. I have personally experienced that OHE is not a good idea for most of problems esp. when your have a lot of categorical features and they present high cardinality (i.e. many levels in each categorical feature), and if you search you find such examples that people struggle using OHE. Anyways, here are two very quick implementation of Catboost Regressor in Kaggle <a href=\"https://www.kaggle.com/nicapotato/simple-catboost\" rel=\"nofollow noreferrer\">1</a>, <a href=\"https://www.kaggle.com/miloofcroton/house-prices-regression-using-catboost-2/log\" rel=\"nofollow noreferrer\">2</a> to have a quick start. Good thing about Catboost is that one does not need to encode categorical features, you can pass then as it is, you only need to give the column index of your categorical features (let me know if you have struggle make Catboost up and running!).</p>\n",
                        "",
                        ""
                    ],
                    [
                        "43900",
                        "2",
                        "43897",
                        "",
                        "",
                        "<p>You should always consider normalizing your output to some predefined range, otherwise there is a possibility of the gradients exploding as the loss will be of high magnitudes. It also becomes hard to output such a wide range. Try transforming your output using some StandardScaler, or a RobustScaler if there are significant outliers, and try again. </p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "18174",
            "_score": 13.757537,
            "_source": {
                "title": "Procedure for selecting optimal number of features with Python's Scikit-Learn",
                "content": "Procedure for selecting optimal number of features with Python's Scikit-Learn <p>I have a dataset with 130 features (1000 rows) . I want to select the best features for my classifier. I started with <code>RFE</code> but Its taking too long, i done this:</p>\n\n<pre><code>number_of_columns = 130\n\nfor i in range(1, number_of_columns):\n    rfe = RFE(model, i)\n    fit = rfe.fit(x_train, y_train)\n    acc = fit.score(x_test, y_test\n</code></pre>\n\n<p>Because this took to long, I changed my approach, and I want to see what you think about it, is it good / correct approach.</p>\n\n<p>First I did <code>PCA</code>, and I found out that each column participates with around 1-0.4%, except last 9 columns. Last 9 columns participate with less than 0.00001% so I removed them. Now I have 121 features.</p>\n\n<p><code>pca = PCA()\nfit = pca.fit(x)</code></p>\n\n<p>Then I split my data into train and test (with 121 features).</p>\n\n<p>Then I used <code>SelectFromModel</code>, and I tested it with 4 different classifiers. Each classifier in <code>SelectFromModel</code> reduced the number of columns. I chosed the number of column that was determined by classifier that gave me the best accuracy:</p>\n\n<pre><code>model = SelectFromModel(clf, prefit=True)\n#train_score = clf.score(x_train, y_train)\ntest_score = clf.score(x_test, y_test)\ncolumn_res = model.transform(x_train).shape\n</code></pre>\n\n<p>End finally I used 'RFE'. I have used number of columns that i get with 'SelectFromModel'.</p>\n\n<pre><code>rfe = RFE(model, number_of_columns)\nfit = rfe.fit(x_train, y_train)\nacc = fit.score(x_test, y_test)\n</code></pre>\n\n<p>Is this a good approach, or I did something wrong?</p>\n\n<p>Also, If I got the biggest accuracy in <code>SelectFromModel</code> with one classifier, do I need to use the same classifier in <code>RFE</code>? </p>\n <machine-learning><python><scikit-learn><data-science-model><p>For that amount of features I use Selectbest <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\" rel=\"nofollow noreferrer\">sklearn.feature_selection.SelectKBest</a></p>\n\n<p>To do this, I take 1/4, 1/3, 1/2, 2/3, 3/4 of all the feaures and analyze how the score used to measure the error varies.</p>\n\n<p>OTHER OPTION:</p>\n\n<p>I use LassoCV\n<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html\" rel=\"nofollow noreferrer\">sklearn.linear_model.LassoCV</a></p>\n\n<p>as follows:</p>\n\n<pre><code>kfold_on_rf = StratifiedKFold(\n    n_splits=10, \n    shuffle=False, \n    random_state=SEED\n)\n\nlasso_cv = LassoCV(cv=kfold_on_rf, random_state=SEED, verbose=0)\nsfm = SelectFromModel(lasso_cv)\n</code></pre>\n<p>You may have a try on Lasso (l1 penalty) which does automatic feature selection by \u201eshrinking\u201c parameters. This is one of the standard approaches to data with many columns and \u201enot so many\u201c rows.</p>\n\n<pre><code>sklearn.linear_model.LogisticRegression(penalty=\u2019l1\u2018,...\n</code></pre>\n\n<p>See also this post: <a href=\"https://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_path.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_path.html</a></p>\n\n<p><strong>Edit:</strong></p>\n\n<p>The book \u201eIntroduction to Statistical Learning\u201c gives a really good overview. Here are the Python code examples from the book. Section 6.6.2 covers the Lasso: <a href=\"https://github.com/JWarmenhoven/ISLR-python\" rel=\"nofollow noreferrer\">https://github.com/JWarmenhoven/ISLR-python</a></p>\n",
                "codes": [
                    [
                        "kfold_on_rf = StratifiedKFold(\n    n_splits=10, \n    shuffle=False, \n    random_state=SEED\n)\n\nlasso_cv = LassoCV(cv=kfold_on_rf, random_state=SEED, verbose=0)\nsfm = SelectFromModel(lasso_cv)\n"
                    ],
                    [
                        "sklearn.linear_model.LogisticRegression(penalty=\u2019l1\u2018,...\n"
                    ]
                ],
                "question_id:": "57816",
                "question_votes:": "2",
                "question_text:": "<p>I have a dataset with 130 features (1000 rows) . I want to select the best features for my classifier. I started with <code>RFE</code> but Its taking too long, i done this:</p>\n\n<pre><code>number_of_columns = 130\n\nfor i in range(1, number_of_columns):\n    rfe = RFE(model, i)\n    fit = rfe.fit(x_train, y_train)\n    acc = fit.score(x_test, y_test\n</code></pre>\n\n<p>Because this took to long, I changed my approach, and I want to see what you think about it, is it good / correct approach.</p>\n\n<p>First I did <code>PCA</code>, and I found out that each column participates with around 1-0.4%, except last 9 columns. Last 9 columns participate with less than 0.00001% so I removed them. Now I have 121 features.</p>\n\n<p><code>pca = PCA()\nfit = pca.fit(x)</code></p>\n\n<p>Then I split my data into train and test (with 121 features).</p>\n\n<p>Then I used <code>SelectFromModel</code>, and I tested it with 4 different classifiers. Each classifier in <code>SelectFromModel</code> reduced the number of columns. I chosed the number of column that was determined by classifier that gave me the best accuracy:</p>\n\n<pre><code>model = SelectFromModel(clf, prefit=True)\n#train_score = clf.score(x_train, y_train)\ntest_score = clf.score(x_test, y_test)\ncolumn_res = model.transform(x_train).shape\n</code></pre>\n\n<p>End finally I used 'RFE'. I have used number of columns that i get with 'SelectFromModel'.</p>\n\n<pre><code>rfe = RFE(model, number_of_columns)\nfit = rfe.fit(x_train, y_train)\nacc = fit.score(x_test, y_test)\n</code></pre>\n\n<p>Is this a good approach, or I did something wrong?</p>\n\n<p>Also, If I got the biggest accuracy in <code>SelectFromModel</code> with one classifier, do I need to use the same classifier in <code>RFE</code>? </p>\n",
                "tags": "<machine-learning><python><scikit-learn><data-science-model>",
                "answers": [
                    [
                        "57827",
                        "2",
                        "57816",
                        "",
                        "",
                        "<p>For that amount of features I use Selectbest <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\" rel=\"nofollow noreferrer\">sklearn.feature_selection.SelectKBest</a></p>\n\n<p>To do this, I take 1/4, 1/3, 1/2, 2/3, 3/4 of all the feaures and analyze how the score used to measure the error varies.</p>\n\n<p>OTHER OPTION:</p>\n\n<p>I use LassoCV\n<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html\" rel=\"nofollow noreferrer\">sklearn.linear_model.LassoCV</a></p>\n\n<p>as follows:</p>\n\n<pre><code>kfold_on_rf = StratifiedKFold(\n    n_splits=10, \n    shuffle=False, \n    random_state=SEED\n)\n\nlasso_cv = LassoCV(cv=kfold_on_rf, random_state=SEED, verbose=0)\nsfm = SelectFromModel(lasso_cv)\n</code></pre>\n",
                        "",
                        ""
                    ],
                    [
                        "57823",
                        "2",
                        "57816",
                        "",
                        "",
                        "<p>You may have a try on Lasso (l1 penalty) which does automatic feature selection by \u201eshrinking\u201c parameters. This is one of the standard approaches to data with many columns and \u201enot so many\u201c rows.</p>\n\n<pre><code>sklearn.linear_model.LogisticRegression(penalty=\u2019l1\u2018,...\n</code></pre>\n\n<p>See also this post: <a href=\"https://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_path.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_path.html</a></p>\n\n<p><strong>Edit:</strong></p>\n\n<p>The book \u201eIntroduction to Statistical Learning\u201c gives a really good overview. Here are the Python code examples from the book. Section 6.6.2 covers the Lasso: <a href=\"https://github.com/JWarmenhoven/ISLR-python\" rel=\"nofollow noreferrer\">https://github.com/JWarmenhoven/ISLR-python</a></p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "18283",
            "_score": 13.709344,
            "_source": {
                "title": "Multiple linear the final X output is the same as the imported one despite the fact that p-value are bigger than 0.05",
                "content": "Multiple linear the final X output is the same as the imported one despite the fact that p-value are bigger than 0.05 <p>I am making a simple test on multiple linear regression.</p>\n\n<ol>\n<li><p>Importing datasets and libraries</p>\n\n<pre><code>import numpy as np\nimport matplotlib as plt\nimport pandas as pd\n\ndataset = pd.read_csv('50_Startups.csv')\nX = dataset.iloc[:, :-1]\ny = dataset.iloc[:, 4]\n</code></pre></li>\n<li><p>Split categorical features into numeric</p>\n\n<pre><code>from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nle = LabelEncoder()\noe = OneHotEncoder(categorical_features=[3])\nX.iloc[:, 3] = le.fit_transform(X.iloc[:, 3])\nX = oe.fit_transform(X).toarray()\n</code></pre></li>\n<li><p>Removing a variable to avoid dummy variable trap</p>\n\n<pre><code>X = X[:, 1:]\n</code></pre></li>\n<li><p>Building an optimal model using multiple linear regression and <code>statsmodel</code>:</p>\n\n<pre><code>import statsmodels.api as sm\nX = np.append(arr = np.ones((50, 1)).astype(int), values = X, axis = 1)\n</code></pre></li>\n</ol>\n\n<p>To run the model, I made the following function:</p>\n\n<pre><code>def calculateMultReg(x, sl):\n    dataSetLength = len(x[0])\n    for i in range(0, dataSetLength):\n        regressor_OLS = sm.OLS(endog=y, exog=X).fit()\n        maxPValue = max(regressor_OLS._results.pvalues).astype(float)\n        if(maxPValue&gt;sl):\n            for j in range(0, dataSetLength-i):\n                if(maxPValue==regressor_OLS._results.pvalues[j]):\n                    x = np.delete(x, j, 1)\n        regressor_OLS.summary()\n        return x\ncalculateMultReg(X, 0.05)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/lvJkW.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/lvJkW.png\" alt=\"enter image description here\"></a></p>\n\n<p>The result was that X was as the same as the initial one imported at the top of the script.</p>\n\n<p>But when I do it manually (the multiple linear regression) using the following:</p>\n\n<pre><code>#First pvalue comparing. Column with index 2 has been removed.\nX_opt = X[:, [0, 1, 3, 4, 5]]\n#ordinary least square model\nregressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\nregressor_OLS.summary()\n\n#Second pvalue comparing. Column with index 1 has been removed.\nX_opt = X[:, [0, 3, 4, 5]]\n#ordinary least square model\nregressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\nregressor_OLS.summary()\n...\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/isV0w.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/isV0w.png\" alt=\"enter image description here\"></a></p>\n\n<p>The final X_opt was only 2 fields.</p>\n\n<p>So why this is happening? and how I test a test set?</p>\n <machine-learning><python><regression><linear-regression>",
                "codes": [],
                "question_id:": "58055",
                "question_votes:": "",
                "question_text:": "<p>I am making a simple test on multiple linear regression.</p>\n\n<ol>\n<li><p>Importing datasets and libraries</p>\n\n<pre><code>import numpy as np\nimport matplotlib as plt\nimport pandas as pd\n\ndataset = pd.read_csv('50_Startups.csv')\nX = dataset.iloc[:, :-1]\ny = dataset.iloc[:, 4]\n</code></pre></li>\n<li><p>Split categorical features into numeric</p>\n\n<pre><code>from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nle = LabelEncoder()\noe = OneHotEncoder(categorical_features=[3])\nX.iloc[:, 3] = le.fit_transform(X.iloc[:, 3])\nX = oe.fit_transform(X).toarray()\n</code></pre></li>\n<li><p>Removing a variable to avoid dummy variable trap</p>\n\n<pre><code>X = X[:, 1:]\n</code></pre></li>\n<li><p>Building an optimal model using multiple linear regression and <code>statsmodel</code>:</p>\n\n<pre><code>import statsmodels.api as sm\nX = np.append(arr = np.ones((50, 1)).astype(int), values = X, axis = 1)\n</code></pre></li>\n</ol>\n\n<p>To run the model, I made the following function:</p>\n\n<pre><code>def calculateMultReg(x, sl):\n    dataSetLength = len(x[0])\n    for i in range(0, dataSetLength):\n        regressor_OLS = sm.OLS(endog=y, exog=X).fit()\n        maxPValue = max(regressor_OLS._results.pvalues).astype(float)\n        if(maxPValue&gt;sl):\n            for j in range(0, dataSetLength-i):\n                if(maxPValue==regressor_OLS._results.pvalues[j]):\n                    x = np.delete(x, j, 1)\n        regressor_OLS.summary()\n        return x\ncalculateMultReg(X, 0.05)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/lvJkW.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/lvJkW.png\" alt=\"enter image description here\"></a></p>\n\n<p>The result was that X was as the same as the initial one imported at the top of the script.</p>\n\n<p>But when I do it manually (the multiple linear regression) using the following:</p>\n\n<pre><code>#First pvalue comparing. Column with index 2 has been removed.\nX_opt = X[:, [0, 1, 3, 4, 5]]\n#ordinary least square model\nregressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\nregressor_OLS.summary()\n\n#Second pvalue comparing. Column with index 1 has been removed.\nX_opt = X[:, [0, 3, 4, 5]]\n#ordinary least square model\nregressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\nregressor_OLS.summary()\n...\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/isV0w.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/isV0w.png\" alt=\"enter image description here\"></a></p>\n\n<p>The final X_opt was only 2 fields.</p>\n\n<p>So why this is happening? and how I test a test set?</p>\n",
                "tags": "<machine-learning><python><regression><linear-regression>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15694",
            "_score": 13.703308,
            "_source": {
                "title": "Football match prediction using regression",
                "content": "Football match prediction using regression <p>I am trying to predict goal difference of football matches in keras using a single layer Neural Network. I used mse as metrics and its a low value aroung 0.05 but some predictions has huge difference.\n<a href=\"https://i.stack.imgur.com/R2SLk.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/R2SLk.png\" alt=\"goal Difference Prediction vs Goal Difference Test\"></a></p>\n\n<p>I tried sklearn LinearRegression too but results were almost same. Also I have tried multiple layers network too but results were almost same too.</p>\n\n<p>Any ideas to lower the predicted difference?</p>\n <neural-network><keras><scikit-learn><linear-regression><p>If your MSE is low, but then your predictions on the test set are way off, i can think only of over-fitting either you're leaking information from the training set to the test set ( or vice-versa ) or you simply have a complex model ( too many features ) which you could solve by increasing your data or going for less features.</p>\n\n<p>That's a first diagnosis, maybe you could plot your learning curves so you can check your variance/bias and tell which one of those problems you have.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "52442",
                "question_votes:": "",
                "question_text:": "<p>I am trying to predict goal difference of football matches in keras using a single layer Neural Network. I used mse as metrics and its a low value aroung 0.05 but some predictions has huge difference.\n<a href=\"https://i.stack.imgur.com/R2SLk.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/R2SLk.png\" alt=\"goal Difference Prediction vs Goal Difference Test\"></a></p>\n\n<p>I tried sklearn LinearRegression too but results were almost same. Also I have tried multiple layers network too but results were almost same too.</p>\n\n<p>Any ideas to lower the predicted difference?</p>\n",
                "tags": "<neural-network><keras><scikit-learn><linear-regression>",
                "answers": [
                    [
                        "52449",
                        "2",
                        "52442",
                        "",
                        "",
                        "<p>If your MSE is low, but then your predictions on the test set are way off, i can think only of over-fitting either you're leaking information from the training set to the test set ( or vice-versa ) or you simply have a complex model ( too many features ) which you could solve by increasing your data or going for less features.</p>\n\n<p>That's a first diagnosis, maybe you could plot your learning curves so you can check your variance/bias and tell which one of those problems you have.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10610",
            "_score": 13.674308,
            "_source": {
                "title": "How to handle large number of features in machine learning?",
                "content": "How to handle large number of features in machine learning? <p>I try to do normal classification on high dimensional traditional columnar data (several hundred columns). The features are of different type. In this case, it's clearly out of question to examine each features one by one to figure out what are they exactly and what optimization or feature engineering could be done with them.</p>\n\n<p>Still, I have to do all the necessary preprocessing steps like imputation, standardization etc. But even such basic steps like categorical feature encoding or imputation are problematic because R/Python-pandas are sometimes wrongly recognized the numeric/categorical nature of some variables (and as a consequence, wrongly try to encode or mean-impute the NAs), not to mention other very problematic issues that could be handled if one could oversee the features one by one.</p>\n\n<p>Of course, I could turn to models which are capable of handling non-standardized features with NAs but this limits the number of possible models on one hand and seems me very unprofessional on the other hand. What is the way to get over this issue?</p>\n <machine-learning><neural-network><deep-learning><feature-engineering><dimensionality-reduction><p>I think you should first check the correlations between the features which tells you which of these features can be neglected if you are not done with this step first. This will reduce features dimensionality to some extent by not selecting the features which are dependent on others.</p>\n<p>There are numerous things that you can do. I suggest two things that are very plausible. </p>\n\n<ol>\n<li>Try to use <a href=\"https://datascience.stackexchange.com/a/26719/28175\"><code>PCA</code></a>. Although it is linear, you have the flexibility to reduce the number of features and investigate how much information you are losing. </li>\n<li>Try to find the correlation between each feature and the output. If they are uncorrelated, you might think of ignoring the feature. But beware of cross-features. Eg: It maybe the case that your underlying data is like:</li>\n</ol>\n\n<pre><code>F1 F2 L\nA  X  1\nA  Y  0\nB  X  0\nB  Y  1\n</code></pre>\n\n<p>Now, F1 and F2 individually are uncorrelated with the data, but together they determine the label completely.</p>\n\n<p>Although you have too many features, it can be done automatically.</p>\n<p>There are 4 ways I know in Python. In the following I copied the code I wrote for regression purposes. Classification would be very similar :</p>\n\n<p><strong>First</strong>: <strong>SelectKBest</strong>:</p>\n\n<pre><code>from sklearn.feature_selection import SelectKBest, f_regression\ntrain_data = train_data.apply(pd.to_numeric).astype('float32')\n\nkb = SelectKBest(score_func=f_regression, k=70)\nkb.fit(train_data.loc[:, train_data.columns != 'SalePriceLog'], train_data.SalePriceLog)\nindices = np.argsort(kb.scores_)[::-1]\nselected_features = []\nfor i in range(5):\n  selected_features.append(train_data.columns[indices[i]])\nplt.figure()\nplt.bar(selected_features, kb.scores_[indices[range(5)]], color='r', align='center')\nplt.xticks(rotation=45)\n</code></pre>\n\n<p>results:\n<a href=\"https://i.stack.imgur.com/SxcgW.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/SxcgW.png\" alt=\"enter image description here\"></a></p>\n\n<p><strong>Second: RFE</strong></p>\n\n<pre><code> from sklearn.linear_model import LogisticRegression, LinearRegression\n    from sklearn.feature_selection import RFE\n    model = LinearRegression()\n    rfe = RFE(model, 10)\n    fit_rfe = rfe.fit(train_data.loc[:, train_data.columns != 'SalePriceLog'], train_data.SalePriceLog)\nindices_rfe = np.argsort(fit_rfe.ranking_)\nselected_features_rfe = []\nfor i in range(10):\n    selected_features_rfe.append(train_data.columns[indices_rfe[i]])\nselected_features_rfe\nplt.figure()\nplt.bar(selected_features_rfe, fit_rfe.ranking_[indices[range(10)]], color='r', align='center')\nplt.xticks(rotation=45)\n</code></pre>\n\n<p>results:<a href=\"https://i.stack.imgur.com/OcBFE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/OcBFE.png\" alt=\"enter image description here\"></a></p>\n\n<p><strong>Third: PCA</strong></p>\n\n<pre><code>from sklearn.decomposition import PCA\n# pca = PCA(n_components=5)\npca = PCA(0.999)\nfit = pca.fit(train_data.loc[:, train_data.columns != 'SalePriceLog'])\n</code></pre>\n\n<p><strong>Fourth: ExtraTrees</strong></p>\n\n<pre><code>from sklearn.ensemble import ExtraTreesRegressor\n\nmodel_extra_tree = ExtraTreesRegressor()\nmodel_extra_tree.fit(train_data.loc[:, train_data.columns != 'SalePriceLog'], train_data.SalePriceLog)\nindices_extra_tree = np.argsort(model_extra_tree.feature_importances_)[::-1]\nselected_feature_extra_tree = []\nfor i in range(10):\n    selected_feature_extra_tree.append(train_data.columns[indices_extra_tree[i]])\nplt.figure\nplt.bar(selected_feature_extra_tree, model_extra_tree.feature_importances_[indices_extra_tree[range(10)]])\nplt.xticks(rotation=45)\n</code></pre>\n\n<p>results:<a href=\"https://i.stack.imgur.com/WZOoS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WZOoS.png\" alt=\"enter image description here\"></a></p>\n",
                "codes": [
                    [],
                    [
                        "F1 F2 L\nA  X  1\nA  Y  0\nB  X  0\nB  Y  1\n"
                    ],
                    [
                        "from sklearn.feature_selection import SelectKBest, f_regression\ntrain_data = train_data.apply(pd.to_numeric).astype('float32')\n\nkb = SelectKBest(score_func=f_regression, k=70)\nkb.fit(train_data.loc[:, train_data.columns != 'SalePriceLog'], train_data.SalePriceLog)\nindices = np.argsort(kb.scores_)[::-1]\nselected_features = []\nfor i in range(5):\n  selected_features.append(train_data.columns[indices[i]])\nplt.figure()\nplt.bar(selected_features, kb.scores_[indices[range(5)]], color='r', align='center')\nplt.xticks(rotation=45)\n",
                        " from sklearn.linear_model import LogisticRegression, LinearRegression\n    from sklearn.feature_selection import RFE\n    model = LinearRegression()\n    rfe = RFE(model, 10)\n    fit_rfe = rfe.fit(train_data.loc[:, train_data.columns != 'SalePriceLog'], train_data.SalePriceLog)\nindices_rfe = np.argsort(fit_rfe.ranking_)\nselected_features_rfe = []\nfor i in range(10):\n    selected_features_rfe.append(train_data.columns[indices_rfe[i]])\nselected_features_rfe\nplt.figure()\nplt.bar(selected_features_rfe, fit_rfe.ranking_[indices[range(10)]], color='r', align='center')\nplt.xticks(rotation=45)\n",
                        "from sklearn.decomposition import PCA\n# pca = PCA(n_components=5)\npca = PCA(0.999)\nfit = pca.fit(train_data.loc[:, train_data.columns != 'SalePriceLog'])\n",
                        "from sklearn.ensemble import ExtraTreesRegressor\n\nmodel_extra_tree = ExtraTreesRegressor()\nmodel_extra_tree.fit(train_data.loc[:, train_data.columns != 'SalePriceLog'], train_data.SalePriceLog)\nindices_extra_tree = np.argsort(model_extra_tree.feature_importances_)[::-1]\nselected_feature_extra_tree = []\nfor i in range(10):\n    selected_feature_extra_tree.append(train_data.columns[indices_extra_tree[i]])\nplt.figure\nplt.bar(selected_feature_extra_tree, model_extra_tree.feature_importances_[indices_extra_tree[range(10)]])\nplt.xticks(rotation=45)\n"
                    ]
                ],
                "question_id:": "37957",
                "question_votes:": "3",
                "question_text:": "<p>I try to do normal classification on high dimensional traditional columnar data (several hundred columns). The features are of different type. In this case, it's clearly out of question to examine each features one by one to figure out what are they exactly and what optimization or feature engineering could be done with them.</p>\n\n<p>Still, I have to do all the necessary preprocessing steps like imputation, standardization etc. But even such basic steps like categorical feature encoding or imputation are problematic because R/Python-pandas are sometimes wrongly recognized the numeric/categorical nature of some variables (and as a consequence, wrongly try to encode or mean-impute the NAs), not to mention other very problematic issues that could be handled if one could oversee the features one by one.</p>\n\n<p>Of course, I could turn to models which are capable of handling non-standardized features with NAs but this limits the number of possible models on one hand and seems me very unprofessional on the other hand. What is the way to get over this issue?</p>\n",
                "tags": "<machine-learning><neural-network><deep-learning><feature-engineering><dimensionality-reduction>",
                "answers": [
                    [
                        "37958",
                        "2",
                        "37957",
                        "",
                        "",
                        "<p>I think you should first check the correlations between the features which tells you which of these features can be neglected if you are not done with this step first. This will reduce features dimensionality to some extent by not selecting the features which are dependent on others.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "37963",
                        "2",
                        "37957",
                        "",
                        "",
                        "<p>There are numerous things that you can do. I suggest two things that are very plausible. </p>\n\n<ol>\n<li>Try to use <a href=\"https://datascience.stackexchange.com/a/26719/28175\"><code>PCA</code></a>. Although it is linear, you have the flexibility to reduce the number of features and investigate how much information you are losing. </li>\n<li>Try to find the correlation between each feature and the output. If they are uncorrelated, you might think of ignoring the feature. But beware of cross-features. Eg: It maybe the case that your underlying data is like:</li>\n</ol>\n\n<pre><code>F1 F2 L\nA  X  1\nA  Y  0\nB  X  0\nB  Y  1\n</code></pre>\n\n<p>Now, F1 and F2 individually are uncorrelated with the data, but together they determine the label completely.</p>\n\n<p>Although you have too many features, it can be done automatically.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "37967",
                        "2",
                        "37957",
                        "",
                        "",
                        "<p>There are 4 ways I know in Python. In the following I copied the code I wrote for regression purposes. Classification would be very similar :</p>\n\n<p><strong>First</strong>: <strong>SelectKBest</strong>:</p>\n\n<pre><code>from sklearn.feature_selection import SelectKBest, f_regression\ntrain_data = train_data.apply(pd.to_numeric).astype('float32')\n\nkb = SelectKBest(score_func=f_regression, k=70)\nkb.fit(train_data.loc[:, train_data.columns != 'SalePriceLog'], train_data.SalePriceLog)\nindices = np.argsort(kb.scores_)[::-1]\nselected_features = []\nfor i in range(5):\n  selected_features.append(train_data.columns[indices[i]])\nplt.figure()\nplt.bar(selected_features, kb.scores_[indices[range(5)]], color='r', align='center')\nplt.xticks(rotation=45)\n</code></pre>\n\n<p>results:\n<a href=\"https://i.stack.imgur.com/SxcgW.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/SxcgW.png\" alt=\"enter image description here\"></a></p>\n\n<p><strong>Second: RFE</strong></p>\n\n<pre><code> from sklearn.linear_model import LogisticRegression, LinearRegression\n    from sklearn.feature_selection import RFE\n    model = LinearRegression()\n    rfe = RFE(model, 10)\n    fit_rfe = rfe.fit(train_data.loc[:, train_data.columns != 'SalePriceLog'], train_data.SalePriceLog)\nindices_rfe = np.argsort(fit_rfe.ranking_)\nselected_features_rfe = []\nfor i in range(10):\n    selected_features_rfe.append(train_data.columns[indices_rfe[i]])\nselected_features_rfe\nplt.figure()\nplt.bar(selected_features_rfe, fit_rfe.ranking_[indices[range(10)]], color='r', align='center')\nplt.xticks(rotation=45)\n</code></pre>\n\n<p>results:<a href=\"https://i.stack.imgur.com/OcBFE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/OcBFE.png\" alt=\"enter image description here\"></a></p>\n\n<p><strong>Third: PCA</strong></p>\n\n<pre><code>from sklearn.decomposition import PCA\n# pca = PCA(n_components=5)\npca = PCA(0.999)\nfit = pca.fit(train_data.loc[:, train_data.columns != 'SalePriceLog'])\n</code></pre>\n\n<p><strong>Fourth: ExtraTrees</strong></p>\n\n<pre><code>from sklearn.ensemble import ExtraTreesRegressor\n\nmodel_extra_tree = ExtraTreesRegressor()\nmodel_extra_tree.fit(train_data.loc[:, train_data.columns != 'SalePriceLog'], train_data.SalePriceLog)\nindices_extra_tree = np.argsort(model_extra_tree.feature_importances_)[::-1]\nselected_feature_extra_tree = []\nfor i in range(10):\n    selected_feature_extra_tree.append(train_data.columns[indices_extra_tree[i]])\nplt.figure\nplt.bar(selected_feature_extra_tree, model_extra_tree.feature_importances_[indices_extra_tree[range(10)]])\nplt.xticks(rotation=45)\n</code></pre>\n\n<p>results:<a href=\"https://i.stack.imgur.com/WZOoS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WZOoS.png\" alt=\"enter image description here\"></a></p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13980",
            "_score": 13.632236,
            "_source": {
                "title": "How do I correctly build model on given data to predict target parameter?",
                "content": "How do I correctly build model on given data to predict target parameter? <p>I have some dataset which contains different paramteres and <code>data.head()</code> looks like this</p>\n\n<p><a href=\"https://i.stack.imgur.com/gZ1bH.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/gZ1bH.png\" alt=\"enter image description here\"></a></p>\n\n<p>Applied some preprocessing and performed Feature ranking - </p>\n\n<pre><code>dataset = pd.read_csv(\"ML.csv\",header = 0)\n\n#Get dataset breif\nprint(dataset.shape)\nprint(dataset.isnull().sum())\n#print(dataset.head())\n\n#Data Pre-processing\ndata = dataset.drop('organization_id',1)\ndata = data.drop('status',1)\ndata = data.drop('city',1)\n\n#Find median for features having NaN\nmedian_zip, median_role_id, median_specialty_id, median_latitude, median_longitude = data['zip'].median(),data['role_id'].median(),data['specialty_id'].median(),data['latitude'].median(),data['longitude'].median() \ndata['zip'].fillna(median_zip, inplace=True)\ndata['role_id'].fillna(median_role_id, inplace=True)\ndata['specialty_id'].fillna(median_specialty_id, inplace=True)\ndata['latitude'].fillna(median_latitude, inplace=True)\ndata['longitude'].fillna(median_longitude, inplace=True)\n\n#Fill YearOFExp with 0\ndata['years_of_experience'].fillna(0, inplace=True)\ntarget = dataset.location_id\n\n#Perform Recursive Feature Extraction\nsvm = LinearSVC()\nrfe = RFE(svm, 1)\nrfe = rfe.fit(data, target) #IT give convergence Warning - Normally when an optimization algorithm does not converge, it is usually because the problem is not well-conditioned, perhaps due to a poor scaling of the decision variables. \n\n\nnames = list(data)\nprint(\"Features sorted by their score:\")\nprint(sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), names)))\n</code></pre>\n\n<p>Output</p>\n\n<p>Features sorted by their score:</p>\n\n<pre><code>[(1, 'location_id'), (2, 'department_id'), (3, 'latitude'), (4, 'specialty_id'), (5, 'longitude'), (6, 'zip'), (7, 'shift_id'), (8, 'user_id'), (9, 'role_id'), (10, 'open_positions'), (11, 'years_of_experience')]\n</code></pre>\n\n<p>From this I understand that which parameters have more importance. \n<strong>Is above processing correct to understand the feature important. How can I use above information for better model training?</strong></p>\n\n<p>When I to model training it gives very high accuracy. How come it gives so high accuracy? </p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\ndataset = pd.read_csv(\"prod_data_for_ML.csv\",header = 0)\n\n#Data Pre-processing\ndata = dataset.drop('location_id',1)\ndata = data.drop('status',1)\ndata = data.drop('city',1)\n\n#Find median for features having NaN\nmedian_zip, median_role_id, median_specialty_id, median_latitude, median_longitude = data['zip'].median(),data['role_id'].median(),data['specialty_id'].median(),data['latitude'].median(),data['longitude'].median() \ndata['zip'].fillna(median_zip, inplace=True)\ndata['role_id'].fillna(median_role_id, inplace=True)\ndata['specialty_id'].fillna(median_specialty_id, inplace=True)\ndata['latitude'].fillna(median_latitude, inplace=True)\ndata['longitude'].fillna(median_longitude, inplace=True)\n\n#Fill YearOFExp with 0\ndata['years_of_experience'].fillna(0, inplace=True)\n\n#Start training\n\nlabels = dataset.location_id\ntrain1 = data\nalgo = LinearRegression()\nx_train , x_test , y_train , y_test = train_test_split(train1 , labels , test_size = 0.20,random_state =1)\n\n# x_train.to_csv(\"x_train.csv\", sep=',', encoding='utf-8')\n# x_test.to_csv(\"x_test.csv\", sep=',', encoding='utf-8')\n\nalgo.fit(x_train,y_train)\nalgo.score(x_test,y_test)\n</code></pre>\n\n<p><strong>output</strong></p>\n\n<pre><code>0.981150074104111\n\nfrom sklearn import ensemble\nclf = ensemble.GradientBoostingRegressor(n_estimators = 400, max_depth = 5, min_samples_split = 2,\n          learning_rate = 0.1, loss = 'ls')\nclf.fit(x_train, y_train)\nclf.score(x_test,y_test)\n</code></pre>\n\n<p>Output - </p>\n\n<pre><code>0.99\n</code></pre>\n\n<p><strong>What I want to do is, predicting  <em>location-id</em>  correctly.\n Am I doing anything wrong? What ithe s correct way to build model for this sort of situati?n.</strong></p>\n\n<p>I know there is some way that I can get Precision, recall, f1 for each paramteres. Can anyone give me reference link to perform this.<strong>strong text</strong></p>\n <machine-learning><scikit-learn><regression><linear-regression><recommender-system><h1>Feature ranking</h1>\n\n<p>You still have <code>location_id</code> as a feature when you're trying to predict <code>location_id</code>. \n So of course that comes out as the \"most important,\" and the other features' importance scores are probably mostly meaningless.</p>\n\n<p>After fixing that, the feature ranking gives you some valuable insight to a problem, and depending on your needs you might drop low-performing variables, etc.</p>\n\n<h1>High performance</h1>\n\n<p>(I don't think you're actually computing <em>accuracy</em> in either case.)  It is extremely surprising to me that a LinearRegression model does so well; most of your variables seem categorical, even the dependent <code>location_id</code>.  Unless there's something predictive in the way the ids are actually assigned?  How many unique values does <code>location_id</code> have?</p>\n\n<p>Is the <code>location_id</code> the location of the user, or the job (assuming I've gotten the context right)?  In either case, if you have many copies of the user/job and happen to split them across the training and test sets, then you may just be leaking information that way: the model learns the mapping user(/job)->location, and happens to be able to apply that to nearly every row in the test set.  (That still doesn't make much sense for LinearRegression, but could in the GBM.)  This is pretty similar to what @ShamitVerma has said, but doesn't rely on an interpretable mapping, just that the train/test split doesn't properly separate users/jobs.</p>\n<p>Train data includes latitude, longitude and zipcode. Output variable is location.</p>\n\n<p>It is trivial to predict location if zip and lat,lon are known.  Try removing these attributes and see if that has any impact on validation score. </p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "47345",
                "question_votes:": "",
                "question_text:": "<p>I have some dataset which contains different paramteres and <code>data.head()</code> looks like this</p>\n\n<p><a href=\"https://i.stack.imgur.com/gZ1bH.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/gZ1bH.png\" alt=\"enter image description here\"></a></p>\n\n<p>Applied some preprocessing and performed Feature ranking - </p>\n\n<pre><code>dataset = pd.read_csv(\"ML.csv\",header = 0)\n\n#Get dataset breif\nprint(dataset.shape)\nprint(dataset.isnull().sum())\n#print(dataset.head())\n\n#Data Pre-processing\ndata = dataset.drop('organization_id',1)\ndata = data.drop('status',1)\ndata = data.drop('city',1)\n\n#Find median for features having NaN\nmedian_zip, median_role_id, median_specialty_id, median_latitude, median_longitude = data['zip'].median(),data['role_id'].median(),data['specialty_id'].median(),data['latitude'].median(),data['longitude'].median() \ndata['zip'].fillna(median_zip, inplace=True)\ndata['role_id'].fillna(median_role_id, inplace=True)\ndata['specialty_id'].fillna(median_specialty_id, inplace=True)\ndata['latitude'].fillna(median_latitude, inplace=True)\ndata['longitude'].fillna(median_longitude, inplace=True)\n\n#Fill YearOFExp with 0\ndata['years_of_experience'].fillna(0, inplace=True)\ntarget = dataset.location_id\n\n#Perform Recursive Feature Extraction\nsvm = LinearSVC()\nrfe = RFE(svm, 1)\nrfe = rfe.fit(data, target) #IT give convergence Warning - Normally when an optimization algorithm does not converge, it is usually because the problem is not well-conditioned, perhaps due to a poor scaling of the decision variables. \n\n\nnames = list(data)\nprint(\"Features sorted by their score:\")\nprint(sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), names)))\n</code></pre>\n\n<p>Output</p>\n\n<p>Features sorted by their score:</p>\n\n<pre><code>[(1, 'location_id'), (2, 'department_id'), (3, 'latitude'), (4, 'specialty_id'), (5, 'longitude'), (6, 'zip'), (7, 'shift_id'), (8, 'user_id'), (9, 'role_id'), (10, 'open_positions'), (11, 'years_of_experience')]\n</code></pre>\n\n<p>From this I understand that which parameters have more importance. \n<strong>Is above processing correct to understand the feature important. How can I use above information for better model training?</strong></p>\n\n<p>When I to model training it gives very high accuracy. How come it gives so high accuracy? </p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\ndataset = pd.read_csv(\"prod_data_for_ML.csv\",header = 0)\n\n#Data Pre-processing\ndata = dataset.drop('location_id',1)\ndata = data.drop('status',1)\ndata = data.drop('city',1)\n\n#Find median for features having NaN\nmedian_zip, median_role_id, median_specialty_id, median_latitude, median_longitude = data['zip'].median(),data['role_id'].median(),data['specialty_id'].median(),data['latitude'].median(),data['longitude'].median() \ndata['zip'].fillna(median_zip, inplace=True)\ndata['role_id'].fillna(median_role_id, inplace=True)\ndata['specialty_id'].fillna(median_specialty_id, inplace=True)\ndata['latitude'].fillna(median_latitude, inplace=True)\ndata['longitude'].fillna(median_longitude, inplace=True)\n\n#Fill YearOFExp with 0\ndata['years_of_experience'].fillna(0, inplace=True)\n\n#Start training\n\nlabels = dataset.location_id\ntrain1 = data\nalgo = LinearRegression()\nx_train , x_test , y_train , y_test = train_test_split(train1 , labels , test_size = 0.20,random_state =1)\n\n# x_train.to_csv(\"x_train.csv\", sep=',', encoding='utf-8')\n# x_test.to_csv(\"x_test.csv\", sep=',', encoding='utf-8')\n\nalgo.fit(x_train,y_train)\nalgo.score(x_test,y_test)\n</code></pre>\n\n<p><strong>output</strong></p>\n\n<pre><code>0.981150074104111\n\nfrom sklearn import ensemble\nclf = ensemble.GradientBoostingRegressor(n_estimators = 400, max_depth = 5, min_samples_split = 2,\n          learning_rate = 0.1, loss = 'ls')\nclf.fit(x_train, y_train)\nclf.score(x_test,y_test)\n</code></pre>\n\n<p>Output - </p>\n\n<pre><code>0.99\n</code></pre>\n\n<p><strong>What I want to do is, predicting  <em>location-id</em>  correctly.\n Am I doing anything wrong? What ithe s correct way to build model for this sort of situati?n.</strong></p>\n\n<p>I know there is some way that I can get Precision, recall, f1 for each paramteres. Can anyone give me reference link to perform this.<strong>strong text</strong></p>\n",
                "tags": "<machine-learning><scikit-learn><regression><linear-regression><recommender-system>",
                "answers": [
                    [
                        "47359",
                        "2",
                        "47345",
                        "",
                        "",
                        "<h1>Feature ranking</h1>\n\n<p>You still have <code>location_id</code> as a feature when you're trying to predict <code>location_id</code>. \n So of course that comes out as the \"most important,\" and the other features' importance scores are probably mostly meaningless.</p>\n\n<p>After fixing that, the feature ranking gives you some valuable insight to a problem, and depending on your needs you might drop low-performing variables, etc.</p>\n\n<h1>High performance</h1>\n\n<p>(I don't think you're actually computing <em>accuracy</em> in either case.)  It is extremely surprising to me that a LinearRegression model does so well; most of your variables seem categorical, even the dependent <code>location_id</code>.  Unless there's something predictive in the way the ids are actually assigned?  How many unique values does <code>location_id</code> have?</p>\n\n<p>Is the <code>location_id</code> the location of the user, or the job (assuming I've gotten the context right)?  In either case, if you have many copies of the user/job and happen to split them across the training and test sets, then you may just be leaking information that way: the model learns the mapping user(/job)->location, and happens to be able to apply that to nearly every row in the test set.  (That still doesn't make much sense for LinearRegression, but could in the GBM.)  This is pretty similar to what @ShamitVerma has said, but doesn't rely on an interpretable mapping, just that the train/test split doesn't properly separate users/jobs.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "47351",
                        "2",
                        "47345",
                        "",
                        "",
                        "<p>Train data includes latitude, longitude and zipcode. Output variable is location.</p>\n\n<p>It is trivial to predict location if zip and lat,lon are known.  Try removing these attributes and see if that has any impact on validation score. </p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "2864",
            "_score": 13.632099,
            "_source": {
                "title": "Sklearn feature selection stopping criterion (SelectFromModel)",
                "content": "Sklearn feature selection stopping criterion (SelectFromModel) <p>Sklearn has several functions for feature selection that lets the user determine the size of the chosen subset. An example of this is <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest\" rel=\"nofollow\">SelectKBest</a> where the user determines the value of \"k\", which is the number of top performing features.</p>\n\n<p>Does anyone know what stopping criterion <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel\" rel=\"nofollow\">SelectFromModel</a> uses when it selects a feature subset? The documentation mentiones a \"threshold\"-parameter that determines which features are important enough, and that this parameter is set to \"median\" OR \"mean\" by default.</p>\n <machine-learning><feature-selection><scikit-learn><p>Some regression/classification models can also calculate feature importances - for example <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" rel=\"nofollow\">RandomForestClassifier</a> models have a property <strong>feature_importances_</strong> and <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow\">LogisticRegression</a> models have a <strong>coef_</strong> property. There are many more models that can provide feature importances - but all of them either have a coef_ or feature_importances_ property.</p>\n\n<p>What SelectFromModel does is to check if the object you pass as \"estimator\" has one of these two properties and to return features where this property is higher than the specified threshold (or the mean/median).</p>\n\n<p>For example if you pass a RandomForestClassifier to SelectFromModel, it will return all features where the random forest's feature_importances_ property is higher than the specified threshold. The same happens if you pass a LogisticRegression model, except that it'll compare the coef_ property with the threshold instead.</p>\n\n<p>Selecting the best value for the threshold can be done using a grid- or randomized search.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "12793",
                "question_votes:": "",
                "question_text:": "<p>Sklearn has several functions for feature selection that lets the user determine the size of the chosen subset. An example of this is <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest\" rel=\"nofollow\">SelectKBest</a> where the user determines the value of \"k\", which is the number of top performing features.</p>\n\n<p>Does anyone know what stopping criterion <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel\" rel=\"nofollow\">SelectFromModel</a> uses when it selects a feature subset? The documentation mentiones a \"threshold\"-parameter that determines which features are important enough, and that this parameter is set to \"median\" OR \"mean\" by default.</p>\n",
                "tags": "<machine-learning><feature-selection><scikit-learn>",
                "answers": [
                    [
                        "12798",
                        "2",
                        "12793",
                        "",
                        "",
                        "<p>Some regression/classification models can also calculate feature importances - for example <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" rel=\"nofollow\">RandomForestClassifier</a> models have a property <strong>feature_importances_</strong> and <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow\">LogisticRegression</a> models have a <strong>coef_</strong> property. There are many more models that can provide feature importances - but all of them either have a coef_ or feature_importances_ property.</p>\n\n<p>What SelectFromModel does is to check if the object you pass as \"estimator\" has one of these two properties and to return features where this property is higher than the specified threshold (or the mean/median).</p>\n\n<p>For example if you pass a RandomForestClassifier to SelectFromModel, it will return all features where the random forest's feature_importances_ property is higher than the specified threshold. The same happens if you pass a LogisticRegression model, except that it'll compare the coef_ property with the threshold instead.</p>\n\n<p>Selecting the best value for the threshold can be done using a grid- or randomized search.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7465",
            "_score": 13.593189,
            "_source": {
                "title": "Ridge regression - varying alpha and observing the residual",
                "content": "Ridge regression - varying alpha and observing the residual <p>I am trying to reproduce this figure from Bishop:</p>\n\n<p><a href=\"https://i.stack.imgur.com/xkJUH.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/xkJUH.png\" alt=\"enter image description here\"></a></p>\n\n<p>Residual vs. Alpha (lambda in figure)</p>\n\n<p>The code is pasted below:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import mean_squared_error\n\nx_train = np.linspace(0, 1, 10)\nnoise_10 = np.random.normal(0, 0.3, 10)\ny_train = np.sin(2*np.pi*x_train) + noise_10\nx_train = x_train[:, np.newaxis]\n\nx_test = np.linspace(0, 1, 100)\nnoise_100 = np.random.normal(0, 0.3, 100)\ny_test = np.sin(2*np.pi*x_test) + noise_100\nx_test = x_test[:, np.newaxis]\n\n\nn_alphas = 200\nalphas = np.logspace(-40, -18, n_alphas)\n\nerrors = []\nfor a in alphas:\n    ridge = make_pipeline(PolynomialFeatures(degree = 9), \n              Ridge(alpha=a))\n    ridge.fit(x_train, y_train)\n    mse = mean_squared_error(y_test, ridge.predict(x_test))\n    errors.append(np.sqrt(mse))    \n\nprint(errors)\n</code></pre>\n\n<p>However, the errors array has the same value for all values of alpha. It's taking the first value of <code>alpha = np.exp(-40)</code> and all the other values seem to be the same for all future iterations of the for loop. How can I correct this error?</p>\n <scikit-learn><regression><p>I still haven't figured out what the previously posted code is doing wrong. However, manually populating the alphas array gives me results that are close to the original figure.</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt \nfrom sklearn import linear_model\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import PolynomialFeatures \nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import mean_squared_error\nnp.random.seed(12344)\nx_1000 = np.linspace(0, 1, 1000)\nx_train = np.linspace(0, 1, 10)\nnoise_10 = np.random.normal(0, 0.3, 10)\ny_train = np.sin(2*np.pi*x_train) + noise_10\nx_train = x_train[:, np.newaxis]\nx_test = np.linspace(0, 1, 100)\nnoise_100 = np.random.normal(0, 0.3, 100)\ny_test = np.sin(2*np.pi*x_test) + noise_100\nx_test = x_test[:, np.newaxis]\nlow_alpha = make_pipeline(PolynomialFeatures(degree = 9), Ridge(alpha=np.exp(-18)))\nlow_alpha.fit(x_test, y_test)\nplt.figure(1)\nplt.plot(x_train, low_alpha.predict(x_train), label = 'alpha = ln(-18)')\nplt.plot(x_1000, np.sin(2*np.pi*x_1000))\nplt.legend()\nplt.show\nhigh_alpha = make_pipeline(PolynomialFeatures(degree = 9),\n              Ridge(alpha=np.exp(0)))\nhigh_alpha.fit(x_test, y_test)\nplt.figure(2)\nplt.plot(x_train, high_alpha.predict(x_train), label = 'alpha = 1')\nplt.plot(x_1000, np.sin(2*np.pi*x_1000))\nplt.legend()\nplt.show\nalphas = np.array([np.exp(-30), np.exp(-29), np.exp(-28), np.exp(-27), np.exp(-26), np.exp(-25), np.exp(-24), np.exp(-23), np.exp(-22), np.exp(-21), np.exp(-20), np.exp(-19), np.exp(-18), np.exp(-17), np.exp(-16), np.exp(-15), np.exp(-14), np.exp(-13), np.exp(-12), np.exp(-11), np.exp(-10), np.exp(-9), np.exp(-8), np.exp(-7), np.exp(-6), np.exp(-5), np.exp(-4), np.exp(-3), np.exp(-2), np.exp(-1), np.exp(-1), np.exp(0), np.exp(1)])\n\ntest_errors = []\ntrain_errors = []\n\nfor a in np.nditer(alphas):\n    ridge = make_pipeline(PolynomialFeatures(degree = 9),\n              Ridge(alpha=a))\n    ridge.fit(x_train, y_train)\n    mse_train = mean_squared_error(y_train, ridge.predict(x_train))\n    mse_test = mean_squared_error(y_test, ridge.predict(x_test))\n    train_errors.append(np.sqrt(mse_train))\n    test_errors.append(np.sqrt(mse_test))\nplt.figure(3)\nplt.plot(alphas, test_errors, 'g^', label = 'Test Error')\nplt.plot(alphas, train_errors, 'bs', label = 'Train Error')\nplt.xscale('log')\nplt.xlabel('Regression coefficient Lambda')\nplt.ylabel('Residuals')\nplt.legend()\nplt.show()\n</code></pre>\n\n<p>The output (only for the third figure) is shown below: <a href=\"https://i.stack.imgur.com/dBKRb.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/dBKRb.png\" alt=\"Reproduction of Figure from Bishop\"></a></p>\n<p>I have taken a look on your code. You obtain same errors results for each alpha value because your regularization strength is too small. Replacing : </p>\n\n<pre><code>alphas = np.logspace(-40, -18, n_alphas)\n</code></pre>\n\n<p>with : </p>\n\n<pre><code>alphas = np.logspace(-40, -1, n_alphas)\n</code></pre>\n\n<p>will yields different errors values for alpha values large enough. Are you sure about figure alpha values? Do you have a link to this hands-on?</p>\n\n<p>Also, I would like to highlight the fact that you have to standardize your features before using regularization. Reason is, by creating polynomial features, polynomial features will have different magnitudes. Therefore when fitting model, coefficients to be estimated won't have the same magnitudes neither and so regularization will highly penalize coefficients with large values. Standardization / Normalization is a strong prerequisite to regularization.</p>\n",
                "codes": [
                    [
                        "import numpy as np\nimport matplotlib.pyplot as plt \nfrom sklearn import linear_model\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import PolynomialFeatures \nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import mean_squared_error\nnp.random.seed(12344)\nx_1000 = np.linspace(0, 1, 1000)\nx_train = np.linspace(0, 1, 10)\nnoise_10 = np.random.normal(0, 0.3, 10)\ny_train = np.sin(2*np.pi*x_train) + noise_10\nx_train = x_train[:, np.newaxis]\nx_test = np.linspace(0, 1, 100)\nnoise_100 = np.random.normal(0, 0.3, 100)\ny_test = np.sin(2*np.pi*x_test) + noise_100\nx_test = x_test[:, np.newaxis]\nlow_alpha = make_pipeline(PolynomialFeatures(degree = 9), Ridge(alpha=np.exp(-18)))\nlow_alpha.fit(x_test, y_test)\nplt.figure(1)\nplt.plot(x_train, low_alpha.predict(x_train), label = 'alpha = ln(-18)')\nplt.plot(x_1000, np.sin(2*np.pi*x_1000))\nplt.legend()\nplt.show\nhigh_alpha = make_pipeline(PolynomialFeatures(degree = 9),\n              Ridge(alpha=np.exp(0)))\nhigh_alpha.fit(x_test, y_test)\nplt.figure(2)\nplt.plot(x_train, high_alpha.predict(x_train), label = 'alpha = 1')\nplt.plot(x_1000, np.sin(2*np.pi*x_1000))\nplt.legend()\nplt.show\nalphas = np.array([np.exp(-30), np.exp(-29), np.exp(-28), np.exp(-27), np.exp(-26), np.exp(-25), np.exp(-24), np.exp(-23), np.exp(-22), np.exp(-21), np.exp(-20), np.exp(-19), np.exp(-18), np.exp(-17), np.exp(-16), np.exp(-15), np.exp(-14), np.exp(-13), np.exp(-12), np.exp(-11), np.exp(-10), np.exp(-9), np.exp(-8), np.exp(-7), np.exp(-6), np.exp(-5), np.exp(-4), np.exp(-3), np.exp(-2), np.exp(-1), np.exp(-1), np.exp(0), np.exp(1)])\n\ntest_errors = []\ntrain_errors = []\n\nfor a in np.nditer(alphas):\n    ridge = make_pipeline(PolynomialFeatures(degree = 9),\n              Ridge(alpha=a))\n    ridge.fit(x_train, y_train)\n    mse_train = mean_squared_error(y_train, ridge.predict(x_train))\n    mse_test = mean_squared_error(y_test, ridge.predict(x_test))\n    train_errors.append(np.sqrt(mse_train))\n    test_errors.append(np.sqrt(mse_test))\nplt.figure(3)\nplt.plot(alphas, test_errors, 'g^', label = 'Test Error')\nplt.plot(alphas, train_errors, 'bs', label = 'Train Error')\nplt.xscale('log')\nplt.xlabel('Regression coefficient Lambda')\nplt.ylabel('Residuals')\nplt.legend()\nplt.show()\n"
                    ],
                    [
                        "alphas = np.logspace(-40, -18, n_alphas)\n",
                        "alphas = np.logspace(-40, -1, n_alphas)\n"
                    ]
                ],
                "question_id:": "27918",
                "question_votes:": "2",
                "question_text:": "<p>I am trying to reproduce this figure from Bishop:</p>\n\n<p><a href=\"https://i.stack.imgur.com/xkJUH.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/xkJUH.png\" alt=\"enter image description here\"></a></p>\n\n<p>Residual vs. Alpha (lambda in figure)</p>\n\n<p>The code is pasted below:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import mean_squared_error\n\nx_train = np.linspace(0, 1, 10)\nnoise_10 = np.random.normal(0, 0.3, 10)\ny_train = np.sin(2*np.pi*x_train) + noise_10\nx_train = x_train[:, np.newaxis]\n\nx_test = np.linspace(0, 1, 100)\nnoise_100 = np.random.normal(0, 0.3, 100)\ny_test = np.sin(2*np.pi*x_test) + noise_100\nx_test = x_test[:, np.newaxis]\n\n\nn_alphas = 200\nalphas = np.logspace(-40, -18, n_alphas)\n\nerrors = []\nfor a in alphas:\n    ridge = make_pipeline(PolynomialFeatures(degree = 9), \n              Ridge(alpha=a))\n    ridge.fit(x_train, y_train)\n    mse = mean_squared_error(y_test, ridge.predict(x_test))\n    errors.append(np.sqrt(mse))    \n\nprint(errors)\n</code></pre>\n\n<p>However, the errors array has the same value for all values of alpha. It's taking the first value of <code>alpha = np.exp(-40)</code> and all the other values seem to be the same for all future iterations of the for loop. How can I correct this error?</p>\n",
                "tags": "<scikit-learn><regression>",
                "answers": [
                    [
                        "28012",
                        "2",
                        "27918",
                        "",
                        "",
                        "<p>I still haven't figured out what the previously posted code is doing wrong. However, manually populating the alphas array gives me results that are close to the original figure.</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt \nfrom sklearn import linear_model\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import PolynomialFeatures \nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import mean_squared_error\nnp.random.seed(12344)\nx_1000 = np.linspace(0, 1, 1000)\nx_train = np.linspace(0, 1, 10)\nnoise_10 = np.random.normal(0, 0.3, 10)\ny_train = np.sin(2*np.pi*x_train) + noise_10\nx_train = x_train[:, np.newaxis]\nx_test = np.linspace(0, 1, 100)\nnoise_100 = np.random.normal(0, 0.3, 100)\ny_test = np.sin(2*np.pi*x_test) + noise_100\nx_test = x_test[:, np.newaxis]\nlow_alpha = make_pipeline(PolynomialFeatures(degree = 9), Ridge(alpha=np.exp(-18)))\nlow_alpha.fit(x_test, y_test)\nplt.figure(1)\nplt.plot(x_train, low_alpha.predict(x_train), label = 'alpha = ln(-18)')\nplt.plot(x_1000, np.sin(2*np.pi*x_1000))\nplt.legend()\nplt.show\nhigh_alpha = make_pipeline(PolynomialFeatures(degree = 9),\n              Ridge(alpha=np.exp(0)))\nhigh_alpha.fit(x_test, y_test)\nplt.figure(2)\nplt.plot(x_train, high_alpha.predict(x_train), label = 'alpha = 1')\nplt.plot(x_1000, np.sin(2*np.pi*x_1000))\nplt.legend()\nplt.show\nalphas = np.array([np.exp(-30), np.exp(-29), np.exp(-28), np.exp(-27), np.exp(-26), np.exp(-25), np.exp(-24), np.exp(-23), np.exp(-22), np.exp(-21), np.exp(-20), np.exp(-19), np.exp(-18), np.exp(-17), np.exp(-16), np.exp(-15), np.exp(-14), np.exp(-13), np.exp(-12), np.exp(-11), np.exp(-10), np.exp(-9), np.exp(-8), np.exp(-7), np.exp(-6), np.exp(-5), np.exp(-4), np.exp(-3), np.exp(-2), np.exp(-1), np.exp(-1), np.exp(0), np.exp(1)])\n\ntest_errors = []\ntrain_errors = []\n\nfor a in np.nditer(alphas):\n    ridge = make_pipeline(PolynomialFeatures(degree = 9),\n              Ridge(alpha=a))\n    ridge.fit(x_train, y_train)\n    mse_train = mean_squared_error(y_train, ridge.predict(x_train))\n    mse_test = mean_squared_error(y_test, ridge.predict(x_test))\n    train_errors.append(np.sqrt(mse_train))\n    test_errors.append(np.sqrt(mse_test))\nplt.figure(3)\nplt.plot(alphas, test_errors, 'g^', label = 'Test Error')\nplt.plot(alphas, train_errors, 'bs', label = 'Train Error')\nplt.xscale('log')\nplt.xlabel('Regression coefficient Lambda')\nplt.ylabel('Residuals')\nplt.legend()\nplt.show()\n</code></pre>\n\n<p>The output (only for the third figure) is shown below: <a href=\"https://i.stack.imgur.com/dBKRb.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/dBKRb.png\" alt=\"Reproduction of Figure from Bishop\"></a></p>\n",
                        "",
                        "1"
                    ],
                    [
                        "27951",
                        "2",
                        "27918",
                        "",
                        "",
                        "<p>I have taken a look on your code. You obtain same errors results for each alpha value because your regularization strength is too small. Replacing : </p>\n\n<pre><code>alphas = np.logspace(-40, -18, n_alphas)\n</code></pre>\n\n<p>with : </p>\n\n<pre><code>alphas = np.logspace(-40, -1, n_alphas)\n</code></pre>\n\n<p>will yields different errors values for alpha values large enough. Are you sure about figure alpha values? Do you have a link to this hands-on?</p>\n\n<p>Also, I would like to highlight the fact that you have to standardize your features before using regularization. Reason is, by creating polynomial features, polynomial features will have different magnitudes. Therefore when fitting model, coefficients to be estimated won't have the same magnitudes neither and so regularization will highly penalize coefficients with large values. Standardization / Normalization is a strong prerequisite to regularization.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5431",
            "_score": 13.586796,
            "_source": {
                "title": "How to perform Logistic Regression with a large number of features?",
                "content": "How to perform Logistic Regression with a large number of features? <p>I have a dataset with 330 samples and 27 features for each sample, with a binary class problem for Logistic Regression.</p>\n\n<p>According to the \"rule if ten\" I need at least 10 events for each feature to be included. Though, I have an imbalanced dataset, with 20% o positive class and 80% of negative class.</p>\n\n<p>That gives me only 70 events, allowing approximately only 7/8 features to be included in the Logistic model.</p>\n\n<p>I'd like to evaluate all the features as predictors, I don't want to hand pick any features.</p>\n\n<p>So what would you suggest? Should I make all possible 7 features combinations? Should I evaluate each feature alone with an association model and then pick only the best ones for a final model?</p>\n\n<p>I'm also curious about the handling of categorical and continuous features, can I mix them? If I have a categorical [0-1] and a continuous [0-100], should I normalize?</p>\n\n<p>I'm currently working with Python.</p>\n\n<p>Thanks a lot for your help!</p>\n <machine-learning><python><predictive-modeling><logistic-regression><data><p>You're taking the \"Rule of 10\" too seriously.  It's a very rough rule of thumb.  It's not intended to be used like you are using it.</p>\n\n<p>It sounds like you are thinking: \"I have only 70 positive instances, so by the Rule of 10, I'm only allowed to use 7 features; how do I choose which 7 features to use?\"</p>\n\n<p>That's not what the Rule of 10 means.  It's not some rule that specifies how many features you are permitted to use.  The Rule of 10 is descriptive, not prescriptive, and it's an approximate guideline: if the number of instances is much fewer than 10 times the number of features, you're at especially high risk of overfitting, and you might get poor results.</p>\n\n<p>So what should you do?  You should do what you'd do anyway: use regularization, and use cross-validation to select the regularization hyper-parameters.  Also, it's important to have a hold-out test set that you don't touch until you've finalized everything about the classifier, to avoid overfitting and biased accuracy estimates.</p>\n\n<p>And if you can get more data, that would really help.</p>\n\n<p>Finally, since you have imbalanced classes, you might consider reading about class imbalance and methods for dealing with it.</p>\n<p>In order to reduce your model down to 7 variables there are a few approaches you could take:</p>\n\n<ol>\n<li><a href=\"https://en.wikipedia.org/wiki/Principal_component_analysis\" rel=\"noreferrer\">PCA</a> (unsupervised): this creates \"new\" linear combinations of your data where each proceding component explains as much variance in the data as possible. So the first 7 components (out of 27) should be able to explain a good percentage of the variation in your data. You can then plug these seven components into your logistic regression equation. The disadvantage here is that because the components are combinations of your original variables you lose some interpretability with your regression model. It should however produce very good accuracy. This same technique applied to other dimension reduction methods such as </li>\n<li>Another common method in regression is forward stepwise where you start with one variable and add on another each step, which is either kept or dropped based on some criteria (usually a BIC or AIC score). Backwards stepwise regression is the same thing but you start with all variables and remove one each time again based on some criteria. Based on a brief search it doesn't seem that python has a stepwise regression but they do a similar feature elimination algorithm described in this <a href=\"https://datascience.stackexchange.com/questions/937/does-scikit-learn-have-forward-selection-stepwise-regression-algorithm\">Data Science post</a>.</li>\n<li>Lasso Regression uses an $L_{1}$ penalization norm that shrinks the coefficients of features effectively eliminating some of them.You can include this $L_1$ norm into your logistic regression model. It seems <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\" rel=\"noreferrer\">sklearn's LogisticRegression</a> allows you do assign the penalization you want in order to achieve this. Note: Lasso will not explicitly set variable coefficients to zero, but will shrink them allowing you to select the 7 largest coefficients.</li>\n</ol>\n\n<p>As @E_net4 commented, your continuous question is addressed in another post.</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "21780",
                "question_votes:": "9",
                "question_text:": "<p>I have a dataset with 330 samples and 27 features for each sample, with a binary class problem for Logistic Regression.</p>\n\n<p>According to the \"rule if ten\" I need at least 10 events for each feature to be included. Though, I have an imbalanced dataset, with 20% o positive class and 80% of negative class.</p>\n\n<p>That gives me only 70 events, allowing approximately only 7/8 features to be included in the Logistic model.</p>\n\n<p>I'd like to evaluate all the features as predictors, I don't want to hand pick any features.</p>\n\n<p>So what would you suggest? Should I make all possible 7 features combinations? Should I evaluate each feature alone with an association model and then pick only the best ones for a final model?</p>\n\n<p>I'm also curious about the handling of categorical and continuous features, can I mix them? If I have a categorical [0-1] and a continuous [0-100], should I normalize?</p>\n\n<p>I'm currently working with Python.</p>\n\n<p>Thanks a lot for your help!</p>\n",
                "tags": "<machine-learning><python><predictive-modeling><logistic-regression><data>",
                "answers": [
                    [
                        "21804",
                        "2",
                        "21780",
                        "",
                        "",
                        "<p>You're taking the \"Rule of 10\" too seriously.  It's a very rough rule of thumb.  It's not intended to be used like you are using it.</p>\n\n<p>It sounds like you are thinking: \"I have only 70 positive instances, so by the Rule of 10, I'm only allowed to use 7 features; how do I choose which 7 features to use?\"</p>\n\n<p>That's not what the Rule of 10 means.  It's not some rule that specifies how many features you are permitted to use.  The Rule of 10 is descriptive, not prescriptive, and it's an approximate guideline: if the number of instances is much fewer than 10 times the number of features, you're at especially high risk of overfitting, and you might get poor results.</p>\n\n<p>So what should you do?  You should do what you'd do anyway: use regularization, and use cross-validation to select the regularization hyper-parameters.  Also, it's important to have a hold-out test set that you don't touch until you've finalized everything about the classifier, to avoid overfitting and biased accuracy estimates.</p>\n\n<p>And if you can get more data, that would really help.</p>\n\n<p>Finally, since you have imbalanced classes, you might consider reading about class imbalance and methods for dealing with it.</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "21784",
                        "2",
                        "21780",
                        "",
                        "",
                        "<p>In order to reduce your model down to 7 variables there are a few approaches you could take:</p>\n\n<ol>\n<li><a href=\"https://en.wikipedia.org/wiki/Principal_component_analysis\" rel=\"noreferrer\">PCA</a> (unsupervised): this creates \"new\" linear combinations of your data where each proceding component explains as much variance in the data as possible. So the first 7 components (out of 27) should be able to explain a good percentage of the variation in your data. You can then plug these seven components into your logistic regression equation. The disadvantage here is that because the components are combinations of your original variables you lose some interpretability with your regression model. It should however produce very good accuracy. This same technique applied to other dimension reduction methods such as </li>\n<li>Another common method in regression is forward stepwise where you start with one variable and add on another each step, which is either kept or dropped based on some criteria (usually a BIC or AIC score). Backwards stepwise regression is the same thing but you start with all variables and remove one each time again based on some criteria. Based on a brief search it doesn't seem that python has a stepwise regression but they do a similar feature elimination algorithm described in this <a href=\"https://datascience.stackexchange.com/questions/937/does-scikit-learn-have-forward-selection-stepwise-regression-algorithm\">Data Science post</a>.</li>\n<li>Lasso Regression uses an $L_{1}$ penalization norm that shrinks the coefficients of features effectively eliminating some of them.You can include this $L_1$ norm into your logistic regression model. It seems <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\" rel=\"noreferrer\">sklearn's LogisticRegression</a> allows you do assign the penalization you want in order to achieve this. Note: Lasso will not explicitly set variable coefficients to zero, but will shrink them allowing you to select the 7 largest coefficients.</li>\n</ol>\n\n<p>As @E_net4 commented, your continuous question is addressed in another post.</p>\n",
                        "",
                        "5"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7739",
            "_score": 13.504433,
            "_source": {
                "title": "SKLearn KernelRidge memory demand",
                "content": "SKLearn KernelRidge memory demand <p>I am fitting a model with 100,000 samples x 10 features (6 ints and 4 floats), using SKLearn KernelRidge:</p>\n\n<pre><code>model = KernelRidge(kernel='linear')\n</code></pre>\n\n<p>Looking at the task manager, 'Python' process takes ~40GB.</p>\n\n<p>Can you please explain why is there such a high demand?\nWhat kind of matrix is built in the background?</p>\n <python><scikit-learn><regression><svm><p>This is rather common.  The algorithm for KernelRidge requires a SVD to be performed.  Sadly, the SVD cannot handle a sparse matrix so the _pre_compute_svd function in sklearn just converts the matrix into a dense matrix and moves on.  This tends to blow up memory rather quickly.</p>\n\n<p>You have a couple of choices.  Rewrite the method to handle sparse matrices or just use a different method.  SVR would be the most similiar alternative.  </p>\n",
                "codes": [
                    []
                ],
                "question_id:": "28754",
                "question_votes:": "1",
                "question_text:": "<p>I am fitting a model with 100,000 samples x 10 features (6 ints and 4 floats), using SKLearn KernelRidge:</p>\n\n<pre><code>model = KernelRidge(kernel='linear')\n</code></pre>\n\n<p>Looking at the task manager, 'Python' process takes ~40GB.</p>\n\n<p>Can you please explain why is there such a high demand?\nWhat kind of matrix is built in the background?</p>\n",
                "tags": "<python><scikit-learn><regression><svm>",
                "answers": [
                    [
                        "28760",
                        "2",
                        "28754",
                        "",
                        "",
                        "<p>This is rather common.  The algorithm for KernelRidge requires a SVD to be performed.  Sadly, the SVD cannot handle a sparse matrix so the _pre_compute_svd function in sklearn just converts the matrix into a dense matrix and moves on.  This tends to blow up memory rather quickly.</p>\n\n<p>You have a couple of choices.  Rewrite the method to handle sparse matrices or just use a different method.  SVR would be the most similiar alternative.  </p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17227",
            "_score": 13.48361,
            "_source": {
                "title": "Sklearn train_test_split() error: Found input variables with inconsistent numbers of samples",
                "content": "Sklearn train_test_split() error: Found input variables with inconsistent numbers of samples <p>I am fitting a regression model on randomly generated X1,x2 and Y be the sum of x1, x2 but I am getting this error</p>\n\n<blockquote>\n  <p>ValueError: Found input variables with inconsistent numbers of samples: [2, 10000000]</p>\n</blockquote>\n\n<p><strong>Note:- I am doing this only for learning purposes</strong></p>\n\n<p>My code:-</p>\n\n<pre><code>X = np.random.random_integers(100000000,size=(2,10000000))\nX=(X-(100000000/2))/(100000000/2) # Scaling [-1,1]\nY = X[0]+X[1]\n\nregr = linear_model.LinearRegression()\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, \nrandom_state=0)\nregr.fit(X_train,Y_train)\n</code></pre>\n <machine-learning><python><scikit-learn><numpy><p>You need the shape of your training data to be <code>(num_samples, num_features)</code> or in your case <code>(10000000, 2)</code>. An easy way to fix this is to transpose <code>X</code> before feeding it to the train test split:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>X_train, X_test, y_train, y_test = train_test_split(X.T, Y, test_size=0.2, random_state=0)\nregr.fit(X_train, y_train)  # &lt;-- also 'y_train' not 'Y_train' here\n</code></pre>\n",
                "codes": [
                    [
                        "X_train, X_test, y_train, y_test = train_test_split(X.T, Y, test_size=0.2, random_state=0)\nregr.fit(X_train, y_train)  # <-- also 'y_train' not 'Y_train' here\n"
                    ]
                ],
                "question_id:": "55793",
                "question_votes:": "1",
                "question_text:": "<p>I am fitting a regression model on randomly generated X1,x2 and Y be the sum of x1, x2 but I am getting this error</p>\n\n<blockquote>\n  <p>ValueError: Found input variables with inconsistent numbers of samples: [2, 10000000]</p>\n</blockquote>\n\n<p><strong>Note:- I am doing this only for learning purposes</strong></p>\n\n<p>My code:-</p>\n\n<pre><code>X = np.random.random_integers(100000000,size=(2,10000000))\nX=(X-(100000000/2))/(100000000/2) # Scaling [-1,1]\nY = X[0]+X[1]\n\nregr = linear_model.LinearRegression()\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, \nrandom_state=0)\nregr.fit(X_train,Y_train)\n</code></pre>\n",
                "tags": "<machine-learning><python><scikit-learn><numpy>",
                "answers": [
                    [
                        "55794",
                        "2",
                        "55793",
                        "",
                        "",
                        "<p>You need the shape of your training data to be <code>(num_samples, num_features)</code> or in your case <code>(10000000, 2)</code>. An easy way to fix this is to transpose <code>X</code> before feeding it to the train test split:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>X_train, X_test, y_train, y_test = train_test_split(X.T, Y, test_size=0.2, random_state=0)\nregr.fit(X_train, y_train)  # &lt;-- also 'y_train' not 'Y_train' here\n</code></pre>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3281",
            "_score": 13.441304,
            "_source": {
                "title": "Binary classification: best ways to pre-procees the data",
                "content": "Binary classification: best ways to pre-procees the data <p>About the dataset\nI have a training dataset of</p>\n\n<ul>\n<li>129 columns(last column being the classes, i.e., y values)</li>\n<li>6068 rows</li>\n</ul>\n\n<p>I have to train some algo to do binary classification. The data set has </p>\n\n<ul>\n<li>701 examples of type A</li>\n<li>5367 examples of type B</li>\n</ul>\n\n<p>The test set consists of 1398 examples. Here is the accuracy I got for various algorithms.</p>\n\n<ul>\n<li>voting ensemble -> 0.73963</li>\n<li>stochastic gradient boosting -> 0.77682</li>\n<li>Adaboost -> 0.75107</li>\n<li>bagging classifier(Decision tree) -> 0.76538</li>\n<li>Random Forests -> 0.75250</li>\n<li>Extra trees -> 0.75393</li>\n</ul>\n\n<p>All the above results are from kaggle so they probably are just from half the test set. \nThe above methods were implemented using scikit-learn library in python</p>\n\n<p>Could someone please suggest ways to improve accuracy, may be by things like dimensionality reduction or better algorithms. Also, please provide sample code in possible.</p>\n <machine-learning><python><classification><preprocessing><p>There are two steps to this problem: feature selection/ dimensionality reduction and selecting the predictive model.  Selecting the 'best' features to use in the model will often improve the accuracy, and there are quite a few methods you can use.</p>\n\n<ul>\n<li>When you are working with continuous data, you can use a regularization method such as <strong>Lasso</strong> or <strong>ElasticNet</strong> to select the best features for the model. These are both available in sklearn, but they do require some parameter tuning to find the right hyperparameters to get the best results.  </li>\n<li>You can also take a look at <strong>sklearn.feature_selection</strong>.  These are more statistical approaches to select features, generaly based on their p-values.  This also only works with continuous data.</li>\n<li>Another approach is calculating the Gini importance from decision tree models, such as RandomForest.  This is useful when you have continuous and categorical data.  Here is an example: <a href=\"http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\" rel=\"nofollow\">http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html</a></li>\n</ul>\n\n<p>After you have selected the best features, you want to choose the right model for binary classification.  The go-to model in this case is logistic regression.  There are multiple hyperparameters in sklearn.linear_model.LogisticRegression and in order to get the best results, you may have to perform some grid searches to find the right parameters.</p>\n\n<p>Here are some additional resources that may prove helpful:</p>\n\n<ul>\n<li><a href=\"http://blog.nycdatascience.com/student-works/bnp-claims/\" rel=\"nofollow\">http://blog.nycdatascience.com/student-works/bnp-claims/</a></li>\n<li><a href=\"http://blog.kaggle.com/2016/07/21/approaching-almost-any-machine-learning-problem-abhishek-thakur/\" rel=\"nofollow\">http://blog.kaggle.com/2016/07/21/approaching-almost-any-machine-learning-problem-abhishek-thakur/</a></li>\n<li><a href=\"http://insidebigdata.com/2014/10/22/ask-data-scientist-bias-vs-variance-tradeoff/\" rel=\"nofollow\">http://insidebigdata.com/2014/10/22/ask-data-scientist-bias-vs-variance-tradeoff/</a></li>\n</ul>\n\n<p>I added the last link, discussing bias vs. variance tradeoff, because I think it is important to understand when testing your models.</p>\n<p>A better clarity about the kind of problem that you are trying to solve will be really useful. </p>\n\n<ul>\n<li><p>I any case the first thing I will suggest, is please go through your features and try to understand the relationship with the response. All tree based methods are highly prone to overfitting and hence they don't generalise well.\nIf you come to the conclusion that some variables show a linear relationship and some show a non-linear then you might be better off using Linear methods such as LogisticRegression or LinearDiscriminantClassifier(if your features show an indication that they are sampled from a normal distribution). Obviously you can use PCA or regularization methods if you are certain that some features are highly correlated and offer no prediction value. </p></li>\n<li><p>Secondly, if you have done all the above then you are probably done with the feature selection step. The next approach is feature creation. See if certain variables are non-linear in nature. Then try adding higher degree polynomial terms. Try diagnosing interaction effects between features, try to include features for those interactions. If there are any features you think are redundant to the problem. Think again. See if you can extract any information out of them.</p></li>\n</ul>\n\n<p>Kindly tag the link of the problem here.</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "14084",
                "question_votes:": "2",
                "question_text:": "<p>About the dataset\nI have a training dataset of</p>\n\n<ul>\n<li>129 columns(last column being the classes, i.e., y values)</li>\n<li>6068 rows</li>\n</ul>\n\n<p>I have to train some algo to do binary classification. The data set has </p>\n\n<ul>\n<li>701 examples of type A</li>\n<li>5367 examples of type B</li>\n</ul>\n\n<p>The test set consists of 1398 examples. Here is the accuracy I got for various algorithms.</p>\n\n<ul>\n<li>voting ensemble -> 0.73963</li>\n<li>stochastic gradient boosting -> 0.77682</li>\n<li>Adaboost -> 0.75107</li>\n<li>bagging classifier(Decision tree) -> 0.76538</li>\n<li>Random Forests -> 0.75250</li>\n<li>Extra trees -> 0.75393</li>\n</ul>\n\n<p>All the above results are from kaggle so they probably are just from half the test set. \nThe above methods were implemented using scikit-learn library in python</p>\n\n<p>Could someone please suggest ways to improve accuracy, may be by things like dimensionality reduction or better algorithms. Also, please provide sample code in possible.</p>\n",
                "tags": "<machine-learning><python><classification><preprocessing>",
                "answers": [
                    [
                        "14091",
                        "2",
                        "14084",
                        "",
                        "",
                        "<p>There are two steps to this problem: feature selection/ dimensionality reduction and selecting the predictive model.  Selecting the 'best' features to use in the model will often improve the accuracy, and there are quite a few methods you can use.</p>\n\n<ul>\n<li>When you are working with continuous data, you can use a regularization method such as <strong>Lasso</strong> or <strong>ElasticNet</strong> to select the best features for the model. These are both available in sklearn, but they do require some parameter tuning to find the right hyperparameters to get the best results.  </li>\n<li>You can also take a look at <strong>sklearn.feature_selection</strong>.  These are more statistical approaches to select features, generaly based on their p-values.  This also only works with continuous data.</li>\n<li>Another approach is calculating the Gini importance from decision tree models, such as RandomForest.  This is useful when you have continuous and categorical data.  Here is an example: <a href=\"http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\" rel=\"nofollow\">http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html</a></li>\n</ul>\n\n<p>After you have selected the best features, you want to choose the right model for binary classification.  The go-to model in this case is logistic regression.  There are multiple hyperparameters in sklearn.linear_model.LogisticRegression and in order to get the best results, you may have to perform some grid searches to find the right parameters.</p>\n\n<p>Here are some additional resources that may prove helpful:</p>\n\n<ul>\n<li><a href=\"http://blog.nycdatascience.com/student-works/bnp-claims/\" rel=\"nofollow\">http://blog.nycdatascience.com/student-works/bnp-claims/</a></li>\n<li><a href=\"http://blog.kaggle.com/2016/07/21/approaching-almost-any-machine-learning-problem-abhishek-thakur/\" rel=\"nofollow\">http://blog.kaggle.com/2016/07/21/approaching-almost-any-machine-learning-problem-abhishek-thakur/</a></li>\n<li><a href=\"http://insidebigdata.com/2014/10/22/ask-data-scientist-bias-vs-variance-tradeoff/\" rel=\"nofollow\">http://insidebigdata.com/2014/10/22/ask-data-scientist-bias-vs-variance-tradeoff/</a></li>\n</ul>\n\n<p>I added the last link, discussing bias vs. variance tradeoff, because I think it is important to understand when testing your models.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "14087",
                        "2",
                        "14084",
                        "",
                        "",
                        "<p>A better clarity about the kind of problem that you are trying to solve will be really useful. </p>\n\n<ul>\n<li><p>I any case the first thing I will suggest, is please go through your features and try to understand the relationship with the response. All tree based methods are highly prone to overfitting and hence they don't generalise well.\nIf you come to the conclusion that some variables show a linear relationship and some show a non-linear then you might be better off using Linear methods such as LogisticRegression or LinearDiscriminantClassifier(if your features show an indication that they are sampled from a normal distribution). Obviously you can use PCA or regularization methods if you are certain that some features are highly correlated and offer no prediction value. </p></li>\n<li><p>Secondly, if you have done all the above then you are probably done with the feature selection step. The next approach is feature creation. See if certain variables are non-linear in nature. Then try adding higher degree polynomial terms. Try diagnosing interaction effects between features, try to include features for those interactions. If there are any features you think are redundant to the problem. Think again. See if you can extract any information out of them.</p></li>\n</ul>\n\n<p>Kindly tag the link of the problem here.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13939",
            "_score": 13.438575,
            "_source": {
                "title": "Do I need to encode the target variable for sklearn logistic regression",
                "content": "Do I need to encode the target variable for sklearn logistic regression <p>I'm trying to get familiar with the sklearn library, and now I'm trying to implement logistic regression for a dataframe containing numerical and categorical values to predict a binary target variable.<br>\nWhile reading some documentation I found the logistic regression should be used to predict binary variables presented by 0 and 1.<br>\nMy target variable is \"YES\" and \"NO\", should I code it to 0 and 1 for the algorithm to work properly, or there is no difference?<br> \nMaybe I just didn't get the idea but can someone confirm this to me.</p>\n <scikit-learn><logistic-regression><p>The string labels work just fine, here is an example:</p>\n\n<pre><code>from sklearn.datasets import load_iris\nfrom sklearn.linear_model import LogisticRegression\nimport numpy\nX, y = load_iris(return_X_y=True)\ny_string = numpy.array(['YES' if label == 1 else 'NO' for label in y])\nclf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X, y_string)\ny_pred = clf.predict(X[50:100, :])\nprint(y_pred)\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>['NO' 'NO' 'NO' 'YES' 'NO' 'YES' 'NO' 'YES' 'NO' 'NO' 'YES' 'NO' 'YES'\n 'NO' 'NO' 'NO' 'NO' 'YES' 'YES' 'YES' 'NO' 'NO' 'YES' 'YES' 'NO' 'NO'\n 'YES' 'NO' 'NO' 'YES' 'YES' 'YES' 'YES' 'YES' 'NO' 'NO' 'NO' 'YES' 'NO'\n 'YES' 'YES' 'NO' 'YES' 'YES' 'YES' 'NO' 'NO' 'NO' 'YES' 'NO']\n</code></pre>\n\n<p>Yo can replace <code>y_string</code> to <code>y</code> for the numerical example.</p>\n",
                "codes": [
                    [
                        "from sklearn.datasets import load_iris\nfrom sklearn.linear_model import LogisticRegression\nimport numpy\nX, y = load_iris(return_X_y=True)\ny_string = numpy.array(['YES' if label == 1 else 'NO' for label in y])\nclf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X, y_string)\ny_pred = clf.predict(X[50:100, :])\nprint(y_pred)\n",
                        "['NO' 'NO' 'NO' 'YES' 'NO' 'YES' 'NO' 'YES' 'NO' 'NO' 'YES' 'NO' 'YES'\n 'NO' 'NO' 'NO' 'NO' 'YES' 'YES' 'YES' 'NO' 'NO' 'YES' 'YES' 'NO' 'NO'\n 'YES' 'NO' 'NO' 'YES' 'YES' 'YES' 'YES' 'YES' 'NO' 'NO' 'NO' 'YES' 'NO'\n 'YES' 'YES' 'NO' 'YES' 'YES' 'YES' 'NO' 'NO' 'NO' 'YES' 'NO']\n"
                    ]
                ],
                "question_id:": "47248",
                "question_votes:": "1",
                "question_text:": "<p>I'm trying to get familiar with the sklearn library, and now I'm trying to implement logistic regression for a dataframe containing numerical and categorical values to predict a binary target variable.<br>\nWhile reading some documentation I found the logistic regression should be used to predict binary variables presented by 0 and 1.<br>\nMy target variable is \"YES\" and \"NO\", should I code it to 0 and 1 for the algorithm to work properly, or there is no difference?<br> \nMaybe I just didn't get the idea but can someone confirm this to me.</p>\n",
                "tags": "<scikit-learn><logistic-regression>",
                "answers": [
                    [
                        "47250",
                        "2",
                        "47248",
                        "",
                        "",
                        "<p>The string labels work just fine, here is an example:</p>\n\n<pre><code>from sklearn.datasets import load_iris\nfrom sklearn.linear_model import LogisticRegression\nimport numpy\nX, y = load_iris(return_X_y=True)\ny_string = numpy.array(['YES' if label == 1 else 'NO' for label in y])\nclf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X, y_string)\ny_pred = clf.predict(X[50:100, :])\nprint(y_pred)\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>['NO' 'NO' 'NO' 'YES' 'NO' 'YES' 'NO' 'YES' 'NO' 'NO' 'YES' 'NO' 'YES'\n 'NO' 'NO' 'NO' 'NO' 'YES' 'YES' 'YES' 'NO' 'NO' 'YES' 'YES' 'NO' 'NO'\n 'YES' 'NO' 'NO' 'YES' 'YES' 'YES' 'YES' 'YES' 'NO' 'NO' 'NO' 'YES' 'NO'\n 'YES' 'YES' 'NO' 'YES' 'YES' 'YES' 'NO' 'NO' 'NO' 'YES' 'NO']\n</code></pre>\n\n<p>Yo can replace <code>y_string</code> to <code>y</code> for the numerical example.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15124",
            "_score": 13.397734,
            "_source": {
                "title": "Split the data between the Training Data and Test Data using sklearn",
                "content": "Split the data between the Training Data and Test Data using sklearn <p><strong>Work to do</strong></p>\n\n<p>My job is to take the data and divide it between Training and Test using 30% of the data as Test where both should have the same ratio between positive and negative.</p>\n\n<p><strong>CSV File</strong></p>\n\n<pre><code>age,Feature 2,Feature 3,Feature 4,income,Feature 6,Feature 7,Feature 8,Feature 9,Feature 10,Feature 11,Feature 12,Feature 13,Feature 14,Feature 15,Class\n77,1,0,0,3,0,1,1,1,0,1,1,1,0,1,0\n35,1,0,1,4,0,0,0,1,1,0,1,1,0,1,0\n79,1,0,0,2,0,1,1,0,0,0,1,1,1,0,1\n61,0,1,0,1,0,1,1,1,0,0,0,0,1,0,0\n62,0,0,0,2,0,1,0,0,0,1,1,0,0,0,1\n63,0,1,1,0,1,1,0,0,1,0,0,1,0,0,1\n29,1,1,0,1,1,0,1,1,0,0,1,1,1,1,0\n39,0,1,1,5,1,1,1,0,1,0,1,1,1,1,0\n51,0,1,1,6,1,1,0,1,0,0,1,1,0,1,1\n\n</code></pre>\n\n<p><strong>Code - Training Data and Test Data</strong></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>#!/usr/bin/env python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plot\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import Imputer\n\n\n# Reading CVS file\ndataSet = pd.read_csv('./TestDataFile_ML.csv')\nX = dataSet.iloc[:,:-1].values\ny = dataSet.iloc[:,15].values\n\n\ndf = pd.DataFrame(dataSet)\nprint(df)\n\n# Missing data\nimputer = Imputer(missing_values=\"NaN\" , strategy=\"mean\" , axis=0)\n\n\n# Split the data between the Training Data and Test Data\nxTrain , xTest , yTrain , yTest = train_test_split(X , y , test_size = 0.30 , random_state = 0)\n\n\n# Creating linear regression object\nlinearReg = LinearRegression()\nlinearReg.fit(xTrain , yTrain)\n\n#Now, testing model\nyPrediction = linearReg.predict(xTest)\n\n\nprint(X.shape)\nprint(y.shape)\nprint(xTrain , yTrain)\n\n#Plotting the training set\nplot.scatter(xTrain , yTrain , color=\"red\")\nplot.plot(xTrain , linearReg.predict(xTrain) , color=\"blue\")\nplot.title(\"title\")\nplot.xlabel(\"x label\")\nplot.ylabel(\"y label\")\nplot.show()\n\n# Test set\nplot.scatter(xTest, yTest, color = 'red')\nplot.plot(xTrain, linearReg.predict(xTrain), color = 'blue')\nplot.title(\"title\")\nplot.xlabel(\"x label\")\nplot.ylabel(\"y label\")\nplot.show()\n\n</code></pre>\n\n<p><strong>Problems found</strong></p>\n\n<p>The following error is showing me:\nValueError: x and y must be the same size</p>\n\n<p>This is because apparently in the part of</p>\n\n<pre><code>X = dataSet.iloc [:,: - 1] .values\ny = dataSet.iloc [:, 15] .values\n</code></pre>\n\n<p>I'm not taking the correct values. If someone can help me to correct the error I will thank you</p>\n\n<p><strong>Updates</strong></p>\n\n<p>After adding<code>stratify = y</code> to:</p>\n\n<pre><code>xTrain , xTest , yTrain , yTest = train_test_split(X , y , test_size = 0.30, random_state = 0 , stratify = y)\n</code></pre>\n\n<p>It shows me the following graph, in which I presume that it is incorrect\n<a href=\"https://i.stack.imgur.com/uPJVa.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/uPJVa.jpg\" alt=\"enter image description here\"></a></p>\n <machine-learning><python><scikit-learn><training><p>Just print type of both <code>xTest</code> and <code>yTest</code>. You should see that both are of different type. Or simply print both of them. You should be able to see that they are indeed different.</p>\n\n<p>I think using\u00a0<code>xTest[:,0]</code>\u00a0for plotting should solve the problem.</p>\n\n<p>The same thing applies for <code>xTrain</code>.</p>\n<p>I would like to add here that it is important to remember the <strong>Blind Test Rule</strong>. In particular, in order to avoid accidentally optimising your code for the test data during development, a golden rule is to split the data set in three datasets: </p>\n\n<ol>\n<li>Train dataset, to do the training (i.e. 60%) </li>\n<li>Validation dataset, to test during development (i.e. 20%), and </li>\n<li>Test dataset, to do the final testing <strong>only</strong> at the end of the development (i.e. 20%).</li>\n</ol>\n<p>What you are looking for is called <a href=\"https://en.wikipedia.org/wiki/Stratified_sampling\" rel=\"nofollow noreferrer\">Stratified sampling</a></p>\n\n<p>From this <a href=\"https://stats.stackexchange.com/q/250273/36415\">CrossValidated</a> question, we have a short explanation</p>\n\n<blockquote>\n  <p>Stratified sampling aims at splitting one data set so that each split\n  are similar with respect to something. In a classification setting, it\n  is often chosen to ensure that the train and test sets have\n  approximately the same percentage of samples of each target class as\n  the complete set.</p>\n</blockquote>\n\n<p>To get a stratified split in ScikitLearn, you just need to edit this part of your code</p>\n\n<pre><code># Split the data between the Training Data and Test Data\nxTrain , xTest , yTrain , yTest = train_test_split(X , y , \n                                                  test_size = 0.30 , \n                                                  random_state = 0, \n                                          -----&gt;  stratify = y)\n</code></pre>\n\n<p>This will automatically split your dataset in train and test but also keep the same proportion of positives and negatives as the original dataset.</p>\n\n<p>So, if you have a dataset where the positive class is 70% of the records and negative class 30%, after a stratified split, both train and test will have the same 70-30 distribution.</p>\n",
                "codes": [
                    [],
                    [],
                    [
                        "# Split the data between the Training Data and Test Data\nxTrain , xTest , yTrain , yTest = train_test_split(X , y , \n                                                  test_size = 0.30 , \n                                                  random_state = 0, \n                                          ----->  stratify = y)\n"
                    ]
                ],
                "question_id:": "51236",
                "question_votes:": "",
                "question_text:": "<p><strong>Work to do</strong></p>\n\n<p>My job is to take the data and divide it between Training and Test using 30% of the data as Test where both should have the same ratio between positive and negative.</p>\n\n<p><strong>CSV File</strong></p>\n\n<pre><code>age,Feature 2,Feature 3,Feature 4,income,Feature 6,Feature 7,Feature 8,Feature 9,Feature 10,Feature 11,Feature 12,Feature 13,Feature 14,Feature 15,Class\n77,1,0,0,3,0,1,1,1,0,1,1,1,0,1,0\n35,1,0,1,4,0,0,0,1,1,0,1,1,0,1,0\n79,1,0,0,2,0,1,1,0,0,0,1,1,1,0,1\n61,0,1,0,1,0,1,1,1,0,0,0,0,1,0,0\n62,0,0,0,2,0,1,0,0,0,1,1,0,0,0,1\n63,0,1,1,0,1,1,0,0,1,0,0,1,0,0,1\n29,1,1,0,1,1,0,1,1,0,0,1,1,1,1,0\n39,0,1,1,5,1,1,1,0,1,0,1,1,1,1,0\n51,0,1,1,6,1,1,0,1,0,0,1,1,0,1,1\n\n</code></pre>\n\n<p><strong>Code - Training Data and Test Data</strong></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>#!/usr/bin/env python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plot\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import Imputer\n\n\n# Reading CVS file\ndataSet = pd.read_csv('./TestDataFile_ML.csv')\nX = dataSet.iloc[:,:-1].values\ny = dataSet.iloc[:,15].values\n\n\ndf = pd.DataFrame(dataSet)\nprint(df)\n\n# Missing data\nimputer = Imputer(missing_values=\"NaN\" , strategy=\"mean\" , axis=0)\n\n\n# Split the data between the Training Data and Test Data\nxTrain , xTest , yTrain , yTest = train_test_split(X , y , test_size = 0.30 , random_state = 0)\n\n\n# Creating linear regression object\nlinearReg = LinearRegression()\nlinearReg.fit(xTrain , yTrain)\n\n#Now, testing model\nyPrediction = linearReg.predict(xTest)\n\n\nprint(X.shape)\nprint(y.shape)\nprint(xTrain , yTrain)\n\n#Plotting the training set\nplot.scatter(xTrain , yTrain , color=\"red\")\nplot.plot(xTrain , linearReg.predict(xTrain) , color=\"blue\")\nplot.title(\"title\")\nplot.xlabel(\"x label\")\nplot.ylabel(\"y label\")\nplot.show()\n\n# Test set\nplot.scatter(xTest, yTest, color = 'red')\nplot.plot(xTrain, linearReg.predict(xTrain), color = 'blue')\nplot.title(\"title\")\nplot.xlabel(\"x label\")\nplot.ylabel(\"y label\")\nplot.show()\n\n</code></pre>\n\n<p><strong>Problems found</strong></p>\n\n<p>The following error is showing me:\nValueError: x and y must be the same size</p>\n\n<p>This is because apparently in the part of</p>\n\n<pre><code>X = dataSet.iloc [:,: - 1] .values\ny = dataSet.iloc [:, 15] .values\n</code></pre>\n\n<p>I'm not taking the correct values. If someone can help me to correct the error I will thank you</p>\n\n<p><strong>Updates</strong></p>\n\n<p>After adding<code>stratify = y</code> to:</p>\n\n<pre><code>xTrain , xTest , yTrain , yTest = train_test_split(X , y , test_size = 0.30, random_state = 0 , stratify = y)\n</code></pre>\n\n<p>It shows me the following graph, in which I presume that it is incorrect\n<a href=\"https://i.stack.imgur.com/uPJVa.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/uPJVa.jpg\" alt=\"enter image description here\"></a></p>\n",
                "tags": "<machine-learning><python><scikit-learn><training>",
                "answers": [
                    [
                        "51241",
                        "2",
                        "51236",
                        "",
                        "",
                        "<p>Just print type of both <code>xTest</code> and <code>yTest</code>. You should see that both are of different type. Or simply print both of them. You should be able to see that they are indeed different.</p>\n\n<p>I think using\u00a0<code>xTest[:,0]</code>\u00a0for plotting should solve the problem.</p>\n\n<p>The same thing applies for <code>xTrain</code>.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "53078",
                        "2",
                        "51236",
                        "",
                        "",
                        "<p>I would like to add here that it is important to remember the <strong>Blind Test Rule</strong>. In particular, in order to avoid accidentally optimising your code for the test data during development, a golden rule is to split the data set in three datasets: </p>\n\n<ol>\n<li>Train dataset, to do the training (i.e. 60%) </li>\n<li>Validation dataset, to test during development (i.e. 20%), and </li>\n<li>Test dataset, to do the final testing <strong>only</strong> at the end of the development (i.e. 20%).</li>\n</ol>\n",
                        "",
                        ""
                    ],
                    [
                        "51256",
                        "2",
                        "51236",
                        "",
                        "",
                        "<p>What you are looking for is called <a href=\"https://en.wikipedia.org/wiki/Stratified_sampling\" rel=\"nofollow noreferrer\">Stratified sampling</a></p>\n\n<p>From this <a href=\"https://stats.stackexchange.com/q/250273/36415\">CrossValidated</a> question, we have a short explanation</p>\n\n<blockquote>\n  <p>Stratified sampling aims at splitting one data set so that each split\n  are similar with respect to something. In a classification setting, it\n  is often chosen to ensure that the train and test sets have\n  approximately the same percentage of samples of each target class as\n  the complete set.</p>\n</blockquote>\n\n<p>To get a stratified split in ScikitLearn, you just need to edit this part of your code</p>\n\n<pre><code># Split the data between the Training Data and Test Data\nxTrain , xTest , yTrain , yTest = train_test_split(X , y , \n                                                  test_size = 0.30 , \n                                                  random_state = 0, \n                                          -----&gt;  stratify = y)\n</code></pre>\n\n<p>This will automatically split your dataset in train and test but also keep the same proportion of positives and negatives as the original dataset.</p>\n\n<p>So, if you have a dataset where the positive class is 70% of the records and negative class 30%, after a stratified split, both train and test will have the same 70-30 distribution.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3508",
            "_score": 13.382826,
            "_source": {
                "title": "Output data from scikit learn logistic regression",
                "content": "Output data from scikit learn logistic regression <p>I have run a logistic regression using scikit learn in python.  I know want to output the results to put into a csv and then load into Tableau.  To do that I need to combine the y_test, y_actual, and X_test data.  I was wondering if there's a way to output the y_test, y_actual, and X_test data?  I know I can use to_csv, but when I try that I can extract each of these data and concat together, but I'm afraid its not matching correctly since there's no identifying to join on.  </p>\n\n<p>Alternatively, is there a way to keep a unique id (uid) with the logistic regression so then it's easy to see what the regression predicts for a specific person?</p>\n <python><scikit-learn><logistic-regression><csv><tableau><p>Each line is treated independently at prediction, so you can be sure that the data is kept in the same order.</p>\n\n<p>For simplicity, you can keep your data in a pandas dataframe. Here's a short working example:</p>\n\n\n\n<pre><code>import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\n\nX, y = make_classification(n_samples=100, n_features=10)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nclf = LogisticRegression()\nclf.fit(X_train, y_train)\n\ndata_test = pd.DataFrame(data=X_test, columns=['f{}'.format(i) for i in range(1, 11)])\ndata_test['y_test'] = y_test\ndata_test['y_pred'] = clf.predict(X_test)\n</code></pre>\n",
                "codes": [
                    [
                        "import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\n\nX, y = make_classification(n_samples=100, n_features=10)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nclf = LogisticRegression()\nclf.fit(X_train, y_train)\n\ndata_test = pd.DataFrame(data=X_test, columns=['f{}'.format(i) for i in range(1, 11)])\ndata_test['y_test'] = y_test\ndata_test['y_pred'] = clf.predict(X_test)\n"
                    ]
                ],
                "question_id:": "14831",
                "question_votes:": "1",
                "question_text:": "<p>I have run a logistic regression using scikit learn in python.  I know want to output the results to put into a csv and then load into Tableau.  To do that I need to combine the y_test, y_actual, and X_test data.  I was wondering if there's a way to output the y_test, y_actual, and X_test data?  I know I can use to_csv, but when I try that I can extract each of these data and concat together, but I'm afraid its not matching correctly since there's no identifying to join on.  </p>\n\n<p>Alternatively, is there a way to keep a unique id (uid) with the logistic regression so then it's easy to see what the regression predicts for a specific person?</p>\n",
                "tags": "<python><scikit-learn><logistic-regression><csv><tableau>",
                "answers": [
                    [
                        "14837",
                        "2",
                        "14831",
                        "",
                        "",
                        "<p>Each line is treated independently at prediction, so you can be sure that the data is kept in the same order.</p>\n\n<p>For simplicity, you can keep your data in a pandas dataframe. Here's a short working example:</p>\n\n\n\n<pre><code>import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\n\nX, y = make_classification(n_samples=100, n_features=10)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nclf = LogisticRegression()\nclf.fit(X_train, y_train)\n\ndata_test = pd.DataFrame(data=X_test, columns=['f{}'.format(i) for i in range(1, 11)])\ndata_test['y_test'] = y_test\ndata_test['y_pred'] = clf.predict(X_test)\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11714",
            "_score": 13.379759,
            "_source": {
                "title": "In handwritten digit recognition problem using logistic regression, what changes needed to add another class \"Not a Digit\"",
                "content": "In handwritten digit recognition problem using logistic regression, what changes needed to add another class \"Not a Digit\" <p>In handwritten digit recognition problem using logistic regression, normal implementation would forcibly classify even a picture of dog or cat as a digit. To eliminate this, what changes are needed to add another class i.e. \"Not a Digit\" to already existing 10 classes (0 to 9) ?</p>\n <scikit-learn><logistic-regression><multiclass-classification><image-recognition><multilabel-classification><p>If you are using one vs all classification, you can use a condition where if no class reach a minimum of probability, then it is not a number.\nOr you can train the classifier with another class \"Not a Digit\".\nOr maybe use a pipeline of two classifiers, one that tells you if a picture is a number or not, and if it is a number, classify that number.</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Logistic_regression\" rel=\"nofollow noreferrer\">Logistic regression</a> is normally used to perform binary classification, which answers a <strong>yes or no</strong> question, e.g.:</p>\n\n<ol>\n<li>Is this an 8 or not?</li>\n<li>Will it rain today or not?</li>\n</ol>\n\n<p>Perhaps I have misunderstood your explanation, but it sounds like you are trying to perform <em>multi-class classification</em>, i.e. to classify an image as one of a certain number of options. So a single image must contain (be classified as) a number from the list: <code>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</code>.</p>\n\n<p>Usually, to add an extra class to a model that already does this, you would need to adjust the final output of the model to predict <a href=\"https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f\" rel=\"nofollow noreferrer\">a one-hot vector</a> that is simply one element longer!</p>\n\n<p>In the specific case of the Scikit-Learn <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\"><strong>LogosticRegression</strong></a> class, it seems as though you don't need to specify anything - the class will automatically use a multinomial model and relevant optimiser as soon as it sees that data is not binary (i.e. a yes-no model as explained above).</p>\n\n<p>Have a look at <a href=\"https://scikit-learn.org/stable/auto_examples/linear_model/plot_sparse_logistic_regression_20newsgroups.html#sphx-glr-auto-examples-linear-model-plot-sparse-logistic-regression-20newsgroups-py\" rel=\"nofollow noreferrer\">this official tutorial</a>, which should a multinomial model trained on a dataset with a target variable that has a total of 20 classes. The number of features (<code>n_classes</code> is equal to <code>20</code>) is not passed to the model at all, it is inferred.</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "41295",
                "question_votes:": "1",
                "question_text:": "<p>In handwritten digit recognition problem using logistic regression, normal implementation would forcibly classify even a picture of dog or cat as a digit. To eliminate this, what changes are needed to add another class i.e. \"Not a Digit\" to already existing 10 classes (0 to 9) ?</p>\n",
                "tags": "<scikit-learn><logistic-regression><multiclass-classification><image-recognition><multilabel-classification>",
                "answers": [
                    [
                        "57711",
                        "2",
                        "41295",
                        "",
                        "",
                        "<p>If you are using one vs all classification, you can use a condition where if no class reach a minimum of probability, then it is not a number.\nOr you can train the classifier with another class \"Not a Digit\".\nOr maybe use a pipeline of two classifiers, one that tells you if a picture is a number or not, and if it is a number, classify that number.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "41299",
                        "2",
                        "41295",
                        "",
                        "",
                        "<p><a href=\"https://en.wikipedia.org/wiki/Logistic_regression\" rel=\"nofollow noreferrer\">Logistic regression</a> is normally used to perform binary classification, which answers a <strong>yes or no</strong> question, e.g.:</p>\n\n<ol>\n<li>Is this an 8 or not?</li>\n<li>Will it rain today or not?</li>\n</ol>\n\n<p>Perhaps I have misunderstood your explanation, but it sounds like you are trying to perform <em>multi-class classification</em>, i.e. to classify an image as one of a certain number of options. So a single image must contain (be classified as) a number from the list: <code>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</code>.</p>\n\n<p>Usually, to add an extra class to a model that already does this, you would need to adjust the final output of the model to predict <a href=\"https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f\" rel=\"nofollow noreferrer\">a one-hot vector</a> that is simply one element longer!</p>\n\n<p>In the specific case of the Scikit-Learn <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\"><strong>LogosticRegression</strong></a> class, it seems as though you don't need to specify anything - the class will automatically use a multinomial model and relevant optimiser as soon as it sees that data is not binary (i.e. a yes-no model as explained above).</p>\n\n<p>Have a look at <a href=\"https://scikit-learn.org/stable/auto_examples/linear_model/plot_sparse_logistic_regression_20newsgroups.html#sphx-glr-auto-examples-linear-model-plot-sparse-logistic-regression-20newsgroups-py\" rel=\"nofollow noreferrer\">this official tutorial</a>, which should a multinomial model trained on a dataset with a target variable that has a total of 20 classes. The number of features (<code>n_classes</code> is equal to <code>20</code>) is not passed to the model at all, it is inferred.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16523",
            "_score": 13.335506,
            "_source": {
                "title": "Multicollinearity(Variance Inflation Factor). Variables to remove before doing a model",
                "content": "Multicollinearity(Variance Inflation Factor). Variables to remove before doing a model <p>I am doing an exercise of a Machine Learning System module in python that takes a dataset of cars (cylinders, year, consumption....) and asks for a model, being the variable to predict the consumption of gasoline. As it has three categorical variables, I have generated the dummies.</p>\n\n<p><a href=\"https://i.stack.imgur.com/YleVB.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/YleVB.png\" alt=\"enter image description here\"></a></p>\n\n<p>In the exercise I need to eliminate the variables with multicollinearity, so I used the method showed on my course notes:</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\n\ndef calculateVIF(data):\n    features = list(data.columns)\n    num_features = len(features)\n\n    model = LinearRegression()\n\n    result = pd.DataFrame(index = ['VIF'], columns = features)\n    result = result.fillna(0)\n\n    for ite in range(num_features):\n        x_features = features[:]\n        y_featue = features[ite]\n        x_features.remove(y_featue)\n\n        x = data[x_features]\n        y = data[y_featue]\n\n        model.fit(data[x_features], data[y_featue])\n\n        result[y_featue] = 1/(1 - model.score(data[x_features], data[y_featue]))\n\n    return result\n</code></pre>\n\n<p>Then if I launch the method it calculates a coefficient for each variable:</p>\n\n<p><a href=\"https://i.stack.imgur.com/Z3UiS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Z3UiS.png\" alt=\"enter image description here\"></a></p>\n\n<p>In my course notes it is said:</p>\n\n<ul>\n<li><span class=\"math-container\">$VIF&gt;5$</span> is a high value.</li>\n<li><span class=\"math-container\">$VIF&gt;10$</span> is a very high value</li>\n</ul>\n\n<p>What should I do? I need to remove the variables that have a <span class=\"math-container\">$VIF&gt;10$</span> before executing the model?</p>\n\n<p>The problem I see, for my categorical variable cylinders, is only cylinders_5 has a VIF under 10 so should I remove the others and leave cyclinders_5?</p>\n <machine-learning><scikit-learn><collinearity><p><strong>1)</strong> First, you need to do variable regression i.e for each column in your data set you do simple linear regression and calculate p-value... Thereby you get an idea of the significance of each column against the target variable.  </p>\n\n<p><strong>2)</strong> plot influence plot check the cooks_d value </p>\n\n<pre><code> import statsmodels.api as sm\n  infl = model1.get_influence()\n  sm_fr = infl.summary_frame()\n</code></pre>\n\n<p>3) You will get cooks_d value from sm_fr data frame</p>\n\n<p>4)select the row point  with a cooks_d value>1 and remove that row from your data frame,,\n   now you have removed influential points.\n5)Now check VIF values for new set data frame containing variables and remove the variables having vif>5 as they are insignificant ... you can also check their significance calcualting p value .</p>\n\n<p><em>for overall procedure of building a multi linear regression model satisfying all assumotions of multilinear regression like linearity,homosedasticity,multivariate normality and no multicollineaity see the below example of prediction of profit of start- ups</em></p>\n\n<p><a href=\"https://github.com/tharun435/Data-Science-/blob/master/startups.ipynb\" rel=\"nofollow noreferrer\">https://github.com/tharun435/Data-Science-/blob/master/startups.ipynb</a></p>\n<p>Never remove features from your dataset. Always try to make use of them. Try using some DR techniques like PCA to eliminate the multicollinearity between the features. Removing features means you are losing some info. unless Multicollinearity means that the correlation between them is 1 one then you can delete them safely. Using Tree-based models will capture these little differences between features.</p>\n",
                "codes": [
                    [
                        " import statsmodels.api as sm\n  infl = model1.get_influence()\n  sm_fr = infl.summary_frame()\n"
                    ],
                    []
                ],
                "question_id:": "54280",
                "question_votes:": "1",
                "question_text:": "<p>I am doing an exercise of a Machine Learning System module in python that takes a dataset of cars (cylinders, year, consumption....) and asks for a model, being the variable to predict the consumption of gasoline. As it has three categorical variables, I have generated the dummies.</p>\n\n<p><a href=\"https://i.stack.imgur.com/YleVB.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/YleVB.png\" alt=\"enter image description here\"></a></p>\n\n<p>In the exercise I need to eliminate the variables with multicollinearity, so I used the method showed on my course notes:</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\n\ndef calculateVIF(data):\n    features = list(data.columns)\n    num_features = len(features)\n\n    model = LinearRegression()\n\n    result = pd.DataFrame(index = ['VIF'], columns = features)\n    result = result.fillna(0)\n\n    for ite in range(num_features):\n        x_features = features[:]\n        y_featue = features[ite]\n        x_features.remove(y_featue)\n\n        x = data[x_features]\n        y = data[y_featue]\n\n        model.fit(data[x_features], data[y_featue])\n\n        result[y_featue] = 1/(1 - model.score(data[x_features], data[y_featue]))\n\n    return result\n</code></pre>\n\n<p>Then if I launch the method it calculates a coefficient for each variable:</p>\n\n<p><a href=\"https://i.stack.imgur.com/Z3UiS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Z3UiS.png\" alt=\"enter image description here\"></a></p>\n\n<p>In my course notes it is said:</p>\n\n<ul>\n<li><span class=\"math-container\">$VIF&gt;5$</span> is a high value.</li>\n<li><span class=\"math-container\">$VIF&gt;10$</span> is a very high value</li>\n</ul>\n\n<p>What should I do? I need to remove the variables that have a <span class=\"math-container\">$VIF&gt;10$</span> before executing the model?</p>\n\n<p>The problem I see, for my categorical variable cylinders, is only cylinders_5 has a VIF under 10 so should I remove the others and leave cyclinders_5?</p>\n",
                "tags": "<machine-learning><scikit-learn><collinearity>",
                "answers": [
                    [
                        "54732",
                        "2",
                        "54280",
                        "",
                        "",
                        "<p><strong>1)</strong> First, you need to do variable regression i.e for each column in your data set you do simple linear regression and calculate p-value... Thereby you get an idea of the significance of each column against the target variable.  </p>\n\n<p><strong>2)</strong> plot influence plot check the cooks_d value </p>\n\n<pre><code> import statsmodels.api as sm\n  infl = model1.get_influence()\n  sm_fr = infl.summary_frame()\n</code></pre>\n\n<p>3) You will get cooks_d value from sm_fr data frame</p>\n\n<p>4)select the row point  with a cooks_d value>1 and remove that row from your data frame,,\n   now you have removed influential points.\n5)Now check VIF values for new set data frame containing variables and remove the variables having vif>5 as they are insignificant ... you can also check their significance calcualting p value .</p>\n\n<p><em>for overall procedure of building a multi linear regression model satisfying all assumotions of multilinear regression like linearity,homosedasticity,multivariate normality and no multicollineaity see the below example of prediction of profit of start- ups</em></p>\n\n<p><a href=\"https://github.com/tharun435/Data-Science-/blob/master/startups.ipynb\" rel=\"nofollow noreferrer\">https://github.com/tharun435/Data-Science-/blob/master/startups.ipynb</a></p>\n",
                        "",
                        "2"
                    ],
                    [
                        "54767",
                        "2",
                        "54280",
                        "",
                        "",
                        "<p>Never remove features from your dataset. Always try to make use of them. Try using some DR techniques like PCA to eliminate the multicollinearity between the features. Removing features means you are losing some info. unless Multicollinearity means that the correlation between them is 1 one then you can delete them safely. Using Tree-based models will capture these little differences between features.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6069",
            "_score": 13.283998,
            "_source": {
                "title": "Finding relationships from group of variables",
                "content": "Finding relationships from group of variables <p>Given time-series data of a set of input metrics $M_1$, $M_2$, $M_3$ ... $M_n$ and a set of observed metrics $O_1$, $O_2$, $O_3$ ... $O_m$.</p>\n\n<p>For each $M_i$, what is the best way to find equations that best describe the relationship between $M_i$ and the set of observed metrics?</p>\n\n<p>It is given that all $M_i$ are independent of each other.</p>\n <machine-learning><time-series><statistics><data><correlation><p>It is a pretty difficult task to obtain a function $f_1$ satisfying $M_1(t) = f_1(O_1(t), O_2(t),...)$. It is mostly like a regression problem where you are trying to fit $M_1(t)$.</p>\n\n<p>I could suggest three approaches:</p>\n\n<ol>\n<li>Simple multiple regression. <a href=\"http://scikit-learn.org/stable/modules/linear_model.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/linear_model.html</a>. If that doesn't work, you could increase the order of your observed metric space $O$ using PolynomialFeatures <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html</a> and then try multiple regression. </li>\n</ol>\n\n<p>I don't really fancy these other two approaches but will list them anyway, in case you want to have a go.</p>\n\n<ol start=\"2\">\n<li>Multivariate Adaptive Regression Splines <a href=\"http://contrib.scikit-learn.org/py-earth/content.html\" rel=\"nofollow noreferrer\">http://contrib.scikit-learn.org/py-earth/content.html</a>\nYou will get a good fit but the function will be discrete in nature.</li>\n<li>OpenMLC <a href=\"https://github.com/MachineLearningControl/OpenMLC-Python/releases\" rel=\"nofollow noreferrer\">https://github.com/MachineLearningControl/OpenMLC-Python/releases</a> which uses Genetic Algorithms. This will be able to provide you with functions like $sin(O_i), log(O_i), exp(O_i)$ as well. But the problem is that since it uses genetic algorithms, you won't obtain a deterministic function. The function will change each time you run it with varying accuracy.</li>\n</ol>\n",
                "codes": [
                    []
                ],
                "question_id:": "23862",
                "question_votes:": "",
                "question_text:": "<p>Given time-series data of a set of input metrics $M_1$, $M_2$, $M_3$ ... $M_n$ and a set of observed metrics $O_1$, $O_2$, $O_3$ ... $O_m$.</p>\n\n<p>For each $M_i$, what is the best way to find equations that best describe the relationship between $M_i$ and the set of observed metrics?</p>\n\n<p>It is given that all $M_i$ are independent of each other.</p>\n",
                "tags": "<machine-learning><time-series><statistics><data><correlation>",
                "answers": [
                    [
                        "23864",
                        "2",
                        "23862",
                        "",
                        "",
                        "<p>It is a pretty difficult task to obtain a function $f_1$ satisfying $M_1(t) = f_1(O_1(t), O_2(t),...)$. It is mostly like a regression problem where you are trying to fit $M_1(t)$.</p>\n\n<p>I could suggest three approaches:</p>\n\n<ol>\n<li>Simple multiple regression. <a href=\"http://scikit-learn.org/stable/modules/linear_model.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/linear_model.html</a>. If that doesn't work, you could increase the order of your observed metric space $O$ using PolynomialFeatures <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html</a> and then try multiple regression. </li>\n</ol>\n\n<p>I don't really fancy these other two approaches but will list them anyway, in case you want to have a go.</p>\n\n<ol start=\"2\">\n<li>Multivariate Adaptive Regression Splines <a href=\"http://contrib.scikit-learn.org/py-earth/content.html\" rel=\"nofollow noreferrer\">http://contrib.scikit-learn.org/py-earth/content.html</a>\nYou will get a good fit but the function will be discrete in nature.</li>\n<li>OpenMLC <a href=\"https://github.com/MachineLearningControl/OpenMLC-Python/releases\" rel=\"nofollow noreferrer\">https://github.com/MachineLearningControl/OpenMLC-Python/releases</a> which uses Genetic Algorithms. This will be able to provide you with functions like $sin(O_i), log(O_i), exp(O_i)$ as well. But the problem is that since it uses genetic algorithms, you won't obtain a deterministic function. The function will change each time you run it with varying accuracy.</li>\n</ol>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "2870",
            "_score": 13.272187,
            "_source": {
                "title": "Deep learning - rule generation",
                "content": "Deep learning - rule generation <p>I wanted to know if there is any methodology in Deep/Machine learning, where given a set of input/output values, it can derive rules for the same.</p>\n\n<p>Lets say I generate training input and output by $y=x^2$</p>\n\n<pre><code>i/p  |  o/p\n 0       0\n 2       4\n .       .\n1000   1000000\n</code></pre>\n\n<p>It sort of generate rule like, $y=x*x$</p>\n <machine-learning><deep-learning><training><p>One way of stating what you are looking for is to find a simple mathematical model to explain your data.</p>\n\n<p>One thing about neural networks is that (once they have more than 2 layers, and enough neurons total) they can in theory emulate any function, no matter how complex. This is useful for machine learning as often the function we want to predict is complex and cannot be expressed simply with a few operators. However, it is kind of the opposite of what you want - the neural network behaves like a \"black box\" and you don't get a simple function out, even if there is one driving the data.</p>\n\n<p>You can try to fit a model (any model) to your data using very simple forms of regression, such as <a href=\"https://en.wikipedia.org/wiki/Linear_regression\" rel=\"nofollow\">linear regression</a>. So if you are reasonably sure that your system is a cubic equation $y= ax^3 + bx^2 +cx +d$ then you could create a table like this:</p>\n\n<pre><code>  bias   |   x  |  x*x  |  x*x*x  |     y\n     1       0       0         0        0\n     1       2       4         8        4\n     1       3       9        27        9\n     1       .         .        .       .\n     1     100   1000000    10000   10000\n</code></pre>\n\n<p>and then use a <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\" rel=\"nofollow\">linear regression optimiser</a> (sci-kit learn's SGD optimiser linked). With the above data this should quickly tell you $b=1, a,c,d=0$. But what it won't tell you is whether your model is the best possible or somehow \"correct\". You can scan for more possible formulae by creating more columns - any function of any combination of inputs (if there is more than one) that could be feasible. </p>\n\n<p><em>However</em>, the more columns you add in this way, the more likely it is you will find an incorrect <em>overfit</em> solution that matches all your data using a clever combination of parameters, but which is not a good general predictor. To address this, you will need to add regularisation - a simple L1 or L2 regularisation of the parameters will do (in the link I gave to scikit-learn, the <code>penalty</code> argument can control this), which will penalise large parameters and help you home in on a simple formula if there is one.</p>\n",
                "codes": [
                    [
                        "  bias   |   x  |  x*x  |  x*x*x  |     y\n     1       0       0         0        0\n     1       2       4         8        4\n     1       3       9        27        9\n     1       .         .        .       .\n     1     100   1000000    10000   10000\n"
                    ]
                ],
                "question_id:": "12808",
                "question_votes:": "",
                "question_text:": "<p>I wanted to know if there is any methodology in Deep/Machine learning, where given a set of input/output values, it can derive rules for the same.</p>\n\n<p>Lets say I generate training input and output by $y=x^2$</p>\n\n<pre><code>i/p  |  o/p\n 0       0\n 2       4\n .       .\n1000   1000000\n</code></pre>\n\n<p>It sort of generate rule like, $y=x*x$</p>\n",
                "tags": "<machine-learning><deep-learning><training>",
                "answers": [
                    [
                        "12809",
                        "2",
                        "12808",
                        "",
                        "",
                        "<p>One way of stating what you are looking for is to find a simple mathematical model to explain your data.</p>\n\n<p>One thing about neural networks is that (once they have more than 2 layers, and enough neurons total) they can in theory emulate any function, no matter how complex. This is useful for machine learning as often the function we want to predict is complex and cannot be expressed simply with a few operators. However, it is kind of the opposite of what you want - the neural network behaves like a \"black box\" and you don't get a simple function out, even if there is one driving the data.</p>\n\n<p>You can try to fit a model (any model) to your data using very simple forms of regression, such as <a href=\"https://en.wikipedia.org/wiki/Linear_regression\" rel=\"nofollow\">linear regression</a>. So if you are reasonably sure that your system is a cubic equation $y= ax^3 + bx^2 +cx +d$ then you could create a table like this:</p>\n\n<pre><code>  bias   |   x  |  x*x  |  x*x*x  |     y\n     1       0       0         0        0\n     1       2       4         8        4\n     1       3       9        27        9\n     1       .         .        .       .\n     1     100   1000000    10000   10000\n</code></pre>\n\n<p>and then use a <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\" rel=\"nofollow\">linear regression optimiser</a> (sci-kit learn's SGD optimiser linked). With the above data this should quickly tell you $b=1, a,c,d=0$. But what it won't tell you is whether your model is the best possible or somehow \"correct\". You can scan for more possible formulae by creating more columns - any function of any combination of inputs (if there is more than one) that could be feasible. </p>\n\n<p><em>However</em>, the more columns you add in this way, the more likely it is you will find an incorrect <em>overfit</em> solution that matches all your data using a clever combination of parameters, but which is not a good general predictor. To address this, you will need to add regularisation - a simple L1 or L2 regularisation of the parameters will do (in the link I gave to scikit-learn, the <code>penalty</code> argument can control this), which will penalise large parameters and help you home in on a simple formula if there is one.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4035",
            "_score": 13.262059,
            "_source": {
                "title": "Performance difference between decision trees and logistic regression when one of the features is a string",
                "content": "Performance difference between decision trees and logistic regression when one of the features is a string <p>I have a set of features, one of which is a string. I convert the string to an integer by treating the string as a base 36 number (I only use the first 13 characters). Then I can use DecisionTrees since in the sklearn implementation you need to convert it to a number. When I tried a different model, say Logistic Regression, performance drops drastically, say from 80% to 30% accuracy.</p>\n\n<p>I might have accepted this result if I had been able to use the strings as such in the DecisionTrees model, but since I used the same string to integer conversion for both models, why such great difference?</p>\n\n<p>I cannot go into the details, but let me provide you with an analogy. Let's say you are classifying millions of objects by their usefulness. So you say hammers are 4, screwdrivers 6, washers 10, etc. Of course you have more than one screwdriver, and sometime you forget and give it a value of 5, or something else. The model goes through millions of example, and then makes a prediction about the number for each object. I converted the names into integers, as I explained, and decision trees gives me an 80% accuracy, linear regression 30%. I assume that the problem is that linear regression tries to figure out some mathematical rule that does not exist. But why is decision trees immune from this problem?</p>\n <python><scikit-learn><decision-trees><linear-regression><p>Decision trees can classify categorical data. Even if they treat every string as a separate (non comparable to the others) category, they are still able to detect when two strings are equal.</p>\n\n<p>This is not the case with statistical methods, such as logistic regression. These need I'm interval data. This is why you need to define a <a href=\"https://en.wikipedia.org/wiki/String_metric\" rel=\"nofollow noreferrer\">string similarity metric</a> over your strings. Unless there's a reason for defining your metric this way (notice that differences in the first character of otherwise similar strings get evaluated as much more distant than differences in the last character), probably the algorithm is confused by the values of your strings. Thus, it is possible that your regression learns something that you've introduced with your string conversion, and which does not exist in the original data. This introduced dependency could be confusing your regression and could be overshadowing a more efficient way of learning.</p>\n\n<p>To validate such a hypothesis, you can try applying other string similarity metrics and compare the results. However, be cautious: different metrics might be useful in different contexts.</p>\n<p>String data can be either categorical (where you have e.g. more than 10 examples of each string) or free text.  If it's the former, a decision tree can deal with it no problem. You don't have to convert it into a numeric.</p>\n\n<p>For regression you cannot directly use categorical variables.    If you want to use them in a regression, you will need to create dummy variables to encode the values. e.g. if your categories are \"Red\", \"Yellow\", \"Blue\" for the colour variable, you create variables \"Red\" (which will take a 1 or a 0) and \"Yellow\" (which takes a 1 or 0).  If both are 0, the colour must be \"Blue\".  There are functions in sklearn to do this automatically. </p>\n\n<p>If your string is just free text then you will need a better way of grabbing information out of it.  You can use text mining such as tokenizing, TF-IDF etc. to convert it into numerical and categorical information that can be fed into a classifier. </p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "16509",
                "question_votes:": "4",
                "question_text:": "<p>I have a set of features, one of which is a string. I convert the string to an integer by treating the string as a base 36 number (I only use the first 13 characters). Then I can use DecisionTrees since in the sklearn implementation you need to convert it to a number. When I tried a different model, say Logistic Regression, performance drops drastically, say from 80% to 30% accuracy.</p>\n\n<p>I might have accepted this result if I had been able to use the strings as such in the DecisionTrees model, but since I used the same string to integer conversion for both models, why such great difference?</p>\n\n<p>I cannot go into the details, but let me provide you with an analogy. Let's say you are classifying millions of objects by their usefulness. So you say hammers are 4, screwdrivers 6, washers 10, etc. Of course you have more than one screwdriver, and sometime you forget and give it a value of 5, or something else. The model goes through millions of example, and then makes a prediction about the number for each object. I converted the names into integers, as I explained, and decision trees gives me an 80% accuracy, linear regression 30%. I assume that the problem is that linear regression tries to figure out some mathematical rule that does not exist. But why is decision trees immune from this problem?</p>\n",
                "tags": "<python><scikit-learn><decision-trees><linear-regression>",
                "answers": [
                    [
                        "37214",
                        "2",
                        "16509",
                        "",
                        "",
                        "<p>Decision trees can classify categorical data. Even if they treat every string as a separate (non comparable to the others) category, they are still able to detect when two strings are equal.</p>\n\n<p>This is not the case with statistical methods, such as logistic regression. These need I'm interval data. This is why you need to define a <a href=\"https://en.wikipedia.org/wiki/String_metric\" rel=\"nofollow noreferrer\">string similarity metric</a> over your strings. Unless there's a reason for defining your metric this way (notice that differences in the first character of otherwise similar strings get evaluated as much more distant than differences in the last character), probably the algorithm is confused by the values of your strings. Thus, it is possible that your regression learns something that you've introduced with your string conversion, and which does not exist in the original data. This introduced dependency could be confusing your regression and could be overshadowing a more efficient way of learning.</p>\n\n<p>To validate such a hypothesis, you can try applying other string similarity metrics and compare the results. However, be cautious: different metrics might be useful in different contexts.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "40575",
                        "2",
                        "16509",
                        "",
                        "",
                        "<p>String data can be either categorical (where you have e.g. more than 10 examples of each string) or free text.  If it's the former, a decision tree can deal with it no problem. You don't have to convert it into a numeric.</p>\n\n<p>For regression you cannot directly use categorical variables.    If you want to use them in a regression, you will need to create dummy variables to encode the values. e.g. if your categories are \"Red\", \"Yellow\", \"Blue\" for the colour variable, you create variables \"Red\" (which will take a 1 or a 0) and \"Yellow\" (which takes a 1 or 0).  If both are 0, the colour must be \"Blue\".  There are functions in sklearn to do this automatically. </p>\n\n<p>If your string is just free text then you will need a better way of grabbing information out of it.  You can use text mining such as tokenizing, TF-IDF etc. to convert it into numerical and categorical information that can be fed into a classifier. </p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9090",
            "_score": 13.228067,
            "_source": {
                "title": "is a 4 output regression equivalent to 4 single output regression superposition?",
                "content": "is a 4 output regression equivalent to 4 single output regression superposition? <p>I would like to generate a regression based on 6 different inputs and 4 output. </p>\n\n<p>I use python and I compare sklearn and scipy. But in both cases, regression models are essentially focused on 1 output parameter. </p>\n\n<p>My question is : can I considerer that all of my outputs are unlinked, and if yes, is it true to imagine that I can perform 4 regressions in parallel (one for each output) to make an equivalent 4 ouput model ?</p>\n\n<p>Tank you for your tips !</p>\n <python><neural-network><regression><p>I found something on sklearn to generate a multi output from simple output regression. here it is: <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html</a></p>\n\n<p>It looks to be a superposition, isn't it ?</p>\n<blockquote>\n  <p>\"My question is : can I consider that all of my outputs are unlinked\"</p>\n</blockquote>\n\n<p><strong>No</strong>, in general you can't, unless you have prior knowledge indicating so. There is a high chance that your outputs are correlated. To explore linear correlations, perform a <a href=\"https://en.wikipedia.org/wiki/Correlation_and_dependence\" rel=\"nofollow noreferrer\">correlation</a> analysis (calculate correlation matrix). To investigate nonlinear relations, calculate the <a href=\"https://en.wikipedia.org/wiki/Distance_correlation\" rel=\"nofollow noreferrer\">distance correlation</a>.</p>\n\n<blockquote>\n  <p>and if yes, is it true to imagine that I can perform 4 regressions in\n  parallel (one for each output) to make an equivalent 4 ouput model ?</p>\n</blockquote>\n\n<p>If your analysis proves that there is low correlation between the outputs, <strong>only then</strong> you can implement 4 independent regression models in parallel with meaningful results.</p>\n\n<p>My suggestion would be to implement a MIMO machine learning model (multiple inputs / multiple outputs), such as a <a href=\"https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\" rel=\"nofollow noreferrer\">multivariate Recurrent Neural Network</a>.</p>\n\n<p>Hope it helps :)</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "32490",
                "question_votes:": "2",
                "question_text:": "<p>I would like to generate a regression based on 6 different inputs and 4 output. </p>\n\n<p>I use python and I compare sklearn and scipy. But in both cases, regression models are essentially focused on 1 output parameter. </p>\n\n<p>My question is : can I considerer that all of my outputs are unlinked, and if yes, is it true to imagine that I can perform 4 regressions in parallel (one for each output) to make an equivalent 4 ouput model ?</p>\n\n<p>Tank you for your tips !</p>\n",
                "tags": "<python><neural-network><regression>",
                "answers": [
                    [
                        "32815",
                        "2",
                        "32490",
                        "",
                        "",
                        "<p>I found something on sklearn to generate a multi output from simple output regression. here it is: <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html</a></p>\n\n<p>It looks to be a superposition, isn't it ?</p>\n",
                        "",
                        ""
                    ],
                    [
                        "32502",
                        "2",
                        "32490",
                        "",
                        "",
                        "<blockquote>\n  <p>\"My question is : can I consider that all of my outputs are unlinked\"</p>\n</blockquote>\n\n<p><strong>No</strong>, in general you can't, unless you have prior knowledge indicating so. There is a high chance that your outputs are correlated. To explore linear correlations, perform a <a href=\"https://en.wikipedia.org/wiki/Correlation_and_dependence\" rel=\"nofollow noreferrer\">correlation</a> analysis (calculate correlation matrix). To investigate nonlinear relations, calculate the <a href=\"https://en.wikipedia.org/wiki/Distance_correlation\" rel=\"nofollow noreferrer\">distance correlation</a>.</p>\n\n<blockquote>\n  <p>and if yes, is it true to imagine that I can perform 4 regressions in\n  parallel (one for each output) to make an equivalent 4 ouput model ?</p>\n</blockquote>\n\n<p>If your analysis proves that there is low correlation between the outputs, <strong>only then</strong> you can implement 4 independent regression models in parallel with meaningful results.</p>\n\n<p>My suggestion would be to implement a MIMO machine learning model (multiple inputs / multiple outputs), such as a <a href=\"https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\" rel=\"nofollow noreferrer\">multivariate Recurrent Neural Network</a>.</p>\n\n<p>Hope it helps :)</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6221",
            "_score": 13.216658,
            "_source": {
                "title": "How to do stepwise regression using sklearn?",
                "content": "How to do stepwise regression using sklearn? <p>I could not find a way to stepwise regression in scikit learn. I have checked all other posts on Stack Exchange on this topic. Answers to all of them suggests using f_regression.</p>\n\n<p>But f_regression does not do stepwise regression but only give F-score and pvalues corresponding to each of the regressors, which is only the first step in stepwise regression.</p>\n\n<p>What to do after 1st regressors with the best f-score is chosen?</p>\n <machine-learning><scikit-learn><regression><feature-selection><linear-regression><p>Scikit-learn indeed does not support stepwise regression. That's because what is commonly known as 'stepwise regression' is an algorithm based on p-values of coefficients of linear regression, and scikit-learn deliberately avoids inferential approach to model learning (significance testing etc). Moreover, pure OLS is only one of numerous regression algorithms, and from the scikit-learn point of view it is neither very important, nor one of the best. </p>\n\n<p>There are, however, some pieces of advice for those who still need a good way for feature selection with linear models:</p>\n\n<ol>\n<li>Use inherently sparse models like <code>ElasticNet</code> or <code>Lasso</code>.</li>\n<li>Normalize your features with <code>StandardScaler</code>, and then order your features just by <code>model.coef_</code>. For perfectly independent covariates it is equivalent to sorting by p-values. The class <code>sklearn.feature_selection.RFE</code> will do it for you, and <code>RFECV</code> will even evaluate the optimal number of features.</li>\n<li>Use <a href=\"http://planspace.org/20150423-forward_selection_with_statsmodels/\" rel=\"noreferrer\">an implementation</a> of forward selection by adjusted $R^2$ that works with <code>statsmodels</code>.</li>\n<li>Do brute-force forward or backward selection to maximize your favorite metric on cross-validation (it could take approximately quadratic time in number of covariates). A scikit-learn compatible <code>mlxtend</code> package <a href=\"http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/\" rel=\"noreferrer\">supports</a> this approach for any estimator and any metric.</li>\n<li>If you still want vanilla stepwise regression, it is easier to base it on <code>statsmodels</code>, since this package calculates p-values for you. A basic forward-backward selection could look like this:</li>\n</ol>\n\n<p>```</p>\n\n<pre><code>from sklearn.datasets import load_boston\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\n\ndata = load_boston()\nX = pd.DataFrame(data.data, columns=data.feature_names)\ny = data.target\n\n\ndef stepwise_selection(X, y, \n                       initial_list=[], \n                       threshold_in=0.01, \n                       threshold_out = 0.05, \n                       verbose=True):\n    \"\"\" Perform a forward-backward feature selection \n    based on p-value from statsmodels.api.OLS\n    Arguments:\n        X - pandas.DataFrame with candidate features\n        y - list-like with the target\n        initial_list - list of features to start with (column names of X)\n        threshold_in - include a feature if its p-value &lt; threshold_in\n        threshold_out - exclude a feature if its p-value &gt; threshold_out\n        verbose - whether to print the sequence of inclusions and exclusions\n    Returns: list of selected features \n    Always set threshold_in &lt; threshold_out to avoid infinite looping.\n    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n    \"\"\"\n    included = list(initial_list)\n    while True:\n        changed=False\n        # forward step\n        excluded = list(set(X.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval &lt; threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n\n        # backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n        # use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() # null if pvalues is empty\n        if worst_pval &gt; threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n\nresult = stepwise_selection(X, y)\n\nprint('resulting features:')\nprint(result)\n</code></pre>\n\n<p>This example would print the following output:</p>\n\n<pre><code>Add  LSTAT                          with p-value 5.0811e-88\nAdd  RM                             with p-value 3.47226e-27\nAdd  PTRATIO                        with p-value 1.64466e-14\nAdd  DIS                            with p-value 1.66847e-05\nAdd  NOX                            with p-value 5.48815e-08\nAdd  CHAS                           with p-value 0.000265473\nAdd  B                              with p-value 0.000771946\nAdd  ZN                             with p-value 0.00465162\nresulting features:\n['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX', 'CHAS', 'B', 'ZN']\n</code></pre>\n",
                "codes": [
                    [
                        "from sklearn.datasets import load_boston\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\n\ndata = load_boston()\nX = pd.DataFrame(data.data, columns=data.feature_names)\ny = data.target\n\n\ndef stepwise_selection(X, y, \n                       initial_list=[], \n                       threshold_in=0.01, \n                       threshold_out = 0.05, \n                       verbose=True):\n    \"\"\" Perform a forward-backward feature selection \n    based on p-value from statsmodels.api.OLS\n    Arguments:\n        X - pandas.DataFrame with candidate features\n        y - list-like with the target\n        initial_list - list of features to start with (column names of X)\n        threshold_in - include a feature if its p-value < threshold_in\n        threshold_out - exclude a feature if its p-value > threshold_out\n        verbose - whether to print the sequence of inclusions and exclusions\n    Returns: list of selected features \n    Always set threshold_in < threshold_out to avoid infinite looping.\n    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n    \"\"\"\n    included = list(initial_list)\n    while True:\n        changed=False\n        # forward step\n        excluded = list(set(X.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n\n        # backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n        # use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() # null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n\nresult = stepwise_selection(X, y)\n\nprint('resulting features:')\nprint(result)\n",
                        "Add  LSTAT                          with p-value 5.0811e-88\nAdd  RM                             with p-value 3.47226e-27\nAdd  PTRATIO                        with p-value 1.64466e-14\nAdd  DIS                            with p-value 1.66847e-05\nAdd  NOX                            with p-value 5.48815e-08\nAdd  CHAS                           with p-value 0.000265473\nAdd  B                              with p-value 0.000771946\nAdd  ZN                             with p-value 0.00465162\nresulting features:\n['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX', 'CHAS', 'B', 'ZN']\n"
                    ]
                ],
                "question_id:": "24405",
                "question_votes:": "9",
                "question_text:": "<p>I could not find a way to stepwise regression in scikit learn. I have checked all other posts on Stack Exchange on this topic. Answers to all of them suggests using f_regression.</p>\n\n<p>But f_regression does not do stepwise regression but only give F-score and pvalues corresponding to each of the regressors, which is only the first step in stepwise regression.</p>\n\n<p>What to do after 1st regressors with the best f-score is chosen?</p>\n",
                "tags": "<machine-learning><scikit-learn><regression><feature-selection><linear-regression>",
                "answers": [
                    [
                        "24447",
                        "2",
                        "24405",
                        "",
                        "",
                        "<p>Scikit-learn indeed does not support stepwise regression. That's because what is commonly known as 'stepwise regression' is an algorithm based on p-values of coefficients of linear regression, and scikit-learn deliberately avoids inferential approach to model learning (significance testing etc). Moreover, pure OLS is only one of numerous regression algorithms, and from the scikit-learn point of view it is neither very important, nor one of the best. </p>\n\n<p>There are, however, some pieces of advice for those who still need a good way for feature selection with linear models:</p>\n\n<ol>\n<li>Use inherently sparse models like <code>ElasticNet</code> or <code>Lasso</code>.</li>\n<li>Normalize your features with <code>StandardScaler</code>, and then order your features just by <code>model.coef_</code>. For perfectly independent covariates it is equivalent to sorting by p-values. The class <code>sklearn.feature_selection.RFE</code> will do it for you, and <code>RFECV</code> will even evaluate the optimal number of features.</li>\n<li>Use <a href=\"http://planspace.org/20150423-forward_selection_with_statsmodels/\" rel=\"noreferrer\">an implementation</a> of forward selection by adjusted $R^2$ that works with <code>statsmodels</code>.</li>\n<li>Do brute-force forward or backward selection to maximize your favorite metric on cross-validation (it could take approximately quadratic time in number of covariates). A scikit-learn compatible <code>mlxtend</code> package <a href=\"http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/\" rel=\"noreferrer\">supports</a> this approach for any estimator and any metric.</li>\n<li>If you still want vanilla stepwise regression, it is easier to base it on <code>statsmodels</code>, since this package calculates p-values for you. A basic forward-backward selection could look like this:</li>\n</ol>\n\n<p>```</p>\n\n<pre><code>from sklearn.datasets import load_boston\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\n\ndata = load_boston()\nX = pd.DataFrame(data.data, columns=data.feature_names)\ny = data.target\n\n\ndef stepwise_selection(X, y, \n                       initial_list=[], \n                       threshold_in=0.01, \n                       threshold_out = 0.05, \n                       verbose=True):\n    \"\"\" Perform a forward-backward feature selection \n    based on p-value from statsmodels.api.OLS\n    Arguments:\n        X - pandas.DataFrame with candidate features\n        y - list-like with the target\n        initial_list - list of features to start with (column names of X)\n        threshold_in - include a feature if its p-value &lt; threshold_in\n        threshold_out - exclude a feature if its p-value &gt; threshold_out\n        verbose - whether to print the sequence of inclusions and exclusions\n    Returns: list of selected features \n    Always set threshold_in &lt; threshold_out to avoid infinite looping.\n    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n    \"\"\"\n    included = list(initial_list)\n    while True:\n        changed=False\n        # forward step\n        excluded = list(set(X.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval &lt; threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n\n        # backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n        # use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() # null if pvalues is empty\n        if worst_pval &gt; threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n\nresult = stepwise_selection(X, y)\n\nprint('resulting features:')\nprint(result)\n</code></pre>\n\n<p>This example would print the following output:</p>\n\n<pre><code>Add  LSTAT                          with p-value 5.0811e-88\nAdd  RM                             with p-value 3.47226e-27\nAdd  PTRATIO                        with p-value 1.64466e-14\nAdd  DIS                            with p-value 1.66847e-05\nAdd  NOX                            with p-value 5.48815e-08\nAdd  CHAS                           with p-value 0.000265473\nAdd  B                              with p-value 0.000771946\nAdd  ZN                             with p-value 0.00465162\nresulting features:\n['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX', 'CHAS', 'B', 'ZN']\n</code></pre>\n",
                        "",
                        "10"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17933",
            "_score": 13.204033,
            "_source": {
                "title": "Error setting an array element with a sequence while using TfIdf Vectorirzer and train test split",
                "content": "Error setting an array element with a sequence while using TfIdf Vectorirzer and train test split <p>I am getting value error while trying to classify using TfidfVectorizer. I have looked in the link below but couldn't able to find a solution.</p>\n\n<p>[<a href=\"https://datascience.stackexchange.com/questions/38267/binary-text-classification-with-tfidfvectorizer-gives-valueerror-setting-an-arr][1]\">Binary text classification with TfidfVectorizer gives ValueError: setting an array element with a sequence</a></p>\n\n<p>The code is as below. I know it is because of train_test_split but no clue. please help.</p>\n\n<pre><code>from sklearn.feature_extraction.text import TfidfVectorizer\ntf_idf=TfidfVectorizer(stop_words='english',strip_accents='ascii',max_features=500)\n\ntf_idf_matrix=tf_idf.fit_transform(data['Text'])\n\ndata_extra_features=pd.concat([data,pd.DataFrame(tf_idf_matrix.toarray(),columns=tf_idf.get_feature_names())],axis=1)\nfrom sklearn.model_selection import train_test_split\nX=data_extra_features\nfeatures=X.columns.drop(['Value','Text'])\ntarget=['Value']\nX_train,X_test,y_train,y_test=train_test_split(X[features],X[target])\n\n#Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\n\ndef model_accuray(model,X_train,X_test,y_train,y_test):\n\n    model.fit(X_train,y_train)\n    pred=dt.predict(X_test)\n    print('Traning accurarcy',accuracy_score(y_train,dt.preditct(X_train)))\n    print('Testing accurarcy',accuracy_score(y_test,pred))\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\n#NaiveBayes model\n\nmb=MultinomialNB()\nlr=LogisticRegression()\ndt=DecisionTreeClassifier(min_samples_split=40)\n\n# model_accuray(mb,X_train,X_test,y_train,y_test)\n# model_accuray(lr,X_train,X_test,y_train,y_test)\nmodel_accuray(dt,X_train,X_test,y_train,y_test)\n</code></pre>\n <nlp>",
                "codes": [],
                "question_id:": "57324",
                "question_votes:": "",
                "question_text:": "<p>I am getting value error while trying to classify using TfidfVectorizer. I have looked in the link below but couldn't able to find a solution.</p>\n\n<p>[<a href=\"https://datascience.stackexchange.com/questions/38267/binary-text-classification-with-tfidfvectorizer-gives-valueerror-setting-an-arr][1]\">Binary text classification with TfidfVectorizer gives ValueError: setting an array element with a sequence</a></p>\n\n<p>The code is as below. I know it is because of train_test_split but no clue. please help.</p>\n\n<pre><code>from sklearn.feature_extraction.text import TfidfVectorizer\ntf_idf=TfidfVectorizer(stop_words='english',strip_accents='ascii',max_features=500)\n\ntf_idf_matrix=tf_idf.fit_transform(data['Text'])\n\ndata_extra_features=pd.concat([data,pd.DataFrame(tf_idf_matrix.toarray(),columns=tf_idf.get_feature_names())],axis=1)\nfrom sklearn.model_selection import train_test_split\nX=data_extra_features\nfeatures=X.columns.drop(['Value','Text'])\ntarget=['Value']\nX_train,X_test,y_train,y_test=train_test_split(X[features],X[target])\n\n#Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\n\ndef model_accuray(model,X_train,X_test,y_train,y_test):\n\n    model.fit(X_train,y_train)\n    pred=dt.predict(X_test)\n    print('Traning accurarcy',accuracy_score(y_train,dt.preditct(X_train)))\n    print('Testing accurarcy',accuracy_score(y_test,pred))\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\n#NaiveBayes model\n\nmb=MultinomialNB()\nlr=LogisticRegression()\ndt=DecisionTreeClassifier(min_samples_split=40)\n\n# model_accuray(mb,X_train,X_test,y_train,y_test)\n# model_accuray(lr,X_train,X_test,y_train,y_test)\nmodel_accuray(dt,X_train,X_test,y_train,y_test)\n</code></pre>\n",
                "tags": "<nlp>",
                "answers": []
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "1402",
            "_score": 13.182159,
            "_source": {
                "title": "Python library for segmented regression (a.k.a. piecewise regression)",
                "content": "Python library for segmented regression (a.k.a. piecewise regression) <p>I am looking for a Python library that can perform <a href=\"https://en.wikipedia.org/wiki/Segmented_regression#Segmented_linear_regression.2C_two_segments\" rel=\"noreferrer\">segmented regression (a.k.a. piecewise regression)</a>.</p>\n\n<p><a href=\"https://onlinecourses.science.psu.edu/stat501/node/310\" rel=\"noreferrer\">Example</a>:</p>\n\n<p><a href=\"https://i.stack.imgur.com/ZNoPv.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/ZNoPv.png\" alt=\"enter image description here\"></a></p>\n <python><linear-regression><library><software-recommendation><p>The method proposed by Vito M. R. Muggeo[1] is relatively simple and efficient. It works for a specified number of segments, and for a continuous function. \n<strong>The positions of the breakpoints are iteratively estimated</strong> by performing, for each iteration, a segmented linear regression allowing jumps at the breakpoints. From the values of the jumps, the next breakpoint positions are deduced, until there are no more discontinuity (jumps).</p>\n\n<blockquote>\n  <p>\"the process is iterated until possible convergence, which is not, in\n  general, guaranteed\"</p>\n</blockquote>\n\n<p>In particular, the convergence or the result may depends on the first estimation of the breakpoints.</p>\n\n<p>This is the method used in the R <a href=\"https://cran.r-project.org/web/packages/segmented/segmented.pdf\" rel=\"nofollow noreferrer\">Segmented package</a>.</p>\n\n<p>Here is an implementation in python:</p>\n\n\n\n<pre><code>import numpy as np\nfrom numpy.linalg import lstsq\n\nramp = lambda u: np.maximum( u, 0 )\nstep = lambda u: ( u &gt; 0 ).astype(float)\n\ndef SegmentedLinearReg( X, Y, breakpoints ):\n    nIterationMax = 10\n\n    breakpoints = np.sort( np.array(breakpoints) )\n\n    dt = np.min( np.diff(X) )\n    ones = np.ones_like(X)\n\n    for i in range( nIterationMax ):\n        # Linear regression:  solve A*p = Y\n        Rk = [ramp( X - xk ) for xk in breakpoints ]\n        Sk = [step( X - xk ) for xk in breakpoints ]\n        A = np.array([ ones, X ] + Rk + Sk )\n        p =  lstsq(A.transpose(), Y, rcond=None)[0] \n\n        # Parameters identification:\n        a, b = p[0:2]\n        ck = p[ 2:2+len(breakpoints) ]\n        dk = p[ 2+len(breakpoints): ]\n\n        # Estimation of the next break-points:\n        newBreakpoints = breakpoints - dk/ck \n\n        # Stop condition\n        if np.max(np.abs(newBreakpoints - breakpoints)) &lt; dt/5:\n            break\n\n        breakpoints = newBreakpoints\n    else:\n        print( 'maximum iteration reached' )\n\n    # Compute the final segmented fit:\n    Xsolution = np.insert( np.append( breakpoints, max(X) ), 0, min(X) )\n    ones =  np.ones_like(Xsolution) \n    Rk = [ c*ramp( Xsolution - x0 ) for x0, c in zip(breakpoints, ck) ]\n\n    Ysolution = a*ones + b*Xsolution + np.sum( Rk, axis=0 )\n\n    return Xsolution, Ysolution\n</code></pre>\n\n<p>Example:\n</p>\n\n<pre><code>import matplotlib.pyplot as plt\n\nX = np.linspace( 0, 10, 27 )\nY = 0.2*X  - 0.3* ramp(X-2) + 0.3*ramp(X-6) + 0.05*np.random.randn(len(X))\nplt.plot( X, Y, 'ok' );\n\ninitialBreakpoints = [1, 7]\nplt.plot( *SegmentedLinearReg( X, Y, initialBreakpoints ), '-r' );\nplt.xlabel('X'); plt.ylabel('Y');\n</code></pre>\n\n<p><img src=\"https://i.stack.imgur.com/3BWJz.png\" alt=\"graph\"></p>\n\n<p>[1]: Muggeo, V. M. (2003). Estimating regression models with unknown  breakpoints. Statistics in medicine, 22(19), 3055-3071.</p>\n<p>There is a <a href=\"https://www.datadoghq.com/blog/engineering/piecewise-regression/\" rel=\"nofollow noreferrer\">blog post</a> with a recursive implementation of piecewise regression. That solution fits discontinuous regression.</p>\n\n<p>If you are unsatisfied with discontinuous model and want continuous seting, I would propose to look for your curve in a basis of <code>k</code> L-shaped curves, using Lasso for sparsity:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import Lasso\n# generate data\nnp.random.seed(42)\nx = np.sort(np.random.normal(size=100))\ny_expected = 3 + 0.5 * x + 1.25 * x * (x&gt;0)\ny = y_expected + np.random.normal(size=x.size, scale=0.5)\n# prepare a basis\nk = 10\nthresholds = np.percentile(x, np.linspace(0, 1, k+2)[1:-1]*100)\nbasis = np.hstack([x[:, np.newaxis],  np.maximum(0,  np.column_stack([x]*k)-thresholds)]) \n# fit a model\nmodel = Lasso(0.03).fit(basis, y)\nprint(model.intercept_)\nprint(model.coef_.round(3))\nplt.scatter(x, y)\nplt.plot(x, y_expected, color = 'b')\nplt.plot(x, model.predict(basis), color='k')\nplt.legend(['true', 'predicted'])\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('fitting segmented regression')\nplt.show()\n</code></pre>\n\n<p>This code will return a vector of estimated coefficients to you:</p>\n\n<pre><code>[ 0.57   0.     0.     0.     0.     0.825  0.     0.     0.     0.     0.   ]\n</code></pre>\n\n<p>Due to Lasso approach, it is sparse: the model found exactly one breakpoint among 10 possible. Numbers 0.57 and 0.825 correspond to 0.5 and 1.25 in the true DGP. Although they are not very close, the fitted curves are:</p>\n\n<p><a href=\"https://i.stack.imgur.com/swltL.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/swltL.png\" alt=\"enter image description here\"></a></p>\n\n<p>This approach does not allow you to estimate the breakpoint exactly. But if your dataset is large enough, you can play with different <code>k</code> (maybe tune it by cross-validation) and estimate the breakpoint precisely enough.</p>\n<p><code>numpy.piecewise</code> can do this.</p>\n\n<blockquote>\n  <p>piecewise(x, condlist, funclist, *args, **kw)</p>\n  \n  <p>Evaluate a piecewise-defined function.</p>\n  \n  <p>Given a set of conditions and corresponding functions, evaluate each\n      function on the input data wherever its condition is true.</p>\n</blockquote>\n\n<p>An example is given on SO <a href=\"https://stackoverflow.com/questions/29382903/how-to-apply-piecewise-linear-fit-in-python\">here</a>. For completeness, here is an example:</p>\n\n<pre><code>from scipy import optimize\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ,11, 12, 13, 14, 15], dtype=float)\ny = np.array([5, 7, 9, 11, 13, 15, 28.92, 42.81, 56.7, 70.59, 84.47, 98.36, 112.25, 126.14, 140.03])\n\ndef piecewise_linear(x, x0, y0, k1, k2):\n    return np.piecewise(x, [x &lt; x0, x &gt;= x0], [lambda x:k1*x + y0-k1*x0, lambda x:k2*x + y0-k2*x0])\n\np , e = optimize.curve_fit(piecewise_linear, x, y)\nxd = np.linspace(0, 15, 100)\nplt.plot(x, y, \"o\")\nplt.plot(xd, piecewise_linear(xd, *p))\n</code></pre>\n<p>I've been looking for the same thing, and unfortunately it seems like there isn't one at this time. Some suggestions for how to proceed can be found in this <a href=\"https://datascience.stackexchange.com/questions/8266/is-there-a-library-that-would-perform-segmented-linear-regression-in-python\">previous question</a>. </p>\n\n<p>Alternatively you could look into some R libraries eg segmented, SiZer, strucchange, and if something there works for you try embedding the R code in python with <a href=\"http://rpy.sourceforge.net/\" rel=\"nofollow noreferrer\">rpy2</a>.</p>\n\n<p>Editing to add a link to <a href=\"https://github.com/jcrudy/py-earth\" rel=\"nofollow noreferrer\">py-earth</a>, \"A Python implementation of Jerome Friedman's Multivariate Adaptive Regression Splines\". </p>\n",
                "codes": [
                    [
                        "import numpy as np\nfrom numpy.linalg import lstsq\n\nramp = lambda u: np.maximum( u, 0 )\nstep = lambda u: ( u > 0 ).astype(float)\n\ndef SegmentedLinearReg( X, Y, breakpoints ):\n    nIterationMax = 10\n\n    breakpoints = np.sort( np.array(breakpoints) )\n\n    dt = np.min( np.diff(X) )\n    ones = np.ones_like(X)\n\n    for i in range( nIterationMax ):\n        # Linear regression:  solve A*p = Y\n        Rk = [ramp( X - xk ) for xk in breakpoints ]\n        Sk = [step( X - xk ) for xk in breakpoints ]\n        A = np.array([ ones, X ] + Rk + Sk )\n        p =  lstsq(A.transpose(), Y, rcond=None)[0] \n\n        # Parameters identification:\n        a, b = p[0:2]\n        ck = p[ 2:2+len(breakpoints) ]\n        dk = p[ 2+len(breakpoints): ]\n\n        # Estimation of the next break-points:\n        newBreakpoints = breakpoints - dk/ck \n\n        # Stop condition\n        if np.max(np.abs(newBreakpoints - breakpoints)) < dt/5:\n            break\n\n        breakpoints = newBreakpoints\n    else:\n        print( 'maximum iteration reached' )\n\n    # Compute the final segmented fit:\n    Xsolution = np.insert( np.append( breakpoints, max(X) ), 0, min(X) )\n    ones =  np.ones_like(Xsolution) \n    Rk = [ c*ramp( Xsolution - x0 ) for x0, c in zip(breakpoints, ck) ]\n\n    Ysolution = a*ones + b*Xsolution + np.sum( Rk, axis=0 )\n\n    return Xsolution, Ysolution\n",
                        "import matplotlib.pyplot as plt\n\nX = np.linspace( 0, 10, 27 )\nY = 0.2*X  - 0.3* ramp(X-2) + 0.3*ramp(X-6) + 0.05*np.random.randn(len(X))\nplt.plot( X, Y, 'ok' );\n\ninitialBreakpoints = [1, 7]\nplt.plot( *SegmentedLinearReg( X, Y, initialBreakpoints ), '-r' );\nplt.xlabel('X'); plt.ylabel('Y');\n"
                    ],
                    [
                        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import Lasso\n# generate data\nnp.random.seed(42)\nx = np.sort(np.random.normal(size=100))\ny_expected = 3 + 0.5 * x + 1.25 * x * (x>0)\ny = y_expected + np.random.normal(size=x.size, scale=0.5)\n# prepare a basis\nk = 10\nthresholds = np.percentile(x, np.linspace(0, 1, k+2)[1:-1]*100)\nbasis = np.hstack([x[:, np.newaxis],  np.maximum(0,  np.column_stack([x]*k)-thresholds)]) \n# fit a model\nmodel = Lasso(0.03).fit(basis, y)\nprint(model.intercept_)\nprint(model.coef_.round(3))\nplt.scatter(x, y)\nplt.plot(x, y_expected, color = 'b')\nplt.plot(x, model.predict(basis), color='k')\nplt.legend(['true', 'predicted'])\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('fitting segmented regression')\nplt.show()\n",
                        "[ 0.57   0.     0.     0.     0.     0.825  0.     0.     0.     0.     0.   ]\n"
                    ],
                    [
                        "from scipy import optimize\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ,11, 12, 13, 14, 15], dtype=float)\ny = np.array([5, 7, 9, 11, 13, 15, 28.92, 42.81, 56.7, 70.59, 84.47, 98.36, 112.25, 126.14, 140.03])\n\ndef piecewise_linear(x, x0, y0, k1, k2):\n    return np.piecewise(x, [x < x0, x >= x0], [lambda x:k1*x + y0-k1*x0, lambda x:k2*x + y0-k2*x0])\n\np , e = optimize.curve_fit(piecewise_linear, x, y)\nxd = np.linspace(0, 15, 100)\nplt.plot(x, y, \"o\")\nplt.plot(xd, piecewise_linear(xd, *p))\n"
                    ],
                    []
                ],
                "question_id:": "8457",
                "question_votes:": "16",
                "question_text:": "<p>I am looking for a Python library that can perform <a href=\"https://en.wikipedia.org/wiki/Segmented_regression#Segmented_linear_regression.2C_two_segments\" rel=\"noreferrer\">segmented regression (a.k.a. piecewise regression)</a>.</p>\n\n<p><a href=\"https://onlinecourses.science.psu.edu/stat501/node/310\" rel=\"noreferrer\">Example</a>:</p>\n\n<p><a href=\"https://i.stack.imgur.com/ZNoPv.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/ZNoPv.png\" alt=\"enter image description here\"></a></p>\n",
                "tags": "<python><linear-regression><library><software-recommendation>",
                "answers": [
                    [
                        "32833",
                        "2",
                        "8457",
                        "",
                        "",
                        "<p>The method proposed by Vito M. R. Muggeo[1] is relatively simple and efficient. It works for a specified number of segments, and for a continuous function. \n<strong>The positions of the breakpoints are iteratively estimated</strong> by performing, for each iteration, a segmented linear regression allowing jumps at the breakpoints. From the values of the jumps, the next breakpoint positions are deduced, until there are no more discontinuity (jumps).</p>\n\n<blockquote>\n  <p>\"the process is iterated until possible convergence, which is not, in\n  general, guaranteed\"</p>\n</blockquote>\n\n<p>In particular, the convergence or the result may depends on the first estimation of the breakpoints.</p>\n\n<p>This is the method used in the R <a href=\"https://cran.r-project.org/web/packages/segmented/segmented.pdf\" rel=\"nofollow noreferrer\">Segmented package</a>.</p>\n\n<p>Here is an implementation in python:</p>\n\n\n\n<pre><code>import numpy as np\nfrom numpy.linalg import lstsq\n\nramp = lambda u: np.maximum( u, 0 )\nstep = lambda u: ( u &gt; 0 ).astype(float)\n\ndef SegmentedLinearReg( X, Y, breakpoints ):\n    nIterationMax = 10\n\n    breakpoints = np.sort( np.array(breakpoints) )\n\n    dt = np.min( np.diff(X) )\n    ones = np.ones_like(X)\n\n    for i in range( nIterationMax ):\n        # Linear regression:  solve A*p = Y\n        Rk = [ramp( X - xk ) for xk in breakpoints ]\n        Sk = [step( X - xk ) for xk in breakpoints ]\n        A = np.array([ ones, X ] + Rk + Sk )\n        p =  lstsq(A.transpose(), Y, rcond=None)[0] \n\n        # Parameters identification:\n        a, b = p[0:2]\n        ck = p[ 2:2+len(breakpoints) ]\n        dk = p[ 2+len(breakpoints): ]\n\n        # Estimation of the next break-points:\n        newBreakpoints = breakpoints - dk/ck \n\n        # Stop condition\n        if np.max(np.abs(newBreakpoints - breakpoints)) &lt; dt/5:\n            break\n\n        breakpoints = newBreakpoints\n    else:\n        print( 'maximum iteration reached' )\n\n    # Compute the final segmented fit:\n    Xsolution = np.insert( np.append( breakpoints, max(X) ), 0, min(X) )\n    ones =  np.ones_like(Xsolution) \n    Rk = [ c*ramp( Xsolution - x0 ) for x0, c in zip(breakpoints, ck) ]\n\n    Ysolution = a*ones + b*Xsolution + np.sum( Rk, axis=0 )\n\n    return Xsolution, Ysolution\n</code></pre>\n\n<p>Example:\n</p>\n\n<pre><code>import matplotlib.pyplot as plt\n\nX = np.linspace( 0, 10, 27 )\nY = 0.2*X  - 0.3* ramp(X-2) + 0.3*ramp(X-6) + 0.05*np.random.randn(len(X))\nplt.plot( X, Y, 'ok' );\n\ninitialBreakpoints = [1, 7]\nplt.plot( *SegmentedLinearReg( X, Y, initialBreakpoints ), '-r' );\nplt.xlabel('X'); plt.ylabel('Y');\n</code></pre>\n\n<p><img src=\"https://i.stack.imgur.com/3BWJz.png\" alt=\"graph\"></p>\n\n<p>[1]: Muggeo, V. M. (2003). Estimating regression models with unknown  breakpoints. Statistics in medicine, 22(19), 3055-3071.</p>\n",
                        "",
                        "4"
                    ],
                    [
                        "24862",
                        "2",
                        "8457",
                        "",
                        "",
                        "<p>There is a <a href=\"https://www.datadoghq.com/blog/engineering/piecewise-regression/\" rel=\"nofollow noreferrer\">blog post</a> with a recursive implementation of piecewise regression. That solution fits discontinuous regression.</p>\n\n<p>If you are unsatisfied with discontinuous model and want continuous seting, I would propose to look for your curve in a basis of <code>k</code> L-shaped curves, using Lasso for sparsity:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import Lasso\n# generate data\nnp.random.seed(42)\nx = np.sort(np.random.normal(size=100))\ny_expected = 3 + 0.5 * x + 1.25 * x * (x&gt;0)\ny = y_expected + np.random.normal(size=x.size, scale=0.5)\n# prepare a basis\nk = 10\nthresholds = np.percentile(x, np.linspace(0, 1, k+2)[1:-1]*100)\nbasis = np.hstack([x[:, np.newaxis],  np.maximum(0,  np.column_stack([x]*k)-thresholds)]) \n# fit a model\nmodel = Lasso(0.03).fit(basis, y)\nprint(model.intercept_)\nprint(model.coef_.round(3))\nplt.scatter(x, y)\nplt.plot(x, y_expected, color = 'b')\nplt.plot(x, model.predict(basis), color='k')\nplt.legend(['true', 'predicted'])\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('fitting segmented regression')\nplt.show()\n</code></pre>\n\n<p>This code will return a vector of estimated coefficients to you:</p>\n\n<pre><code>[ 0.57   0.     0.     0.     0.     0.825  0.     0.     0.     0.     0.   ]\n</code></pre>\n\n<p>Due to Lasso approach, it is sparse: the model found exactly one breakpoint among 10 possible. Numbers 0.57 and 0.825 correspond to 0.5 and 1.25 in the true DGP. Although they are not very close, the fitted curves are:</p>\n\n<p><a href=\"https://i.stack.imgur.com/swltL.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/swltL.png\" alt=\"enter image description here\"></a></p>\n\n<p>This approach does not allow you to estimate the breakpoint exactly. But if your dataset is large enough, you can play with different <code>k</code> (maybe tune it by cross-validation) and estimate the breakpoint precisely enough.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "17584",
                        "2",
                        "8457",
                        "",
                        "",
                        "<p><code>numpy.piecewise</code> can do this.</p>\n\n<blockquote>\n  <p>piecewise(x, condlist, funclist, *args, **kw)</p>\n  \n  <p>Evaluate a piecewise-defined function.</p>\n  \n  <p>Given a set of conditions and corresponding functions, evaluate each\n      function on the input data wherever its condition is true.</p>\n</blockquote>\n\n<p>An example is given on SO <a href=\"https://stackoverflow.com/questions/29382903/how-to-apply-piecewise-linear-fit-in-python\">here</a>. For completeness, here is an example:</p>\n\n<pre><code>from scipy import optimize\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ,11, 12, 13, 14, 15], dtype=float)\ny = np.array([5, 7, 9, 11, 13, 15, 28.92, 42.81, 56.7, 70.59, 84.47, 98.36, 112.25, 126.14, 140.03])\n\ndef piecewise_linear(x, x0, y0, k1, k2):\n    return np.piecewise(x, [x &lt; x0, x &gt;= x0], [lambda x:k1*x + y0-k1*x0, lambda x:k2*x + y0-k2*x0])\n\np , e = optimize.curve_fit(piecewise_linear, x, y)\nxd = np.linspace(0, 15, 100)\nplt.plot(x, y, \"o\")\nplt.plot(xd, piecewise_linear(xd, *p))\n</code></pre>\n",
                        "",
                        "6"
                    ],
                    [
                        "8472",
                        "2",
                        "8457",
                        "",
                        "",
                        "<p>I've been looking for the same thing, and unfortunately it seems like there isn't one at this time. Some suggestions for how to proceed can be found in this <a href=\"https://datascience.stackexchange.com/questions/8266/is-there-a-library-that-would-perform-segmented-linear-regression-in-python\">previous question</a>. </p>\n\n<p>Alternatively you could look into some R libraries eg segmented, SiZer, strucchange, and if something there works for you try embedding the R code in python with <a href=\"http://rpy.sourceforge.net/\" rel=\"nofollow noreferrer\">rpy2</a>.</p>\n\n<p>Editing to add a link to <a href=\"https://github.com/jcrudy/py-earth\" rel=\"nofollow noreferrer\">py-earth</a>, \"A Python implementation of Jerome Friedman's Multivariate Adaptive Regression Splines\". </p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12033",
            "_score": 13.150242,
            "_source": {
                "title": "too few data while too many degrees of freedom in linear regression",
                "content": "too few data while too many degrees of freedom in linear regression <p>To recognize handwritten digits, I have a fully connected network, containing only 2 layers: input layer (all pixels of the image) and output layer (0 or 1). I use the simplest linear regression for training (with gradient descent) and got excellent results.</p>\n\n<p>However, I just realized that my model had far more degrees of freedom than data points. Say the data are all n<em>n pixel pictures to recognize, so the number of degrees of freedom is n</em>n+1. I use n=50, but I only use less than 20 data points (20 training pictures). From the point of view of linear fitting/regression, the number of data points should at least surpass that of degrees of freedom. But now in my model the reverse happens, no solution should be found. What happened</p>\n <linear-regression><gradient-descent><p>Good question. The solution lies in understanding how weights play into the model's prediction. I've glossed over a bunch of issues here, but the big picture is what is most important.</p>\n\n<p><strong>Theory</strong></p>\n\n<ol>\n<li>When you create a model all the weights are psuedo-randomly initialized. This solves your problem of not having enough degrees of freedom to solve a linear regression. We've interpolated our weights and our model will update only the weights it needs as it trains. </li>\n<li>Additionally, your model will probably find that most of your weights converge to zero. If you are using sklearn's <code>load_digits()</code> function, I recall that about half of each image was just white pixels. It is likely that there is a significant percentage of pixels that do not matter across all images (and thus might be assigned a weight of zero). Your question of how can you trust the prediction of the model is thus answered and we can modify our statement about degrees of freedom to: <em>There cannot exist a greater number of discovered statistical trends than there are data samples</em>. It is hard to measure \"number of discovered statistical trends\", but it follows that there is a finite number and that they are less than the number of samples minus 1.</li>\n</ol>\n\n<p><strong>Example</strong></p>\n\n<p>With a fully-connected, shallow neural network consisting of the input layer with weights and an output layer with two neurons, the input to the activation function of each of the output neurons will be something like the following:</p>\n\n<p><span class=\"math-container\">$$f(B_1+\\sum_{i=1}^{i}W_i*{I_i}_A)=P$$</span></p>\n\n<p>where </p>\n\n<ol>\n<li><span class=\"math-container\">$P$</span> is the class probability, </li>\n<li><span class=\"math-container\">$B_1$</span> is the bias of the output layer, </li>\n<li><span class=\"math-container\">$W_i$</span> is the weight of a specific neuronal connection, </li>\n<li><span class=\"math-container\">${I_i}_A$</span> is the output of the connected neuron if activated (in this case the pixel value), and </li>\n<li><span class=\"math-container\">$f()$</span> is the activation function of the output layer neuron.</li>\n</ol>\n\n<p>If we didn't initialize <span class=\"math-container\">$W_i$</span> to something/anything, we would be unable to solve the equation (more variables than samples). However, by randomly initializing them, the equation immediately becomes solvable and we can use stochastic gradient descent or a different algorithm to optimize our weights. I hope this shows how pseudo-randomly initializing <span class=\"math-container\">$W_i$</span> solves the mathematical problem of degrees of freedom.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "42322",
                "question_votes:": "4",
                "question_text:": "<p>To recognize handwritten digits, I have a fully connected network, containing only 2 layers: input layer (all pixels of the image) and output layer (0 or 1). I use the simplest linear regression for training (with gradient descent) and got excellent results.</p>\n\n<p>However, I just realized that my model had far more degrees of freedom than data points. Say the data are all n<em>n pixel pictures to recognize, so the number of degrees of freedom is n</em>n+1. I use n=50, but I only use less than 20 data points (20 training pictures). From the point of view of linear fitting/regression, the number of data points should at least surpass that of degrees of freedom. But now in my model the reverse happens, no solution should be found. What happened</p>\n",
                "tags": "<linear-regression><gradient-descent>",
                "answers": [
                    [
                        "44791",
                        "2",
                        "42322",
                        "",
                        "",
                        "<p>Good question. The solution lies in understanding how weights play into the model's prediction. I've glossed over a bunch of issues here, but the big picture is what is most important.</p>\n\n<p><strong>Theory</strong></p>\n\n<ol>\n<li>When you create a model all the weights are psuedo-randomly initialized. This solves your problem of not having enough degrees of freedom to solve a linear regression. We've interpolated our weights and our model will update only the weights it needs as it trains. </li>\n<li>Additionally, your model will probably find that most of your weights converge to zero. If you are using sklearn's <code>load_digits()</code> function, I recall that about half of each image was just white pixels. It is likely that there is a significant percentage of pixels that do not matter across all images (and thus might be assigned a weight of zero). Your question of how can you trust the prediction of the model is thus answered and we can modify our statement about degrees of freedom to: <em>There cannot exist a greater number of discovered statistical trends than there are data samples</em>. It is hard to measure \"number of discovered statistical trends\", but it follows that there is a finite number and that they are less than the number of samples minus 1.</li>\n</ol>\n\n<p><strong>Example</strong></p>\n\n<p>With a fully-connected, shallow neural network consisting of the input layer with weights and an output layer with two neurons, the input to the activation function of each of the output neurons will be something like the following:</p>\n\n<p><span class=\"math-container\">$$f(B_1+\\sum_{i=1}^{i}W_i*{I_i}_A)=P$$</span></p>\n\n<p>where </p>\n\n<ol>\n<li><span class=\"math-container\">$P$</span> is the class probability, </li>\n<li><span class=\"math-container\">$B_1$</span> is the bias of the output layer, </li>\n<li><span class=\"math-container\">$W_i$</span> is the weight of a specific neuronal connection, </li>\n<li><span class=\"math-container\">${I_i}_A$</span> is the output of the connected neuron if activated (in this case the pixel value), and </li>\n<li><span class=\"math-container\">$f()$</span> is the activation function of the output layer neuron.</li>\n</ol>\n\n<p>If we didn't initialize <span class=\"math-container\">$W_i$</span> to something/anything, we would be unable to solve the equation (more variables than samples). However, by randomly initializing them, the equation immediately becomes solvable and we can use stochastic gradient descent or a different algorithm to optimize our weights. I hope this shows how pseudo-randomly initializing <span class=\"math-container\">$W_i$</span> solves the mathematical problem of degrees of freedom.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "273",
            "_score": 13.14859,
            "_source": {
                "title": "SVM using scikit learn runs endlessly and never completes execution",
                "content": "SVM using scikit learn runs endlessly and never completes execution <p>I am trying to run SVR using scikit learn ( python ) on a training dataset having 595605 rows and 5 columns(features) and test dataset having 397070 rows. The data has been pre-processed and regularized.</p>\n\n<p>I am able to successfully run the test examples but on executing using my dataset and letting it run for over an hour, I could still not see any output or termination of program. I have tried executing using a different IDE and even from terminal but that doesn't seem to be the issue.\nI have also tried changing the 'C' parameter value from 1 to 1e3.</p>\n\n<p>I am facing similar issues with all svm implementations using scikit.</p>\n\n<p>Am I not waiting enough for it to complete ?\nHow much time should this execution take ?</p>\n\n<p>From my experience it shouldn't require over a few minutes.</p>\n\n<p>Here is my system configuration:\nUbuntu 14.04, 8GB RAM, lots of free memory, 4th gen i7 processor</p>\n <python><svm><scikit-learn><p>Leave it to run overnight or better for 24 hours. \nWhat is your CPU utilization? If none of the cores is running at 100% then you have a problem. Probably with memory. Have you checked whether your dataset fits into 8GB at all?\nHave you tried the SGDClassifier? It is one of the fastest there. Worth giving it a try first hoping it completes in an hour or so.</p>\n<p>Did you include scaling in your pre-processing step? I had this issue when running my SVM. My dataset is ~780,000 samples (row) with 20 features (col). My training set is ~235k samples. It turns out that I just forgot to scale my data! If this is the case, try adding this bit to your code:</p>\n\n<p><strong>scale data to [-1,1] ; increase SVM speed:</strong>   </p>\n\n<blockquote>\n  <p>from sklearn.preprocessing import MinMaxScaler<br>\n  scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)<br>\n  X_train = scaling.transform(X_train)<br>\n  X_test = scaling.transform(X_test)<br></p>\n</blockquote>\n<p>I have encountered this issue and <code>cache_size</code> as others are suggesting does not help at all. You can see <a href=\"https://github.com/scikit-learn/scikit-learn/issues/8012\" rel=\"nofollow noreferrer\">this post</a> and <a href=\"https://github.com/cjlin1/libsvm/issues/80\" rel=\"nofollow noreferrer\">this one</a> as the main contributor suggested that you should change the code manually. </p>\n\n<p>As you know, <code>SVC</code> and <code>SVR</code> are optimization problems and they stop when the error margin is so little where the further optimization is futile. So there is another parameter in these, <code>max_iter</code>, where you can set how many iterations it should do.</p>\n\n<p>I have used <code>sklearn</code> in python and <code>e1071</code> in R and R is much faster getting to the result without setting the <code>max_iter</code> and <code>sklearn</code> takes 2-4 times longer. The only way that I could bring down the computation time for python was using <code>max_iter</code>. It is relative to the complexity of your model, number of features, kernels and hyperparameters, but for small dataset I used for around 4000 datapoint and <code>max_iter</code> was <code>10000</code> the results were not different at all and it was acceptable.</p>\n<p>Try normalising the data to [-1,1]. I faced a similar problem and upon normalisation everything worked fine. You can normalise data easily using :</p>\n\n<p><code>from sklearn import preprocessing\nX_train = preprocessing.scale(X_train)\nX_test = preprocessing.scale(X_test)</code></p>\n<p>With such a huge dataset I think you'd be better off using a neural network, deep learning, random forest (they are surprisingly good), etc. </p>\n\n<p>As mentioned in earlier replies, the time taken is proportional to the third power of the number of training samples. Even the prediction time is polynomial in terms of number of test vectors.</p>\n\n<p>If you really must use SVM then I'd recommend using GPU speed up or reducing the training dataset size. Try with a sample (10,000 rows maybe) of the data first to see whether it's not an issue with the data format or distribution. </p>\n\n<p>As mentioned in other replies, linear kernels are faster.</p>\n<p>You need to scale your data. Scaling will normalize your data points to -1 to 1 range, which will help in faster convergence.</p>\n\n<p>Try using following code:</p>\n\n<pre><code># X is your numpy data array.\n\nfrom sklearn import preprocessing\n\nX = preprocessing.scale(X)\n</code></pre>\n<p>I recently encountered similar problem because forgot to scale features in my dataset which was earlier used to train ensemble model kind. Failure to scale the data may be the likely culprit as pointed by Shelby Matlock. You may try different scalers available in  sklearn, such as <a href=\"http://scikit-learn.org/stable/auto_examples/preprocessing/plot_robust_scaling.html\" rel=\"nofollow noreferrer\">RobustScaler</a>:</p>\n\n<p><code>from sklearn.preprocessing import RobustScaler\n scaler = RobustScaler()\n X = scaler.fit_transfrom(X)</code></p>\n\n<p>X is now transformed/scaled and ready to be fed to your desired model.</p>\n<p>This makes sense. IIUC, the speed of execution of support vector operations is bound by number of samples, not dimensionality. In other words, it is capped by CPU time and not RAM. I'm not sure exactly how much time this should take, but I'm running some benchmarks to find out.</p>\n<p>Kernelized SVMs require the computation of a distance function between each point in the dataset, which is the dominating cost of $\\mathcal{O}(n_\\text{features} \\times n_\\text{observations}^2)$. The storage of the distances is a burden on memory, so they're recomputed on the fly. Thankfully, only the points nearest the decision boundary are needed most of the time. Frequently computed distances are stored in a cache. If the cache is getting thrashed then the running time blows up to $\\mathcal{O}(n_\\text{features} \\times n_\\text{observations}^3)$.</p>\n\n<p>You can increase this cache by invoking SVR as</p>\n\n<pre><code>model = SVR(cache_size=7000)\n</code></pre>\n\n<p>In general, this is not going to work. But all is not lost. You can subsample the data and use the rest as a validation set, or you can pick a different model. Above the 200,000 observation range, it's wise to choose linear learners.</p>\n\n<p>Kernel SVM can be approximated, by approximating the kernel matrix and feeding it to a linear SVM. This allows you to trade off between accuracy and performance in linear time.</p>\n\n<p>A popular means of achieving this is to use 100 or so cluster centers found by kmeans/kmeans++ as the basis of your kernel function. The new derived features are then fed into a linear model. This works very well in practice. Tools like <a href=\"https://code.google.com/p/sofia-ml/\">sophia-ml</a> and <a href=\"https://github.com/JohnLangford/vowpal_wabbit/wiki\">vowpal wabbit</a> are how Google, Yahoo and Microsoft do this. Input/output becomes the dominating cost for simple linear learners.</p>\n\n<p>In the abundance of data, nonparametric models perform roughly the same for most problems. The exceptions being structured inputs, like text, images, time series, audio.</p>\n\n<h2>Further reading</h2>\n\n<ul>\n<li><a href=\"http://fastml.com/the-secret-of-the-big-guys/\">How to implement this.</a></li>\n<li><a href=\"http://fastml.com/go-non-linear-with-vowpal-wabbit/\">How to train an ngram neural network with dropout that scales linearly</a></li>\n<li><a href=\"http://peekaboo-vision.blogspot.co.uk/2012/12/kernel-approximations-for-efficient.html\">Kernel Approximations</a></li>\n<li><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.144.9009&amp;rep=rep1&amp;type=pdf\">A formal paper on using kmeans to approximate kernel machines</a></li>\n</ul>\n<p>I just had a similar issue with a dataset which contains only 115 elements and only one single feature (international airline data). The solution was to scale the data. What I missed in answers so far was the usage of a Pipeline:</p>\n\n<pre><code>from sklearn.svm import SVR\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nmodel = Pipeline([('scaler', StandardScaler()),\n                  ('svr', SVR(kernel='linear'))])\n</code></pre>\n\n<p>You can train <code>model</code> like a usual classification / regression model and evaluate it the same way. Nothing changes, only the definition of the model.</p>\n<p>SVM solves an optimization problem of quadratic order.</p>\n\n<p>I do not have anything to add that has not been said here. I just want to post a link the sklearn page about <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\" rel=\"noreferrer\">SVC</a> which clarifies what is going on:</p>\n\n<blockquote>\n  <p>The implementation is based on libsvm. The fit time complexity is more\n  than quadratic with the number of samples which makes it hard to scale\n  to dataset with more than a couple of 10000 samples.</p>\n</blockquote>\n\n<p>If you do not want to use kernels, and a linear SVM suffices, there is <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html\" rel=\"noreferrer\">LinearSVR</a> which is much faster because it uses an optimization approach ala linear regressions. You'll have to normalize your data though, in case you're not doing so already, because it applies regularization to the intercept coefficient, which is not probably what you want. It means if your data average is far from zero, it will not be able to solve it satisfactorily.</p>\n\n<p>What you can also use is stochastic gradient descent to solve the optimization problem. Sklearn features <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html\" rel=\"noreferrer\">SGDRegressor</a>. You have to use <code>loss='epsilon_insensitive'</code> to have similar results to linear SVM. See the documentation. I would only use gradient descent as a last resort though because it implies much tweaking of the hyperparameters in order to avoid getting stuck in local minima. Use <code>LinearSVR</code> if you can.</p>\n",
                "codes": [
                    [],
                    [],
                    [],
                    [
                        "from sklearn import preprocessing\nX_train = preprocessing.scale(X_train)\nX_test = preprocessing.scale(X_test)"
                    ],
                    [],
                    [
                        "# X is your numpy data array.\n\nfrom sklearn import preprocessing\n\nX = preprocessing.scale(X)\n"
                    ],
                    [
                        "from sklearn.preprocessing import RobustScaler\n scaler = RobustScaler()\n X = scaler.fit_transfrom(X)"
                    ],
                    [],
                    [
                        "model = SVR(cache_size=7000)\n"
                    ],
                    [
                        "from sklearn.svm import SVR\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nmodel = Pipeline([('scaler', StandardScaler()),\n                  ('svr', SVR(kernel='linear'))])\n"
                    ],
                    []
                ],
                "question_id:": "989",
                "question_votes:": "74",
                "question_text:": "<p>I am trying to run SVR using scikit learn ( python ) on a training dataset having 595605 rows and 5 columns(features) and test dataset having 397070 rows. The data has been pre-processed and regularized.</p>\n\n<p>I am able to successfully run the test examples but on executing using my dataset and letting it run for over an hour, I could still not see any output or termination of program. I have tried executing using a different IDE and even from terminal but that doesn't seem to be the issue.\nI have also tried changing the 'C' parameter value from 1 to 1e3.</p>\n\n<p>I am facing similar issues with all svm implementations using scikit.</p>\n\n<p>Am I not waiting enough for it to complete ?\nHow much time should this execution take ?</p>\n\n<p>From my experience it shouldn't require over a few minutes.</p>\n\n<p>Here is my system configuration:\nUbuntu 14.04, 8GB RAM, lots of free memory, 4th gen i7 processor</p>\n",
                "tags": "<python><svm><scikit-learn>",
                "answers": [
                    [
                        "10571",
                        "2",
                        "989",
                        "",
                        "",
                        "<p>Leave it to run overnight or better for 24 hours. \nWhat is your CPU utilization? If none of the cores is running at 100% then you have a problem. Probably with memory. Have you checked whether your dataset fits into 8GB at all?\nHave you tried the SGDClassifier? It is one of the fastest there. Worth giving it a try first hoping it completes in an hour or so.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "19975",
                        "2",
                        "989",
                        "",
                        "",
                        "<p>Did you include scaling in your pre-processing step? I had this issue when running my SVM. My dataset is ~780,000 samples (row) with 20 features (col). My training set is ~235k samples. It turns out that I just forgot to scale my data! If this is the case, try adding this bit to your code:</p>\n\n<p><strong>scale data to [-1,1] ; increase SVM speed:</strong>   </p>\n\n<blockquote>\n  <p>from sklearn.preprocessing import MinMaxScaler<br>\n  scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)<br>\n  X_train = scaling.transform(X_train)<br>\n  X_test = scaling.transform(X_test)<br></p>\n</blockquote>\n",
                        "",
                        "8"
                    ],
                    [
                        "52430",
                        "2",
                        "989",
                        "",
                        "",
                        "<p>I have encountered this issue and <code>cache_size</code> as others are suggesting does not help at all. You can see <a href=\"https://github.com/scikit-learn/scikit-learn/issues/8012\" rel=\"nofollow noreferrer\">this post</a> and <a href=\"https://github.com/cjlin1/libsvm/issues/80\" rel=\"nofollow noreferrer\">this one</a> as the main contributor suggested that you should change the code manually. </p>\n\n<p>As you know, <code>SVC</code> and <code>SVR</code> are optimization problems and they stop when the error margin is so little where the further optimization is futile. So there is another parameter in these, <code>max_iter</code>, where you can set how many iterations it should do.</p>\n\n<p>I have used <code>sklearn</code> in python and <code>e1071</code> in R and R is much faster getting to the result without setting the <code>max_iter</code> and <code>sklearn</code> takes 2-4 times longer. The only way that I could bring down the computation time for python was using <code>max_iter</code>. It is relative to the complexity of your model, number of features, kernels and hyperparameters, but for small dataset I used for around 4000 datapoint and <code>max_iter</code> was <code>10000</code> the results were not different at all and it was acceptable.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "24623",
                        "2",
                        "989",
                        "",
                        "",
                        "<p>Try normalising the data to [-1,1]. I faced a similar problem and upon normalisation everything worked fine. You can normalise data easily using :</p>\n\n<p><code>from sklearn import preprocessing\nX_train = preprocessing.scale(X_train)\nX_test = preprocessing.scale(X_test)</code></p>\n",
                        "",
                        "2"
                    ],
                    [
                        "10554",
                        "2",
                        "989",
                        "",
                        "",
                        "<p>With such a huge dataset I think you'd be better off using a neural network, deep learning, random forest (they are surprisingly good), etc. </p>\n\n<p>As mentioned in earlier replies, the time taken is proportional to the third power of the number of training samples. Even the prediction time is polynomial in terms of number of test vectors.</p>\n\n<p>If you really must use SVM then I'd recommend using GPU speed up or reducing the training dataset size. Try with a sample (10,000 rows maybe) of the data first to see whether it's not an issue with the data format or distribution. </p>\n\n<p>As mentioned in other replies, linear kernels are faster.</p>\n",
                        "",
                        "7"
                    ],
                    [
                        "16065",
                        "2",
                        "989",
                        "",
                        "",
                        "<p>You need to scale your data. Scaling will normalize your data points to -1 to 1 range, which will help in faster convergence.</p>\n\n<p>Try using following code:</p>\n\n<pre><code># X is your numpy data array.\n\nfrom sklearn import preprocessing\n\nX = preprocessing.scale(X)\n</code></pre>\n",
                        "",
                        "1"
                    ],
                    [
                        "20309",
                        "2",
                        "989",
                        "",
                        "",
                        "<p>I recently encountered similar problem because forgot to scale features in my dataset which was earlier used to train ensemble model kind. Failure to scale the data may be the likely culprit as pointed by Shelby Matlock. You may try different scalers available in  sklearn, such as <a href=\"http://scikit-learn.org/stable/auto_examples/preprocessing/plot_robust_scaling.html\" rel=\"nofollow noreferrer\">RobustScaler</a>:</p>\n\n<p><code>from sklearn.preprocessing import RobustScaler\n scaler = RobustScaler()\n X = scaler.fit_transfrom(X)</code></p>\n\n<p>X is now transformed/scaled and ready to be fed to your desired model.</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "990",
                        "2",
                        "989",
                        "",
                        "",
                        "<p>This makes sense. IIUC, the speed of execution of support vector operations is bound by number of samples, not dimensionality. In other words, it is capped by CPU time and not RAM. I'm not sure exactly how much time this should take, but I'm running some benchmarks to find out.</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "996",
                        "2",
                        "989",
                        "",
                        "",
                        "<p>Kernelized SVMs require the computation of a distance function between each point in the dataset, which is the dominating cost of $\\mathcal{O}(n_\\text{features} \\times n_\\text{observations}^2)$. The storage of the distances is a burden on memory, so they're recomputed on the fly. Thankfully, only the points nearest the decision boundary are needed most of the time. Frequently computed distances are stored in a cache. If the cache is getting thrashed then the running time blows up to $\\mathcal{O}(n_\\text{features} \\times n_\\text{observations}^3)$.</p>\n\n<p>You can increase this cache by invoking SVR as</p>\n\n<pre><code>model = SVR(cache_size=7000)\n</code></pre>\n\n<p>In general, this is not going to work. But all is not lost. You can subsample the data and use the rest as a validation set, or you can pick a different model. Above the 200,000 observation range, it's wise to choose linear learners.</p>\n\n<p>Kernel SVM can be approximated, by approximating the kernel matrix and feeding it to a linear SVM. This allows you to trade off between accuracy and performance in linear time.</p>\n\n<p>A popular means of achieving this is to use 100 or so cluster centers found by kmeans/kmeans++ as the basis of your kernel function. The new derived features are then fed into a linear model. This works very well in practice. Tools like <a href=\"https://code.google.com/p/sofia-ml/\">sophia-ml</a> and <a href=\"https://github.com/JohnLangford/vowpal_wabbit/wiki\">vowpal wabbit</a> are how Google, Yahoo and Microsoft do this. Input/output becomes the dominating cost for simple linear learners.</p>\n\n<p>In the abundance of data, nonparametric models perform roughly the same for most problems. The exceptions being structured inputs, like text, images, time series, audio.</p>\n\n<h2>Further reading</h2>\n\n<ul>\n<li><a href=\"http://fastml.com/the-secret-of-the-big-guys/\">How to implement this.</a></li>\n<li><a href=\"http://fastml.com/go-non-linear-with-vowpal-wabbit/\">How to train an ngram neural network with dropout that scales linearly</a></li>\n<li><a href=\"http://peekaboo-vision.blogspot.co.uk/2012/12/kernel-approximations-for-efficient.html\">Kernel Approximations</a></li>\n<li><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.144.9009&amp;rep=rep1&amp;type=pdf\">A formal paper on using kmeans to approximate kernel machines</a></li>\n</ul>\n",
                        "",
                        "67"
                    ],
                    [
                        "30437",
                        "2",
                        "989",
                        "",
                        "",
                        "<p>I just had a similar issue with a dataset which contains only 115 elements and only one single feature (international airline data). The solution was to scale the data. What I missed in answers so far was the usage of a Pipeline:</p>\n\n<pre><code>from sklearn.svm import SVR\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nmodel = Pipeline([('scaler', StandardScaler()),\n                  ('svr', SVR(kernel='linear'))])\n</code></pre>\n\n<p>You can train <code>model</code> like a usual classification / regression model and evaluate it the same way. Nothing changes, only the definition of the model.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "12664",
                        "2",
                        "989",
                        "",
                        "",
                        "<p>SVM solves an optimization problem of quadratic order.</p>\n\n<p>I do not have anything to add that has not been said here. I just want to post a link the sklearn page about <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\" rel=\"noreferrer\">SVC</a> which clarifies what is going on:</p>\n\n<blockquote>\n  <p>The implementation is based on libsvm. The fit time complexity is more\n  than quadratic with the number of samples which makes it hard to scale\n  to dataset with more than a couple of 10000 samples.</p>\n</blockquote>\n\n<p>If you do not want to use kernels, and a linear SVM suffices, there is <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html\" rel=\"noreferrer\">LinearSVR</a> which is much faster because it uses an optimization approach ala linear regressions. You'll have to normalize your data though, in case you're not doing so already, because it applies regularization to the intercept coefficient, which is not probably what you want. It means if your data average is far from zero, it will not be able to solve it satisfactorily.</p>\n\n<p>What you can also use is stochastic gradient descent to solve the optimization problem. Sklearn features <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html\" rel=\"noreferrer\">SGDRegressor</a>. You have to use <code>loss='epsilon_insensitive'</code> to have similar results to linear SVM. See the documentation. I would only use gradient descent as a last resort though because it implies much tweaking of the hyperparameters in order to avoid getting stuck in local minima. Use <code>LinearSVR</code> if you can.</p>\n",
                        "",
                        "15"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5271",
            "_score": 13.114312,
            "_source": {
                "title": "Why do we convert skewed data into a normal distribution",
                "content": "Why do we convert skewed data into a normal distribution <p>I was going through a solution of the Housing prices competition on Kaggle (<a href=\"https://www.kaggle.com/humananalog/xgboost-lasso/code\" rel=\"noreferrer\">Human Analog's Kernel on House Prices: Advance Regression Techniques</a>) and came across this part:</p>\n\n<pre><code># Transform the skewed numeric features by taking log(feature + 1).\n# This will make the features more normal.\nfrom scipy.stats import skew\n\nskewed = train_df_munged[numeric_features].apply(lambda x: skew(x.dropna().astype(float)))\nskewed = skewed[skewed &gt; 0.75]\nskewed = skewed.index\n\ntrain_df_munged[skewed] = np.log1p(train_df_munged[skewed])\ntest_df_munged[skewed] = np.log1p(test_df_munged[skewed])\n</code></pre>\n\n<p>I am not sure of what is the need for converting a skewed distribution into a normal distribution. Please, can someone explain in detail: </p>\n\n<ol>\n<li>Why is this being done here? or How is this helpful?</li>\n<li>How is this different from feature-scaling?</li>\n<li>Is this a necessary step for feature-engineering? What is likely to happen if I skip this step?</li>\n</ol>\n <regression><feature-extraction><feature-engineering><kaggle><feature-scaling><p>Because data science is just statistics at the end of the day, and one of the key assumptions of statistics is the <a href=\"https://en.m.wikipedia.org/wiki/Central_limit_theorem\" rel=\"nofollow noreferrer\">Central Limit Theorem</a>. So this step is being done because some <a href=\"https://en.m.wikipedia.org/wiki/Parametric_statistics\" rel=\"nofollow noreferrer\">subsequent step</a> uses stats techniques that rely on it.</p>\n<p>You might want to interpret your coefficients. That is, to be able to say things like \"if I increase my variable $X_1$ by 1, then, on average and all else being equal, $Y$ should increase by $\\beta_1$\".</p>\n\n<p>For your coefficients to be interpretable, linear regression assumes a bunch of things.</p>\n\n<p>One of these things is no multicollinearity. That is, your $X$ variables should not be correlated against each other.</p>\n\n<p>Another is <a href=\"https://en.wikipedia.org/wiki/Homoscedasticity\" rel=\"noreferrer\">Homoscedasticity</a>. The errors your model commits should have the same variance, i.e. you should ensure the linear regression does not make small errors for low values of $X$ and big errors for higher values of $X$. In other words, the difference between what you predict $\\hat Y$ and the true values $Y$ should be constant. You can ensure that by making sure that $Y$ follows a Gaussian distribution. (The proof is highly mathematical.)</p>\n\n<p>Depending on your data, you may be able to make it Gaussian. Typical transformations are taking the inverse, the logarithm or square roots. Many others exist of course, it all depends on your data. You have to look at your data, and then do a histogram or run a <a href=\"https://en.wikipedia.org/wiki/Normality_test\" rel=\"noreferrer\">normality test</a>, such as the Shapiro-Wilk test.</p>\n\n<p>These are all techniques to build an <a href=\"https://en.wikipedia.org/wiki/Bias_of_an_estimator\" rel=\"noreferrer\">unbiased estimator</a>. I don't think it has anything to do with convergence as others have said (sometimes you may also want to normalize your data, but that is a different topic).</p>\n\n<p>Following the <a href=\"https://en.wikipedia.org/wiki/Linear_regression#Assumptions\" rel=\"noreferrer\">linear regression assumptions</a> is important if you want to either interpret the coefficients or if you want to use statistical tests in your model. Otherwise, forget about it.</p>\n\n<p>Applying the logarithm or normalizing your data, is also important because linear regression optimization algorithms typically minimize $\\|\\hat y - y\\|^2$, so if you have some big $y$ outliers, your estimator is going to be VERY concerned about minimizing those, since it is concerned about the squared error, not absolute error. Normalizing your data is important in those case and this is why scikit-learn has a <code>normalize</code> option in the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" rel=\"noreferrer\">LinearRegression</a> constructor.</p>\n<p>The skewed data here is being normalised by adding one(one added so that the zeros are being transformed to one as log of 0 is not defined) and taking natural log. The data can be nearly normalised using the transformation techniques like taking square root or reciprocal or logarithm. Now, why it is required. Actually many of the algorithms in data assume that the data science is normal and calculate various stats assuming this. So the more the data is close to normal the more it fits the assumption.</p>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "20237",
                "question_votes:": "14",
                "question_text:": "<p>I was going through a solution of the Housing prices competition on Kaggle (<a href=\"https://www.kaggle.com/humananalog/xgboost-lasso/code\" rel=\"noreferrer\">Human Analog's Kernel on House Prices: Advance Regression Techniques</a>) and came across this part:</p>\n\n<pre><code># Transform the skewed numeric features by taking log(feature + 1).\n# This will make the features more normal.\nfrom scipy.stats import skew\n\nskewed = train_df_munged[numeric_features].apply(lambda x: skew(x.dropna().astype(float)))\nskewed = skewed[skewed &gt; 0.75]\nskewed = skewed.index\n\ntrain_df_munged[skewed] = np.log1p(train_df_munged[skewed])\ntest_df_munged[skewed] = np.log1p(test_df_munged[skewed])\n</code></pre>\n\n<p>I am not sure of what is the need for converting a skewed distribution into a normal distribution. Please, can someone explain in detail: </p>\n\n<ol>\n<li>Why is this being done here? or How is this helpful?</li>\n<li>How is this different from feature-scaling?</li>\n<li>Is this a necessary step for feature-engineering? What is likely to happen if I skip this step?</li>\n</ol>\n",
                "tags": "<regression><feature-extraction><feature-engineering><kaggle><feature-scaling>",
                "answers": [
                    [
                        "20243",
                        "2",
                        "20237",
                        "",
                        "",
                        "<p>Because data science is just statistics at the end of the day, and one of the key assumptions of statistics is the <a href=\"https://en.m.wikipedia.org/wiki/Central_limit_theorem\" rel=\"nofollow noreferrer\">Central Limit Theorem</a>. So this step is being done because some <a href=\"https://en.m.wikipedia.org/wiki/Parametric_statistics\" rel=\"nofollow noreferrer\">subsequent step</a> uses stats techniques that rely on it.</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "20428",
                        "2",
                        "20237",
                        "",
                        "",
                        "<p>You might want to interpret your coefficients. That is, to be able to say things like \"if I increase my variable $X_1$ by 1, then, on average and all else being equal, $Y$ should increase by $\\beta_1$\".</p>\n\n<p>For your coefficients to be interpretable, linear regression assumes a bunch of things.</p>\n\n<p>One of these things is no multicollinearity. That is, your $X$ variables should not be correlated against each other.</p>\n\n<p>Another is <a href=\"https://en.wikipedia.org/wiki/Homoscedasticity\" rel=\"noreferrer\">Homoscedasticity</a>. The errors your model commits should have the same variance, i.e. you should ensure the linear regression does not make small errors for low values of $X$ and big errors for higher values of $X$. In other words, the difference between what you predict $\\hat Y$ and the true values $Y$ should be constant. You can ensure that by making sure that $Y$ follows a Gaussian distribution. (The proof is highly mathematical.)</p>\n\n<p>Depending on your data, you may be able to make it Gaussian. Typical transformations are taking the inverse, the logarithm or square roots. Many others exist of course, it all depends on your data. You have to look at your data, and then do a histogram or run a <a href=\"https://en.wikipedia.org/wiki/Normality_test\" rel=\"noreferrer\">normality test</a>, such as the Shapiro-Wilk test.</p>\n\n<p>These are all techniques to build an <a href=\"https://en.wikipedia.org/wiki/Bias_of_an_estimator\" rel=\"noreferrer\">unbiased estimator</a>. I don't think it has anything to do with convergence as others have said (sometimes you may also want to normalize your data, but that is a different topic).</p>\n\n<p>Following the <a href=\"https://en.wikipedia.org/wiki/Linear_regression#Assumptions\" rel=\"noreferrer\">linear regression assumptions</a> is important if you want to either interpret the coefficients or if you want to use statistical tests in your model. Otherwise, forget about it.</p>\n\n<p>Applying the logarithm or normalizing your data, is also important because linear regression optimization algorithms typically minimize $\\|\\hat y - y\\|^2$, so if you have some big $y$ outliers, your estimator is going to be VERY concerned about minimizing those, since it is concerned about the squared error, not absolute error. Normalizing your data is important in those case and this is why scikit-learn has a <code>normalize</code> option in the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" rel=\"noreferrer\">LinearRegression</a> constructor.</p>\n",
                        "",
                        "12"
                    ],
                    [
                        "20241",
                        "2",
                        "20237",
                        "",
                        "",
                        "<p>The skewed data here is being normalised by adding one(one added so that the zeros are being transformed to one as log of 0 is not defined) and taking natural log. The data can be nearly normalised using the transformation techniques like taking square root or reciprocal or logarithm. Now, why it is required. Actually many of the algorithms in data assume that the data science is normal and calculate various stats assuming this. So the more the data is close to normal the more it fits the assumption.</p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16381",
            "_score": 13.062195,
            "_source": {
                "title": "Classification report returns same accuracy precision recall averages at binary classification problem",
                "content": "Classification report returns same accuracy precision recall averages at binary classification problem <p>My results are:     </p>\n\n<p><a href=\"https://i.stack.imgur.com/QBZ9G.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/QBZ9G.png\" alt=\"enter image description here\"></a>          </p>\n\n<p>This is the Code:</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report\n\ndf = pd.read_csv(dataset)\nX = df.drop(columns=['backers_count','converted_pledged_amount','pledged'\n      ,'id','usd_pledged','state','static_usd_rate','funded_percentage'])\ny = df['state'].values\n# Split dataset into train and test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42,stratify=y)\n\n# Create Logistic Regression Classifier\nlogreg = LogisticRegression(solver='lbfgs',max_iter=400)\nlogreg.fit(X_train, y_train)  \nlog_predict = logreg.predict(X_test)\n\n#train model with cv of 10\ncv_scores = cross_val_score(logreg, X, y, cv=10)\n\n# Print the results\nprint(\"=== Confusion Matrix ===\")\nprint(confusion_matrix(y_test, log_predict))\nprint('\\n')\nprint(\"=== Classification Report ===\")\nprint(classification_report(y_test, log_predict))\nprint('\\n')\nprint(\"=== All Accuracy Scores ===\")\nprint(cv_scores)\nprint('\\n')\nprint(\"=== Mean Accuracy Score ===\")\nprint(\"Mean Accuracy Score - Logistic Regression: \", cv_scores.mean())\n</code></pre>\n\n<p>Is it normal to have identical values to micro avgs macro avgs and weighted for precision recall f1-score and to accuracy as well or there's something wrong with my model? This also happens(getting identical results to precision recall f1-score accuracy) at other classification models with the same dataset that I've tried like random forest and SVC. If its normal how do I interpret this, or is it just wrong code and try to fix this?</p>\n\n<p>Which avg matters and should record for binary classification(micro macro or weighted) or all?</p>\n <machine-learning><python><classification>",
                "codes": [],
                "question_id:": "53966",
                "question_votes:": "1",
                "question_text:": "<p>My results are:     </p>\n\n<p><a href=\"https://i.stack.imgur.com/QBZ9G.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/QBZ9G.png\" alt=\"enter image description here\"></a>          </p>\n\n<p>This is the Code:</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report\n\ndf = pd.read_csv(dataset)\nX = df.drop(columns=['backers_count','converted_pledged_amount','pledged'\n      ,'id','usd_pledged','state','static_usd_rate','funded_percentage'])\ny = df['state'].values\n# Split dataset into train and test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42,stratify=y)\n\n# Create Logistic Regression Classifier\nlogreg = LogisticRegression(solver='lbfgs',max_iter=400)\nlogreg.fit(X_train, y_train)  \nlog_predict = logreg.predict(X_test)\n\n#train model with cv of 10\ncv_scores = cross_val_score(logreg, X, y, cv=10)\n\n# Print the results\nprint(\"=== Confusion Matrix ===\")\nprint(confusion_matrix(y_test, log_predict))\nprint('\\n')\nprint(\"=== Classification Report ===\")\nprint(classification_report(y_test, log_predict))\nprint('\\n')\nprint(\"=== All Accuracy Scores ===\")\nprint(cv_scores)\nprint('\\n')\nprint(\"=== Mean Accuracy Score ===\")\nprint(\"Mean Accuracy Score - Logistic Regression: \", cv_scores.mean())\n</code></pre>\n\n<p>Is it normal to have identical values to micro avgs macro avgs and weighted for precision recall f1-score and to accuracy as well or there's something wrong with my model? This also happens(getting identical results to precision recall f1-score accuracy) at other classification models with the same dataset that I've tried like random forest and SVC. If its normal how do I interpret this, or is it just wrong code and try to fix this?</p>\n\n<p>Which avg matters and should record for binary classification(micro macro or weighted) or all?</p>\n",
                "tags": "<machine-learning><python><classification>",
                "answers": []
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13308",
            "_score": 13.042124,
            "_source": {
                "title": "What does a negative coefficient of determination mean for evaluating ridge regression?",
                "content": "What does a negative coefficient of determination mean for evaluating ridge regression? <p>Judging by the negative result being displayed from my ridge.score() I am guessing that I am doing something wrong. Maybe someone could point me in the right direction?</p>\n\n<pre><code># Create a practice data set for exploring Ridge Regression\n\n\ndata_2 = np.array([[1, 2, 0], [3, 4, 1], [5, 6, 0], [1, 3, 1],\n           [3, 5, 1], [1, 7, 0], [1, 8, 1]], dtype=np.float64)\n\n\n# Separate X and Y\n\nx_2 = data_2[:, [0, 1]]\ny_2 = data_2[:, 2]\n\n# Train Test Split\nx_2_train, x_2_test, y_2_train, y_2_test = train_test_split(x_2, y_2, random_state=0)\n\n# Scale the training data\nscaler_2 = StandardScaler()\nscaler_2.fit(x_2_train)\nx_2_transformed = scaler_2.transform(x_2_train)\n\n# Ridge Regression\nridge_2 = Ridge().fit(x_2_transformed, y_2_train)\nx_2_test_scaled = scaler_2.transform(x_2_test)\nridge_2.score(x_2_test_scaled, y_2_test)\n</code></pre>\n\n<p>Output is: -4.47</p>\n\n<p><strong>EDIT:</strong> From reading the scikit learn docs this value is the R<span class=\"math-container\">$^2$</span> value. I guess the question is though, how do we interpret this?</p>\n <machine-learning><scikit-learn><ridge-regression><p>A negative value means you're getting a terrible fit - which makes sense if you create a test set that doesn't have the same distribution as the training set. </p>\n\n<p>From the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge.score\" rel=\"nofollow noreferrer\">sklearn documentation</a>:</p>\n\n<blockquote>\n  <p>The coefficient <span class=\"math-container\">$R^2$</span> is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a <span class=\"math-container\">$R^2$</span> score of 0.0.</p>\n</blockquote>\n<p>To understand what negative value of coefficient of determination (<span class=\"math-container\">$r^2$</span>). You need to know what <span class=\"math-container\">$r^2$</span> = 0 means.</p>\n\n<p><span class=\"math-container\">$r^2$</span> = 0 means that the squared error of your regressor fit is same as the squared error for a fit that always returns the mean of your targets.</p>\n\n<p>If <span class=\"math-container\">$r^2$</span> is negative it means that your regressor fit has a higher squared error than the mean fit. That is, it performs worse than the mean fit.</p>\n\n<p><span class=\"math-container\">$r^2$</span> = 1 - Squared error(your fit)/Squared error(mean fit)</p>\n\n<p><span class=\"math-container\">`</span></p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "45668",
                "question_votes:": "2",
                "question_text:": "<p>Judging by the negative result being displayed from my ridge.score() I am guessing that I am doing something wrong. Maybe someone could point me in the right direction?</p>\n\n<pre><code># Create a practice data set for exploring Ridge Regression\n\n\ndata_2 = np.array([[1, 2, 0], [3, 4, 1], [5, 6, 0], [1, 3, 1],\n           [3, 5, 1], [1, 7, 0], [1, 8, 1]], dtype=np.float64)\n\n\n# Separate X and Y\n\nx_2 = data_2[:, [0, 1]]\ny_2 = data_2[:, 2]\n\n# Train Test Split\nx_2_train, x_2_test, y_2_train, y_2_test = train_test_split(x_2, y_2, random_state=0)\n\n# Scale the training data\nscaler_2 = StandardScaler()\nscaler_2.fit(x_2_train)\nx_2_transformed = scaler_2.transform(x_2_train)\n\n# Ridge Regression\nridge_2 = Ridge().fit(x_2_transformed, y_2_train)\nx_2_test_scaled = scaler_2.transform(x_2_test)\nridge_2.score(x_2_test_scaled, y_2_test)\n</code></pre>\n\n<p>Output is: -4.47</p>\n\n<p><strong>EDIT:</strong> From reading the scikit learn docs this value is the R<span class=\"math-container\">$^2$</span> value. I guess the question is though, how do we interpret this?</p>\n",
                "tags": "<machine-learning><scikit-learn><ridge-regression>",
                "answers": [
                    [
                        "45670",
                        "2",
                        "45668",
                        "",
                        "",
                        "<p>A negative value means you're getting a terrible fit - which makes sense if you create a test set that doesn't have the same distribution as the training set. </p>\n\n<p>From the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge.score\" rel=\"nofollow noreferrer\">sklearn documentation</a>:</p>\n\n<blockquote>\n  <p>The coefficient <span class=\"math-container\">$R^2$</span> is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a <span class=\"math-container\">$R^2$</span> score of 0.0.</p>\n</blockquote>\n",
                        "",
                        "3"
                    ],
                    [
                        "45674",
                        "2",
                        "45668",
                        "",
                        "",
                        "<p>To understand what negative value of coefficient of determination (<span class=\"math-container\">$r^2$</span>). You need to know what <span class=\"math-container\">$r^2$</span> = 0 means.</p>\n\n<p><span class=\"math-container\">$r^2$</span> = 0 means that the squared error of your regressor fit is same as the squared error for a fit that always returns the mean of your targets.</p>\n\n<p>If <span class=\"math-container\">$r^2$</span> is negative it means that your regressor fit has a higher squared error than the mean fit. That is, it performs worse than the mean fit.</p>\n\n<p><span class=\"math-container\">$r^2$</span> = 1 - Squared error(your fit)/Squared error(mean fit)</p>\n\n<p><span class=\"math-container\">`</span></p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11401",
            "_score": 12.957305,
            "_source": {
                "title": "Evaluation of linear regression model",
                "content": "Evaluation of linear regression model <p>I want to evaluate the performance of my linear regression model. I have the true values of y (y-true). I am thinking of two way for evaluation but not sure which one is correct. </p>\n\n<p>Let's assume that we have 2 samples and each sample has two outputs as following: </p>\n\n<pre><code>y_true = [[0.5, 0.5],[0.6, 0.3]]\ny_pred = [[0.3, 0.7],[0.9, 0.1]]\n</code></pre>\n\n<p><strong>- Approach#1 :</strong> </p>\n\n<p>One way to calculate the sum of the difference between the actual and predicted for each vector and then average all, as follows: </p>\n\n<p>sum_diff_Vector(1) = abs( 0.5 - 0.3 ) + abs( 0.5 - 0.7 ) =  0.4</p>\n\n<p>sum_diff_Vector(2) = abs( 0.6 - 0.9 ) + abs( 0.3 - 0.1 ) = 0.5</p>\n\n<p>Then avg ( sum_diff_Vector(1) , sum_diff_Vector(2) ) = 0.45</p>\n\n<p><strong>- Approach#2 :</strong> </p>\n\n<p>Another way to use the mean absolute error provided by sklearn.metrics in python.  The thing with this metric, as opposed to the previous method, it calculates the mean absolute error for each output over all samples independently and then average all of them, as follows: </p>\n\n<p>MAE_OUTPUT(1) = abs(( 0.5 - 0.3 ) + ( 0.6 - 0.9 )) / 2 = 0.25</p>\n\n<p>MAE_OUTPUT(1) = abs(( 0.5 - 0.7 ) + ( 0.3 - 0.1 )) /2 = 0.2 </p>\n\n<p>Then avg ( MAE_OUTPUT(1) , MAE_OUTPUT(1) ) =  0.225</p>\n\n<p>Which way is correct and I should use ? please advise? </p>\n <linear-regression><evaluation><p>The only difference is in your example is that you divide by an additional two, because you take the mean per vector instead of the sum. Correctness does not play here because for comparison between different models the only difference is a constant factor and for interpretability it depends on the problem you are solving.</p>\n\n<p>The mean absolute error punishes mistakes linearly while the mean squared error punishes larger mistakes more heavily. This means this depends a bit on what you want to measure, based on the problem you are solving. Next to proper evaluation you could use this same measure to change the KPI you are optimizing directly with a different loss function.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "40265",
                "question_votes:": "1",
                "question_text:": "<p>I want to evaluate the performance of my linear regression model. I have the true values of y (y-true). I am thinking of two way for evaluation but not sure which one is correct. </p>\n\n<p>Let's assume that we have 2 samples and each sample has two outputs as following: </p>\n\n<pre><code>y_true = [[0.5, 0.5],[0.6, 0.3]]\ny_pred = [[0.3, 0.7],[0.9, 0.1]]\n</code></pre>\n\n<p><strong>- Approach#1 :</strong> </p>\n\n<p>One way to calculate the sum of the difference between the actual and predicted for each vector and then average all, as follows: </p>\n\n<p>sum_diff_Vector(1) = abs( 0.5 - 0.3 ) + abs( 0.5 - 0.7 ) =  0.4</p>\n\n<p>sum_diff_Vector(2) = abs( 0.6 - 0.9 ) + abs( 0.3 - 0.1 ) = 0.5</p>\n\n<p>Then avg ( sum_diff_Vector(1) , sum_diff_Vector(2) ) = 0.45</p>\n\n<p><strong>- Approach#2 :</strong> </p>\n\n<p>Another way to use the mean absolute error provided by sklearn.metrics in python.  The thing with this metric, as opposed to the previous method, it calculates the mean absolute error for each output over all samples independently and then average all of them, as follows: </p>\n\n<p>MAE_OUTPUT(1) = abs(( 0.5 - 0.3 ) + ( 0.6 - 0.9 )) / 2 = 0.25</p>\n\n<p>MAE_OUTPUT(1) = abs(( 0.5 - 0.7 ) + ( 0.3 - 0.1 )) /2 = 0.2 </p>\n\n<p>Then avg ( MAE_OUTPUT(1) , MAE_OUTPUT(1) ) =  0.225</p>\n\n<p>Which way is correct and I should use ? please advise? </p>\n",
                "tags": "<linear-regression><evaluation>",
                "answers": [
                    [
                        "40266",
                        "2",
                        "40265",
                        "",
                        "",
                        "<p>The only difference is in your example is that you divide by an additional two, because you take the mean per vector instead of the sum. Correctness does not play here because for comparison between different models the only difference is a constant factor and for interpretability it depends on the problem you are solving.</p>\n\n<p>The mean absolute error punishes mistakes linearly while the mean squared error punishes larger mistakes more heavily. This means this depends a bit on what you want to measure, based on the problem you are solving. Next to proper evaluation you could use this same measure to change the KPI you are optimizing directly with a different loss function.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16312",
            "_score": 12.924646,
            "_source": {
                "title": "Why is r squared lowered when adding polynomial features?",
                "content": "Why is r squared lowered when adding polynomial features? <p>I am trying to find a best fit line <code>f(x) = ?</code> for a random set of <em>x,y</em> coordinates.</p>\n\n<p>Linear Regression with polynomial features works well for around 10 different polynomials but beyond 10 the r squared actually starts to drop!</p>\n\n<p>If the new features are not useful to the Linear Regression I would assume that they would be given a coefficient of 0 and therefore adding features should not hurt the overall r squared.</p>\n\n<p>I reproduced this problem when housing price predictions when creating a large amount of interaction features.</p>\n\n<p>I have my python code below:</p>\n\n<p><strong>Create Random Data</strong></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef pol(x):\n    return x * np.cos(x)\n\nx = np.linspace(0, 12, 100)\nrng = np.random.RandomState(1234)\nrng.shuffle(x)\nx = np.sort(x[:25])\ny = pol(x) + np.random.randn(25)*2\n\n\nplt.scatter(x, y, color='green', s=50, marker='.')\n\nplt.show()\n</code></pre>\n\n<p><strong>Regress and Check Each R Squared</strong></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\n\nfor p in range(1,30):\n    plot_range = [i/10 for i in range(0,120)]\n    poly = PolynomialFeatures(p)\n    X_fin = poly.fit_transform([[samp] for samp in x])\n    X_fin_plot = poly.fit_transform([[samp] for samp in plot_range])\n    reg = LinearRegression().fit(X_fin, y)\n\n    from sklearn.metrics import mean_squared_error, r2_score\n    print(p,r2_score(y, reg.predict(X_fin)))\n</code></pre>\n\n<p><strong>Display Last Regression Line</strong></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>plt.scatter(x, y, color='green', s=50, marker='.')\nplt.plot(plot_range,reg.predict(X_fin_plot))\nplt.show()\n</code></pre>\n\n<p>I also have two plots to compare. The first is with 10 polynomial features and the second is with 40. Notice how the second misses the majority of the first points.\n<a href=\"https://i.stack.imgur.com/8yQku.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/8yQku.png\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/tpJEW.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/tpJEW.png\" alt=\"enter image description here\"></a></p>\n <scikit-learn><predictive-modeling><linear-regression><p>You've got 25 points, so there is a perfect fitting polynomial of degree 24.  That doesn't happen, so something is breaking in the OLS solver, but I'm not sure of what exactly or how to detect that.  It's not too surprising though that you may have numerical issues when <code>p</code> gets large: you've got an x-value near 0.1 and others past 10; raising them to the 24th power pushes them very far apart, and probably generates many more significant digits than python is keeping around.</p>\n\n<p>I've put together a demonstration:<br>\n<a href=\"https://github.com/bmreiniger/datascience.stackexchange/blob/master/53818.ipynb\" rel=\"nofollow noreferrer\">https://github.com/bmreiniger/datascience.stackexchange/blob/master/53818.ipynb</a><br>\nScaling the x-values helps, though we still don't find something visually matching the perfect polynomial fit.</p>\n\n<p>See also <a href=\"https://stats.stackexchange.com/questions/350130/why-is-gradient-descent-so-bad-at-optimizing-polynomial-regression\">https://stats.stackexchange.com/questions/350130/why-is-gradient-descent-so-bad-at-optimizing-polynomial-regression</a></p>\n<p>My original answer was not correct, so here is a corrected answer:</p>\n\n<p>When you use <code>PolynomialFeatures()</code>, you don't get the intended polynomials. Instead you get polynomials plus an interaction term:</p>\n\n<pre><code>from sklearn.preprocessing import PolynomialFeatures import numpy as \nnp    z = np.array([[0, 1],\n                    [2, 3],\n                    [4, 5]]) \npoly = PolynomialFeatures(2)\nprint(poly.fit_transform(z))\n</code></pre>\n\n<p>Output is:</p>\n\n<pre><code>[[ 1.  0.  1.  0.  0.  1.]\n [ 1.  2.  3.  4.  6.  9.]\n [ 1.  4.  5. 16. 20. 25.]]\n</code></pre>\n\n<p>A raw polynomial should look like:</p>\n\n<pre><code>new_z = np.hstack((z**(i+1) for i in range(2)))\nprint(new_z)\n</code></pre>\n\n<p>Output is:</p>\n\n<pre><code>[[ 0  1  0  1]\n [ 2  3  4  9]\n [ 4  5 16 25]]\n</code></pre>\n\n<p>Here is a quick R implementation of your problem with raw polynomials:</p>\n\n<pre><code>x = c(0.12121212, 1.09090909, 3.27272727, 3.51515152, 4, 4.24242424,\n  4.72727273, 4.84848485, 5.09090909, 6.18181818, 6.78787879, 7.15151515,\n  7.39393939, 7.63636364, 8.24242424, 8.60606061, 9.09090909, 9.81818182,\n  9.93939394, 10.3030303, 10.54545455, 10.66666667, 11.39393939, 11.63636364,\n  11.87878788)\n\ny = c(-2.87011136,1.77132943,-1.23698978,-3.09768628,-2.11919042,-4.11234626,\n  -1.1684339, 1.34601699, -2.37623758,4.20290438, 6.16349341, 3.60661197,\n  2.58898819, 3.80785471, -2.96359566, -5.672873, -9.71694313, -7.62778351,\n  -8.95730409, -8.04664475, -5.18464423, -6.54562138, 3.45527603, 6.11936457,\n  9.30106747)\n\nregdata = data.frame(x,y)\ncolnames(regdata) &lt;- c(\"x\",\"y\")\n\nr2list = list()\nr2adjlist = list()\nplist = list()\n\nfor (p in seq(1:29)){\n  reg = lm(y~poly(x,p, raw=T), data=regdata)\n  print(paste0(\"Poly: \", p))\n  print(paste0(\"  R2      \", summary(reg)<span class=\"math-container\">$r.squared))\n  print(paste0(\"  R2_adj. \", summary(reg)$</span>adj.r.squared))\n  r2list[[p]] &lt;-  summary(reg)<span class=\"math-container\">$r.squared\n  r2adjlist[[p]] &lt;- summary(reg)$</span>adj.r.squared\n  plist[[p]] &lt;- p\n}\n\nplot(plist, r2list,xlab=\"Polynomial\", ylab=\"R2\")\nlines(plist, r2list)\n</code></pre>\n\n<p>The R2 contingent on the degree of the polynomial is shown below:\n<a href=\"https://i.stack.imgur.com/ZYuYB.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ZYuYB.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>So your initial intuition was (of course) correct, but your treatment of data was not correct.</p>\n",
                "codes": [
                    [],
                    [
                        "from sklearn.preprocessing import PolynomialFeatures import numpy as \nnp    z = np.array([[0, 1],\n                    [2, 3],\n                    [4, 5]]) \npoly = PolynomialFeatures(2)\nprint(poly.fit_transform(z))\n",
                        "[[ 1.  0.  1.  0.  0.  1.]\n [ 1.  2.  3.  4.  6.  9.]\n [ 1.  4.  5. 16. 20. 25.]]\n",
                        "new_z = np.hstack((z**(i+1) for i in range(2)))\nprint(new_z)\n",
                        "[[ 0  1  0  1]\n [ 2  3  4  9]\n [ 4  5 16 25]]\n"
                    ]
                ],
                "question_id:": "53818",
                "question_votes:": "1",
                "question_text:": "<p>I am trying to find a best fit line <code>f(x) = ?</code> for a random set of <em>x,y</em> coordinates.</p>\n\n<p>Linear Regression with polynomial features works well for around 10 different polynomials but beyond 10 the r squared actually starts to drop!</p>\n\n<p>If the new features are not useful to the Linear Regression I would assume that they would be given a coefficient of 0 and therefore adding features should not hurt the overall r squared.</p>\n\n<p>I reproduced this problem when housing price predictions when creating a large amount of interaction features.</p>\n\n<p>I have my python code below:</p>\n\n<p><strong>Create Random Data</strong></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef pol(x):\n    return x * np.cos(x)\n\nx = np.linspace(0, 12, 100)\nrng = np.random.RandomState(1234)\nrng.shuffle(x)\nx = np.sort(x[:25])\ny = pol(x) + np.random.randn(25)*2\n\n\nplt.scatter(x, y, color='green', s=50, marker='.')\n\nplt.show()\n</code></pre>\n\n<p><strong>Regress and Check Each R Squared</strong></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\n\nfor p in range(1,30):\n    plot_range = [i/10 for i in range(0,120)]\n    poly = PolynomialFeatures(p)\n    X_fin = poly.fit_transform([[samp] for samp in x])\n    X_fin_plot = poly.fit_transform([[samp] for samp in plot_range])\n    reg = LinearRegression().fit(X_fin, y)\n\n    from sklearn.metrics import mean_squared_error, r2_score\n    print(p,r2_score(y, reg.predict(X_fin)))\n</code></pre>\n\n<p><strong>Display Last Regression Line</strong></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>plt.scatter(x, y, color='green', s=50, marker='.')\nplt.plot(plot_range,reg.predict(X_fin_plot))\nplt.show()\n</code></pre>\n\n<p>I also have two plots to compare. The first is with 10 polynomial features and the second is with 40. Notice how the second misses the majority of the first points.\n<a href=\"https://i.stack.imgur.com/8yQku.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/8yQku.png\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/tpJEW.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/tpJEW.png\" alt=\"enter image description here\"></a></p>\n",
                "tags": "<scikit-learn><predictive-modeling><linear-regression>",
                "answers": [
                    [
                        "54107",
                        "2",
                        "53818",
                        "",
                        "",
                        "<p>You've got 25 points, so there is a perfect fitting polynomial of degree 24.  That doesn't happen, so something is breaking in the OLS solver, but I'm not sure of what exactly or how to detect that.  It's not too surprising though that you may have numerical issues when <code>p</code> gets large: you've got an x-value near 0.1 and others past 10; raising them to the 24th power pushes them very far apart, and probably generates many more significant digits than python is keeping around.</p>\n\n<p>I've put together a demonstration:<br>\n<a href=\"https://github.com/bmreiniger/datascience.stackexchange/blob/master/53818.ipynb\" rel=\"nofollow noreferrer\">https://github.com/bmreiniger/datascience.stackexchange/blob/master/53818.ipynb</a><br>\nScaling the x-values helps, though we still don't find something visually matching the perfect polynomial fit.</p>\n\n<p>See also <a href=\"https://stats.stackexchange.com/questions/350130/why-is-gradient-descent-so-bad-at-optimizing-polynomial-regression\">https://stats.stackexchange.com/questions/350130/why-is-gradient-descent-so-bad-at-optimizing-polynomial-regression</a></p>\n",
                        "",
                        "2"
                    ],
                    [
                        "53822",
                        "2",
                        "53818",
                        "",
                        "",
                        "<p>My original answer was not correct, so here is a corrected answer:</p>\n\n<p>When you use <code>PolynomialFeatures()</code>, you don't get the intended polynomials. Instead you get polynomials plus an interaction term:</p>\n\n<pre><code>from sklearn.preprocessing import PolynomialFeatures import numpy as \nnp    z = np.array([[0, 1],\n                    [2, 3],\n                    [4, 5]]) \npoly = PolynomialFeatures(2)\nprint(poly.fit_transform(z))\n</code></pre>\n\n<p>Output is:</p>\n\n<pre><code>[[ 1.  0.  1.  0.  0.  1.]\n [ 1.  2.  3.  4.  6.  9.]\n [ 1.  4.  5. 16. 20. 25.]]\n</code></pre>\n\n<p>A raw polynomial should look like:</p>\n\n<pre><code>new_z = np.hstack((z**(i+1) for i in range(2)))\nprint(new_z)\n</code></pre>\n\n<p>Output is:</p>\n\n<pre><code>[[ 0  1  0  1]\n [ 2  3  4  9]\n [ 4  5 16 25]]\n</code></pre>\n\n<p>Here is a quick R implementation of your problem with raw polynomials:</p>\n\n<pre><code>x = c(0.12121212, 1.09090909, 3.27272727, 3.51515152, 4, 4.24242424,\n  4.72727273, 4.84848485, 5.09090909, 6.18181818, 6.78787879, 7.15151515,\n  7.39393939, 7.63636364, 8.24242424, 8.60606061, 9.09090909, 9.81818182,\n  9.93939394, 10.3030303, 10.54545455, 10.66666667, 11.39393939, 11.63636364,\n  11.87878788)\n\ny = c(-2.87011136,1.77132943,-1.23698978,-3.09768628,-2.11919042,-4.11234626,\n  -1.1684339, 1.34601699, -2.37623758,4.20290438, 6.16349341, 3.60661197,\n  2.58898819, 3.80785471, -2.96359566, -5.672873, -9.71694313, -7.62778351,\n  -8.95730409, -8.04664475, -5.18464423, -6.54562138, 3.45527603, 6.11936457,\n  9.30106747)\n\nregdata = data.frame(x,y)\ncolnames(regdata) &lt;- c(\"x\",\"y\")\n\nr2list = list()\nr2adjlist = list()\nplist = list()\n\nfor (p in seq(1:29)){\n  reg = lm(y~poly(x,p, raw=T), data=regdata)\n  print(paste0(\"Poly: \", p))\n  print(paste0(\"  R2      \", summary(reg)<span class=\"math-container\">$r.squared))\n  print(paste0(\"  R2_adj. \", summary(reg)$</span>adj.r.squared))\n  r2list[[p]] &lt;-  summary(reg)<span class=\"math-container\">$r.squared\n  r2adjlist[[p]] &lt;- summary(reg)$</span>adj.r.squared\n  plist[[p]] &lt;- p\n}\n\nplot(plist, r2list,xlab=\"Polynomial\", ylab=\"R2\")\nlines(plist, r2list)\n</code></pre>\n\n<p>The R2 contingent on the degree of the polynomial is shown below:\n<a href=\"https://i.stack.imgur.com/ZYuYB.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ZYuYB.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>So your initial intuition was (of course) correct, but your treatment of data was not correct.</p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13535",
            "_score": 12.924514,
            "_source": {
                "title": "'DataFrame' object has no attribute 'to_dataframe'",
                "content": "'DataFrame' object has no attribute 'to_dataframe' <p>I'm sure I have a small error here that I'm overlooking, but am having a tough time figuring out what I need to change. </p>\n\n<p>Here is my code up until the error I'm getting.</p>\n\n<pre><code># Load libraries\nimport pandas as pd\nimport numpy as np\nfrom pandas.tools.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analyisis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\n# Load dataset\nnames = ['action','reject','approve','occ','loanamt', 'suffolk', 'appinc','typur','unit','married','dep','emp',yjob','self','atotinc','cototinc','hexp']\n\n# from azureml import Workspace\n# ws = Workspace(\n#      workspace_id='',\n#      authorization_token='==',\n#      endpoint='https://studioapi.azureml.net'\n# )\n# ds = ws.datasets['loanapp_c.csv']\n\nds = pd.read_csv('desktop/python ML/loanapp_c.csv')\ndataset = ds.to_dataframe()\n</code></pre>\n\n<p>I was running this on Azure and am now trying to do it locally. Here is the error I'm getting:</p>\n\n<pre><code>AttributeError                Traceback (most recent call last)\n&lt;ipython-input-3-b49a23658806&gt; in &lt;module&gt;()\n     32\n     33 ds = pd.read_csv('desktop/python ML/loanapp_c.csv')\n---&gt; 34 dataset = ds.to_dataframe()\n     35\n     36 # shape\n\n~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in_getattr_(self, name)\n     4374 if self._info_axis.can_hold_identifiers_and_holds_name(name):\n            return self[name]\n  -&gt; 4376 return object._getattribute_(self,name)\n     4377\n     4378 def _setattr_(self, name, value):\n\nAttributeError: 'DataFrame' object has no attribute 'to_dataframe'\n</code></pre>\n\n<p>Not sure what I have wrong.</p>\n <dataframe><p>According to what I understand. You are loading <code>loanapp_c.csv</code> in <code>ds</code> using this code:</p>\n\n<pre><code>ds = pd.read_csv('desktop/python ML/loanapp_c.csv')\n</code></pre>\n\n<p><code>ds</code> over here is a DataFrame object. What you are doing is calling <code>to_dataframe</code> on an object which a DataFrame already.</p>\n\n<p>Removing this <code>dataset = ds.to_dataframe()</code> from your code should solve the error</p>\n<p>The function <code>pd.read_csv()</code> is already a DataFrame and thus that kind of object does not support calling <code>.to_dataframe()</code>. </p>\n\n<p>You can check the type of your variable <code>ds</code> using <code>print(type(ds))</code>, you will see that it is a pandas DataFrame type.</p>\n",
                "codes": [
                    [
                        "ds = pd.read_csv('desktop/python ML/loanapp_c.csv')\n"
                    ],
                    []
                ],
                "question_id:": "46149",
                "question_votes:": "",
                "question_text:": "<p>I'm sure I have a small error here that I'm overlooking, but am having a tough time figuring out what I need to change. </p>\n\n<p>Here is my code up until the error I'm getting.</p>\n\n<pre><code># Load libraries\nimport pandas as pd\nimport numpy as np\nfrom pandas.tools.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analyisis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\n# Load dataset\nnames = ['action','reject','approve','occ','loanamt', 'suffolk', 'appinc','typur','unit','married','dep','emp',yjob','self','atotinc','cototinc','hexp']\n\n# from azureml import Workspace\n# ws = Workspace(\n#      workspace_id='',\n#      authorization_token='==',\n#      endpoint='https://studioapi.azureml.net'\n# )\n# ds = ws.datasets['loanapp_c.csv']\n\nds = pd.read_csv('desktop/python ML/loanapp_c.csv')\ndataset = ds.to_dataframe()\n</code></pre>\n\n<p>I was running this on Azure and am now trying to do it locally. Here is the error I'm getting:</p>\n\n<pre><code>AttributeError                Traceback (most recent call last)\n&lt;ipython-input-3-b49a23658806&gt; in &lt;module&gt;()\n     32\n     33 ds = pd.read_csv('desktop/python ML/loanapp_c.csv')\n---&gt; 34 dataset = ds.to_dataframe()\n     35\n     36 # shape\n\n~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in_getattr_(self, name)\n     4374 if self._info_axis.can_hold_identifiers_and_holds_name(name):\n            return self[name]\n  -&gt; 4376 return object._getattribute_(self,name)\n     4377\n     4378 def _setattr_(self, name, value):\n\nAttributeError: 'DataFrame' object has no attribute 'to_dataframe'\n</code></pre>\n\n<p>Not sure what I have wrong.</p>\n",
                "tags": "<dataframe>",
                "answers": [
                    [
                        "46152",
                        "2",
                        "46149",
                        "",
                        "",
                        "<p>According to what I understand. You are loading <code>loanapp_c.csv</code> in <code>ds</code> using this code:</p>\n\n<pre><code>ds = pd.read_csv('desktop/python ML/loanapp_c.csv')\n</code></pre>\n\n<p><code>ds</code> over here is a DataFrame object. What you are doing is calling <code>to_dataframe</code> on an object which a DataFrame already.</p>\n\n<p>Removing this <code>dataset = ds.to_dataframe()</code> from your code should solve the error</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "46150",
                        "2",
                        "46149",
                        "",
                        "",
                        "<p>The function <code>pd.read_csv()</code> is already a DataFrame and thus that kind of object does not support calling <code>.to_dataframe()</code>. </p>\n\n<p>You can check the type of your variable <code>ds</code> using <code>print(type(ds))</code>, you will see that it is a pandas DataFrame type.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8866",
            "_score": 12.913842,
            "_source": {
                "title": "How to scale prediction back after preprocessing",
                "content": "How to scale prediction back after preprocessing <p>So I'm a newbie to machine learning and am currently using the iris data set. I ran through a quick online tutorial about predicting stock prices and thought I'd try and do the iris one myself.</p>\n\n<p>The issue I'm having is that I'm using preprocessing to scale the data to train my classifier. However when I make a prediction, the answer is also scaled. When I comment out all the preprocessing, I get accurate results. Is there a way to scale the prediction back?</p>\n\n<p>The outputs are rounded to 0, 1 or 2 with each number representing one of three species.</p>\n\n<p>You can see my code below:</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing, model_selection\nfrom sklearn.linear_model import LinearRegression\n\ndf = pd.read_csv(\"iris.csv\")\n\n# setosa - 0\n# versicolor - 1\n# virginica - 2\ndf = df.replace(\"setosa\", 0)\ndf = df.replace(\"versicolor\", 1)\ndf = df.replace(\"virginica\", 2)\n\nX = np.array(df.drop(['species'], 1))\n\ny = np.array(df['species'])\n\n# Scale features\n# X = preprocessing.scale(X)\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)\n\nclf = LinearRegression(n_jobs=1)  # Linear regression clf\n\nclf.fit(X_train, y_train)\n\nconfidence = clf.score(X_test, y_test)\n\nprint(\"Confidence: \" + confidence)\n\n# Inputs\nsepal_length = float(input(\"Enter sepal length: \"))\nsepal_width = float(input(\"Enter sepal width: \"))\npetal_length = float(input(\"Enter petal length: \"))\npetal_width = float(input(\"Enter petal width: \"))\n\n# Create panda data frame with inputted data\nindex = [0]\nd = {'sepal_length': sepal_length, 'sepal_width': sepal_width, 'petal_length': petal_length, 'petal_width': petal_width}\npredict_df = pd.DataFrame(data=d, index=index)\n\n# Create np array of features\npredict_X = np.array(predict_df)\n\n# Need to scale new X feature values\n# predict_X = preprocessing.scale(predict_X, axis=1)\n\n# Make a prediction against prediction features\nprediction = clf.predict(predict_X)\n\nprint(predict_X, prediction)\n\nrounded_prediction = int(round(prediction[0]))\n\nif rounded_prediction == 0:\n    print(\"== Predicted as Setosa ==\")\nelif rounded_prediction == 1:\n    print(\"== Predicted as Versicolor ==\")\nelif rounded_prediction == 2:\n    print(\"== Predicted as Virginica ==\")\nelse:\n    print(\"== Unable to make a prediction ==\")\n</code></pre>\n\n<p>Here is an example of my output with preprocessing enabled. I'll be using one of the lines from the CSV as an example (6.4 sepal length, 3.2 sepal width, 4.5 petal length and 1.5 petal width) which should equal the versicolor species (1):</p>\n\n<pre><code>Confidence: 0.9449475378336242\nEnter sepal length: 6.4\nEnter sepal width: 3.2\nEnter petal length: 4.5\nEnter petal width: 1.5\n[[ 1.39427847 -0.39039797  0.33462683 -1.33850733]] [0.41069281]\n== Predicted as Setosa ==\n</code></pre>\n\n<p>Now with preprocessing commented out:</p>\n\n<pre><code>Confidence: 0.9132522144785978\nEnter sepal length: 6.4\nEnter sepal width: 3.2\nEnter petal length: 4.5\nEnter petal width: 1.5\n[[6.4 3.2 4.5 1.5]] [1.29119283]\n== Predicted as Versicolor ==\n</code></pre>\n\n<p>It seems I'm either doing the preprocessing wrong, or there's an extra step that I've missed out. I'm sorry if I get some of the terminology wrong and thanks in advance for answering.</p>\n <machine-learning><python><preprocessing><p>I think your methodology is correct, but this line:</p>\n\n<pre><code># Scale features\n# X = preprocessing.scale(X)\n</code></pre>\n\n<p>should be changed to:</p>\n\n<pre><code># Scale features\n# X = preprocessing.scale(X, axis = 1)\n</code></pre>\n\n<p>As the default for scale is to set axis to 0 (I wonder why!). If the problem persists comment it and I will edit.</p>\n\n<p><strong>Edit</strong></p>\n\n<p>Although your methodology is not wrong, it is more suitable to use sklearn StandardScaler. See <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\" rel=\"nofollow noreferrer\">the documentation</a> of this class. Usually, it is better to fit the scaler with the training data and transform the test data according to that fit.</p>\n<p>When you decided you have to scale your data, you usually have to follow these steps:</p>\n\n<p>For training:</p>\n\n<ol>\n<li>Scale / Standarize the training set</li>\n<li>Store the scaling / standarization factors of the training set</li>\n<li>Train the model</li>\n</ol>\n\n<p>For predicting:</p>\n\n<ol>\n<li>Scale / standarize the input data, but very important, with the scaling/standarization factors stored during the training process. You dont have to compute the min, max or mean values of the new data.</li>\n<li>Predict</li>\n</ol>\n\n<p>The reason is that you have to map the new data to the same feature-space used for the training process, so you have to scale/std it with the same factors, otherwise, you are changing the feature space.</p>\n",
                "codes": [
                    [
                        "# Scale features\n# X = preprocessing.scale(X)\n",
                        "# Scale features\n# X = preprocessing.scale(X, axis = 1)\n"
                    ],
                    []
                ],
                "question_id:": "31969",
                "question_votes:": "2",
                "question_text:": "<p>So I'm a newbie to machine learning and am currently using the iris data set. I ran through a quick online tutorial about predicting stock prices and thought I'd try and do the iris one myself.</p>\n\n<p>The issue I'm having is that I'm using preprocessing to scale the data to train my classifier. However when I make a prediction, the answer is also scaled. When I comment out all the preprocessing, I get accurate results. Is there a way to scale the prediction back?</p>\n\n<p>The outputs are rounded to 0, 1 or 2 with each number representing one of three species.</p>\n\n<p>You can see my code below:</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing, model_selection\nfrom sklearn.linear_model import LinearRegression\n\ndf = pd.read_csv(\"iris.csv\")\n\n# setosa - 0\n# versicolor - 1\n# virginica - 2\ndf = df.replace(\"setosa\", 0)\ndf = df.replace(\"versicolor\", 1)\ndf = df.replace(\"virginica\", 2)\n\nX = np.array(df.drop(['species'], 1))\n\ny = np.array(df['species'])\n\n# Scale features\n# X = preprocessing.scale(X)\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)\n\nclf = LinearRegression(n_jobs=1)  # Linear regression clf\n\nclf.fit(X_train, y_train)\n\nconfidence = clf.score(X_test, y_test)\n\nprint(\"Confidence: \" + confidence)\n\n# Inputs\nsepal_length = float(input(\"Enter sepal length: \"))\nsepal_width = float(input(\"Enter sepal width: \"))\npetal_length = float(input(\"Enter petal length: \"))\npetal_width = float(input(\"Enter petal width: \"))\n\n# Create panda data frame with inputted data\nindex = [0]\nd = {'sepal_length': sepal_length, 'sepal_width': sepal_width, 'petal_length': petal_length, 'petal_width': petal_width}\npredict_df = pd.DataFrame(data=d, index=index)\n\n# Create np array of features\npredict_X = np.array(predict_df)\n\n# Need to scale new X feature values\n# predict_X = preprocessing.scale(predict_X, axis=1)\n\n# Make a prediction against prediction features\nprediction = clf.predict(predict_X)\n\nprint(predict_X, prediction)\n\nrounded_prediction = int(round(prediction[0]))\n\nif rounded_prediction == 0:\n    print(\"== Predicted as Setosa ==\")\nelif rounded_prediction == 1:\n    print(\"== Predicted as Versicolor ==\")\nelif rounded_prediction == 2:\n    print(\"== Predicted as Virginica ==\")\nelse:\n    print(\"== Unable to make a prediction ==\")\n</code></pre>\n\n<p>Here is an example of my output with preprocessing enabled. I'll be using one of the lines from the CSV as an example (6.4 sepal length, 3.2 sepal width, 4.5 petal length and 1.5 petal width) which should equal the versicolor species (1):</p>\n\n<pre><code>Confidence: 0.9449475378336242\nEnter sepal length: 6.4\nEnter sepal width: 3.2\nEnter petal length: 4.5\nEnter petal width: 1.5\n[[ 1.39427847 -0.39039797  0.33462683 -1.33850733]] [0.41069281]\n== Predicted as Setosa ==\n</code></pre>\n\n<p>Now with preprocessing commented out:</p>\n\n<pre><code>Confidence: 0.9132522144785978\nEnter sepal length: 6.4\nEnter sepal width: 3.2\nEnter petal length: 4.5\nEnter petal width: 1.5\n[[6.4 3.2 4.5 1.5]] [1.29119283]\n== Predicted as Versicolor ==\n</code></pre>\n\n<p>It seems I'm either doing the preprocessing wrong, or there's an extra step that I've missed out. I'm sorry if I get some of the terminology wrong and thanks in advance for answering.</p>\n",
                "tags": "<machine-learning><python><preprocessing>",
                "answers": [
                    [
                        "31972",
                        "2",
                        "31969",
                        "",
                        "",
                        "<p>I think your methodology is correct, but this line:</p>\n\n<pre><code># Scale features\n# X = preprocessing.scale(X)\n</code></pre>\n\n<p>should be changed to:</p>\n\n<pre><code># Scale features\n# X = preprocessing.scale(X, axis = 1)\n</code></pre>\n\n<p>As the default for scale is to set axis to 0 (I wonder why!). If the problem persists comment it and I will edit.</p>\n\n<p><strong>Edit</strong></p>\n\n<p>Although your methodology is not wrong, it is more suitable to use sklearn StandardScaler. See <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\" rel=\"nofollow noreferrer\">the documentation</a> of this class. Usually, it is better to fit the scaler with the training data and transform the test data according to that fit.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "31971",
                        "2",
                        "31969",
                        "",
                        "",
                        "<p>When you decided you have to scale your data, you usually have to follow these steps:</p>\n\n<p>For training:</p>\n\n<ol>\n<li>Scale / Standarize the training set</li>\n<li>Store the scaling / standarization factors of the training set</li>\n<li>Train the model</li>\n</ol>\n\n<p>For predicting:</p>\n\n<ol>\n<li>Scale / standarize the input data, but very important, with the scaling/standarization factors stored during the training process. You dont have to compute the min, max or mean values of the new data.</li>\n<li>Predict</li>\n</ol>\n\n<p>The reason is that you have to map the new data to the same feature-space used for the training process, so you have to scale/std it with the same factors, otherwise, you are changing the feature space.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13323",
            "_score": 12.88739,
            "_source": {
                "title": "How can positional encodings including a sine operation be linearly transformable for any offset?",
                "content": "How can positional encodings including a sine operation be linearly transformable for any offset? <p>In the paper <a href=\"https://arxiv.org/pdf/1706.03762.pdf\" rel=\"nofollow noreferrer\">\"Attention is all you need\"</a> the authors add a positional encoding to each token in the sequence (section 3.5). The following encoding is chosen:</p>\n\n<p><span class=\"math-container\">$ PE(pos, 2dim) = sin(pos / 10000 ^ {2dim/d_{model}} ) $</span></p>\n\n<p><span class=\"math-container\">$ PE(pos, 2dim+1) = cos(pos / 10000 ^ {2dim/d_{model}} ) $</span></p>\n\n<p>The text states that \"for any fixed offset <span class=\"math-container\">$k$</span>, <span class=\"math-container\">$PE(pos+k)$</span> can be represented as a linear function of <span class=\"math-container\">$PE(pos)$</span>\". This did not seem obvious due to me due to the nonlinearity of the sine function. Other resources like <a href=\"http://mlexplained.com/2017/12/29/attention-is-all-you-need-explained/\" rel=\"nofollow noreferrer\">Attention is all you need Explained</a> mention this property but do not go deeper into it.</p>\n\n<p>I decided to experiment with this by attempting to map a number of outputs from the <span class=\"math-container\">$PE(pos)$</span> function to outputs with a given offset <span class=\"math-container\">$k$</span>. </p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef PE_even(pos, dim):\n    \"\"\" This corresponds to the 2dim state. \"\"\"\n    size = 10000\n    d_Model = 512\n    return np.sin(pos / (size ** (2 * dim / d_Model)))\n\npositions = pd.Series(np.arange(0, 1000))\n\nk = 10\na = positions.apply(lambda p: PE_even(p, 64))\nb = positions.apply(lambda p: PE_even(p + k, 64))\n\nX = a.values.reshape(-1, 1)\ny = b.values\nr = LinearRegression()\nr.fit(X, y)\nr.score(X, y)\n</code></pre>\n\n<p>However, no offset nor any range of numbers in these dimensions yields a suitable fit. As <span class=\"math-container\">$k$</span> increases and the sine waves resulting from the <span class=\"math-container\">$PE(pos)$</span> function get out of sync, the correlation of the transformation and the truth decreases. Even using simple neural networks with and without linearities does not yield a good fit. </p>\n\n<p>Did I misapprehend the statement in the paper, or is my code or understanding of the underlying math here faulty?</p>\n <machine-learning><math><linear-algebra><p>I elected to ask this question on the Mathematics Stack Exchange and I thought it prudent to add the answer here:</p>\n\n<p><a href=\"https://math.stackexchange.com/q/3119882\">https://math.stackexchange.com/q/3119882</a></p>\n\n<p>From what I have learned from <a href=\"https://math.stackexchange.com/users/30382/servaes\">@Servaes</a>, who was kind enough to answer the question, there is a function </p>\n\n<p><span class=\"math-container\">$\\operatorname{PE}(\\text{pos}+k,2d)=\\operatorname{PE}(\\text{pos},2d)\\cos(k/c^d)+\\operatorname{PE}(\\text{pos},2d+1)\\sin(k/c^d)$</span></p>\n\n<p>that allows for the property of transforming any positional encoding into one with a given offset. However, due to the required use of the sin() and cos() functions this is not a linear transformation. </p>\n",
                "codes": [
                    []
                ],
                "question_id:": "45691",
                "question_votes:": "1",
                "question_text:": "<p>In the paper <a href=\"https://arxiv.org/pdf/1706.03762.pdf\" rel=\"nofollow noreferrer\">\"Attention is all you need\"</a> the authors add a positional encoding to each token in the sequence (section 3.5). The following encoding is chosen:</p>\n\n<p><span class=\"math-container\">$ PE(pos, 2dim) = sin(pos / 10000 ^ {2dim/d_{model}} ) $</span></p>\n\n<p><span class=\"math-container\">$ PE(pos, 2dim+1) = cos(pos / 10000 ^ {2dim/d_{model}} ) $</span></p>\n\n<p>The text states that \"for any fixed offset <span class=\"math-container\">$k$</span>, <span class=\"math-container\">$PE(pos+k)$</span> can be represented as a linear function of <span class=\"math-container\">$PE(pos)$</span>\". This did not seem obvious due to me due to the nonlinearity of the sine function. Other resources like <a href=\"http://mlexplained.com/2017/12/29/attention-is-all-you-need-explained/\" rel=\"nofollow noreferrer\">Attention is all you need Explained</a> mention this property but do not go deeper into it.</p>\n\n<p>I decided to experiment with this by attempting to map a number of outputs from the <span class=\"math-container\">$PE(pos)$</span> function to outputs with a given offset <span class=\"math-container\">$k$</span>. </p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef PE_even(pos, dim):\n    \"\"\" This corresponds to the 2dim state. \"\"\"\n    size = 10000\n    d_Model = 512\n    return np.sin(pos / (size ** (2 * dim / d_Model)))\n\npositions = pd.Series(np.arange(0, 1000))\n\nk = 10\na = positions.apply(lambda p: PE_even(p, 64))\nb = positions.apply(lambda p: PE_even(p + k, 64))\n\nX = a.values.reshape(-1, 1)\ny = b.values\nr = LinearRegression()\nr.fit(X, y)\nr.score(X, y)\n</code></pre>\n\n<p>However, no offset nor any range of numbers in these dimensions yields a suitable fit. As <span class=\"math-container\">$k$</span> increases and the sine waves resulting from the <span class=\"math-container\">$PE(pos)$</span> function get out of sync, the correlation of the transformation and the truth decreases. Even using simple neural networks with and without linearities does not yield a good fit. </p>\n\n<p>Did I misapprehend the statement in the paper, or is my code or understanding of the underlying math here faulty?</p>\n",
                "tags": "<machine-learning><math><linear-algebra>",
                "answers": [
                    [
                        "46008",
                        "2",
                        "45691",
                        "",
                        "",
                        "<p>I elected to ask this question on the Mathematics Stack Exchange and I thought it prudent to add the answer here:</p>\n\n<p><a href=\"https://math.stackexchange.com/q/3119882\">https://math.stackexchange.com/q/3119882</a></p>\n\n<p>From what I have learned from <a href=\"https://math.stackexchange.com/users/30382/servaes\">@Servaes</a>, who was kind enough to answer the question, there is a function </p>\n\n<p><span class=\"math-container\">$\\operatorname{PE}(\\text{pos}+k,2d)=\\operatorname{PE}(\\text{pos},2d)\\cos(k/c^d)+\\operatorname{PE}(\\text{pos},2d+1)\\sin(k/c^d)$</span></p>\n\n<p>that allows for the property of transforming any positional encoding into one with a given offset. However, due to the required use of the sin() and cos() functions this is not a linear transformation. </p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6280",
            "_score": 12.886441,
            "_source": {
                "title": "How to force weights to be non-negative in Linear regression only with Numpy",
                "content": "How to force weights to be non-negative in Linear regression only with Numpy <p>My question is the same as here:\n<a href=\"https://datascience.stackexchange.com/questions/18258/how-to-force-weights-to-be-non-negative-in-linear-regression\">How to force weights to be non-negative in Linear regression</a></p>\n\n<p>Except that I can only use Numpy (I cannot use Scipy or Scikit Learn).\nIndeed, I am running my Python script on a server which doesn't include these modules.</p>\n\n<p>Is there any solution ?</p>\n\n<p>Thank you very much!</p>\n <python><regression><numpy><p>The sklearn implementation of Lasso that can force non-negative weights (as in <a href=\"https://datascience.stackexchange.com/a/19791/24162\">this answer</a>) is based on the <a href=\"https://en.wikipedia.org/wiki/Coordinate_descent\" rel=\"nofollow noreferrer\">coordinate descent</a> algorithm. You can reimplement it, using for example coordinate-wise <a href=\"https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization\" rel=\"nofollow noreferrer\">Newton method</a>. For simplicity, I did not inclide intercept into the model:</p>\n\n<pre><code>import numpy as np\n# generate the data\nnp.random.seed(1)\nn = 1000\nX = np.random.normal(size=(n, 5))\ny = np.dot(X, [0,0,1,2,3]) + np.random.normal(size=n, scale=3)\n# initial solution (with some negative weights):\nbeta = np.dot(np.linalg.inv(np.dot(X.transpose(),X)), np.dot(X.transpose(), y))\nprint(beta)\n# clip the solution from below with zero\nprev_beta = beta.copy()\nbeta = np.maximum(beta, 1)\n# improve the solution by restricted coordinate-wise Newton descent\nhessian = np.dot(X.transpose(), X)\nwhile not (prev_beta == beta).all():\n    prev_beta = beta.copy()\n    for i in range(len(beta)):\n        grad = np.dot(np.dot(X,beta)-y, X)\n        beta[i] = np.maximum(0, beta[i] - grad[i] / hessian[i,i])\nprint(beta)\n</code></pre>\n\n<p>This code will output initial and final beta's:</p>\n\n<pre><code>[-0.01404546 -0.02633036  1.06028543  1.99696564  2.93511618]\n[ 0.          0.          1.05919989  1.99673774  2.93442334]\n</code></pre>\n\n<p>You can see that OLS beta differ from your optimal beta not only in the first two coefficients (that have been negative), but the rest of coefficients were also adjusted.</p>\n",
                "codes": [
                    [
                        "import numpy as np\n# generate the data\nnp.random.seed(1)\nn = 1000\nX = np.random.normal(size=(n, 5))\ny = np.dot(X, [0,0,1,2,3]) + np.random.normal(size=n, scale=3)\n# initial solution (with some negative weights):\nbeta = np.dot(np.linalg.inv(np.dot(X.transpose(),X)), np.dot(X.transpose(), y))\nprint(beta)\n# clip the solution from below with zero\nprev_beta = beta.copy()\nbeta = np.maximum(beta, 1)\n# improve the solution by restricted coordinate-wise Newton descent\nhessian = np.dot(X.transpose(), X)\nwhile not (prev_beta == beta).all():\n    prev_beta = beta.copy()\n    for i in range(len(beta)):\n        grad = np.dot(np.dot(X,beta)-y, X)\n        beta[i] = np.maximum(0, beta[i] - grad[i] / hessian[i,i])\nprint(beta)\n",
                        "[-0.01404546 -0.02633036  1.06028543  1.99696564  2.93511618]\n[ 0.          0.          1.05919989  1.99673774  2.93442334]\n"
                    ]
                ],
                "question_id:": "24595",
                "question_votes:": "",
                "question_text:": "<p>My question is the same as here:\n<a href=\"https://datascience.stackexchange.com/questions/18258/how-to-force-weights-to-be-non-negative-in-linear-regression\">How to force weights to be non-negative in Linear regression</a></p>\n\n<p>Except that I can only use Numpy (I cannot use Scipy or Scikit Learn).\nIndeed, I am running my Python script on a server which doesn't include these modules.</p>\n\n<p>Is there any solution ?</p>\n\n<p>Thank you very much!</p>\n",
                "tags": "<python><regression><numpy>",
                "answers": [
                    [
                        "24630",
                        "2",
                        "24595",
                        "",
                        "",
                        "<p>The sklearn implementation of Lasso that can force non-negative weights (as in <a href=\"https://datascience.stackexchange.com/a/19791/24162\">this answer</a>) is based on the <a href=\"https://en.wikipedia.org/wiki/Coordinate_descent\" rel=\"nofollow noreferrer\">coordinate descent</a> algorithm. You can reimplement it, using for example coordinate-wise <a href=\"https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization\" rel=\"nofollow noreferrer\">Newton method</a>. For simplicity, I did not inclide intercept into the model:</p>\n\n<pre><code>import numpy as np\n# generate the data\nnp.random.seed(1)\nn = 1000\nX = np.random.normal(size=(n, 5))\ny = np.dot(X, [0,0,1,2,3]) + np.random.normal(size=n, scale=3)\n# initial solution (with some negative weights):\nbeta = np.dot(np.linalg.inv(np.dot(X.transpose(),X)), np.dot(X.transpose(), y))\nprint(beta)\n# clip the solution from below with zero\nprev_beta = beta.copy()\nbeta = np.maximum(beta, 1)\n# improve the solution by restricted coordinate-wise Newton descent\nhessian = np.dot(X.transpose(), X)\nwhile not (prev_beta == beta).all():\n    prev_beta = beta.copy()\n    for i in range(len(beta)):\n        grad = np.dot(np.dot(X,beta)-y, X)\n        beta[i] = np.maximum(0, beta[i] - grad[i] / hessian[i,i])\nprint(beta)\n</code></pre>\n\n<p>This code will output initial and final beta's:</p>\n\n<pre><code>[-0.01404546 -0.02633036  1.06028543  1.99696564  2.93511618]\n[ 0.          0.          1.05919989  1.99673774  2.93442334]\n</code></pre>\n\n<p>You can see that OLS beta differ from your optimal beta not only in the first two coefficients (that have been negative), but the rest of coefficients were also adjusted.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17157",
            "_score": 12.796372,
            "_source": {
                "title": "Can we use DecisionTreeClassifier of sklearn for continuous target variable?",
                "content": "Can we use DecisionTreeClassifier of sklearn for continuous target variable? <p>I have a continuous target variable named \"quality\" which ranges from 0 to 10. Also I have 11 input variables in my dataset.</p>\n\n<p>When I'm building my model using DecisionTreeClassifier() of sklearn then I'm getting a score of 60% but when I'm building my model using DecisionTreeRegressor() of sklearn then I'm getting accuracy of 3% only and also RMSE as 85%.</p>\n\n<p>Also, when using Linear Regression my R-squared value is 0.376. Is it good?</p>\n\n<p>Dataset Link : <a href=\"https://archive.ics.uci.edu/ml/datasets/Wine+Quality\" rel=\"nofollow noreferrer\">https://archive.ics.uci.edu/ml/datasets/Wine+Quality</a></p>\n\n<p>Am I doing something wrong?</p>\n\n<p>I need help. Thank you.</p>\n <python><classification><scikit-learn><regression><decision-trees><p>In the Wine Dataset you linked, the <code>quality</code> column is not a continues variable but a discrete. It takes integer value between 0 and 10.</p>\n\n<p>When you use the <code>DecisionTreeClassifier</code>, you make the assumption that your target variable is a multi-class one with the values <code>0,1,2,3,4,5,6,7,8,9,10</code>. So, the model tries to predict one of these and only these values.</p>\n\n<p>When you use the <code>DecisionTreeRegressor</code>, the assumption is that any number between 0 and 10 is acceptable. Like the number <code>4.52356</code>. As a result, the accuracy will be noticeable worst. If you still want to use the Regressor for some reason, you can try to round the outcome and then calculate the accuracy. Keep in mind that RMSA doesn't fit your problem. You have a multi-class and not a regression model.</p>\n<p>All algorithms support both Classification and Regression(continuous target variable). The interesting part is about what data we are going to train the model and how they perform on test data. we'll consider the best out come of the data.</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "55654",
                "question_votes:": "1",
                "question_text:": "<p>I have a continuous target variable named \"quality\" which ranges from 0 to 10. Also I have 11 input variables in my dataset.</p>\n\n<p>When I'm building my model using DecisionTreeClassifier() of sklearn then I'm getting a score of 60% but when I'm building my model using DecisionTreeRegressor() of sklearn then I'm getting accuracy of 3% only and also RMSE as 85%.</p>\n\n<p>Also, when using Linear Regression my R-squared value is 0.376. Is it good?</p>\n\n<p>Dataset Link : <a href=\"https://archive.ics.uci.edu/ml/datasets/Wine+Quality\" rel=\"nofollow noreferrer\">https://archive.ics.uci.edu/ml/datasets/Wine+Quality</a></p>\n\n<p>Am I doing something wrong?</p>\n\n<p>I need help. Thank you.</p>\n",
                "tags": "<python><classification><scikit-learn><regression><decision-trees>",
                "answers": [
                    [
                        "55692",
                        "2",
                        "55654",
                        "",
                        "",
                        "<p>In the Wine Dataset you linked, the <code>quality</code> column is not a continues variable but a discrete. It takes integer value between 0 and 10.</p>\n\n<p>When you use the <code>DecisionTreeClassifier</code>, you make the assumption that your target variable is a multi-class one with the values <code>0,1,2,3,4,5,6,7,8,9,10</code>. So, the model tries to predict one of these and only these values.</p>\n\n<p>When you use the <code>DecisionTreeRegressor</code>, the assumption is that any number between 0 and 10 is acceptable. Like the number <code>4.52356</code>. As a result, the accuracy will be noticeable worst. If you still want to use the Regressor for some reason, you can try to round the outcome and then calculate the accuracy. Keep in mind that RMSA doesn't fit your problem. You have a multi-class and not a regression model.</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "55718",
                        "2",
                        "55654",
                        "",
                        "",
                        "<p>All algorithms support both Classification and Regression(continuous target variable). The interesting part is about what data we are going to train the model and how they perform on test data. we'll consider the best out come of the data.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16526",
            "_score": 12.788824,
            "_source": {
                "title": "Reward negative derivative on linear regression",
                "content": "Reward negative derivative on linear regression <p>I'm actually new to Data Science and I'm trying to make a simple linear regression with only one feature X ( which I added the feature log(X) before adding a polynomial features) on a motley dataset using Python an all the Data Science stack that comes with it (numpy, pandas, sci-kit learn, ...) <br></p>\n\n<p>Here you can find a piece of code of my regression using scikitlearn:</p>\n\n<pre><code>def add_log(x):\n    return np.concatenate((x, np.log(x)), axis=1)\n\n # Fetch the training set\n_X = np.array(X).reshape(-1, 1) # X = [1, 26, 45, ..., 100, ..., 8000 ]\n_Y = np.array(Y).reshape(-1, 1) # Y = [1206.78, 412.4, 20.8, ..., 1.34, ..., 0.034]\nY_train = _Y\nX_train = add_log(_X) if use_log else _X\n\n# Create the pipeline\nsteps = [\n    ('scalar', StandardScaler()),\n    ('poly', PolynomialFeatures(6)),\n    ('model', Lasso(alpha=alpha, fit_intercept=True))\n]\n\n\n\npipeline = Pipeline(steps)\npipeline.fit(X_train, Y_train)\n</code></pre>\n\n<p>My feature X can go between <strong>1</strong> to <strong>~80 000</strong> and Y can go between <strong>0</strong> and <strong>~2M</strong><br></p>\n\n<p>There is one thing I know about the curve I should obtain is that it should always decrease so the derivative <strong>should be always negative</strong></p>\n\n<p>I make a little schema to explain what I expect vs what I have:\n<a href=\"https://i.stack.imgur.com/pycUG.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/pycUG.png\" alt=\"enter image description here\"></a>\nTherefore I would like to reward prediction where derivative <strong>is always negative</strong> even if my data suggest the opposite.</p>\n\n<p>Is there a way to do that with sci-kit learn?\nOr maybe I'm suggesting a bad solution to my problem and there is another way to obtain what I want ? <br></p>\n\n<p>Thank you</p>\n <scikit-learn><linear-regression><p>Its classic outlier. You could for example remove him or replace with new value(by Interpolation).\nYou have many ways to work around this problem.</p>\n\n<p>Links for you:</p>\n\n<p><a href=\"https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba\" rel=\"nofollow noreferrer\">https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba</a></p>\n\n<p>With some code:\n<a href=\"https://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623\" rel=\"nofollow noreferrer\">https://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623</a></p>\n<p>When you use linear regression you always need to define a parametric function you want to fit. So if you know that your fitted curve/line should have a negative slope, you could simply choose a linear function, such as: <code>y = b0 + b1*x + u</code> (no polys!). Judging from your figure, the slope (<code>b1</code>) should be negative. The consequence will be that you probably will not get a great fit since the function is not very flexible. But you will get an easy-to-interpret result. </p>\n\n<p>What you can do to improve performance in this case is to work on your features. You can center the features (divide by mean) or scale them (divide by 1000 or so). However, since this is a linear transformation you will not gain much from this. Another option would be to do a log-log transformation (take logs for <code>y</code> and <code>X</code>). This will give you an interpretation such as \"<em>if X increases by 1%, y changes by b1%</em>\". The advantage is that \"large\" values will become smaller, which gives a better fit on data with large(r) values. Since your data seems to be mostly positive, this could be an option. The model looks like: <code>log(y) = b0 + b1*log(x) + u</code>.</p>\n\n<p>Another approach would be to see if some of your observations are \"outliers\" and cause your estimated function to be \"wobbly\". You can - for instance - define a quadratic model such as: <code>y = b0 + b1*x + b2*x^2 + u</code>, estimate the model, and detect outliers based on Cook's distance. However, this approach seems arbitrary since you would need to remove observations until you get the desired slope. It is not a really good idea to select data until the data fit what we want to see. It may only be an option if just a few observations cause trouble (as it seems to be the case in your plot).</p>\n\n<p>Yet another possibility would be that you \"split\" your data. Here I assume that only observations in some range cause trouble (in you figure the \"low\" x's) while the rest of the observations (\"higer\" x's) follow a linear trend or so. I had exactly the same problem recently. I had a linear trend for the largest part of my x's, while only few observations had a highly non-linear pattern. I detected this using generalised additive models (GAM). Here is a tutorial for a <a href=\"https://codeburst.io/pygam-getting-started-with-generalized-additive-models-in-python-457df5b4705f\" rel=\"nofollow noreferrer\">Python implementation</a>. </p>\n\n<p>This was my result:\n<a href=\"https://i.stack.imgur.com/LFFiQ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/LFFiQ.png\" alt=\"enter image description here\"></a></p>\n\n<p>The figure shows that there is a mostly linear trend for the largest part of the data (lower 90% here). Only the upper 10% caused trouble. So I estimated a linear model, but added an interaction term to alow for a separate slope for the upper 10% of data. By doing so I got a reasonable linear estimate for the slope of the lower 90%, while avoiding a \"biased\" estimate by the \"wobbly\" upper 10%  of data. This works as follows: you generate a dummy/indicator variable which equals <code>I=1</code> for the \"wobbly\" data and <code>I=0</code> otherwise. Then you estimate a linear model like: <code>y = b0 + b1*X + b2*I + b3*I*X + u</code>. The result is that you get an extra intercept (<code>b2</code>) and slope (<code>b3</code>) for the \"wobbly\" part of the data indicated by <code>I</code>. This in turn means that you also get an extra slope for the non-wobbly part of the data (<code>b0, b1</code>).  </p>\n\n<p>Another thing: Why do you use lasso? Lasso is used to \"shrink\" features/variables. You only have one variable, so there is no need to shrink it. I would go for <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" rel=\"nofollow noreferrer\">ordinary least squares</a> (OLS), so a simple linear regression.</p>\n<p><a href=\"https://datascience.stackexchange.com/questions/18258/how-to-force-weights-to-be-non-negative-in-linear-regression\">This question</a> seems related, and I think <a href=\"https://datascience.stackexchange.com/a/19791/75152\">Adarsh's answer</a> can help you out.</p>\n\n<blockquote>\n  <p>Lasso has a parameter positive which can be set to True and force the coefficients to be positive. Further, setting the Regularization coefficient alpha to lie close to 0 makes the Lasso mimic Linear Regression with no regularization.</p>\n</blockquote>\n\n<p>In your case, you need the coefficients to be negative instead of positive.  If you flip the sign of your target value, then this becomes equivalent to forcing positive coefficients.  I think the following modification to your code would work:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def add_log(x):\n    return np.concatenate((x, np.log(x)), axis=1)\n\n# Fetch the training set\n_X = np.array(X).reshape(-1, 1) # X = [1, 26, 45, ..., 100, ..., 8000 ]\n_Y = np.array(Y).reshape(-1, 1) # Y = [1206.78, 412.4, 20.8, ..., 1.34, ..., 0.034]\n\n# flip the sign of the targets\nY_train = -1 * _Y\nX_train = add_log(_X) if use_log else _X\n\n# Create the pipeline\nsteps = [\n    ('scalar', StandardScaler()),\n    ('poly', PolynomialFeatures(6)),\n    ('model', Lasso(alpha=alpha, fit_intercept=True, positive=True))\n]\n\npipeline = Pipeline(steps)\npipeline.fit(X_train, Y_train)\n\n# Don't forget to flip the sign of your model output\n<span class=\"math-container\">```</span>\n</code></pre>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "54289",
                "question_votes:": "4",
                "question_text:": "<p>I'm actually new to Data Science and I'm trying to make a simple linear regression with only one feature X ( which I added the feature log(X) before adding a polynomial features) on a motley dataset using Python an all the Data Science stack that comes with it (numpy, pandas, sci-kit learn, ...) <br></p>\n\n<p>Here you can find a piece of code of my regression using scikitlearn:</p>\n\n<pre><code>def add_log(x):\n    return np.concatenate((x, np.log(x)), axis=1)\n\n # Fetch the training set\n_X = np.array(X).reshape(-1, 1) # X = [1, 26, 45, ..., 100, ..., 8000 ]\n_Y = np.array(Y).reshape(-1, 1) # Y = [1206.78, 412.4, 20.8, ..., 1.34, ..., 0.034]\nY_train = _Y\nX_train = add_log(_X) if use_log else _X\n\n# Create the pipeline\nsteps = [\n    ('scalar', StandardScaler()),\n    ('poly', PolynomialFeatures(6)),\n    ('model', Lasso(alpha=alpha, fit_intercept=True))\n]\n\n\n\npipeline = Pipeline(steps)\npipeline.fit(X_train, Y_train)\n</code></pre>\n\n<p>My feature X can go between <strong>1</strong> to <strong>~80 000</strong> and Y can go between <strong>0</strong> and <strong>~2M</strong><br></p>\n\n<p>There is one thing I know about the curve I should obtain is that it should always decrease so the derivative <strong>should be always negative</strong></p>\n\n<p>I make a little schema to explain what I expect vs what I have:\n<a href=\"https://i.stack.imgur.com/pycUG.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/pycUG.png\" alt=\"enter image description here\"></a>\nTherefore I would like to reward prediction where derivative <strong>is always negative</strong> even if my data suggest the opposite.</p>\n\n<p>Is there a way to do that with sci-kit learn?\nOr maybe I'm suggesting a bad solution to my problem and there is another way to obtain what I want ? <br></p>\n\n<p>Thank you</p>\n",
                "tags": "<scikit-learn><linear-regression>",
                "answers": [
                    [
                        "55295",
                        "2",
                        "54289",
                        "",
                        "",
                        "<p>Its classic outlier. You could for example remove him or replace with new value(by Interpolation).\nYou have many ways to work around this problem.</p>\n\n<p>Links for you:</p>\n\n<p><a href=\"https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba\" rel=\"nofollow noreferrer\">https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba</a></p>\n\n<p>With some code:\n<a href=\"https://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623\" rel=\"nofollow noreferrer\">https://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623</a></p>\n",
                        "",
                        "4"
                    ],
                    [
                        "55298",
                        "2",
                        "54289",
                        "",
                        "",
                        "<p>When you use linear regression you always need to define a parametric function you want to fit. So if you know that your fitted curve/line should have a negative slope, you could simply choose a linear function, such as: <code>y = b0 + b1*x + u</code> (no polys!). Judging from your figure, the slope (<code>b1</code>) should be negative. The consequence will be that you probably will not get a great fit since the function is not very flexible. But you will get an easy-to-interpret result. </p>\n\n<p>What you can do to improve performance in this case is to work on your features. You can center the features (divide by mean) or scale them (divide by 1000 or so). However, since this is a linear transformation you will not gain much from this. Another option would be to do a log-log transformation (take logs for <code>y</code> and <code>X</code>). This will give you an interpretation such as \"<em>if X increases by 1%, y changes by b1%</em>\". The advantage is that \"large\" values will become smaller, which gives a better fit on data with large(r) values. Since your data seems to be mostly positive, this could be an option. The model looks like: <code>log(y) = b0 + b1*log(x) + u</code>.</p>\n\n<p>Another approach would be to see if some of your observations are \"outliers\" and cause your estimated function to be \"wobbly\". You can - for instance - define a quadratic model such as: <code>y = b0 + b1*x + b2*x^2 + u</code>, estimate the model, and detect outliers based on Cook's distance. However, this approach seems arbitrary since you would need to remove observations until you get the desired slope. It is not a really good idea to select data until the data fit what we want to see. It may only be an option if just a few observations cause trouble (as it seems to be the case in your plot).</p>\n\n<p>Yet another possibility would be that you \"split\" your data. Here I assume that only observations in some range cause trouble (in you figure the \"low\" x's) while the rest of the observations (\"higer\" x's) follow a linear trend or so. I had exactly the same problem recently. I had a linear trend for the largest part of my x's, while only few observations had a highly non-linear pattern. I detected this using generalised additive models (GAM). Here is a tutorial for a <a href=\"https://codeburst.io/pygam-getting-started-with-generalized-additive-models-in-python-457df5b4705f\" rel=\"nofollow noreferrer\">Python implementation</a>. </p>\n\n<p>This was my result:\n<a href=\"https://i.stack.imgur.com/LFFiQ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/LFFiQ.png\" alt=\"enter image description here\"></a></p>\n\n<p>The figure shows that there is a mostly linear trend for the largest part of the data (lower 90% here). Only the upper 10% caused trouble. So I estimated a linear model, but added an interaction term to alow for a separate slope for the upper 10% of data. By doing so I got a reasonable linear estimate for the slope of the lower 90%, while avoiding a \"biased\" estimate by the \"wobbly\" upper 10%  of data. This works as follows: you generate a dummy/indicator variable which equals <code>I=1</code> for the \"wobbly\" data and <code>I=0</code> otherwise. Then you estimate a linear model like: <code>y = b0 + b1*X + b2*I + b3*I*X + u</code>. The result is that you get an extra intercept (<code>b2</code>) and slope (<code>b3</code>) for the \"wobbly\" part of the data indicated by <code>I</code>. This in turn means that you also get an extra slope for the non-wobbly part of the data (<code>b0, b1</code>).  </p>\n\n<p>Another thing: Why do you use lasso? Lasso is used to \"shrink\" features/variables. You only have one variable, so there is no need to shrink it. I would go for <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" rel=\"nofollow noreferrer\">ordinary least squares</a> (OLS), so a simple linear regression.</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "55296",
                        "2",
                        "54289",
                        "",
                        "",
                        "<p><a href=\"https://datascience.stackexchange.com/questions/18258/how-to-force-weights-to-be-non-negative-in-linear-regression\">This question</a> seems related, and I think <a href=\"https://datascience.stackexchange.com/a/19791/75152\">Adarsh's answer</a> can help you out.</p>\n\n<blockquote>\n  <p>Lasso has a parameter positive which can be set to True and force the coefficients to be positive. Further, setting the Regularization coefficient alpha to lie close to 0 makes the Lasso mimic Linear Regression with no regularization.</p>\n</blockquote>\n\n<p>In your case, you need the coefficients to be negative instead of positive.  If you flip the sign of your target value, then this becomes equivalent to forcing positive coefficients.  I think the following modification to your code would work:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def add_log(x):\n    return np.concatenate((x, np.log(x)), axis=1)\n\n# Fetch the training set\n_X = np.array(X).reshape(-1, 1) # X = [1, 26, 45, ..., 100, ..., 8000 ]\n_Y = np.array(Y).reshape(-1, 1) # Y = [1206.78, 412.4, 20.8, ..., 1.34, ..., 0.034]\n\n# flip the sign of the targets\nY_train = -1 * _Y\nX_train = add_log(_X) if use_log else _X\n\n# Create the pipeline\nsteps = [\n    ('scalar', StandardScaler()),\n    ('poly', PolynomialFeatures(6)),\n    ('model', Lasso(alpha=alpha, fit_intercept=True, positive=True))\n]\n\npipeline = Pipeline(steps)\npipeline.fit(X_train, Y_train)\n\n# Don't forget to flip the sign of your model output\n<span class=\"math-container\">```</span>\n</code></pre>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8848",
            "_score": 12.741004,
            "_source": {
                "title": "What's the best classification model for this recommendation engine?",
                "content": "What's the best classification model for this recommendation engine? <p>I'm not a data scientist but I'm trying to implement a recommendation engine on my company. My application runs on PHP but I'll use Python to process this data.</p>\n\n<p>My company is an online school, with 40 online courses as of now. I have a CSV file with around 30k users preferences, and it looks like this:</p>\n\n<p><a href=\"https://i.stack.imgur.com/fXx4G.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/fXx4G.png\" alt=\"Dataframe\"></a></p>\n\n<p>0 means that user is not subscribed (I consider here that he has no interest), while 1 means subscribed (interested).</p>\n\n<p>My idea is to compare one single user array such as [0,1,0,0,0,1,1...] with all this data and return a grade for each course with the probability of interest for this user.</p>\n\n<p>I was thinking of using a Multinomial Logistic Regression, but as far as I know (and I don't know much) it would return me a binary result, right?</p>\n\n<p>What classification model would you recommend me to use? Ideally, my result should be something like:</p>\n\n<p>[0.95, 0.1, 0.54, 0.3, 0.87...]</p>\n\n<p>Cheers!</p>\n <python><recommender-system><multiclass-classification><p>Without more information about your dataset, it's impossible to recommend one particular classifier over another.</p>\n\n<p>If you want your classifier to return a vector of probabilities, then if you're using the sklearn library, you could use the <code>predict_proba</code> method.</p>\n\n<p>Here's an example:</p>\n\n<pre><code>from sklearn.datasets import load_digits\ndigits = load_digits(2)\nfrom sklearn.linear_model import LogisticRegression\npreds = LogisticRegression().fit(digits.data, digits.target).predict_proba(digits.data)\nprint([i[1] for i in preds]) \n</code></pre>\n",
                "codes": [
                    [
                        "from sklearn.datasets import load_digits\ndigits = load_digits(2)\nfrom sklearn.linear_model import LogisticRegression\npreds = LogisticRegression().fit(digits.data, digits.target).predict_proba(digits.data)\nprint([i[1] for i in preds]) \n"
                    ]
                ],
                "question_id:": "31932",
                "question_votes:": "1",
                "question_text:": "<p>I'm not a data scientist but I'm trying to implement a recommendation engine on my company. My application runs on PHP but I'll use Python to process this data.</p>\n\n<p>My company is an online school, with 40 online courses as of now. I have a CSV file with around 30k users preferences, and it looks like this:</p>\n\n<p><a href=\"https://i.stack.imgur.com/fXx4G.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/fXx4G.png\" alt=\"Dataframe\"></a></p>\n\n<p>0 means that user is not subscribed (I consider here that he has no interest), while 1 means subscribed (interested).</p>\n\n<p>My idea is to compare one single user array such as [0,1,0,0,0,1,1...] with all this data and return a grade for each course with the probability of interest for this user.</p>\n\n<p>I was thinking of using a Multinomial Logistic Regression, but as far as I know (and I don't know much) it would return me a binary result, right?</p>\n\n<p>What classification model would you recommend me to use? Ideally, my result should be something like:</p>\n\n<p>[0.95, 0.1, 0.54, 0.3, 0.87...]</p>\n\n<p>Cheers!</p>\n",
                "tags": "<python><recommender-system><multiclass-classification>",
                "answers": [
                    [
                        "31934",
                        "2",
                        "31932",
                        "",
                        "",
                        "<p>Without more information about your dataset, it's impossible to recommend one particular classifier over another.</p>\n\n<p>If you want your classifier to return a vector of probabilities, then if you're using the sklearn library, you could use the <code>predict_proba</code> method.</p>\n\n<p>Here's an example:</p>\n\n<pre><code>from sklearn.datasets import load_digits\ndigits = load_digits(2)\nfrom sklearn.linear_model import LogisticRegression\npreds = LogisticRegression().fit(digits.data, digits.target).predict_proba(digits.data)\nprint([i[1] for i in preds]) \n</code></pre>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7606",
            "_score": 12.73221,
            "_source": {
                "title": "How does multicollinearity affect neural networks?",
                "content": "How does multicollinearity affect neural networks? <p><a href=\"https://en.wikipedia.org/wiki/Multicollinearity\" rel=\"noreferrer\">Multicollinearity</a> is a problem for linear regression because the results become unstable / depend too much on single elements (<a href=\"http://blog.datadive.net/selecting-good-features-part-ii-linear-models-and-regularization/\" rel=\"noreferrer\">source</a>).</p>\n\n<p>(Also, the inverse of $X^TX$ doesn't exist so the standard OLS estimator does not exist ... I have no idea how, but <a href=\"https://gist.github.com/MartinThoma/6e7714fd4774b5185ac7c3ace9a5b780\" rel=\"noreferrer\">sklearn deals with it just fine</a>)</p>\n\n<p>Is (perfect) multicollinearity also a problem for neural networks?</p>\n <neural-network><correlation><p>I am playing with a Neural Network for regression tasks (i.e.: one output node) in these days. I got some data, provided by my company, that show very little heterogeneity, with groups of variables that are highly correlated.\nWhen I run a TensorFlow session, and print the loss values across the training epochs, it returns NaNs. I repeated the same model on different, larger and more variegated dataset, and it always worked good.</p>\n\n<p>So, one thing to keep in mind is that excessive multicollinearity could tilt the computation of your loss function.</p>\n<p>Multi colinearity affects the learning of Artificial Neural network.  Since the information in the dependent variable is very less compared to the other variables, the neural network will take more time to converge.</p>\n\n<p>In packages like sklearn, the dependent variables are identified and omitted from the calculation.  I have used the lm function in R and it marks the coefficient of the dependent variable with NA.  one can remove the variable from the calculation and still the coefficients are going to be same.  In these cases, the rank of the x matrix will be less than the number of columns.  </p>\n\n<p>Even though there are no inverse exists for xTx, most of the packages will not calculate the inverse directly, but they will calculate the pseudo inverse.  </p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "28328",
                "question_votes:": "5",
                "question_text:": "<p><a href=\"https://en.wikipedia.org/wiki/Multicollinearity\" rel=\"noreferrer\">Multicollinearity</a> is a problem for linear regression because the results become unstable / depend too much on single elements (<a href=\"http://blog.datadive.net/selecting-good-features-part-ii-linear-models-and-regularization/\" rel=\"noreferrer\">source</a>).</p>\n\n<p>(Also, the inverse of $X^TX$ doesn't exist so the standard OLS estimator does not exist ... I have no idea how, but <a href=\"https://gist.github.com/MartinThoma/6e7714fd4774b5185ac7c3ace9a5b780\" rel=\"noreferrer\">sklearn deals with it just fine</a>)</p>\n\n<p>Is (perfect) multicollinearity also a problem for neural networks?</p>\n",
                "tags": "<neural-network><correlation>",
                "answers": [
                    [
                        "43337",
                        "2",
                        "28328",
                        "",
                        "",
                        "<p>I am playing with a Neural Network for regression tasks (i.e.: one output node) in these days. I got some data, provided by my company, that show very little heterogeneity, with groups of variables that are highly correlated.\nWhen I run a TensorFlow session, and print the loss values across the training epochs, it returns NaNs. I repeated the same model on different, larger and more variegated dataset, and it always worked good.</p>\n\n<p>So, one thing to keep in mind is that excessive multicollinearity could tilt the computation of your loss function.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "28329",
                        "2",
                        "28328",
                        "",
                        "",
                        "<p>Multi colinearity affects the learning of Artificial Neural network.  Since the information in the dependent variable is very less compared to the other variables, the neural network will take more time to converge.</p>\n\n<p>In packages like sklearn, the dependent variables are identified and omitted from the calculation.  I have used the lm function in R and it marks the coefficient of the dependent variable with NA.  one can remove the variable from the calculation and still the coefficients are going to be same.  In these cases, the rank of the x matrix will be less than the number of columns.  </p>\n\n<p>Even though there are no inverse exists for xTx, most of the packages will not calculate the inverse directly, but they will calculate the pseudo inverse.  </p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16044",
            "_score": 12.645705,
            "_source": {
                "title": "Changing categorical data to binary data is not reflected on the dataset",
                "content": "Changing categorical data to binary data is not reflected on the dataset <p>I am working through the Titanic competition.  This is my code so far:</p>\n\n<pre><code>import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\ntrain = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Titanic-Kaggle/master/train.csv\")\ntest = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Titanic-Kaggle/master/test.csv\")\n\ntrain['Sex'].replace(['female', 'male'], [0, 1])\ntrain['Embarked'].replace(['C', 'Q', 'S'], [1, 2, 3])\n\n# Fill missing values in Age feature with each sex\u2019s median value of Age\ntrain['Age'].fillna(train.groupby('Sex')['Age'].transform(\"median\"), inplace=True)\n\nlinReg = LinearRegression()\n\ndata = train[['Pclass', 'Sex', 'Parch', 'Fare', 'Age']]\n\n# implement train_test_split\nx_train, x_test, y_train, y_test = train_test_split(data, train['Survived'], test_size=0.2, random_state=0)\n\n# Training the machine learning algorithm\nlinReg.fit(x_train, y_train)\n\n# Checking the accuracy score of the model\naccuracy = linReg.score(x_test, y_test)\nprint(accuracy*100, '%')\n</code></pre>\n\n<p>This line previously looked like this: <code>data = train[['Pclass', 'Parch', 'Fare', 'Age']]</code>, which ended up giving me an accuracy score of <code>19.5%</code>.  I realized that I didn't include sex so I went ahead and did this:</p>\n\n<p><code>data = train[['Pclass', 'Sex', 'Parch', 'Fare', 'Age']]</code></p>\n\n<p>Then, I got the following error:</p>\n\n<p><code>ValueError: could not convert string to float: 'female'</code></p>\n\n<p>Here I realized that the changes that I've done to my <code>train['Sex']</code> and <code>train['Age']</code> did not reflect on the training and the testing of the model, which seems to be the reason why my model performed at <code>19.5%</code>.  How do I come across this problem?</p>\n <machine-learning><python><scikit-learn><linear-regression><kaggle><p>You need to transform your independent variables into numeric values. Normally for binary variables, we use the 0-1-encoding. Introduce a new variable called is_female. If the observation is a male person then give the variable the value <span class=\"math-container\">$0$</span> and if the observation is a female person give the observation the value <span class=\"math-container\">$1$</span>.</p>\n\n<p>If you have categorical variables like a city with three categories you will need to create additional variables. Imagine we have the possible values <code>[\"New York\", \"London\", \"Moskau\"]</code>. Then you create three variables is_new_york, is_london, is_moskau.\nIf we have an observation from New York this will result in is_new_york=1, is_london=0, is_moskau=0. If we have an observation from London then the values will be is_new_york=0, is_london=1, is_moskau=0 and if we have an observation from Moskau then the values will be is_new_york=0, is_london=0, is_moskau=1. This type of encoding is called one-hot encoding. You can also have multiple cities. For example, if a person lives in Moskau and London then you can use is_new_york=0, is_london=1, is_moskau=1.  </p>\n<p>Though you have converted the values into integer but you are not assigning it.</p>\n\n<pre><code>train['Sex'].replace(['female', 'male'], [0, 1])\ntrain['Embarked'].replace(['C', 'Q', 'S'], [1, 2, 3])\n</code></pre>\n\n<p>should be like that</p>\n\n<pre><code>train['Sex'] = train['Sex'].replace(['female', 'male'], [0, 1])\ntrain['Embarked'] = train['Embarked'].replace(['C', 'Q', 'S'], [1, 2, 3])\n</code></pre>\n\n<p>.</p>\n\n<pre><code>train['Age'].fillna(train.groupby('Sex')['Age'].transform(\"median\"), inplace=True)\n</code></pre>\n\n<p>this code is working without assigning the value just because you have used <strong>inplace=True</strong>. Otherwise you have to assign it back as I mentioned for \"Sex\" and \"Embarked\".</p>\n\n<p><strong>scikit.preprocessing provides us various util methods for handling all such issues. Like <em>LabelEncoder, Imputer</em> for these purposes.</strong></p>\n\n<p><strong><em>LabelEncoder</em>, will convert string to integer values whereas <em>Imputer</em>, will replace the missing value.</strong></p>\n\n<p>Sample code for your reference:</p>\n\n<pre><code>from sklearn.preprocessing import Imputer, LabelEncoder \nfrom collections import defaultdict \ndata = train[['Pclass', 'Sex', 'Parch', 'Fare', 'Age']]\n#If you want to convert all features string to integer \nd = defaultdict(LabelEncoder) \ndata = data.apply(lambda x: d[x.name].fit_transform(x))\n\n#Otherwise you can convert each feature strings separately as mentioned below \nencoder = LabelEncoder() \ndata['Sex'] = encoder.fit_transform(data['Sex'])\n\nimputer = Imputer(strategy=\"median\") \ndata = imputer.fit_transform(data)\n</code></pre>\n",
                "codes": [
                    [],
                    [
                        "train['Sex'].replace(['female', 'male'], [0, 1])\ntrain['Embarked'].replace(['C', 'Q', 'S'], [1, 2, 3])\n",
                        "train['Sex'] = train['Sex'].replace(['female', 'male'], [0, 1])\ntrain['Embarked'] = train['Embarked'].replace(['C', 'Q', 'S'], [1, 2, 3])\n",
                        "train['Age'].fillna(train.groupby('Sex')['Age'].transform(\"median\"), inplace=True)\n",
                        "from sklearn.preprocessing import Imputer, LabelEncoder \nfrom collections import defaultdict \ndata = train[['Pclass', 'Sex', 'Parch', 'Fare', 'Age']]\n#If you want to convert all features string to integer \nd = defaultdict(LabelEncoder) \ndata = data.apply(lambda x: d[x.name].fit_transform(x))\n\n#Otherwise you can convert each feature strings separately as mentioned below \nencoder = LabelEncoder() \ndata['Sex'] = encoder.fit_transform(data['Sex'])\n\nimputer = Imputer(strategy=\"median\") \ndata = imputer.fit_transform(data)\n"
                    ]
                ],
                "question_id:": "53224",
                "question_votes:": "",
                "question_text:": "<p>I am working through the Titanic competition.  This is my code so far:</p>\n\n<pre><code>import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\ntrain = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Titanic-Kaggle/master/train.csv\")\ntest = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Titanic-Kaggle/master/test.csv\")\n\ntrain['Sex'].replace(['female', 'male'], [0, 1])\ntrain['Embarked'].replace(['C', 'Q', 'S'], [1, 2, 3])\n\n# Fill missing values in Age feature with each sex\u2019s median value of Age\ntrain['Age'].fillna(train.groupby('Sex')['Age'].transform(\"median\"), inplace=True)\n\nlinReg = LinearRegression()\n\ndata = train[['Pclass', 'Sex', 'Parch', 'Fare', 'Age']]\n\n# implement train_test_split\nx_train, x_test, y_train, y_test = train_test_split(data, train['Survived'], test_size=0.2, random_state=0)\n\n# Training the machine learning algorithm\nlinReg.fit(x_train, y_train)\n\n# Checking the accuracy score of the model\naccuracy = linReg.score(x_test, y_test)\nprint(accuracy*100, '%')\n</code></pre>\n\n<p>This line previously looked like this: <code>data = train[['Pclass', 'Parch', 'Fare', 'Age']]</code>, which ended up giving me an accuracy score of <code>19.5%</code>.  I realized that I didn't include sex so I went ahead and did this:</p>\n\n<p><code>data = train[['Pclass', 'Sex', 'Parch', 'Fare', 'Age']]</code></p>\n\n<p>Then, I got the following error:</p>\n\n<p><code>ValueError: could not convert string to float: 'female'</code></p>\n\n<p>Here I realized that the changes that I've done to my <code>train['Sex']</code> and <code>train['Age']</code> did not reflect on the training and the testing of the model, which seems to be the reason why my model performed at <code>19.5%</code>.  How do I come across this problem?</p>\n",
                "tags": "<machine-learning><python><scikit-learn><linear-regression><kaggle>",
                "answers": [
                    [
                        "53229",
                        "2",
                        "53224",
                        "",
                        "",
                        "<p>You need to transform your independent variables into numeric values. Normally for binary variables, we use the 0-1-encoding. Introduce a new variable called is_female. If the observation is a male person then give the variable the value <span class=\"math-container\">$0$</span> and if the observation is a female person give the observation the value <span class=\"math-container\">$1$</span>.</p>\n\n<p>If you have categorical variables like a city with three categories you will need to create additional variables. Imagine we have the possible values <code>[\"New York\", \"London\", \"Moskau\"]</code>. Then you create three variables is_new_york, is_london, is_moskau.\nIf we have an observation from New York this will result in is_new_york=1, is_london=0, is_moskau=0. If we have an observation from London then the values will be is_new_york=0, is_london=1, is_moskau=0 and if we have an observation from Moskau then the values will be is_new_york=0, is_london=0, is_moskau=1. This type of encoding is called one-hot encoding. You can also have multiple cities. For example, if a person lives in Moskau and London then you can use is_new_york=0, is_london=1, is_moskau=1.  </p>\n",
                        "",
                        "1"
                    ],
                    [
                        "53247",
                        "2",
                        "53224",
                        "",
                        "",
                        "<p>Though you have converted the values into integer but you are not assigning it.</p>\n\n<pre><code>train['Sex'].replace(['female', 'male'], [0, 1])\ntrain['Embarked'].replace(['C', 'Q', 'S'], [1, 2, 3])\n</code></pre>\n\n<p>should be like that</p>\n\n<pre><code>train['Sex'] = train['Sex'].replace(['female', 'male'], [0, 1])\ntrain['Embarked'] = train['Embarked'].replace(['C', 'Q', 'S'], [1, 2, 3])\n</code></pre>\n\n<p>.</p>\n\n<pre><code>train['Age'].fillna(train.groupby('Sex')['Age'].transform(\"median\"), inplace=True)\n</code></pre>\n\n<p>this code is working without assigning the value just because you have used <strong>inplace=True</strong>. Otherwise you have to assign it back as I mentioned for \"Sex\" and \"Embarked\".</p>\n\n<p><strong>scikit.preprocessing provides us various util methods for handling all such issues. Like <em>LabelEncoder, Imputer</em> for these purposes.</strong></p>\n\n<p><strong><em>LabelEncoder</em>, will convert string to integer values whereas <em>Imputer</em>, will replace the missing value.</strong></p>\n\n<p>Sample code for your reference:</p>\n\n<pre><code>from sklearn.preprocessing import Imputer, LabelEncoder \nfrom collections import defaultdict \ndata = train[['Pclass', 'Sex', 'Parch', 'Fare', 'Age']]\n#If you want to convert all features string to integer \nd = defaultdict(LabelEncoder) \ndata = data.apply(lambda x: d[x.name].fit_transform(x))\n\n#Otherwise you can convert each feature strings separately as mentioned below \nencoder = LabelEncoder() \ndata['Sex'] = encoder.fit_transform(data['Sex'])\n\nimputer = Imputer(strategy=\"median\") \ndata = imputer.fit_transform(data)\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13620",
            "_score": 12.609257,
            "_source": {
                "title": "where does kmeans store its trained model parameters in scikit learn?",
                "content": "where does kmeans store its trained model parameters in scikit learn? <p>Like in linear regression, there is <code>model.intercept_</code> and <code>model.coef_</code> but in kmeans i found  <code>kmeans.inertia_</code> , I dont know what is that.</p>\n <python><scikit-learn><k-means><machine-learning-model><p>K-means stores 4 model parameters namely <code>cluster_centers_</code>, <code>labels_</code>, <code>inertia_</code>, <code>n_iter_</code>. For details on what they store you can look at the official <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\" rel=\"nofollow noreferrer\">documentation.</a> Also, Inertia, or the within-cluster sum of squares criterion, can be recognized as a measure of how internally coherent clusters are. You can see a full description <a href=\"https://scikit-learn.org/stable/modules/clustering.html\" rel=\"nofollow noreferrer\">here</a> under the section: 2.3.2. K-means.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "46394",
                "question_votes:": "",
                "question_text:": "<p>Like in linear regression, there is <code>model.intercept_</code> and <code>model.coef_</code> but in kmeans i found  <code>kmeans.inertia_</code> , I dont know what is that.</p>\n",
                "tags": "<python><scikit-learn><k-means><machine-learning-model>",
                "answers": [
                    [
                        "46398",
                        "2",
                        "46394",
                        "",
                        "",
                        "<p>K-means stores 4 model parameters namely <code>cluster_centers_</code>, <code>labels_</code>, <code>inertia_</code>, <code>n_iter_</code>. For details on what they store you can look at the official <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\" rel=\"nofollow noreferrer\">documentation.</a> Also, Inertia, or the within-cluster sum of squares criterion, can be recognized as a measure of how internally coherent clusters are. You can see a full description <a href=\"https://scikit-learn.org/stable/modules/clustering.html\" rel=\"nofollow noreferrer\">here</a> under the section: 2.3.2. K-means.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16779",
            "_score": 12.501329,
            "_source": {
                "title": "How do I fix mis-rendered matplotlib?",
                "content": "How do I fix mis-rendered matplotlib? <p><strong>How do I correct my data or format it so that it is presentable, and fix my graphs?</strong></p>\n\n<ul>\n<li>Dataset is 345551 rows \u00d7 7 columns.</li>\n<li>I am using numpy, pandas, seaborn and matplot lib.</li>\n<li>It seems that my pricing data is being displayed in scientific notation. </li>\n</ul>\n\n<p>When I fit a linear regression model I get the following coefficients <br></p>\n\n<p><em>property_type= -3.096186e+05<br>\nnew_build= -1.909146e+04<br></em></p>\n\n<p>When I use a train/test split and check my predictions they don't make sense.</p>\n\n<p><em>index=246862<br>\nactual=440000<br>\npredicted=4.252606e+05</em></p>\n\n<p><a href=\"https://i.stack.imgur.com/byQvq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/byQvq.png\" alt=\"graph data is labelled in scientific notation\"></a>\n<a href=\"https://i.stack.imgur.com/rR8EO.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/rR8EO.png\" alt=\"distribution is skewed left, and logged in scientific notation\"></a>\n<a href=\"https://i.stack.imgur.com/jytCt.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/jytCt.png\" alt=\"matplotlib scatter graph does not render correctly, why? \"></a></p>\n <machine-learning><scikit-learn><linear-regression><matplotlib><distribution><p>Try using <code>numpy</code>'s <code>log</code> or <code>log1p</code>. The <code>math</code> module also offers logarithmic functionality.</p>\n\n<p>You can use <code>sklearn</code> to transform your variables - see <code>MinMaxScaler</code>, <code>StandardScaler</code>, etc.</p>\n\n<p>Other transformations like Box-Cox can be found in <code>scipy.stats</code></p>\n",
                "codes": [
                    []
                ],
                "question_id:": "54832",
                "question_votes:": "",
                "question_text:": "<p><strong>How do I correct my data or format it so that it is presentable, and fix my graphs?</strong></p>\n\n<ul>\n<li>Dataset is 345551 rows \u00d7 7 columns.</li>\n<li>I am using numpy, pandas, seaborn and matplot lib.</li>\n<li>It seems that my pricing data is being displayed in scientific notation. </li>\n</ul>\n\n<p>When I fit a linear regression model I get the following coefficients <br></p>\n\n<p><em>property_type= -3.096186e+05<br>\nnew_build= -1.909146e+04<br></em></p>\n\n<p>When I use a train/test split and check my predictions they don't make sense.</p>\n\n<p><em>index=246862<br>\nactual=440000<br>\npredicted=4.252606e+05</em></p>\n\n<p><a href=\"https://i.stack.imgur.com/byQvq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/byQvq.png\" alt=\"graph data is labelled in scientific notation\"></a>\n<a href=\"https://i.stack.imgur.com/rR8EO.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/rR8EO.png\" alt=\"distribution is skewed left, and logged in scientific notation\"></a>\n<a href=\"https://i.stack.imgur.com/jytCt.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/jytCt.png\" alt=\"matplotlib scatter graph does not render correctly, why? \"></a></p>\n",
                "tags": "<machine-learning><scikit-learn><linear-regression><matplotlib><distribution>",
                "answers": [
                    [
                        "54854",
                        "2",
                        "54832",
                        "",
                        "",
                        "<p>Try using <code>numpy</code>'s <code>log</code> or <code>log1p</code>. The <code>math</code> module also offers logarithmic functionality.</p>\n\n<p>You can use <code>sklearn</code> to transform your variables - see <code>MinMaxScaler</code>, <code>StandardScaler</code>, etc.</p>\n\n<p>Other transformations like Box-Cox can be found in <code>scipy.stats</code></p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6135",
            "_score": 12.500683,
            "_source": {
                "title": "Multiple time-series predictions with Random Forests (in Python)",
                "content": "Multiple time-series predictions with Random Forests (in Python) <p>I am interested in time-series forecasting with <a href=\"https://en.wikipedia.org/wiki/Random_forest\" rel=\"nofollow noreferrer\">RandomForest</a>. The basic approach is to use a rolling window and use the data points within the window as features for the RandomForest regression, where we regress the next values after the window on the values within the window. Just plain autoregressive model (with lags), but with Random Forest instead of linear regression.</p>\n\n<h3>Problem:</h3>\n\n<p>If I have more than one time-series (multiple time-series), how to pass them in RF regression?</p>\n\n<p>For example: given two time series $y_1(t)$ and $y_2(t)$, the outcome time series is $z(t)$ and I am interested in predicting the values of $z(t)$ based on the combination of $y_1$ and $y_2$.</p>\n\n<p>What I need, is to use rolling window for each $y_1$ and $y_2$, and then feed these values within the window from both time-series into RF regression, to predict the value of $z(t)$.</p>\n\n<h3>Question:</h3>\n\n<p>How do I incorporate the data from both rolling windows into the input for RF regression?</p>\n <time-series><random-forest><forecast><p>Random forest (as well as most of supervised learning models) accepts a vector $x=(x_1,...x_k)$ for each observation and tries to correctly predict output $y$. So you need to convert your training data to this format. The following <code>pandas</code>-based function will help:</p>\n\n<pre><code>import pandas as pd\n\ndef table2lags(table, max_lag, min_lag=0, separator='_'):\n    \"\"\" Given a dataframe, return a dataframe with different lags of all its columns \"\"\"\n    values=[]\n    for i in range(min_lag, max_lag + 1):\n        values.append(table.shift(i).copy())\n        values[-1].columns = [c + separator + str(i) for c in table.columns]\n    return pd.concat(values, axis=1)\n</code></pre>\n\n<p>For example, the following code:</p>\n\n<pre><code>df = pd.DataFrame({'y1':[1,2,3,4,5], 'y2':[10,20,40,50,30], 'z': [1,4,9,16,25]})\nx = table2lags(df[['y1', 'y2']], 2)\nprint(x)\n</code></pre>\n\n<p>will produce output</p>\n\n<pre><code>   y1_0  y1_1  y1_2  y2_0  y2_1  y2_2\n0   1.0   NaN   NaN  10.0   NaN   NaN\n1   2.0   1.0   NaN  20.0  10.0   NaN\n2   3.0   2.0   1.0  40.0  20.0  10.0\n3   4.0   3.0   2.0  50.0  40.0  20.0\n4   5.0   4.0   3.0  30.0  50.0  40.0\n</code></pre>\n\n<p>The first two rows have missing values, because lags 1 and 2 are undefined on them. You can fill them with what you find appropriate, or simply omit them.</p>\n\n<p>When you have matrix of $x$ values, you can feed it, for example, to a <code>scikit-learn</code> regressor:</p>\n\n<pre><code>from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor().fit(x[2:], df['z'][2:])\n</code></pre>\n\n<p>Finally, a piece of advice. Your model could much improve if you used not only raw lagged values as features, but also their different aggregations: mean, other linear combinations (e.g. ewm), quantiles, etc. Including additional linear combinations into a linear model is useless, but for tree-based models it can be of much help.</p>\n",
                "codes": [
                    [
                        "import pandas as pd\n\ndef table2lags(table, max_lag, min_lag=0, separator='_'):\n    \"\"\" Given a dataframe, return a dataframe with different lags of all its columns \"\"\"\n    values=[]\n    for i in range(min_lag, max_lag + 1):\n        values.append(table.shift(i).copy())\n        values[-1].columns = [c + separator + str(i) for c in table.columns]\n    return pd.concat(values, axis=1)\n",
                        "df = pd.DataFrame({'y1':[1,2,3,4,5], 'y2':[10,20,40,50,30], 'z': [1,4,9,16,25]})\nx = table2lags(df[['y1', 'y2']], 2)\nprint(x)\n",
                        "   y1_0  y1_1  y1_2  y2_0  y2_1  y2_2\n0   1.0   NaN   NaN  10.0   NaN   NaN\n1   2.0   1.0   NaN  20.0  10.0   NaN\n2   3.0   2.0   1.0  40.0  20.0  10.0\n3   4.0   3.0   2.0  50.0  40.0  20.0\n4   5.0   4.0   3.0  30.0  50.0  40.0\n",
                        "from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor().fit(x[2:], df['z'][2:])\n"
                    ]
                ],
                "question_id:": "24108",
                "question_votes:": "3",
                "question_text:": "<p>I am interested in time-series forecasting with <a href=\"https://en.wikipedia.org/wiki/Random_forest\" rel=\"nofollow noreferrer\">RandomForest</a>. The basic approach is to use a rolling window and use the data points within the window as features for the RandomForest regression, where we regress the next values after the window on the values within the window. Just plain autoregressive model (with lags), but with Random Forest instead of linear regression.</p>\n\n<h3>Problem:</h3>\n\n<p>If I have more than one time-series (multiple time-series), how to pass them in RF regression?</p>\n\n<p>For example: given two time series $y_1(t)$ and $y_2(t)$, the outcome time series is $z(t)$ and I am interested in predicting the values of $z(t)$ based on the combination of $y_1$ and $y_2$.</p>\n\n<p>What I need, is to use rolling window for each $y_1$ and $y_2$, and then feed these values within the window from both time-series into RF regression, to predict the value of $z(t)$.</p>\n\n<h3>Question:</h3>\n\n<p>How do I incorporate the data from both rolling windows into the input for RF regression?</p>\n",
                "tags": "<time-series><random-forest><forecast>",
                "answers": [
                    [
                        "24177",
                        "2",
                        "24108",
                        "",
                        "",
                        "<p>Random forest (as well as most of supervised learning models) accepts a vector $x=(x_1,...x_k)$ for each observation and tries to correctly predict output $y$. So you need to convert your training data to this format. The following <code>pandas</code>-based function will help:</p>\n\n<pre><code>import pandas as pd\n\ndef table2lags(table, max_lag, min_lag=0, separator='_'):\n    \"\"\" Given a dataframe, return a dataframe with different lags of all its columns \"\"\"\n    values=[]\n    for i in range(min_lag, max_lag + 1):\n        values.append(table.shift(i).copy())\n        values[-1].columns = [c + separator + str(i) for c in table.columns]\n    return pd.concat(values, axis=1)\n</code></pre>\n\n<p>For example, the following code:</p>\n\n<pre><code>df = pd.DataFrame({'y1':[1,2,3,4,5], 'y2':[10,20,40,50,30], 'z': [1,4,9,16,25]})\nx = table2lags(df[['y1', 'y2']], 2)\nprint(x)\n</code></pre>\n\n<p>will produce output</p>\n\n<pre><code>   y1_0  y1_1  y1_2  y2_0  y2_1  y2_2\n0   1.0   NaN   NaN  10.0   NaN   NaN\n1   2.0   1.0   NaN  20.0  10.0   NaN\n2   3.0   2.0   1.0  40.0  20.0  10.0\n3   4.0   3.0   2.0  50.0  40.0  20.0\n4   5.0   4.0   3.0  30.0  50.0  40.0\n</code></pre>\n\n<p>The first two rows have missing values, because lags 1 and 2 are undefined on them. You can fill them with what you find appropriate, or simply omit them.</p>\n\n<p>When you have matrix of $x$ values, you can feed it, for example, to a <code>scikit-learn</code> regressor:</p>\n\n<pre><code>from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor().fit(x[2:], df['z'][2:])\n</code></pre>\n\n<p>Finally, a piece of advice. Your model could much improve if you used not only raw lagged values as features, but also their different aggregations: mean, other linear combinations (e.g. ewm), quantiles, etc. Including additional linear combinations into a linear model is useless, but for tree-based models it can be of much help.</p>\n",
                        "",
                        "10"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15465",
            "_score": 12.490446,
            "_source": {
                "title": "Weighted Linear Combination of Classifiers",
                "content": "Weighted Linear Combination of Classifiers <p>I am trying to build an ensemble of classifiers whereby I want my algorithm to learn a set of weights such that it can weight the outputs of different classifiers for a set of data points.</p>\n\n<p>I am wondering, how would I go about learning these weights? I tried using automatic differentiation but the weights are not moving at all (no gradient information).</p>\n\n<p>Does anyone know how I can fix this?</p>\n <classification><ensemble-modeling><p>I don't know how to fix your automatic differentiation, but I can show you what I did (and I have seen others do too) when I wanted to achieve the same thing. You can fit a linear meta-classifier on the outputs of your classifiers that you want to ensemble. Here is the implementation from <a href=\"https://github.com/simon-larsson/extrakit-learn\" rel=\"nofollow noreferrer\">my scikit toolbox</a>:</p>\n\n<pre><code>'''\n-------------------------------------------------------\n    Stack Classifier - extrakit-learn\n\n    Author: Simon Larsson &lt;larssonsimon0@gmail.com&gt;\n\n    License: MIT\n-------------------------------------------------------\n'''\n\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.utils.validation import check_X_y, check_array, check_is_fitted\nimport numpy as np\n\nclass StackClassifier(BaseEstimator, ClassifierMixin):\n    ''' Stack Classifier\n\n    Ensemble classifier that uses one meta classifiers and several sub-classifiers.\n    The sub-classifiers give their output to to the meta classifier which will use\n    them as input features.\n\n    Parameters\n    ----------\n    clfs : Classifiers who's output will assist the meta_clf, list classifier\n\n    meta_clf : Ensemble classifier that makes the final output, classifier\n\n    drop_first : Drop first class probability to avoid multi-collinearity, bool\n\n    keep_features : If original input features should be used by meta_clf, bool\n\n    refit : If sub-classifiers should be refit, bool\n    '''\n\n    def __init__(self, clfs, meta_clf, drop_first=True, keep_features=False, refit=True):\n        self.clfs = clfs\n        self.meta_clf = meta_clf\n        self.drop_first = drop_first\n        self.keep_features = keep_features\n        self.refit = refit\n\n    def fit(self, X, y):\n        ''' Fitting of the classifier\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            The training input samples.\n\n        y : array-like, shape (n_samples,)\n            The target values. An array of int.\n\n        Returns\n        -------\n        self : object\n            Returns self.\n        '''\n\n        X, y = check_X_y(X, y, accept_sparse=True)\n\n        # Refit of classifier ensemble\n        if self.refit:\n            for clf in self.clfs:\n                clf.fit(X, y)\n\n        # Build new tier-2 features\n        X_meta = build_meta_X(self.clfs, X, self.keep_features)\n\n        # Fit meta classifer, Stack the ensemble\n        self.meta_clf.fit(X_meta, y)\n\n        # set attributes\n        self.n_features_ = X.shape[1]\n        self.n_meta_features_ = X_meta.shape[1]\n        self.n_clfs_ = len(self.clfs)\n\n        return self\n\n    def predict_proba(self, X):\n        ''' Probability prediction\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            The prediction input samples.\n\n        Returns\n        -------\n        y : ndarray, shape (n_samples,)\n            Returns an array of probabilities, floats.\n        '''\n\n        X = check_array(X, accept_sparse=True)\n        check_is_fitted(self, 'n_features_')\n\n        # Build new tier-2 features\n        X_meta = build_meta_X(self.clfs, X, self.keep_features)\n\n        return self.meta_clf.predict_proba(X_meta)\n\n    def predict(self, X):\n        ''' Classification\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            The prediction input samples.\n\n        Returns\n        -------\n        y : ndarray, shape (n_samples,)\n            Returns an array of classifications, bools.\n        '''\n\n        X = check_array(X, accept_sparse=True)\n        check_is_fitted(self, 'n_features_')\n\n        # Build new tier-2 features\n        X_meta = build_meta_X(self.clfs, X, self.keep_features)\n\n        return self.meta_clf.predict(X_meta)\n\ndef build_meta_X(clfs, X=None, drop_first=True, keep_features=False):\n    ''' Build features that includes outputs of the sub-classifiers\n\n    Parameters\n    ----------\n    clfs : Classifiers that who's output will assist the meta_clf, list classifier\n\n    X : {array-like, sparse matrix}, shape (n_samples, n_features)\n        The prediction input samples.\n\n    drop_first : Drop first proba to avoid multi-collinearity, bool\n\n    keep_features : If original input features should be used by meta_clf, bool\n\n    Returns\n    -------\n    X_meta : {array-like, sparse matrix}, shape (n_samples, n_features + n_clfs*classes)\n                 The prediction input samples for the meta clf.\n    '''\n\n    if keep_features:\n        X_meta = X\n    else:\n        X_meta = None\n\n    for clf in clfs:\n\n        if X_meta is None:\n            if drop_first:\n                X_meta = clf.predict_proba(X)\n            else:\n                X_meta = clf.predict_proba(X)[:, 1:]\n        else:\n            if drop_first:\n                y_ = clf.predict_proba(X)\n            else:\n                y_ = clf.predict_proba(X)[:, 1:]\n            X_meta = np.hstack([X_meta, y_])\n\n    return X_meta\n</code></pre>\n\n<p>This would allow you to use any meta-classifier, but with linear models like ridge/lasso/logistic regression it will acts as learned linear weights of your ensemble classifiers. Like this:</p>\n\n<pre><code>from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xklearn.models import StackClassifier\n\nX, y = make_classification(n_classes=2, n_features=4, n_samples=1000)\n\nmeta_clf = LogisticRegression(solver='lbfgs')\nensemble = [DecisionTreeClassifier(max_depth=1), \n            DecisionTreeClassifier(max_depth=5), \n            DecisionTreeClassifier(max_depth=10)]\n\nstack_clf = StackClassifier(clfs=ensemble, meta_clf=meta_clf)\nstack_clf.fit(X, y)\n\nprint('Weights:', stack_clf.meta_clf.coef_[0],' Bias: ', stack_clf.meta_clf.intercept_)\n</code></pre>\n\n<p>output:</p>\n\n<pre><code>Weights: [0.50017775 2.2626092  6.30510687]  Bias:  [-4.82988374]\n</code></pre>\n",
                "codes": [
                    [
                        "'''\n-------------------------------------------------------\n    Stack Classifier - extrakit-learn\n\n    Author: Simon Larsson <larssonsimon0@gmail.com>\n\n    License: MIT\n-------------------------------------------------------\n'''\n\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.utils.validation import check_X_y, check_array, check_is_fitted\nimport numpy as np\n\nclass StackClassifier(BaseEstimator, ClassifierMixin):\n    ''' Stack Classifier\n\n    Ensemble classifier that uses one meta classifiers and several sub-classifiers.\n    The sub-classifiers give their output to to the meta classifier which will use\n    them as input features.\n\n    Parameters\n    ----------\n    clfs : Classifiers who's output will assist the meta_clf, list classifier\n\n    meta_clf : Ensemble classifier that makes the final output, classifier\n\n    drop_first : Drop first class probability to avoid multi-collinearity, bool\n\n    keep_features : If original input features should be used by meta_clf, bool\n\n    refit : If sub-classifiers should be refit, bool\n    '''\n\n    def __init__(self, clfs, meta_clf, drop_first=True, keep_features=False, refit=True):\n        self.clfs = clfs\n        self.meta_clf = meta_clf\n        self.drop_first = drop_first\n        self.keep_features = keep_features\n        self.refit = refit\n\n    def fit(self, X, y):\n        ''' Fitting of the classifier\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            The training input samples.\n\n        y : array-like, shape (n_samples,)\n            The target values. An array of int.\n\n        Returns\n        -------\n        self : object\n            Returns self.\n        '''\n\n        X, y = check_X_y(X, y, accept_sparse=True)\n\n        # Refit of classifier ensemble\n        if self.refit:\n            for clf in self.clfs:\n                clf.fit(X, y)\n\n        # Build new tier-2 features\n        X_meta = build_meta_X(self.clfs, X, self.keep_features)\n\n        # Fit meta classifer, Stack the ensemble\n        self.meta_clf.fit(X_meta, y)\n\n        # set attributes\n        self.n_features_ = X.shape[1]\n        self.n_meta_features_ = X_meta.shape[1]\n        self.n_clfs_ = len(self.clfs)\n\n        return self\n\n    def predict_proba(self, X):\n        ''' Probability prediction\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            The prediction input samples.\n\n        Returns\n        -------\n        y : ndarray, shape (n_samples,)\n            Returns an array of probabilities, floats.\n        '''\n\n        X = check_array(X, accept_sparse=True)\n        check_is_fitted(self, 'n_features_')\n\n        # Build new tier-2 features\n        X_meta = build_meta_X(self.clfs, X, self.keep_features)\n\n        return self.meta_clf.predict_proba(X_meta)\n\n    def predict(self, X):\n        ''' Classification\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            The prediction input samples.\n\n        Returns\n        -------\n        y : ndarray, shape (n_samples,)\n            Returns an array of classifications, bools.\n        '''\n\n        X = check_array(X, accept_sparse=True)\n        check_is_fitted(self, 'n_features_')\n\n        # Build new tier-2 features\n        X_meta = build_meta_X(self.clfs, X, self.keep_features)\n\n        return self.meta_clf.predict(X_meta)\n\ndef build_meta_X(clfs, X=None, drop_first=True, keep_features=False):\n    ''' Build features that includes outputs of the sub-classifiers\n\n    Parameters\n    ----------\n    clfs : Classifiers that who's output will assist the meta_clf, list classifier\n\n    X : {array-like, sparse matrix}, shape (n_samples, n_features)\n        The prediction input samples.\n\n    drop_first : Drop first proba to avoid multi-collinearity, bool\n\n    keep_features : If original input features should be used by meta_clf, bool\n\n    Returns\n    -------\n    X_meta : {array-like, sparse matrix}, shape (n_samples, n_features + n_clfs*classes)\n                 The prediction input samples for the meta clf.\n    '''\n\n    if keep_features:\n        X_meta = X\n    else:\n        X_meta = None\n\n    for clf in clfs:\n\n        if X_meta is None:\n            if drop_first:\n                X_meta = clf.predict_proba(X)\n            else:\n                X_meta = clf.predict_proba(X)[:, 1:]\n        else:\n            if drop_first:\n                y_ = clf.predict_proba(X)\n            else:\n                y_ = clf.predict_proba(X)[:, 1:]\n            X_meta = np.hstack([X_meta, y_])\n\n    return X_meta\n",
                        "from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xklearn.models import StackClassifier\n\nX, y = make_classification(n_classes=2, n_features=4, n_samples=1000)\n\nmeta_clf = LogisticRegression(solver='lbfgs')\nensemble = [DecisionTreeClassifier(max_depth=1), \n            DecisionTreeClassifier(max_depth=5), \n            DecisionTreeClassifier(max_depth=10)]\n\nstack_clf = StackClassifier(clfs=ensemble, meta_clf=meta_clf)\nstack_clf.fit(X, y)\n\nprint('Weights:', stack_clf.meta_clf.coef_[0],' Bias: ', stack_clf.meta_clf.intercept_)\n",
                        "Weights: [0.50017775 2.2626092  6.30510687]  Bias:  [-4.82988374]\n"
                    ]
                ],
                "question_id:": "51965",
                "question_votes:": "3",
                "question_text:": "<p>I am trying to build an ensemble of classifiers whereby I want my algorithm to learn a set of weights such that it can weight the outputs of different classifiers for a set of data points.</p>\n\n<p>I am wondering, how would I go about learning these weights? I tried using automatic differentiation but the weights are not moving at all (no gradient information).</p>\n\n<p>Does anyone know how I can fix this?</p>\n",
                "tags": "<classification><ensemble-modeling>",
                "answers": [
                    [
                        "51969",
                        "2",
                        "51965",
                        "",
                        "",
                        "<p>I don't know how to fix your automatic differentiation, but I can show you what I did (and I have seen others do too) when I wanted to achieve the same thing. You can fit a linear meta-classifier on the outputs of your classifiers that you want to ensemble. Here is the implementation from <a href=\"https://github.com/simon-larsson/extrakit-learn\" rel=\"nofollow noreferrer\">my scikit toolbox</a>:</p>\n\n<pre><code>'''\n-------------------------------------------------------\n    Stack Classifier - extrakit-learn\n\n    Author: Simon Larsson &lt;larssonsimon0@gmail.com&gt;\n\n    License: MIT\n-------------------------------------------------------\n'''\n\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.utils.validation import check_X_y, check_array, check_is_fitted\nimport numpy as np\n\nclass StackClassifier(BaseEstimator, ClassifierMixin):\n    ''' Stack Classifier\n\n    Ensemble classifier that uses one meta classifiers and several sub-classifiers.\n    The sub-classifiers give their output to to the meta classifier which will use\n    them as input features.\n\n    Parameters\n    ----------\n    clfs : Classifiers who's output will assist the meta_clf, list classifier\n\n    meta_clf : Ensemble classifier that makes the final output, classifier\n\n    drop_first : Drop first class probability to avoid multi-collinearity, bool\n\n    keep_features : If original input features should be used by meta_clf, bool\n\n    refit : If sub-classifiers should be refit, bool\n    '''\n\n    def __init__(self, clfs, meta_clf, drop_first=True, keep_features=False, refit=True):\n        self.clfs = clfs\n        self.meta_clf = meta_clf\n        self.drop_first = drop_first\n        self.keep_features = keep_features\n        self.refit = refit\n\n    def fit(self, X, y):\n        ''' Fitting of the classifier\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            The training input samples.\n\n        y : array-like, shape (n_samples,)\n            The target values. An array of int.\n\n        Returns\n        -------\n        self : object\n            Returns self.\n        '''\n\n        X, y = check_X_y(X, y, accept_sparse=True)\n\n        # Refit of classifier ensemble\n        if self.refit:\n            for clf in self.clfs:\n                clf.fit(X, y)\n\n        # Build new tier-2 features\n        X_meta = build_meta_X(self.clfs, X, self.keep_features)\n\n        # Fit meta classifer, Stack the ensemble\n        self.meta_clf.fit(X_meta, y)\n\n        # set attributes\n        self.n_features_ = X.shape[1]\n        self.n_meta_features_ = X_meta.shape[1]\n        self.n_clfs_ = len(self.clfs)\n\n        return self\n\n    def predict_proba(self, X):\n        ''' Probability prediction\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            The prediction input samples.\n\n        Returns\n        -------\n        y : ndarray, shape (n_samples,)\n            Returns an array of probabilities, floats.\n        '''\n\n        X = check_array(X, accept_sparse=True)\n        check_is_fitted(self, 'n_features_')\n\n        # Build new tier-2 features\n        X_meta = build_meta_X(self.clfs, X, self.keep_features)\n\n        return self.meta_clf.predict_proba(X_meta)\n\n    def predict(self, X):\n        ''' Classification\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            The prediction input samples.\n\n        Returns\n        -------\n        y : ndarray, shape (n_samples,)\n            Returns an array of classifications, bools.\n        '''\n\n        X = check_array(X, accept_sparse=True)\n        check_is_fitted(self, 'n_features_')\n\n        # Build new tier-2 features\n        X_meta = build_meta_X(self.clfs, X, self.keep_features)\n\n        return self.meta_clf.predict(X_meta)\n\ndef build_meta_X(clfs, X=None, drop_first=True, keep_features=False):\n    ''' Build features that includes outputs of the sub-classifiers\n\n    Parameters\n    ----------\n    clfs : Classifiers that who's output will assist the meta_clf, list classifier\n\n    X : {array-like, sparse matrix}, shape (n_samples, n_features)\n        The prediction input samples.\n\n    drop_first : Drop first proba to avoid multi-collinearity, bool\n\n    keep_features : If original input features should be used by meta_clf, bool\n\n    Returns\n    -------\n    X_meta : {array-like, sparse matrix}, shape (n_samples, n_features + n_clfs*classes)\n                 The prediction input samples for the meta clf.\n    '''\n\n    if keep_features:\n        X_meta = X\n    else:\n        X_meta = None\n\n    for clf in clfs:\n\n        if X_meta is None:\n            if drop_first:\n                X_meta = clf.predict_proba(X)\n            else:\n                X_meta = clf.predict_proba(X)[:, 1:]\n        else:\n            if drop_first:\n                y_ = clf.predict_proba(X)\n            else:\n                y_ = clf.predict_proba(X)[:, 1:]\n            X_meta = np.hstack([X_meta, y_])\n\n    return X_meta\n</code></pre>\n\n<p>This would allow you to use any meta-classifier, but with linear models like ridge/lasso/logistic regression it will acts as learned linear weights of your ensemble classifiers. Like this:</p>\n\n<pre><code>from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xklearn.models import StackClassifier\n\nX, y = make_classification(n_classes=2, n_features=4, n_samples=1000)\n\nmeta_clf = LogisticRegression(solver='lbfgs')\nensemble = [DecisionTreeClassifier(max_depth=1), \n            DecisionTreeClassifier(max_depth=5), \n            DecisionTreeClassifier(max_depth=10)]\n\nstack_clf = StackClassifier(clfs=ensemble, meta_clf=meta_clf)\nstack_clf.fit(X, y)\n\nprint('Weights:', stack_clf.meta_clf.coef_[0],' Bias: ', stack_clf.meta_clf.intercept_)\n</code></pre>\n\n<p>output:</p>\n\n<pre><code>Weights: [0.50017775 2.2626092  6.30510687]  Bias:  [-4.82988374]\n</code></pre>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7069",
            "_score": 12.420658,
            "_source": {
                "title": "Is it possible to use the saved xgboost model (with one-hot encoding features) on unseen data (without one-hot encoding) for prediction?",
                "content": "Is it possible to use the saved xgboost model (with one-hot encoding features) on unseen data (without one-hot encoding) for prediction? <p>I think the question is self-explanatory. But let's say you have a data with a few features with categorical data, and when building a model for example XGBoost you one-hot encode categorical features. Now you want to do prediction based on test data using the saved model. Obviously the test data needs to be one-hot encoded and need have similar features as training set. The question is whether it is possible to find a way not one-hot encode the test data and directly use it for prediction? Would this be somehow possible? </p>\n\n<p>To me it appears that whatever comes in to my saved model need to be as it was used during training i.e. one-hot encoded features! But this is not neat, especially when building widgets and dashboards!</p>\n\n<p>Any comments/hints are appreciated. </p>\n <machine-learning><xgboost><prediction><p>A model is built on a specific set of features, which may include categorical features encoded using one-hot encoding.  If you have new data with additional categories, your model has no idea how to interpret the significance of those categories.  You should either map the new value to <em>none</em> of the 1-hot values identified in training, or to an 'other' value.</p>\n\n<p>For example, say you trained on data that had color=[blue,green].  Your one-hot fields would have color_blue and color_green.  You could also have a field called color=other, that you might use to encode very infrequent values.  That's a data preparation choice. So for 'red', you could encode that as either:</p>\n\n<ul>\n<li>color_green = 0</li>\n<li>color_blue = 0</li>\n</ul>\n\n<p>or</p>\n\n<ul>\n<li>color_green = 0</li>\n<li>color_blue = 0</li>\n<li>color_other = 1</li>\n</ul>\n\n<p>Using either of these techniques will work with xgboost, but as xgboost only accepts numeric inputs, you will have to choose one of these methods as a data pre-processing step.</p>\n<p>Since its pretty old post, possibly this response is helpful for others.</p>\n\n<p>Its true that some of the algo's accept data in Categorical format and internally converts into OneHotEncoding. In such cases, model accept the data in raw format and doesnt require any explicit conversion handling.</p>\n\n<p>In case if it's not supported, we have to save both the models, i.e.</p>\n\n<ol>\n<li>Model used for Encoding the data</li>\n<li>Model used for predicting the data</li>\n</ol>\n\n<p>In a simpler way we can save related models in a single file as well.\nRefer code snippet below:</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import OneHotEncoder\nimport pickle as pk\nimport pandas as pd\nimport numpy as np\n\nX,y = pd.read_csv(&lt;\"Some_file.csv\"&gt;) #replace with actual csv file\nfile = open(\"models.pkl\", \"wb\")\n\nencoder = OneHotEncoder(sparse=False)\noneHotEncodedFeature = encoder.fit_transform(X[&lt;'Categorical_feature'&gt;].values.reshape(-1,1))\npk.dump(encoder,file)\n\n# Some processing for concatenating oneHotEncodedFeature with other features and assume it its X again.\nlinReg = LinearRegression()\nlinReg.fit(X,y)\npk.dump(encoder,linReg)\nfile.close()\n\n#Now for prediction in future i.e. during production setup\n\nfile = open(\"model.pkl\", \"rb\")\ntrained_encoder = pk.load(file)\ntrained_model_for_prediction = pk.load(file)\n</code></pre>\n",
                "codes": [
                    [],
                    [
                        "from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import OneHotEncoder\nimport pickle as pk\nimport pandas as pd\nimport numpy as np\n\nX,y = pd.read_csv(<\"Some_file.csv\">) #replace with actual csv file\nfile = open(\"models.pkl\", \"wb\")\n\nencoder = OneHotEncoder(sparse=False)\noneHotEncodedFeature = encoder.fit_transform(X[<'Categorical_feature'>].values.reshape(-1,1))\npk.dump(encoder,file)\n\n# Some processing for concatenating oneHotEncodedFeature with other features and assume it its X again.\nlinReg = LinearRegression()\nlinReg.fit(X,y)\npk.dump(encoder,linReg)\nfile.close()\n\n#Now for prediction in future i.e. during production setup\n\nfile = open(\"model.pkl\", \"rb\")\ntrained_encoder = pk.load(file)\ntrained_model_for_prediction = pk.load(file)\n"
                    ]
                ],
                "question_id:": "26797",
                "question_votes:": "1",
                "question_text:": "<p>I think the question is self-explanatory. But let's say you have a data with a few features with categorical data, and when building a model for example XGBoost you one-hot encode categorical features. Now you want to do prediction based on test data using the saved model. Obviously the test data needs to be one-hot encoded and need have similar features as training set. The question is whether it is possible to find a way not one-hot encode the test data and directly use it for prediction? Would this be somehow possible? </p>\n\n<p>To me it appears that whatever comes in to my saved model need to be as it was used during training i.e. one-hot encoded features! But this is not neat, especially when building widgets and dashboards!</p>\n\n<p>Any comments/hints are appreciated. </p>\n",
                "tags": "<machine-learning><xgboost><prediction>",
                "answers": [
                    [
                        "26798",
                        "2",
                        "26797",
                        "",
                        "",
                        "<p>A model is built on a specific set of features, which may include categorical features encoded using one-hot encoding.  If you have new data with additional categories, your model has no idea how to interpret the significance of those categories.  You should either map the new value to <em>none</em> of the 1-hot values identified in training, or to an 'other' value.</p>\n\n<p>For example, say you trained on data that had color=[blue,green].  Your one-hot fields would have color_blue and color_green.  You could also have a field called color=other, that you might use to encode very infrequent values.  That's a data preparation choice. So for 'red', you could encode that as either:</p>\n\n<ul>\n<li>color_green = 0</li>\n<li>color_blue = 0</li>\n</ul>\n\n<p>or</p>\n\n<ul>\n<li>color_green = 0</li>\n<li>color_blue = 0</li>\n<li>color_other = 1</li>\n</ul>\n\n<p>Using either of these techniques will work with xgboost, but as xgboost only accepts numeric inputs, you will have to choose one of these methods as a data pre-processing step.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "53767",
                        "2",
                        "26797",
                        "",
                        "",
                        "<p>Since its pretty old post, possibly this response is helpful for others.</p>\n\n<p>Its true that some of the algo's accept data in Categorical format and internally converts into OneHotEncoding. In such cases, model accept the data in raw format and doesnt require any explicit conversion handling.</p>\n\n<p>In case if it's not supported, we have to save both the models, i.e.</p>\n\n<ol>\n<li>Model used for Encoding the data</li>\n<li>Model used for predicting the data</li>\n</ol>\n\n<p>In a simpler way we can save related models in a single file as well.\nRefer code snippet below:</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import OneHotEncoder\nimport pickle as pk\nimport pandas as pd\nimport numpy as np\n\nX,y = pd.read_csv(&lt;\"Some_file.csv\"&gt;) #replace with actual csv file\nfile = open(\"models.pkl\", \"wb\")\n\nencoder = OneHotEncoder(sparse=False)\noneHotEncodedFeature = encoder.fit_transform(X[&lt;'Categorical_feature'&gt;].values.reshape(-1,1))\npk.dump(encoder,file)\n\n# Some processing for concatenating oneHotEncodedFeature with other features and assume it its X again.\nlinReg = LinearRegression()\nlinReg.fit(X,y)\npk.dump(encoder,linReg)\nfile.close()\n\n#Now for prediction in future i.e. during production setup\n\nfile = open(\"model.pkl\", \"rb\")\ntrained_encoder = pk.load(file)\ntrained_model_for_prediction = pk.load(file)\n</code></pre>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "31",
            "_score": 12.416427,
            "_source": {
                "title": "Machine learning techniques for estimating users' age based on Facebook sites they like",
                "content": "Machine learning techniques for estimating users' age based on Facebook sites they like <p>I have a database from my Facebook application and I am trying to use machine learning to estimate users' age based on what Facebook sites they like.</p>\n\n<p>There are three crucial characteristics of my database:</p>\n\n<ul>\n<li><p>the age distribution in my training set (12k of users in sum) is skewed towards younger users (i.e. I have 1157 users aged 27, and 23 users aged 65);</p></li>\n<li><p>many sites have no more than 5 likers (I filtered out the FB sites with less than 5 likers).</p></li>\n<li><p>there's many more features than samples.</p></li>\n</ul>\n\n<p>So, my questions are: what strategy would you suggest to prepare the data for further analysis? Should I perform some sort of dimensionality reduction? Which ML method would be most appropriate to use in this case?</p>\n\n<p>I mainly use Python, so Python-specific hints would be greatly appreciated.</p>\n <machine-learning><dimensionality-reduction><python><p>Apart from the fancier methods you could try the Bayes formula</p>\n\n<p>P(I | p1 ... pn) =   P(p1 ... pn | I) P(I) / sum_i (P(p1 ... pn | i) P(i))</p>\n\n<p>P(I | p1 ... pn) is the probability that a user belongs to age group I if he liked p1, .., pn</p>\n\n<p>P(i) is the probability that a user belongs to age group i</p>\n\n<p>P(p1 .. pn | i) is the probability that a user liked p1, .., pn if he belongs to age group i.</p>\n\n<ul>\n<li>You already have the estimates for P(i) from your data: this is just the proportion of users in age group I. </li>\n<li><p>To estimate P(p1 ... pn |i), for each age group i estimate the probability (frequency) p_ij to like a page j. To have p_ij non-zero for all j, you can mix in the frequency for the whole population with a small weight.</p></li>\n<li><p>Then log P(p1...pn| i) = sum(log p_ij, i = p1, .., pn), the sum over all pages that a new user likes. This formula would be approximately true assuming that a user likes the pages in his age group independently. </p></li>\n<li>Theoretically, you should also add log (1-p_ij) for all i that he hasn't liked, but in practice you should find that the sum of log (1-p_ij) will be irrelevantly small, so you won't need too much memory.</li>\n</ul>\n\n<p>If you or someone else has tried this, please comment about the result.</p>\n<p>Another suggestion is to test the <a href=\"http://en.wikipedia.org/wiki/Logistic_regression\" rel=\"noreferrer\">logistic regression</a>. As an added bonus, the  weights (coefficients) of the model will give you an idea of which sites are age-distriminant.  </p>\n\n<p>Sklearn offers the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"noreferrer\">sklearn.linear_model.LogisticRegression</a> package that is designed to handle sparse data as well.</p>\n\n<p>As mentionned in the comments, in the present case, with more input variables than samples, you need to regularize the model (with <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"noreferrer\">sklearn.linear_model.LogisticRegression</a> use the <code>penalty='l1'</code> argument).</p>\n<p>One thing to start off with would be k-NN.  The idea here is that you have a user/item matrix and for some of the users you have a reported age.  The age for a person in the user item matrix might be well determined by something like the mean or median age of some nearest neighbors in the item space.</p>\n\n<p>So you have each user expressed as a vector in item space, find the k nearest neighbors and assign the vector in question some summary stat of the nearest neighbor ages.  You can choose k on a distance cutoff or more realistically by iteratively assigning ages to a train hold out and choosing the k that minimizes the error in that assignment.</p>\n\n<p>If the dimensionality is a problem you can easily perform reduction in this setup by single value decomposition choosing the m vectors that capture the most variance across the group.</p>\n\n<p>In all cases since each feature is binary it seems that cosine similarity would be your go to distance metric.</p>\n\n<p>I need to think a bit more about other approaches (regression, rf, etc...) given the narrow focus of your feature space (all variants of the same action, liking) I think the user/item approach might be the best.</p>\n\n<p>One note of caution, if the ages you have for train are self reported you might need to correct some of them.  People on facebook tend to report ages in the decade they were born.  Plot a histogram of the birth dates (derived from ages) and see if you have spikes at decades like 70s, 80s, 90s.</p>\n<p>I recently did a similar project in Python (predicting opinions using FB like data), and had good results with the following basic process:</p>\n\n<ol>\n<li>Read in the training set (n = N) by iterating over comma-delimited like records line-by-line and use a counter to identify the most popular pages</li>\n<li>For each of the K most popular pages (I used about 5000, but you can play around with different values), use pandas.DataFrame.isin to test whether each individual in the training set likes each page, then make a N x K dataframe of the results (I'll call it xdata_train)</li>\n<li>Create a series (I'll call it ydata_train) containing all of the outcome variables (in my case opinions, in yours age) with the same index as xdata_train</li>\n<li>Set up a random forest classifier through scikit-learn to predict\nydata_train based on xdata_train</li>\n<li>Use scikit-learn's cross-validation testing to tweak parameters and\nrefine accuracy (tweaking number of popular pages, number of trees,\nmin leaf size, etc.)</li>\n<li>Output random forest classifier and list of most popular pages with pickle (or keep in memory if you are doing everything at once)</li>\n<li>Load in the rest of your data, load the list of popular pages (if necessary), and repeat step 2 to produce xdata_new</li>\n<li>Load the random forest classifier (if necessary) and use it to predict values for the xdata_new data</li>\n<li>Output the predicted scores to a new CSV or other output format of your choosing</li>\n</ol>\n\n<p>In your case, you'd need to swap out the classifier for a regressor (so see here: <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html</a>) but otherwise the same process should work without much trouble. </p>\n\n<p>Also, you should be aware of the most amazing feature of random forests in Python: instant parallelization! Those of us who started out doing this in R and then moved over are always amazed, especially when you get to work on a machine with a few dozen cores (see here: <a href=\"http://blog.yhathq.com/posts/comparing-random-forests-in-python-and-r.html\">http://blog.yhathq.com/posts/comparing-random-forests-in-python-and-r.html</a>).</p>\n\n<p>Finally, note that this would be a perfect application for network analysis if you have the data on friends as well as the individuals themselves. If you can analyze the ages of a user's friends, the age of the user will almost certainly be within a year or two of the median among his or her friends, particularly if the users are young enough to have built their friend networks while still in school (since most will be classmates). That prediction would likely trump any you would get from modeling---this is a textbook example of a problem where the right data > the right model every time. </p>\n\n<p>Good luck!</p>\n<p>This is a very interesting problem.</p>\n\n<p>I faced a similar one by analyzing the pictures users upload to the social network. I did the following approach:</p>\n\n<ul>\n<li>Rather than associating data to ages (15 y.o., 27 y.o., ...) what I did is to establish different groups of ages: Less than 18, from 18 to 30 and greater than 30 (this is due to the specific problem we were facing, but you can choose whatever intervals you want). This division helps a lot to solve the problem.</li>\n<li>Afterwards, I created a hierarchical clustering (divisive or aggregative). Then I choose those branches where I had users with known ages (or group ages) and then for that branch I extended the same age to that group.</li>\n</ul>\n\n<p>This approach is <strong>semi-supervised learning</strong> and I recommended it in case you only have some data labeled.</p>\n\n<p>Please, notice that on a social network, people usually lie about the age (just for fun, or sometimes because they want to camuflate themselves on the social net).</p>\n<p>Some research from <a href=\"http://www.dongnguyen.nl/publications.html\" rel=\"nofollow\">D. Nguyen et al.</a> try to predict twitter user's age based on their tweets. Maybe you find them useful. They use logistic and linear regression.</p>\n",
                "codes": [
                    [],
                    [],
                    [],
                    [],
                    [],
                    []
                ],
                "question_id:": "116",
                "question_votes:": "27",
                "question_text:": "<p>I have a database from my Facebook application and I am trying to use machine learning to estimate users' age based on what Facebook sites they like.</p>\n\n<p>There are three crucial characteristics of my database:</p>\n\n<ul>\n<li><p>the age distribution in my training set (12k of users in sum) is skewed towards younger users (i.e. I have 1157 users aged 27, and 23 users aged 65);</p></li>\n<li><p>many sites have no more than 5 likers (I filtered out the FB sites with less than 5 likers).</p></li>\n<li><p>there's many more features than samples.</p></li>\n</ul>\n\n<p>So, my questions are: what strategy would you suggest to prepare the data for further analysis? Should I perform some sort of dimensionality reduction? Which ML method would be most appropriate to use in this case?</p>\n\n<p>I mainly use Python, so Python-specific hints would be greatly appreciated.</p>\n",
                "tags": "<machine-learning><dimensionality-reduction><python>",
                "answers": [
                    [
                        "3757",
                        "2",
                        "116",
                        "",
                        "",
                        "<p>Apart from the fancier methods you could try the Bayes formula</p>\n\n<p>P(I | p1 ... pn) =   P(p1 ... pn | I) P(I) / sum_i (P(p1 ... pn | i) P(i))</p>\n\n<p>P(I | p1 ... pn) is the probability that a user belongs to age group I if he liked p1, .., pn</p>\n\n<p>P(i) is the probability that a user belongs to age group i</p>\n\n<p>P(p1 .. pn | i) is the probability that a user liked p1, .., pn if he belongs to age group i.</p>\n\n<ul>\n<li>You already have the estimates for P(i) from your data: this is just the proportion of users in age group I. </li>\n<li><p>To estimate P(p1 ... pn |i), for each age group i estimate the probability (frequency) p_ij to like a page j. To have p_ij non-zero for all j, you can mix in the frequency for the whole population with a small weight.</p></li>\n<li><p>Then log P(p1...pn| i) = sum(log p_ij, i = p1, .., pn), the sum over all pages that a new user likes. This formula would be approximately true assuming that a user likes the pages in his age group independently. </p></li>\n<li>Theoretically, you should also add log (1-p_ij) for all i that he hasn't liked, but in practice you should find that the sum of log (1-p_ij) will be irrelevantly small, so you won't need too much memory.</li>\n</ul>\n\n<p>If you or someone else has tried this, please comment about the result.</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "174",
                        "2",
                        "116",
                        "",
                        "",
                        "<p>Another suggestion is to test the <a href=\"http://en.wikipedia.org/wiki/Logistic_regression\" rel=\"noreferrer\">logistic regression</a>. As an added bonus, the  weights (coefficients) of the model will give you an idea of which sites are age-distriminant.  </p>\n\n<p>Sklearn offers the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"noreferrer\">sklearn.linear_model.LogisticRegression</a> package that is designed to handle sparse data as well.</p>\n\n<p>As mentionned in the comments, in the present case, with more input variables than samples, you need to regularize the model (with <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"noreferrer\">sklearn.linear_model.LogisticRegression</a> use the <code>penalty='l1'</code> argument).</p>\n",
                        "",
                        "5"
                    ],
                    [
                        "121",
                        "2",
                        "116",
                        "",
                        "",
                        "<p>One thing to start off with would be k-NN.  The idea here is that you have a user/item matrix and for some of the users you have a reported age.  The age for a person in the user item matrix might be well determined by something like the mean or median age of some nearest neighbors in the item space.</p>\n\n<p>So you have each user expressed as a vector in item space, find the k nearest neighbors and assign the vector in question some summary stat of the nearest neighbor ages.  You can choose k on a distance cutoff or more realistically by iteratively assigning ages to a train hold out and choosing the k that minimizes the error in that assignment.</p>\n\n<p>If the dimensionality is a problem you can easily perform reduction in this setup by single value decomposition choosing the m vectors that capture the most variance across the group.</p>\n\n<p>In all cases since each feature is binary it seems that cosine similarity would be your go to distance metric.</p>\n\n<p>I need to think a bit more about other approaches (regression, rf, etc...) given the narrow focus of your feature space (all variants of the same action, liking) I think the user/item approach might be the best.</p>\n\n<p>One note of caution, if the ages you have for train are self reported you might need to correct some of them.  People on facebook tend to report ages in the decade they were born.  Plot a histogram of the birth dates (derived from ages) and see if you have spikes at decades like 70s, 80s, 90s.</p>\n",
                        "",
                        "18"
                    ],
                    [
                        "204",
                        "2",
                        "116",
                        "",
                        "",
                        "<p>I recently did a similar project in Python (predicting opinions using FB like data), and had good results with the following basic process:</p>\n\n<ol>\n<li>Read in the training set (n = N) by iterating over comma-delimited like records line-by-line and use a counter to identify the most popular pages</li>\n<li>For each of the K most popular pages (I used about 5000, but you can play around with different values), use pandas.DataFrame.isin to test whether each individual in the training set likes each page, then make a N x K dataframe of the results (I'll call it xdata_train)</li>\n<li>Create a series (I'll call it ydata_train) containing all of the outcome variables (in my case opinions, in yours age) with the same index as xdata_train</li>\n<li>Set up a random forest classifier through scikit-learn to predict\nydata_train based on xdata_train</li>\n<li>Use scikit-learn's cross-validation testing to tweak parameters and\nrefine accuracy (tweaking number of popular pages, number of trees,\nmin leaf size, etc.)</li>\n<li>Output random forest classifier and list of most popular pages with pickle (or keep in memory if you are doing everything at once)</li>\n<li>Load in the rest of your data, load the list of popular pages (if necessary), and repeat step 2 to produce xdata_new</li>\n<li>Load the random forest classifier (if necessary) and use it to predict values for the xdata_new data</li>\n<li>Output the predicted scores to a new CSV or other output format of your choosing</li>\n</ol>\n\n<p>In your case, you'd need to swap out the classifier for a regressor (so see here: <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html</a>) but otherwise the same process should work without much trouble. </p>\n\n<p>Also, you should be aware of the most amazing feature of random forests in Python: instant parallelization! Those of us who started out doing this in R and then moved over are always amazed, especially when you get to work on a machine with a few dozen cores (see here: <a href=\"http://blog.yhathq.com/posts/comparing-random-forests-in-python-and-r.html\">http://blog.yhathq.com/posts/comparing-random-forests-in-python-and-r.html</a>).</p>\n\n<p>Finally, note that this would be a perfect application for network analysis if you have the data on friends as well as the individuals themselves. If you can analyze the ages of a user's friends, the age of the user will almost certainly be within a year or two of the median among his or her friends, particularly if the users are young enough to have built their friend networks while still in school (since most will be classmates). That prediction would likely trump any you would get from modeling---this is a textbook example of a problem where the right data > the right model every time. </p>\n\n<p>Good luck!</p>\n",
                        "",
                        "7"
                    ],
                    [
                        "574",
                        "2",
                        "116",
                        "",
                        "",
                        "<p>This is a very interesting problem.</p>\n\n<p>I faced a similar one by analyzing the pictures users upload to the social network. I did the following approach:</p>\n\n<ul>\n<li>Rather than associating data to ages (15 y.o., 27 y.o., ...) what I did is to establish different groups of ages: Less than 18, from 18 to 30 and greater than 30 (this is due to the specific problem we were facing, but you can choose whatever intervals you want). This division helps a lot to solve the problem.</li>\n<li>Afterwards, I created a hierarchical clustering (divisive or aggregative). Then I choose those branches where I had users with known ages (or group ages) and then for that branch I extended the same age to that group.</li>\n</ul>\n\n<p>This approach is <strong>semi-supervised learning</strong> and I recommended it in case you only have some data labeled.</p>\n\n<p>Please, notice that on a social network, people usually lie about the age (just for fun, or sometimes because they want to camuflate themselves on the social net).</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "582",
                        "2",
                        "116",
                        "",
                        "",
                        "<p>Some research from <a href=\"http://www.dongnguyen.nl/publications.html\" rel=\"nofollow\">D. Nguyen et al.</a> try to predict twitter user's age based on their tweets. Maybe you find them useful. They use logistic and linear regression.</p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5001",
            "_score": 12.399394,
            "_source": {
                "title": "Question Regarding Multi-label probability predictions",
                "content": "Question Regarding Multi-label probability predictions <p>I have been doing a problem in which I have to predict probabilities for each of the labels in a multi-label (four to be precise) classification problem.</p>\n\n<p>Example of a solution:</p>\n\n<pre><code>Id, North,          East,            West,           South\n1,  0.71663940211,  0.037567315693,  0.03525987339,  0.0021068944991\n...\n</code></pre>\n\n<p>The training data is of the form where each y(i) is labelled either 0,1,2 or 3 (encoded for N,E,W &amp; S respectively)</p>\n\n<p>I will be grateful if you can just tell me how to approach this problem.\nLinks giving direct insight to the problem will also sufficient.</p>\n <machine-learning><multiclass-classification><probability><p>A question is a bit broaden as you do not specify if you do not know how to do it in theory or how to tackle it with a ML method.</p>\n\n<p>Some of ML methods:</p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">LogisticRegression</a> in sklearn handles multiple class</p>\n\n<pre><code>lr = LogisticRegression()\nlr.fit(X, y)\nclass_probabilities = lr.predict_proba(X)  # outputs the probabilities\n</code></pre>\n\n<p>You might also want to consider Support Vector Machines.</p>\n\n<p>Theory: </p>\n\n<p>You can do a \"one vs rest\" when you train a single classifier per class taking the sample of all other classes as negative example. (see <a href=\"https://en.wikipedia.org/wiki/Multiclass_classification\" rel=\"nofollow noreferrer\">wiki article</a> for that) </p>\n",
                "codes": [
                    [
                        "lr = LogisticRegression()\nlr.fit(X, y)\nclass_probabilities = lr.predict_proba(X)  # outputs the probabilities\n"
                    ]
                ],
                "question_id:": "19466",
                "question_votes:": "2",
                "question_text:": "<p>I have been doing a problem in which I have to predict probabilities for each of the labels in a multi-label (four to be precise) classification problem.</p>\n\n<p>Example of a solution:</p>\n\n<pre><code>Id, North,          East,            West,           South\n1,  0.71663940211,  0.037567315693,  0.03525987339,  0.0021068944991\n...\n</code></pre>\n\n<p>The training data is of the form where each y(i) is labelled either 0,1,2 or 3 (encoded for N,E,W &amp; S respectively)</p>\n\n<p>I will be grateful if you can just tell me how to approach this problem.\nLinks giving direct insight to the problem will also sufficient.</p>\n",
                "tags": "<machine-learning><multiclass-classification><probability>",
                "answers": [
                    [
                        "19474",
                        "2",
                        "19466",
                        "",
                        "",
                        "<p>A question is a bit broaden as you do not specify if you do not know how to do it in theory or how to tackle it with a ML method.</p>\n\n<p>Some of ML methods:</p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">LogisticRegression</a> in sklearn handles multiple class</p>\n\n<pre><code>lr = LogisticRegression()\nlr.fit(X, y)\nclass_probabilities = lr.predict_proba(X)  # outputs the probabilities\n</code></pre>\n\n<p>You might also want to consider Support Vector Machines.</p>\n\n<p>Theory: </p>\n\n<p>You can do a \"one vs rest\" when you train a single classifier per class taking the sample of all other classes as negative example. (see <a href=\"https://en.wikipedia.org/wiki/Multiclass_classification\" rel=\"nofollow noreferrer\">wiki article</a> for that) </p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5000",
            "_score": 12.372951,
            "_source": {
                "title": "AUC and classification report in Logistic regression in python",
                "content": "AUC and classification report in Logistic regression in python <p>I have been trying to implement logistic regression in python. Basically the code works and it gives the accuracy of the predictive model at a level of 91% but for some reason the AUC score is 0.5 which is basically the worst possible score because it means that the model is completely random. Also the classification report returns error: \"UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. 'precision', 'predicted', average, warn_for)\". Does anyone know what should I change so it works properly?</p>\n\n<pre><code> import numpy as np\n import pandas as pd\n from sklearn.cross_validation import train_test_split\n from sklearn.linear_model import LogisticRegression\n from sklearn.metrics import accuracy_score  \n from sklearn.preprocessing import StandardScaler\n from sklearn.metrics import roc_auc_score\n from sklearn.metrics import classification_report\n\n data_file = pd.read_csv('loan.csv', delimiter=',')\n\n # variable preprocessing\n\n data_file['loan_status'] = np.where(data_file['loan_status'].isin(['Fully \n Paid', 'Current']), 1, 0)\n loan_stat=data_file['loan_status']\n loan_stat=loan_stat.astype(np.float64)\n\n m = {\n    'n/a': 0,     \n    '&lt; 1 year': 0,\n    '1 year': 1,\n    '2 years': 2,\n    '3 years': 3,\n    '4 years': 4,\n    '5 years': 5,\n    '6 years': 6,\n    '7 years': 7,\n    '8 years': 8,\n    '9 years': 9,\n    '10+ years': 10\n }\n emp_length=data_file.emp_length.map(m)\n emp_length.astype(np.float64)\n\n annual_inc=data_file['annual_inc']\n delinq_2yrs=data_file['delinq_2yrs']\n dti=data_file['dti']\n loan_amnt=data_file['loan_amnt']\n installment=data_file['installment']\n int_rate=data_file['int_rate']\n total_acc=data_file['total_acc']\n open_acc=data_file['open_acc']\n pub_rec=data_file['pub_rec']\n acc_now_delinq=data_file['acc_now_delinq']\n\n #variables combined into one dataframe\n\n X=pd.DataFrame()\n\n X['annua_inc']=annual_inc\n X['delinq_2yrs']=delinq_2yrs\n X['dti']=dti\n X['emp_length']=emp_length\n X['loan_amnt']=loan_amnt\n X['installment']=installment\n X['int_rate']=int_rate\n X['total_acc']=total_acc\n X['open_acc']=open_acc\n X['pub_rec']=pub_rec\n X['acc_now_delinq']=acc_now_delinq\n X['loan_stat']=loan_stat\n\n X=X.dropna(axis=0)\n y=X['loan_stat']\n X=X.drop(['loan_stat'], axis=1)\n\n scaler=StandardScaler()\n X=scaler.fit_transform(X)\n\n X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n random_state=42)\n\n model=LogisticRegression(penalty='l2', C=1)\n model.fit(X_train, y_train)\n score=accuracy_score(y_test, model.predict(X_test))\n roc=roc_auc_score(y_test, model.predict(X_test))\n cr=classification_report(y_test, model.predict(X_test))\n</code></pre>\n\n<p>Here is the link to the data: <a href=\"https://www.kaggle.com/wendykan/lending-club-loan-data/downloads/lending-club-loan-data.zip\" rel=\"nofollow noreferrer\">https://www.kaggle.com/wendykan/lending-club-loan-data/downloads/lending-club-loan-data.zip</a></p>\n <python><scikit-learn><logistic-regression><p>In order to calculate the AUC, you need to have probabilities. Therefore you should use the following function: </p>\n\n<pre><code>roc=roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n</code></pre>\n\n<p>This will give you the probability for each sample in X_test having label 1. </p>\n",
                "codes": [
                    [
                        "roc=roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n"
                    ]
                ],
                "question_id:": "19465",
                "question_votes:": "1",
                "question_text:": "<p>I have been trying to implement logistic regression in python. Basically the code works and it gives the accuracy of the predictive model at a level of 91% but for some reason the AUC score is 0.5 which is basically the worst possible score because it means that the model is completely random. Also the classification report returns error: \"UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. 'precision', 'predicted', average, warn_for)\". Does anyone know what should I change so it works properly?</p>\n\n<pre><code> import numpy as np\n import pandas as pd\n from sklearn.cross_validation import train_test_split\n from sklearn.linear_model import LogisticRegression\n from sklearn.metrics import accuracy_score  \n from sklearn.preprocessing import StandardScaler\n from sklearn.metrics import roc_auc_score\n from sklearn.metrics import classification_report\n\n data_file = pd.read_csv('loan.csv', delimiter=',')\n\n # variable preprocessing\n\n data_file['loan_status'] = np.where(data_file['loan_status'].isin(['Fully \n Paid', 'Current']), 1, 0)\n loan_stat=data_file['loan_status']\n loan_stat=loan_stat.astype(np.float64)\n\n m = {\n    'n/a': 0,     \n    '&lt; 1 year': 0,\n    '1 year': 1,\n    '2 years': 2,\n    '3 years': 3,\n    '4 years': 4,\n    '5 years': 5,\n    '6 years': 6,\n    '7 years': 7,\n    '8 years': 8,\n    '9 years': 9,\n    '10+ years': 10\n }\n emp_length=data_file.emp_length.map(m)\n emp_length.astype(np.float64)\n\n annual_inc=data_file['annual_inc']\n delinq_2yrs=data_file['delinq_2yrs']\n dti=data_file['dti']\n loan_amnt=data_file['loan_amnt']\n installment=data_file['installment']\n int_rate=data_file['int_rate']\n total_acc=data_file['total_acc']\n open_acc=data_file['open_acc']\n pub_rec=data_file['pub_rec']\n acc_now_delinq=data_file['acc_now_delinq']\n\n #variables combined into one dataframe\n\n X=pd.DataFrame()\n\n X['annua_inc']=annual_inc\n X['delinq_2yrs']=delinq_2yrs\n X['dti']=dti\n X['emp_length']=emp_length\n X['loan_amnt']=loan_amnt\n X['installment']=installment\n X['int_rate']=int_rate\n X['total_acc']=total_acc\n X['open_acc']=open_acc\n X['pub_rec']=pub_rec\n X['acc_now_delinq']=acc_now_delinq\n X['loan_stat']=loan_stat\n\n X=X.dropna(axis=0)\n y=X['loan_stat']\n X=X.drop(['loan_stat'], axis=1)\n\n scaler=StandardScaler()\n X=scaler.fit_transform(X)\n\n X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n random_state=42)\n\n model=LogisticRegression(penalty='l2', C=1)\n model.fit(X_train, y_train)\n score=accuracy_score(y_test, model.predict(X_test))\n roc=roc_auc_score(y_test, model.predict(X_test))\n cr=classification_report(y_test, model.predict(X_test))\n</code></pre>\n\n<p>Here is the link to the data: <a href=\"https://www.kaggle.com/wendykan/lending-club-loan-data/downloads/lending-club-loan-data.zip\" rel=\"nofollow noreferrer\">https://www.kaggle.com/wendykan/lending-club-loan-data/downloads/lending-club-loan-data.zip</a></p>\n",
                "tags": "<python><scikit-learn><logistic-regression>",
                "answers": [
                    [
                        "19470",
                        "2",
                        "19465",
                        "",
                        "",
                        "<p>In order to calculate the AUC, you need to have probabilities. Therefore you should use the following function: </p>\n\n<pre><code>roc=roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n</code></pre>\n\n<p>This will give you the probability for each sample in X_test having label 1. </p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "2363",
            "_score": 12.35633,
            "_source": {
                "title": "Python : How to use Multinomial Logistic Regression using SKlearn",
                "content": "Python : How to use Multinomial Logistic Regression using SKlearn <p>I have a test dataset and train dataset as below. I have provided sample data with min records, but my data has more than 1000's of record. Here if you see <code>E</code> is my target variable which I need to predict using an algorithm. It has only four categories like 1, 2, 3, 4. It can take only any of these values.</p>\n\n<h3>Training Dataset:</h3>\n\n<pre><code>A    B    C    D    E\n1    20   30   1    1\n2    22   12   33   2\n3    45   65   77   3\n12   43   55   65   4\n11   25   30   1    1\n22   23   19   31   2\n31   41   11   70   3\n1    48   23   60   4\n</code></pre>\n\n<h3>Test Dataset:</h3>\n\n<pre><code>A    B    C    D    E\n11   21   12   11\n1    2    3    4\n5    6    7    8 \n99   87   65   34 \n11   21   24   12\n</code></pre>\n\n<p>Since <code>E</code> has only 4 categories, I thought of predicting this using Multinomial Logistic Regression (1 vs Rest Logic). I am trying to implement it using Python. </p>\n\n<p>I know the logic that we need to set these targets in a variable and use an algorithm to predict any of these values:</p>\n\n<pre><code>output = [1,2,3,4]\n</code></pre>\n\n<p>But I am stuck at a point on how to use it using python (sklearn) to loop through these values and what algorithm should I use to predict the output values? Any help would be greatly appreciated.</p>\n <python><data-mining><logistic-regression><scikit-learn><p>Put the training data into two numpy arrays:</p>\n\n<pre><code>import numpy as np\n\n# data from columns A - D\nXtrain = np.array([[1,    20,   30,   1],\n                   [2,    22,   12,   33],\n                   [3,    45,   65,   77],\n                   [12,   43,   55,   65],\n                   [11,   25,   30,   1],\n                   [22,   23,   19,   31],\n                   [31,   41,   11,   70],\n                   [1,    48,   23,   60]])\n\n# data from column E\nytrain = np.array([1, 2, 3, 4, 1, 2, 3, 4])\n</code></pre>\n\n<p>Then train a logistic regression model:</p>\n\n<pre><code>from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression().fit(Xtrain, ytrain)\n</code></pre>\n\n<p>Make predictions (on the training data):</p>\n\n<pre><code>yhat = lr.predict(Xtrain)\n</code></pre>\n\n<p>=> results in \"1, 4, 3, 4, 1, 2, 3, 4\".. so it's got 7 right and 1 wrong.</p>\n\n<p>Calculate accuracy:</p>\n\n<pre><code>from sklearn.metrics import accuracy_score\n\naccuracy_score(ytrain, yhat)\n</code></pre>\n\n<p>=> results in 87.5% accuracy</p>\n\n<p>To make predictions for new data, just create another numpy array containing your test data and call <code>lr.predict</code> on it.</p>\n\n<p>You might also want to look into parameter tuning to improve your score. For example the LogisticRegression class has some parameters that control regularization - tuning them with methods found in sklearn.grid_search might improve your score.</p>\n",
                "codes": [
                    [
                        "import numpy as np\n\n# data from columns A - D\nXtrain = np.array([[1,    20,   30,   1],\n                   [2,    22,   12,   33],\n                   [3,    45,   65,   77],\n                   [12,   43,   55,   65],\n                   [11,   25,   30,   1],\n                   [22,   23,   19,   31],\n                   [31,   41,   11,   70],\n                   [1,    48,   23,   60]])\n\n# data from column E\nytrain = np.array([1, 2, 3, 4, 1, 2, 3, 4])\n",
                        "from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression().fit(Xtrain, ytrain)\n",
                        "yhat = lr.predict(Xtrain)\n",
                        "from sklearn.metrics import accuracy_score\n\naccuracy_score(ytrain, yhat)\n"
                    ]
                ],
                "question_id:": "11334",
                "question_votes:": "3",
                "question_text:": "<p>I have a test dataset and train dataset as below. I have provided sample data with min records, but my data has more than 1000's of record. Here if you see <code>E</code> is my target variable which I need to predict using an algorithm. It has only four categories like 1, 2, 3, 4. It can take only any of these values.</p>\n\n<h3>Training Dataset:</h3>\n\n<pre><code>A    B    C    D    E\n1    20   30   1    1\n2    22   12   33   2\n3    45   65   77   3\n12   43   55   65   4\n11   25   30   1    1\n22   23   19   31   2\n31   41   11   70   3\n1    48   23   60   4\n</code></pre>\n\n<h3>Test Dataset:</h3>\n\n<pre><code>A    B    C    D    E\n11   21   12   11\n1    2    3    4\n5    6    7    8 \n99   87   65   34 \n11   21   24   12\n</code></pre>\n\n<p>Since <code>E</code> has only 4 categories, I thought of predicting this using Multinomial Logistic Regression (1 vs Rest Logic). I am trying to implement it using Python. </p>\n\n<p>I know the logic that we need to set these targets in a variable and use an algorithm to predict any of these values:</p>\n\n<pre><code>output = [1,2,3,4]\n</code></pre>\n\n<p>But I am stuck at a point on how to use it using python (sklearn) to loop through these values and what algorithm should I use to predict the output values? Any help would be greatly appreciated.</p>\n",
                "tags": "<python><data-mining><logistic-regression><scikit-learn>",
                "answers": [
                    [
                        "11336",
                        "2",
                        "11334",
                        "",
                        "",
                        "<p>Put the training data into two numpy arrays:</p>\n\n<pre><code>import numpy as np\n\n# data from columns A - D\nXtrain = np.array([[1,    20,   30,   1],\n                   [2,    22,   12,   33],\n                   [3,    45,   65,   77],\n                   [12,   43,   55,   65],\n                   [11,   25,   30,   1],\n                   [22,   23,   19,   31],\n                   [31,   41,   11,   70],\n                   [1,    48,   23,   60]])\n\n# data from column E\nytrain = np.array([1, 2, 3, 4, 1, 2, 3, 4])\n</code></pre>\n\n<p>Then train a logistic regression model:</p>\n\n<pre><code>from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression().fit(Xtrain, ytrain)\n</code></pre>\n\n<p>Make predictions (on the training data):</p>\n\n<pre><code>yhat = lr.predict(Xtrain)\n</code></pre>\n\n<p>=> results in \"1, 4, 3, 4, 1, 2, 3, 4\".. so it's got 7 right and 1 wrong.</p>\n\n<p>Calculate accuracy:</p>\n\n<pre><code>from sklearn.metrics import accuracy_score\n\naccuracy_score(ytrain, yhat)\n</code></pre>\n\n<p>=> results in 87.5% accuracy</p>\n\n<p>To make predictions for new data, just create another numpy array containing your test data and call <code>lr.predict</code> on it.</p>\n\n<p>You might also want to look into parameter tuning to improve your score. For example the LogisticRegression class has some parameters that control regularization - tuning them with methods found in sklearn.grid_search might improve your score.</p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4536",
            "_score": 12.312384,
            "_source": {
                "title": "Sklearn regression problem",
                "content": "Sklearn regression problem <p>I try to fit a data matrix X to an output vector y with a regression model in sklearn. I have some training data and some test data, where the score is the RMSE.</p>\n\n<p>So my best score I achieved with SVR, kernel 'poly' and tuning the hyperparameters 'C', 'degree' and 'gamma' with optunity and cross-validation.</p>\n\n<p>I actually don't know how to achieve better scores so I ask here in this forum for another approach. I tried already KernelRidge, Linear Regression, SVR with other kernels, Neural Networks but all of them gave worse results. It is actually possible to do better, since other people do better in this task, but I have no more Idea what I can do to imporve the score. Any Ideas?</p>\n <scikit-learn><p>Data pre-processing and feature extraction are the two most important parts of a machine learning technique. That's right, NOT THE MODEL. If you have good features then even a very simple model will get amazing results.</p>\n\n<p>Data pre-processing goes from your raw data and remolds it to be better suited to machine learning algorithms. This means pulling out important statistics from your data or converting your data into other formats in order to it being more representative. For example if you are using a technique which is sensitive to range, then you should normalize all your features. If you are using text data you should build word vectors. There are countless ways pre-processing and feature extraction can be implemented.</p>\n\n<p>Then, you want to use feature selection. From all the information you extracted from your data not all of it will be useful. There are machine learning algorithms such as: PCA, LDA, cross-correlation, etc. Which will select the features that are the most representative and ignore the rest.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "17925",
                "question_votes:": "",
                "question_text:": "<p>I try to fit a data matrix X to an output vector y with a regression model in sklearn. I have some training data and some test data, where the score is the RMSE.</p>\n\n<p>So my best score I achieved with SVR, kernel 'poly' and tuning the hyperparameters 'C', 'degree' and 'gamma' with optunity and cross-validation.</p>\n\n<p>I actually don't know how to achieve better scores so I ask here in this forum for another approach. I tried already KernelRidge, Linear Regression, SVR with other kernels, Neural Networks but all of them gave worse results. It is actually possible to do better, since other people do better in this task, but I have no more Idea what I can do to imporve the score. Any Ideas?</p>\n",
                "tags": "<scikit-learn>",
                "answers": [
                    [
                        "17938",
                        "2",
                        "17925",
                        "",
                        "",
                        "<p>Data pre-processing and feature extraction are the two most important parts of a machine learning technique. That's right, NOT THE MODEL. If you have good features then even a very simple model will get amazing results.</p>\n\n<p>Data pre-processing goes from your raw data and remolds it to be better suited to machine learning algorithms. This means pulling out important statistics from your data or converting your data into other formats in order to it being more representative. For example if you are using a technique which is sensitive to range, then you should normalize all your features. If you are using text data you should build word vectors. There are countless ways pre-processing and feature extraction can be implemented.</p>\n\n<p>Then, you want to use feature selection. From all the information you extracted from your data not all of it will be useful. There are machine learning algorithms such as: PCA, LDA, cross-correlation, etc. Which will select the features that are the most representative and ignore the rest.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "363",
            "_score": 12.295245,
            "_source": {
                "title": "Scikit Learn Logistic Regression Memory Leak",
                "content": "Scikit Learn Logistic Regression Memory Leak <p>I'm curious if anyone else has run into this. I have a data set with about 350k samples, each with 4k sparse features. The sparse fill rate is about 0.5%. The data is stored in a <code>scipy.sparse.csr.csr_matrix</code> object, with <code>dtype='numpy.float64'</code>.</p>\n\n<p>I'm using this as an input to sklearn's Logistic Regression classifier. The <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow\">documentation</a> indicates that sparse CSR matrices are acceptable inputs to this classifier. However, when I train the classifier, I get extremely bad memory performance; the memory usage of my process explodes from ~150 MB to fill all the available memory and then everything grinds to a halt as memory swapping to disk takes over.</p>\n\n<p>Does anyone know why this classifier might expand the sparse matrix to a dense matrix? I'm using the default parameters for the classifier at the moment, within an updated anacoda distribution. Thanks!</p>\n\n<pre><code>scipy.__version__ = '0.14.0'\nsklearn.__version__ = '0.15.2'\n</code></pre>\n <efficiency><performance><scikit-learn><p>Ok, this ended up being an RTFM situation, although in this case it was RTF error message.</p>\n\n<p>While running this, I kept getting the following error:</p>\n\n<pre><code>DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n</code></pre>\n\n<p>I assumed that, since this had to do with the target vector, and since it was a warning only, that it would just silently change my target vector to 1-D.</p>\n\n<p>However, when I explicitly converted my target vector to 1-D, my memory problems went away. Apparently having the target vector in an incorrect form caused it to convert my input vectors into dense vectors from sparse vectors.</p>\n\n<p>Lesson learned: <strong>follow the recommendations</strong> when sklearn 'suggests' you do something.</p>\n",
                "codes": [
                    [
                        "DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
                    ]
                ],
                "question_id:": "1223",
                "question_votes:": "4",
                "question_text:": "<p>I'm curious if anyone else has run into this. I have a data set with about 350k samples, each with 4k sparse features. The sparse fill rate is about 0.5%. The data is stored in a <code>scipy.sparse.csr.csr_matrix</code> object, with <code>dtype='numpy.float64'</code>.</p>\n\n<p>I'm using this as an input to sklearn's Logistic Regression classifier. The <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow\">documentation</a> indicates that sparse CSR matrices are acceptable inputs to this classifier. However, when I train the classifier, I get extremely bad memory performance; the memory usage of my process explodes from ~150 MB to fill all the available memory and then everything grinds to a halt as memory swapping to disk takes over.</p>\n\n<p>Does anyone know why this classifier might expand the sparse matrix to a dense matrix? I'm using the default parameters for the classifier at the moment, within an updated anacoda distribution. Thanks!</p>\n\n<pre><code>scipy.__version__ = '0.14.0'\nsklearn.__version__ = '0.15.2'\n</code></pre>\n",
                "tags": "<efficiency><performance><scikit-learn>",
                "answers": [
                    [
                        "1224",
                        "2",
                        "1223",
                        "",
                        "",
                        "<p>Ok, this ended up being an RTFM situation, although in this case it was RTF error message.</p>\n\n<p>While running this, I kept getting the following error:</p>\n\n<pre><code>DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n</code></pre>\n\n<p>I assumed that, since this had to do with the target vector, and since it was a warning only, that it would just silently change my target vector to 1-D.</p>\n\n<p>However, when I explicitly converted my target vector to 1-D, my memory problems went away. Apparently having the target vector in an incorrect form caused it to convert my input vectors into dense vectors from sparse vectors.</p>\n\n<p>Lesson learned: <strong>follow the recommendations</strong> when sklearn 'suggests' you do something.</p>\n",
                        "",
                        "6"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5270",
            "_score": 12.284527,
            "_source": {
                "title": "How to use live data to improve a existing model?",
                "content": "How to use live data to improve a existing model? <p>I am using logistic regression to train a model to predict 'click/non-click' using ['browser info', 'publisher info', , 'location', 'time', 'day'].  </p>\n\n<p>I wanted to know the ways in which I can use the new live data to improve the improve the already trained model.   </p>\n\n<p>Does a solution exist which takes into account - change in feature set?</p>\n <machine-learning><logistic-regression><training><p>Suppose you have a model that has been trained on $N$ data over $E$ epochs. This means that the model has seen each of the $N$ examples, $E$ times.</p>\n\n<p>Now say you got $M$ more training data. Normally you would want to train the new ones for $E$ epochs as well. </p>\n\n<p>However if $N$ and $M$ don't come from the same underlying distribution (or don't represent it adequately), this would result in the model \"forgetting\" the first $N$ examples and \"paying more attention\" to the latter $M$ ones.</p>\n\n<p>You could try training your model for $&lt;E$ epochs, so that it learns the latter but doesn't forget the former, but that is purely empirical and very hard to achieve in practice.</p>\n\n<p>You can a few things to avoid this:</p>\n\n<ol>\n<li><strong>Retrain</strong> your whole model using both the $N+M$ examples (which you would shuffle). This would require a new complete training of the model on regular occasions and would be <strong>increasingly</strong> difficult to train (due to the ever increasing size of the training data). This is a <strong>very inefficient</strong> solution and wouldn't work for any on-line training application</li>\n<li>Make use of a model that supports <strong>on-line training</strong>. Some algorithms support incremental (on-line) training, without you needing to retrain the whole thing. A <a href=\"http://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_comparison.html\" rel=\"nofollow noreferrer\">scikit-learn comparison</a> is available.</li>\n<li>Customize an algorithm so that is has the desired effect. For example, you could train a linear SVM incrementally, with a large regularization penalty and an SGD classifier. This is discussed in more detail for scikit-learn <a href=\"https://stackoverflow.com/questions/23056460/does-the-svm-in-sklearn-support-incremental-online-learning\">here</a>.</li>\n</ol>\n",
                "codes": [
                    []
                ],
                "question_id:": "20236",
                "question_votes:": "3",
                "question_text:": "<p>I am using logistic regression to train a model to predict 'click/non-click' using ['browser info', 'publisher info', , 'location', 'time', 'day'].  </p>\n\n<p>I wanted to know the ways in which I can use the new live data to improve the improve the already trained model.   </p>\n\n<p>Does a solution exist which takes into account - change in feature set?</p>\n",
                "tags": "<machine-learning><logistic-regression><training>",
                "answers": [
                    [
                        "20238",
                        "2",
                        "20236",
                        "",
                        "",
                        "<p>Suppose you have a model that has been trained on $N$ data over $E$ epochs. This means that the model has seen each of the $N$ examples, $E$ times.</p>\n\n<p>Now say you got $M$ more training data. Normally you would want to train the new ones for $E$ epochs as well. </p>\n\n<p>However if $N$ and $M$ don't come from the same underlying distribution (or don't represent it adequately), this would result in the model \"forgetting\" the first $N$ examples and \"paying more attention\" to the latter $M$ ones.</p>\n\n<p>You could try training your model for $&lt;E$ epochs, so that it learns the latter but doesn't forget the former, but that is purely empirical and very hard to achieve in practice.</p>\n\n<p>You can a few things to avoid this:</p>\n\n<ol>\n<li><strong>Retrain</strong> your whole model using both the $N+M$ examples (which you would shuffle). This would require a new complete training of the model on regular occasions and would be <strong>increasingly</strong> difficult to train (due to the ever increasing size of the training data). This is a <strong>very inefficient</strong> solution and wouldn't work for any on-line training application</li>\n<li>Make use of a model that supports <strong>on-line training</strong>. Some algorithms support incremental (on-line) training, without you needing to retrain the whole thing. A <a href=\"http://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_comparison.html\" rel=\"nofollow noreferrer\">scikit-learn comparison</a> is available.</li>\n<li>Customize an algorithm so that is has the desired effect. For example, you could train a linear SVM incrementally, with a large regularization penalty and an SGD classifier. This is discussed in more detail for scikit-learn <a href=\"https://stackoverflow.com/questions/23056460/does-the-svm-in-sklearn-support-incremental-online-learning\">here</a>.</li>\n</ol>\n",
                        "",
                        "5"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11832",
            "_score": 12.248193,
            "_source": {
                "title": "How to implement gridsearchCV for onevsrestclassifier of LogisticRegression classifier?",
                "content": "How to implement gridsearchCV for onevsrestclassifier of LogisticRegression classifier? <pre><code>parameters = [{'C': [10**-2, 10**-1, 10**0,10**1, 10**2, 10**3]}]\n\nmodel_tunning = GridSearchCV(OneVsRestClassifier(LogisticRegression(penalty='l1')), param_grid=parameters,scoring=\"f1\")\nmodel_tunning.fit(x_train_multilabel, y_train)\n\n\n\n\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-38-5d5850fe8978&gt; in &lt;module&gt;()\n  2 \n  3 model_tunning = GridSearchCV(OneVsRestClassifier(LogisticRegression(penalty='l1')), param_grid=parameters,scoring=\"f1\")\n----&gt; 4 model_tunning.fit(x_train_multilabel, y_train)\n\nValueError: Invalid parameter C for estimator OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n      intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n      penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n      verbose=0, warm_start=False),\n      n_jobs=1). Check the list of available parameters with `estimator.get_params().keys()\n</code></pre>\n <logistic-regression><p>When you use nested estimators with grid search you can scope the parameters with __ as a separator. In this case the LogisticRegression model is stored as an attribute named estimator inside the OneVsRestClassifier model:</p>\n\n<pre><code>from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsRestClassifier\n\ntuned_parameters = [{'estimator__C': [100, 10, 1, 0.1, 0.01, 0.001, 0.0001]}]\n\n# Find Optimal C by grid search \n\nlog_reg_clf = OneVsRestClassifier(LogisticRegression())\n\nlogistic_gs = GridSearchCV(log_reg_clf, tuned_parameters,scoring = 'f1_micro', cv=3)\n\nlogistic_gs.fit(x_train_bow, y_train)\nprint(logistic_gs.best_estimator_)\n</code></pre>\n<p>You can see I have set up a basic pipeline here using GridSearchCV, tf-idf, Logistic Regression and OneVsRestClassifier. In the param_grid, you can set <code>'clf__estimator__C'</code> instead of just <code>'C'</code></p>\n\n<pre><code>tfidf_vectorizer = TfidfVectorizer(smooth_idf=True)\nlog_reg_clf = OneVsRestClassifier(LogisticRegression(intercept_scaling=1, class_weight='balanced', random_state=0))\n\n# Create regularization hyperparameter space\nC = np.logspace(0, 4, 10)\n\nparam_grid = [{'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n           'vect__max_features': (None, 5000, 10000, 50000),\n           'vect__norm': ['l1','l2'],\n           'clf__estimator__C': C,\n           'clf__estimator__penalty': ['l1','l2']\n          }\n         ]\n\n\nlog_reg_clf_tfidf = Pipeline([('vect', tfidf_vectorizer), ('clf', log_reg_clf)])\n\nprint(log_reg_clf_tfidf.get_params().keys())\n\ngs_logReg_tfidf = GridSearchCV(log_reg_clf_tfidf, param_grid, scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\ngs_logReg_tfidf.fit(X_train, y_train)\nprint(\"The best parameters: \\n\", gs_logReg_tfidf.best_params_)\nprint(\"The best score: \\n\", gs_logReg_tfidf.best_score_)\n\ndf_test_predicted_idf = gs_logReg_tfidf.predict(X_test)\n</code></pre>\n",
                "codes": [
                    [
                        "from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsRestClassifier\n\ntuned_parameters = [{'estimator__C': [100, 10, 1, 0.1, 0.01, 0.001, 0.0001]}]\n\n# Find Optimal C by grid search \n\nlog_reg_clf = OneVsRestClassifier(LogisticRegression())\n\nlogistic_gs = GridSearchCV(log_reg_clf, tuned_parameters,scoring = 'f1_micro', cv=3)\n\nlogistic_gs.fit(x_train_bow, y_train)\nprint(logistic_gs.best_estimator_)\n"
                    ],
                    [
                        "tfidf_vectorizer = TfidfVectorizer(smooth_idf=True)\nlog_reg_clf = OneVsRestClassifier(LogisticRegression(intercept_scaling=1, class_weight='balanced', random_state=0))\n\n# Create regularization hyperparameter space\nC = np.logspace(0, 4, 10)\n\nparam_grid = [{'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n           'vect__max_features': (None, 5000, 10000, 50000),\n           'vect__norm': ['l1','l2'],\n           'clf__estimator__C': C,\n           'clf__estimator__penalty': ['l1','l2']\n          }\n         ]\n\n\nlog_reg_clf_tfidf = Pipeline([('vect', tfidf_vectorizer), ('clf', log_reg_clf)])\n\nprint(log_reg_clf_tfidf.get_params().keys())\n\ngs_logReg_tfidf = GridSearchCV(log_reg_clf_tfidf, param_grid, scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\ngs_logReg_tfidf.fit(X_train, y_train)\nprint(\"The best parameters: \\n\", gs_logReg_tfidf.best_params_)\nprint(\"The best score: \\n\", gs_logReg_tfidf.best_score_)\n\ndf_test_predicted_idf = gs_logReg_tfidf.predict(X_test)\n"
                    ]
                ],
                "question_id:": "41680",
                "question_votes:": "1",
                "question_text:": "<pre><code>parameters = [{'C': [10**-2, 10**-1, 10**0,10**1, 10**2, 10**3]}]\n\nmodel_tunning = GridSearchCV(OneVsRestClassifier(LogisticRegression(penalty='l1')), param_grid=parameters,scoring=\"f1\")\nmodel_tunning.fit(x_train_multilabel, y_train)\n\n\n\n\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-38-5d5850fe8978&gt; in &lt;module&gt;()\n  2 \n  3 model_tunning = GridSearchCV(OneVsRestClassifier(LogisticRegression(penalty='l1')), param_grid=parameters,scoring=\"f1\")\n----&gt; 4 model_tunning.fit(x_train_multilabel, y_train)\n\nValueError: Invalid parameter C for estimator OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n      intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n      penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n      verbose=0, warm_start=False),\n      n_jobs=1). Check the list of available parameters with `estimator.get_params().keys()\n</code></pre>\n",
                "tags": "<logistic-regression>",
                "answers": [
                    [
                        "43653",
                        "2",
                        "41680",
                        "",
                        "",
                        "<p>When you use nested estimators with grid search you can scope the parameters with __ as a separator. In this case the LogisticRegression model is stored as an attribute named estimator inside the OneVsRestClassifier model:</p>\n\n<pre><code>from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsRestClassifier\n\ntuned_parameters = [{'estimator__C': [100, 10, 1, 0.1, 0.01, 0.001, 0.0001]}]\n\n# Find Optimal C by grid search \n\nlog_reg_clf = OneVsRestClassifier(LogisticRegression())\n\nlogistic_gs = GridSearchCV(log_reg_clf, tuned_parameters,scoring = 'f1_micro', cv=3)\n\nlogistic_gs.fit(x_train_bow, y_train)\nprint(logistic_gs.best_estimator_)\n</code></pre>\n",
                        "",
                        "1"
                    ],
                    [
                        "55510",
                        "2",
                        "41680",
                        "",
                        "",
                        "<p>You can see I have set up a basic pipeline here using GridSearchCV, tf-idf, Logistic Regression and OneVsRestClassifier. In the param_grid, you can set <code>'clf__estimator__C'</code> instead of just <code>'C'</code></p>\n\n<pre><code>tfidf_vectorizer = TfidfVectorizer(smooth_idf=True)\nlog_reg_clf = OneVsRestClassifier(LogisticRegression(intercept_scaling=1, class_weight='balanced', random_state=0))\n\n# Create regularization hyperparameter space\nC = np.logspace(0, 4, 10)\n\nparam_grid = [{'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n           'vect__max_features': (None, 5000, 10000, 50000),\n           'vect__norm': ['l1','l2'],\n           'clf__estimator__C': C,\n           'clf__estimator__penalty': ['l1','l2']\n          }\n         ]\n\n\nlog_reg_clf_tfidf = Pipeline([('vect', tfidf_vectorizer), ('clf', log_reg_clf)])\n\nprint(log_reg_clf_tfidf.get_params().keys())\n\ngs_logReg_tfidf = GridSearchCV(log_reg_clf_tfidf, param_grid, scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\ngs_logReg_tfidf.fit(X_train, y_train)\nprint(\"The best parameters: \\n\", gs_logReg_tfidf.best_params_)\nprint(\"The best score: \\n\", gs_logReg_tfidf.best_score_)\n\ndf_test_predicted_idf = gs_logReg_tfidf.predict(X_test)\n</code></pre>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9312",
            "_score": 12.2358465,
            "_source": {
                "title": "How to apply machine learning model to new dataset",
                "content": "How to apply machine learning model to new dataset <p>I'm very new to machine learning &amp; python in general and I'm trying to apply a Decision Tree Classifier to my dataset that I'm working on.</p>\n\n<p>I would like to use this model to predict the outcome after training it with certain cellular features. The training data consists of a results column, describing either a living/dead cell as 1 and 0 respectively. The additional columns are the cellular features I'm used for training.</p>\n\n<p>However, I am unsure about how to apply my finalized model and introduce it to new data. What I would like to do is have it predict the \"Result\" tab (the 0 and 1 values) by giving it the values for 'ASA', 'ASC', 'ASMR', 'IMIH', 'IMIA', 'TCH' in the new dataset.</p>\n\n<p>I would also like it to convert these predictions and possibly have it add these to a .csv file for later use, but I'm not sure how to do that.</p>\n\n<p>This is the code I've been using, I'm having trouble with the segment (\"Load test dataset\") near the end and I think I'm doing that bit wrong, but I added the full code just as clarification.</p>\n\n<pre><code>import pandas\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nimport numpy\n\nfile = '/Users/Aida/Desktop/AlivevsDeadTest_Improved.csv'\nnames = ['Result', 'ASA', 'ASC', 'ASMR', 'IMIH', 'IMIA', 'TCH']\ndataset = pandas.read_csv(file, names=names)\n\n# Peek at the data\nprint(dataset.head(21))\n\n# Statistical summary\nprint(dataset.describe())\n\n# Split-out validation dataset\narray = dataset.values\nX = array[1:,1:10]\nY = array[1:,0]\nvalidation_size = 0.20\nseed = 7\nX_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n\n# Test options and evaluation metric\nseed = 7\nscoring = 'accuracy'\n\n# Spot Check Algorithms\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC()))\n\n# Evaluate each model in turn\nresults = []\nnames = []\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n\n# Compare Algorithms\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()\n\n# Make predictions on validation dataset\ncart = DecisionTreeClassifier()\ncart.fit(X_train, Y_train)\npredictions = cart.predict(X_validation)\nprint(accuracy_score(Y_validation, predictions))\nprint(confusion_matrix(Y_validation, predictions))\nprint(classification_report(Y_validation, predictions))\n\n# Finalize model\nimport pickle\ncart_model = DecisionTreeClassifier()\ncart_model.fit(X_train, Y_train)\n\n# Save model to disk\nfilename = 'Final_Model.sav'\npickle.dump(cart_model, open(filename, 'wb'))\n\n# Load model from disk and use it to make new predictions\nloaded_model = pickle.load(open(filename, 'rb'))\nresult = loaded_model.score(X_validation, Y_validation)\nprint(result)\n\n# Load test dataset\nfinal_predict = numpy.loadtxt(\"AlivevsDead_Final.csv\", delimiter=\";\")\nX_train = final_predict\npred = cart_model.predict(X_train)\nprint(pred)\n</code></pre>\n\n<p>When I run this script it gives me an error, here's kind of what it looks like: </p>\n\n<pre><code>Traceback (most recent call last):\n  File \"C:/Users/Aida/Desktop/tennistesting.py\", line 89, in &lt;module&gt;\n    final_predict = numpy.loadtxt(\"AlivevsDead_Final.csv\", delimiter=\";\")\nValueError: could not convert string to float: 'Result,ASA,ASC,ASMR,IMIH,IMIA,TCH'\n</code></pre>\n\n<p>From what I understand, machine learning consists of 3 steps, which include training, validation and finally applying it to a new dataset to perform predictions. I just don't know how to introduce this new dataset and have the model perform predictions on it.</p>\n\n<p>When I run the model, I asked it to display a small segment of the dataset as clarification, this can be found below. </p>\n\n<pre><code> Result  ASA          ASC     ...              IMIH         IMIA          TCH\n0  Result  ASA          ASC     ...              IMIH         IMIA          TCH\n1       1   84  1.275275533     ...       0.650034902  0.000235479  4.126984127\n2       1  218  1.020682416     ...       0.339955874  0.000535448  8.125748503\n3       1  207  1.453129647     ...       0.575357024   0.00061345  5.629370629\n4       1  106  1.088015726     ...       0.729552852  0.000135923  7.162162162\n</code></pre>\n\n<p>I'm sorry if this was a silly question! I'm just very new to all of this and was hoping if anyone could possibly help me out with understanding how it's done properly.</p>\n\n<p>Thanks in advance!</p>\n <machine-learning><python><machine-learning-model><p>It seems like the headings of your DataFrame, </p>\n\n<pre><code>Result,ASA,ASC,ASMR,IMIH,IMIA,TCH\n</code></pre>\n\n<p>is also the first line of your DataFrame, see where the 0th index is when you display the small segment of the dataset as clarification. </p>\n\n<p>So the model thinks you first set of data is: </p>\n\n<pre><code>Result,ASA,ASC,ASMR,IMIH,IMIA,TCH\n</code></pre>\n\n<p>instead of: </p>\n\n<pre><code>1   84  1.275275533     ...       0.650034902  0.000235479  4.126984127\n</code></pre>\n\n<p>To stop this, remove the <code>names=names</code> from</p>\n\n<pre><code>dataset = pandas.read_csv(file, names=names)\n</code></pre>\n\n<p>because it looks like they are already the headings of the data in the csv file and pandas.read_csv will pick them up automatically. </p>\n<p>You are loading it incorrectly as it's a CSV file (delimiter is $,$ not $;$ by default) is what I can conclude..(may be wrong) </p>\n\n<p>Try Using pandas Library..</p>\n\n<p>Or exactly,</p>\n\n<pre><code>import pandas as pd\ndf_test = pd.read_csv(path to file)\n</code></pre>\n\n<p>Also you should use <code>to_feather</code> from pandas itself to save the files..</p>\n\n<p>It's a bit faster that way...</p>\n",
                "codes": [
                    [
                        "Result,ASA,ASC,ASMR,IMIH,IMIA,TCH\n",
                        "Result,ASA,ASC,ASMR,IMIH,IMIA,TCH\n",
                        "1   84  1.275275533     ...       0.650034902  0.000235479  4.126984127\n",
                        "dataset = pandas.read_csv(file, names=names)\n"
                    ],
                    [
                        "import pandas as pd\ndf_test = pd.read_csv(path to file)\n"
                    ]
                ],
                "question_id:": "33256",
                "question_votes:": "",
                "question_text:": "<p>I'm very new to machine learning &amp; python in general and I'm trying to apply a Decision Tree Classifier to my dataset that I'm working on.</p>\n\n<p>I would like to use this model to predict the outcome after training it with certain cellular features. The training data consists of a results column, describing either a living/dead cell as 1 and 0 respectively. The additional columns are the cellular features I'm used for training.</p>\n\n<p>However, I am unsure about how to apply my finalized model and introduce it to new data. What I would like to do is have it predict the \"Result\" tab (the 0 and 1 values) by giving it the values for 'ASA', 'ASC', 'ASMR', 'IMIH', 'IMIA', 'TCH' in the new dataset.</p>\n\n<p>I would also like it to convert these predictions and possibly have it add these to a .csv file for later use, but I'm not sure how to do that.</p>\n\n<p>This is the code I've been using, I'm having trouble with the segment (\"Load test dataset\") near the end and I think I'm doing that bit wrong, but I added the full code just as clarification.</p>\n\n<pre><code>import pandas\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nimport numpy\n\nfile = '/Users/Aida/Desktop/AlivevsDeadTest_Improved.csv'\nnames = ['Result', 'ASA', 'ASC', 'ASMR', 'IMIH', 'IMIA', 'TCH']\ndataset = pandas.read_csv(file, names=names)\n\n# Peek at the data\nprint(dataset.head(21))\n\n# Statistical summary\nprint(dataset.describe())\n\n# Split-out validation dataset\narray = dataset.values\nX = array[1:,1:10]\nY = array[1:,0]\nvalidation_size = 0.20\nseed = 7\nX_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n\n# Test options and evaluation metric\nseed = 7\nscoring = 'accuracy'\n\n# Spot Check Algorithms\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC()))\n\n# Evaluate each model in turn\nresults = []\nnames = []\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n\n# Compare Algorithms\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()\n\n# Make predictions on validation dataset\ncart = DecisionTreeClassifier()\ncart.fit(X_train, Y_train)\npredictions = cart.predict(X_validation)\nprint(accuracy_score(Y_validation, predictions))\nprint(confusion_matrix(Y_validation, predictions))\nprint(classification_report(Y_validation, predictions))\n\n# Finalize model\nimport pickle\ncart_model = DecisionTreeClassifier()\ncart_model.fit(X_train, Y_train)\n\n# Save model to disk\nfilename = 'Final_Model.sav'\npickle.dump(cart_model, open(filename, 'wb'))\n\n# Load model from disk and use it to make new predictions\nloaded_model = pickle.load(open(filename, 'rb'))\nresult = loaded_model.score(X_validation, Y_validation)\nprint(result)\n\n# Load test dataset\nfinal_predict = numpy.loadtxt(\"AlivevsDead_Final.csv\", delimiter=\";\")\nX_train = final_predict\npred = cart_model.predict(X_train)\nprint(pred)\n</code></pre>\n\n<p>When I run this script it gives me an error, here's kind of what it looks like: </p>\n\n<pre><code>Traceback (most recent call last):\n  File \"C:/Users/Aida/Desktop/tennistesting.py\", line 89, in &lt;module&gt;\n    final_predict = numpy.loadtxt(\"AlivevsDead_Final.csv\", delimiter=\";\")\nValueError: could not convert string to float: 'Result,ASA,ASC,ASMR,IMIH,IMIA,TCH'\n</code></pre>\n\n<p>From what I understand, machine learning consists of 3 steps, which include training, validation and finally applying it to a new dataset to perform predictions. I just don't know how to introduce this new dataset and have the model perform predictions on it.</p>\n\n<p>When I run the model, I asked it to display a small segment of the dataset as clarification, this can be found below. </p>\n\n<pre><code> Result  ASA          ASC     ...              IMIH         IMIA          TCH\n0  Result  ASA          ASC     ...              IMIH         IMIA          TCH\n1       1   84  1.275275533     ...       0.650034902  0.000235479  4.126984127\n2       1  218  1.020682416     ...       0.339955874  0.000535448  8.125748503\n3       1  207  1.453129647     ...       0.575357024   0.00061345  5.629370629\n4       1  106  1.088015726     ...       0.729552852  0.000135923  7.162162162\n</code></pre>\n\n<p>I'm sorry if this was a silly question! I'm just very new to all of this and was hoping if anyone could possibly help me out with understanding how it's done properly.</p>\n\n<p>Thanks in advance!</p>\n",
                "tags": "<machine-learning><python><machine-learning-model>",
                "answers": [
                    [
                        "39433",
                        "2",
                        "33256",
                        "",
                        "",
                        "<p>It seems like the headings of your DataFrame, </p>\n\n<pre><code>Result,ASA,ASC,ASMR,IMIH,IMIA,TCH\n</code></pre>\n\n<p>is also the first line of your DataFrame, see where the 0th index is when you display the small segment of the dataset as clarification. </p>\n\n<p>So the model thinks you first set of data is: </p>\n\n<pre><code>Result,ASA,ASC,ASMR,IMIH,IMIA,TCH\n</code></pre>\n\n<p>instead of: </p>\n\n<pre><code>1   84  1.275275533     ...       0.650034902  0.000235479  4.126984127\n</code></pre>\n\n<p>To stop this, remove the <code>names=names</code> from</p>\n\n<pre><code>dataset = pandas.read_csv(file, names=names)\n</code></pre>\n\n<p>because it looks like they are already the headings of the data in the csv file and pandas.read_csv will pick them up automatically. </p>\n",
                        "",
                        ""
                    ],
                    [
                        "33258",
                        "2",
                        "33256",
                        "",
                        "",
                        "<p>You are loading it incorrectly as it's a CSV file (delimiter is $,$ not $;$ by default) is what I can conclude..(may be wrong) </p>\n\n<p>Try Using pandas Library..</p>\n\n<p>Or exactly,</p>\n\n<pre><code>import pandas as pd\ndf_test = pd.read_csv(path to file)\n</code></pre>\n\n<p>Also you should use <code>to_feather</code> from pandas itself to save the files..</p>\n\n<p>It's a bit faster that way...</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "1824",
            "_score": 12.181227,
            "_source": {
                "title": "What regressors are recommended with text modeling?",
                "content": "What regressors are recommended with text modeling? <p>For the sake of my own exploration, I am working on a sales prediction project. I am using text extracted from a set of books to build a predictive model.  </p>\n\n<p>With scikit learn, I have created a Tfidf, and together with the numeric sales numbers, I created a SGDRegressor. But I'd like to practice with other models.  </p>\n\n<p>I am looking over the options available to me, and I'm wondering, what other algorithms might be useful in this kind of regression scenario? And/or, what other algorithms in scikit learn will take a tfidf as the dataset?   </p>\n <nlp><text-mining><regression><scikit-learn><p>In sklearn Anything that will take sparse data can take output from TFIDF.</p>\n\n<p>In sklearn basically all data any model can take is either dense (normal array) or sparse (that only stores the location of values != 0). You can convert from sparse to dense, but chances are you'll run out of memory if you try.</p>\n\n<p>I'm quite a big fan of using linear algorithms on text data (sgdregressor for example have a ton of different options you can play with). But other algorithms like randomforest that Sergey mentioned, and naive bayes models can also work with that kind of data. Basically what you are looking for is anything that can take sparse input data.</p>\n\n<p>(One thing I've done in the past when working with text+other data is taking output from an sgd's analysis of the data and feeding that + the other data to another algorithm like randomforest. It's a simple and quite powerful method)</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "9846",
                "question_votes:": "3",
                "question_text:": "<p>For the sake of my own exploration, I am working on a sales prediction project. I am using text extracted from a set of books to build a predictive model.  </p>\n\n<p>With scikit learn, I have created a Tfidf, and together with the numeric sales numbers, I created a SGDRegressor. But I'd like to practice with other models.  </p>\n\n<p>I am looking over the options available to me, and I'm wondering, what other algorithms might be useful in this kind of regression scenario? And/or, what other algorithms in scikit learn will take a tfidf as the dataset?   </p>\n",
                "tags": "<nlp><text-mining><regression><scikit-learn>",
                "answers": [
                    [
                        "9884",
                        "2",
                        "9846",
                        "",
                        "",
                        "<p>In sklearn Anything that will take sparse data can take output from TFIDF.</p>\n\n<p>In sklearn basically all data any model can take is either dense (normal array) or sparse (that only stores the location of values != 0). You can convert from sparse to dense, but chances are you'll run out of memory if you try.</p>\n\n<p>I'm quite a big fan of using linear algorithms on text data (sgdregressor for example have a ton of different options you can play with). But other algorithms like randomforest that Sergey mentioned, and naive bayes models can also work with that kind of data. Basically what you are looking for is anything that can take sparse input data.</p>\n\n<p>(One thing I've done in the past when working with text+other data is taking output from an sgd's analysis of the data and feeding that + the other data to another algorithm like randomforest. It's a simple and quite powerful method)</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "251",
            "_score": 12.176481,
            "_source": {
                "title": "Does scikit-learn have forward selection/stepwise regression algorithm?",
                "content": "Does scikit-learn have forward selection/stepwise regression algorithm? <p>I'm working on the problem with too many features and training my models takes way too long. I implemented forward selection algorithm to choose features.</p>\n\n<p>However, I was wondering does scikit-learn have forward selection/stepwise regression algorithm?</p>\n <feature-selection><scikit-learn><p>Sklearn DOES have a forward selection algorithm, although it isn't called that in scikit-learn.  The feature selection method called <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html\" rel=\"noreferrer\">F_regression</a> in scikit-learn will sequentially include features that improve the model the most, until there are <code>K</code> features in the model (K is an input).  </p>\n\n<p>It starts by regression the labels on each feature individually, and then observing which feature improved the model the most using the F-statistic.  Then it incorporates the winning feature into the model.  Then it iterates through the remaining features to find the next feature which improves the model the most, again using the F-statistic or F test.  It does this until there are K features in the model.</p>\n\n<p>Notice that the remaining features that are correlated to features incorporated into the model will probably not be selected, since they do not correlate with the residuals (although they might correlate well with the labels).  This helps guard against multi-collinearity.</p>\n<p>Scikit-learn indeed does not support stepwise regression. That's because what is commonly known as 'stepwise regression' is an algorithm based on p-values of coefficients of linear regression, and scikit-learn deliberately avoids inferential approach to model learning (significance testing etc). Moreover, pure OLS is only one of numerous regression algorithms, and from the scikit-learn point of view it is neither very important, nor one of the best. </p>\n\n<p>There are, however, some pieces of advice for those who still need a good way for feature selection with linear models:</p>\n\n<ol>\n<li>Use inherently sparse models like <code>ElasticNet</code> or <code>Lasso</code>.</li>\n<li>Normalize your features with <code>StandardScaler</code>, and then order your features just by <code>model.coef_</code>. For perfectly independent covariates it is equivalent to sorting by p-values. The class <code>sklearn.feature_selection.RFE</code> will do it for you, and <code>RFECV</code> will even evaluate the optimal number of features.</li>\n<li>Use <a href=\"http://planspace.org/20150423-forward_selection_with_statsmodels/\" rel=\"noreferrer\">an implementation</a> of forward selection by adjusted $R^2$ that works with <code>statsmodels</code>.</li>\n<li>Do brute-force forward or backward selection to maximize your favorite metric on cross-validation (it could take approximately quadratic time in number of covariates). A scikit-learn compatible <code>mlxtend</code> package <a href=\"http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/\" rel=\"noreferrer\">supports</a> this approach for any estimator and any metric.</li>\n<li>If you still want vanilla stepwise regression, it is easier to base it on <code>statsmodels</code>, since this package calculates p-values for you. A basic forward-backward selection could look like this:</li>\n</ol>\n\n<p>```</p>\n\n<pre><code>from sklearn.datasets import load_boston\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\n\ndata = load_boston()\nX = pd.DataFrame(data.data, columns=data.feature_names)\ny = data.target\n\n\ndef stepwise_selection(X, y, \n                       initial_list=[], \n                       threshold_in=0.01, \n                       threshold_out = 0.05, \n                       verbose=True):\n    \"\"\" Perform a forward-backward feature selection \n    based on p-value from statsmodels.api.OLS\n    Arguments:\n        X - pandas.DataFrame with candidate features\n        y - list-like with the target\n        initial_list - list of features to start with (column names of X)\n        threshold_in - include a feature if its p-value &lt; threshold_in\n        threshold_out - exclude a feature if its p-value &gt; threshold_out\n        verbose - whether to print the sequence of inclusions and exclusions\n    Returns: list of selected features \n    Always set threshold_in &lt; threshold_out to avoid infinite looping.\n    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n    \"\"\"\n    included = list(initial_list)\n    while True:\n        changed=False\n        # forward step\n        excluded = list(set(X.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval &lt; threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n\n        # backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n        # use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() # null if pvalues is empty\n        if worst_pval &gt; threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n\nresult = stepwise_selection(X, y)\n\nprint('resulting features:')\nprint(result)\n</code></pre>\n\n<p>This example would print the following output:</p>\n\n<pre><code>Add  LSTAT                          with p-value 5.0811e-88\nAdd  RM                             with p-value 3.47226e-27\nAdd  PTRATIO                        with p-value 1.64466e-14\nAdd  DIS                            with p-value 1.66847e-05\nAdd  NOX                            with p-value 5.48815e-08\nAdd  CHAS                           with p-value 0.000265473\nAdd  B                              with p-value 0.000771946\nAdd  ZN                             with p-value 0.00465162\nresulting features:\n['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX', 'CHAS', 'B', 'ZN']\n</code></pre>\n<p>Actually sklearn doesn't have a forward selection algorithm, thought a <a href=\"https://github.com/scikit-learn/scikit-learn/pull/8684\" rel=\"nofollow noreferrer\">pull request</a> with an implementation of forward feature selection waits in the Scikit-Learn repository since April 2017.</p>\n\n<p>As an alternative, there is forward and one-step-ahead backward selection in <a href=\"https://github.com/rasbt/mlxtend/\" rel=\"nofollow noreferrer\">mlxtend</a>. You can find it's document in <a href=\"http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/\" rel=\"nofollow noreferrer\">Sequential Feature Selector</a></p>\n<p>No, sklearn doesn't seem to have a forward selection algorithm. However, it does provide recursive feature elimination, which is a greedy feature elimination algorithm similar to sequential backward selection. See the documentation here:</p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\">http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html</a></p>\n<p>In fact there is a nice algorithm called \"Forward_Select\" that uses Statsmodels and allows you to set your own metric (AIC, BIC, Adjusted-R-Squared, or whatever you like) to progressively add a variable to the model. The algorithm can be found in the comments section of this page - scroll down and you'll see it near the bottom of the page.</p>\n\n<p><a href=\"https://planspace.org/20150423-forward_selection_with_statsmodels/\" rel=\"nofollow noreferrer\">https://planspace.org/20150423-forward_selection_with_statsmodels/</a></p>\n\n<p>I would add that the algorithm also has one nice feature: you can apply it to either classification or regression problems! You just have to tell it.</p>\n\n<p>Try it and see for yourself.</p>\n",
                "codes": [
                    [],
                    [
                        "from sklearn.datasets import load_boston\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\n\ndata = load_boston()\nX = pd.DataFrame(data.data, columns=data.feature_names)\ny = data.target\n\n\ndef stepwise_selection(X, y, \n                       initial_list=[], \n                       threshold_in=0.01, \n                       threshold_out = 0.05, \n                       verbose=True):\n    \"\"\" Perform a forward-backward feature selection \n    based on p-value from statsmodels.api.OLS\n    Arguments:\n        X - pandas.DataFrame with candidate features\n        y - list-like with the target\n        initial_list - list of features to start with (column names of X)\n        threshold_in - include a feature if its p-value < threshold_in\n        threshold_out - exclude a feature if its p-value > threshold_out\n        verbose - whether to print the sequence of inclusions and exclusions\n    Returns: list of selected features \n    Always set threshold_in < threshold_out to avoid infinite looping.\n    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n    \"\"\"\n    included = list(initial_list)\n    while True:\n        changed=False\n        # forward step\n        excluded = list(set(X.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n\n        # backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n        # use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() # null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n\nresult = stepwise_selection(X, y)\n\nprint('resulting features:')\nprint(result)\n",
                        "Add  LSTAT                          with p-value 5.0811e-88\nAdd  RM                             with p-value 3.47226e-27\nAdd  PTRATIO                        with p-value 1.64466e-14\nAdd  DIS                            with p-value 1.66847e-05\nAdd  NOX                            with p-value 5.48815e-08\nAdd  CHAS                           with p-value 0.000265473\nAdd  B                              with p-value 0.000771946\nAdd  ZN                             with p-value 0.00465162\nresulting features:\n['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX', 'CHAS', 'B', 'ZN']\n"
                    ],
                    [],
                    [],
                    []
                ],
                "question_id:": "937",
                "question_votes:": "35",
                "question_text:": "<p>I'm working on the problem with too many features and training my models takes way too long. I implemented forward selection algorithm to choose features.</p>\n\n<p>However, I was wondering does scikit-learn have forward selection/stepwise regression algorithm?</p>\n",
                "tags": "<feature-selection><scikit-learn>",
                "answers": [
                    [
                        "12000",
                        "2",
                        "937",
                        "",
                        "",
                        "<p>Sklearn DOES have a forward selection algorithm, although it isn't called that in scikit-learn.  The feature selection method called <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html\" rel=\"noreferrer\">F_regression</a> in scikit-learn will sequentially include features that improve the model the most, until there are <code>K</code> features in the model (K is an input).  </p>\n\n<p>It starts by regression the labels on each feature individually, and then observing which feature improved the model the most using the F-statistic.  Then it incorporates the winning feature into the model.  Then it iterates through the remaining features to find the next feature which improves the model the most, again using the F-statistic or F test.  It does this until there are K features in the model.</p>\n\n<p>Notice that the remaining features that are correlated to features incorporated into the model will probably not be selected, since they do not correlate with the residuals (although they might correlate well with the labels).  This helps guard against multi-collinearity.</p>\n",
                        "",
                        "11"
                    ],
                    [
                        "24823",
                        "2",
                        "937",
                        "",
                        "",
                        "<p>Scikit-learn indeed does not support stepwise regression. That's because what is commonly known as 'stepwise regression' is an algorithm based on p-values of coefficients of linear regression, and scikit-learn deliberately avoids inferential approach to model learning (significance testing etc). Moreover, pure OLS is only one of numerous regression algorithms, and from the scikit-learn point of view it is neither very important, nor one of the best. </p>\n\n<p>There are, however, some pieces of advice for those who still need a good way for feature selection with linear models:</p>\n\n<ol>\n<li>Use inherently sparse models like <code>ElasticNet</code> or <code>Lasso</code>.</li>\n<li>Normalize your features with <code>StandardScaler</code>, and then order your features just by <code>model.coef_</code>. For perfectly independent covariates it is equivalent to sorting by p-values. The class <code>sklearn.feature_selection.RFE</code> will do it for you, and <code>RFECV</code> will even evaluate the optimal number of features.</li>\n<li>Use <a href=\"http://planspace.org/20150423-forward_selection_with_statsmodels/\" rel=\"noreferrer\">an implementation</a> of forward selection by adjusted $R^2$ that works with <code>statsmodels</code>.</li>\n<li>Do brute-force forward or backward selection to maximize your favorite metric on cross-validation (it could take approximately quadratic time in number of covariates). A scikit-learn compatible <code>mlxtend</code> package <a href=\"http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/\" rel=\"noreferrer\">supports</a> this approach for any estimator and any metric.</li>\n<li>If you still want vanilla stepwise regression, it is easier to base it on <code>statsmodels</code>, since this package calculates p-values for you. A basic forward-backward selection could look like this:</li>\n</ol>\n\n<p>```</p>\n\n<pre><code>from sklearn.datasets import load_boston\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\n\ndata = load_boston()\nX = pd.DataFrame(data.data, columns=data.feature_names)\ny = data.target\n\n\ndef stepwise_selection(X, y, \n                       initial_list=[], \n                       threshold_in=0.01, \n                       threshold_out = 0.05, \n                       verbose=True):\n    \"\"\" Perform a forward-backward feature selection \n    based on p-value from statsmodels.api.OLS\n    Arguments:\n        X - pandas.DataFrame with candidate features\n        y - list-like with the target\n        initial_list - list of features to start with (column names of X)\n        threshold_in - include a feature if its p-value &lt; threshold_in\n        threshold_out - exclude a feature if its p-value &gt; threshold_out\n        verbose - whether to print the sequence of inclusions and exclusions\n    Returns: list of selected features \n    Always set threshold_in &lt; threshold_out to avoid infinite looping.\n    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n    \"\"\"\n    included = list(initial_list)\n    while True:\n        changed=False\n        # forward step\n        excluded = list(set(X.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval &lt; threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n\n        # backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n        # use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() # null if pvalues is empty\n        if worst_pval &gt; threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n\nresult = stepwise_selection(X, y)\n\nprint('resulting features:')\nprint(result)\n</code></pre>\n\n<p>This example would print the following output:</p>\n\n<pre><code>Add  LSTAT                          with p-value 5.0811e-88\nAdd  RM                             with p-value 3.47226e-27\nAdd  PTRATIO                        with p-value 1.64466e-14\nAdd  DIS                            with p-value 1.66847e-05\nAdd  NOX                            with p-value 5.48815e-08\nAdd  CHAS                           with p-value 0.000265473\nAdd  B                              with p-value 0.000771946\nAdd  ZN                             with p-value 0.00465162\nresulting features:\n['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX', 'CHAS', 'B', 'ZN']\n</code></pre>\n",
                        "",
                        "8"
                    ],
                    [
                        "48291",
                        "2",
                        "937",
                        "",
                        "",
                        "<p>Actually sklearn doesn't have a forward selection algorithm, thought a <a href=\"https://github.com/scikit-learn/scikit-learn/pull/8684\" rel=\"nofollow noreferrer\">pull request</a> with an implementation of forward feature selection waits in the Scikit-Learn repository since April 2017.</p>\n\n<p>As an alternative, there is forward and one-step-ahead backward selection in <a href=\"https://github.com/rasbt/mlxtend/\" rel=\"nofollow noreferrer\">mlxtend</a>. You can find it's document in <a href=\"http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/\" rel=\"nofollow noreferrer\">Sequential Feature Selector</a></p>\n",
                        "",
                        ""
                    ],
                    [
                        "998",
                        "2",
                        "937",
                        "",
                        "",
                        "<p>No, sklearn doesn't seem to have a forward selection algorithm. However, it does provide recursive feature elimination, which is a greedy feature elimination algorithm similar to sequential backward selection. See the documentation here:</p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\">http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html</a></p>\n",
                        "",
                        "22"
                    ],
                    [
                        "30910",
                        "2",
                        "937",
                        "",
                        "",
                        "<p>In fact there is a nice algorithm called \"Forward_Select\" that uses Statsmodels and allows you to set your own metric (AIC, BIC, Adjusted-R-Squared, or whatever you like) to progressively add a variable to the model. The algorithm can be found in the comments section of this page - scroll down and you'll see it near the bottom of the page.</p>\n\n<p><a href=\"https://planspace.org/20150423-forward_selection_with_statsmodels/\" rel=\"nofollow noreferrer\">https://planspace.org/20150423-forward_selection_with_statsmodels/</a></p>\n\n<p>I would add that the algorithm also has one nice feature: you can apply it to either classification or regression problems! You just have to tell it.</p>\n\n<p>Try it and see for yourself.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3230",
            "_score": 12.120484,
            "_source": {
                "title": "Technology stack for linear regression on (not so) large dataset",
                "content": "Technology stack for linear regression on (not so) large dataset <p>While attending to the Coursera's Machine Learning Course, I figured out that I could use a database from the company I work for (~50MM records) to do some linear regression experiments.</p>\n\n<p>But one of the steps involved on proposing this experiment, is to define the technology stack required for this task.</p>\n\n<p>From my understanding the following tasks should be covered:</p>\n\n<ol>\n<li>Read raw data and store it on an non-production database</li>\n<li>Transform data to a \"regression friendly\" format</li>\n<li>Store the transformed data on an intermediate database</li>\n<li>Compute the actual regression</li>\n</ol>\n\n<p>For #1 I can take some paths, like doing a custom .NET or Java program, or even use an ETL process (this is more to copy data to somewhere else and don't mess with production database).</p>\n\n<p>On #2 the funny part begins: should I consider a specialized tool for a &lt;100MM records database? If so, what would you suggest for transforming this data into a matrix-like representation?</p>\n\n<p>I believe #3 is dependant on the #4: I see lots of samples (eg.: in R, or Matlab/Octave) based on text or csv files. Are these the standard formats for these computations? Or should I read from a database</p>\n\n<p>For #4, from what I could understanding using R is the way to go, right?</p>\n\n<p>Finally, should I consider a multi-gig multi-processors server, or considering it's an experiment in which spending some hours of computation is not a big issue, a 4GB machine will do the job?</p>\n\n<p>I am aware that this question may be considered too broad, but I really would like to hear from you about what should I consider for it, and even if I am missing something (or going to a totally wrong path).</p>\n\n<p>Regarding the data, you can consider it like the house pricing in Boston: it's a 30 features (columns) dataset, used to predict the value for one of these columns.</p>\n\n<p>(question originally posted on Stack Overflow)</p>\n <machine-learning><r><linear-regression><p>Since no one has mentioned RAM-efficient methods yet:</p>\n\n<p>Instead of loading everything into RAM, you can use online/out-of-core learning.</p>\n\n<p>Python's <a href=\"http://scikit-learn.org\" rel=\"nofollow\">Scikit-Learn</a> for example has the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\" rel=\"nofollow\">SGDClassifier</a> class. Set its loss function to \"log\" and you get logistic regression. Using the partial_fit function you can feed it small batches of data that you read straight from the database (or from some CSV file,...).</p>\n\n<p><a href=\"https://github.com/JohnLangford/vowpal_wabbit/wiki\" rel=\"nofollow\">Vowpal Wabbit</a> might also be worth a try. Its made for out-of-core learning - hardly uses any RAM and you won't find anything that's much faster.</p>\n\n<p>You could also use Python's <a href=\"http://keras.io/\" rel=\"nofollow\">Keras</a> library to build a neural network (or in the simplest case just logistic regression), which you can also feed with small batches of data instead of loading everything into RAM. Compared to the other two recommendations a neural network could also learn non-linear dependencies.</p>\n\n<p>Besides that, try to start with fewer samples - plot the learning curves with 10k, 100k, 1M samples and see if 100M samples are even necessary to get a good score.</p>\n<p>It's easier if your entire dataset fits into RAM. \nSo check how large it is in GB and get enough RAM. Multiprocessor probably won't help much. So try to get highest frequency proc with just a few cores. \nYou could extract your data into a csv and use R or Scikit-learn for modelling. </p>\n<p>You can use R or Python for 100 million records with the conventional regression libraries. You will require around 16GB of RAM according to my experience, may be more than that!! A quadcore processor will be fine while running algorithms and during pre-processing steps. It would be better to store the transformed data to an immediate database.  </p>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "13912",
                "question_votes:": "2",
                "question_text:": "<p>While attending to the Coursera's Machine Learning Course, I figured out that I could use a database from the company I work for (~50MM records) to do some linear regression experiments.</p>\n\n<p>But one of the steps involved on proposing this experiment, is to define the technology stack required for this task.</p>\n\n<p>From my understanding the following tasks should be covered:</p>\n\n<ol>\n<li>Read raw data and store it on an non-production database</li>\n<li>Transform data to a \"regression friendly\" format</li>\n<li>Store the transformed data on an intermediate database</li>\n<li>Compute the actual regression</li>\n</ol>\n\n<p>For #1 I can take some paths, like doing a custom .NET or Java program, or even use an ETL process (this is more to copy data to somewhere else and don't mess with production database).</p>\n\n<p>On #2 the funny part begins: should I consider a specialized tool for a &lt;100MM records database? If so, what would you suggest for transforming this data into a matrix-like representation?</p>\n\n<p>I believe #3 is dependant on the #4: I see lots of samples (eg.: in R, or Matlab/Octave) based on text or csv files. Are these the standard formats for these computations? Or should I read from a database</p>\n\n<p>For #4, from what I could understanding using R is the way to go, right?</p>\n\n<p>Finally, should I consider a multi-gig multi-processors server, or considering it's an experiment in which spending some hours of computation is not a big issue, a 4GB machine will do the job?</p>\n\n<p>I am aware that this question may be considered too broad, but I really would like to hear from you about what should I consider for it, and even if I am missing something (or going to a totally wrong path).</p>\n\n<p>Regarding the data, you can consider it like the house pricing in Boston: it's a 30 features (columns) dataset, used to predict the value for one of these columns.</p>\n\n<p>(question originally posted on Stack Overflow)</p>\n",
                "tags": "<machine-learning><r><linear-regression>",
                "answers": [
                    [
                        "14470",
                        "2",
                        "13912",
                        "",
                        "",
                        "<p>Since no one has mentioned RAM-efficient methods yet:</p>\n\n<p>Instead of loading everything into RAM, you can use online/out-of-core learning.</p>\n\n<p>Python's <a href=\"http://scikit-learn.org\" rel=\"nofollow\">Scikit-Learn</a> for example has the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\" rel=\"nofollow\">SGDClassifier</a> class. Set its loss function to \"log\" and you get logistic regression. Using the partial_fit function you can feed it small batches of data that you read straight from the database (or from some CSV file,...).</p>\n\n<p><a href=\"https://github.com/JohnLangford/vowpal_wabbit/wiki\" rel=\"nofollow\">Vowpal Wabbit</a> might also be worth a try. Its made for out-of-core learning - hardly uses any RAM and you won't find anything that's much faster.</p>\n\n<p>You could also use Python's <a href=\"http://keras.io/\" rel=\"nofollow\">Keras</a> library to build a neural network (or in the simplest case just logistic regression), which you can also feed with small batches of data instead of loading everything into RAM. Compared to the other two recommendations a neural network could also learn non-linear dependencies.</p>\n\n<p>Besides that, try to start with fewer samples - plot the learning curves with 10k, 100k, 1M samples and see if 100M samples are even necessary to get a good score.</p>\n",
                        "",
                        "4"
                    ],
                    [
                        "13930",
                        "2",
                        "13912",
                        "",
                        "",
                        "<p>It's easier if your entire dataset fits into RAM. \nSo check how large it is in GB and get enough RAM. Multiprocessor probably won't help much. So try to get highest frequency proc with just a few cores. \nYou could extract your data into a csv and use R or Scikit-learn for modelling. </p>\n",
                        "",
                        "1"
                    ],
                    [
                        "13945",
                        "2",
                        "13912",
                        "",
                        "",
                        "<p>You can use R or Python for 100 million records with the conventional regression libraries. You will require around 16GB of RAM according to my experience, may be more than that!! A quadcore processor will be fine while running algorithms and during pre-processing steps. It would be better to store the transformed data to an immediate database.  </p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16960",
            "_score": 12.114767,
            "_source": {
                "title": "Which classification model to use on large, high-dimensional dataset?",
                "content": "Which classification model to use on large, high-dimensional dataset? <p>I face a classification task: with several features a target features is to be predicted. I'm working with python.</p>\n\n<p>My dataset includes 60 features from which I picked 16 which I think could be relevant (many others are time stamps, for example). The problem is that most of these 16 features are categorical - encoding them with <code>get_dummies</code> generates 886 features.</p>\n\n<p>The data also includes about 17 million observations.</p>\n\n<p>I am now wondering about how to tackle this problem and what to research and try next. I summarized this in these two questions and I'd love to hear some opinions!</p>\n\n<p><strong>First</strong>. If possible, I'd like to reduce the number of features. I tried using <code>SelectFromModel</code> with a <code>RandomForestClassifier</code> which worked okay, I think, as features were reduced drastically without much loss of prediction power. However, as my categorial features are split into several new features, only parts of the original features are selected (it's not einther all or none of the features that originated from one). Is this a problem? If so, can this be avoided?</p>\n\n<p><strong>Second</strong>. As one model can be tuned a lot by playing with parameters or input representation, I would like to focus on a few promising models. For faster results, I used only 200,000 observations to train <code>KNeighborsClassifier</code>, <code>LogisticRegression</code>, <code>LinearSVC</code>, <code>DecisionTreeClassifier</code>, <code>RandomForestClassifier</code>, <code>GradientBoostingClassifier</code> and <code>MLPClassifier</code> (neural network); all from <code>sklearn</code>.</p>\n\n<p>I would not continue to pursue <code>KNeighborsClassifier</code> and <code>GradientBoostingClassifier</code> as they already took a lot of time to train for this small subset.\nAs <code>RandomForestClassifier</code> is supposed to perform nearly always better than <code>DecisionTreeClassifier</code>, I would drop the latter, too, but stick to <code>RandomForestClassifier</code>.\nThe two linear models <code>LogisticRegression</code> and <code>LinearSVC</code> worked well with <code>penalty = l1</code>, but very badly with <code>penalty = l2</code>, so that I would continue to pursue both with <code>penalty = l1</code> (altough I expect similar results).\nMy first neural network performed very badly, but I guess there a plety of things to try for improving; however, I expect a very long training time with the full dataset (as this small subset took quite a while already).\nI did not try a naive bayes classifier (as it is supposed to perform worse than linear models anyway) or a support vector machine (as they are supposed to perform badly with many observations).</p>\n\n<p>Summary: I would continue my work by looking at <code>RandomForestClassifier</code>, <code>LogisticRegression</code>/<code>LinearSVC</code> and (if you think this is a good idea) neural networks. Is this reasonable?</p>\n\n<p>Thanks a lot!</p>\n <python><classification><categorical-data><p>I don't really have experience with such a massive dataset, but my first thought would be to explore the instances in order to see if so many are needed. I would start with an ablation experiment, trying various sizes of training data with a simple method (random forest seems a good idea) in order to observe the evolution of the performance w.r.t size of the training data. It's likely that the performance reaches a plateau at some point, and it would be useful to know this point.</p>\n\n<p>It might also make sense to study if the data contains duplicates or near duplicates. You can't remove duplicates directly because the distribution matters, but it might be possible to replace them by assigning weights to instances. I'm not expert in this but there are methods for <a href=\"https://en.wikipedia.org/wiki/Instance_selection\" rel=\"nofollow noreferrer\">instance selection</a>.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "55191",
                "question_votes:": "1",
                "question_text:": "<p>I face a classification task: with several features a target features is to be predicted. I'm working with python.</p>\n\n<p>My dataset includes 60 features from which I picked 16 which I think could be relevant (many others are time stamps, for example). The problem is that most of these 16 features are categorical - encoding them with <code>get_dummies</code> generates 886 features.</p>\n\n<p>The data also includes about 17 million observations.</p>\n\n<p>I am now wondering about how to tackle this problem and what to research and try next. I summarized this in these two questions and I'd love to hear some opinions!</p>\n\n<p><strong>First</strong>. If possible, I'd like to reduce the number of features. I tried using <code>SelectFromModel</code> with a <code>RandomForestClassifier</code> which worked okay, I think, as features were reduced drastically without much loss of prediction power. However, as my categorial features are split into several new features, only parts of the original features are selected (it's not einther all or none of the features that originated from one). Is this a problem? If so, can this be avoided?</p>\n\n<p><strong>Second</strong>. As one model can be tuned a lot by playing with parameters or input representation, I would like to focus on a few promising models. For faster results, I used only 200,000 observations to train <code>KNeighborsClassifier</code>, <code>LogisticRegression</code>, <code>LinearSVC</code>, <code>DecisionTreeClassifier</code>, <code>RandomForestClassifier</code>, <code>GradientBoostingClassifier</code> and <code>MLPClassifier</code> (neural network); all from <code>sklearn</code>.</p>\n\n<p>I would not continue to pursue <code>KNeighborsClassifier</code> and <code>GradientBoostingClassifier</code> as they already took a lot of time to train for this small subset.\nAs <code>RandomForestClassifier</code> is supposed to perform nearly always better than <code>DecisionTreeClassifier</code>, I would drop the latter, too, but stick to <code>RandomForestClassifier</code>.\nThe two linear models <code>LogisticRegression</code> and <code>LinearSVC</code> worked well with <code>penalty = l1</code>, but very badly with <code>penalty = l2</code>, so that I would continue to pursue both with <code>penalty = l1</code> (altough I expect similar results).\nMy first neural network performed very badly, but I guess there a plety of things to try for improving; however, I expect a very long training time with the full dataset (as this small subset took quite a while already).\nI did not try a naive bayes classifier (as it is supposed to perform worse than linear models anyway) or a support vector machine (as they are supposed to perform badly with many observations).</p>\n\n<p>Summary: I would continue my work by looking at <code>RandomForestClassifier</code>, <code>LogisticRegression</code>/<code>LinearSVC</code> and (if you think this is a good idea) neural networks. Is this reasonable?</p>\n\n<p>Thanks a lot!</p>\n",
                "tags": "<python><classification><categorical-data>",
                "answers": [
                    [
                        "55196",
                        "2",
                        "55191",
                        "",
                        "",
                        "<p>I don't really have experience with such a massive dataset, but my first thought would be to explore the instances in order to see if so many are needed. I would start with an ablation experiment, trying various sizes of training data with a simple method (random forest seems a good idea) in order to observe the evolution of the performance w.r.t size of the training data. It's likely that the performance reaches a plateau at some point, and it would be useful to know this point.</p>\n\n<p>It might also make sense to study if the data contains duplicates or near duplicates. You can't remove duplicates directly because the distribution matters, but it might be possible to replace them by assigning weights to instances. I'm not expert in this but there are methods for <a href=\"https://en.wikipedia.org/wiki/Instance_selection\" rel=\"nofollow noreferrer\">instance selection</a>.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14267",
            "_score": 12.091744,
            "_source": {
                "title": "Multilabel classifcation in sklearn with soft (fuzzy) labels",
                "content": "Multilabel classifcation in sklearn with soft (fuzzy) labels <p>I have a model which is trained in sklearn on a 5-way classification problem, which performs relatively well (there are kNN and SVM versions, and both reproduce a test set with high accuracy).</p>\n\n<p>When the model is applied in \"real life\", it is highly likely that many samples will contain linear combinations of multiple classes.  So a sample may be 70% class A and 30% class B. </p>\n\n<p>Much of what I have read about multilabel classification in sklearn relates to problems which don't fit this paradigm well, most of them are \"tagging\" type problems such as movie genre classification.  Is there a way to apply my SVM/kNN models to this type of problem?  I would prefer to only train on single-class examples but can modify the training set to create some multi-class samples too.</p>\n\n<p>It seems I could work this by simply doing an indivdiual binary classifier for each class.  However, this wouldn't give me the relative strength of each label, i.e. the linear coefficient.  Is that possible?</p>\n <classification><scikit-learn><multilabel-classification><p>For example, for a 3-class classification, we want to train with a label like <span class=\"math-container\">$A$</span>, which is one-hot encoded as <span class=\"math-container\">$(1, 0, 0)$</span>, and also with a fuzzy label like <span class=\"math-container\">$(0.8, 0.2, 0)$</span>. In that case, kNN and SVM of sklearn does not support fuzzy labels. </p>\n\n<p>However, we can use sklearn's <code>MultiOutputRegressor</code> that extends a one-output Regressor such as Support Vector Regression (SVR) to multiple outputs. It is worth noting that neural networks are a natural fit for this type of label since they readily work with numerical vectors as labels.</p>\n\n<p>Here is a code that goes through different types of labels for kNN, SVC (multi-class SVM), and MultiRegression SVR:</p>\n\n<pre><code>import sklearn\nimport pandas as pd\nfrom sklearn.svm import SVC, SVR\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.multioutput import MultiOutputRegressor\nimport numpy as np\n\nN = 1000\nsplit = int(0.8 * N)\nfolds = 5\nseed = 1234\n\n# Data\nnp.random.seed(seed)\nfeature_1 = np.random.normal(0, 2, N)\nfeature_2 = np.random.normal(5, 6, N)\nX = np.vstack([feature_1, feature_2]).T\n\nY_label = np.random.choice(['A', 'B', 'C'], N)\n\nY_one_hot = pd.get_dummies(Y_label).values\n\nsmooth_filter = np.array([0.01, 0.98, 0.01])\nY_fuzzy = np.apply_along_axis(\n    lambda m: np.convolve(m, smooth_filter, mode='same'), axis=1, arr=Y_one_hot\n)\n\n\nkfold = KFold(n_splits=folds, random_state=seed)\n\nkNN = KNeighborsClassifier(n_neighbors=3)\nsvc = SVC()\nsvr = SVR()\nmulti_svr = MultiOutputRegressor(estimator=SVR())\n\nknn_label = np.average(cross_val_score(kNN, X, Y_label, cv=kfold))\nknn_one_hot = np.average(cross_val_score(kNN, X, Y_one_hot, cv=kfold))\ntry:\n    knn_fuzzy = np.average(cross_val_score(kNN, X, Y_fuzzy, cv=kfold))\nexcept ValueError:\n    print('kNN: fuzzy classes are not supported')\nsvc_label = np.average(cross_val_score(svc, X, Y_label, cv=kfold))\ntry:\n    svc_one_hot = np.average(cross_val_score(svc, X, Y_one_hot, cv=kfold))\nexcept ValueError:\n    print('SVC: vector is not supported')\ntry:\n    svr_one_hot = np.average(cross_val_score(svr, X, Y_one_hot, cv=kfold))\nexcept ValueError:\n    print('SVR: vector is not supported')\nmulti_svr_one_hot = np.average(cross_val_score(multi_svr, X, Y_one_hot, cv=kfold, scoring='neg_mean_absolute_error'))\nmulti_svr_fuzzy = np.average(cross_val_score(multi_svr, X, Y_fuzzy, cv=kfold, scoring='neg_mean_absolute_error'))\n\nprint('sklearn version', sklearn.__version__)\nprint('Y example: ',\n      \"label: \", Y_label[0],\n      \", one hot: \", Y_one_hot[0, :],\n      \", fuzzy: \", Y_fuzzy[0, :])\nprint('kNN label: ', knn_label)\nprint('kNN one hot: ', knn_one_hot)\nprint('SVC label: ', svc_label)\nprint('MultiSVR one hot: ', multi_svr_one_hot)\nprint('MultiSVR fuzzy: ', multi_svr_fuzzy)\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>kNN: fuzzy classes are not supported\nSVC: vector is not supported\nSVR: vector is not supported\nsklearn version 0.19.1\nY example:  label:  B , one hot:  [0 1 0] , fuzzy:  [0.01 0.98 0.01]\nkNN label:  0.321\nkNN one hot:  0.254\nSVC label:  0.332\nMultiSVR one hot:  -0.4066160996805417\nMultiSVR fuzzy:  -0.3970780923514713\n</code></pre>\n\n<p>Although kNN does not throw an exception for one-hot encoded labels, accuracy <code>0.254</code> shows that it does not work correctly with the vector. </p>\n\n<p>Also, Negative Mean Absolute Error is reported for MultiSVR since the task is understood as regression. Score <code>accuracy</code> can only be used after changing the fuzzy labels and predictions back to a label.</p>\n",
                "codes": [
                    [
                        "import sklearn\nimport pandas as pd\nfrom sklearn.svm import SVC, SVR\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.multioutput import MultiOutputRegressor\nimport numpy as np\n\nN = 1000\nsplit = int(0.8 * N)\nfolds = 5\nseed = 1234\n\n# Data\nnp.random.seed(seed)\nfeature_1 = np.random.normal(0, 2, N)\nfeature_2 = np.random.normal(5, 6, N)\nX = np.vstack([feature_1, feature_2]).T\n\nY_label = np.random.choice(['A', 'B', 'C'], N)\n\nY_one_hot = pd.get_dummies(Y_label).values\n\nsmooth_filter = np.array([0.01, 0.98, 0.01])\nY_fuzzy = np.apply_along_axis(\n    lambda m: np.convolve(m, smooth_filter, mode='same'), axis=1, arr=Y_one_hot\n)\n\n\nkfold = KFold(n_splits=folds, random_state=seed)\n\nkNN = KNeighborsClassifier(n_neighbors=3)\nsvc = SVC()\nsvr = SVR()\nmulti_svr = MultiOutputRegressor(estimator=SVR())\n\nknn_label = np.average(cross_val_score(kNN, X, Y_label, cv=kfold))\nknn_one_hot = np.average(cross_val_score(kNN, X, Y_one_hot, cv=kfold))\ntry:\n    knn_fuzzy = np.average(cross_val_score(kNN, X, Y_fuzzy, cv=kfold))\nexcept ValueError:\n    print('kNN: fuzzy classes are not supported')\nsvc_label = np.average(cross_val_score(svc, X, Y_label, cv=kfold))\ntry:\n    svc_one_hot = np.average(cross_val_score(svc, X, Y_one_hot, cv=kfold))\nexcept ValueError:\n    print('SVC: vector is not supported')\ntry:\n    svr_one_hot = np.average(cross_val_score(svr, X, Y_one_hot, cv=kfold))\nexcept ValueError:\n    print('SVR: vector is not supported')\nmulti_svr_one_hot = np.average(cross_val_score(multi_svr, X, Y_one_hot, cv=kfold, scoring='neg_mean_absolute_error'))\nmulti_svr_fuzzy = np.average(cross_val_score(multi_svr, X, Y_fuzzy, cv=kfold, scoring='neg_mean_absolute_error'))\n\nprint('sklearn version', sklearn.__version__)\nprint('Y example: ',\n      \"label: \", Y_label[0],\n      \", one hot: \", Y_one_hot[0, :],\n      \", fuzzy: \", Y_fuzzy[0, :])\nprint('kNN label: ', knn_label)\nprint('kNN one hot: ', knn_one_hot)\nprint('SVC label: ', svc_label)\nprint('MultiSVR one hot: ', multi_svr_one_hot)\nprint('MultiSVR fuzzy: ', multi_svr_fuzzy)\n",
                        "kNN: fuzzy classes are not supported\nSVC: vector is not supported\nSVR: vector is not supported\nsklearn version 0.19.1\nY example:  label:  B , one hot:  [0 1 0] , fuzzy:  [0.01 0.98 0.01]\nkNN label:  0.321\nkNN one hot:  0.254\nSVC label:  0.332\nMultiSVR one hot:  -0.4066160996805417\nMultiSVR fuzzy:  -0.3970780923514713\n"
                    ]
                ],
                "question_id:": "48111",
                "question_votes:": "1",
                "question_text:": "<p>I have a model which is trained in sklearn on a 5-way classification problem, which performs relatively well (there are kNN and SVM versions, and both reproduce a test set with high accuracy).</p>\n\n<p>When the model is applied in \"real life\", it is highly likely that many samples will contain linear combinations of multiple classes.  So a sample may be 70% class A and 30% class B. </p>\n\n<p>Much of what I have read about multilabel classification in sklearn relates to problems which don't fit this paradigm well, most of them are \"tagging\" type problems such as movie genre classification.  Is there a way to apply my SVM/kNN models to this type of problem?  I would prefer to only train on single-class examples but can modify the training set to create some multi-class samples too.</p>\n\n<p>It seems I could work this by simply doing an indivdiual binary classifier for each class.  However, this wouldn't give me the relative strength of each label, i.e. the linear coefficient.  Is that possible?</p>\n",
                "tags": "<classification><scikit-learn><multilabel-classification>",
                "answers": [
                    [
                        "48117",
                        "2",
                        "48111",
                        "",
                        "",
                        "<p>For example, for a 3-class classification, we want to train with a label like <span class=\"math-container\">$A$</span>, which is one-hot encoded as <span class=\"math-container\">$(1, 0, 0)$</span>, and also with a fuzzy label like <span class=\"math-container\">$(0.8, 0.2, 0)$</span>. In that case, kNN and SVM of sklearn does not support fuzzy labels. </p>\n\n<p>However, we can use sklearn's <code>MultiOutputRegressor</code> that extends a one-output Regressor such as Support Vector Regression (SVR) to multiple outputs. It is worth noting that neural networks are a natural fit for this type of label since they readily work with numerical vectors as labels.</p>\n\n<p>Here is a code that goes through different types of labels for kNN, SVC (multi-class SVM), and MultiRegression SVR:</p>\n\n<pre><code>import sklearn\nimport pandas as pd\nfrom sklearn.svm import SVC, SVR\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.multioutput import MultiOutputRegressor\nimport numpy as np\n\nN = 1000\nsplit = int(0.8 * N)\nfolds = 5\nseed = 1234\n\n# Data\nnp.random.seed(seed)\nfeature_1 = np.random.normal(0, 2, N)\nfeature_2 = np.random.normal(5, 6, N)\nX = np.vstack([feature_1, feature_2]).T\n\nY_label = np.random.choice(['A', 'B', 'C'], N)\n\nY_one_hot = pd.get_dummies(Y_label).values\n\nsmooth_filter = np.array([0.01, 0.98, 0.01])\nY_fuzzy = np.apply_along_axis(\n    lambda m: np.convolve(m, smooth_filter, mode='same'), axis=1, arr=Y_one_hot\n)\n\n\nkfold = KFold(n_splits=folds, random_state=seed)\n\nkNN = KNeighborsClassifier(n_neighbors=3)\nsvc = SVC()\nsvr = SVR()\nmulti_svr = MultiOutputRegressor(estimator=SVR())\n\nknn_label = np.average(cross_val_score(kNN, X, Y_label, cv=kfold))\nknn_one_hot = np.average(cross_val_score(kNN, X, Y_one_hot, cv=kfold))\ntry:\n    knn_fuzzy = np.average(cross_val_score(kNN, X, Y_fuzzy, cv=kfold))\nexcept ValueError:\n    print('kNN: fuzzy classes are not supported')\nsvc_label = np.average(cross_val_score(svc, X, Y_label, cv=kfold))\ntry:\n    svc_one_hot = np.average(cross_val_score(svc, X, Y_one_hot, cv=kfold))\nexcept ValueError:\n    print('SVC: vector is not supported')\ntry:\n    svr_one_hot = np.average(cross_val_score(svr, X, Y_one_hot, cv=kfold))\nexcept ValueError:\n    print('SVR: vector is not supported')\nmulti_svr_one_hot = np.average(cross_val_score(multi_svr, X, Y_one_hot, cv=kfold, scoring='neg_mean_absolute_error'))\nmulti_svr_fuzzy = np.average(cross_val_score(multi_svr, X, Y_fuzzy, cv=kfold, scoring='neg_mean_absolute_error'))\n\nprint('sklearn version', sklearn.__version__)\nprint('Y example: ',\n      \"label: \", Y_label[0],\n      \", one hot: \", Y_one_hot[0, :],\n      \", fuzzy: \", Y_fuzzy[0, :])\nprint('kNN label: ', knn_label)\nprint('kNN one hot: ', knn_one_hot)\nprint('SVC label: ', svc_label)\nprint('MultiSVR one hot: ', multi_svr_one_hot)\nprint('MultiSVR fuzzy: ', multi_svr_fuzzy)\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>kNN: fuzzy classes are not supported\nSVC: vector is not supported\nSVR: vector is not supported\nsklearn version 0.19.1\nY example:  label:  B , one hot:  [0 1 0] , fuzzy:  [0.01 0.98 0.01]\nkNN label:  0.321\nkNN one hot:  0.254\nSVC label:  0.332\nMultiSVR one hot:  -0.4066160996805417\nMultiSVR fuzzy:  -0.3970780923514713\n</code></pre>\n\n<p>Although kNN does not throw an exception for one-hot encoded labels, accuracy <code>0.254</code> shows that it does not work correctly with the vector. </p>\n\n<p>Also, Negative Mean Absolute Error is reported for MultiSVR since the task is understood as regression. Score <code>accuracy</code> can only be used after changing the fuzzy labels and predictions back to a label.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12838",
            "_score": 12.079998,
            "_source": {
                "title": "What model is suitable for classification of a small data set?",
                "content": "What model is suitable for classification of a small data set? <p>I have a dataset that consists of 365 records, and I want to apply a classification model on it (binary classification).</p>\n\n<p>As an output, in addition to the classification labels, I want to retrieve the classification confidence for each instance.</p>\n\n<p>I don't know how to deal with such a case. Can I use, for example, linear classifiers (SVM, logistic regression) with this small dataset? Because, I want to retrieve the classification confidence as well.</p>\n\n<p>I read that decision trees can be a good classifier for small datasets, but how can I retrieve the classification confidence with it?</p>\n\n<p>The dataset consists of tweets, each classified as positive or negative (from a sentiment perspective), and my feature vector consists of 2400 features (combination between word2vec embeddings and other features).</p>\n\n<p>Also, do you recommend me to use word2vec embeddings with such a small dataset? I think the classifier can't learn something from them using small dataset.</p>\n <classification><multiclass-classification><p>The only way to know if a classifier is suitable for your data set is to try it and test it. All classifiers you've mentioned have a way to give confidences of their predictions. Logistic regression and decision trees will give you the probability that a sample is the positive class. SVM's will give you the distance to the decision hyperplane which can be used as a confidence measure; with some additional computations, you can also get a probability with SVM's, but I won't detail that here.</p>\n\n<p>One concern for such a small data set is overfitting when the number of features is much larger than the number of samples. You should address that by using some form of regularization.</p>\n<p>The question whether to use a linear classifier depends less on the number of samples you have in your dataset and more whether your dataset is linearly separable (by the way, SVMs can be non-linear with the kernel trick).</p>\n\n<p>Now with regards to confidence in the classification, In SVMs there is a method that calculates the probability that a given sample belongs to a particular class using <strong>Platt scaling</strong> (\"<a href=\"http://citeseer.ist.psu.edu/viewdoc/download;jsessionid=92D78A0432AC435DC3DADF0A86A70E1D?doi=10.1.1.41.1639&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow noreferrer\">Original Paper</a>\"). This is the approach that is used in sklearn's SVM confidence implementation. You can read more about it in the following link:</p>\n\n<p><a href=\"https://prateekvjoshi.com/2015/12/15/how-to-compute-confidence-measure-for-svm-classifiers/\" rel=\"nofollow noreferrer\">How To Compute Confidence Measure For SVM Classifiers</a></p>\n\n<p>In both SVMs and linear regression models you can calculate the distance of a sample from the border and treat it as a confidence measurement (but it is not exactly that).</p>\n\n<p>With decision trees I'm not an expert but a similar question was posted and answered in the following link:</p>\n\n<p><a href=\"https://datascience.stackexchange.com/questions/11171/decision-tree-how-to-understand-or-calculate-the-probability-confidence-of-pred\">Decision tree, how to understand or calculate the probability/confidence of prediction result</a></p>\n\n<p>I would strongly recommend using some known embedding method like the word2vec, since as you mentioned, your dataset is too small for your model to be able to properly learn an encoding of context and vocabulary from.</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "44693",
                "question_votes:": "2",
                "question_text:": "<p>I have a dataset that consists of 365 records, and I want to apply a classification model on it (binary classification).</p>\n\n<p>As an output, in addition to the classification labels, I want to retrieve the classification confidence for each instance.</p>\n\n<p>I don't know how to deal with such a case. Can I use, for example, linear classifiers (SVM, logistic regression) with this small dataset? Because, I want to retrieve the classification confidence as well.</p>\n\n<p>I read that decision trees can be a good classifier for small datasets, but how can I retrieve the classification confidence with it?</p>\n\n<p>The dataset consists of tweets, each classified as positive or negative (from a sentiment perspective), and my feature vector consists of 2400 features (combination between word2vec embeddings and other features).</p>\n\n<p>Also, do you recommend me to use word2vec embeddings with such a small dataset? I think the classifier can't learn something from them using small dataset.</p>\n",
                "tags": "<classification><multiclass-classification>",
                "answers": [
                    [
                        "46331",
                        "2",
                        "44693",
                        "",
                        "",
                        "<p>The only way to know if a classifier is suitable for your data set is to try it and test it. All classifiers you've mentioned have a way to give confidences of their predictions. Logistic regression and decision trees will give you the probability that a sample is the positive class. SVM's will give you the distance to the decision hyperplane which can be used as a confidence measure; with some additional computations, you can also get a probability with SVM's, but I won't detail that here.</p>\n\n<p>One concern for such a small data set is overfitting when the number of features is much larger than the number of samples. You should address that by using some form of regularization.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "44695",
                        "2",
                        "44693",
                        "",
                        "",
                        "<p>The question whether to use a linear classifier depends less on the number of samples you have in your dataset and more whether your dataset is linearly separable (by the way, SVMs can be non-linear with the kernel trick).</p>\n\n<p>Now with regards to confidence in the classification, In SVMs there is a method that calculates the probability that a given sample belongs to a particular class using <strong>Platt scaling</strong> (\"<a href=\"http://citeseer.ist.psu.edu/viewdoc/download;jsessionid=92D78A0432AC435DC3DADF0A86A70E1D?doi=10.1.1.41.1639&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow noreferrer\">Original Paper</a>\"). This is the approach that is used in sklearn's SVM confidence implementation. You can read more about it in the following link:</p>\n\n<p><a href=\"https://prateekvjoshi.com/2015/12/15/how-to-compute-confidence-measure-for-svm-classifiers/\" rel=\"nofollow noreferrer\">How To Compute Confidence Measure For SVM Classifiers</a></p>\n\n<p>In both SVMs and linear regression models you can calculate the distance of a sample from the border and treat it as a confidence measurement (but it is not exactly that).</p>\n\n<p>With decision trees I'm not an expert but a similar question was posted and answered in the following link:</p>\n\n<p><a href=\"https://datascience.stackexchange.com/questions/11171/decision-tree-how-to-understand-or-calculate-the-probability-confidence-of-pred\">Decision tree, how to understand or calculate the probability/confidence of prediction result</a></p>\n\n<p>I would strongly recommend using some known embedding method like the word2vec, since as you mentioned, your dataset is too small for your model to be able to properly learn an encoding of context and vocabulary from.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10973",
            "_score": 12.072422,
            "_source": {
                "title": "Target data values are not evenly distributed",
                "content": "Target data values are not evenly distributed <p>Data nature: </p>\n\n<p>I have features with 10 numeric type, and other 10 categorical, with a lot of  values, at the end, using one-hot encoding I got a matrix of 600 columns. My problem is with accuracy which is 0.7, knowing that other peers got more that 0.9.</p>\n\n<p>Problem:</p>\n\n<p>Target data is binary, and is not evenly distributed at all. Trying blindly after pre-processing <code>from sklearn.linear_model import LogisticRegression</code> and <code>sklearn.svm</code> scored using <code>roc_auc_score</code>:  <code>.7</code> and <code>.75</code>.</p>\n\n<p>Back to basics, I run this </p>\n\n<pre><code>train['cible'].value_counts() / train['cible'].count()\n</code></pre>\n\n<p>and got </p>\n\n<pre><code>1    0.970791\n0    0.029209\nName: cible, dtype: float64\n</code></pre>\n\n<p>Quite interesting I think, but how can I improve accuracy. Any hints ?</p>\n\n<p>Note: I will edit and add False Positive Rate and True Positive Rate as I lost output, after scaling, missing data imputation and retraining the model which takes couple of hours.</p>\n <python><logistic-regression><accuracy><p>From <code>scikitlearn LogisticRegression</code> docs:</p>\n\n<blockquote>\n  <p><strong>class_weight</strong> : dict or \u2018balanced\u2019, default: None</p>\n  \n  <p>Weights associated with classes in the form {class_label: weight}. If\n  not given, all classes are supposed to have weight one. The \u201cbalanced\u201d\n  mode uses the values of y to automatically adjust weights inversely\n  proportional to class frequencies in the input data as n_samples /\n  (n_classes * np.bincount(y)). Note that these weights will be\n  multiplied with sample_weight (passed through the fit method) if\n  sample_weight is specified. New in version 0.17:\n  class_weight=\u2019balanced\u2019</p>\n</blockquote>\n\n<p>So try to add <code>class_weight='balanced'</code>in your call to <code>LogisticRegression()</code></p>\n\n<p>Or maybe if this doesn't work, try to use as trainSet an evenly split dataset: where the number of samples of class 1 is equal to class 0.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "38868",
                "question_votes:": "1",
                "question_text:": "<p>Data nature: </p>\n\n<p>I have features with 10 numeric type, and other 10 categorical, with a lot of  values, at the end, using one-hot encoding I got a matrix of 600 columns. My problem is with accuracy which is 0.7, knowing that other peers got more that 0.9.</p>\n\n<p>Problem:</p>\n\n<p>Target data is binary, and is not evenly distributed at all. Trying blindly after pre-processing <code>from sklearn.linear_model import LogisticRegression</code> and <code>sklearn.svm</code> scored using <code>roc_auc_score</code>:  <code>.7</code> and <code>.75</code>.</p>\n\n<p>Back to basics, I run this </p>\n\n<pre><code>train['cible'].value_counts() / train['cible'].count()\n</code></pre>\n\n<p>and got </p>\n\n<pre><code>1    0.970791\n0    0.029209\nName: cible, dtype: float64\n</code></pre>\n\n<p>Quite interesting I think, but how can I improve accuracy. Any hints ?</p>\n\n<p>Note: I will edit and add False Positive Rate and True Positive Rate as I lost output, after scaling, missing data imputation and retraining the model which takes couple of hours.</p>\n",
                "tags": "<python><logistic-regression><accuracy>",
                "answers": [
                    [
                        "38871",
                        "2",
                        "38868",
                        "",
                        "",
                        "<p>From <code>scikitlearn LogisticRegression</code> docs:</p>\n\n<blockquote>\n  <p><strong>class_weight</strong> : dict or \u2018balanced\u2019, default: None</p>\n  \n  <p>Weights associated with classes in the form {class_label: weight}. If\n  not given, all classes are supposed to have weight one. The \u201cbalanced\u201d\n  mode uses the values of y to automatically adjust weights inversely\n  proportional to class frequencies in the input data as n_samples /\n  (n_classes * np.bincount(y)). Note that these weights will be\n  multiplied with sample_weight (passed through the fit method) if\n  sample_weight is specified. New in version 0.17:\n  class_weight=\u2019balanced\u2019</p>\n</blockquote>\n\n<p>So try to add <code>class_weight='balanced'</code>in your call to <code>LogisticRegression()</code></p>\n\n<p>Or maybe if this doesn't work, try to use as trainSet an evenly split dataset: where the number of samples of class 1 is equal to class 0.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11516",
            "_score": 12.06022,
            "_source": {
                "title": "Gradient Descent Python Implementation isnt converging",
                "content": "Gradient Descent Python Implementation isnt converging <p>I trying to implement gradient descent in Python and I am following andrew ng course in order to follow the math. However, my implementation isnt working as I expect it to. It would be great you the community can help me identify my mistake.</p>\n\n<p>as I increase the range from 3 to higher number, I dont converge rather thetas move from very positive to very negative and finally nan because they get extremely small.</p>\n\n<p>following is the code.</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\n\nX = pd.DataFrame(load_boston().data, columns = load_boston().feature_names)\nX['theta0'] = 1\ny = load_boston().target\ny = pd.DataFrame(y, columns = ['target'])\ntheta = pd.DataFrame(np.random.randn(X.shape[1]),columns = ['target'], index = X.columns.values)\n\nprint('theta shape',theta.shape)\nprint('X shape',X.shape)\nprint('y shape',y.shape)\nprint(theta)\n\ndef predict(X,theta, ycol = 'target'):\n    return X.dot(theta)\n\nmse_values =[]\nalpha = 0.01\nfor i in range(10000):\n  error = predict(X,theta) - y\n  theta = theta - ((alpha)* (1/len(X)) * X.T.dot(error))\n  mse= np.sum(error**2)/len(X)\n  print('mse: ', mse.values)\n  mse_values.append(mse)\n  print('+'*5)\n\n\n\nplt.plot(mse_values)\nplt.show()  \n</code></pre>\n <python><gradient-descent><p>If you use the backtracking method (details in my answer in this link: </p>\n\n<p><a href=\"https://datascience.stackexchange.com/questions/24534/does-gradient-descent-always-converge-to-an-optimum/40644#40644\">Does gradient descent always converge to an optimum?</a>)</p>\n\n<p>then you can avoid spending time to manually find the \"right learning rate\" as in your case here. </p>\n<p>I was doubting my implementation all the way but it was the <code>learning rate</code>.\nafter a lot of experimentation I found the right one, but I am very much surprised as to how small the learning rate had to be in order for it to work, i.e <code>alpha = 0.000001</code></p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "40666",
                "question_votes:": "",
                "question_text:": "<p>I trying to implement gradient descent in Python and I am following andrew ng course in order to follow the math. However, my implementation isnt working as I expect it to. It would be great you the community can help me identify my mistake.</p>\n\n<p>as I increase the range from 3 to higher number, I dont converge rather thetas move from very positive to very negative and finally nan because they get extremely small.</p>\n\n<p>following is the code.</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\n\nX = pd.DataFrame(load_boston().data, columns = load_boston().feature_names)\nX['theta0'] = 1\ny = load_boston().target\ny = pd.DataFrame(y, columns = ['target'])\ntheta = pd.DataFrame(np.random.randn(X.shape[1]),columns = ['target'], index = X.columns.values)\n\nprint('theta shape',theta.shape)\nprint('X shape',X.shape)\nprint('y shape',y.shape)\nprint(theta)\n\ndef predict(X,theta, ycol = 'target'):\n    return X.dot(theta)\n\nmse_values =[]\nalpha = 0.01\nfor i in range(10000):\n  error = predict(X,theta) - y\n  theta = theta - ((alpha)* (1/len(X)) * X.T.dot(error))\n  mse= np.sum(error**2)/len(X)\n  print('mse: ', mse.values)\n  mse_values.append(mse)\n  print('+'*5)\n\n\n\nplt.plot(mse_values)\nplt.show()  \n</code></pre>\n",
                "tags": "<python><gradient-descent>",
                "answers": [
                    [
                        "51493",
                        "2",
                        "40666",
                        "",
                        "",
                        "<p>If you use the backtracking method (details in my answer in this link: </p>\n\n<p><a href=\"https://datascience.stackexchange.com/questions/24534/does-gradient-descent-always-converge-to-an-optimum/40644#40644\">Does gradient descent always converge to an optimum?</a>)</p>\n\n<p>then you can avoid spending time to manually find the \"right learning rate\" as in your case here. </p>\n",
                        "",
                        "1"
                    ],
                    [
                        "40710",
                        "2",
                        "40666",
                        "",
                        "",
                        "<p>I was doubting my implementation all the way but it was the <code>learning rate</code>.\nafter a lot of experimentation I found the right one, but I am very much surprised as to how small the learning rate had to be in order for it to work, i.e <code>alpha = 0.000001</code></p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10292",
            "_score": 12.007808,
            "_source": {
                "title": "Partitioning data into features/labels and train/test after reading from csv file",
                "content": "Partitioning data into features/labels and train/test after reading from csv file <p>I need to read data from csv file and then first partition that data into features and labels and then into training and testing set. However, there are several issues cropping up again and again. Below is the code I tried with error ,</p>\n\n<pre><code>ValueError: could not convert string to float: 'mon' \non line \nY: train_y})\n</code></pre>\n\n<p>The code for Linear Regression :-</p>\n\n<pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport numpy as np\n\nlearning_rate = 0.01\ntraining_epochs = 1000\ndisplay_step = 50\n\ndata = pd.read_csv('forestfires.csv')\ny = data.temp\nx = data.drop('temp', axis=1)\n\ntrain_x, test_x, train_y, test_y = train_test_split(x, y,test_size=0.2)\nn_samples = train_x.shape[0]\nn_features = train_x.shape[1]\n\nX = tf.placeholder('float', [None, n_features])\nY = tf.placeholder('float', [None, 1])\n\n# Model weights.\nW = tf.Variable(np.random.randn(n_features, 1), dtype='float32')\nb = tf.Variable(np.random.randn(1), dtype='float32')\n\n# Construct linear model.\nprediction = tf.matmul(X, W) + b\nloss = tf.reduce_sum(tf.pow(prediction - Y, 2))/(2 * n_samples)\noptimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n\n# Start training.\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for epoch in range(training_epochs):\n        for (x, y) in zip(train_x, train_y):\n            sess.run(optimizer, feed_dict={X: train_x,\n                                           Y: train_y})\n            # Display logs per epoch step.\n            if (epoch + 1) % display_step == 0:\n                c = sess.run(loss, feed_dict={X: train_x,\n                                              Y: train_y})\n                print ('Epoch:', '%04d' % (epoch+1), 'cost=','{:.9f}'.format(c), \\\n                       'W=', sess.run(W), 'b=', sess.run(b))\n    print ('Training Done!')\n    training_cost = sess.run(loss, feed_dict={X: train_x,\n                                              Y: train_y})\n    print ('Training cost=', training_cost, 'W=', sess.run(W), 'b=', sess.run(b), '\\n')\n    # Graphic display.\n    plt.plot(train_x, train_y, 'ro', label='Original data')\n    plt.plot(train_x, sess.run(W) * train_x + sess.run(b), label='Fitted line')\n    plt.legend()\n    plt.show()\n</code></pre>\n\n<p>Could anyone help me with reading data properly in a rather general way. Snapshot of the data :-</p>\n\n<p><a href=\"https://i.stack.imgur.com/kOLkU.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/kOLkU.png\" alt=\"enter image description here\"></a></p>\n <data-mining><pandas><linear-regression><p>I don't know exactly how your data is but <code>y = data.temp</code> may be a Series containing the string values which should be cast to float values. Try to change it to the following alternative.</p>\n\n<blockquote>\n  <p>y = data.temp.astype(float)</p>\n</blockquote>\n",
                "codes": [
                    []
                ],
                "question_id:": "37118",
                "question_votes:": "2",
                "question_text:": "<p>I need to read data from csv file and then first partition that data into features and labels and then into training and testing set. However, there are several issues cropping up again and again. Below is the code I tried with error ,</p>\n\n<pre><code>ValueError: could not convert string to float: 'mon' \non line \nY: train_y})\n</code></pre>\n\n<p>The code for Linear Regression :-</p>\n\n<pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport numpy as np\n\nlearning_rate = 0.01\ntraining_epochs = 1000\ndisplay_step = 50\n\ndata = pd.read_csv('forestfires.csv')\ny = data.temp\nx = data.drop('temp', axis=1)\n\ntrain_x, test_x, train_y, test_y = train_test_split(x, y,test_size=0.2)\nn_samples = train_x.shape[0]\nn_features = train_x.shape[1]\n\nX = tf.placeholder('float', [None, n_features])\nY = tf.placeholder('float', [None, 1])\n\n# Model weights.\nW = tf.Variable(np.random.randn(n_features, 1), dtype='float32')\nb = tf.Variable(np.random.randn(1), dtype='float32')\n\n# Construct linear model.\nprediction = tf.matmul(X, W) + b\nloss = tf.reduce_sum(tf.pow(prediction - Y, 2))/(2 * n_samples)\noptimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n\n# Start training.\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for epoch in range(training_epochs):\n        for (x, y) in zip(train_x, train_y):\n            sess.run(optimizer, feed_dict={X: train_x,\n                                           Y: train_y})\n            # Display logs per epoch step.\n            if (epoch + 1) % display_step == 0:\n                c = sess.run(loss, feed_dict={X: train_x,\n                                              Y: train_y})\n                print ('Epoch:', '%04d' % (epoch+1), 'cost=','{:.9f}'.format(c), \\\n                       'W=', sess.run(W), 'b=', sess.run(b))\n    print ('Training Done!')\n    training_cost = sess.run(loss, feed_dict={X: train_x,\n                                              Y: train_y})\n    print ('Training cost=', training_cost, 'W=', sess.run(W), 'b=', sess.run(b), '\\n')\n    # Graphic display.\n    plt.plot(train_x, train_y, 'ro', label='Original data')\n    plt.plot(train_x, sess.run(W) * train_x + sess.run(b), label='Fitted line')\n    plt.legend()\n    plt.show()\n</code></pre>\n\n<p>Could anyone help me with reading data properly in a rather general way. Snapshot of the data :-</p>\n\n<p><a href=\"https://i.stack.imgur.com/kOLkU.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/kOLkU.png\" alt=\"enter image description here\"></a></p>\n",
                "tags": "<data-mining><pandas><linear-regression>",
                "answers": [
                    [
                        "37120",
                        "2",
                        "37118",
                        "",
                        "",
                        "<p>I don't know exactly how your data is but <code>y = data.temp</code> may be a Series containing the string values which should be cast to float values. Try to change it to the following alternative.</p>\n\n<blockquote>\n  <p>y = data.temp.astype(float)</p>\n</blockquote>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9308",
            "_score": 11.982991,
            "_source": {
                "title": "Predicting Customer Activity Absence",
                "content": "Predicting Customer Activity Absence <p>Could you please assist me with to following question?</p>\n\n<p>I have a customer activity dataframe that looks like this:\n<a href=\"https://i.stack.imgur.com/5KeAU.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/5KeAU.png\" alt=\"enter image description here\"></a></p>\n\n<p>It contains at least 500.000 customers and a \"timeseries\" of 42 months. The ones and zeroes represent customer activity. If a customer was active during a particular month then there will be a 1, if not - 0. I need determine those customers that most likely (+ probability) will not be active during the next 6 months (2018 July-December). </p>\n\n<p>Could you please direct me what approach/models should i use in order to predict this? I use Python.</p>\n\n<p>Thanks in advance!</p>\n <python><pandas><prediction><dataframe><data-analysis><p>First issue in your model building method is that you have data in the binary form for each month and you are trying to predict into a 6 month time period. You gotta define what will be considered active in the next 6 months?</p>\n\n<ol>\n<li>Active in 6 months  = Active in each individual months?\nor </li>\n<li>Active in 6 months = Active in any given month?</li>\n</ol>\n\n<p>If you want to first predict for individual months, you can use logistic regression. It is useful for a binary classification of this kind.</p>\n\n<p>Use LogisticRegression from sklearn.linear_model to train and fit the data.\nThen, use confusion matrix and classification_report from sklearn.metrics to test the performance of your model.</p>\n\n<p>After having predictions for next 6 months, you can create a new column that checks if there are any 1's in the last 6 months and stores 1 else stores 0</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "33246",
                "question_votes:": "1",
                "question_text:": "<p>Could you please assist me with to following question?</p>\n\n<p>I have a customer activity dataframe that looks like this:\n<a href=\"https://i.stack.imgur.com/5KeAU.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/5KeAU.png\" alt=\"enter image description here\"></a></p>\n\n<p>It contains at least 500.000 customers and a \"timeseries\" of 42 months. The ones and zeroes represent customer activity. If a customer was active during a particular month then there will be a 1, if not - 0. I need determine those customers that most likely (+ probability) will not be active during the next 6 months (2018 July-December). </p>\n\n<p>Could you please direct me what approach/models should i use in order to predict this? I use Python.</p>\n\n<p>Thanks in advance!</p>\n",
                "tags": "<python><pandas><prediction><dataframe><data-analysis>",
                "answers": [
                    [
                        "33252",
                        "2",
                        "33246",
                        "",
                        "",
                        "<p>First issue in your model building method is that you have data in the binary form for each month and you are trying to predict into a 6 month time period. You gotta define what will be considered active in the next 6 months?</p>\n\n<ol>\n<li>Active in 6 months  = Active in each individual months?\nor </li>\n<li>Active in 6 months = Active in any given month?</li>\n</ol>\n\n<p>If you want to first predict for individual months, you can use logistic regression. It is useful for a binary classification of this kind.</p>\n\n<p>Use LogisticRegression from sklearn.linear_model to train and fit the data.\nThen, use confusion matrix and classification_report from sklearn.metrics to test the performance of your model.</p>\n\n<p>After having predictions for next 6 months, you can create a new column that checks if there are any 1's in the last 6 months and stores 1 else stores 0</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8776",
            "_score": 11.916349,
            "_source": {
                "title": "How to estimate the variance of regressors in scikit-learn?",
                "content": "How to estimate the variance of regressors in scikit-learn? <p>Every classifier in scikit-learn has a method <code>predict_proba(x)</code> that predicts class probabilities for <code>x</code>. How to do the same thing for regressors? </p>\n\n<p>The only regressor for which I know how to estimate the variance of the predictions is Gaussian process regression, for which I can do the following:</p>\n\n<pre><code>y_pred, sigma = gp.predict(x, return_std=True)\n</code></pre>\n\n<p>In one dimension, I can even plot, how confident the Gaussian process regressor is about its prediction of different data points</p>\n\n<p><a href=\"https://i.stack.imgur.com/gPHav.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/gPHav.png\" alt=\"enter image description here\"></a></p>\n\n<p>How to estimate the variance of predictions for other regressors? For example, for kernel ridge regressor, multi-layer perceptron, ensemble regressors?</p>\n <python><scikit-learn><regression><variance><p>There are some papers studying uncertainty in deep learning models using dropout. For instance take a look at </p>\n\n<p><a href=\"https://arxiv.org/abs/1506.02142\" rel=\"nofollow noreferrer\">Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</a> \nand \n<a href=\"https://www.sciencedirect.com/science/article/pii/S016794731930163X\" rel=\"nofollow noreferrer\">Uncertainty quantification using Bayesian neural networks in classification: Application to biomedical image segmentation</a></p>\n\n<p>As far as I understood, enabling dropouts while predicting allows running a kind of Monte Carlo Simulations, hence you can obtain the mean of these simulations. For a classification task, these simulations are followed by estimating the epistemic and aleatoric of a model by making use of the discrete nature of the output <a href=\"https://www.sciencedirect.com/science/article/pii/S016794731930163X\" rel=\"nofollow noreferrer\">2</a>. However, it is not very clear to me how this works in case of regression. But one idea that comes to my mind is that we can estimate the confidence interval using the mean and standard deviation of the predicted values in the Monte Carlo runs using \n<span class=\"math-container\">\\begin{equation}\n\\text{confidence interval} = \\mu \\pm t \\times \\frac{\\sigma}{\\sqrt{T}} \n\\end{equation}</span>\nwhere <span class=\"math-container\">$\\mu$</span> and <span class=\"math-container\">$\\sigma$</span> are the mean and standard deviation obtained from the Monte Carlo runs, <span class=\"math-container\">$t$</span> is derived from t-distribution table and using the degrees of freedom and <span class=\"math-container\">$T$</span> is the number of Monte Carlo simulations. \nI am not sure if this is a good measure of uncertainty and I would like to get some feedback on this as I am working on a similar issue. </p>\n<p>I have an idea but I am not sure if it is correct. Please feel free to express whatever opinion or emotions you might have about the following solution.</p>\n\n<p>Classification and regression tasks are very similar. If done, for example, via neural networks, then a network for regression will differ from the corresponding network for classification only in activation function of the output neuron and the loss function.</p>\n\n<p>The idea is to bin the target variable for the regression task, make a classification on the binned labels, and then use <code>predict_proba</code> to get the probability of the predicted values to be in a certain interval.</p>\n\n<p>The prediction probability for the initial regression task can be estimated based on the results of <code>predict_proba</code> for the corresponding classification.</p>\n\n<p>This is how it can be done for the same toy problem as shown on the picture in the question. The task is to learn a 1-D gaussian function</p>\n\n<pre><code>def gaussian(x, mu, sig):\n    return np.exp(-np.square((x-mu)/sig)/2)\n</code></pre>\n\n<p>given some training data.</p>\n\n<p>I build the following neural network in Keras:</p>\n\n<p><a href=\"https://i.stack.imgur.com/jqkPB.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/jqkPB.png\" alt=\"enter image description here\"></a></p>\n\n<p>The network is trained simultaneously for both classification and regression. It splits only in the last layer. The input is one-dimensional. \nThe hidden layer has 10 neurons. The output layer for regression is one neuron with the linear activation. The output layer for classification has several softmax neurons. Their amount depends on how many bins are filled with target variables.</p>\n\n<p>In this toy example, I have 6 training data points:</p>\n\n<pre><code># training data\nx_train = np.atleast_2d([3.2487, -1.2235, -10.0, 10.0, -5.7789, 6.6834]).T\ny_train = gaussian(x_train, mu, sig)\n</code></pre>\n\n<p>I divide the whole range were the target variable changes (0 to 1) into 10 bins. Each bin is 0.1 wide. The amount of bins can be thought of as a hyper-parameter. The more bins the closer the classification problem to the corresponding regression problem. But too many bins is probably not good.</p>\n\n<pre><code># Binning the target variable\nhist, bin_edges = np.histogram(y_train, bins=np.linspace(0, 1, 11))\ny_c = np.digitize(y_train, bin_edges)\nn_classes = len(np.unique(y_c))\n\n# Binarize targets for classification\nlb = LabelBinarizer()\ny_b = lb.fit_transform(y_c)\n</code></pre>\n\n<p>The training data fall into three bins. You can see in the picture why. The four points far on each side (two on the left side, and two on the right side) are all in one bin, and each of the remaining points in the middle is in a separate bin. The remaining seven bins are empty. So, the output layer for the classification task has 3 softmax neurons. I use 1-hot encoding for the labels.</p>\n\n<p>This is the network:</p>\n\n<pre><code># NNet with one input and two outputs: one for reg, another for clf\nmain_input = Input(shape=(1,), dtype='float32', name='main_input')\nhidden = Dense(10, input_dim=1, activation='tanh')(main_input)\nreg_output = Dense(1, activation='linear', name='reg_output')(hidden)\nclf_output = Dense(n_classes, activation='softmax', name='clf_output')(hidden)\nmodel = Model(inputs=[main_input], outputs=[reg_output, clf_output])\n</code></pre>\n\n<p>Different loss functions are used for classification and regression. I also assign different loss weights which can be thought of as another hyper-parameter.</p>\n\n<pre><code>model.compile(optimizer='adam',\n              loss={'reg_output': 'mse', 'clf_output': 'categorical_crossentropy'},\n              loss_weights={'reg_output': 1., 'clf_output': 0.2})\n</code></pre>\n\n<p>Training:</p>\n\n<pre><code>model.fit({'main_input': x_train},\n          {'reg_output': y_train, 'clf_output': y_b},\n          epochs=1000, verbose=0)\n</code></pre>\n\n<p>Running <code>model.predict</code> gives prediction for the regression and prediction probabilities for classification.</p>\n\n<pre><code># Prediction for both classification and regression \ny_pred, pred_proba_c = model.predict({'main_input': x})\n</code></pre>\n\n<p>Each row of the array <code>pred_proba_c</code> contains probabilities of putting a test point to one of three classes. I estimate a regression's analogue of <code>predict_proba</code> by taking the maximum of these three probabilities. </p>\n\n<pre><code># This is a regression's analogue of predict_proba \nr_pred_proba = np.max(pred_proba_c, axis=1)\n</code></pre>\n\n<p>This is the result. The prediction probability is shown in the bottom half of the picture. </p>\n\n<p><a href=\"https://i.stack.imgur.com/ZQdvd.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ZQdvd.png\" alt=\"enter image description here\"></a></p>\n\n<p>Intuitively, the probability is high where there are training data, and it decreases in the regions between the training data. The model becomes less sure about its predictions far from the training data.</p>\n\n<p>The maxima of the prediction probability are not exactly at the training points. This might be because there is no exact correspondence between the underlying classification and regression problems. They are related but they are not the same, and the relationship between them depends on the values of the hyper-parameters, and the learning algorithm. For example, if I change the loss weights,</p>\n\n<pre><code>model.compile(optimizer='adam',\n              loss={'reg_output': 'mse', 'clf_output': 'categorical_crossentropy'},\n              loss_weights={'reg_output': 1., 'clf_output': 1})\n</code></pre>\n\n<p>I get the following picture:</p>\n\n<p><a href=\"https://i.stack.imgur.com/ZuuVN.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ZuuVN.png\" alt=\"enter image description here\"></a></p>\n\n<p>Now the prediction probability values are different but the qualitative behavior is the same.</p>\n\n<p>The complete code is as follows:</p>\n\n<pre><code>import numpy as np \nimport matplotlib.pyplot as plt\nfrom keras.models import Model\nfrom keras.layers import Input, Dense\nfrom sklearn.preprocessing import LabelBinarizer\n\nnp.random.seed(1)\n\nx = np.atleast_2d(np.linspace(-10, 10, 200)).T\n\nmu = 0\nsig = 2\n\ndef gaussian(x, mu, sig):\n    return np.exp(-np.square((x-mu)/sig)/2)\n\n# training data\nx_train = np.atleast_2d([3.2487, -1.2235, -10.0, 10.0, -5.7789, 6.6834]).T\ny_train = gaussian(x_train, mu, sig)\n\n# Binning the target variable\nhist, bin_edges = np.histogram(y_train, bins=np.linspace(0, 1, 11))\ny_c = np.digitize(y_train, bin_edges)\nn_classes = len(np.unique(y_c))\n\n# Binarize targets for classification\nlb = LabelBinarizer()\ny_b = lb.fit_transform(y_c)\n\n# NNet with one input and two outputs: one for reg, another for clf\nmain_input = Input(shape=(1,), dtype='float32', name='main_input')\nhidden = Dense(10, input_dim=1, activation='tanh')(main_input)\nreg_output = Dense(1, activation='linear', name='reg_output')(hidden)\nclf_output = Dense(n_classes, activation='softmax', name='clf_output')(hidden)\nmodel = Model(inputs=[main_input], outputs=[reg_output, clf_output])\n\nmodel.compile(optimizer='adam',\n              loss={'reg_output': 'mse', 'clf_output': 'categorical_crossentropy'},\n              loss_weights={'reg_output': 1., 'clf_output': 0.2})\n\nmodel.fit({'main_input': x_train},\n          {'reg_output': y_train, 'clf_output': y_b},\n          epochs=1000, verbose=0)\n\n\n# Prediction for both classification and regression \ny_pred, pred_proba_c = model.predict({'main_input': x})\n\n# This is a regression's analogue of predict_proba \nr_pred_proba = np.max(pred_proba_c, axis=1)\n\nf, ax = plt.subplots(2, sharex=True)\nax[0].plot(x, gaussian(x, mu, sig), color=\"red\", label=\"ground truth\")\nax[0].scatter(x_train, y_train, color='navy', s=30, marker='o', label=\"training data\")\nax[0].plot(x, y_pred, 'b-', color=\"blue\", label=\"prediction\")\nax[0].legend(loc='best')\nax[0].grid()\nax[1].plot(x, r_pred_proba, color=\"navy\", label=\"prediction probability\")\nax[1].legend(loc='best')\nax[1].grid()\nplt.show()\n</code></pre>\n<p>I believe it is the <em>probabilistic nature of a model</em> that allows you to get the variance of predictions, or more generally defined as <strong>the uncertainty of predictions</strong>, like the Gaussian process you mentioned. This is not simply avaialble in standard regressors.</p>\n\n<p>I think you should be looking at <strong>Probabilistic regressors</strong> like <em>BayesianRidge</em> if you would like to estimate the uncertainty of your model. An implementation  is also avaialble in <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html#sklearn.linear_model.BayesianRidge\" rel=\"nofollow noreferrer\">scikit-learn</a>, also <a href=\"https://github.com/markdregan/Bayesian-Modelling-in-Python\" rel=\"nofollow noreferrer\">this nice python package</a> based on PyMC3 or directly via <a href=\"https://docs.pymc.io/notebooks/GLM-linear.html\" rel=\"nofollow noreferrer\">PyMC3</a> itself for instance. In the latter there are examples like for Bayesian regression in Jupyter Notebook with a good explanation.</p>\n\n<p>In principle, <strong>Bayesian Models</strong> do not return a a single estimate for the model parameters, but a distribution that make it possible to make inferences about new observations as well as to examine our uncertainty in the model. You may find this <a href=\"https://towardsdatascience.com/bayesian-linear-regression-in-python-using-machine-learning-to-predict-student-grades-part-2-b72059a8ac7e\" rel=\"nofollow noreferrer\">post</a> useful.</p>\n\n<p><strong>Note:</strong> Adding a normal prior on the weights as it is done in Bayesian regression, one turn the Least-Squares problem to regularized L2 regression under the hood as well (see the full math. derivation <a href=\"https://wiseodd.github.io/techblog/2017/01/05/bayesian-regression/\" rel=\"nofollow noreferrer\">here</a>).</p>\n\n<p><strong>Updated Answer</strong>: I totally forgot the classical yet simple and powerful <strong>Bootstrap Sampling</strong> method to calculate confidence intervals for machine learning algorithms. A textbook definition says:</p>\n\n<blockquote>\n  <p>Bootstrapping is a nonparametric approach to statistical inference\n  that substitutes computation for more traditional distributional\n  assumptions and asymptotic results. A number of advantages:</p>\n  \n  <ul>\n  <li>The bootstrap is quite general, although there are some cases in which it fails.</li>\n  <li>Because it does not require distributional assumptions (such as normally distributed errors), the bootstrap can provide more accurate\n  inferences when the data are not well behaved or when the sample size\n  is small.</li>\n  <li>It is possible to apply the bootstrap to statistics with sampling distributions that are difficult to derive, even asymptotically.</li>\n  <li>It is relatively simple to apply the bootstrap to complex data-collection plans (such as stratified and clustered samples). </li>\n  </ul>\n  \n  <p>Reference: Fox, John. Applied regression analysis and generalized linear\n  models. Sage Publications, 2015.</p>\n</blockquote>\n\n<p>Please note you do not need a model with probabilistic nature. See this <a href=\"https://machinelearningmastery.com/calculate-bootstrap-confidence-intervals-machine-learning-results-python/\" rel=\"nofollow noreferrer\">post</a>, or this <a href=\"https://stackoverflow.com/questions/16707141/python-estimating-regression-parameter-confidence-intervals-with-scikits-boots\">answer</a> or this <a href=\"https://stats.stackexchange.com/questions/183230/bootstrapping-confidence-interval-from-a-regression-prediction\">one</a>.</p>\n",
                "codes": [
                    [],
                    [
                        "def gaussian(x, mu, sig):\n    return np.exp(-np.square((x-mu)/sig)/2)\n",
                        "# training data\nx_train = np.atleast_2d([3.2487, -1.2235, -10.0, 10.0, -5.7789, 6.6834]).T\ny_train = gaussian(x_train, mu, sig)\n",
                        "# Binning the target variable\nhist, bin_edges = np.histogram(y_train, bins=np.linspace(0, 1, 11))\ny_c = np.digitize(y_train, bin_edges)\nn_classes = len(np.unique(y_c))\n\n# Binarize targets for classification\nlb = LabelBinarizer()\ny_b = lb.fit_transform(y_c)\n",
                        "# NNet with one input and two outputs: one for reg, another for clf\nmain_input = Input(shape=(1,), dtype='float32', name='main_input')\nhidden = Dense(10, input_dim=1, activation='tanh')(main_input)\nreg_output = Dense(1, activation='linear', name='reg_output')(hidden)\nclf_output = Dense(n_classes, activation='softmax', name='clf_output')(hidden)\nmodel = Model(inputs=[main_input], outputs=[reg_output, clf_output])\n",
                        "model.compile(optimizer='adam',\n              loss={'reg_output': 'mse', 'clf_output': 'categorical_crossentropy'},\n              loss_weights={'reg_output': 1., 'clf_output': 0.2})\n",
                        "model.fit({'main_input': x_train},\n          {'reg_output': y_train, 'clf_output': y_b},\n          epochs=1000, verbose=0)\n",
                        "# Prediction for both classification and regression \ny_pred, pred_proba_c = model.predict({'main_input': x})\n",
                        "# This is a regression's analogue of predict_proba \nr_pred_proba = np.max(pred_proba_c, axis=1)\n",
                        "model.compile(optimizer='adam',\n              loss={'reg_output': 'mse', 'clf_output': 'categorical_crossentropy'},\n              loss_weights={'reg_output': 1., 'clf_output': 1})\n",
                        "import numpy as np \nimport matplotlib.pyplot as plt\nfrom keras.models import Model\nfrom keras.layers import Input, Dense\nfrom sklearn.preprocessing import LabelBinarizer\n\nnp.random.seed(1)\n\nx = np.atleast_2d(np.linspace(-10, 10, 200)).T\n\nmu = 0\nsig = 2\n\ndef gaussian(x, mu, sig):\n    return np.exp(-np.square((x-mu)/sig)/2)\n\n# training data\nx_train = np.atleast_2d([3.2487, -1.2235, -10.0, 10.0, -5.7789, 6.6834]).T\ny_train = gaussian(x_train, mu, sig)\n\n# Binning the target variable\nhist, bin_edges = np.histogram(y_train, bins=np.linspace(0, 1, 11))\ny_c = np.digitize(y_train, bin_edges)\nn_classes = len(np.unique(y_c))\n\n# Binarize targets for classification\nlb = LabelBinarizer()\ny_b = lb.fit_transform(y_c)\n\n# NNet with one input and two outputs: one for reg, another for clf\nmain_input = Input(shape=(1,), dtype='float32', name='main_input')\nhidden = Dense(10, input_dim=1, activation='tanh')(main_input)\nreg_output = Dense(1, activation='linear', name='reg_output')(hidden)\nclf_output = Dense(n_classes, activation='softmax', name='clf_output')(hidden)\nmodel = Model(inputs=[main_input], outputs=[reg_output, clf_output])\n\nmodel.compile(optimizer='adam',\n              loss={'reg_output': 'mse', 'clf_output': 'categorical_crossentropy'},\n              loss_weights={'reg_output': 1., 'clf_output': 0.2})\n\nmodel.fit({'main_input': x_train},\n          {'reg_output': y_train, 'clf_output': y_b},\n          epochs=1000, verbose=0)\n\n\n# Prediction for both classification and regression \ny_pred, pred_proba_c = model.predict({'main_input': x})\n\n# This is a regression's analogue of predict_proba \nr_pred_proba = np.max(pred_proba_c, axis=1)\n\nf, ax = plt.subplots(2, sharex=True)\nax[0].plot(x, gaussian(x, mu, sig), color=\"red\", label=\"ground truth\")\nax[0].scatter(x_train, y_train, color='navy', s=30, marker='o', label=\"training data\")\nax[0].plot(x, y_pred, 'b-', color=\"blue\", label=\"prediction\")\nax[0].legend(loc='best')\nax[0].grid()\nax[1].plot(x, r_pred_proba, color=\"navy\", label=\"prediction probability\")\nax[1].legend(loc='best')\nax[1].grid()\nplt.show()\n"
                    ],
                    []
                ],
                "question_id:": "31773",
                "question_votes:": "4",
                "question_text:": "<p>Every classifier in scikit-learn has a method <code>predict_proba(x)</code> that predicts class probabilities for <code>x</code>. How to do the same thing for regressors? </p>\n\n<p>The only regressor for which I know how to estimate the variance of the predictions is Gaussian process regression, for which I can do the following:</p>\n\n<pre><code>y_pred, sigma = gp.predict(x, return_std=True)\n</code></pre>\n\n<p>In one dimension, I can even plot, how confident the Gaussian process regressor is about its prediction of different data points</p>\n\n<p><a href=\"https://i.stack.imgur.com/gPHav.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/gPHav.png\" alt=\"enter image description here\"></a></p>\n\n<p>How to estimate the variance of predictions for other regressors? For example, for kernel ridge regressor, multi-layer perceptron, ensemble regressors?</p>\n",
                "tags": "<python><scikit-learn><regression><variance>",
                "answers": [
                    [
                        "57131",
                        "2",
                        "31773",
                        "",
                        "",
                        "<p>There are some papers studying uncertainty in deep learning models using dropout. For instance take a look at </p>\n\n<p><a href=\"https://arxiv.org/abs/1506.02142\" rel=\"nofollow noreferrer\">Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</a> \nand \n<a href=\"https://www.sciencedirect.com/science/article/pii/S016794731930163X\" rel=\"nofollow noreferrer\">Uncertainty quantification using Bayesian neural networks in classification: Application to biomedical image segmentation</a></p>\n\n<p>As far as I understood, enabling dropouts while predicting allows running a kind of Monte Carlo Simulations, hence you can obtain the mean of these simulations. For a classification task, these simulations are followed by estimating the epistemic and aleatoric of a model by making use of the discrete nature of the output <a href=\"https://www.sciencedirect.com/science/article/pii/S016794731930163X\" rel=\"nofollow noreferrer\">2</a>. However, it is not very clear to me how this works in case of regression. But one idea that comes to my mind is that we can estimate the confidence interval using the mean and standard deviation of the predicted values in the Monte Carlo runs using \n<span class=\"math-container\">\\begin{equation}\n\\text{confidence interval} = \\mu \\pm t \\times \\frac{\\sigma}{\\sqrt{T}} \n\\end{equation}</span>\nwhere <span class=\"math-container\">$\\mu$</span> and <span class=\"math-container\">$\\sigma$</span> are the mean and standard deviation obtained from the Monte Carlo runs, <span class=\"math-container\">$t$</span> is derived from t-distribution table and using the degrees of freedom and <span class=\"math-container\">$T$</span> is the number of Monte Carlo simulations. \nI am not sure if this is a good measure of uncertainty and I would like to get some feedback on this as I am working on a similar issue. </p>\n",
                        "",
                        ""
                    ],
                    [
                        "32486",
                        "2",
                        "31773",
                        "",
                        "",
                        "<p>I have an idea but I am not sure if it is correct. Please feel free to express whatever opinion or emotions you might have about the following solution.</p>\n\n<p>Classification and regression tasks are very similar. If done, for example, via neural networks, then a network for regression will differ from the corresponding network for classification only in activation function of the output neuron and the loss function.</p>\n\n<p>The idea is to bin the target variable for the regression task, make a classification on the binned labels, and then use <code>predict_proba</code> to get the probability of the predicted values to be in a certain interval.</p>\n\n<p>The prediction probability for the initial regression task can be estimated based on the results of <code>predict_proba</code> for the corresponding classification.</p>\n\n<p>This is how it can be done for the same toy problem as shown on the picture in the question. The task is to learn a 1-D gaussian function</p>\n\n<pre><code>def gaussian(x, mu, sig):\n    return np.exp(-np.square((x-mu)/sig)/2)\n</code></pre>\n\n<p>given some training data.</p>\n\n<p>I build the following neural network in Keras:</p>\n\n<p><a href=\"https://i.stack.imgur.com/jqkPB.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/jqkPB.png\" alt=\"enter image description here\"></a></p>\n\n<p>The network is trained simultaneously for both classification and regression. It splits only in the last layer. The input is one-dimensional. \nThe hidden layer has 10 neurons. The output layer for regression is one neuron with the linear activation. The output layer for classification has several softmax neurons. Their amount depends on how many bins are filled with target variables.</p>\n\n<p>In this toy example, I have 6 training data points:</p>\n\n<pre><code># training data\nx_train = np.atleast_2d([3.2487, -1.2235, -10.0, 10.0, -5.7789, 6.6834]).T\ny_train = gaussian(x_train, mu, sig)\n</code></pre>\n\n<p>I divide the whole range were the target variable changes (0 to 1) into 10 bins. Each bin is 0.1 wide. The amount of bins can be thought of as a hyper-parameter. The more bins the closer the classification problem to the corresponding regression problem. But too many bins is probably not good.</p>\n\n<pre><code># Binning the target variable\nhist, bin_edges = np.histogram(y_train, bins=np.linspace(0, 1, 11))\ny_c = np.digitize(y_train, bin_edges)\nn_classes = len(np.unique(y_c))\n\n# Binarize targets for classification\nlb = LabelBinarizer()\ny_b = lb.fit_transform(y_c)\n</code></pre>\n\n<p>The training data fall into three bins. You can see in the picture why. The four points far on each side (two on the left side, and two on the right side) are all in one bin, and each of the remaining points in the middle is in a separate bin. The remaining seven bins are empty. So, the output layer for the classification task has 3 softmax neurons. I use 1-hot encoding for the labels.</p>\n\n<p>This is the network:</p>\n\n<pre><code># NNet with one input and two outputs: one for reg, another for clf\nmain_input = Input(shape=(1,), dtype='float32', name='main_input')\nhidden = Dense(10, input_dim=1, activation='tanh')(main_input)\nreg_output = Dense(1, activation='linear', name='reg_output')(hidden)\nclf_output = Dense(n_classes, activation='softmax', name='clf_output')(hidden)\nmodel = Model(inputs=[main_input], outputs=[reg_output, clf_output])\n</code></pre>\n\n<p>Different loss functions are used for classification and regression. I also assign different loss weights which can be thought of as another hyper-parameter.</p>\n\n<pre><code>model.compile(optimizer='adam',\n              loss={'reg_output': 'mse', 'clf_output': 'categorical_crossentropy'},\n              loss_weights={'reg_output': 1., 'clf_output': 0.2})\n</code></pre>\n\n<p>Training:</p>\n\n<pre><code>model.fit({'main_input': x_train},\n          {'reg_output': y_train, 'clf_output': y_b},\n          epochs=1000, verbose=0)\n</code></pre>\n\n<p>Running <code>model.predict</code> gives prediction for the regression and prediction probabilities for classification.</p>\n\n<pre><code># Prediction for both classification and regression \ny_pred, pred_proba_c = model.predict({'main_input': x})\n</code></pre>\n\n<p>Each row of the array <code>pred_proba_c</code> contains probabilities of putting a test point to one of three classes. I estimate a regression's analogue of <code>predict_proba</code> by taking the maximum of these three probabilities. </p>\n\n<pre><code># This is a regression's analogue of predict_proba \nr_pred_proba = np.max(pred_proba_c, axis=1)\n</code></pre>\n\n<p>This is the result. The prediction probability is shown in the bottom half of the picture. </p>\n\n<p><a href=\"https://i.stack.imgur.com/ZQdvd.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ZQdvd.png\" alt=\"enter image description here\"></a></p>\n\n<p>Intuitively, the probability is high where there are training data, and it decreases in the regions between the training data. The model becomes less sure about its predictions far from the training data.</p>\n\n<p>The maxima of the prediction probability are not exactly at the training points. This might be because there is no exact correspondence between the underlying classification and regression problems. They are related but they are not the same, and the relationship between them depends on the values of the hyper-parameters, and the learning algorithm. For example, if I change the loss weights,</p>\n\n<pre><code>model.compile(optimizer='adam',\n              loss={'reg_output': 'mse', 'clf_output': 'categorical_crossentropy'},\n              loss_weights={'reg_output': 1., 'clf_output': 1})\n</code></pre>\n\n<p>I get the following picture:</p>\n\n<p><a href=\"https://i.stack.imgur.com/ZuuVN.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ZuuVN.png\" alt=\"enter image description here\"></a></p>\n\n<p>Now the prediction probability values are different but the qualitative behavior is the same.</p>\n\n<p>The complete code is as follows:</p>\n\n<pre><code>import numpy as np \nimport matplotlib.pyplot as plt\nfrom keras.models import Model\nfrom keras.layers import Input, Dense\nfrom sklearn.preprocessing import LabelBinarizer\n\nnp.random.seed(1)\n\nx = np.atleast_2d(np.linspace(-10, 10, 200)).T\n\nmu = 0\nsig = 2\n\ndef gaussian(x, mu, sig):\n    return np.exp(-np.square((x-mu)/sig)/2)\n\n# training data\nx_train = np.atleast_2d([3.2487, -1.2235, -10.0, 10.0, -5.7789, 6.6834]).T\ny_train = gaussian(x_train, mu, sig)\n\n# Binning the target variable\nhist, bin_edges = np.histogram(y_train, bins=np.linspace(0, 1, 11))\ny_c = np.digitize(y_train, bin_edges)\nn_classes = len(np.unique(y_c))\n\n# Binarize targets for classification\nlb = LabelBinarizer()\ny_b = lb.fit_transform(y_c)\n\n# NNet with one input and two outputs: one for reg, another for clf\nmain_input = Input(shape=(1,), dtype='float32', name='main_input')\nhidden = Dense(10, input_dim=1, activation='tanh')(main_input)\nreg_output = Dense(1, activation='linear', name='reg_output')(hidden)\nclf_output = Dense(n_classes, activation='softmax', name='clf_output')(hidden)\nmodel = Model(inputs=[main_input], outputs=[reg_output, clf_output])\n\nmodel.compile(optimizer='adam',\n              loss={'reg_output': 'mse', 'clf_output': 'categorical_crossentropy'},\n              loss_weights={'reg_output': 1., 'clf_output': 0.2})\n\nmodel.fit({'main_input': x_train},\n          {'reg_output': y_train, 'clf_output': y_b},\n          epochs=1000, verbose=0)\n\n\n# Prediction for both classification and regression \ny_pred, pred_proba_c = model.predict({'main_input': x})\n\n# This is a regression's analogue of predict_proba \nr_pred_proba = np.max(pred_proba_c, axis=1)\n\nf, ax = plt.subplots(2, sharex=True)\nax[0].plot(x, gaussian(x, mu, sig), color=\"red\", label=\"ground truth\")\nax[0].scatter(x_train, y_train, color='navy', s=30, marker='o', label=\"training data\")\nax[0].plot(x, y_pred, 'b-', color=\"blue\", label=\"prediction\")\nax[0].legend(loc='best')\nax[0].grid()\nax[1].plot(x, r_pred_proba, color=\"navy\", label=\"prediction probability\")\nax[1].legend(loc='best')\nax[1].grid()\nplt.show()\n</code></pre>\n",
                        "",
                        "1"
                    ],
                    [
                        "31775",
                        "2",
                        "31773",
                        "",
                        "",
                        "<p>I believe it is the <em>probabilistic nature of a model</em> that allows you to get the variance of predictions, or more generally defined as <strong>the uncertainty of predictions</strong>, like the Gaussian process you mentioned. This is not simply avaialble in standard regressors.</p>\n\n<p>I think you should be looking at <strong>Probabilistic regressors</strong> like <em>BayesianRidge</em> if you would like to estimate the uncertainty of your model. An implementation  is also avaialble in <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html#sklearn.linear_model.BayesianRidge\" rel=\"nofollow noreferrer\">scikit-learn</a>, also <a href=\"https://github.com/markdregan/Bayesian-Modelling-in-Python\" rel=\"nofollow noreferrer\">this nice python package</a> based on PyMC3 or directly via <a href=\"https://docs.pymc.io/notebooks/GLM-linear.html\" rel=\"nofollow noreferrer\">PyMC3</a> itself for instance. In the latter there are examples like for Bayesian regression in Jupyter Notebook with a good explanation.</p>\n\n<p>In principle, <strong>Bayesian Models</strong> do not return a a single estimate for the model parameters, but a distribution that make it possible to make inferences about new observations as well as to examine our uncertainty in the model. You may find this <a href=\"https://towardsdatascience.com/bayesian-linear-regression-in-python-using-machine-learning-to-predict-student-grades-part-2-b72059a8ac7e\" rel=\"nofollow noreferrer\">post</a> useful.</p>\n\n<p><strong>Note:</strong> Adding a normal prior on the weights as it is done in Bayesian regression, one turn the Least-Squares problem to regularized L2 regression under the hood as well (see the full math. derivation <a href=\"https://wiseodd.github.io/techblog/2017/01/05/bayesian-regression/\" rel=\"nofollow noreferrer\">here</a>).</p>\n\n<p><strong>Updated Answer</strong>: I totally forgot the classical yet simple and powerful <strong>Bootstrap Sampling</strong> method to calculate confidence intervals for machine learning algorithms. A textbook definition says:</p>\n\n<blockquote>\n  <p>Bootstrapping is a nonparametric approach to statistical inference\n  that substitutes computation for more traditional distributional\n  assumptions and asymptotic results. A number of advantages:</p>\n  \n  <ul>\n  <li>The bootstrap is quite general, although there are some cases in which it fails.</li>\n  <li>Because it does not require distributional assumptions (such as normally distributed errors), the bootstrap can provide more accurate\n  inferences when the data are not well behaved or when the sample size\n  is small.</li>\n  <li>It is possible to apply the bootstrap to statistics with sampling distributions that are difficult to derive, even asymptotically.</li>\n  <li>It is relatively simple to apply the bootstrap to complex data-collection plans (such as stratified and clustered samples). </li>\n  </ul>\n  \n  <p>Reference: Fox, John. Applied regression analysis and generalized linear\n  models. Sage Publications, 2015.</p>\n</blockquote>\n\n<p>Please note you do not need a model with probabilistic nature. See this <a href=\"https://machinelearningmastery.com/calculate-bootstrap-confidence-intervals-machine-learning-results-python/\" rel=\"nofollow noreferrer\">post</a>, or this <a href=\"https://stackoverflow.com/questions/16707141/python-estimating-regression-parameter-confidence-intervals-with-scikits-boots\">answer</a> or this <a href=\"https://stats.stackexchange.com/questions/183230/bootstrapping-confidence-interval-from-a-regression-prediction\">one</a>.</p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3983",
            "_score": 11.751892,
            "_source": {
                "title": "Classification problem approach with Python",
                "content": "Classification problem approach with Python <p>I am a Python beginner, just getting into machine learning and need advice on the approach i should use for my problem.</p>\n\n<p>Here is an example of my data-set.\n<a href=\"https://i.stack.imgur.com/STKE0.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/STKE0.png\" alt=\"enter image description here\"></a></p>\n\n<p>Where the RESULT is a corresponding INDEX in each VALUES array and every row is a separate array, i need to find the probability of each index of an array being the RESULT based on its configuration, where the overall configuration and distribution is most important rather than any individual value.</p>\n <machine-learning><python><predictive-modeling><probability><p>You are looking at a <strong>Classification problem</strong>.</p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">Logistic regression</a>, <a href=\"http://scikit-learn.org/stable/modules/tree.html\" rel=\"nofollow noreferrer\">Decision trees</a>, <a href=\"http://scikit-learn.org/stable/modules/svm.html\" rel=\"nofollow noreferrer\">SVM</a>. Any of the above can solve the job for you. But selecting the best model depends upon how good it is able to predict the test set. Use <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\" rel=\"nofollow noreferrer\">cross-validations</a> and see which model can give you better accuracy. So split you test and train set accordingly. You don't expect the model to predict, if you haven't trained it. See <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html\" rel=\"nofollow noreferrer\">stratified sampling</a> for starters.</p>\n\n<p>Though your predictors might be <strong>categorical</strong> or <strong>ordinals</strong>, they can be treated as <strong>numericals</strong>.</p>\n\n<p>You have built in functions like <em>predict_proba</em> to find class probability. The references for this can be found in above links. But go through how they work and what is the policy for selecting best plane in any classification, so that you don't feel like you are using a black-box. Since you are saying that you are a beginner, <a href=\"http://pandas.pydata.org/\" rel=\"nofollow noreferrer\">pandas</a> will be a very useful module for reading data into dataframes and mending it as you like.</p>\n\n<p>Hope this clears something.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "16326",
                "question_votes:": "2",
                "question_text:": "<p>I am a Python beginner, just getting into machine learning and need advice on the approach i should use for my problem.</p>\n\n<p>Here is an example of my data-set.\n<a href=\"https://i.stack.imgur.com/STKE0.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/STKE0.png\" alt=\"enter image description here\"></a></p>\n\n<p>Where the RESULT is a corresponding INDEX in each VALUES array and every row is a separate array, i need to find the probability of each index of an array being the RESULT based on its configuration, where the overall configuration and distribution is most important rather than any individual value.</p>\n",
                "tags": "<machine-learning><python><predictive-modeling><probability>",
                "answers": [
                    [
                        "16327",
                        "2",
                        "16326",
                        "",
                        "",
                        "<p>You are looking at a <strong>Classification problem</strong>.</p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">Logistic regression</a>, <a href=\"http://scikit-learn.org/stable/modules/tree.html\" rel=\"nofollow noreferrer\">Decision trees</a>, <a href=\"http://scikit-learn.org/stable/modules/svm.html\" rel=\"nofollow noreferrer\">SVM</a>. Any of the above can solve the job for you. But selecting the best model depends upon how good it is able to predict the test set. Use <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\" rel=\"nofollow noreferrer\">cross-validations</a> and see which model can give you better accuracy. So split you test and train set accordingly. You don't expect the model to predict, if you haven't trained it. See <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html\" rel=\"nofollow noreferrer\">stratified sampling</a> for starters.</p>\n\n<p>Though your predictors might be <strong>categorical</strong> or <strong>ordinals</strong>, they can be treated as <strong>numericals</strong>.</p>\n\n<p>You have built in functions like <em>predict_proba</em> to find class probability. The references for this can be found in above links. But go through how they work and what is the policy for selecting best plane in any classification, so that you don't feel like you are using a black-box. Since you are saying that you are a beginner, <a href=\"http://pandas.pydata.org/\" rel=\"nofollow noreferrer\">pandas</a> will be a very useful module for reading data into dataframes and mending it as you like.</p>\n\n<p>Hope this clears something.</p>\n",
                        "",
                        "5"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8246",
            "_score": 11.750383,
            "_source": {
                "title": "Predict_proba and confusion matrix result interpretaion with Logistic regression in Python",
                "content": "Predict_proba and confusion matrix result interpretaion with Logistic regression in Python <p>I have a credit data set, and I need to find the probability of credit balance >1500 for given 2 sets of values\nMy code is the following\n1- Confusion Matrix results\n confusion_matrix(y,y_pred)\narray([[390,   1],\n       [  6,   3]], dtype=int64)</p>\n\n<p>What does it mean? is 390 the number of true positive or false negative?</p>\n\n<p>2- Predict_proba- I set X_pred to a matrix of 2 rows to certain values I want to test for Credit_balance >15000 and I get the following\narray([[0.93227393, 0.06772607],\n       [0.1729211 , 0.8270789 ]])\nHow do I interpret these values but dont understant how\nI can share my code if you want to better understand</p>\n <logistic-regression><p>You really need to understand what at least logistic regression is giving you out, let alone what it does internally to get those values. I really recommend you to read sklearn documentation of logistic regression <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">here</a> and atleast the <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\" rel=\"nofollow noreferrer\">wiki page</a>.</p>\n\n<ol>\n<li><p>The confusion matrix you had produced is of <code>[[tn, fp], [fn, tp]]</code> type. Do a <code>.ravel</code> on <code>numpy.ndarray</code> you received and assign that to this <code>(tn, fp, fn, tp)</code>. 390 in your case is the number of <code>true negatives</code>.</p></li>\n<li><p><code>predict_proba</code> takes a data point vector and gives you the probability of it being in the positive and negative class. So each inner array in your case will sum to one.</p></li>\n</ol>\n\n<p>Hope this helps.</p>\n\n<p><em>Edit 1</em>:</p>\n\n<p>From your comments, the order of probability returned for you is the order how classes are registered in class attribute. You can check the class order from the attribute <code>classes_</code>. If your classifier class instance is <code>clf</code> on which you applied <code>.fit</code>, then <code>clf.classes_</code> is the order of the classes. This is the order the <code>predict_proba</code> spits the probability. Most of the times the order is ascending if classes are ordinals.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "30331",
                "question_votes:": "",
                "question_text:": "<p>I have a credit data set, and I need to find the probability of credit balance >1500 for given 2 sets of values\nMy code is the following\n1- Confusion Matrix results\n confusion_matrix(y,y_pred)\narray([[390,   1],\n       [  6,   3]], dtype=int64)</p>\n\n<p>What does it mean? is 390 the number of true positive or false negative?</p>\n\n<p>2- Predict_proba- I set X_pred to a matrix of 2 rows to certain values I want to test for Credit_balance >15000 and I get the following\narray([[0.93227393, 0.06772607],\n       [0.1729211 , 0.8270789 ]])\nHow do I interpret these values but dont understant how\nI can share my code if you want to better understand</p>\n",
                "tags": "<logistic-regression>",
                "answers": [
                    [
                        "30332",
                        "2",
                        "30331",
                        "",
                        "",
                        "<p>You really need to understand what at least logistic regression is giving you out, let alone what it does internally to get those values. I really recommend you to read sklearn documentation of logistic regression <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">here</a> and atleast the <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\" rel=\"nofollow noreferrer\">wiki page</a>.</p>\n\n<ol>\n<li><p>The confusion matrix you had produced is of <code>[[tn, fp], [fn, tp]]</code> type. Do a <code>.ravel</code> on <code>numpy.ndarray</code> you received and assign that to this <code>(tn, fp, fn, tp)</code>. 390 in your case is the number of <code>true negatives</code>.</p></li>\n<li><p><code>predict_proba</code> takes a data point vector and gives you the probability of it being in the positive and negative class. So each inner array in your case will sum to one.</p></li>\n</ol>\n\n<p>Hope this helps.</p>\n\n<p><em>Edit 1</em>:</p>\n\n<p>From your comments, the order of probability returned for you is the order how classes are registered in class attribute. You can check the class order from the attribute <code>classes_</code>. If your classifier class instance is <code>clf</code> on which you applied <code>.fit</code>, then <code>clf.classes_</code> is the order of the classes. This is the order the <code>predict_proba</code> spits the probability. Most of the times the order is ascending if classes are ordinals.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4148",
            "_score": 11.746068,
            "_source": {
                "title": "How to learn to score new documents based on a existing set of scored documents?",
                "content": "How to learn to score new documents based on a existing set of scored documents? <p>I have a 50 000 documents of 1000 words or more ranked between 0 and 2000. They all deal with a similar topic. I'd like to create an algorithm that can learn to score new documents.</p>\n\n<p>What approach do you think I should take?</p>\n\n<p>I am a newbie in the field of machine learninig so if you could point me to introduction material about the particular solution you think of. I will be glad.</p>\n <machine-learning><predictive-modeling><text-mining><scoring><p>Basically this is a classification problem.</p>\n\n<p>You would want to model y(rank) ~ x(Document). \nAnd when you get a new document you need an estimated rank.</p>\n\n<p>Things you may want to consider.</p>\n\n<ul>\n<li>Do in need 2000 class labels, or is there any way to reduce the class labels to 3 classes etc. (class labels == score)</li>\n<li>How do I represent my documents. In short they must be numerically represented. (Approaches - One Hot Encoding, TFIDF, Embedding etc)</li>\n<li>Finally the last question which classification model should I use?.</li>\n</ul>\n\n<p>Linear Algebra followed by Andrew Ngs ML course is a good starting point. </p>\n<p>First come up with some features for the document. Stuff like frequency of some popular words associated with that topic might work. In this way get the features for all the documents and then apply some algorithm. Some ways you could apply them are:</p>\n\n<p>1) k means - cluster the documents on the basis of the features. Each cluster should be predominantly associated with a particular score value. Then see which cluster a new document will be assigned to.</p>\n\n<p>2) Supervised learning - use neural networks, multiclass SVMs etc to classify the new document to a particular class (score) using the model you would have generated.</p>\n\n<p>All of these are examples of classification to a discrete score value. However, since you are dealing with a large score range (0-2000), you could also try something like regression which will give you a continuous value, but could be rounded off to the nearest discrete one.</p>\n\n<p>Check out the Coursera course on Machine Learning for a great introduction!</p>\n<p>This requires that the dataset can stay in RAM but it does what I want using sklearn:</p>\n\n<pre><code>import numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import Ridge\n\n\ncorpus = [\n    'postgresql is great software for database engineering',\n    'postgresql is spam',\n    'spam &amp; egg',\n    'postgresql is the same as pg',\n    'more database is great stuff',\n]\n\ntest = [\n    'postgresql is spam &amp; egg',\n    'pg is a great database software',\n]\n\nvectorizer = CountVectorizer(min_df=1)\nX = vectorizer.fit_transform(corpus)\ny = np.array([[10, 1, 0, 7, 6]]).T  # documents score\nclf = Ridge(alpha=1.0)\nclf.fit(X, y)\n\nZ = vectorizer.transform(test)\n\nprint(clf.predict(Z))\n</code></pre>\n",
                "codes": [
                    [],
                    [],
                    [
                        "import numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import Ridge\n\n\ncorpus = [\n    'postgresql is great software for database engineering',\n    'postgresql is spam',\n    'spam & egg',\n    'postgresql is the same as pg',\n    'more database is great stuff',\n]\n\ntest = [\n    'postgresql is spam & egg',\n    'pg is a great database software',\n]\n\nvectorizer = CountVectorizer(min_df=1)\nX = vectorizer.fit_transform(corpus)\ny = np.array([[10, 1, 0, 7, 6]]).T  # documents score\nclf = Ridge(alpha=1.0)\nclf.fit(X, y)\n\nZ = vectorizer.transform(test)\n\nprint(clf.predict(Z))\n"
                    ]
                ],
                "question_id:": "16889",
                "question_votes:": "2",
                "question_text:": "<p>I have a 50 000 documents of 1000 words or more ranked between 0 and 2000. They all deal with a similar topic. I'd like to create an algorithm that can learn to score new documents.</p>\n\n<p>What approach do you think I should take?</p>\n\n<p>I am a newbie in the field of machine learninig so if you could point me to introduction material about the particular solution you think of. I will be glad.</p>\n",
                "tags": "<machine-learning><predictive-modeling><text-mining><scoring>",
                "answers": [
                    [
                        "16898",
                        "2",
                        "16889",
                        "",
                        "",
                        "<p>Basically this is a classification problem.</p>\n\n<p>You would want to model y(rank) ~ x(Document). \nAnd when you get a new document you need an estimated rank.</p>\n\n<p>Things you may want to consider.</p>\n\n<ul>\n<li>Do in need 2000 class labels, or is there any way to reduce the class labels to 3 classes etc. (class labels == score)</li>\n<li>How do I represent my documents. In short they must be numerically represented. (Approaches - One Hot Encoding, TFIDF, Embedding etc)</li>\n<li>Finally the last question which classification model should I use?.</li>\n</ul>\n\n<p>Linear Algebra followed by Andrew Ngs ML course is a good starting point. </p>\n",
                        "",
                        "2"
                    ],
                    [
                        "16892",
                        "2",
                        "16889",
                        "",
                        "",
                        "<p>First come up with some features for the document. Stuff like frequency of some popular words associated with that topic might work. In this way get the features for all the documents and then apply some algorithm. Some ways you could apply them are:</p>\n\n<p>1) k means - cluster the documents on the basis of the features. Each cluster should be predominantly associated with a particular score value. Then see which cluster a new document will be assigned to.</p>\n\n<p>2) Supervised learning - use neural networks, multiclass SVMs etc to classify the new document to a particular class (score) using the model you would have generated.</p>\n\n<p>All of these are examples of classification to a discrete score value. However, since you are dealing with a large score range (0-2000), you could also try something like regression which will give you a continuous value, but could be rounded off to the nearest discrete one.</p>\n\n<p>Check out the Coursera course on Machine Learning for a great introduction!</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "16905",
                        "2",
                        "16889",
                        "",
                        "",
                        "<p>This requires that the dataset can stay in RAM but it does what I want using sklearn:</p>\n\n<pre><code>import numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import Ridge\n\n\ncorpus = [\n    'postgresql is great software for database engineering',\n    'postgresql is spam',\n    'spam &amp; egg',\n    'postgresql is the same as pg',\n    'more database is great stuff',\n]\n\ntest = [\n    'postgresql is spam &amp; egg',\n    'pg is a great database software',\n]\n\nvectorizer = CountVectorizer(min_df=1)\nX = vectorizer.fit_transform(corpus)\ny = np.array([[10, 1, 0, 7, 6]]).T  # documents score\nclf = Ridge(alpha=1.0)\nclf.fit(X, y)\n\nZ = vectorizer.transform(test)\n\nprint(clf.predict(Z))\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15113",
            "_score": 11.697215,
            "_source": {
                "title": "Deciding on the number of components in PCA",
                "content": "Deciding on the number of components in PCA <p>I have been running my model several times now. Each time i get different results based on what number i put in my PCA component number range (I used raw numbers in the code instead of the range function).</p>\n\n<p>If i put the range from 1 to the max_number (e.g.100) of components i get certain accuracy, lets say 60%, and the component number chosen is 80. So 60% at 80 components.</p>\n\n<p>Now if i repeat the run with a range from 1 to 79, i get accuracy 62%, with number of component chosen as 45</p>\n\n<p>If i run the whole thing again, while choosing range from 1 to 100 separated by 10 (instead of 5, or 1), e.g. range(1, 100, 10), I get a different accuracy as well.</p>\n\n<p>The accuracy is varying and not linear, meaning that if the number of components increase, the accuracy will not necessarily increase.</p>\n\n<p>So what should i do?</p>\n\n<p>Should i run the analysis with component range 1 to max separated by 1 (e.g. range (1,max), and then each time i get a chosen component number i should investigate the series below it?\nCan someone help please?</p>\n\n<p>Here is my code</p>\n\n<pre><code># Search for the best combination of PCA truncation\n# and class reg (LogReg).\n\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(random_state=42, class_weight= 'balanced', max_iter=5000)\npipe_logreg = Pipeline(steps=[('pca', pca), ('logreg', logreg)])\n\n\n# Parameters of pipelines can be set using \u2018__\u2019 separated parameter names:\nparameters_logreg = [{'pca__n_components': [1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 100]}, \n                     {'logreg__C':[0.5, 1, 10, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 250, 300, 400, 500], \n                    'logreg__penalty':['l2'],\n                    'logreg__warm_start':['False', 'True'],\n                    'logreg__solver': ['newton-cg', 'lbfgs', 'sag'],\n                    'logreg__multi_class': ['ovr', 'multinomial', 'auto']},\n                     {'logreg__C':[0.5, 1, 10, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 250, 300, 400, 500], \n                    'logreg__penalty':['l1'],\n                    'logreg__warm_start':['False', 'True'],\n                    'logreg__solver': ['liblinear', 'saga'],\n                    'logreg__multi_class': ['ovr', 'auto'],\n                    }]\n\nclflogreg = GridSearchCV(pipe_logreg, param_grid =parameters_logreg, iid=False, cv=10,\n                      return_train_score=False)\nclflogreg.fit(X_balanced, y_balanced)\n\n\n# Plot the PCA spectrum (logreg)\npca.fit(X_balanced)\n\nfig1, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(6, 6)) #(I added 1 to fig)\nax0.plot(pca.explained_variance_ratio_, linewidth=2)\nax0.set_ylabel('PCA explained variance')\n\nax0.axvline(clflogreg.best_estimator_.named_steps['pca'].n_components,\n            linestyle=':', label='n_components chosen')\nax0.legend(prop=dict(size=12))\n\n# For each number of components, find the best classifier results\nresults_logreg = pd.DataFrame(clflogreg.cv_results_) #(Added _logreg to all variable def)\ncomponents_col_logreg = 'param_pca__n_components'\nbest_clfs_logreg = results_logreg.groupby(components_col_logreg).apply(\n    lambda g: g.nlargest(1, 'mean_test_score'))\n\nbest_clfs_logreg.plot(x=components_col_logreg, y='mean_test_score', yerr='std_test_score',\n               legend=False, ax=ax1)\nax1.set_ylabel('Classification accuracy (val)')\nax1.set_xlabel('n_components')\n\nplt.tight_layout()\nplt.show()\n</code></pre>\n <machine-learning><classification><machine-learning-model><pca><blockquote>\n  <p>The accuracy is varying and not linear, meaning that if the number of components increase, the accuracy will not necessarily increase.</p>\n</blockquote>\n\n<p>This is not unexpected. Choosing the right number of components requires balancing the <em>extra information</em> given by the additional dimensions and the <em>useless noise and redundancy</em> present therein. Even though PCA is a linear transform, and even if you used a linear classifier, the dependence of the classifier performance on the number of components is generally very non-linear. </p>\n\n<p>Two options (or alterations thereof) are common:</p>\n\n<ol>\n<li><p>Pick a <em>predefined</em> level of variance to keep (usually 90% or 95%, at least for me) and just stick with it. Think of it as regularization, rather than as a hyper-parameter.</p></li>\n<li><p>Treat it as a hyper-parameter and optimize over a validation set for the number of components to keep <span class=\"math-container\">$k$</span>. This is essentially what you are doing already. It's perfectly reasonable to simply choose the <span class=\"math-container\">$k$</span> that gave the best performance (on a held-out set).</p></li>\n</ol>\n",
                "codes": [
                    []
                ],
                "question_id:": "51214",
                "question_votes:": "2",
                "question_text:": "<p>I have been running my model several times now. Each time i get different results based on what number i put in my PCA component number range (I used raw numbers in the code instead of the range function).</p>\n\n<p>If i put the range from 1 to the max_number (e.g.100) of components i get certain accuracy, lets say 60%, and the component number chosen is 80. So 60% at 80 components.</p>\n\n<p>Now if i repeat the run with a range from 1 to 79, i get accuracy 62%, with number of component chosen as 45</p>\n\n<p>If i run the whole thing again, while choosing range from 1 to 100 separated by 10 (instead of 5, or 1), e.g. range(1, 100, 10), I get a different accuracy as well.</p>\n\n<p>The accuracy is varying and not linear, meaning that if the number of components increase, the accuracy will not necessarily increase.</p>\n\n<p>So what should i do?</p>\n\n<p>Should i run the analysis with component range 1 to max separated by 1 (e.g. range (1,max), and then each time i get a chosen component number i should investigate the series below it?\nCan someone help please?</p>\n\n<p>Here is my code</p>\n\n<pre><code># Search for the best combination of PCA truncation\n# and class reg (LogReg).\n\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(random_state=42, class_weight= 'balanced', max_iter=5000)\npipe_logreg = Pipeline(steps=[('pca', pca), ('logreg', logreg)])\n\n\n# Parameters of pipelines can be set using \u2018__\u2019 separated parameter names:\nparameters_logreg = [{'pca__n_components': [1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 100]}, \n                     {'logreg__C':[0.5, 1, 10, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 250, 300, 400, 500], \n                    'logreg__penalty':['l2'],\n                    'logreg__warm_start':['False', 'True'],\n                    'logreg__solver': ['newton-cg', 'lbfgs', 'sag'],\n                    'logreg__multi_class': ['ovr', 'multinomial', 'auto']},\n                     {'logreg__C':[0.5, 1, 10, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 250, 300, 400, 500], \n                    'logreg__penalty':['l1'],\n                    'logreg__warm_start':['False', 'True'],\n                    'logreg__solver': ['liblinear', 'saga'],\n                    'logreg__multi_class': ['ovr', 'auto'],\n                    }]\n\nclflogreg = GridSearchCV(pipe_logreg, param_grid =parameters_logreg, iid=False, cv=10,\n                      return_train_score=False)\nclflogreg.fit(X_balanced, y_balanced)\n\n\n# Plot the PCA spectrum (logreg)\npca.fit(X_balanced)\n\nfig1, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(6, 6)) #(I added 1 to fig)\nax0.plot(pca.explained_variance_ratio_, linewidth=2)\nax0.set_ylabel('PCA explained variance')\n\nax0.axvline(clflogreg.best_estimator_.named_steps['pca'].n_components,\n            linestyle=':', label='n_components chosen')\nax0.legend(prop=dict(size=12))\n\n# For each number of components, find the best classifier results\nresults_logreg = pd.DataFrame(clflogreg.cv_results_) #(Added _logreg to all variable def)\ncomponents_col_logreg = 'param_pca__n_components'\nbest_clfs_logreg = results_logreg.groupby(components_col_logreg).apply(\n    lambda g: g.nlargest(1, 'mean_test_score'))\n\nbest_clfs_logreg.plot(x=components_col_logreg, y='mean_test_score', yerr='std_test_score',\n               legend=False, ax=ax1)\nax1.set_ylabel('Classification accuracy (val)')\nax1.set_xlabel('n_components')\n\nplt.tight_layout()\nplt.show()\n</code></pre>\n",
                "tags": "<machine-learning><classification><machine-learning-model><pca>",
                "answers": [
                    [
                        "55807",
                        "2",
                        "51214",
                        "",
                        "",
                        "<blockquote>\n  <p>The accuracy is varying and not linear, meaning that if the number of components increase, the accuracy will not necessarily increase.</p>\n</blockquote>\n\n<p>This is not unexpected. Choosing the right number of components requires balancing the <em>extra information</em> given by the additional dimensions and the <em>useless noise and redundancy</em> present therein. Even though PCA is a linear transform, and even if you used a linear classifier, the dependence of the classifier performance on the number of components is generally very non-linear. </p>\n\n<p>Two options (or alterations thereof) are common:</p>\n\n<ol>\n<li><p>Pick a <em>predefined</em> level of variance to keep (usually 90% or 95%, at least for me) and just stick with it. Think of it as regularization, rather than as a hyper-parameter.</p></li>\n<li><p>Treat it as a hyper-parameter and optimize over a validation set for the number of components to keep <span class=\"math-container\">$k$</span>. This is essentially what you are doing already. It's perfectly reasonable to simply choose the <span class=\"math-container\">$k$</span> that gave the best performance (on a held-out set).</p></li>\n</ol>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9524",
            "_score": 11.679319,
            "_source": {
                "title": "When to perform feature selection, how, and how does data affect choosing the predictive model?",
                "content": "When to perform feature selection, how, and how does data affect choosing the predictive model? <p>Some background:</p>\n\n<p>I am attempting to predict attendance at this place using various features I have collected. I added to these features by extracting binary information from some of them. For example, temperature was expanded to temperature, temp>100, temp&lt;60, tempbetween60and100, the seasons were expanded out from the months as well. In total, I have 237 features, which include binary, multi-level categorical, and numerical.</p>\n\n<p>the output, attendance, is either numerical (by true attendance) or categorical (by binning attendance into 0-500, 501-1000, 1001-1200, 1201+ ). I am debating whether or not to further simplify the task and turn it into binary classification and do 2 bins, 0-800 and 801+</p>\n\n<p>My attempts thus far:</p>\n\n<p>My first approach, with much guidance on SO, was to gather as much data as possible (a max of 3 years worth of samples, with as many features as possible) and create a neural net to predict the true attendance. With some advice, I tried simpler methods, such as linear/logistic/other regression, but to no avail. Eventually, I switched to classification in hopes it would improve the accuracy and make this easier. In truth, the binning is all I would need to know, as opposed to true attendance anyway. The accuracy did improve, up to about 70%. Since then Ive tried methods such as PCA, Cross Validation, feature selection, etc. </p>\n\n<p>I have mostly used SkLearn's library, but have also used the Orange gui due to ease of trying various models.</p>\n\n<p>I come here now to get even more advice:</p>\n\n<p>Should I perform feature selection on this data? I know I have some data that is highly correlated, as I extracted some out from others. </p>\n\n<p>If yes, how? I have looked at pearsons coef between all columns, MIC between all columns, and I tried using feature importance in various ways here:</p>\n\n<pre><code>from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\nimport pandas as pd\nfrom collections import defaultdict\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.metrics import r2_score\nfrom sklearn.svm import LinearSVC\nfrom sklearn.feature_selection import RFE\nfrom sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import mutual_info_classif\n\n\ndf = pd.read_excel('Attempt1.xlsx', index_col=0, header=0)\nrows, cols = df.shape\n\nX = df.iloc[: , 0:(cols - 1)]\nY = df.iloc[: , cols - 1 ]\nprint(X.shape)\nprint(Y.shape)\n\n# Places attendance into bins\nY = Y.apply(lambda x: 0 if 0 &lt;= x &lt;= 500 else (1 if 500 &lt; x &lt;= 1000 else (2 if 1000 &lt; x &lt;= 1200 else 3)))\nprint(np.unique(Y))\n\n#Column names\nnames = list(X)\n\nX_train = X.iloc[:rows-151, :]\nX_test = X.iloc[rows-151:, :]\n\nY_train = Y.iloc[:rows-151]\nY_test = Y.iloc[rows-151:]\n\n# # chi2 of categorical features\n# feat = chi2(X_train.drop('Temperature', axis=1),Y_train)\n# print(feat)\n\nrf1 = RandomForestClassifier()\nrf1.fit(X_train,Y_train)\n\nfeatures = []\n\nprint(\"Features sorted by their score classifier (gini):\")\nfeatures.append(sorted(zip(map(lambda x: round(x, 4), rf1.feature_importances_), names),\n             reverse=True))\n\nrf2= RandomForestClassifier(criterion='entropy')\nrf2.fit(X_train,Y_train)\n\nprint(\"Features sorted by their score classifier (entropy):\")\nfeatures.append(sorted(zip(map(lambda x: round(x, 4), rf2.feature_importances_), names),\n             reverse=True))\n\nsvm = LinearSVC()\n# create the RFE model for the svm classifier\n# and select attributes\nrfe1 = RFE(svm, 20)\nrfe1 = rfe1.fit(X_train, Y_train)\n# print summaries for the selection of attributes\nfeatures.append([x for x,y in zip(list(X_train),rfe1.support_) if y==True ])\n\n\n\nrf3 = RandomForestClassifier()\n\nrfe2 = RFE(rf3, 20)\nrfe2 = rfe2.fit(X_train, Y_train)\n# print summaries for the selection of attributes\nfeatures.append([x for x,y in zip(list(X_train),rfe2.support_) if y==True ])\n\n\nrf4= RandomForestClassifier(criterion='entropy')\n\nrfe3 = RFE(rf4, 20)\nrfe3 = rfe3.fit(X_train, Y_train)\n# print summaries for the selection of attributes\nfeatures.append([x for x,y in zip(list(X_train),rfe3.support_) if y==True ])\n\nall_feats = {}\nfor a,b,c,d,e in zip(features[0], features[1], features[2], features[3], features[4]):\n    if a[1] not in all_feats.keys():\n        all_feats[a[1]] = 1\n    else:\n        all_feats[a[1]] += 1\n    if b[1] not in all_feats.keys():\n        all_feats[b[1]] = 1\n    else:\n        all_feats[b[1]] += 1\n    if c not in all_feats.keys():\n        all_feats[c] = 1\n    else:\n        all_feats[c] += 1\n    if d not in all_feats.keys():\n        all_feats[d] = 1\n    else:\n        all_feats[d] += 1\n    if e not in all_feats.keys():\n        all_feats[e] = 1\n    else:\n        all_feats[e] += 1\nprint(sorted(all_feats, key=all_feats.get, reverse=True)[:10])\n</code></pre>\n\n<p>My goal here was to extract the top ten features that each method chose. This didnt improve performance from testing in Orange</p>\n\n<p>At this point, I am not sure what is left besides picking a better model and tuning the parameters, because even after feature selection I seem to be stuck at 70%. Is there a better way to look at my data and decide </p>\n\n<ol>\n<li>Feature selection? Y/n</li>\n<li>If yes, which methods?</li>\n<li>PCA or similar methods? Y/n</li>\n<li>If yes, which method?</li>\n<li>Which model? Linear, or not?</li>\n<li>How to tune the model?</li>\n</ol>\n\n<p>From all of my testing and various models used, I believe I need to learn how to better understand this data and use that to guide the steps, but I cant seem to get a handle on it.. any suggestions?</p>\n\n<p><a href=\"https://drive.google.com/file/d/1LgVJECBfX_cGx-BeKmVobSy4Le91vtzp/view?usp=sharing\" rel=\"nofollow noreferrer\">Link to full data</a></p>\n\n<p>In the data provided, the yellow and bold data are missing values. I imputed them using their corresponding data in future years, as it is probably close. In testing, I tried this, and imputing using mean/common values, as well as eliminating all rows with missing values.</p>\n\n<p>Quick edit: please excuse the messy and borderline bad code... it was written frantically attempting to test it before leaving</p>\n <machine-learning><python><classification><predictive-modeling><feature-selection>",
                "codes": [],
                "question_id:": "33905",
                "question_votes:": "1",
                "question_text:": "<p>Some background:</p>\n\n<p>I am attempting to predict attendance at this place using various features I have collected. I added to these features by extracting binary information from some of them. For example, temperature was expanded to temperature, temp>100, temp&lt;60, tempbetween60and100, the seasons were expanded out from the months as well. In total, I have 237 features, which include binary, multi-level categorical, and numerical.</p>\n\n<p>the output, attendance, is either numerical (by true attendance) or categorical (by binning attendance into 0-500, 501-1000, 1001-1200, 1201+ ). I am debating whether or not to further simplify the task and turn it into binary classification and do 2 bins, 0-800 and 801+</p>\n\n<p>My attempts thus far:</p>\n\n<p>My first approach, with much guidance on SO, was to gather as much data as possible (a max of 3 years worth of samples, with as many features as possible) and create a neural net to predict the true attendance. With some advice, I tried simpler methods, such as linear/logistic/other regression, but to no avail. Eventually, I switched to classification in hopes it would improve the accuracy and make this easier. In truth, the binning is all I would need to know, as opposed to true attendance anyway. The accuracy did improve, up to about 70%. Since then Ive tried methods such as PCA, Cross Validation, feature selection, etc. </p>\n\n<p>I have mostly used SkLearn's library, but have also used the Orange gui due to ease of trying various models.</p>\n\n<p>I come here now to get even more advice:</p>\n\n<p>Should I perform feature selection on this data? I know I have some data that is highly correlated, as I extracted some out from others. </p>\n\n<p>If yes, how? I have looked at pearsons coef between all columns, MIC between all columns, and I tried using feature importance in various ways here:</p>\n\n<pre><code>from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\nimport pandas as pd\nfrom collections import defaultdict\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.metrics import r2_score\nfrom sklearn.svm import LinearSVC\nfrom sklearn.feature_selection import RFE\nfrom sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import mutual_info_classif\n\n\ndf = pd.read_excel('Attempt1.xlsx', index_col=0, header=0)\nrows, cols = df.shape\n\nX = df.iloc[: , 0:(cols - 1)]\nY = df.iloc[: , cols - 1 ]\nprint(X.shape)\nprint(Y.shape)\n\n# Places attendance into bins\nY = Y.apply(lambda x: 0 if 0 &lt;= x &lt;= 500 else (1 if 500 &lt; x &lt;= 1000 else (2 if 1000 &lt; x &lt;= 1200 else 3)))\nprint(np.unique(Y))\n\n#Column names\nnames = list(X)\n\nX_train = X.iloc[:rows-151, :]\nX_test = X.iloc[rows-151:, :]\n\nY_train = Y.iloc[:rows-151]\nY_test = Y.iloc[rows-151:]\n\n# # chi2 of categorical features\n# feat = chi2(X_train.drop('Temperature', axis=1),Y_train)\n# print(feat)\n\nrf1 = RandomForestClassifier()\nrf1.fit(X_train,Y_train)\n\nfeatures = []\n\nprint(\"Features sorted by their score classifier (gini):\")\nfeatures.append(sorted(zip(map(lambda x: round(x, 4), rf1.feature_importances_), names),\n             reverse=True))\n\nrf2= RandomForestClassifier(criterion='entropy')\nrf2.fit(X_train,Y_train)\n\nprint(\"Features sorted by their score classifier (entropy):\")\nfeatures.append(sorted(zip(map(lambda x: round(x, 4), rf2.feature_importances_), names),\n             reverse=True))\n\nsvm = LinearSVC()\n# create the RFE model for the svm classifier\n# and select attributes\nrfe1 = RFE(svm, 20)\nrfe1 = rfe1.fit(X_train, Y_train)\n# print summaries for the selection of attributes\nfeatures.append([x for x,y in zip(list(X_train),rfe1.support_) if y==True ])\n\n\n\nrf3 = RandomForestClassifier()\n\nrfe2 = RFE(rf3, 20)\nrfe2 = rfe2.fit(X_train, Y_train)\n# print summaries for the selection of attributes\nfeatures.append([x for x,y in zip(list(X_train),rfe2.support_) if y==True ])\n\n\nrf4= RandomForestClassifier(criterion='entropy')\n\nrfe3 = RFE(rf4, 20)\nrfe3 = rfe3.fit(X_train, Y_train)\n# print summaries for the selection of attributes\nfeatures.append([x for x,y in zip(list(X_train),rfe3.support_) if y==True ])\n\nall_feats = {}\nfor a,b,c,d,e in zip(features[0], features[1], features[2], features[3], features[4]):\n    if a[1] not in all_feats.keys():\n        all_feats[a[1]] = 1\n    else:\n        all_feats[a[1]] += 1\n    if b[1] not in all_feats.keys():\n        all_feats[b[1]] = 1\n    else:\n        all_feats[b[1]] += 1\n    if c not in all_feats.keys():\n        all_feats[c] = 1\n    else:\n        all_feats[c] += 1\n    if d not in all_feats.keys():\n        all_feats[d] = 1\n    else:\n        all_feats[d] += 1\n    if e not in all_feats.keys():\n        all_feats[e] = 1\n    else:\n        all_feats[e] += 1\nprint(sorted(all_feats, key=all_feats.get, reverse=True)[:10])\n</code></pre>\n\n<p>My goal here was to extract the top ten features that each method chose. This didnt improve performance from testing in Orange</p>\n\n<p>At this point, I am not sure what is left besides picking a better model and tuning the parameters, because even after feature selection I seem to be stuck at 70%. Is there a better way to look at my data and decide </p>\n\n<ol>\n<li>Feature selection? Y/n</li>\n<li>If yes, which methods?</li>\n<li>PCA or similar methods? Y/n</li>\n<li>If yes, which method?</li>\n<li>Which model? Linear, or not?</li>\n<li>How to tune the model?</li>\n</ol>\n\n<p>From all of my testing and various models used, I believe I need to learn how to better understand this data and use that to guide the steps, but I cant seem to get a handle on it.. any suggestions?</p>\n\n<p><a href=\"https://drive.google.com/file/d/1LgVJECBfX_cGx-BeKmVobSy4Le91vtzp/view?usp=sharing\" rel=\"nofollow noreferrer\">Link to full data</a></p>\n\n<p>In the data provided, the yellow and bold data are missing values. I imputed them using their corresponding data in future years, as it is probably close. In testing, I tried this, and imputing using mean/common values, as well as eliminating all rows with missing values.</p>\n\n<p>Quick edit: please excuse the messy and borderline bad code... it was written frantically attempting to test it before leaving</p>\n",
                "tags": "<machine-learning><python><classification><predictive-modeling><feature-selection>",
                "answers": []
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "188",
            "_score": 11.667519,
            "_source": {
                "title": "Skewed multi-class data",
                "content": "Skewed multi-class data <p>I have a dataset which contains ~100,000 samples of 50 classes. I have been using SVM with an RBF kernel to train and predict new data. The problem though is the dataset is skewed towards different classes. </p>\n\n<p>For example, Class 1 - 30 (~3% each), Class 31 - 45 (~0.6% each), Class 46 - 50 (~0.2% each)</p>\n\n<p>I see that the model tends to very rarely predict the classes which occur less frequent in the training set, even though the test set has the same class distribution as the training set. </p>\n\n<p>I am aware that there are technique such as 'undersampling' where the majority class is scaled down to the minor class. However, is this applicable here where there are so many different classes? Are there other methods to help handle this case?</p>\n <classification><svm><p>I would suggest you to use libsvm, which already has adjustable class weights implemented in it. Rather than replicating the training samples, one modifies the C parameter for different classes in the SVM optimization. For example if your data has 2 classes, and the first class is only 10% of the data, you would choose class weights to be 10 and 1 for class 1 and 2 respectively. Therefore, margin violations of the first class would cost 10 times more than the margin violations for second class, and per-class accuracies would be more balanced.</p>\n<p>Regarding the approach, SVM with an RBF kernel does a good job, but SVMs can be slowed down by large object sizes, unless you are employing CV with e.g. one tenth of the data randomly assigned to each fold.  However, did you ask yourself why you are employing SVMs in the first place?  </p>\n\n<p>Have you tried multivariate linear regression, $\\mathbf{Y}=\\mathbf{X}\\boldsymbol{\\beta}$, where each record of $\\mathbf{Y}$ is coded $y_{ij}=+1$ if the $i$th object is in class $j$, and $y_{ij}=-1$ otherwise?  If the classification accuracy is appreciably high using linear regression, then your data are linearly separable, and more complex methods such as SVMs and ANNs aren't needed.  Step 2 would be to show that k-nearest neighbor, naive Bayes, linear (Fisher) discriminant analysis, polytomous logistic regression, etc., break down and fail. </p>\n\n<p>For terminology, you might couch the issue of having more class weights in the context of \"lower proportions of objects in certain classes,\" or \"near-zero class size.\"  Skew tends to be used for describing the distribution of a feature's values, as in skewness, fat tails, etc.     </p>\n\n<p>How many features do you have?  Did you try unsupervised clustering (class discovery) on the 100,000 objects before trying supervised classification (class prediction) with SVM?  Maybe the 100,000 objects can be grouped into fewer classes than 50, for which the new class membership could be used as the target class during classification analysis.  This may alleviate the problem of having near-zero class size.</p>\n<p>I have faced this problem many times while using SVM with Rbf kernel. Using Linear kernel instead of Rbf kernel solved my problem, but I dealt with lesser number of classes. The results were less skewed and more accurate with the linear kernel. Hope this solves your problem.</p>\n\n<p>Edit: While I wrote original answer I was naive enough to not consider weighting the classes as one of them correctly answered. Also, while using rbf kernel its important to make sure that the penalty parameter or the 'C' value as per sklearn's svm module is too generic. I find that the default value of C=1 is too generic most of the time and I typically end up with a value of C=10000. Hope this helps others who get skewed results with svm(rbf) despite of having good distribution of classes in data.</p>\n<p>I am not an export in using SVMs, but usually (if you are using a machine learning library like Python's <code>scikit-learn</code> or R's <code>libsvm</code>, there is the <code>class_weight</code> parameter, or <code>class.weights</code>, respectively. </p>\n\n<p>Or if you'd use a Bayes classifier, you would take this \"skew\" into account via the \"prior (class) probabilities\" P(&omega;<sub>j</sub>)</p>\n",
                "codes": [
                    [],
                    [],
                    [],
                    []
                ],
                "question_id:": "736",
                "question_votes:": "8",
                "question_text:": "<p>I have a dataset which contains ~100,000 samples of 50 classes. I have been using SVM with an RBF kernel to train and predict new data. The problem though is the dataset is skewed towards different classes. </p>\n\n<p>For example, Class 1 - 30 (~3% each), Class 31 - 45 (~0.6% each), Class 46 - 50 (~0.2% each)</p>\n\n<p>I see that the model tends to very rarely predict the classes which occur less frequent in the training set, even though the test set has the same class distribution as the training set. </p>\n\n<p>I am aware that there are technique such as 'undersampling' where the majority class is scaled down to the minor class. However, is this applicable here where there are so many different classes? Are there other methods to help handle this case?</p>\n",
                "tags": "<classification><svm>",
                "answers": [
                    [
                        "740",
                        "2",
                        "736",
                        "",
                        "",
                        "<p>I would suggest you to use libsvm, which already has adjustable class weights implemented in it. Rather than replicating the training samples, one modifies the C parameter for different classes in the SVM optimization. For example if your data has 2 classes, and the first class is only 10% of the data, you would choose class weights to be 10 and 1 for class 1 and 2 respectively. Therefore, margin violations of the first class would cost 10 times more than the margin violations for second class, and per-class accuracies would be more balanced.</p>\n",
                        "",
                        "6"
                    ],
                    [
                        "5508",
                        "2",
                        "736",
                        "",
                        "",
                        "<p>Regarding the approach, SVM with an RBF kernel does a good job, but SVMs can be slowed down by large object sizes, unless you are employing CV with e.g. one tenth of the data randomly assigned to each fold.  However, did you ask yourself why you are employing SVMs in the first place?  </p>\n\n<p>Have you tried multivariate linear regression, $\\mathbf{Y}=\\mathbf{X}\\boldsymbol{\\beta}$, where each record of $\\mathbf{Y}$ is coded $y_{ij}=+1$ if the $i$th object is in class $j$, and $y_{ij}=-1$ otherwise?  If the classification accuracy is appreciably high using linear regression, then your data are linearly separable, and more complex methods such as SVMs and ANNs aren't needed.  Step 2 would be to show that k-nearest neighbor, naive Bayes, linear (Fisher) discriminant analysis, polytomous logistic regression, etc., break down and fail. </p>\n\n<p>For terminology, you might couch the issue of having more class weights in the context of \"lower proportions of objects in certain classes,\" or \"near-zero class size.\"  Skew tends to be used for describing the distribution of a feature's values, as in skewness, fat tails, etc.     </p>\n\n<p>How many features do you have?  Did you try unsupervised clustering (class discovery) on the 100,000 objects before trying supervised classification (class prediction) with SVM?  Maybe the 100,000 objects can be grouped into fewer classes than 50, for which the new class membership could be used as the target class during classification analysis.  This may alleviate the problem of having near-zero class size.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "737",
                        "2",
                        "736",
                        "",
                        "",
                        "<p>I have faced this problem many times while using SVM with Rbf kernel. Using Linear kernel instead of Rbf kernel solved my problem, but I dealt with lesser number of classes. The results were less skewed and more accurate with the linear kernel. Hope this solves your problem.</p>\n\n<p>Edit: While I wrote original answer I was naive enough to not consider weighting the classes as one of them correctly answered. Also, while using rbf kernel its important to make sure that the penalty parameter or the 'C' value as per sklearn's svm module is too generic. I find that the default value of C=1 is too generic most of the time and I typically end up with a value of C=10000. Hope this helps others who get skewed results with svm(rbf) despite of having good distribution of classes in data.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "770",
                        "2",
                        "736",
                        "",
                        "",
                        "<p>I am not an export in using SVMs, but usually (if you are using a machine learning library like Python's <code>scikit-learn</code> or R's <code>libsvm</code>, there is the <code>class_weight</code> parameter, or <code>class.weights</code>, respectively. </p>\n\n<p>Or if you'd use a Bayes classifier, you would take this \"skew\" into account via the \"prior (class) probabilities\" P(&omega;<sub>j</sub>)</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12406",
            "_score": 11.666587,
            "_source": {
                "title": "Mean Absolute Error in Random Forest Regression",
                "content": "Mean Absolute Error in Random Forest Regression <p>I am new to the whole ML scene and am trying to resolve the <a href=\"https://www.kaggle.com/c/allstate-claims-severity/data\" rel=\"nofollow noreferrer\">Allstate Kaggle challenge</a> to get a better feeling for the Random Forest Regression technique. </p>\n\n<p>The challenge is evaluated based on the MAE for each row. </p>\n\n<p>I've run the <code>sklearn</code> <code>RandomForrestRegressor</code> on my validation set, using the <code>criterion=mae</code> attribute. To my understanding this will run the Forest algorithm calculating the <code>mae</code> instead of the <code>mse</code> for each node.</p>\n\n<p>After that I've used this: <code>metrics.mean_absolute_error(Y_valid, m.predict(X_valid))</code> in order to calculate the MAE for each row of data.</p>\n\n<p>What I would like to know is if the logic I'm following is sound. Am I making a fundamental mistake or missing something here? Should I have used the default MSE based Regressor and then calculate the MAE of each row using the <code>mean_absolute_error</code> function?</p>\n <machine-learning><regression><random-forest><linear-regression><p>Let me clarify few fundamental things:</p>\n\n<ol>\n<li><p>In <code>sklearn</code>, <em>RandomForrest Regressor</em> <code>criterion</code> is:</p>\n\n<blockquote>\n  <p><em>The function to measure the quality of a split</em></p>\n</blockquote>\n\n<p>It's a performance measure (by default, <em>MSE</em>) which helps the algorithm to decide on a rule for an optimum split on a node in a tree.</p></li>\n<li><p><em>Kaggle</em> is giving you a metric, i.e. <em>MAE</em> (again a performance/ quality measure) but to evaluate the performance of your ML model, once finalized.</p></li>\n</ol>\n\n<p>To come back to your question: while both <em>MAE/ MSE</em> are performance measures, they are being used at two different stages of a modeling process and might not be related. So, while it makes sense to evaluate your final model on <em>MAE</em> as you would be judged on it, you can choose any of MAE/ MSE for <code>criterion</code> (i.e. for <em>RandomForest</em>) depending on performance at validation stage.</p>\n\n<p>While the above being said, keep in mind that you might want to evaluate the validation errors (i.e. for finalizing a model) on the same metric (i.e. MAE in this case), to keep error measure consistent with the test set evaluation.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "43542",
                "question_votes:": "",
                "question_text:": "<p>I am new to the whole ML scene and am trying to resolve the <a href=\"https://www.kaggle.com/c/allstate-claims-severity/data\" rel=\"nofollow noreferrer\">Allstate Kaggle challenge</a> to get a better feeling for the Random Forest Regression technique. </p>\n\n<p>The challenge is evaluated based on the MAE for each row. </p>\n\n<p>I've run the <code>sklearn</code> <code>RandomForrestRegressor</code> on my validation set, using the <code>criterion=mae</code> attribute. To my understanding this will run the Forest algorithm calculating the <code>mae</code> instead of the <code>mse</code> for each node.</p>\n\n<p>After that I've used this: <code>metrics.mean_absolute_error(Y_valid, m.predict(X_valid))</code> in order to calculate the MAE for each row of data.</p>\n\n<p>What I would like to know is if the logic I'm following is sound. Am I making a fundamental mistake or missing something here? Should I have used the default MSE based Regressor and then calculate the MAE of each row using the <code>mean_absolute_error</code> function?</p>\n",
                "tags": "<machine-learning><regression><random-forest><linear-regression>",
                "answers": [
                    [
                        "43546",
                        "2",
                        "43542",
                        "",
                        "",
                        "<p>Let me clarify few fundamental things:</p>\n\n<ol>\n<li><p>In <code>sklearn</code>, <em>RandomForrest Regressor</em> <code>criterion</code> is:</p>\n\n<blockquote>\n  <p><em>The function to measure the quality of a split</em></p>\n</blockquote>\n\n<p>It's a performance measure (by default, <em>MSE</em>) which helps the algorithm to decide on a rule for an optimum split on a node in a tree.</p></li>\n<li><p><em>Kaggle</em> is giving you a metric, i.e. <em>MAE</em> (again a performance/ quality measure) but to evaluate the performance of your ML model, once finalized.</p></li>\n</ol>\n\n<p>To come back to your question: while both <em>MAE/ MSE</em> are performance measures, they are being used at two different stages of a modeling process and might not be related. So, while it makes sense to evaluate your final model on <em>MAE</em> as you would be judged on it, you can choose any of MAE/ MSE for <code>criterion</code> (i.e. for <em>RandomForest</em>) depending on performance at validation stage.</p>\n\n<p>While the above being said, keep in mind that you might want to evaluate the validation errors (i.e. for finalizing a model) on the same metric (i.e. MAE in this case), to keep error measure consistent with the test set evaluation.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13648",
            "_score": 11.613522,
            "_source": {
                "title": "Products classification by name",
                "content": "Products classification by name <p>I am a beginner with machine learning, and I'm trying to build a model to classify products by category according to the words present in the product name.\nMy goal is to predict the category of some new product, just by observing the categories for existing products.<br>\nFor example, having the following products:</p>\n\n<pre><code>PRODUCT                                     CATEGORY\nsoap bar johnsons green leaves              bath\ncookie bauducco lemon 120gr                 cookie\nnesfit cookie choc and st                   cookie\nstrawberry soap soft                        bath\nspoon hercules medium                       kitchen\nsoap dish plastic medium                    bath\n[...]\n</code></pre>\n\n<p>My first thought is to group the words (tokens) present in each product, indicating the designated category and the occurrences count (to be used as a weight). So, for this sample, I have:</p>\n\n<pre><code>WORD           CATEGORY         COUNT\nsoap           bath             3\ncookie         cookie           2\nmedium         bath             1\nmedium         kitchen          1\nbar            bath             1\njohnsons       bath             1\n</code></pre>\n\n<p>Having this, I could be able to train a model, and use it to classify a new product. </p>\n\n<p>For example, having a new product <code>hands liquid soap 120oz</code>, it could be classified as <code>bath</code>, because it contains the word <code>soap</code>, which have a strong weight for the <code>bath</code> category.  </p>\n\n<p>In other case, the new product <code>medium hammer</code> could be classified as <code>bath</code> or <code>kitchen</code> , according the occurrence of the word <code>medium</code> in the training set.</p>\n\n<p>So, my doubts are: </p>\n\n<ul>\n<li>Am I going to the correct approach?</li>\n<li>What is the best algorithm to be used in this case?</li>\n<li>How can I apply this using Weka?</li>\n</ul>\n <classification><multiclass-classification><p>This should be doable with pre-trained word vectors + document/sentence vectors.  Tutorial : <a href=\"https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e\" rel=\"nofollow noreferrer\">https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e</a></p>\n\n<p><a href=\"https://i.stack.imgur.com/KVB2l.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/KVB2l.png\" alt=\"enter image description here\"></a></p>\n\n<p>All Product labels with \"similar meanings\" should cluster in a short distance. </p>\n\n<p>After product name ha been transformed into a vector, vector can be fed into a logistic regression classifier (Or a shallow neural network). </p>\n\n<p>Tutorial : <a href=\"https://towardsdatascience.com/multi-class-text-classification-with-doc2vec-logistic-regression-9da9947b43f4\" rel=\"nofollow noreferrer\">https://towardsdatascience.com/multi-class-text-classification-with-doc2vec-logistic-regression-9da9947b43f4</a></p>\n<p>I think, and have done similar problem too, that this problem can be solved in this way:<br>\n1. Generate NGrams<br>\n2. Create 1 hot encoding matrix<br>\n3. Pass to Naive Bayes or Random forest</p>\n\n<p>It would automatically count the words count (you can apply TFIDF too) and based on that weightage will be calculated.<br>\nExamples: </p>\n\n<ul>\n<li><a href=\"https://medium.com/data-from-the-trenches/text-classification-the-first-step-toward-nlp-mastery-f5f95d525d73\" rel=\"nofollow noreferrer\">https://medium.com/data-from-the-trenches/text-classification-the-first-step-toward-nlp-mastery-f5f95d525d73</a></li>\n<li><a href=\"https://www.ritchieng.com/machine-learning-multinomial-naive-bayes-vectorization/\" rel=\"nofollow noreferrer\">https://www.ritchieng.com/machine-learning-multinomial-naive-bayes-vectorization/</a></li>\n<li>This is detailed one:\n<a href=\"https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/\" rel=\"nofollow noreferrer\">https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/</a></li>\n</ul>\n<p>You can also try <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\" rel=\"nofollow noreferrer\">Tfidf</a> Vectorizer from Sklearn which would be helpful in your case, As Tfidf vectorization inherently is able to learn and differentiate between the frequently occurring words and rarely occurring words by calculating the product of term frequency and inverse document frequency. Check <a href=\"https://en.wikipedia.org/wiki/Tf%E2%80%93idf\" rel=\"nofollow noreferrer\">here</a> for more details. On top of this featurization, You can try Naive Bayes as it's pretty fast and seems to work well for text data as it uses with conditional probabilities. Use performance metrics such as confusion matrix to get a better sense of what is happening as accuracy is not a good measure when your data is imbalance. Hope it helps</p>\n<p>If you have enough data and reasonable number of classes, you can definitely train your model. The grouping of words that you have done is similar to an approach called bag-of-words model. You can use that to build a classifier using Naive Bayes or SVM etc. \nOn a different note, you can also look at the KNN algorithm because it looks fit for your use case. You can have a look at <a href=\"https://ac.els-cdn.com/S1877705814003750/1-s2.0-S1877705814003750-main.pdf?_tid=91daeabf-59c2-43b7-92d7-ee279d97460c&amp;acdnat=1552500809_0f7d8383d7a176153137d906c096c1e9\" rel=\"nofollow noreferrer\">this</a> paper</p>\n<p>The steps are the following:</p>\n\n<ol>\n<li><strong>Prepare your dataset</strong>. Put everything in a dataframe. Divide it in train and test (or even train, cv and test). Use of the order of 10k samples for the test set, or 10-20%, whatever is smaller. Consider using <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html</a></li>\n<li><strong>Encode your input.</strong> You can convert the input, which is a string, to a bag of words, or to a TFIDF. Consider using <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html</a>.</li>\n<li><strong>Instantiate and train your model</strong>. You can use for example a simple logistic regression model, for example <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</a>.</li>\n<li><strong>Test the performance of the model.</strong> Use the test set to understand how well your model is doing. You can use for example the accuracy (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html</a>) or the precision and recall for each class (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html</a> and <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html</a>). Understand well what they mean (<a href=\"https://en.wikipedia.org/wiki/Precision_and_recall\" rel=\"nofollow noreferrer\">https://en.wikipedia.org/wiki/Precision_and_recall</a>).</li>\n</ol>\n\n<p>Your pseudocode should be something like:</p>\n\n<pre><code>-&gt; Divide train and test set. Output: X_train, y_train, X_test, y_test\n-&gt; Instantiate tfidf and the desired model (e.g. logistic regression).\n-&gt; Fit tfidf with X_train (e.g. use .fit_transform) and get the X_train_transformed\n-&gt; Fit the model (e.g. using .fit) with X_train_transformed and y_train\n-&gt; Use X_test to get a prediction y_pred of the model (first pass it through tfidf and then through the model object, e.g. using .predict)\n-&gt; Use y_pred and y_test to get some metrics to understand the performance of the model.\n</code></pre>\n\n<p>Hope this works for you.</p>\n",
                "codes": [
                    [],
                    [],
                    [],
                    [],
                    [
                        "-> Divide train and test set. Output: X_train, y_train, X_test, y_test\n-> Instantiate tfidf and the desired model (e.g. logistic regression).\n-> Fit tfidf with X_train (e.g. use .fit_transform) and get the X_train_transformed\n-> Fit the model (e.g. using .fit) with X_train_transformed and y_train\n-> Use X_test to get a prediction y_pred of the model (first pass it through tfidf and then through the model object, e.g. using .predict)\n-> Use y_pred and y_test to get some metrics to understand the performance of the model.\n"
                    ]
                ],
                "question_id:": "46483",
                "question_votes:": "5",
                "question_text:": "<p>I am a beginner with machine learning, and I'm trying to build a model to classify products by category according to the words present in the product name.\nMy goal is to predict the category of some new product, just by observing the categories for existing products.<br>\nFor example, having the following products:</p>\n\n<pre><code>PRODUCT                                     CATEGORY\nsoap bar johnsons green leaves              bath\ncookie bauducco lemon 120gr                 cookie\nnesfit cookie choc and st                   cookie\nstrawberry soap soft                        bath\nspoon hercules medium                       kitchen\nsoap dish plastic medium                    bath\n[...]\n</code></pre>\n\n<p>My first thought is to group the words (tokens) present in each product, indicating the designated category and the occurrences count (to be used as a weight). So, for this sample, I have:</p>\n\n<pre><code>WORD           CATEGORY         COUNT\nsoap           bath             3\ncookie         cookie           2\nmedium         bath             1\nmedium         kitchen          1\nbar            bath             1\njohnsons       bath             1\n</code></pre>\n\n<p>Having this, I could be able to train a model, and use it to classify a new product. </p>\n\n<p>For example, having a new product <code>hands liquid soap 120oz</code>, it could be classified as <code>bath</code>, because it contains the word <code>soap</code>, which have a strong weight for the <code>bath</code> category.  </p>\n\n<p>In other case, the new product <code>medium hammer</code> could be classified as <code>bath</code> or <code>kitchen</code> , according the occurrence of the word <code>medium</code> in the training set.</p>\n\n<p>So, my doubts are: </p>\n\n<ul>\n<li>Am I going to the correct approach?</li>\n<li>What is the best algorithm to be used in this case?</li>\n<li>How can I apply this using Weka?</li>\n</ul>\n",
                "tags": "<classification><multiclass-classification>",
                "answers": [
                    [
                        "47332",
                        "2",
                        "46483",
                        "",
                        "",
                        "<p>This should be doable with pre-trained word vectors + document/sentence vectors.  Tutorial : <a href=\"https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e\" rel=\"nofollow noreferrer\">https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e</a></p>\n\n<p><a href=\"https://i.stack.imgur.com/KVB2l.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/KVB2l.png\" alt=\"enter image description here\"></a></p>\n\n<p>All Product labels with \"similar meanings\" should cluster in a short distance. </p>\n\n<p>After product name ha been transformed into a vector, vector can be fed into a logistic regression classifier (Or a shallow neural network). </p>\n\n<p>Tutorial : <a href=\"https://towardsdatascience.com/multi-class-text-classification-with-doc2vec-logistic-regression-9da9947b43f4\" rel=\"nofollow noreferrer\">https://towardsdatascience.com/multi-class-text-classification-with-doc2vec-logistic-regression-9da9947b43f4</a></p>\n",
                        "",
                        "2"
                    ],
                    [
                        "47398",
                        "2",
                        "46483",
                        "",
                        "",
                        "<p>I think, and have done similar problem too, that this problem can be solved in this way:<br>\n1. Generate NGrams<br>\n2. Create 1 hot encoding matrix<br>\n3. Pass to Naive Bayes or Random forest</p>\n\n<p>It would automatically count the words count (you can apply TFIDF too) and based on that weightage will be calculated.<br>\nExamples: </p>\n\n<ul>\n<li><a href=\"https://medium.com/data-from-the-trenches/text-classification-the-first-step-toward-nlp-mastery-f5f95d525d73\" rel=\"nofollow noreferrer\">https://medium.com/data-from-the-trenches/text-classification-the-first-step-toward-nlp-mastery-f5f95d525d73</a></li>\n<li><a href=\"https://www.ritchieng.com/machine-learning-multinomial-naive-bayes-vectorization/\" rel=\"nofollow noreferrer\">https://www.ritchieng.com/machine-learning-multinomial-naive-bayes-vectorization/</a></li>\n<li>This is detailed one:\n<a href=\"https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/\" rel=\"nofollow noreferrer\">https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/</a></li>\n</ul>\n",
                        "",
                        "4"
                    ],
                    [
                        "47325",
                        "2",
                        "46483",
                        "",
                        "",
                        "<p>You can also try <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\" rel=\"nofollow noreferrer\">Tfidf</a> Vectorizer from Sklearn which would be helpful in your case, As Tfidf vectorization inherently is able to learn and differentiate between the frequently occurring words and rarely occurring words by calculating the product of term frequency and inverse document frequency. Check <a href=\"https://en.wikipedia.org/wiki/Tf%E2%80%93idf\" rel=\"nofollow noreferrer\">here</a> for more details. On top of this featurization, You can try Naive Bayes as it's pretty fast and seems to work well for text data as it uses with conditional probabilities. Use performance metrics such as confusion matrix to get a better sense of what is happening as accuracy is not a good measure when your data is imbalance. Hope it helps</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "47256",
                        "2",
                        "46483",
                        "",
                        "",
                        "<p>If you have enough data and reasonable number of classes, you can definitely train your model. The grouping of words that you have done is similar to an approach called bag-of-words model. You can use that to build a classifier using Naive Bayes or SVM etc. \nOn a different note, you can also look at the KNN algorithm because it looks fit for your use case. You can have a look at <a href=\"https://ac.els-cdn.com/S1877705814003750/1-s2.0-S1877705814003750-main.pdf?_tid=91daeabf-59c2-43b7-92d7-ee279d97460c&amp;acdnat=1552500809_0f7d8383d7a176153137d906c096c1e9\" rel=\"nofollow noreferrer\">this</a> paper</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "47505",
                        "2",
                        "46483",
                        "",
                        "",
                        "<p>The steps are the following:</p>\n\n<ol>\n<li><strong>Prepare your dataset</strong>. Put everything in a dataframe. Divide it in train and test (or even train, cv and test). Use of the order of 10k samples for the test set, or 10-20%, whatever is smaller. Consider using <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html</a></li>\n<li><strong>Encode your input.</strong> You can convert the input, which is a string, to a bag of words, or to a TFIDF. Consider using <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html</a>.</li>\n<li><strong>Instantiate and train your model</strong>. You can use for example a simple logistic regression model, for example <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</a>.</li>\n<li><strong>Test the performance of the model.</strong> Use the test set to understand how well your model is doing. You can use for example the accuracy (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html</a>) or the precision and recall for each class (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html</a> and <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html</a>). Understand well what they mean (<a href=\"https://en.wikipedia.org/wiki/Precision_and_recall\" rel=\"nofollow noreferrer\">https://en.wikipedia.org/wiki/Precision_and_recall</a>).</li>\n</ol>\n\n<p>Your pseudocode should be something like:</p>\n\n<pre><code>-&gt; Divide train and test set. Output: X_train, y_train, X_test, y_test\n-&gt; Instantiate tfidf and the desired model (e.g. logistic regression).\n-&gt; Fit tfidf with X_train (e.g. use .fit_transform) and get the X_train_transformed\n-&gt; Fit the model (e.g. using .fit) with X_train_transformed and y_train\n-&gt; Use X_test to get a prediction y_pred of the model (first pass it through tfidf and then through the model object, e.g. using .predict)\n-&gt; Use y_pred and y_test to get some metrics to understand the performance of the model.\n</code></pre>\n\n<p>Hope this works for you.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5999",
            "_score": 11.593146,
            "_source": {
                "title": "Time Series forecasting model",
                "content": "Time Series forecasting model <p>I have time series dataset with 7 categorical features (Names) and each of them has 3-5 numerical features (results of activities of each person) for the period 1996-2017 by months. \nIs it possible to create a model that will be forecasting \"Y\" on the base of values for selected Names.\nFor example: John + Jack = Y? in 2017-02-01.</p>\n\n<p>Example of the dataset:\n<a href=\"https://i.stack.imgur.com/5AfxS.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/5AfxS.jpg\" alt=\"enter image description here\"></a></p>\n <machine-learning><python><time-series><p>Yes, you certainly can. You have to convert all your categorical variables into one numbers. This means, names in your <code>Name</code> and <code>Name2</code> columns can be converted using <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" rel=\"nofollow noreferrer\">one-hot encoder</a>.  </p>\n\n<p>After converting them, you may consider some feature engineering techniques to such dimensionality reduction based on your scenario. </p>\n\n<p>After this, you can use whatever the model is in your mind to solve your problem. Also, please take a peak at this <a href=\"https://stackoverflow.com/questions/34007308/linear-regression-analysis-with-string-categorical-features-variables\">post</a>.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "23639",
                "question_votes:": "",
                "question_text:": "<p>I have time series dataset with 7 categorical features (Names) and each of them has 3-5 numerical features (results of activities of each person) for the period 1996-2017 by months. \nIs it possible to create a model that will be forecasting \"Y\" on the base of values for selected Names.\nFor example: John + Jack = Y? in 2017-02-01.</p>\n\n<p>Example of the dataset:\n<a href=\"https://i.stack.imgur.com/5AfxS.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/5AfxS.jpg\" alt=\"enter image description here\"></a></p>\n",
                "tags": "<machine-learning><python><time-series>",
                "answers": [
                    [
                        "23641",
                        "2",
                        "23639",
                        "",
                        "",
                        "<p>Yes, you certainly can. You have to convert all your categorical variables into one numbers. This means, names in your <code>Name</code> and <code>Name2</code> columns can be converted using <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" rel=\"nofollow noreferrer\">one-hot encoder</a>.  </p>\n\n<p>After converting them, you may consider some feature engineering techniques to such dimensionality reduction based on your scenario. </p>\n\n<p>After this, you can use whatever the model is in your mind to solve your problem. Also, please take a peak at this <a href=\"https://stackoverflow.com/questions/34007308/linear-regression-analysis-with-string-categorical-features-variables\">post</a>.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "18395",
            "_score": 11.581194,
            "_source": {
                "title": "Scikit-compatible network lasso implementation",
                "content": "Scikit-compatible network lasso implementation <p>Is anyone aware of a scikit-compatible network Lasso (nLasso) implementation? </p>\n\n<p>These papers have source code as well:</p>\n\n<blockquote>\n  <p><a href=\"https://web.stanford.edu/~boyd/papers/pdf/network_lasso.pdf\" rel=\"nofollow noreferrer\">D. Hallac, J. Leskovec, and S. Boyd, \u201cNetwork lasso: Clustering and optimization in large graphs,\u201d in Proc. SIGKDD, 2015, pp. 387\u2013396.</a></p>\n</blockquote>\n\n<p>Code: <a href=\"https://riken-yamada.github.io/localizedlasso.html\" rel=\"nofollow noreferrer\">https://riken-yamada.github.io/localizedlasso.html</a></p>\n\n<blockquote>\n  <p><a href=\"http://proceedings.mlr.press/v54/yamada17a/yamada17a.pdf\" rel=\"nofollow noreferrer\">[2] M.Yamada, T. Koh, T. Iwata, J. Shawe-Taylor, and S. Kaski, \u201cLocalized Lasso for High-Dimensional Regression,\u201d in Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, vol. 54. Fort Lauderdale, FL, USA: PMLR, Apr. 2017, pp. 325\u2013333.</a></p>\n</blockquote>\n\n<p>Code: <a href=\"https://github.com/davidhallac/NetworkLasso\" rel=\"nofollow noreferrer\">https://github.com/davidhallac/NetworkLasso</a></p>\n\n<p>But these particular implementations are not very general and can't be used as a part of the pipelines. </p>\n\n<p>I would like to use nLasso to do something like this (the example picked from <a href=\"https://scikit-learn.org/stable/auto_examples/feature_selection/plot_select_from_model_boston.html#sphx-glr-auto-examples-feature-selection-plot-select-from-model-boston-py\" rel=\"nofollow noreferrer\">the scikit tutorial</a>):</p>\n\n<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.datasets import load_boston\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LassoCV\n\n# Load the boston dataset.\nboston = load_boston()\nX, y = boston['data'], boston['target']\n\n# We use the base estimator LassoCV since the L1 norm promotes sparsity of features.\nclf = LassoCV(cv=5)\n\n# Set a minimum threshold of 0.25\nsfm = SelectFromModel(clf, threshold=0.25)\nsfm.fit(X, y)\nn_features = sfm.transform(X).shape[1]\n</code></pre>\n <scikit-learn><feature-selection><lasso>",
                "codes": [],
                "question_id:": "58265",
                "question_votes:": "1",
                "question_text:": "<p>Is anyone aware of a scikit-compatible network Lasso (nLasso) implementation? </p>\n\n<p>These papers have source code as well:</p>\n\n<blockquote>\n  <p><a href=\"https://web.stanford.edu/~boyd/papers/pdf/network_lasso.pdf\" rel=\"nofollow noreferrer\">D. Hallac, J. Leskovec, and S. Boyd, \u201cNetwork lasso: Clustering and optimization in large graphs,\u201d in Proc. SIGKDD, 2015, pp. 387\u2013396.</a></p>\n</blockquote>\n\n<p>Code: <a href=\"https://riken-yamada.github.io/localizedlasso.html\" rel=\"nofollow noreferrer\">https://riken-yamada.github.io/localizedlasso.html</a></p>\n\n<blockquote>\n  <p><a href=\"http://proceedings.mlr.press/v54/yamada17a/yamada17a.pdf\" rel=\"nofollow noreferrer\">[2] M.Yamada, T. Koh, T. Iwata, J. Shawe-Taylor, and S. Kaski, \u201cLocalized Lasso for High-Dimensional Regression,\u201d in Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, vol. 54. Fort Lauderdale, FL, USA: PMLR, Apr. 2017, pp. 325\u2013333.</a></p>\n</blockquote>\n\n<p>Code: <a href=\"https://github.com/davidhallac/NetworkLasso\" rel=\"nofollow noreferrer\">https://github.com/davidhallac/NetworkLasso</a></p>\n\n<p>But these particular implementations are not very general and can't be used as a part of the pipelines. </p>\n\n<p>I would like to use nLasso to do something like this (the example picked from <a href=\"https://scikit-learn.org/stable/auto_examples/feature_selection/plot_select_from_model_boston.html#sphx-glr-auto-examples-feature-selection-plot-select-from-model-boston-py\" rel=\"nofollow noreferrer\">the scikit tutorial</a>):</p>\n\n<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.datasets import load_boston\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LassoCV\n\n# Load the boston dataset.\nboston = load_boston()\nX, y = boston['data'], boston['target']\n\n# We use the base estimator LassoCV since the L1 norm promotes sparsity of features.\nclf = LassoCV(cv=5)\n\n# Set a minimum threshold of 0.25\nsfm = SelectFromModel(clf, threshold=0.25)\nsfm.fit(X, y)\nn_features = sfm.transform(X).shape[1]\n</code></pre>\n",
                "tags": "<scikit-learn><feature-selection><lasso>",
                "answers": []
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9845",
            "_score": 11.563343,
            "_source": {
                "title": "Best ML model for predicting yearly data with many blocks?",
                "content": "Best ML model for predicting yearly data with many blocks? <p>I would like to forewarn by saying I am by no means an expert in this topic and I apologize if I mix terminology, phrased the question wrong, or any information is incorrect. </p>\n\n<p>I would like to use a machine learning model for the current dataset that I have gathered. The dataset has about 8000 blocks (or entities), and each of these blocks has 7 features. Each feature has around 10 yearly values, which are counts (ex: 2005=1, 2006=2 ... 2014=0, 2015=3). The long stretch goal would be able to predict the 11th, and even 12th, yearly value for each feature. </p>\n\n<p>I would really love to apply machine learning to this dataset. I've looked into the following because they seem to be the best solution to my problem: linear regression models, LSTM neural networks, and time series forecasting, although I am still unsure of how my dataset can fit into these certain models.</p>\n\n<p>Please let me know if I can offer any more information!</p>\n <machine-learning><time-series><statistics><data><lstm><p>This sounds like a job for a Recurrent Neural Network. I must be honest I have yet to fully dive into them but the idea is it has connections pointing backwards which it feeds to itself. It is often used for stock predictions and time series related problems. There is a entire section dedicated to it in O'Reillys \"Hands on Machine Learning with SKlearn and Tensorflow\". I highly recommend it. Great tool to have. Good luck.</p>\n<p>Your data consists of time series. Recurrent neural networks, RNNs, are applied successfully to problems like this data. Its structure is appropriate for you. Especially, you can use LSTM which is very powerful for time series data. Also there are a lot of papers in arxiv about its capabilities, pros and cons.</p>\n\n<p>I think, linear regression can fail for your task.</p>\n\n<p>I suggest you to read <a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\" rel=\"nofollow noreferrer\">this</a> and <a href=\"https://towardsdatascience.com/recurrent-neural-networks-and-lstm-4b601dd822a5\" rel=\"nofollow noreferrer\">this</a> articles to understand how LSTM works and what you can do with it. Then you can decide is it appropriate for your problem or not.</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "35883",
                "question_votes:": "",
                "question_text:": "<p>I would like to forewarn by saying I am by no means an expert in this topic and I apologize if I mix terminology, phrased the question wrong, or any information is incorrect. </p>\n\n<p>I would like to use a machine learning model for the current dataset that I have gathered. The dataset has about 8000 blocks (or entities), and each of these blocks has 7 features. Each feature has around 10 yearly values, which are counts (ex: 2005=1, 2006=2 ... 2014=0, 2015=3). The long stretch goal would be able to predict the 11th, and even 12th, yearly value for each feature. </p>\n\n<p>I would really love to apply machine learning to this dataset. I've looked into the following because they seem to be the best solution to my problem: linear regression models, LSTM neural networks, and time series forecasting, although I am still unsure of how my dataset can fit into these certain models.</p>\n\n<p>Please let me know if I can offer any more information!</p>\n",
                "tags": "<machine-learning><time-series><statistics><data><lstm>",
                "answers": [
                    [
                        "35891",
                        "2",
                        "35883",
                        "",
                        "",
                        "<p>This sounds like a job for a Recurrent Neural Network. I must be honest I have yet to fully dive into them but the idea is it has connections pointing backwards which it feeds to itself. It is often used for stock predictions and time series related problems. There is a entire section dedicated to it in O'Reillys \"Hands on Machine Learning with SKlearn and Tensorflow\". I highly recommend it. Great tool to have. Good luck.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "38596",
                        "2",
                        "35883",
                        "",
                        "",
                        "<p>Your data consists of time series. Recurrent neural networks, RNNs, are applied successfully to problems like this data. Its structure is appropriate for you. Especially, you can use LSTM which is very powerful for time series data. Also there are a lot of papers in arxiv about its capabilities, pros and cons.</p>\n\n<p>I think, linear regression can fail for your task.</p>\n\n<p>I suggest you to read <a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\" rel=\"nofollow noreferrer\">this</a> and <a href=\"https://towardsdatascience.com/recurrent-neural-networks-and-lstm-4b601dd822a5\" rel=\"nofollow noreferrer\">this</a> articles to understand how LSTM works and what you can do with it. Then you can decide is it appropriate for your problem or not.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10557",
            "_score": 11.563259,
            "_source": {
                "title": "bad regression performance on imbalanced dataset",
                "content": "bad regression performance on imbalanced dataset <p>My current dataset has a shape of 5300 rows by 160 columns with a numeric target variable range=[641, 3001].<br>\n<a href=\"https://i.stack.imgur.com/n5gYk.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/n5gYk.png\" alt=\"distribution of y_true\"></a><br>\nThat\u2019s no big dataset, but should in general be enough for decent regression quality. The columns are features from different consecutive process steps. </p>\n\n<p>The project goal is to predict the numerical variable, with the satisfactory object to be very precise in the area up too 1200, which are 115 rows (2,1%). For target variables above 1200 the precision can be lower than in the area [640, 1200]. The target-variable is normally distributed with its mean ~1780 (25%: 1620, 75%: 1950) and variance of 267.5.</p>\n\n<p>prediction vs actual:<br>\n<a href=\"https://i.stack.imgur.com/9mONF.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/9mONF.png\" alt=\"prediction vs actual\"></a><br>\nresidual plot:<br>\n<a href=\"https://i.stack.imgur.com/Qhhci.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Qhhci.png\" alt=\"residual-plot\"></a><br>\nMy problem is (see plots above), that no matter what I try, the range of predictions (y_hat) is very limited and rather random (Training RMSE ~300, Test RMSE ~450), best test-mean-abs-error for y-values &lt;= 1200  ~= 120.</p>\n\n<p>I\u2019ve already tried:</p>\n\n<ul>\n<li>feature cleaning</li>\n<li>process step wise addition of features to compare model performance/information gain</li>\n<li>feature generation </li>\n<li>derive new features (by business logic)</li>\n<li>generate features\n\n<ul>\n<li>cross-product of features</li>\n<li>differences to previous rows</li>\n<li>differences between features</li>\n<li>differences per feature to mean</li>\n<li>durations based on timestamps</li>\n</ul></li>\n<li>normalizing, scaling</li>\n<li>log-transformation of target variable</li>\n<li>Over- &amp;/ Under-Sampling</li>\n<li>various algorithms (using GridSearchCV for hyper-parameter tuning):</li>\n<li>sklearn [SVR, RandomForrestRegressor, LinearRegression, Lasso, ElasticNet]</li>\n<li>xgboost</li>\n<li>(mxnet.gluon.Dense)</li>\n</ul>\n\n<p>What would be your approach? Do you have any advice what technique I could try or what I've probably missed? Or if it's more likely that the training data simply doesn't fit well on the target variable?</p>\n <regression><supervised-learning><performance><class-imbalance><p>Your residuals are huge, which is not surprising, given that your data is very variable, a linear model may not be the best choice for this task. You could try transforming your data (log, sqrt) depending on the nature of your data to reduce the variability, but as I said, your variability is huge.</p>\n\n<p>Alternatively you could try modeling the variance with a mixed model if it makes sense for your data, given some additional knowledge of some variable.</p>\n\n<p>Other then that you could try a different algorithm for this task.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "37823",
                "question_votes:": "1",
                "question_text:": "<p>My current dataset has a shape of 5300 rows by 160 columns with a numeric target variable range=[641, 3001].<br>\n<a href=\"https://i.stack.imgur.com/n5gYk.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/n5gYk.png\" alt=\"distribution of y_true\"></a><br>\nThat\u2019s no big dataset, but should in general be enough for decent regression quality. The columns are features from different consecutive process steps. </p>\n\n<p>The project goal is to predict the numerical variable, with the satisfactory object to be very precise in the area up too 1200, which are 115 rows (2,1%). For target variables above 1200 the precision can be lower than in the area [640, 1200]. The target-variable is normally distributed with its mean ~1780 (25%: 1620, 75%: 1950) and variance of 267.5.</p>\n\n<p>prediction vs actual:<br>\n<a href=\"https://i.stack.imgur.com/9mONF.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/9mONF.png\" alt=\"prediction vs actual\"></a><br>\nresidual plot:<br>\n<a href=\"https://i.stack.imgur.com/Qhhci.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Qhhci.png\" alt=\"residual-plot\"></a><br>\nMy problem is (see plots above), that no matter what I try, the range of predictions (y_hat) is very limited and rather random (Training RMSE ~300, Test RMSE ~450), best test-mean-abs-error for y-values &lt;= 1200  ~= 120.</p>\n\n<p>I\u2019ve already tried:</p>\n\n<ul>\n<li>feature cleaning</li>\n<li>process step wise addition of features to compare model performance/information gain</li>\n<li>feature generation </li>\n<li>derive new features (by business logic)</li>\n<li>generate features\n\n<ul>\n<li>cross-product of features</li>\n<li>differences to previous rows</li>\n<li>differences between features</li>\n<li>differences per feature to mean</li>\n<li>durations based on timestamps</li>\n</ul></li>\n<li>normalizing, scaling</li>\n<li>log-transformation of target variable</li>\n<li>Over- &amp;/ Under-Sampling</li>\n<li>various algorithms (using GridSearchCV for hyper-parameter tuning):</li>\n<li>sklearn [SVR, RandomForrestRegressor, LinearRegression, Lasso, ElasticNet]</li>\n<li>xgboost</li>\n<li>(mxnet.gluon.Dense)</li>\n</ul>\n\n<p>What would be your approach? Do you have any advice what technique I could try or what I've probably missed? Or if it's more likely that the training data simply doesn't fit well on the target variable?</p>\n",
                "tags": "<regression><supervised-learning><performance><class-imbalance>",
                "answers": [
                    [
                        "38249",
                        "2",
                        "37823",
                        "",
                        "",
                        "<p>Your residuals are huge, which is not surprising, given that your data is very variable, a linear model may not be the best choice for this task. You could try transforming your data (log, sqrt) depending on the nature of your data to reduce the variability, but as I said, your variability is huge.</p>\n\n<p>Alternatively you could try modeling the variance with a mixed model if it makes sense for your data, given some additional knowledge of some variable.</p>\n\n<p>Other then that you could try a different algorithm for this task.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10514",
            "_score": 11.502236,
            "_source": {
                "title": "Confusion Matrixs for Binary classifier",
                "content": "Confusion Matrixs for Binary classifier <p>I am new to modeling, and I am practicing building a logistic regression model. I would like to create a confusion matrix, but my code doesn't seem to work.</p>\n\n<p>Here is the code for the model (which works):</p>\n\n<pre><code>from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\n#train, test = train_test_split(hp[age], test_size=0.3)\n\n#from sklearn import preprocessing\nX = hp['age'].values.reshape((32561,1))\n#X = hp[['age','hours-per-week']].values\ny = hp['evalinvest'].values\n\nLogReg = LogisticRegression()\nLogReg.fit(X,y)\nprint(LogReg.score(X,y))\n\n0.916710174749\n</code></pre>\n\n<p>Here is where I am having diffculty:</p>\n\n<pre><code># Confusion Matrix\nimport numpy as np\nfrom sklearn.metrics import *\nCM = confusion_matrix(X,y)\nprint (\"\\n\\nConfusion matrix:\\n\", CM)\n</code></pre>\n\n<hr>\n\n<p>It runs and outputs results, but I don't feel like it is correct.</p>\n\n<p>Confusion matrix:</p>\n\n<pre><code> [[  0   0   0 ...,   0   0   0]\n [  0   0   0 ...,   0   0   0]\n [385  10   0 ...,   0   0   0]\n ..., \n [  1   0   0 ...,   0   0   0]\n [  3   0   0 ...,   0   0   0]\n [ 33  10   0 ...,   0   0   0]]\n</code></pre>\n\n<p>Then, when I run the following code, it doesn't work:</p>\n\n<pre><code>tn, fp, fn, tp = CM.ravel()\nprint (\"\\nTP, TN, FP, FN:\", tp, \",\", tn, \",\", fp, \",\", fn)\n</code></pre>\n\n<p>error:</p>\n\n<pre><code>---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-68-dca3ebbdc69a&gt; in &lt;module&gt;()\n----&gt; 1 tn, fp, fn, tp = CM.ravel()\n      2 print (\"\\nTP, TN, FP, FN:\", tp, \",\", tn, \",\", fp, \",\", fn)\n\nValueError: too many values to unpack (expected 4)\n</code></pre>\n <classification><logistic-regression><confusion-matrix><p>I think you are confused on many levels here.</p>\n\n<ul>\n<li>Logistic regression is a classifier. It gives you the probability that given an $x_{i}$, the probability it belongs to a class or classes.</li>\n<li>So you will be having your <code>evalinvest</code> as classes, not continuous values.</li>\n<li>When you call <code>predict</code> method on top of trained <code>LogisticRegression</code> model, it predicts class for each $x_{i}$ in your test set. So you expect a single array of class labels they belong to.</li>\n<li><code>sklearn.metrics.confusion_matrix</code> function takes in the original class values to the ones that are predicted by the model you had trained and returns what $x_{i}$ has been classified into what class. So it returns an <code>n(c) x n(c)</code> array where <code>n(c)</code> is the number of classes. So the diagonal of the matrix indicates the number of elements of class <code>i</code> being classified as class <code>i</code>. And an ideal model should be expected to get this numbers good. The mistake which you had made you sent in your <code>X</code> (train) matrix into it and <code>y</code> (labels) into it, which is wrong. You are supposed to send in <code>y_true</code>(true labels) and <code>y_pred</code> (predicted labels from the model). Check the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\" rel=\"nofollow noreferrer\">documentation</a> for more.</li>\n<li>Ideally the function should have thrown an error. But unfortunately you had only one row in your <code>X</code> and one in <code>y</code> and they both are of same size and it passed <code>assert</code> it had to make.</li>\n<li>And <code>np.ravel</code> converts an multi-dimensional array into <code>1D</code> array. So if you doing a binary classification, you would be having a <code>2x2</code> matrix, whose flattened array would have been four elements and the assignment would have worked. But the ravelling you had made releases $n(c)^2$ elements. So there you go <code>ValueError</code>. See the <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.ravel.html\" rel=\"nofollow noreferrer\">docs</a></li>\n</ul>\n\n<p>I hope my other <a href=\"https://datascience.stackexchange.com/questions/27132/decision-tree-used-for-calculating-precision-accuracy-and-recall-class-breakd/27137#27137\">answer</a> on confusion matrices may clear things a little more.</p>\n\n<p>Hope it clears some mistakes you are making.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "37687",
                "question_votes:": "",
                "question_text:": "<p>I am new to modeling, and I am practicing building a logistic regression model. I would like to create a confusion matrix, but my code doesn't seem to work.</p>\n\n<p>Here is the code for the model (which works):</p>\n\n<pre><code>from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\n#train, test = train_test_split(hp[age], test_size=0.3)\n\n#from sklearn import preprocessing\nX = hp['age'].values.reshape((32561,1))\n#X = hp[['age','hours-per-week']].values\ny = hp['evalinvest'].values\n\nLogReg = LogisticRegression()\nLogReg.fit(X,y)\nprint(LogReg.score(X,y))\n\n0.916710174749\n</code></pre>\n\n<p>Here is where I am having diffculty:</p>\n\n<pre><code># Confusion Matrix\nimport numpy as np\nfrom sklearn.metrics import *\nCM = confusion_matrix(X,y)\nprint (\"\\n\\nConfusion matrix:\\n\", CM)\n</code></pre>\n\n<hr>\n\n<p>It runs and outputs results, but I don't feel like it is correct.</p>\n\n<p>Confusion matrix:</p>\n\n<pre><code> [[  0   0   0 ...,   0   0   0]\n [  0   0   0 ...,   0   0   0]\n [385  10   0 ...,   0   0   0]\n ..., \n [  1   0   0 ...,   0   0   0]\n [  3   0   0 ...,   0   0   0]\n [ 33  10   0 ...,   0   0   0]]\n</code></pre>\n\n<p>Then, when I run the following code, it doesn't work:</p>\n\n<pre><code>tn, fp, fn, tp = CM.ravel()\nprint (\"\\nTP, TN, FP, FN:\", tp, \",\", tn, \",\", fp, \",\", fn)\n</code></pre>\n\n<p>error:</p>\n\n<pre><code>---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-68-dca3ebbdc69a&gt; in &lt;module&gt;()\n----&gt; 1 tn, fp, fn, tp = CM.ravel()\n      2 print (\"\\nTP, TN, FP, FN:\", tp, \",\", tn, \",\", fp, \",\", fn)\n\nValueError: too many values to unpack (expected 4)\n</code></pre>\n",
                "tags": "<classification><logistic-regression><confusion-matrix>",
                "answers": [
                    [
                        "37693",
                        "2",
                        "37687",
                        "",
                        "",
                        "<p>I think you are confused on many levels here.</p>\n\n<ul>\n<li>Logistic regression is a classifier. It gives you the probability that given an $x_{i}$, the probability it belongs to a class or classes.</li>\n<li>So you will be having your <code>evalinvest</code> as classes, not continuous values.</li>\n<li>When you call <code>predict</code> method on top of trained <code>LogisticRegression</code> model, it predicts class for each $x_{i}$ in your test set. So you expect a single array of class labels they belong to.</li>\n<li><code>sklearn.metrics.confusion_matrix</code> function takes in the original class values to the ones that are predicted by the model you had trained and returns what $x_{i}$ has been classified into what class. So it returns an <code>n(c) x n(c)</code> array where <code>n(c)</code> is the number of classes. So the diagonal of the matrix indicates the number of elements of class <code>i</code> being classified as class <code>i</code>. And an ideal model should be expected to get this numbers good. The mistake which you had made you sent in your <code>X</code> (train) matrix into it and <code>y</code> (labels) into it, which is wrong. You are supposed to send in <code>y_true</code>(true labels) and <code>y_pred</code> (predicted labels from the model). Check the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\" rel=\"nofollow noreferrer\">documentation</a> for more.</li>\n<li>Ideally the function should have thrown an error. But unfortunately you had only one row in your <code>X</code> and one in <code>y</code> and they both are of same size and it passed <code>assert</code> it had to make.</li>\n<li>And <code>np.ravel</code> converts an multi-dimensional array into <code>1D</code> array. So if you doing a binary classification, you would be having a <code>2x2</code> matrix, whose flattened array would have been four elements and the assignment would have worked. But the ravelling you had made releases $n(c)^2$ elements. So there you go <code>ValueError</code>. See the <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.ravel.html\" rel=\"nofollow noreferrer\">docs</a></li>\n</ul>\n\n<p>I hope my other <a href=\"https://datascience.stackexchange.com/questions/27132/decision-tree-used-for-calculating-precision-accuracy-and-recall-class-breakd/27137#27137\">answer</a> on confusion matrices may clear things a little more.</p>\n\n<p>Hope it clears some mistakes you are making.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "18148",
            "_score": 11.432788,
            "_source": {
                "title": "What regression model can handle tiny amounts of data?",
                "content": "What regression model can handle tiny amounts of data? <p>I'm trying to use machine learning to predict properties of a material during a crash test, but each data point requires physically crashing an expensive toy car, so I can only gather a few hundred data points. The end goal is to use the trained model to figure out how to optimize material strength given the parameters I can tweak in the material, which I'm using as inputs.</p>\n\n<p>What type of model would be able to:</p>\n\n<ol>\n<li><p>Handle very few data points (minimizing number of crashes necessary)</p></li>\n<li><p>Accurately learn a likely very complex relationship between the inputs (design choices) and the output (performance in crash)</p></li>\n<li><p>Be able to then be explored to figure out, in as few crashes as possible, which changes to the inputs should be made to maximize the output</p></li>\n</ol>\n <machine-learning><regression><model-selection><p>The description of your problem is vague. In case you want to do causal analysis, you need to consider the <a href=\"https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff\" rel=\"nofollow noreferrer\">bias-variance-tradeoff</a>. For a causal analysis you would stick to low bias (e.g. using a \"best linear unbiased estimator\" like ordinary least square regression), while most ML models, such as neural nets or boosting, go for low variance. </p>\n\n<p>Still not clear to me: how does your data look like. If you have more features/variables (<span class=\"math-container\">$X$</span>) than observations (<span class=\"math-container\">$i$</span>) your problem is <strong>high dimensional</strong>. For a high dimensional problem, use the <a href=\"https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html\" rel=\"nofollow noreferrer\">Lasso</a>. If <span class=\"math-container\">$i$</span>><span class=\"math-container\">$X$</span> and you have say at least 40+ degrees of freedom, you could simply apply OLS regression. If you (can) use OLS and you care for significance and confidence bands, use robust standard errors (hc2, hc3).</p>\n\n<p>As mentioned above, you will likely have high variance using OLS or Lasso. What you can do to work on that in a causal model, is to make linear transformations of <span class=\"math-container\">$x_i$</span>, e.g. add polynomials, or you can add interactions of two <span class=\"math-container\">$x$</span>, e.g. <span class=\"math-container\">$x_3=x_1 x_2$</span>. </p>\n\n<p>Finally, you could use <a href=\"https://github.com/Bixi81/R-ml/blob/master/GAM_regression_splines.R\" rel=\"nofollow noreferrer\">generalized additive models</a> (e.g. with regression splines) to model \"complexity\" if it originates from non-linearity in <span class=\"math-container\">$X$</span>. However, in this case you go in the direction of decreasing variance (at the cost of probably introducing unwanted bias).</p>\n\n<p>I guess the nature of your problem is of \"high dimension\". This is a little special (and I'm no expert here). Have a look at \"<a href=\"https://web.stanford.edu/~hastie/Papers/ESLII.pdf\" rel=\"nofollow noreferrer\">Elements of Statistical Learning</a>\", Chapter 18. The book gives a really good overview of possible options to deal with this problem.</p>\n<p>As you want to handle very complex relationship between the inputs, model should be strong enough. It seems that neural network would perform better than svm for example. The problem is the number of points in dataset. However, it just means, that you should try to develop appropriate architecture for your task. There are many challenges in wich nn shows good results on small datasets (with a few hundreds of instances). So, I suggest you experiment with architecture. There are two links with examples how to build baseline model <a href=\"https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/\" rel=\"nofollow noreferrer\">https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/</a> (dataset for regression problem)</p>\n\n<p><a href=\"https://janakiev.com/notebooks/keras-iris/\" rel=\"nofollow noreferrer\">https://janakiev.com/notebooks/keras-iris/</a> (iris is a small but easy dataset for classification)</p>\n\n<p>This step is rather easy. Then you can try to change number of layers and neurons, add dropout to prevent overfitting on small dataset. Although it would demand efforts, results could be high.</p>\n\n<p>Other good model, as for me, is gradient boosting. It includes ensemble of trees (GB usually based on trees) and performs good results on small datasets <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html</a> But this model should also be tuned for your problem, regularization techniques will help to reduce overfitting on a small number of examples.</p>\n\n<p><strong>The main message is:</strong> there's not universal algorithm, which works great from scratch with small data and high complexity, but there is a range of tools to make powerful algorithms perform good on small observations (regularization, dropout, depth and number of trees in GB, learning rate). </p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "57766",
                "question_votes:": "2",
                "question_text:": "<p>I'm trying to use machine learning to predict properties of a material during a crash test, but each data point requires physically crashing an expensive toy car, so I can only gather a few hundred data points. The end goal is to use the trained model to figure out how to optimize material strength given the parameters I can tweak in the material, which I'm using as inputs.</p>\n\n<p>What type of model would be able to:</p>\n\n<ol>\n<li><p>Handle very few data points (minimizing number of crashes necessary)</p></li>\n<li><p>Accurately learn a likely very complex relationship between the inputs (design choices) and the output (performance in crash)</p></li>\n<li><p>Be able to then be explored to figure out, in as few crashes as possible, which changes to the inputs should be made to maximize the output</p></li>\n</ol>\n",
                "tags": "<machine-learning><regression><model-selection>",
                "answers": [
                    [
                        "57858",
                        "2",
                        "57766",
                        "",
                        "",
                        "<p>The description of your problem is vague. In case you want to do causal analysis, you need to consider the <a href=\"https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff\" rel=\"nofollow noreferrer\">bias-variance-tradeoff</a>. For a causal analysis you would stick to low bias (e.g. using a \"best linear unbiased estimator\" like ordinary least square regression), while most ML models, such as neural nets or boosting, go for low variance. </p>\n\n<p>Still not clear to me: how does your data look like. If you have more features/variables (<span class=\"math-container\">$X$</span>) than observations (<span class=\"math-container\">$i$</span>) your problem is <strong>high dimensional</strong>. For a high dimensional problem, use the <a href=\"https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html\" rel=\"nofollow noreferrer\">Lasso</a>. If <span class=\"math-container\">$i$</span>><span class=\"math-container\">$X$</span> and you have say at least 40+ degrees of freedom, you could simply apply OLS regression. If you (can) use OLS and you care for significance and confidence bands, use robust standard errors (hc2, hc3).</p>\n\n<p>As mentioned above, you will likely have high variance using OLS or Lasso. What you can do to work on that in a causal model, is to make linear transformations of <span class=\"math-container\">$x_i$</span>, e.g. add polynomials, or you can add interactions of two <span class=\"math-container\">$x$</span>, e.g. <span class=\"math-container\">$x_3=x_1 x_2$</span>. </p>\n\n<p>Finally, you could use <a href=\"https://github.com/Bixi81/R-ml/blob/master/GAM_regression_splines.R\" rel=\"nofollow noreferrer\">generalized additive models</a> (e.g. with regression splines) to model \"complexity\" if it originates from non-linearity in <span class=\"math-container\">$X$</span>. However, in this case you go in the direction of decreasing variance (at the cost of probably introducing unwanted bias).</p>\n\n<p>I guess the nature of your problem is of \"high dimension\". This is a little special (and I'm no expert here). Have a look at \"<a href=\"https://web.stanford.edu/~hastie/Papers/ESLII.pdf\" rel=\"nofollow noreferrer\">Elements of Statistical Learning</a>\", Chapter 18. The book gives a really good overview of possible options to deal with this problem.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "57772",
                        "2",
                        "57766",
                        "",
                        "",
                        "<p>As you want to handle very complex relationship between the inputs, model should be strong enough. It seems that neural network would perform better than svm for example. The problem is the number of points in dataset. However, it just means, that you should try to develop appropriate architecture for your task. There are many challenges in wich nn shows good results on small datasets (with a few hundreds of instances). So, I suggest you experiment with architecture. There are two links with examples how to build baseline model <a href=\"https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/\" rel=\"nofollow noreferrer\">https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/</a> (dataset for regression problem)</p>\n\n<p><a href=\"https://janakiev.com/notebooks/keras-iris/\" rel=\"nofollow noreferrer\">https://janakiev.com/notebooks/keras-iris/</a> (iris is a small but easy dataset for classification)</p>\n\n<p>This step is rather easy. Then you can try to change number of layers and neurons, add dropout to prevent overfitting on small dataset. Although it would demand efforts, results could be high.</p>\n\n<p>Other good model, as for me, is gradient boosting. It includes ensemble of trees (GB usually based on trees) and performs good results on small datasets <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html</a> But this model should also be tuned for your problem, regularization techniques will help to reduce overfitting on a small number of examples.</p>\n\n<p><strong>The main message is:</strong> there's not universal algorithm, which works great from scratch with small data and high complexity, but there is a range of tools to make powerful algorithms perform good on small observations (regularization, dropout, depth and number of trees in GB, learning rate). </p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8600",
            "_score": 11.427869,
            "_source": {
                "title": "Regression Neural Network using tflearn",
                "content": "Regression Neural Network using tflearn <p>I have a script which I wrote using python and tflearn. I created a regression neural network model which takes in chemical analysis of wine as input and predicts a score out of 10.</p>\n\n<p>Dataset: <a href=\"http://archive.ics.uci.edu/ml/datasets/Wine+Quality\" rel=\"nofollow noreferrer\">http://archive.ics.uci.edu/ml/datasets/Wine+Quality</a></p>\n\n<p>The problem I have is that the prediction of my model is very bad. I'm also new to tflearn, I have only coded classification neural networks(twice). So, I'm a complete beginner in coding regression and in using tflearn. </p>\n\n<p>Code:</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nimport tflearn\nfrom tflearn.layers.core import input_data, fully_connected, dropout\nfrom tflearn.layers.estimator import regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n\ndef preprocess():\n\n    data_source_red = 'F:\\Gautam\\...\\winequality-red.csv'\n    data_source_white = 'F:\\Gautam\\...\\winequality-white.csv'\n\n    data_red = pd.read_csv(data_source_red, index_col=False, sep=';')\n    data_white = pd.read_csv(data_source_white, index_col=False, sep=';')\n\n    data = pd.concat([data_red, data_white])\n    data = data.dropna(inplace=False)\n\n    x = data[data.columns[0:11]].values\n\n    y = data[data.columns[11]].values\n\n    sc = StandardScaler()\n    x = sc.fit_transform(x)\n\n    y = np.expand_dims(y, -1)\n\n    x = np.float32(x)\n    y = np.float32(y)\n\n    return (x, y)\n\n\nx, y = preprocess()\n\ntrain_x, test_x, train_y, test_y = train_test_split(x, y, test_size = 0.2)\n\nnetwork = input_data(shape=[None, 11], name='Input_layer')\n\nnetwork = fully_connected(network, 5, activation='relu', name='Hidden_layer_1')\n\nnetwork = fully_connected(network, 1, activation='linear', name='Output_layer')\n\nnetwork = regression(network, batch_size=64, optimizer='sgd', learning_rate=0.2, loss='mean_square', metric='R2')\n\nmodel = tflearn.DNN(network)\n\nmodel.fit(train_x, train_y, show_metric=True, run_id='wine_regression', validation_set=0.1, n_epoch=10)\n\nresult = model.evaluate(test_x, test_y)\nprint('Accuracy is %0.2f%%' % (result[0] * 100))\n\npred_y = model.predict(test_x)\n\nplt.plot(test_y, color = 'red', label = 'Real data')\nplt.plot(pred_y, color = 'blue', label = 'Predicted data')\nplt.title('Prediction')\nplt.legend()\nplt.show()\n</code></pre>\n\n<p>Again, the prediction is very bad. Also, the loss and R2 values go hectic. Sometimes, the loss is low(6.45) and sometimes very high(23445.45). The same goes for R2 value too. Sometimes, R2 value goes above 1.0</p>\n\n<p>Even if the loss is minimum(0.1) and R2 as 0.95, the graph shows that the actual value varies lot from the predicted values.</p>\n\n<p>What mistake am I doing? Why is my prediction very bad? And why are the values R2 and loss too high sometimes and too low sometimes?</p>\n\n<p>Am I missing something here? This is my first regression neural network, so I don't know much about this. I hope that my question is clear. Thanks.</p>\n <machine-learning><neural-network><deep-learning><regression><tflearn>",
                "codes": [],
                "question_id:": "31333",
                "question_votes:": "2",
                "question_text:": "<p>I have a script which I wrote using python and tflearn. I created a regression neural network model which takes in chemical analysis of wine as input and predicts a score out of 10.</p>\n\n<p>Dataset: <a href=\"http://archive.ics.uci.edu/ml/datasets/Wine+Quality\" rel=\"nofollow noreferrer\">http://archive.ics.uci.edu/ml/datasets/Wine+Quality</a></p>\n\n<p>The problem I have is that the prediction of my model is very bad. I'm also new to tflearn, I have only coded classification neural networks(twice). So, I'm a complete beginner in coding regression and in using tflearn. </p>\n\n<p>Code:</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nimport tflearn\nfrom tflearn.layers.core import input_data, fully_connected, dropout\nfrom tflearn.layers.estimator import regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n\ndef preprocess():\n\n    data_source_red = 'F:\\Gautam\\...\\winequality-red.csv'\n    data_source_white = 'F:\\Gautam\\...\\winequality-white.csv'\n\n    data_red = pd.read_csv(data_source_red, index_col=False, sep=';')\n    data_white = pd.read_csv(data_source_white, index_col=False, sep=';')\n\n    data = pd.concat([data_red, data_white])\n    data = data.dropna(inplace=False)\n\n    x = data[data.columns[0:11]].values\n\n    y = data[data.columns[11]].values\n\n    sc = StandardScaler()\n    x = sc.fit_transform(x)\n\n    y = np.expand_dims(y, -1)\n\n    x = np.float32(x)\n    y = np.float32(y)\n\n    return (x, y)\n\n\nx, y = preprocess()\n\ntrain_x, test_x, train_y, test_y = train_test_split(x, y, test_size = 0.2)\n\nnetwork = input_data(shape=[None, 11], name='Input_layer')\n\nnetwork = fully_connected(network, 5, activation='relu', name='Hidden_layer_1')\n\nnetwork = fully_connected(network, 1, activation='linear', name='Output_layer')\n\nnetwork = regression(network, batch_size=64, optimizer='sgd', learning_rate=0.2, loss='mean_square', metric='R2')\n\nmodel = tflearn.DNN(network)\n\nmodel.fit(train_x, train_y, show_metric=True, run_id='wine_regression', validation_set=0.1, n_epoch=10)\n\nresult = model.evaluate(test_x, test_y)\nprint('Accuracy is %0.2f%%' % (result[0] * 100))\n\npred_y = model.predict(test_x)\n\nplt.plot(test_y, color = 'red', label = 'Real data')\nplt.plot(pred_y, color = 'blue', label = 'Predicted data')\nplt.title('Prediction')\nplt.legend()\nplt.show()\n</code></pre>\n\n<p>Again, the prediction is very bad. Also, the loss and R2 values go hectic. Sometimes, the loss is low(6.45) and sometimes very high(23445.45). The same goes for R2 value too. Sometimes, R2 value goes above 1.0</p>\n\n<p>Even if the loss is minimum(0.1) and R2 as 0.95, the graph shows that the actual value varies lot from the predicted values.</p>\n\n<p>What mistake am I doing? Why is my prediction very bad? And why are the values R2 and loss too high sometimes and too low sometimes?</p>\n\n<p>Am I missing something here? This is my first regression neural network, so I don't know much about this. I hope that my question is clear. Thanks.</p>\n",
                "tags": "<machine-learning><neural-network><deep-learning><regression><tflearn>",
                "answers": []
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7713",
            "_score": 11.339064,
            "_source": {
                "title": "PCA or cluster table of experimental fitness scores",
                "content": "PCA or cluster table of experimental fitness scores <p>I need to find patterns experimental data.</p>\n\n<p>The columns are \"experiments\" which are chemical treatments for growth experiments.  The rows are individual gene names, the values are a fitness-defect score, which reflect the genes contribution to growth. </p>\n\n<p>I would like to find patterns that are reflected across all experiments using some type of PCA or clustering.  I have been trying to use sklearn but have not been successful in applying a model. </p>\n\n<p>The data looks like:</p>\n\n<pre><code>gene     SGTC_1                   SGTC_2                 SGTC_3 \nYAL002W  3.56420220283773        1.80774301690328       0.431491057210906\nYAL004W -0.885645399324204      -1.76020417788351       0.883034190306176\n</code></pre>\n\n<p>....</p>\n\n<p>There are 4000 rows for genes and 30 columns for experiments.</p>\n\n<p>Any suggestions would be greatly appreciated.</p>\n <scikit-learn><clustering><pca><p>PCA is a dimensionality reduction algorithm - it projects your high dimensional data onto a lower dimensional plane. This is useful for either visualisation (if you reduce to 2 or 3 dimensions to plot), or for training machine learning models.</p>\n\n<p>You say you want to find patterns in your data - I\u2019m not quite sure what you mean by this. Do you want to visualise your data, train a model on it and make some prediction, or something else?</p>\n\n<p>To visualise high dimensional data, you could use either the tSNE (t-stochastic neighbour embedding) algorithm, or PCA.</p>\n\n<p>Depending on the type of data you have, you can \u201cfind patterns\u201d in different ways.</p>\n\n<p>If your data is unlabelled (you don\u2019t know the classes of each sample or there is no dependent variable) you can use unsupervised learning algorithms such as K-means clustering, K nearest neighbours, Gaussian mixture model. If your data has dependent variables, depending on whether your dependent variable is categorical or continuous, you could use classification algorithms for the former and regression algorithms for the latter. Classification algorithms include logistic regression or decision trees. Regression models include linear regression.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "28669",
                "question_votes:": "",
                "question_text:": "<p>I need to find patterns experimental data.</p>\n\n<p>The columns are \"experiments\" which are chemical treatments for growth experiments.  The rows are individual gene names, the values are a fitness-defect score, which reflect the genes contribution to growth. </p>\n\n<p>I would like to find patterns that are reflected across all experiments using some type of PCA or clustering.  I have been trying to use sklearn but have not been successful in applying a model. </p>\n\n<p>The data looks like:</p>\n\n<pre><code>gene     SGTC_1                   SGTC_2                 SGTC_3 \nYAL002W  3.56420220283773        1.80774301690328       0.431491057210906\nYAL004W -0.885645399324204      -1.76020417788351       0.883034190306176\n</code></pre>\n\n<p>....</p>\n\n<p>There are 4000 rows for genes and 30 columns for experiments.</p>\n\n<p>Any suggestions would be greatly appreciated.</p>\n",
                "tags": "<scikit-learn><clustering><pca>",
                "answers": [
                    [
                        "28673",
                        "2",
                        "28669",
                        "",
                        "",
                        "<p>PCA is a dimensionality reduction algorithm - it projects your high dimensional data onto a lower dimensional plane. This is useful for either visualisation (if you reduce to 2 or 3 dimensions to plot), or for training machine learning models.</p>\n\n<p>You say you want to find patterns in your data - I\u2019m not quite sure what you mean by this. Do you want to visualise your data, train a model on it and make some prediction, or something else?</p>\n\n<p>To visualise high dimensional data, you could use either the tSNE (t-stochastic neighbour embedding) algorithm, or PCA.</p>\n\n<p>Depending on the type of data you have, you can \u201cfind patterns\u201d in different ways.</p>\n\n<p>If your data is unlabelled (you don\u2019t know the classes of each sample or there is no dependent variable) you can use unsupervised learning algorithms such as K-means clustering, K nearest neighbours, Gaussian mixture model. If your data has dependent variables, depending on whether your dependent variable is categorical or continuous, you could use classification algorithms for the former and regression algorithms for the latter. Classification algorithms include logistic regression or decision trees. Regression models include linear regression.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10596",
            "_score": 11.2752075,
            "_source": {
                "title": "Is there a definitive and more conclusive way of interpreting the R^2 score from a linear regression model in terms of prediction accuracy?",
                "content": "Is there a definitive and more conclusive way of interpreting the R^2 score from a linear regression model in terms of prediction accuracy? <p>I'm trying to find a definitive way to conclude the R^2 score from a prediction accuracy point of view rather than variance. How should I do it?</p>\n\n<p>Conceptually, most blogs / articles explain R^2 as:</p>\n\n<ol>\n<li>The variation in the data points that can be explained by the model. </li>\n<li>A measure of how closely fitted the data points are to the regression line.</li>\n</ol>\n\n<p>I find these answers to be unsatisfactory.</p>\n\n<p>If the R^2 score is 0.7, is it right for me to say that 70% of the data has been predicted accurately by the model? Since most explanations are tied to the explanation of the variance I'm thinking that looking at it from an 'accuracy' stand point of view is wrong. It implies that if I predicted 10 random points on the x-axis I would accurately guess 7 of its actual values. </p>\n\n<p>According to <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" rel=\"nofollow noreferrer\">scikit-learn's</a> documentation page at the 'score' section:</p>\n\n<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum()</p>\n\n<p>Apart from scikit-learn's way of calculation, another way of calculation is simply the squared of R (coefficient of correlation).</p>\n\n<p>Which way is right? Are both the same? Or are they related in some way?</p>\n\n<p>Assuming the right way of calculation is based off scikit-learn's documentation where the R^2 score is the variance from the predicted mean divided by the variance from the actual mean, is it even possible that the variance from the predicted mean is smaller than the variance from the actual mean? </p>\n\n<p>How can the variance from the prediction model which is built upon another dataset (let's say dataset A) be smaller than the actual variance of dataset B?</p>\n\n<p>Deeply appreciate any thoughts, comments or clarification. </p>\n <regression><linear-regression><machine-learning-model><scoring><p>Quoting Dr. Bruce Ratner:</p>\n\n<p>\"R-sq is a first-blush indicator of a good model. R-sq is often misused as the measure to assess which model produces better predictions...The root mean squared error (RMSE) is the measure for determining the better model. The smaller the RMSE value, the better the model is (the predictions are more precise).\"</p>\n\n<p>I sourced this from Dr. Ratner's LinkedIn, so I can't link to it. His website is: dmstat1.com</p>\n\n<p>Be careful with R-sq. The more variables you use the higher your R-sq value will be <em>no matter how good or bad your model is</em>. If you are using more than a few predictor variables you should also look at Adjusted-R-sq.</p>\n\n<p>If you would rather get a measure of accuracy you should look at RMSE. If you are comparing two models also look at Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC).</p>\n\n<p>To answer your question, if the R-sq is 0.7, it is incorrect to say that 70% of the data has been predicted accurately by the model. R-sq is a measure of <em>how much variance is accounted for within the predictor variables you are using</em>. R-sq of 0.7 means that your predictor variables can explain 70% of the variance in the response variable.</p>\n\n<p>For example pretend that the price of a cup of coffee is influenced ONLY by the price of water and the price of coffee beans. If I only know the price of water and I predict the price of coffee using only the price of water my R-sq is 0.5, because I know only 1/2 of the things that influence the price of a cup of coffee.</p>\n\n<p>In reality, it is virtually impossible to know ALL predictors that influence an outcome (R-sq = 1) because we either don't know what variables influence an outcome, or the variables that influence an outcome aren't contained in the dataset.</p>\n<p>Your first definition is correct. It's the fraction of variation explained by the model. It is not accuracy.</p>\n\n<p>Your labels (\"y\" values) vary, and the model tries to explain why by predicting those values. Think of the variance as the sum of squared differences from their mean (variance is just the 1/n * total squared error). This is like the base case prediction in the case of no model, 0 coefficients, just an intercept, predicting the mean label for every data point. This is \"v\" in your quote, and the squared error of this 'null' model.</p>\n\n<p>Consider your actual model, and how much the labels vary from these real predictions. The sum of those squares is the models error, it's \"u\" here, and it's the part the model still didn't get right. R2 = 1-u/v, or R2 = (v-u)/v, and this measures the fraction of all that variance in the labels (v) that is explained (v-u) by the model.</p>\n\n<p>It falls out from the definition of correlation coefficient with some math; see Wikipedia.</p>\n\n<p>R2 can be negative, but this means the model is worse than predicting just the mean of the labels, and is 'bad'. But applying some other model not fit on the data could sure do that. It could also be positive if the model was somewhat predictive.</p>\n\n<p>It's not a measure of how many regressors you know either.</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "37921",
                "question_votes:": "3",
                "question_text:": "<p>I'm trying to find a definitive way to conclude the R^2 score from a prediction accuracy point of view rather than variance. How should I do it?</p>\n\n<p>Conceptually, most blogs / articles explain R^2 as:</p>\n\n<ol>\n<li>The variation in the data points that can be explained by the model. </li>\n<li>A measure of how closely fitted the data points are to the regression line.</li>\n</ol>\n\n<p>I find these answers to be unsatisfactory.</p>\n\n<p>If the R^2 score is 0.7, is it right for me to say that 70% of the data has been predicted accurately by the model? Since most explanations are tied to the explanation of the variance I'm thinking that looking at it from an 'accuracy' stand point of view is wrong. It implies that if I predicted 10 random points on the x-axis I would accurately guess 7 of its actual values. </p>\n\n<p>According to <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" rel=\"nofollow noreferrer\">scikit-learn's</a> documentation page at the 'score' section:</p>\n\n<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum()</p>\n\n<p>Apart from scikit-learn's way of calculation, another way of calculation is simply the squared of R (coefficient of correlation).</p>\n\n<p>Which way is right? Are both the same? Or are they related in some way?</p>\n\n<p>Assuming the right way of calculation is based off scikit-learn's documentation where the R^2 score is the variance from the predicted mean divided by the variance from the actual mean, is it even possible that the variance from the predicted mean is smaller than the variance from the actual mean? </p>\n\n<p>How can the variance from the prediction model which is built upon another dataset (let's say dataset A) be smaller than the actual variance of dataset B?</p>\n\n<p>Deeply appreciate any thoughts, comments or clarification. </p>\n",
                "tags": "<regression><linear-regression><machine-learning-model><scoring>",
                "answers": [
                    [
                        "37930",
                        "2",
                        "37921",
                        "",
                        "",
                        "<p>Quoting Dr. Bruce Ratner:</p>\n\n<p>\"R-sq is a first-blush indicator of a good model. R-sq is often misused as the measure to assess which model produces better predictions...The root mean squared error (RMSE) is the measure for determining the better model. The smaller the RMSE value, the better the model is (the predictions are more precise).\"</p>\n\n<p>I sourced this from Dr. Ratner's LinkedIn, so I can't link to it. His website is: dmstat1.com</p>\n\n<p>Be careful with R-sq. The more variables you use the higher your R-sq value will be <em>no matter how good or bad your model is</em>. If you are using more than a few predictor variables you should also look at Adjusted-R-sq.</p>\n\n<p>If you would rather get a measure of accuracy you should look at RMSE. If you are comparing two models also look at Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC).</p>\n\n<p>To answer your question, if the R-sq is 0.7, it is incorrect to say that 70% of the data has been predicted accurately by the model. R-sq is a measure of <em>how much variance is accounted for within the predictor variables you are using</em>. R-sq of 0.7 means that your predictor variables can explain 70% of the variance in the response variable.</p>\n\n<p>For example pretend that the price of a cup of coffee is influenced ONLY by the price of water and the price of coffee beans. If I only know the price of water and I predict the price of coffee using only the price of water my R-sq is 0.5, because I know only 1/2 of the things that influence the price of a cup of coffee.</p>\n\n<p>In reality, it is virtually impossible to know ALL predictors that influence an outcome (R-sq = 1) because we either don't know what variables influence an outcome, or the variables that influence an outcome aren't contained in the dataset.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "37931",
                        "2",
                        "37921",
                        "",
                        "",
                        "<p>Your first definition is correct. It's the fraction of variation explained by the model. It is not accuracy.</p>\n\n<p>Your labels (\"y\" values) vary, and the model tries to explain why by predicting those values. Think of the variance as the sum of squared differences from their mean (variance is just the 1/n * total squared error). This is like the base case prediction in the case of no model, 0 coefficients, just an intercept, predicting the mean label for every data point. This is \"v\" in your quote, and the squared error of this 'null' model.</p>\n\n<p>Consider your actual model, and how much the labels vary from these real predictions. The sum of those squares is the models error, it's \"u\" here, and it's the part the model still didn't get right. R2 = 1-u/v, or R2 = (v-u)/v, and this measures the fraction of all that variance in the labels (v) that is explained (v-u) by the model.</p>\n\n<p>It falls out from the definition of correlation coefficient with some math; see Wikipedia.</p>\n\n<p>R2 can be negative, but this means the model is worse than predicting just the mean of the labels, and is 'bad'. But applying some other model not fit on the data could sure do that. It could also be positive if the model was somewhat predictive.</p>\n\n<p>It's not a measure of how many regressors you know either.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15026",
            "_score": 11.227014,
            "_source": {
                "title": "Use Machine Learning/Artificial Intelligence to predict next number (n+1) in a given sequence of random increasing integers",
                "content": "Use Machine Learning/Artificial Intelligence to predict next number (n+1) in a given sequence of random increasing integers <p>The AI must predict the next number in a given sequence of incremental integers (with no obvious pattern) using Python but so far I don't get the intended result!\nI tried changing the learning rate and iterations but so far no luck!</p>\n\n<p>Example sequence: [1, 3, 7, 8, 21, 49, 76, 224]</p>\n\n<p>Expected result: 467</p>\n\n<p>Result found : 2,795.5</p>\n\n<p>Cost: 504579.43</p>\n\n<p>PS. The same thread exists on AI Stackexchange &amp; Stackoverflow and I've been advised to post it here!</p>\n\n<p>This is what I've done so far:</p>\n\n<pre><code>import numpy as np\n\n# Init sequence\ndata =\\\n    [\n        [0, 1.0], [1, 3.0], [2, 7.0], [3, 8.0],\n        [4, 21.0], [5, 49.0], [6, 76.0], [7, 224.0]\n    ]\n\nX = np.matrix(data)[:, 0]\ny = np.matrix(data)[:, 1]\n\ndef J(X, y, theta):\n    theta = np.matrix(theta).T\n    m = len(y)\n    predictions = X * theta\n    sqError = np.power((predictions-y), [2])\n    return 1/(2*m) * sum(sqError)\n\ndataX = np.matrix(data)[:, 0:1]\nX = np.ones((len(dataX), 2))\nX[:, 1:] = dataX\n\n# gradient descent function\ndef gradient(X, y, alpha, theta, iters):\n    J_history = np.zeros(iters)\n    m = len(y)\n    theta = np.matrix(theta).T\n    for i in range(iters):\n        h0 = X * theta\n        delta = (1 / m) * (X.T * h0 - X.T * y)\n        theta = theta - alpha * delta\n        J_history[i] = J(X, y, theta.T)\n     return J_history, theta\nprint('\\n'+40*'=')\n\n# Theta initialization\ntheta = np.matrix([np.random.random(), np.random.random()])\n\n# Learning rate\nalpha = 0.02\n\n# Iterations\niters = 1000000\n\nprint('\\n== Model summary ==\\nLearning rate: {}\\nIterations: {}\\nInitial \ntheta: {}\\nInitial J: {:.2f}\\n'\n  .format(alpha, iters, theta, J(X, y, theta).item()))\nprint('Training model... ')\n\n# Train model and find optimal Theta value\nJ_history, theta_min = gradient(X, y, alpha, theta, iters)\nprint('Done, Model is trained')\nprint('\\nModelled prediction function is:\\ny = {:.2f} * x + {:.2f}'\n  .format(theta_min[1].item(), theta_min[0].item()))\nprint('Cost is: {:.2f}'.format(J(X, y, theta_min.T).item()))\n\n# Calculate the predicted profit\ndef predict(pop):\n    return [1, pop] * theta_min\n\n# Now\np = len(data)\nprint('\\n'+40*'=')\nprint('Initial sequence was:\\n', *np.array(data)[:, 1])\nprint('\\nNext numbers should be: {:,.1f}'\n  .format(predict(p).item()))\n</code></pre>\n\n<p><strong>Another method I tried but still giving wrong results</strong></p>\n\n<pre><code>import numpy as np\nfrom sklearn import datasets, linear_model\n\n# Define the problem\nproblem = [1, 3, 7, 8, 21, 49, 76, 224]\n\n# create x and y for the problem\n\nx = []\ny = []\n\nfor (xi, yi) in enumerate(problem):\n    x.append([xi])\n    y.append(yi)\n\nx = np.array(x)\ny = np.array(y)\n# Create linear regression object\nregr = linear_model.LinearRegression()\nregr.fit(x, y)\n\n# create the testing set\nx_test = [[i] for i in range(len(x), 3 + len(x))]\n\n# The coefficients\nprint('Coefficients: \\n', regr.coef_)\n# The mean squared error\nprint(\"Mean squared error: %.2f\" % np.mean((regr.predict(x) - y) ** 2))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % regr.score(x, y))\n\n# Do predictions\ny_predicted = regr.predict(x_test)\n\nprint(\"Next few numbers in the series are\")\nfor pred in y_predicted:\n    print(pred)\n</code></pre>\n <machine-learning><python><prediction><p>You are solving a problem which is not designed for a ANN, neural network has difficulties when you deal with univariate, few data.</p>\n\n<p>Because they will have to learn a solution based on few examples.</p>\n\n<p>However, a possible solution is achievable:</p>\n\n<p>import numpy as np</p>\n\n<pre><code># Init sequence\ndata = [[0, 1.0], [1, 3.0], [2, 7.0], [3, 8.0],\n    [4, 21.0], [5, 49.0], [6, 76.0], [7, 224.0]]\n\nX = np.matrix(data)[:, 0]\ny = np.matrix(data)[:, 1]\n\nReg=neural_network.MLPRegressor(solver='lbfgs',random_state=4,hidden_layer_sizes=(100,20,2),learning_rate='adaptive',verbose=True)\n\ny2 = np.ravel(y)\nF=Reg.fit(X=X,y=y2,)\nF.predict(8)\n</code></pre>\n\n<p>Note that the random_state parameter has a very large influence when I use a Neural Network. If you move this parameter (integer) you will find that the solution has a really large range.</p>\n",
                "codes": [
                    [
                        "# Init sequence\ndata = [[0, 1.0], [1, 3.0], [2, 7.0], [3, 8.0],\n    [4, 21.0], [5, 49.0], [6, 76.0], [7, 224.0]]\n\nX = np.matrix(data)[:, 0]\ny = np.matrix(data)[:, 1]\n\nReg=neural_network.MLPRegressor(solver='lbfgs',random_state=4,hidden_layer_sizes=(100,20,2),learning_rate='adaptive',verbose=True)\n\ny2 = np.ravel(y)\nF=Reg.fit(X=X,y=y2,)\nF.predict(8)\n"
                    ]
                ],
                "question_id:": "51033",
                "question_votes:": "3",
                "question_text:": "<p>The AI must predict the next number in a given sequence of incremental integers (with no obvious pattern) using Python but so far I don't get the intended result!\nI tried changing the learning rate and iterations but so far no luck!</p>\n\n<p>Example sequence: [1, 3, 7, 8, 21, 49, 76, 224]</p>\n\n<p>Expected result: 467</p>\n\n<p>Result found : 2,795.5</p>\n\n<p>Cost: 504579.43</p>\n\n<p>PS. The same thread exists on AI Stackexchange &amp; Stackoverflow and I've been advised to post it here!</p>\n\n<p>This is what I've done so far:</p>\n\n<pre><code>import numpy as np\n\n# Init sequence\ndata =\\\n    [\n        [0, 1.0], [1, 3.0], [2, 7.0], [3, 8.0],\n        [4, 21.0], [5, 49.0], [6, 76.0], [7, 224.0]\n    ]\n\nX = np.matrix(data)[:, 0]\ny = np.matrix(data)[:, 1]\n\ndef J(X, y, theta):\n    theta = np.matrix(theta).T\n    m = len(y)\n    predictions = X * theta\n    sqError = np.power((predictions-y), [2])\n    return 1/(2*m) * sum(sqError)\n\ndataX = np.matrix(data)[:, 0:1]\nX = np.ones((len(dataX), 2))\nX[:, 1:] = dataX\n\n# gradient descent function\ndef gradient(X, y, alpha, theta, iters):\n    J_history = np.zeros(iters)\n    m = len(y)\n    theta = np.matrix(theta).T\n    for i in range(iters):\n        h0 = X * theta\n        delta = (1 / m) * (X.T * h0 - X.T * y)\n        theta = theta - alpha * delta\n        J_history[i] = J(X, y, theta.T)\n     return J_history, theta\nprint('\\n'+40*'=')\n\n# Theta initialization\ntheta = np.matrix([np.random.random(), np.random.random()])\n\n# Learning rate\nalpha = 0.02\n\n# Iterations\niters = 1000000\n\nprint('\\n== Model summary ==\\nLearning rate: {}\\nIterations: {}\\nInitial \ntheta: {}\\nInitial J: {:.2f}\\n'\n  .format(alpha, iters, theta, J(X, y, theta).item()))\nprint('Training model... ')\n\n# Train model and find optimal Theta value\nJ_history, theta_min = gradient(X, y, alpha, theta, iters)\nprint('Done, Model is trained')\nprint('\\nModelled prediction function is:\\ny = {:.2f} * x + {:.2f}'\n  .format(theta_min[1].item(), theta_min[0].item()))\nprint('Cost is: {:.2f}'.format(J(X, y, theta_min.T).item()))\n\n# Calculate the predicted profit\ndef predict(pop):\n    return [1, pop] * theta_min\n\n# Now\np = len(data)\nprint('\\n'+40*'=')\nprint('Initial sequence was:\\n', *np.array(data)[:, 1])\nprint('\\nNext numbers should be: {:,.1f}'\n  .format(predict(p).item()))\n</code></pre>\n\n<p><strong>Another method I tried but still giving wrong results</strong></p>\n\n<pre><code>import numpy as np\nfrom sklearn import datasets, linear_model\n\n# Define the problem\nproblem = [1, 3, 7, 8, 21, 49, 76, 224]\n\n# create x and y for the problem\n\nx = []\ny = []\n\nfor (xi, yi) in enumerate(problem):\n    x.append([xi])\n    y.append(yi)\n\nx = np.array(x)\ny = np.array(y)\n# Create linear regression object\nregr = linear_model.LinearRegression()\nregr.fit(x, y)\n\n# create the testing set\nx_test = [[i] for i in range(len(x), 3 + len(x))]\n\n# The coefficients\nprint('Coefficients: \\n', regr.coef_)\n# The mean squared error\nprint(\"Mean squared error: %.2f\" % np.mean((regr.predict(x) - y) ** 2))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % regr.score(x, y))\n\n# Do predictions\ny_predicted = regr.predict(x_test)\n\nprint(\"Next few numbers in the series are\")\nfor pred in y_predicted:\n    print(pred)\n</code></pre>\n",
                "tags": "<machine-learning><python><prediction>",
                "answers": [
                    [
                        "51040",
                        "2",
                        "51033",
                        "",
                        "",
                        "<p>You are solving a problem which is not designed for a ANN, neural network has difficulties when you deal with univariate, few data.</p>\n\n<p>Because they will have to learn a solution based on few examples.</p>\n\n<p>However, a possible solution is achievable:</p>\n\n<p>import numpy as np</p>\n\n<pre><code># Init sequence\ndata = [[0, 1.0], [1, 3.0], [2, 7.0], [3, 8.0],\n    [4, 21.0], [5, 49.0], [6, 76.0], [7, 224.0]]\n\nX = np.matrix(data)[:, 0]\ny = np.matrix(data)[:, 1]\n\nReg=neural_network.MLPRegressor(solver='lbfgs',random_state=4,hidden_layer_sizes=(100,20,2),learning_rate='adaptive',verbose=True)\n\ny2 = np.ravel(y)\nF=Reg.fit(X=X,y=y2,)\nF.predict(8)\n</code></pre>\n\n<p>Note that the random_state parameter has a very large influence when I use a Neural Network. If you move this parameter (integer) you will find that the solution has a really large range.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16286",
            "_score": 11.224332,
            "_source": {
                "title": "Correlation feature selection followed by regression",
                "content": "Correlation feature selection followed by regression <p>I have quarterly results data for a company with around 100 variables. Total 60 quarters results are available (total records 60).</p>\n\n<p>sample data: (only few columns &amp; 10 rows)</p>\n\n<p><a href=\"https://i.stack.imgur.com/629og.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/629og.png\" alt=\"enter image description here\"></a></p>\n\n<p>I would like know following,</p>\n\n<ol>\n<li><p>which ML algorithms / methods to be used to get the information about most important variable(s) affecting the price movement </p></li>\n<li><p>how much each variable is contributing towards price movement (+ve or -ve)</p></li>\n<li><p>predict, if a variable value is changed then how it'll affect the price movement</p></li>\n</ol>\n\n<p>Thanks!</p>\n <machine-learning><regression><feature-selection><correlation><p>Try below code, here I have taken other data. pca = PCA(n_components = None) first you give here none to check how much each feature is contributing.</p>\n\n<pre><code># Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Importing the dataset\ndataset = pd.read_csv('Wine.csv')\nX = dataset.iloc[:, 0:13].values\ny = dataset.iloc[:, 13].values\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# Applying PCA\nfrom sklearn.decomposition import PCA\npca = PCA(n_components = None)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\nexplained_variance = pca.explained_variance_ratio_\nprint explained_variance\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>array([0.36884109, 0.19318394, 0.10752862, 0.07421996, 0.06245904,\n       0.04909   , 0.04117287, 0.02495984, 0.02308855, 0.01864124,\n       0.01731766, 0.01252785, 0.00696933])\n</code></pre>\n\n<p>In the above output you can see the contribution in decreasing order. If you choose n =2 , then 57% of variance you are covering, etc. After reducing dimension, you can choose algorithm for this.</p>\n<p>I think this is a case for linear regression with a lasso/ridge penalty. The lasso/ridge does \u201eshrink\u201c features/variables, so that it is easy to see which features are important. Since you have 100 variables, you could opt for lasso, since lasso can also \u201eautomatically\u201c exclude features. Here is a lasso example in Python: <a href=\"https://datascience.stackexchange.com/a/53639/71442\">https://datascience.stackexchange.com/a/53639/71442</a>.</p>\n",
                "codes": [
                    [
                        "# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Importing the dataset\ndataset = pd.read_csv('Wine.csv')\nX = dataset.iloc[:, 0:13].values\ny = dataset.iloc[:, 13].values\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# Applying PCA\nfrom sklearn.decomposition import PCA\npca = PCA(n_components = None)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\nexplained_variance = pca.explained_variance_ratio_\nprint explained_variance\n",
                        "array([0.36884109, 0.19318394, 0.10752862, 0.07421996, 0.06245904,\n       0.04909   , 0.04117287, 0.02495984, 0.02308855, 0.01864124,\n       0.01731766, 0.01252785, 0.00696933])\n"
                    ],
                    []
                ],
                "question_id:": "53759",
                "question_votes:": "",
                "question_text:": "<p>I have quarterly results data for a company with around 100 variables. Total 60 quarters results are available (total records 60).</p>\n\n<p>sample data: (only few columns &amp; 10 rows)</p>\n\n<p><a href=\"https://i.stack.imgur.com/629og.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/629og.png\" alt=\"enter image description here\"></a></p>\n\n<p>I would like know following,</p>\n\n<ol>\n<li><p>which ML algorithms / methods to be used to get the information about most important variable(s) affecting the price movement </p></li>\n<li><p>how much each variable is contributing towards price movement (+ve or -ve)</p></li>\n<li><p>predict, if a variable value is changed then how it'll affect the price movement</p></li>\n</ol>\n\n<p>Thanks!</p>\n",
                "tags": "<machine-learning><regression><feature-selection><correlation>",
                "answers": [
                    [
                        "53763",
                        "2",
                        "53759",
                        "",
                        "",
                        "<p>Try below code, here I have taken other data. pca = PCA(n_components = None) first you give here none to check how much each feature is contributing.</p>\n\n<pre><code># Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Importing the dataset\ndataset = pd.read_csv('Wine.csv')\nX = dataset.iloc[:, 0:13].values\ny = dataset.iloc[:, 13].values\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# Applying PCA\nfrom sklearn.decomposition import PCA\npca = PCA(n_components = None)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\nexplained_variance = pca.explained_variance_ratio_\nprint explained_variance\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>array([0.36884109, 0.19318394, 0.10752862, 0.07421996, 0.06245904,\n       0.04909   , 0.04117287, 0.02495984, 0.02308855, 0.01864124,\n       0.01731766, 0.01252785, 0.00696933])\n</code></pre>\n\n<p>In the above output you can see the contribution in decreasing order. If you choose n =2 , then 57% of variance you are covering, etc. After reducing dimension, you can choose algorithm for this.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "53762",
                        "2",
                        "53759",
                        "",
                        "",
                        "<p>I think this is a case for linear regression with a lasso/ridge penalty. The lasso/ridge does \u201eshrink\u201c features/variables, so that it is easy to see which features are important. Since you have 100 variables, you could opt for lasso, since lasso can also \u201eautomatically\u201c exclude features. Here is a lasso example in Python: <a href=\"https://datascience.stackexchange.com/a/53639/71442\">https://datascience.stackexchange.com/a/53639/71442</a>.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13337",
            "_score": 11.196566,
            "_source": {
                "title": "Scaling does not speed up the SVM model",
                "content": "Scaling does not speed up the SVM model <p>I tried to standardize the training data with samples of 629,145 rows and 24 features:</p>\n\n<pre><code>from sklearn import datasets\nimport pandas as pd\nfrom sklearn import svm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\ndf = pd.read_csv('mydata.csv', dtype='object')\n\n#manually choosing 24 features\nX=df.loc[:, ['Bwd Pkt Len Min','Subflow Fwd Byts','TotLen Fwd Pkts','TotLen Fwd Pkts','Bwd Pkt Len Std','Flow IAT Min',\n             'Fwd IAT Min','Flow IAT Mean','Flow Duration','Flow IAT Std','Active Min','Active Mean','Fwd IAT Min',\n             'Bwd IAT Mean','Fwd IAT Mean','Init Fwd Win Byts','ACK Flag Cnt','Fwd PSH Flags','SYN Flag Cnt','Fwd Pkts/s',\n             'Bwd Pkts/s','Init Bwd Win Byts','PSH Flag Cnt','Pkt Size Avg']]\nY= df['Label'] \n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4,random_state=42) # 60% training and 40% test\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n#Create a svm Classifier\nclf = svm.SVC(kernel='rbf') # not linear Kernel\nclf.fit(X_train, y_train)\n</code></pre>\n\n<p>Already 6 hours and SVM does not converge. Same data is converged with other algorithms very fast as RF and I know it is quite normal as SVM considered computationally high algorithm compared to KNN and RF.. I read quite a bit of questions/answers and articles. </p>\n\n<ol>\n<li>I wonder how can I track and analyze the problem visually (probably plotting some graphs as cost function or ?). </li>\n<li>Can parameter tuning (C parameter) be of the help and speed up this? </li>\n<li>What could be your advice? </li>\n</ol>\n\n<p>Thanks very much</p>\n <machine-learning><python><scikit-learn><svm><p>I do not program on python. Nevertheless, I would say the key relies in the number of samples (629,145). They are many. The SVM has to test them to pick which are <em>good</em> support vectors for data partition/regression and given the size of the dataset there are a lot of alternatives. That issue plus the number of different C, gamma/sigma and, perhaps, epsilon (not sure you are classifying or regressing) tested during the optimisation of the SVM hinders convergence.\nThere are people who used clusters instead of the original dataset to train the SVM. For instance: \nBarros de Almeida, M., de Padua Braga, A., Braga, J.P., 2000. SVM-KM: speeding SVMs learning with a priori cluster selection and k-means, in: Proceedings. Vol.1. Sixth Brazilian Symposium on Neural Networks. Rio de Janeiro, (Brazil), pp. 162\u2013167.\ncan be a good starting reference but, I am aware there a others. There is at least one R package based on that idea (LinearizedSVR).\nIn addition, there are analytical methods to infer the values of the parameters C, gamma/sigma and epsilon (for regression) based on the characteristics of the training dataset. That means no optimisation is necessary, although there is a friend that still tunes gamma/sigma but fixes C fallowing these approaches. I think there is available code (at least for R) somewhere in the net. The refs are:\nCherkassky, V., Ma, Y., 2004. Practical selection of SVM parameters and noise estimation for SVM regression. Neural Networks 17 (1), 113\u2013126. 10.1016/S0893-6080(03)00169-2\nfor regression and, \nKeerthi, S.S., Lin, C.-J., 2003. Asymptotic Behaviors of Support Vector Machines with Gaussian Kernel. Neural Comput. 15 (7), 1667\u20131689. 10.1162/089976603321891855\nfor classification SVMs.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "45728",
                "question_votes:": "3",
                "question_text:": "<p>I tried to standardize the training data with samples of 629,145 rows and 24 features:</p>\n\n<pre><code>from sklearn import datasets\nimport pandas as pd\nfrom sklearn import svm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\ndf = pd.read_csv('mydata.csv', dtype='object')\n\n#manually choosing 24 features\nX=df.loc[:, ['Bwd Pkt Len Min','Subflow Fwd Byts','TotLen Fwd Pkts','TotLen Fwd Pkts','Bwd Pkt Len Std','Flow IAT Min',\n             'Fwd IAT Min','Flow IAT Mean','Flow Duration','Flow IAT Std','Active Min','Active Mean','Fwd IAT Min',\n             'Bwd IAT Mean','Fwd IAT Mean','Init Fwd Win Byts','ACK Flag Cnt','Fwd PSH Flags','SYN Flag Cnt','Fwd Pkts/s',\n             'Bwd Pkts/s','Init Bwd Win Byts','PSH Flag Cnt','Pkt Size Avg']]\nY= df['Label'] \n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4,random_state=42) # 60% training and 40% test\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n#Create a svm Classifier\nclf = svm.SVC(kernel='rbf') # not linear Kernel\nclf.fit(X_train, y_train)\n</code></pre>\n\n<p>Already 6 hours and SVM does not converge. Same data is converged with other algorithms very fast as RF and I know it is quite normal as SVM considered computationally high algorithm compared to KNN and RF.. I read quite a bit of questions/answers and articles. </p>\n\n<ol>\n<li>I wonder how can I track and analyze the problem visually (probably plotting some graphs as cost function or ?). </li>\n<li>Can parameter tuning (C parameter) be of the help and speed up this? </li>\n<li>What could be your advice? </li>\n</ol>\n\n<p>Thanks very much</p>\n",
                "tags": "<machine-learning><python><scikit-learn><svm>",
                "answers": [
                    [
                        "45800",
                        "2",
                        "45728",
                        "",
                        "",
                        "<p>I do not program on python. Nevertheless, I would say the key relies in the number of samples (629,145). They are many. The SVM has to test them to pick which are <em>good</em> support vectors for data partition/regression and given the size of the dataset there are a lot of alternatives. That issue plus the number of different C, gamma/sigma and, perhaps, epsilon (not sure you are classifying or regressing) tested during the optimisation of the SVM hinders convergence.\nThere are people who used clusters instead of the original dataset to train the SVM. For instance: \nBarros de Almeida, M., de Padua Braga, A., Braga, J.P., 2000. SVM-KM: speeding SVMs learning with a priori cluster selection and k-means, in: Proceedings. Vol.1. Sixth Brazilian Symposium on Neural Networks. Rio de Janeiro, (Brazil), pp. 162\u2013167.\ncan be a good starting reference but, I am aware there a others. There is at least one R package based on that idea (LinearizedSVR).\nIn addition, there are analytical methods to infer the values of the parameters C, gamma/sigma and epsilon (for regression) based on the characteristics of the training dataset. That means no optimisation is necessary, although there is a friend that still tunes gamma/sigma but fixes C fallowing these approaches. I think there is available code (at least for R) somewhere in the net. The refs are:\nCherkassky, V., Ma, Y., 2004. Practical selection of SVM parameters and noise estimation for SVM regression. Neural Networks 17 (1), 113\u2013126. 10.1016/S0893-6080(03)00169-2\nfor regression and, \nKeerthi, S.S., Lin, C.-J., 2003. Asymptotic Behaviors of Support Vector Machines with Gaussian Kernel. Neural Comput. 15 (7), 1667\u20131689. 10.1162/089976603321891855\nfor classification SVMs.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7591",
            "_score": 11.193518,
            "_source": {
                "title": "Sci-kit learn function to select threshold for higher recall than precision",
                "content": "Sci-kit learn function to select threshold for higher recall than precision <p>When we care more that there should be no false negatives, as far as possible\u2026 ie. higher recall (video is suitable for kid or not), we should use (receiver operating characteristic) ROC (area under the curve) AUC and try to maximize it.</p>\n\n<p>Scikit-Learn provides a function to compute this directly:</p>\n\n<pre><code>from sklearn.metrics import roc_auc_score\nroc_auc_score(y_train_5, y_scores)\n</code></pre>\n\n<p>Similarly, when we care more about the false positives than the false negatives, example shop lifting case then what should we do?</p>\n\n<p>Should we just try to maximize the recall ignoring the precision or is there a better metric?</p>\n\n<p>I had read somewhere \"Use the precision vs recall curve and get that max\" but not very sure what that means... Can you please explain the same?</p>\n\n<p>If there a direct function for this metric in sci-kit learn, like above for the first case, please do let me know.</p>\n <machine-learning><neural-network><deep-learning><classification><scikit-learn><p>As far as a fuction in scikit to implement a certain threshold for a higher recall, I don't think there is one.</p>\n\n<p>But, depending on what model you're using, you can vary the threshold for probability outputs of the model to obtain a higher Recall.</p>\n\n<p>For example, say you are using a <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" rel=\"nofollow noreferrer\">Random Forest</a> or <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">Logistic Regression</a> classifier model, then you can use the <code>predict_proba</code> function on your data set; this will return probabilities for each sample belonging to a particular class. If you then create a new array from the output of <code>predict_proba</code> using your threshold, then the model will have a Recall with your desired accuracy when it classifies new unseen data.</p>\n\n<p>e.g pseudo code for binary classification</p>\n\n<pre><code>clf = sklearn.ensemble.RandomForestClassifier()\nmodel = fit(X,y) # fit model to training datset\nprobs = model.predict_proba(X_new) # prediction on a new dataset X_new\n\nthreshold = 0.7 # threshold we set where the probability prediction must be above this to be classified as a '1'\nclasses = probs[:,1] # say it is the class in the second column you care about predictint\nclasses[classes&gt;=threshold] = 1\nclasses[classes&lt;threshold] = 0\n</code></pre>\n<p>The easiest way is to replace your labels. The other way is to set importance of the more important class to a higher value so the cost function moves toward direction to take much care for your desired label. You can set the <em>class_weight</em>. Take a look at <a href=\"https://stackoverflow.com/questions/30972029/how-does-the-class-weight-parameter-in-scikit-learn-work\">here</a> and <a href=\"http://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane_unbalanced.html\" rel=\"nofollow noreferrer\">here</a>.</p>\n",
                "codes": [
                    [
                        "clf = sklearn.ensemble.RandomForestClassifier()\nmodel = fit(X,y) # fit model to training datset\nprobs = model.predict_proba(X_new) # prediction on a new dataset X_new\n\nthreshold = 0.7 # threshold we set where the probability prediction must be above this to be classified as a '1'\nclasses = probs[:,1] # say it is the class in the second column you care about predictint\nclasses[classes>=threshold] = 1\nclasses[classes<threshold] = 0\n"
                    ],
                    []
                ],
                "question_id:": "28282",
                "question_votes:": "5",
                "question_text:": "<p>When we care more that there should be no false negatives, as far as possible\u2026 ie. higher recall (video is suitable for kid or not), we should use (receiver operating characteristic) ROC (area under the curve) AUC and try to maximize it.</p>\n\n<p>Scikit-Learn provides a function to compute this directly:</p>\n\n<pre><code>from sklearn.metrics import roc_auc_score\nroc_auc_score(y_train_5, y_scores)\n</code></pre>\n\n<p>Similarly, when we care more about the false positives than the false negatives, example shop lifting case then what should we do?</p>\n\n<p>Should we just try to maximize the recall ignoring the precision or is there a better metric?</p>\n\n<p>I had read somewhere \"Use the precision vs recall curve and get that max\" but not very sure what that means... Can you please explain the same?</p>\n\n<p>If there a direct function for this metric in sci-kit learn, like above for the first case, please do let me know.</p>\n",
                "tags": "<machine-learning><neural-network><deep-learning><classification><scikit-learn>",
                "answers": [
                    [
                        "28286",
                        "2",
                        "28282",
                        "",
                        "",
                        "<p>As far as a fuction in scikit to implement a certain threshold for a higher recall, I don't think there is one.</p>\n\n<p>But, depending on what model you're using, you can vary the threshold for probability outputs of the model to obtain a higher Recall.</p>\n\n<p>For example, say you are using a <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" rel=\"nofollow noreferrer\">Random Forest</a> or <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">Logistic Regression</a> classifier model, then you can use the <code>predict_proba</code> function on your data set; this will return probabilities for each sample belonging to a particular class. If you then create a new array from the output of <code>predict_proba</code> using your threshold, then the model will have a Recall with your desired accuracy when it classifies new unseen data.</p>\n\n<p>e.g pseudo code for binary classification</p>\n\n<pre><code>clf = sklearn.ensemble.RandomForestClassifier()\nmodel = fit(X,y) # fit model to training datset\nprobs = model.predict_proba(X_new) # prediction on a new dataset X_new\n\nthreshold = 0.7 # threshold we set where the probability prediction must be above this to be classified as a '1'\nclasses = probs[:,1] # say it is the class in the second column you care about predictint\nclasses[classes&gt;=threshold] = 1\nclasses[classes&lt;threshold] = 0\n</code></pre>\n",
                        "",
                        "1"
                    ],
                    [
                        "28283",
                        "2",
                        "28282",
                        "",
                        "",
                        "<p>The easiest way is to replace your labels. The other way is to set importance of the more important class to a higher value so the cost function moves toward direction to take much care for your desired label. You can set the <em>class_weight</em>. Take a look at <a href=\"https://stackoverflow.com/questions/30972029/how-does-the-class-weight-parameter-in-scikit-learn-work\">here</a> and <a href=\"http://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane_unbalanced.html\" rel=\"nofollow noreferrer\">here</a>.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14755",
            "_score": 11.185981,
            "_source": {
                "title": "How to test multiple algorithms at once?",
                "content": "How to test multiple algorithms at once? <p>I was wandering if there is a method with Python and/or Sklearn  to test multiple algorithms at once instead of run them one by one and see the accuracy.  I have been looking on the web and I've found a method call  <strong>\"Spot-Checking Algorithms\"</strong> form this eBook:  <em>Machine learning with pyhton</em> </p>\n\n<pre><code># Spot-Check Algorithms\n\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC()))\n\n# evaluate each model in turn\n\nresults = []\nnames = []\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=seed)\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, \n    scoring='accuracy')\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\nprint(msg)\n</code></pre>\n\n<p>Here the result: </p>\n\n<pre><code>LR: 0.966667 (0.040825)\nLDA: 0.975000 (0.038188)\nKNN: 0.983333 (0.033333)\nCART: 0.975000 (0.038188)\nNB: 0.975000 (0.053359)\nSVM: 0.981667 (0.025000)\n</code></pre>\n\n<p>I find this code very efficient and a real saving time but because I am a beginner, I want to confront sources to make my own opinion and also make sure that it could be useful to solve  a real business problem .</p>\n <machine-learning><python><scikit-learn><algorithms>",
                "codes": [],
                "question_id:": "49419",
                "question_votes:": "",
                "question_text:": "<p>I was wandering if there is a method with Python and/or Sklearn  to test multiple algorithms at once instead of run them one by one and see the accuracy.  I have been looking on the web and I've found a method call  <strong>\"Spot-Checking Algorithms\"</strong> form this eBook:  <em>Machine learning with pyhton</em> </p>\n\n<pre><code># Spot-Check Algorithms\n\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC()))\n\n# evaluate each model in turn\n\nresults = []\nnames = []\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=seed)\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, \n    scoring='accuracy')\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\nprint(msg)\n</code></pre>\n\n<p>Here the result: </p>\n\n<pre><code>LR: 0.966667 (0.040825)\nLDA: 0.975000 (0.038188)\nKNN: 0.983333 (0.033333)\nCART: 0.975000 (0.038188)\nNB: 0.975000 (0.053359)\nSVM: 0.981667 (0.025000)\n</code></pre>\n\n<p>I find this code very efficient and a real saving time but because I am a beginner, I want to confront sources to make my own opinion and also make sure that it could be useful to solve  a real business problem .</p>\n",
                "tags": "<machine-learning><python><scikit-learn><algorithms>",
                "answers": []
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "1152",
            "_score": 11.00399,
            "_source": {
                "title": "Contributions of each feature in classification?",
                "content": "Contributions of each feature in classification? <p>I have some features and I am using Weka to classify my instances.</p>\n\n<p>For example I have:</p>\n\n<p><code>Number of adj   number of adverb    number of punctuation</code> </p>\n\n<p>in my feature set. However, I would like to know the contribution of each feature in the feature set. So what metrics or parameters are helpful to get the contribution of features?</p>\n <machine-learning><nlp><p>This is called feature ranking, which is closely related to <a href=\"https://en.wikipedia.org/wiki/Feature_selection\" rel=\"nofollow noreferrer\">feature selection</a>.</p>\n\n<ul>\n<li>feature ranking = determining the importance of any individual feature</li>\n<li>feature selection = selecting a subset of relevant features for use in model construction. </li>\n</ul>\n\n<p>So if you are able to ranked features, you can use it to select features, and if you can select a subset of useful features, you've done at least a partial ranking by removing the useless ones. </p>\n\n<p>This <a href=\"https://en.wikipedia.org/wiki/Feature_selection\" rel=\"nofollow noreferrer\">Wikipedia page</a> and this <a href=\"https://www.quora.com/How-do-I-perform-feature-selection?share=1\" rel=\"nofollow noreferrer\">Quora post</a> should give some ideas. The distinction filter methods vs. wrapper based methods vs. embedded methods is the most common one.</p>\n\n<hr>\n\n<p>One straightforward approximate way is to use <a href=\"http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\" rel=\"nofollow noreferrer\">feature importance with forests of trees</a>:</p>\n\n<p><a href=\"https://i.stack.imgur.com/r7Io5.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/r7Io5.png\" alt=\"enter image description here\"></a></p>\n\n<p>Other common ways:</p>\n\n<ul>\n<li><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\" rel=\"nofollow noreferrer\">recursive feature elimination</a>.</li>\n<li>stepwise regression (or <a href=\"http://scikit-learn.org/stable/modules/linear_model.html#lars-lasso\" rel=\"nofollow noreferrer\">LARS Lasso</a>).</li>\n</ul>\n\n<p>If you use scikit-learn, check out <a href=\"http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection\" rel=\"nofollow noreferrer\">module-sklearn.feature_selection</a>. I'd guess Weka has some similar functions.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "6648",
                "question_votes:": "4",
                "question_text:": "<p>I have some features and I am using Weka to classify my instances.</p>\n\n<p>For example I have:</p>\n\n<p><code>Number of adj   number of adverb    number of punctuation</code> </p>\n\n<p>in my feature set. However, I would like to know the contribution of each feature in the feature set. So what metrics or parameters are helpful to get the contribution of features?</p>\n",
                "tags": "<machine-learning><nlp>",
                "answers": [
                    [
                        "6651",
                        "2",
                        "6648",
                        "",
                        "",
                        "<p>This is called feature ranking, which is closely related to <a href=\"https://en.wikipedia.org/wiki/Feature_selection\" rel=\"nofollow noreferrer\">feature selection</a>.</p>\n\n<ul>\n<li>feature ranking = determining the importance of any individual feature</li>\n<li>feature selection = selecting a subset of relevant features for use in model construction. </li>\n</ul>\n\n<p>So if you are able to ranked features, you can use it to select features, and if you can select a subset of useful features, you've done at least a partial ranking by removing the useless ones. </p>\n\n<p>This <a href=\"https://en.wikipedia.org/wiki/Feature_selection\" rel=\"nofollow noreferrer\">Wikipedia page</a> and this <a href=\"https://www.quora.com/How-do-I-perform-feature-selection?share=1\" rel=\"nofollow noreferrer\">Quora post</a> should give some ideas. The distinction filter methods vs. wrapper based methods vs. embedded methods is the most common one.</p>\n\n<hr>\n\n<p>One straightforward approximate way is to use <a href=\"http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\" rel=\"nofollow noreferrer\">feature importance with forests of trees</a>:</p>\n\n<p><a href=\"https://i.stack.imgur.com/r7Io5.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/r7Io5.png\" alt=\"enter image description here\"></a></p>\n\n<p>Other common ways:</p>\n\n<ul>\n<li><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\" rel=\"nofollow noreferrer\">recursive feature elimination</a>.</li>\n<li>stepwise regression (or <a href=\"http://scikit-learn.org/stable/modules/linear_model.html#lars-lasso\" rel=\"nofollow noreferrer\">LARS Lasso</a>).</li>\n</ul>\n\n<p>If you use scikit-learn, check out <a href=\"http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection\" rel=\"nofollow noreferrer\">module-sklearn.feature_selection</a>. I'd guess Weka has some similar functions.</p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6323",
            "_score": 10.9335375,
            "_source": {
                "title": "Can Neural Networks be trained to smooth values / output the average?",
                "content": "Can Neural Networks be trained to smooth values / output the average? <p>Let's say we have a neural network with one input neuron and one output neuron. The training data $(x, f(x))$ is generated by a process</p>\n\n<p>$$f(x) = ax + \\mathcal{N}(b, c)$$</p>\n\n<p>with $a, b, c \\in \\mathbb{R}^+$, e.g. something like</p>\n\n<pre><code>feature  | target\n-----------------\n0             0.0\n0             1.0\n0             1.5\n0            -1.2\n0            -0.9\n...\n</code></pre>\n\n<p>I know that neural networks can deal pretty well with labeling errors in classification problems. Meaning if you have a large dataset and a couple of examples have the wrong label, they get basically ignored.</p>\n\n<p>But for this kind of problem I'm not too sure. A first experiment indicates that they do smooth values.</p>\n\n<p><strong>Are there choices in architecture / training which help the smoothing / averaging / removal of noise?</strong></p>\n\n<h2>What I tried</h2>\n\n<p>I created a network which can solve this kind of regression problem without noise. It gets a MSE of about <code>0.0005</code>. When I add a bit of noise to the training set only, I get an MSE of <code>0.001</code>:</p>\n\n<pre><code>#!/usr/bin/env python\n\n# core modules\nimport random\n\n# 3rd party modules\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n\ndef main(add_noise=True):\n    # Get data\n    xs, ys = create_data_points(10000)\n    x_train, x_test, y_train, y_test = train_test_split(xs, ys, test_size=0.20)\n\n    # Add noise to training data\n    if add_noise:\n        noise = np.random.normal(0, 0.1, len(x_train))\n        x_train = x_train + noise\n\n    # Create model\n    model = create_model()\n    model.compile(optimizer='rmsprop',\n                  loss='mse',\n                  metrics=['mse'])\n\n    # Fit model to data.\n    model.fit(x_train, y_train, epochs=10, batch_size=32, verbose=1)\n\n    # Evaluate\n    y_pred = model.predict(x_test, batch_size=100).flatten()\n    print(\"MSE on test set:\")\n    print(((y_pred - y_test)**2).sum() / len(y_test))\n\n\ndef create_data_points(nb_points):\n    xs = []\n    ys = []\n    for i in range(nb_points):\n        x = random.random()\n        xs.append(x)\n        ys.append(2 * x)\n    return np.array(xs), np.array(ys)\n\n\ndef create_model(input_dim=1, output_dim=1):\n    model = Sequential()\n    model.add(Dense(200, input_dim=input_dim, activation='relu'))\n    model.add(Dense(200, input_dim=input_dim, activation='relu'))\n    model.add(Dense(output_dim, activation='linear'))\n    return model\n\n\nif __name__ == '__main__':\n    main()\n</code></pre>\n\n<h2>Outliers</h2>\n\n<p>In an earlier version of this question I wrote \"outlier\" when I meant \"label noise\". For outliers, there is:</p>\n\n<ul>\n<li><a href=\"http://www.scialert.net/fulltext/?doi=jas.2005.1394.1398&amp;org=11\" rel=\"noreferrer\">The Effects of Outliers Data on Neural Network Performance</a></li>\n</ul>\n <neural-network><regression><noise><blockquote>\n  <p>I know that neural networks can deal pretty well with outliers.</p>\n</blockquote>\n\n<p>Not necessarily. </p>\n\n<p>It depends on your loss function and sample size. </p>\n\n<p>In linear regression, the loss function is MSE. MSE is not robust against outliers, so linear regression is not robust against outliers. Having larger sample will mitigate the impact of a outliers. </p>\n\n<p>Same principles applies to neural network.</p>\n\n<blockquote>\n  <p>Are there choices in architecture / training which help the smoothing / averaging / removal of noise?</p>\n</blockquote>\n\n<p>That's just the problem of over fitting.</p>\n\n<p>@tom has covered the most commonly used techniques. The only thing I will add is  using larger sample size. Sometime this can be achieve cheaply by using data augmentation techniques (i.e. image rotation etc).  </p>\n<p>In general simpler models are more robust to noise in the input.  The strength of neural networks is also their biggest 'gotcha' - they are extremely expressive. This means they easily overfit and can be sensitive to noise in inputs.  The strategy of simplifying a model to make it more robust to noise is called regularization.  There are many types:</p>\n\n<ul>\n<li>use smaller hidden layers (i.e. 20 instead of 200 nodes)</li>\n<li>use dropout, where during training inputs are randomly set to 0 during training (makes the network more robust to noise overall)</li>\n<li>stop training earlier - 'early stopping'</li>\n<li>use L1 or L2 regularization, which imposes a cost on the weights</li>\n</ul>\n\n<p>All of these can be done from with Keras.  You want to make your network more robust to noise without decreasing your validation quality.  To do this, I would try the above suggestions in order.  You can measure overfitting by looking at the difference between predictive accuracy on your training data and validation data.  If they are very different - your model has learned structure in your training data that is not in your validation that is NOT what you want.  Try to fiddle regularization nobs until (1) your train-validation AUC or accuracy is very similar, (2) your validation AUC/accuracy is still sufficiently high.</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "24728",
                "question_votes:": "6",
                "question_text:": "<p>Let's say we have a neural network with one input neuron and one output neuron. The training data $(x, f(x))$ is generated by a process</p>\n\n<p>$$f(x) = ax + \\mathcal{N}(b, c)$$</p>\n\n<p>with $a, b, c \\in \\mathbb{R}^+$, e.g. something like</p>\n\n<pre><code>feature  | target\n-----------------\n0             0.0\n0             1.0\n0             1.5\n0            -1.2\n0            -0.9\n...\n</code></pre>\n\n<p>I know that neural networks can deal pretty well with labeling errors in classification problems. Meaning if you have a large dataset and a couple of examples have the wrong label, they get basically ignored.</p>\n\n<p>But for this kind of problem I'm not too sure. A first experiment indicates that they do smooth values.</p>\n\n<p><strong>Are there choices in architecture / training which help the smoothing / averaging / removal of noise?</strong></p>\n\n<h2>What I tried</h2>\n\n<p>I created a network which can solve this kind of regression problem without noise. It gets a MSE of about <code>0.0005</code>. When I add a bit of noise to the training set only, I get an MSE of <code>0.001</code>:</p>\n\n<pre><code>#!/usr/bin/env python\n\n# core modules\nimport random\n\n# 3rd party modules\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n\ndef main(add_noise=True):\n    # Get data\n    xs, ys = create_data_points(10000)\n    x_train, x_test, y_train, y_test = train_test_split(xs, ys, test_size=0.20)\n\n    # Add noise to training data\n    if add_noise:\n        noise = np.random.normal(0, 0.1, len(x_train))\n        x_train = x_train + noise\n\n    # Create model\n    model = create_model()\n    model.compile(optimizer='rmsprop',\n                  loss='mse',\n                  metrics=['mse'])\n\n    # Fit model to data.\n    model.fit(x_train, y_train, epochs=10, batch_size=32, verbose=1)\n\n    # Evaluate\n    y_pred = model.predict(x_test, batch_size=100).flatten()\n    print(\"MSE on test set:\")\n    print(((y_pred - y_test)**2).sum() / len(y_test))\n\n\ndef create_data_points(nb_points):\n    xs = []\n    ys = []\n    for i in range(nb_points):\n        x = random.random()\n        xs.append(x)\n        ys.append(2 * x)\n    return np.array(xs), np.array(ys)\n\n\ndef create_model(input_dim=1, output_dim=1):\n    model = Sequential()\n    model.add(Dense(200, input_dim=input_dim, activation='relu'))\n    model.add(Dense(200, input_dim=input_dim, activation='relu'))\n    model.add(Dense(output_dim, activation='linear'))\n    return model\n\n\nif __name__ == '__main__':\n    main()\n</code></pre>\n\n<h2>Outliers</h2>\n\n<p>In an earlier version of this question I wrote \"outlier\" when I meant \"label noise\". For outliers, there is:</p>\n\n<ul>\n<li><a href=\"http://www.scialert.net/fulltext/?doi=jas.2005.1394.1398&amp;org=11\" rel=\"noreferrer\">The Effects of Outliers Data on Neural Network Performance</a></li>\n</ul>\n",
                "tags": "<neural-network><regression><noise>",
                "answers": [
                    [
                        "24743",
                        "2",
                        "24728",
                        "",
                        "",
                        "<blockquote>\n  <p>I know that neural networks can deal pretty well with outliers.</p>\n</blockquote>\n\n<p>Not necessarily. </p>\n\n<p>It depends on your loss function and sample size. </p>\n\n<p>In linear regression, the loss function is MSE. MSE is not robust against outliers, so linear regression is not robust against outliers. Having larger sample will mitigate the impact of a outliers. </p>\n\n<p>Same principles applies to neural network.</p>\n\n<blockquote>\n  <p>Are there choices in architecture / training which help the smoothing / averaging / removal of noise?</p>\n</blockquote>\n\n<p>That's just the problem of over fitting.</p>\n\n<p>@tom has covered the most commonly used techniques. The only thing I will add is  using larger sample size. Sometime this can be achieve cheaply by using data augmentation techniques (i.e. image rotation etc).  </p>\n",
                        "",
                        "4"
                    ],
                    [
                        "24732",
                        "2",
                        "24728",
                        "",
                        "",
                        "<p>In general simpler models are more robust to noise in the input.  The strength of neural networks is also their biggest 'gotcha' - they are extremely expressive. This means they easily overfit and can be sensitive to noise in inputs.  The strategy of simplifying a model to make it more robust to noise is called regularization.  There are many types:</p>\n\n<ul>\n<li>use smaller hidden layers (i.e. 20 instead of 200 nodes)</li>\n<li>use dropout, where during training inputs are randomly set to 0 during training (makes the network more robust to noise overall)</li>\n<li>stop training earlier - 'early stopping'</li>\n<li>use L1 or L2 regularization, which imposes a cost on the weights</li>\n</ul>\n\n<p>All of these can be done from with Keras.  You want to make your network more robust to noise without decreasing your validation quality.  To do this, I would try the above suggestions in order.  You can measure overfitting by looking at the difference between predictive accuracy on your training data and validation data.  If they are very different - your model has learned structure in your training data that is not in your validation that is NOT what you want.  Try to fiddle regularization nobs until (1) your train-validation AUC or accuracy is very similar, (2) your validation AUC/accuracy is still sufficiently high.</p>\n",
                        "",
                        "7"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8236",
            "_score": 10.866505,
            "_source": {
                "title": "Logistic regression if 3 categories in outcome variable",
                "content": "Logistic regression if 3 categories in outcome variable <p>Logistic regression is generally performed if there are 2 categories in outcome variables. I just tried it for iris dataset with species as y variable which has 3 categories. I used following code: </p>\n\n<pre><code>import pandas as pd\nimport matplotlib.pylab as plt\n\nfrom sklearn.linear_model import LogisticRegression\nclf = LogisticRegression()\n\nfrom sklearn import datasets\niris = datasets.load_iris() \n\nclf.fit(iris.data, iris.target)\nlogcoefdf = pd.DataFrame(data=clf.coef_, \n     columns=[\"SL\", \"SW\", \"PL\", \"PW\"], \n     index=['setosa','versicolor','virginica'])\nprint(logcoefdf)\nlogcoefdf.plot.bar()\nplt.show()\n</code></pre>\n\n<p>The printout and plot of coefficients is as follows: </p>\n\n<pre><code>                  SL        SW        PL        PW\nsetosa      0.414988  1.461297 -2.262141 -1.029095\nversicolor  0.416640 -1.600833  0.577658 -1.385538\nvirginica  -1.707525 -1.534268  2.470972  2.555382\n</code></pre>\n\n<p>(I have labelled rows by names of species but I am not sure if this is correct).</p>\n\n<p>From above output I get following plot: </p>\n\n<p><a href=\"https://i.stack.imgur.com/Zj84C.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Zj84C.png\" alt=\"enter image description here\"></a></p>\n\n<p>What is the interpretation of these results? Does it mean that petal length (PL) is lowest in setosa and highest in virginica group? And both sepal width and petal width are less in versicolor species? Thanks for your insight.</p>\n\n<p>Edit: \nIf I use only 2 categories of iris dataset, I get only one set of coefficients: </p>\n\n<pre><code>clf.fit(iris.data[0:100,:], iris.target[0:100])\nprint(clf.coef_)\n</code></pre>\n\n<p>Output: </p>\n\n<pre><code>[[-0.40731745 -1.46092371  2.24004724  1.00841492]]\n</code></pre>\n\n<p>Is it that Logistic regression is being performed for all possible combinations of categories, i.e. setosa vs versicolor, versicolor vs virginica and virginica vs setosa?</p>\n <logistic-regression><categorical-data><p>Logistic regression can work on multi-class. Frankly it is not big different from binary classifier. The question is how does it find the coefficients for each class which you had displayed. By default to find the coefficients for a single class, it goes with <code>one vs rest combination</code>. So <code>setosa</code> vs remaining all classes. It gets coefficients iteratively by minimizing cross entropy. So ultimately you will end up with a matrix having a size of <code>n_classes vs features</code>.</p>\n\n<p>Coming to the interpretation part of the question. To interpret the importance of a single feature, you can do it as - <em>Given the coefficients of every other feature to be same (in comparing a class with another) including intercept, the class that has the feature with highest coefficient has greater chance of engulfing the new point.</em> This being said the features having <code>high petal length and width</code> and <code>low sepal length and width</code> contribute good for a data point to belong to class <code>virginica</code>. But it does not make much sense to interpret each coefficient individually. Hope I made some sense.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "30303",
                "question_votes:": "1",
                "question_text:": "<p>Logistic regression is generally performed if there are 2 categories in outcome variables. I just tried it for iris dataset with species as y variable which has 3 categories. I used following code: </p>\n\n<pre><code>import pandas as pd\nimport matplotlib.pylab as plt\n\nfrom sklearn.linear_model import LogisticRegression\nclf = LogisticRegression()\n\nfrom sklearn import datasets\niris = datasets.load_iris() \n\nclf.fit(iris.data, iris.target)\nlogcoefdf = pd.DataFrame(data=clf.coef_, \n     columns=[\"SL\", \"SW\", \"PL\", \"PW\"], \n     index=['setosa','versicolor','virginica'])\nprint(logcoefdf)\nlogcoefdf.plot.bar()\nplt.show()\n</code></pre>\n\n<p>The printout and plot of coefficients is as follows: </p>\n\n<pre><code>                  SL        SW        PL        PW\nsetosa      0.414988  1.461297 -2.262141 -1.029095\nversicolor  0.416640 -1.600833  0.577658 -1.385538\nvirginica  -1.707525 -1.534268  2.470972  2.555382\n</code></pre>\n\n<p>(I have labelled rows by names of species but I am not sure if this is correct).</p>\n\n<p>From above output I get following plot: </p>\n\n<p><a href=\"https://i.stack.imgur.com/Zj84C.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Zj84C.png\" alt=\"enter image description here\"></a></p>\n\n<p>What is the interpretation of these results? Does it mean that petal length (PL) is lowest in setosa and highest in virginica group? And both sepal width and petal width are less in versicolor species? Thanks for your insight.</p>\n\n<p>Edit: \nIf I use only 2 categories of iris dataset, I get only one set of coefficients: </p>\n\n<pre><code>clf.fit(iris.data[0:100,:], iris.target[0:100])\nprint(clf.coef_)\n</code></pre>\n\n<p>Output: </p>\n\n<pre><code>[[-0.40731745 -1.46092371  2.24004724  1.00841492]]\n</code></pre>\n\n<p>Is it that Logistic regression is being performed for all possible combinations of categories, i.e. setosa vs versicolor, versicolor vs virginica and virginica vs setosa?</p>\n",
                "tags": "<logistic-regression><categorical-data>",
                "answers": [
                    [
                        "30314",
                        "2",
                        "30303",
                        "",
                        "",
                        "<p>Logistic regression can work on multi-class. Frankly it is not big different from binary classifier. The question is how does it find the coefficients for each class which you had displayed. By default to find the coefficients for a single class, it goes with <code>one vs rest combination</code>. So <code>setosa</code> vs remaining all classes. It gets coefficients iteratively by minimizing cross entropy. So ultimately you will end up with a matrix having a size of <code>n_classes vs features</code>.</p>\n\n<p>Coming to the interpretation part of the question. To interpret the importance of a single feature, you can do it as - <em>Given the coefficients of every other feature to be same (in comparing a class with another) including intercept, the class that has the feature with highest coefficient has greater chance of engulfing the new point.</em> This being said the features having <code>high petal length and width</code> and <code>low sepal length and width</code> contribute good for a data point to belong to class <code>virginica</code>. But it does not make much sense to interpret each coefficient individually. Hope I made some sense.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13612",
            "_score": 10.787824,
            "_source": {
                "title": "amount of data required for a good ann mdel",
                "content": "amount of data required for a good ann mdel <p>I am new to deep learning and started with ANN. I have a dataset with 15 parameters and 2100 rows. r2_score with Multi linear regression and random forest models is around 85% but when i try an ANN with this dataset r2_score is very less, around 32% . Is it because the number of rows are less? If so atleast what number of rows are required to go for ANN. I have added the code too for reference</p>\n\n<pre><code>import pandas as pd\n\ndataset = pd.read_csv('chiller-2_runningdata_withcommon_parameters.csv')\n\ndataset = dataset.drop(['DateTime','delta','KWH','RunStatus','OP Hours'], axis=1)\n\nX = dataset.iloc[:,:-1 ].values\ny = dataset.iloc[:,15:16].values\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\n\nsc_X = StandardScaler()\n\nsc_Y = StandardScaler()\n\nX_train = sc_X.fit_transform(X_train)\n\nX_test = sc_X.transform(X_test)\n\ny_train = sc_Y.fit_transform(y_train)\n\n# Importing the Keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = 15))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform'))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nclassifier.fit(X_train, y_train, batch_size = 32, epochs = 500)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = sc_Y.inverse_transform(y_pred)\ny_pred_train = classifier.predict(X_train)\ny_pred_train = sc_Y.inverse_transform(y_pred_train)\ny_train = sc_Y.inverse_transform(y_train)\n\n\n#calculate r2_score\nfrom sklearn.metrics import r2_score\nscore_train = r2_score(y_pred_train,y_train)\nscore_test = r2_score(y_pred,y_test)\n</code></pre>\n <machine-learning><neural-network><dataset><regression><p>You seem to use a loss function for classification problems, binary crossentropy, for a regression problem.</p>\n\n<p>Try to change your compile function to something like</p>\n\n<pre><code>model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n</code></pre>\n\n<p>Also, you can change your fit function to</p>\n\n<pre><code>model.fit(X_train, y_train, epochs=500, validation_data=(X_test, y_test), verbose=2)\n</code></pre>\n\n<p>to track your accuracy during training. This might help you detect overfitting and change the amount of epochs accordingly.</p>\n\n<p>Don't worry about your amount of data, try understanding the difference between classification and regression problems instead.</p>\n<p>You are using a classification loss function for a regression task.\nThis makes a huge difference as <strong>classification error and regression errors are not the same.</strong></p>\n\n<p>Let me give a brief example:</p>\n\n<p>If you had to predict the demand of a commodity for the coming month, its very unlikely that you would be 100% correct. <strong>You would be close</strong> but not 100% right. </p>\n\n<p>If you are 100% correct, then you have a <strong>high accuracy</strong> because you predicted it exactly as it must be. A classification loss function would learn that you classified the value right. <strong>Hence a high accuracy !</strong></p>\n\n<p>But if you if you are close but not exactly right, <strong>the accuracy is zero.</strong>\nYou know it that you are close to the answer , but the classification theories will infer as a poor performing model.</p>\n\n<p><strong>Regression allows this as , the job is to be as close to the prediction as possible.</strong></p>\n\n<p>This is where MSE is preffered over cross-entropy in regression. Because of the intuition it holds.</p>\n\n<p>I would suggest you to dig more into this ( My example would be very naive , sorry ) about loss functions of regression and classification. That would help alot!</p>\n\n<p>I hope you get me.\nCheers!</p>\n",
                "codes": [
                    [
                        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
                        "model.fit(X_train, y_train, epochs=500, validation_data=(X_test, y_test), verbose=2)\n"
                    ],
                    []
                ],
                "question_id:": "46368",
                "question_votes:": "",
                "question_text:": "<p>I am new to deep learning and started with ANN. I have a dataset with 15 parameters and 2100 rows. r2_score with Multi linear regression and random forest models is around 85% but when i try an ANN with this dataset r2_score is very less, around 32% . Is it because the number of rows are less? If so atleast what number of rows are required to go for ANN. I have added the code too for reference</p>\n\n<pre><code>import pandas as pd\n\ndataset = pd.read_csv('chiller-2_runningdata_withcommon_parameters.csv')\n\ndataset = dataset.drop(['DateTime','delta','KWH','RunStatus','OP Hours'], axis=1)\n\nX = dataset.iloc[:,:-1 ].values\ny = dataset.iloc[:,15:16].values\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\n\nsc_X = StandardScaler()\n\nsc_Y = StandardScaler()\n\nX_train = sc_X.fit_transform(X_train)\n\nX_test = sc_X.transform(X_test)\n\ny_train = sc_Y.fit_transform(y_train)\n\n# Importing the Keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = 15))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform'))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nclassifier.fit(X_train, y_train, batch_size = 32, epochs = 500)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = sc_Y.inverse_transform(y_pred)\ny_pred_train = classifier.predict(X_train)\ny_pred_train = sc_Y.inverse_transform(y_pred_train)\ny_train = sc_Y.inverse_transform(y_train)\n\n\n#calculate r2_score\nfrom sklearn.metrics import r2_score\nscore_train = r2_score(y_pred_train,y_train)\nscore_test = r2_score(y_pred,y_test)\n</code></pre>\n",
                "tags": "<machine-learning><neural-network><dataset><regression>",
                "answers": [
                    [
                        "46395",
                        "2",
                        "46368",
                        "",
                        "",
                        "<p>You seem to use a loss function for classification problems, binary crossentropy, for a regression problem.</p>\n\n<p>Try to change your compile function to something like</p>\n\n<pre><code>model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n</code></pre>\n\n<p>Also, you can change your fit function to</p>\n\n<pre><code>model.fit(X_train, y_train, epochs=500, validation_data=(X_test, y_test), verbose=2)\n</code></pre>\n\n<p>to track your accuracy during training. This might help you detect overfitting and change the amount of epochs accordingly.</p>\n\n<p>Don't worry about your amount of data, try understanding the difference between classification and regression problems instead.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "46441",
                        "2",
                        "46368",
                        "",
                        "",
                        "<p>You are using a classification loss function for a regression task.\nThis makes a huge difference as <strong>classification error and regression errors are not the same.</strong></p>\n\n<p>Let me give a brief example:</p>\n\n<p>If you had to predict the demand of a commodity for the coming month, its very unlikely that you would be 100% correct. <strong>You would be close</strong> but not 100% right. </p>\n\n<p>If you are 100% correct, then you have a <strong>high accuracy</strong> because you predicted it exactly as it must be. A classification loss function would learn that you classified the value right. <strong>Hence a high accuracy !</strong></p>\n\n<p>But if you if you are close but not exactly right, <strong>the accuracy is zero.</strong>\nYou know it that you are close to the answer , but the classification theories will infer as a poor performing model.</p>\n\n<p><strong>Regression allows this as , the job is to be as close to the prediction as possible.</strong></p>\n\n<p>This is where MSE is preffered over cross-entropy in regression. Because of the intuition it holds.</p>\n\n<p>I would suggest you to dig more into this ( My example would be very naive , sorry ) about loss functions of regression and classification. That would help alot!</p>\n\n<p>I hope you get me.\nCheers!</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "372",
            "_score": 10.726979,
            "_source": {
                "title": "Stochastic gradient descent based on vector operations?",
                "content": "Stochastic gradient descent based on vector operations? <p>let's assume that I want to train a stochastic gradient descent regression algorithm using a dataset that has N samples. Since the size of the dataset is fixed, I will reuse the data T times. At each iteration or \"epoch\", I use each training sample exactly once after randomly reordering the whole training set.</p>\n\n<p>My implementation is based on Python and Numpy. Therefore, using vector operations can remarkably decrease computation time. Coming up with a vectorized implementation of batch gradient descent is quite straightforward. However, in the case of stochastic gradient descent I can not figure out how to avoid the outer loop that iterates through all the samples at each epoch.</p>\n\n<p>Does anybody know any vectorized implementation of stochastic gradient descent? </p>\n\n<p><strong>EDIT</strong>: I've been asked why would I like to use online gradient descent if the size of my dataset is fixed. </p>\n\n<p>From [1], one can see that online gradient descent converges slower than batch gradient descent to the minimum of the empirical cost. However, it converges faster to the minimum of the expected cost, which measures generalization performance. I'd like to test the impact of these theoretical results in my particular problem, by means of cross validation. Without a vectorized implementation, my online gradient descent code is much slower than the batch gradient descent one. That remarkably increases the time it takes to the cross validation process to be completed.</p>\n\n<p><strong>EDIT</strong>: I include here the pseudocode of my on-line gradient descent implementation, as requested by ffriend. I am solving a regression problem.</p>\n\n<pre><code>Method: on-line gradient descent (regression)\nInput: X (nxp matrix; each line contains a training sample, represented as a length-p vector), Y (length-n vector; output of the training samples)\nOutput: A (length-p+1 vector of coefficients)\n\nInitialize coefficients (assign value 0 to all coefficients)\nCalculate outputs F\nprev_error = inf\nerror = sum((F-Y)^2)/n\nit = 0\nwhile abs(error - prev_error)&gt;ERROR_THRESHOLD and it&lt;=MAX_ITERATIONS:\n    Randomly shuffle training samples\n    for each training sample i:\n        Compute error for training sample i\n        Update coefficients based on the error above\n    prev_error = error\n    Calculate outputs F\n    error = sum((F-Y)^2)/n\n    it = it + 1\n</code></pre>\n\n<p>[1] \"Large Scale Online Learning\", L. Bottou, Y. Le Cunn, NIPS 2003.</p>\n <python><gradient-descent><regression><p>Check out the partial_fit method of <a href=\"http://scikit-learn.org/0.15/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier\" rel=\"nofollow\">scikit's SGD classifier</a>. You have control over what you call with it: you can do it \"true\" online learning by passing an instance at a time, or you can batch up instances into mini-batches if all your data are available in an array. If they are, you can slice the array to provide the minibatches.</p>\n<p>First of all, word \"sample\" is normally used to describe <a href=\"http://en.wikipedia.org/wiki/Sample_%28statistics%29\"><em>subset</em> of population</a>, so I will refer to the same thing as \"example\". </p>\n\n<p>Your SGD implementation is slow because of this line: </p>\n\n<pre><code>for each training example i:\n</code></pre>\n\n<p>Here you explicitly use exactly one example for each update of model parameters. By definition, vectorization is a technique for converting operations on one element into operations on a vector of such elements. Thus, no, you cannot process examples one by one and still use vectorization. </p>\n\n<p>You can, however, approximate true SGD by using <strong>mini-batches</strong>. Mini-batch is a small subset of original dataset (say, 100 examples). You calculate error and parameter updates based on mini-batches, but you still iterate over many of them without global optimization, making the process stochastic. So, to make your implementation much faster it's enough to change previous line to: </p>\n\n<pre><code>batches = split dataset into mini-batches\nfor batch in batches: \n</code></pre>\n\n<p>and calculate error from batch, not from a single example. </p>\n\n<p>Though pretty obvious, I should also mention vectorization on per-example level. That is, instead of something like this: </p>\n\n<pre><code>theta = np.array([...])  # parameter vector\nx = np.array([...])      # example\ny = 0                    # predicted response\nfor i in range(len(example)):\n    y += x[i] * theta[i]\nerror = (true_y - y) ** 2  # true_y - true value of response\n</code></pre>\n\n<p>you should definitely do something like this: </p>\n\n<pre><code>error = (true_y - sum(np.dot(x, theta))) ** 2\n</code></pre>\n\n<p>which, again, easy to generalize for mini-batches:</p>\n\n<pre><code>true_y = np.array([...])     # vector of response values\nX = np.array([[...], [...]]) # mini-batch\nerrors = true_y - sum(np.dot(X, theta), 1)\nerror = sum(e ** 2 for e in errors)\n</code></pre>\n",
                "codes": [
                    [],
                    [
                        "for each training example i:\n",
                        "batches = split dataset into mini-batches\nfor batch in batches: \n",
                        "theta = np.array([...])  # parameter vector\nx = np.array([...])      # example\ny = 0                    # predicted response\nfor i in range(len(example)):\n    y += x[i] * theta[i]\nerror = (true_y - y) ** 2  # true_y - true value of response\n",
                        "error = (true_y - sum(np.dot(x, theta))) ** 2\n",
                        "true_y = np.array([...])     # vector of response values\nX = np.array([[...], [...]]) # mini-batch\nerrors = true_y - sum(np.dot(X, theta), 1)\nerror = sum(e ** 2 for e in errors)\n"
                    ]
                ],
                "question_id:": "1246",
                "question_votes:": "9",
                "question_text:": "<p>let's assume that I want to train a stochastic gradient descent regression algorithm using a dataset that has N samples. Since the size of the dataset is fixed, I will reuse the data T times. At each iteration or \"epoch\", I use each training sample exactly once after randomly reordering the whole training set.</p>\n\n<p>My implementation is based on Python and Numpy. Therefore, using vector operations can remarkably decrease computation time. Coming up with a vectorized implementation of batch gradient descent is quite straightforward. However, in the case of stochastic gradient descent I can not figure out how to avoid the outer loop that iterates through all the samples at each epoch.</p>\n\n<p>Does anybody know any vectorized implementation of stochastic gradient descent? </p>\n\n<p><strong>EDIT</strong>: I've been asked why would I like to use online gradient descent if the size of my dataset is fixed. </p>\n\n<p>From [1], one can see that online gradient descent converges slower than batch gradient descent to the minimum of the empirical cost. However, it converges faster to the minimum of the expected cost, which measures generalization performance. I'd like to test the impact of these theoretical results in my particular problem, by means of cross validation. Without a vectorized implementation, my online gradient descent code is much slower than the batch gradient descent one. That remarkably increases the time it takes to the cross validation process to be completed.</p>\n\n<p><strong>EDIT</strong>: I include here the pseudocode of my on-line gradient descent implementation, as requested by ffriend. I am solving a regression problem.</p>\n\n<pre><code>Method: on-line gradient descent (regression)\nInput: X (nxp matrix; each line contains a training sample, represented as a length-p vector), Y (length-n vector; output of the training samples)\nOutput: A (length-p+1 vector of coefficients)\n\nInitialize coefficients (assign value 0 to all coefficients)\nCalculate outputs F\nprev_error = inf\nerror = sum((F-Y)^2)/n\nit = 0\nwhile abs(error - prev_error)&gt;ERROR_THRESHOLD and it&lt;=MAX_ITERATIONS:\n    Randomly shuffle training samples\n    for each training sample i:\n        Compute error for training sample i\n        Update coefficients based on the error above\n    prev_error = error\n    Calculate outputs F\n    error = sum((F-Y)^2)/n\n    it = it + 1\n</code></pre>\n\n<p>[1] \"Large Scale Online Learning\", L. Bottou, Y. Le Cunn, NIPS 2003.</p>\n",
                "tags": "<python><gradient-descent><regression>",
                "answers": [
                    [
                        "2265",
                        "2",
                        "1246",
                        "",
                        "",
                        "<p>Check out the partial_fit method of <a href=\"http://scikit-learn.org/0.15/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier\" rel=\"nofollow\">scikit's SGD classifier</a>. You have control over what you call with it: you can do it \"true\" online learning by passing an instance at a time, or you can batch up instances into mini-batches if all your data are available in an array. If they are, you can slice the array to provide the minibatches.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "2515",
                        "2",
                        "1246",
                        "",
                        "",
                        "<p>First of all, word \"sample\" is normally used to describe <a href=\"http://en.wikipedia.org/wiki/Sample_%28statistics%29\"><em>subset</em> of population</a>, so I will refer to the same thing as \"example\". </p>\n\n<p>Your SGD implementation is slow because of this line: </p>\n\n<pre><code>for each training example i:\n</code></pre>\n\n<p>Here you explicitly use exactly one example for each update of model parameters. By definition, vectorization is a technique for converting operations on one element into operations on a vector of such elements. Thus, no, you cannot process examples one by one and still use vectorization. </p>\n\n<p>You can, however, approximate true SGD by using <strong>mini-batches</strong>. Mini-batch is a small subset of original dataset (say, 100 examples). You calculate error and parameter updates based on mini-batches, but you still iterate over many of them without global optimization, making the process stochastic. So, to make your implementation much faster it's enough to change previous line to: </p>\n\n<pre><code>batches = split dataset into mini-batches\nfor batch in batches: \n</code></pre>\n\n<p>and calculate error from batch, not from a single example. </p>\n\n<p>Though pretty obvious, I should also mention vectorization on per-example level. That is, instead of something like this: </p>\n\n<pre><code>theta = np.array([...])  # parameter vector\nx = np.array([...])      # example\ny = 0                    # predicted response\nfor i in range(len(example)):\n    y += x[i] * theta[i]\nerror = (true_y - y) ** 2  # true_y - true value of response\n</code></pre>\n\n<p>you should definitely do something like this: </p>\n\n<pre><code>error = (true_y - sum(np.dot(x, theta))) ** 2\n</code></pre>\n\n<p>which, again, easy to generalize for mini-batches:</p>\n\n<pre><code>true_y = np.array([...])     # vector of response values\nX = np.array([[...], [...]]) # mini-batch\nerrors = true_y - sum(np.dot(X, theta), 1)\nerror = sum(e ** 2 for e in errors)\n</code></pre>\n",
                        "",
                        "10"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14246",
            "_score": 10.704806,
            "_source": {
                "title": "What are the ways to partition a large file that does not fit into memory so it can later be fed as training data?",
                "content": "What are the ways to partition a large file that does not fit into memory so it can later be fed as training data? <p>Is there any other way to partition a large file that does not fit into memory so it can be fed as training data other than using spark? or hadoop?</p>\n <machine-learning><bigdata><p>Yes, of cause. But, it's insignificant, because Spark and Hadoop are better.</p>\n\n<p>This is my idea. Suppose that your memory can take in 100,000 examples. So splitting your data set to files with size lower than 100,000.</p>\n\n<p>The key and most complex step is how to train classify with those data. Good luck, For Gradient descent series optimization algorithms (GB, SGD and so on), most algorithms (SVM, GBDT, Bayes, LR, deeplearn and so on) support this. You could \n load one file to RAM and fed them to classifier until to find the best parameter. </p>\n\n<p>My code is very simple. Before each iteration, re-shuffling the order of simples and re-splitting data set will boost the classifier.</p>\n\n<pre class=\"lang-python prettyprint-override\"><code>import numpy as np\n\nX = np.random.random((100, 2))\ny = [1 if x[0] &gt; x[1] else 0 for x in X]\n\nfrom sklearn.linear_model import LogisticRegression\n\nlr_cly = LogisticRegression()\n\ndef stop_train(X_s, y_s, threshold):\n    scores = [gnb.score(X, y) for X, y in zip(X_s, y_s)]\n    return np.mean(scores) &gt; threshold\n\ndef iter_train(cly, X, y, threshold=0.99, max_iter=10):\n    X_s = [X[:50, :], X[50:, :]]\n    y_s = [y[:50], y[50:]]\n\n    iter_times = 0\n    while iter_times &lt;= max_iter:\n        print \"--------------\"\n        for X, y in zip(X_s, y_s):\n            cly.fit(X, y)\n            print cly.score(X, y)\n        if stop_train(X_s, y_s, threshold):\n            break\n        iter_times += 1\n\niter_train(lr_cly, X, y)\n</code></pre>\n",
                "codes": [
                    [
                        "import numpy as np\n\nX = np.random.random((100, 2))\ny = [1 if x[0] > x[1] else 0 for x in X]\n\nfrom sklearn.linear_model import LogisticRegression\n\nlr_cly = LogisticRegression()\n\ndef stop_train(X_s, y_s, threshold):\n    scores = [gnb.score(X, y) for X, y in zip(X_s, y_s)]\n    return np.mean(scores) > threshold\n\ndef iter_train(cly, X, y, threshold=0.99, max_iter=10):\n    X_s = [X[:50, :], X[50:, :]]\n    y_s = [y[:50], y[50:]]\n\n    iter_times = 0\n    while iter_times <= max_iter:\n        print \"--------------\"\n        for X, y in zip(X_s, y_s):\n            cly.fit(X, y)\n            print cly.score(X, y)\n        if stop_train(X_s, y_s, threshold):\n            break\n        iter_times += 1\n\niter_train(lr_cly, X, y)\n"
                    ]
                ],
                "question_id:": "48054",
                "question_votes:": "1",
                "question_text:": "<p>Is there any other way to partition a large file that does not fit into memory so it can be fed as training data other than using spark? or hadoop?</p>\n",
                "tags": "<machine-learning><bigdata>",
                "answers": [
                    [
                        "48077",
                        "2",
                        "48054",
                        "",
                        "",
                        "<p>Yes, of cause. But, it's insignificant, because Spark and Hadoop are better.</p>\n\n<p>This is my idea. Suppose that your memory can take in 100,000 examples. So splitting your data set to files with size lower than 100,000.</p>\n\n<p>The key and most complex step is how to train classify with those data. Good luck, For Gradient descent series optimization algorithms (GB, SGD and so on), most algorithms (SVM, GBDT, Bayes, LR, deeplearn and so on) support this. You could \n load one file to RAM and fed them to classifier until to find the best parameter. </p>\n\n<p>My code is very simple. Before each iteration, re-shuffling the order of simples and re-splitting data set will boost the classifier.</p>\n\n<pre class=\"lang-python prettyprint-override\"><code>import numpy as np\n\nX = np.random.random((100, 2))\ny = [1 if x[0] &gt; x[1] else 0 for x in X]\n\nfrom sklearn.linear_model import LogisticRegression\n\nlr_cly = LogisticRegression()\n\ndef stop_train(X_s, y_s, threshold):\n    scores = [gnb.score(X, y) for X, y in zip(X_s, y_s)]\n    return np.mean(scores) &gt; threshold\n\ndef iter_train(cly, X, y, threshold=0.99, max_iter=10):\n    X_s = [X[:50, :], X[50:, :]]\n    y_s = [y[:50], y[50:]]\n\n    iter_times = 0\n    while iter_times &lt;= max_iter:\n        print \"--------------\"\n        for X, y in zip(X_s, y_s):\n            cly.fit(X, y)\n            print cly.score(X, y)\n        if stop_train(X_s, y_s, threshold):\n            break\n        iter_times += 1\n\niter_train(lr_cly, X, y)\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16411",
            "_score": 10.693784,
            "_source": {
                "title": "Similarity score: Can Sklearn SVR predict values greater than 1 and less than 0?",
                "content": "Similarity score: Can Sklearn SVR predict values greater than 1 and less than 0? <p>I am using <code>svm.SVR()</code> from scikit-learn to apply Logistic Regression on my training data to solve a similarity problem. Using GridSearchCV, I am finding the best hyper parameters using the scoring as \"R2\". The best hyperparameters are <code>C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.001, gamma=0.005, kernel='rbf', shrinking=True, tol=0.001</code>.</p>\n\n<p>I fit the training data and training label as <code>model.fit(X_train, Y_train)</code></p>\n\n<p>Now I use test data in the same model as: <code>prediction = model.predict(X_test)</code></p>\n\n<p>The reason I am using SVM-Regression is to find similarity between two inputs. However, for some of the test data, the prediction contains value in negative (less than 0) and for all the same vs same comparison it returns the value as 1.09469178. I am expecting the value to be between 0 and 1. Is this normal or am I doing something wrong?</p>\n <python><scikit-learn><regression><similarity><blockquote>\n  <p>I am using svm.SVR() from scikit-learn to apply Logistic Regression on my training data to solve similarity problem.</p>\n</blockquote>\n\n<p>Wait a second, if you're using support-vector regression, then you're <em>not</em> using logistic regression.  These two are very different algorithms.  They aren't even applicable to the same type of problem.  Support-vector regression is used when you are predicting a continuous target, whereas logistic regression (despite the name) is a classification algorithm.</p>\n\n<blockquote>\n  <p>However, for some of the test data, the prediction contains value in negative (less than 0) and for all the same vs same comparison it returns the value as 1.09469178.</p>\n</blockquote>\n\n<p>There's nothing unusual about this if you're using support-vector regression.  A support-vector machine can (in theory) output any real number.</p>\n\n<p>Logistic regression, on the other hand, is a <a href=\"https://en.wikipedia.org/wiki/Sigmoid_function\" rel=\"nofollow noreferrer\">sigmoid function</a>.  It will take as input any real number and output a result between 0 and 1.  Maybe you meant to use scikit's <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">LogisticRegression</a> model rather than SVR?</p>\n\n<blockquote>\n  <p>The reason I am using SVM-Regression is to find similarity between two inputs.</p>\n</blockquote>\n\n<p>Could you expound on your use-case a bit more?  Support-vector regression isn't really meant to be used to compute similarity.</p>\n\n<p>I'm speculating that you have a training set of (X, y) pairs (where y is a label between 0 and 1).  You are training a model to output <span class=\"math-container\">$\\hat{y}$</span>, a prediction of y.  To find the similarity of two inputs, <span class=\"math-container\">$X_i$</span> and <span class=\"math-container\">$X_j$</span>, you pass them both through the model and measure the difference in the <span class=\"math-container\">$\\hat{y}_i$</span> and <span class=\"math-container\">$\\hat{y}_j$</span>.  Is that right?</p>\n\n<p>If so, I think this is a really roundabout way of computing similarity, and is unlikely to yield better results that a more straightforward method.  I'm not sure that you need a machine learning algorithm at all.</p>\n\n<p>Have you looked into other similarity metrics that might be suitable for your problem?  For similarity based on Euclidean distance, you can compute <span class=\"math-container\">$\\frac{1}{1 + d(X_i, X_j)}$</span> (where <span class=\"math-container\">$d$</span> is the euclidean distance function).  <a href=\"https://en.wikipedia.org/wiki/Cosine_similarity\" rel=\"nofollow noreferrer\">Cosine similarity</a> might be a good choice if you care more about the similarity in direction of two input vectors.</p>\n<p>This is normal: unless your training data covers the population very well, the test set is bound to contain instances which slightly deviate from the cases seen in the training data. With any regression method, this might cause predicted values to go slightly out of range. If the application requires normalized values, these deviations should be programmatically corrected post-process (i.e. anything negative changed to 0 and anything higher than 1 changed to 1).</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "54026",
                "question_votes:": "2",
                "question_text:": "<p>I am using <code>svm.SVR()</code> from scikit-learn to apply Logistic Regression on my training data to solve a similarity problem. Using GridSearchCV, I am finding the best hyper parameters using the scoring as \"R2\". The best hyperparameters are <code>C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.001, gamma=0.005, kernel='rbf', shrinking=True, tol=0.001</code>.</p>\n\n<p>I fit the training data and training label as <code>model.fit(X_train, Y_train)</code></p>\n\n<p>Now I use test data in the same model as: <code>prediction = model.predict(X_test)</code></p>\n\n<p>The reason I am using SVM-Regression is to find similarity between two inputs. However, for some of the test data, the prediction contains value in negative (less than 0) and for all the same vs same comparison it returns the value as 1.09469178. I am expecting the value to be between 0 and 1. Is this normal or am I doing something wrong?</p>\n",
                "tags": "<python><scikit-learn><regression><similarity>",
                "answers": [
                    [
                        "54031",
                        "2",
                        "54026",
                        "",
                        "",
                        "<blockquote>\n  <p>I am using svm.SVR() from scikit-learn to apply Logistic Regression on my training data to solve similarity problem.</p>\n</blockquote>\n\n<p>Wait a second, if you're using support-vector regression, then you're <em>not</em> using logistic regression.  These two are very different algorithms.  They aren't even applicable to the same type of problem.  Support-vector regression is used when you are predicting a continuous target, whereas logistic regression (despite the name) is a classification algorithm.</p>\n\n<blockquote>\n  <p>However, for some of the test data, the prediction contains value in negative (less than 0) and for all the same vs same comparison it returns the value as 1.09469178.</p>\n</blockquote>\n\n<p>There's nothing unusual about this if you're using support-vector regression.  A support-vector machine can (in theory) output any real number.</p>\n\n<p>Logistic regression, on the other hand, is a <a href=\"https://en.wikipedia.org/wiki/Sigmoid_function\" rel=\"nofollow noreferrer\">sigmoid function</a>.  It will take as input any real number and output a result between 0 and 1.  Maybe you meant to use scikit's <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">LogisticRegression</a> model rather than SVR?</p>\n\n<blockquote>\n  <p>The reason I am using SVM-Regression is to find similarity between two inputs.</p>\n</blockquote>\n\n<p>Could you expound on your use-case a bit more?  Support-vector regression isn't really meant to be used to compute similarity.</p>\n\n<p>I'm speculating that you have a training set of (X, y) pairs (where y is a label between 0 and 1).  You are training a model to output <span class=\"math-container\">$\\hat{y}$</span>, a prediction of y.  To find the similarity of two inputs, <span class=\"math-container\">$X_i$</span> and <span class=\"math-container\">$X_j$</span>, you pass them both through the model and measure the difference in the <span class=\"math-container\">$\\hat{y}_i$</span> and <span class=\"math-container\">$\\hat{y}_j$</span>.  Is that right?</p>\n\n<p>If so, I think this is a really roundabout way of computing similarity, and is unlikely to yield better results that a more straightforward method.  I'm not sure that you need a machine learning algorithm at all.</p>\n\n<p>Have you looked into other similarity metrics that might be suitable for your problem?  For similarity based on Euclidean distance, you can compute <span class=\"math-container\">$\\frac{1}{1 + d(X_i, X_j)}$</span> (where <span class=\"math-container\">$d$</span> is the euclidean distance function).  <a href=\"https://en.wikipedia.org/wiki/Cosine_similarity\" rel=\"nofollow noreferrer\">Cosine similarity</a> might be a good choice if you care more about the similarity in direction of two input vectors.</p>\n",
                        "",
                        "4"
                    ],
                    [
                        "54030",
                        "2",
                        "54026",
                        "",
                        "",
                        "<p>This is normal: unless your training data covers the population very well, the test set is bound to contain instances which slightly deviate from the cases seen in the training data. With any regression method, this might cause predicted values to go slightly out of range. If the application requires normalized values, these deviations should be programmatically corrected post-process (i.e. anything negative changed to 0 and anything higher than 1 changed to 1).</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14052",
            "_score": 10.669344,
            "_source": {
                "title": "neural network to find a very simple linear model (scikit-learn)",
                "content": "neural network to find a very simple linear model (scikit-learn) <p>I'm trying to test different machine learning algorithm to try to find correlation between various data on MRI scans.\nSince I'm dealing with medical data, I don't have access to many events, but still I'm trying to see what a simple fully connected NN while provides me.\nBy debugging, it looks like even if I enter the output almost as is in the input, a simple NN using the default scikit-learn NN regressor is unable to find a satisfactory model.\nI tried to reproduce the effect and I'd like to share with you the following code. I guess I'm just doing something wrong, because, basically, I'd like the NN to produce a simple model where label=X2-X1 and it doesn't work to me which is really surprising me.</p>\n\n<p>here is the code:</p>\n\n<pre><code>\nimport sklearn.neural_network as NN\nimport matplotlib.pyplot as plt\nimport numpy as np\nN_events=100000 # number of rows of dataset\nN_features = 2 # number of features\nX = np.random.rand(N_events,N_features) # chose the data randomly\nlabels = X[:,1]-X[:,0] # label = X2-X1\n\nC = NN.MLPRegressor(hidden_layer_sizes=(2,2),max_iter=500000,random_state=1) # very simple scikit-learn NN regressor\nn = N_events // 2 # half data for training, half for test\n\nprint(X[0:10,1]-X[0:10,0]) # check that indeed label=X2-X1\nprint(labels[0:10])\nC.fit( X[0:n,:] , labels[0:n]) # train the model\n\n# plot y_predicted vs y_true for the test set... \nplt.figure()\ny_real = labels[n:] # \ny_pred = C.predict(X[n:,:])\nplt.plot(y_real,y_pred,'.')\n\n# plot y_predicted vs y_true for the training set... even this doesn't work\nplt.figure()\ny_real = labels[0:n] # \ny_pred = C.predict(X[0:n,:])\nplt.plot(y_real,y_pred,'.')\n</code>\n</pre>\n\n<p>I was expecting the NN with 2x2 = 4 degrees of freedom to easily find such a simple model (note that I even don't add unused features which could <em>disturb</em> the fit, since N_features is 2 here), so I guess I'm just not using the code correctly.\nCan anyone helps me ?</p>\n\n<p>Many thanks</p>\n <neural-network><scikit-learn><linear-regression><p>The problem is <code>relu</code> which is the default activation function. It zeros the inputs smaller than 0. Problem will be solved by using other functions. For example:</p>\n\n<pre><code>C = NN.MLPRegressor(activation=\"identity\", hidden_layer_sizes=(1,1),max_iter=25,random_state=1)\n</code></pre>\n\n<p>Note that even 1 hidden layer with 1 neuron is enough to find the <span class=\"math-container\">$X_2 = X_1$</span> decision boundary.</p>\n",
                "codes": [
                    [
                        "C = NN.MLPRegressor(activation=\"identity\", hidden_layer_sizes=(1,1),max_iter=25,random_state=1)\n"
                    ]
                ],
                "question_id:": "47515",
                "question_votes:": "1",
                "question_text:": "<p>I'm trying to test different machine learning algorithm to try to find correlation between various data on MRI scans.\nSince I'm dealing with medical data, I don't have access to many events, but still I'm trying to see what a simple fully connected NN while provides me.\nBy debugging, it looks like even if I enter the output almost as is in the input, a simple NN using the default scikit-learn NN regressor is unable to find a satisfactory model.\nI tried to reproduce the effect and I'd like to share with you the following code. I guess I'm just doing something wrong, because, basically, I'd like the NN to produce a simple model where label=X2-X1 and it doesn't work to me which is really surprising me.</p>\n\n<p>here is the code:</p>\n\n<pre><code>\nimport sklearn.neural_network as NN\nimport matplotlib.pyplot as plt\nimport numpy as np\nN_events=100000 # number of rows of dataset\nN_features = 2 # number of features\nX = np.random.rand(N_events,N_features) # chose the data randomly\nlabels = X[:,1]-X[:,0] # label = X2-X1\n\nC = NN.MLPRegressor(hidden_layer_sizes=(2,2),max_iter=500000,random_state=1) # very simple scikit-learn NN regressor\nn = N_events // 2 # half data for training, half for test\n\nprint(X[0:10,1]-X[0:10,0]) # check that indeed label=X2-X1\nprint(labels[0:10])\nC.fit( X[0:n,:] , labels[0:n]) # train the model\n\n# plot y_predicted vs y_true for the test set... \nplt.figure()\ny_real = labels[n:] # \ny_pred = C.predict(X[n:,:])\nplt.plot(y_real,y_pred,'.')\n\n# plot y_predicted vs y_true for the training set... even this doesn't work\nplt.figure()\ny_real = labels[0:n] # \ny_pred = C.predict(X[0:n,:])\nplt.plot(y_real,y_pred,'.')\n</code>\n</pre>\n\n<p>I was expecting the NN with 2x2 = 4 degrees of freedom to easily find such a simple model (note that I even don't add unused features which could <em>disturb</em> the fit, since N_features is 2 here), so I guess I'm just not using the code correctly.\nCan anyone helps me ?</p>\n\n<p>Many thanks</p>\n",
                "tags": "<neural-network><scikit-learn><linear-regression>",
                "answers": [
                    [
                        "47527",
                        "2",
                        "47515",
                        "",
                        "",
                        "<p>The problem is <code>relu</code> which is the default activation function. It zeros the inputs smaller than 0. Problem will be solved by using other functions. For example:</p>\n\n<pre><code>C = NN.MLPRegressor(activation=\"identity\", hidden_layer_sizes=(1,1),max_iter=25,random_state=1)\n</code></pre>\n\n<p>Note that even 1 hidden layer with 1 neuron is enough to find the <span class=\"math-container\">$X_2 = X_1$</span> decision boundary.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8871",
            "_score": 10.662486,
            "_source": {
                "title": "Add noise to an example set",
                "content": "Add noise to an example set <p>I'm trying to study the effect of curse of dimensionality in classification algorithms.</p>\n\n<p>I have a simple dataset with only 1 feature. So i can represent the set in a 1 dimension.\nIf now i want to introduce some noise in this dataset, is it correct to add another feature with random values to my dataset ?</p>\n <machine-learning><classification><p>In addition to what Lupacante conceptually and nicely showed such that the added feature(s) has(have) to be informative for the model otherwise it can get ignored by majority of models (perhaps easily by regularized models), I would like add that you also increase the dimensionally of the feature space synthetically using many simple mathematical expressions as well. Concertedly, let's say your only feature (column) is: </p>\n\n<p><strong>x</strong></p>\n\n<p>You may easily construct other features like (it is common practice actually in physical sciences):</p>\n\n<p><strong>x$^2$</strong>, <strong>x$^3$</strong>, <strong>x$^{0.5}$</strong>, $sin(x)$, <strong>x$^2$sin(x)</strong>,...</p>\n\n<p>Till you hit the so-called <em>the curse of dimensionality</em> for your exercise. Although I am not yet sure what features/num_samples ratio exactly causes the curse of dimensionality! What I have gathered so far about the curse of dimensionality has been very subjective. </p>\n<p>The problem with adding an extra feature with random values is that, if it's uninformative (as it likely is, given that its values are all random), it might get ignored by your classifier.</p>\n\n<p>For example:</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom numpy import arange, random, array\n\nx1 = arange(100)\ny = 3 + 2*x1\nLinearRegression().fit(array([x1, x2]).T, y).coef_\n</code></pre>\n\n<p>returns <code>array([ 2.00000000e+00, -1.30768001e-15])</code>, meaning that the coefficient of the new feature (the one with random values) was practically set to $0$.</p>\n\n<p>What you could do is this:</p>\n\n<pre><code>x = arange(100)\ny = 3 + 2*x + random.randn(100)\n</code></pre>\n\n<p>Then, if you try plotting <code>y</code> against <code>x</code>, you'll see that the values don't lie on a perfectly straight line, but rather they deviate from it slightly (and randomly).</p>\n<p>It depends on what is understood as noise, since a noise source can be interpreted as any way of corrupting/altering the data.</p>\n\n<p>Technically, if you want to add noise to your dataset you can proceed as follows:</p>\n\n<ol>\n<li>Add noise to the raw data, i.e, corrupt the raw data with some noise distribution and with certain signal to noise ratio,</li>\n</ol>\n\n<p>or</p>\n\n<ol start=\"2\">\n<li>Add noise to the feature space, but keeping its dimension. </li>\n</ol>\n\n<p>Adding noise is not the same as changing the dimension of the feature space. If the data is linearly separable in the original feature space, it will be also separable although you add an extra random feature. Take a look at figure 1 and figure 2. Figure depicts the scatter plot (var1_1 vs var1_1) of a linear separable data in a one dimensional feature space. Figure 2 depicts the scatter plot of the same feature space with an extra random feature, now the dimension is 2, but the data is still linearly separable. You only have to look at the projection of the data in the var1_1 axis.</p>\n\n<p>Figure 1: Scatter plot of separable data in a 1-D feature space\n<a href=\"https://i.stack.imgur.com/mmkDz.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/mmkDz.png\" alt=\"Scatter plot of separable data in a 1-D feature space\"></a></p>\n\n<p>Figure 2:Scatter plot of separable data in a 2-D feature space, which is the same as the previous space plus an extra random feature\n[<img src=\"https://i.stack.imgur.com/mE9dw.png\" alt=\"Scatter plot of separable data in a 2-D feature space], which is the same as the previous space plus an extra random feature[2]\"></p>\n\n<p>If you want to evaluate the robustness of your prediction model against noise, I will take option 1, since it not straightforward to derive what kind of noise to apply in the feature space. If you are working with images, you can blur them or if you are dealing with audio files, you can add white gaussian noise, or another kind of noise source, for example another mixing the original audio files with other sound sources.</p>\n",
                "codes": [
                    [],
                    [
                        "from sklearn.linear_model import LinearRegression\nfrom numpy import arange, random, array\n\nx1 = arange(100)\ny = 3 + 2*x1\nLinearRegression().fit(array([x1, x2]).T, y).coef_\n",
                        "x = arange(100)\ny = 3 + 2*x + random.randn(100)\n"
                    ],
                    []
                ],
                "question_id:": "31980",
                "question_votes:": "2",
                "question_text:": "<p>I'm trying to study the effect of curse of dimensionality in classification algorithms.</p>\n\n<p>I have a simple dataset with only 1 feature. So i can represent the set in a 1 dimension.\nIf now i want to introduce some noise in this dataset, is it correct to add another feature with random values to my dataset ?</p>\n",
                "tags": "<machine-learning><classification>",
                "answers": [
                    [
                        "31983",
                        "2",
                        "31980",
                        "",
                        "",
                        "<p>In addition to what Lupacante conceptually and nicely showed such that the added feature(s) has(have) to be informative for the model otherwise it can get ignored by majority of models (perhaps easily by regularized models), I would like add that you also increase the dimensionally of the feature space synthetically using many simple mathematical expressions as well. Concertedly, let's say your only feature (column) is: </p>\n\n<p><strong>x</strong></p>\n\n<p>You may easily construct other features like (it is common practice actually in physical sciences):</p>\n\n<p><strong>x$^2$</strong>, <strong>x$^3$</strong>, <strong>x$^{0.5}$</strong>, $sin(x)$, <strong>x$^2$sin(x)</strong>,...</p>\n\n<p>Till you hit the so-called <em>the curse of dimensionality</em> for your exercise. Although I am not yet sure what features/num_samples ratio exactly causes the curse of dimensionality! What I have gathered so far about the curse of dimensionality has been very subjective. </p>\n",
                        "",
                        "2"
                    ],
                    [
                        "31981",
                        "2",
                        "31980",
                        "",
                        "",
                        "<p>The problem with adding an extra feature with random values is that, if it's uninformative (as it likely is, given that its values are all random), it might get ignored by your classifier.</p>\n\n<p>For example:</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom numpy import arange, random, array\n\nx1 = arange(100)\ny = 3 + 2*x1\nLinearRegression().fit(array([x1, x2]).T, y).coef_\n</code></pre>\n\n<p>returns <code>array([ 2.00000000e+00, -1.30768001e-15])</code>, meaning that the coefficient of the new feature (the one with random values) was practically set to $0$.</p>\n\n<p>What you could do is this:</p>\n\n<pre><code>x = arange(100)\ny = 3 + 2*x + random.randn(100)\n</code></pre>\n\n<p>Then, if you try plotting <code>y</code> against <code>x</code>, you'll see that the values don't lie on a perfectly straight line, but rather they deviate from it slightly (and randomly).</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "31984",
                        "2",
                        "31980",
                        "",
                        "",
                        "<p>It depends on what is understood as noise, since a noise source can be interpreted as any way of corrupting/altering the data.</p>\n\n<p>Technically, if you want to add noise to your dataset you can proceed as follows:</p>\n\n<ol>\n<li>Add noise to the raw data, i.e, corrupt the raw data with some noise distribution and with certain signal to noise ratio,</li>\n</ol>\n\n<p>or</p>\n\n<ol start=\"2\">\n<li>Add noise to the feature space, but keeping its dimension. </li>\n</ol>\n\n<p>Adding noise is not the same as changing the dimension of the feature space. If the data is linearly separable in the original feature space, it will be also separable although you add an extra random feature. Take a look at figure 1 and figure 2. Figure depicts the scatter plot (var1_1 vs var1_1) of a linear separable data in a one dimensional feature space. Figure 2 depicts the scatter plot of the same feature space with an extra random feature, now the dimension is 2, but the data is still linearly separable. You only have to look at the projection of the data in the var1_1 axis.</p>\n\n<p>Figure 1: Scatter plot of separable data in a 1-D feature space\n<a href=\"https://i.stack.imgur.com/mmkDz.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/mmkDz.png\" alt=\"Scatter plot of separable data in a 1-D feature space\"></a></p>\n\n<p>Figure 2:Scatter plot of separable data in a 2-D feature space, which is the same as the previous space plus an extra random feature\n[<img src=\"https://i.stack.imgur.com/mE9dw.png\" alt=\"Scatter plot of separable data in a 2-D feature space], which is the same as the previous space plus an extra random feature[2]\"></p>\n\n<p>If you want to evaluate the robustness of your prediction model against noise, I will take option 1, since it not straightforward to derive what kind of noise to apply in the feature space. If you are working with images, you can blur them or if you are dealing with audio files, you can add white gaussian noise, or another kind of noise source, for example another mixing the original audio files with other sound sources.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7395",
            "_score": 10.590332,
            "_source": {
                "title": "How to use GridSearchCV with RidgeClassifier",
                "content": "How to use GridSearchCV with RidgeClassifier <p>I'm trying to use <code>GridSearchCV</code> with <code>RidgeClassifier</code>, but I'm getting this error: </p>\n\n<p>My problem is <strong>regression</strong> type.</p>\n\n<blockquote>\n  <p>IndexError: too many indices for array</p>\n</blockquote>\n\n<p>I'm new to Machine Learning, please help me out.\nThis is the code I've been trying to implement: </p>\n\n<pre><code>from sklearn.grid_search import GridSearchCV\nfrom sklearn.metrics import classification_report\n\ntuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n                     'C': [1, 10, 100, 1000]},\n                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\nscores = ['precision', 'recall']\nalphas = np.array([1,0.1,0.01,0.001,0.0001,0])\nmodel = RidgeClassifier(normalize=True, random_state=100, tol=0.1)\nfor score in scores:\n    clf = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n    clf.fit(X, Y)\n    print(\"Best parameters set found on development set:\")\n    print(clf.best_params_)\n    for params, mean_score, scores in clf.grid_scores_:\n        print(\"%0.3f (+/-%0.03f) for %r\"\n              % (mean_score, scores.std() * 2, params))\n</code></pre>\n\n<p>This is the complete error log: </p>\n\n<pre><code>---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\n&lt;ipython-input-59-c97c7e0fc6f3&gt; in &lt;module&gt;()\n     12 for score in scores:\n     13     clf = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n---&gt; 14     clf.fit(X, Y)\n     15     print(\"Best parameters set found on development set:\")\n     16     print(clf.best_params_)\n\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc in fit(self, X, y)\n    836 \n    837         \"\"\"\n--&gt; 838         return self._fit(X, y, ParameterGrid(self.param_grid))\n    839 \n    840 \n\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc in _fit(self, X, y, parameter_iterable)\n    551                                  'of samples (%i) than data (X: %i samples)'\n    552                                  % (len(y), n_samples))\n--&gt; 553         cv = check_cv(cv, X, y, classifier=is_classifier(estimator))\n    554 \n    555         if self.verbose &gt; 0:\n\n/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc in check_cv(cv, X, y, classifier)\n   1833         if classifier:\n   1834             if type_of_target(y) in ['binary', 'multiclass']:\n-&gt; 1835                 cv = StratifiedKFold(y, cv)\n   1836             else:\n   1837                 cv = KFold(_num_samples(y), cv)\n\n/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc in __init__(self, y, n_folds, shuffle, random_state)\n    568         for test_fold_idx, per_label_splits in enumerate(zip(*per_label_cvs)):\n    569             for label, (_, test_split) in zip(unique_labels, per_label_splits):\n--&gt; 570                 label_test_folds = test_folds[y == label]\n    571                 # the test split can be too big because we used\n    572                 # KFold(max(c, self.n_folds), self.n_folds) instead of\n\nIndexError: too many indices for array\n</code></pre>\n <python><scikit-learn><grid-search><p>The problem is that Y has shape <code>(15780,1)</code>. The shape of Y should show <code>(15780,)</code>. The explanation for this is a bit long, so I just give here the links-</p>\n\n<p><a href=\"https://stackoverflow.com/questions/22053050/difference-between-numpy-array-shape-r-1-and-r\">Difference between shapes (R,1) and (R,)</a></p>\n\n<p><a href=\"https://stackoverflow.com/questions/31995175/scikit-learn-cross-val-score-too-many-indices-for-array\">Solution for IndexError: too many indices for array</a></p>\n",
                "codes": [
                    []
                ],
                "question_id:": "27704",
                "question_votes:": "",
                "question_text:": "<p>I'm trying to use <code>GridSearchCV</code> with <code>RidgeClassifier</code>, but I'm getting this error: </p>\n\n<p>My problem is <strong>regression</strong> type.</p>\n\n<blockquote>\n  <p>IndexError: too many indices for array</p>\n</blockquote>\n\n<p>I'm new to Machine Learning, please help me out.\nThis is the code I've been trying to implement: </p>\n\n<pre><code>from sklearn.grid_search import GridSearchCV\nfrom sklearn.metrics import classification_report\n\ntuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n                     'C': [1, 10, 100, 1000]},\n                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\nscores = ['precision', 'recall']\nalphas = np.array([1,0.1,0.01,0.001,0.0001,0])\nmodel = RidgeClassifier(normalize=True, random_state=100, tol=0.1)\nfor score in scores:\n    clf = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n    clf.fit(X, Y)\n    print(\"Best parameters set found on development set:\")\n    print(clf.best_params_)\n    for params, mean_score, scores in clf.grid_scores_:\n        print(\"%0.3f (+/-%0.03f) for %r\"\n              % (mean_score, scores.std() * 2, params))\n</code></pre>\n\n<p>This is the complete error log: </p>\n\n<pre><code>---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\n&lt;ipython-input-59-c97c7e0fc6f3&gt; in &lt;module&gt;()\n     12 for score in scores:\n     13     clf = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n---&gt; 14     clf.fit(X, Y)\n     15     print(\"Best parameters set found on development set:\")\n     16     print(clf.best_params_)\n\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc in fit(self, X, y)\n    836 \n    837         \"\"\"\n--&gt; 838         return self._fit(X, y, ParameterGrid(self.param_grid))\n    839 \n    840 \n\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc in _fit(self, X, y, parameter_iterable)\n    551                                  'of samples (%i) than data (X: %i samples)'\n    552                                  % (len(y), n_samples))\n--&gt; 553         cv = check_cv(cv, X, y, classifier=is_classifier(estimator))\n    554 \n    555         if self.verbose &gt; 0:\n\n/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc in check_cv(cv, X, y, classifier)\n   1833         if classifier:\n   1834             if type_of_target(y) in ['binary', 'multiclass']:\n-&gt; 1835                 cv = StratifiedKFold(y, cv)\n   1836             else:\n   1837                 cv = KFold(_num_samples(y), cv)\n\n/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc in __init__(self, y, n_folds, shuffle, random_state)\n    568         for test_fold_idx, per_label_splits in enumerate(zip(*per_label_cvs)):\n    569             for label, (_, test_split) in zip(unique_labels, per_label_splits):\n--&gt; 570                 label_test_folds = test_folds[y == label]\n    571                 # the test split can be too big because we used\n    572                 # KFold(max(c, self.n_folds), self.n_folds) instead of\n\nIndexError: too many indices for array\n</code></pre>\n",
                "tags": "<python><scikit-learn><grid-search>",
                "answers": [
                    [
                        "27721",
                        "2",
                        "27704",
                        "",
                        "",
                        "<p>The problem is that Y has shape <code>(15780,1)</code>. The shape of Y should show <code>(15780,)</code>. The explanation for this is a bit long, so I just give here the links-</p>\n\n<p><a href=\"https://stackoverflow.com/questions/22053050/difference-between-numpy-array-shape-r-1-and-r\">Difference between shapes (R,1) and (R,)</a></p>\n\n<p><a href=\"https://stackoverflow.com/questions/31995175/scikit-learn-cross-val-score-too-many-indices-for-array\">Solution for IndexError: too many indices for array</a></p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7666",
            "_score": 10.586785,
            "_source": {
                "title": "Train new data to pre-trained model",
                "content": "Train new data to pre-trained model <p>Let's say I've trained my model and made my predictions. </p>\n\n<p>My question is... How can I append some new data to my pre-trained model without retrain the model from the beginning.</p>\n <machine-learning><python><deep-learning><p>I would say it depends upon the ML framework you are using. I have worked on Scikit and Tensorflow.</p>\n\n<p>Both works in a different way.</p>\n\n<p><strong>Scikit:</strong> </p>\n\n<ol>\n<li>partial_fit() is one way. If we call partial_fit() multiple times,\nframework will update the existing weights instead of\nre-initializing it again.</li>\n<li>warm_state is another way which is provided by many algo. For\nexample RandomForestRegressor(), it will add new estimators(new\ntress) which gets trained with new data we pass to it. Refer <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\" rel=\"nofollow noreferrer\">Scikit\nlink for more explanation</a></li>\n</ol>\n\n<p><strong>Tensorflow</strong>: Consider a basic TF code as mentioned below:</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.preprocessing import StandardScaler\nhousing = fetch_california_housing()\nm, n = housing.data.shape\ntarget = housing.target.reshape(-1,1)\nscaler = StandardScaler()\nscaled_housing_data = scaler.fit_transform(housing.data)\nhousing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\nn_epochs = 1000\nlearning_rate = 0.01\nX = tf.placeholder(shape = (None, n+1), dtype=tf.float32, name=\"X\")\ny = tf.placeholder(shape=(None,1), dtype=tf.float32, name=\"y\")\ntheta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\ny_pred = tf.matmul(X, theta, name=\"predictions\")\nerror = y_pred - y\nmse = tf.reduce_mean(tf.square(error), name=\"mse\")\ngradients = 2/m * tf.matmul(tf.transpose(X), error)\ntraining_op = tf.assign(theta, theta - learning_rate * gradients)\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    for epoch in range(n_epochs):\n        fn,wights, loss, pred, op = sess.run((error, theta, mse, y_pred,training_op), feed_dict={X:housing_data_plus_bias, y:target})\n        print(loss)\n    best_theta = theta.eval()\n    print(best_theta)\n</code></pre>\n\n<p>Consider I have trained and deployed this model(as a tf.saver() object). Now if I want to predict new values I have to feed my model with new <strong>X values</strong> and identify <strong>\"y_pred\".</strong>.\nThis process will not update my <strong>theta</strong>(weights) values(tensor graph, evaluate its dependent tensors only) and for prediction model will use existing <strong>theta</strong>.\nIn case I want to update <strong>theta</strong>, using the new samples, I have to evaluate <strong>training_op</strong>. </p>\n\n<p>In this way we can improve TF model later with the new data. </p>\n\n<p>Note: <strong>training_op</strong>, has a dependency on <strong>theta</strong> and <strong>gradient</strong>.</p>\n<p>I cannot comment yet. If you just load the model and use a fit method it will update the weights, not reinstance all the weights. It will just perform a number of weights update that you can chose, using the new data.</p>\n<p>It all depends on the specific algorithm you're using. Some of them support incremental learning, while others don't.</p>\n\n<p>For example, in the case of sci-kit learn, using <code>fit()</code> more than once on the same model will simply overwrite the model's weights each time (see <a href=\"http://scikit-learn.org/stable/tutorial/basic/tutorial.html#refitting-and-updating-parameters\" rel=\"nofollow noreferrer\">here</a> for more details). </p>\n\n<p>What you can do however, is look for algorithms that implement the <code>partial_fit</code> api, and use this to retrain your existing models - see <a href=\"http://scikit-learn.org/stable/modules/scaling_strategies.html#incremental-learning\" rel=\"nofollow noreferrer\">the documentation</a> for a list of algorithms that support incremental learning and thus implement this api.</p>\n\n<p>An alternative solution is to look for algorithms that support the <code>warm_start</code> parameter, e.g. <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">LogisticRegression</a>. Note that <code>warm_start</code> might also be influenced by other parameters, so you need to pay attention to their values, too - e.g. in the case of LogisticRegression, <code>warm_start</code> won't work if you use the <code>liblinear</code> solver (which is the default).</p>\n",
                "codes": [
                    [
                        "import numpy as np\nimport tensorflow as tf\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.preprocessing import StandardScaler\nhousing = fetch_california_housing()\nm, n = housing.data.shape\ntarget = housing.target.reshape(-1,1)\nscaler = StandardScaler()\nscaled_housing_data = scaler.fit_transform(housing.data)\nhousing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\nn_epochs = 1000\nlearning_rate = 0.01\nX = tf.placeholder(shape = (None, n+1), dtype=tf.float32, name=\"X\")\ny = tf.placeholder(shape=(None,1), dtype=tf.float32, name=\"y\")\ntheta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\ny_pred = tf.matmul(X, theta, name=\"predictions\")\nerror = y_pred - y\nmse = tf.reduce_mean(tf.square(error), name=\"mse\")\ngradients = 2/m * tf.matmul(tf.transpose(X), error)\ntraining_op = tf.assign(theta, theta - learning_rate * gradients)\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    for epoch in range(n_epochs):\n        fn,wights, loss, pred, op = sess.run((error, theta, mse, y_pred,training_op), feed_dict={X:housing_data_plus_bias, y:target})\n        print(loss)\n    best_theta = theta.eval()\n    print(best_theta)\n"
                    ],
                    [],
                    []
                ],
                "question_id:": "28512",
                "question_votes:": "3",
                "question_text:": "<p>Let's say I've trained my model and made my predictions. </p>\n\n<p>My question is... How can I append some new data to my pre-trained model without retrain the model from the beginning.</p>\n",
                "tags": "<machine-learning><python><deep-learning>",
                "answers": [
                    [
                        "53431",
                        "2",
                        "28512",
                        "",
                        "",
                        "<p>I would say it depends upon the ML framework you are using. I have worked on Scikit and Tensorflow.</p>\n\n<p>Both works in a different way.</p>\n\n<p><strong>Scikit:</strong> </p>\n\n<ol>\n<li>partial_fit() is one way. If we call partial_fit() multiple times,\nframework will update the existing weights instead of\nre-initializing it again.</li>\n<li>warm_state is another way which is provided by many algo. For\nexample RandomForestRegressor(), it will add new estimators(new\ntress) which gets trained with new data we pass to it. Refer <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\" rel=\"nofollow noreferrer\">Scikit\nlink for more explanation</a></li>\n</ol>\n\n<p><strong>Tensorflow</strong>: Consider a basic TF code as mentioned below:</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.preprocessing import StandardScaler\nhousing = fetch_california_housing()\nm, n = housing.data.shape\ntarget = housing.target.reshape(-1,1)\nscaler = StandardScaler()\nscaled_housing_data = scaler.fit_transform(housing.data)\nhousing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\nn_epochs = 1000\nlearning_rate = 0.01\nX = tf.placeholder(shape = (None, n+1), dtype=tf.float32, name=\"X\")\ny = tf.placeholder(shape=(None,1), dtype=tf.float32, name=\"y\")\ntheta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\ny_pred = tf.matmul(X, theta, name=\"predictions\")\nerror = y_pred - y\nmse = tf.reduce_mean(tf.square(error), name=\"mse\")\ngradients = 2/m * tf.matmul(tf.transpose(X), error)\ntraining_op = tf.assign(theta, theta - learning_rate * gradients)\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    for epoch in range(n_epochs):\n        fn,wights, loss, pred, op = sess.run((error, theta, mse, y_pred,training_op), feed_dict={X:housing_data_plus_bias, y:target})\n        print(loss)\n    best_theta = theta.eval()\n    print(best_theta)\n</code></pre>\n\n<p>Consider I have trained and deployed this model(as a tf.saver() object). Now if I want to predict new values I have to feed my model with new <strong>X values</strong> and identify <strong>\"y_pred\".</strong>.\nThis process will not update my <strong>theta</strong>(weights) values(tensor graph, evaluate its dependent tensors only) and for prediction model will use existing <strong>theta</strong>.\nIn case I want to update <strong>theta</strong>, using the new samples, I have to evaluate <strong>training_op</strong>. </p>\n\n<p>In this way we can improve TF model later with the new data. </p>\n\n<p>Note: <strong>training_op</strong>, has a dependency on <strong>theta</strong> and <strong>gradient</strong>.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "28517",
                        "2",
                        "28512",
                        "",
                        "",
                        "<p>I cannot comment yet. If you just load the model and use a fit method it will update the weights, not reinstance all the weights. It will just perform a number of weights update that you can chose, using the new data.</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "38709",
                        "2",
                        "28512",
                        "",
                        "",
                        "<p>It all depends on the specific algorithm you're using. Some of them support incremental learning, while others don't.</p>\n\n<p>For example, in the case of sci-kit learn, using <code>fit()</code> more than once on the same model will simply overwrite the model's weights each time (see <a href=\"http://scikit-learn.org/stable/tutorial/basic/tutorial.html#refitting-and-updating-parameters\" rel=\"nofollow noreferrer\">here</a> for more details). </p>\n\n<p>What you can do however, is look for algorithms that implement the <code>partial_fit</code> api, and use this to retrain your existing models - see <a href=\"http://scikit-learn.org/stable/modules/scaling_strategies.html#incremental-learning\" rel=\"nofollow noreferrer\">the documentation</a> for a list of algorithms that support incremental learning and thus implement this api.</p>\n\n<p>An alternative solution is to look for algorithms that support the <code>warm_start</code> parameter, e.g. <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">LogisticRegression</a>. Note that <code>warm_start</code> might also be influenced by other parameters, so you need to pay attention to their values, too - e.g. in the case of LogisticRegression, <code>warm_start</code> won't work if you use the <code>liblinear</code> solver (which is the default).</p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17395",
            "_score": 10.562616,
            "_source": {
                "title": "Multilabel classification for a learning to rank application",
                "content": "Multilabel classification for a learning to rank application <p>I am looking for some suggestions on Learning to Rank method for search engines. I created a dataset with the following data:</p>\n\n<pre><code>query_dependent_score, independent_score, (query_dependent_score*independent_score), classification_label\n</code></pre>\n\n<p><code>query_dependent_score</code> is the TF-IDF score i.e. similarity b/w query and a document.</p>\n\n<p><code>independent_score</code> is the viewing time of the document.</p>\n\n<p>There are going to be 3 classes:</p>\n\n<ul>\n<li>0 (not relevant),</li>\n<li>1 (kind of relevant),</li>\n<li>2 (most relevant)</li>\n</ul>\n\n<p>I have a total of 750 queries and I collected top 10 results of each, so I have a total of 7500 data points.</p>\n\n<p>I have been thinking of estimating a relevance function like:</p>\n\n<pre><code>w0 + w1*query_dependent_score + w2*independent_score + w3*(query_dependent_score*independent_score)\n</code></pre>\n\n<p>I can clearly see this is like a classification problem but I wanted some info on whether this is right way to approach this problem.</p>\n\n<p>I referred to <a href=\"https://datascience.stackexchange.com/questions/12101/machine-learning-technique-to-calculate-weighted-average-weights\">Machine learning technique to calculate weighted average weights?</a> for some ideas.</p>\n\n<p>Following is the code that I have written:</p>\n\n<pre><code>from sklearn.linear_model import LogisticRegression\nimport numpy as np\n\nDATASET_PATH = \"...\"\n\nsearch_data = np.genfromtxt(DATASET_PATH, delimiter=',', skip_header=1, usecols=(1, 2, 3, 4))\ndocument_grades = search_data[:, 3:4]\ndocument_signals = search_data[:, :3]  # This has 3 features.\n\ntotal_rows = np.shape(search_data)[0]\nsplit_point = int(total_rows * 0.8)\n\ntraining_data_X, test_data_X = document_signals[:split_point, :], document_signals[split_point:, :]\ntraining_data_y, test_data_y = document_grades[:split_point, :], document_grades[split_point:, :]\n\nclf = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n\nclf.fit(X=training_data_X, y=training_data_y.ravel())\n\nprint(clf.classes_)  # [0, 1, 2]\nprint(clf.coef_)  # This is a 3 x 3 matrix?\nprint(clf.intercept_)  # An array of 3 elements?\n</code></pre>\n\n<p>Based on the <code>sklearn</code>'s documentation <code>coef_</code> should give me the values of <code>w1</code>, <code>w2</code> and <code>w3</code>, and <code>intercept_</code> should give me the value of <code>w0</code>.</p>\n\n<p>But I have a matrix and an array for those weights. I am not sure how to get the values of the weights for the relevance function?</p>\n\n<p>I am looking into learning to rank for the first time, so any suggestions are welcome.</p>\n <scikit-learn><learning-to-rank><p>In the <code>multinomial</code> mode, the docs specify that the outputs of <code>coef_</code> and <code>intercept_</code> are as you are seeing them: one output for each target class. The underlying model is three logistic regressions, whose outputs are softmax'ed (or with mode <code>ovr</code>, simply normalized).</p>\n\n<p>As to the broader question, since your three output classes are ordered, you might benefit from using that information. Either just perform regression (assumes that the numeric 0,1,2 are meaningful) or use \"ordinal regression.\"</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "56129",
                "question_votes:": "1",
                "question_text:": "<p>I am looking for some suggestions on Learning to Rank method for search engines. I created a dataset with the following data:</p>\n\n<pre><code>query_dependent_score, independent_score, (query_dependent_score*independent_score), classification_label\n</code></pre>\n\n<p><code>query_dependent_score</code> is the TF-IDF score i.e. similarity b/w query and a document.</p>\n\n<p><code>independent_score</code> is the viewing time of the document.</p>\n\n<p>There are going to be 3 classes:</p>\n\n<ul>\n<li>0 (not relevant),</li>\n<li>1 (kind of relevant),</li>\n<li>2 (most relevant)</li>\n</ul>\n\n<p>I have a total of 750 queries and I collected top 10 results of each, so I have a total of 7500 data points.</p>\n\n<p>I have been thinking of estimating a relevance function like:</p>\n\n<pre><code>w0 + w1*query_dependent_score + w2*independent_score + w3*(query_dependent_score*independent_score)\n</code></pre>\n\n<p>I can clearly see this is like a classification problem but I wanted some info on whether this is right way to approach this problem.</p>\n\n<p>I referred to <a href=\"https://datascience.stackexchange.com/questions/12101/machine-learning-technique-to-calculate-weighted-average-weights\">Machine learning technique to calculate weighted average weights?</a> for some ideas.</p>\n\n<p>Following is the code that I have written:</p>\n\n<pre><code>from sklearn.linear_model import LogisticRegression\nimport numpy as np\n\nDATASET_PATH = \"...\"\n\nsearch_data = np.genfromtxt(DATASET_PATH, delimiter=',', skip_header=1, usecols=(1, 2, 3, 4))\ndocument_grades = search_data[:, 3:4]\ndocument_signals = search_data[:, :3]  # This has 3 features.\n\ntotal_rows = np.shape(search_data)[0]\nsplit_point = int(total_rows * 0.8)\n\ntraining_data_X, test_data_X = document_signals[:split_point, :], document_signals[split_point:, :]\ntraining_data_y, test_data_y = document_grades[:split_point, :], document_grades[split_point:, :]\n\nclf = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n\nclf.fit(X=training_data_X, y=training_data_y.ravel())\n\nprint(clf.classes_)  # [0, 1, 2]\nprint(clf.coef_)  # This is a 3 x 3 matrix?\nprint(clf.intercept_)  # An array of 3 elements?\n</code></pre>\n\n<p>Based on the <code>sklearn</code>'s documentation <code>coef_</code> should give me the values of <code>w1</code>, <code>w2</code> and <code>w3</code>, and <code>intercept_</code> should give me the value of <code>w0</code>.</p>\n\n<p>But I have a matrix and an array for those weights. I am not sure how to get the values of the weights for the relevance function?</p>\n\n<p>I am looking into learning to rank for the first time, so any suggestions are welcome.</p>\n",
                "tags": "<scikit-learn><learning-to-rank>",
                "answers": [
                    [
                        "56175",
                        "2",
                        "56129",
                        "",
                        "",
                        "<p>In the <code>multinomial</code> mode, the docs specify that the outputs of <code>coef_</code> and <code>intercept_</code> are as you are seeing them: one output for each target class. The underlying model is three logistic regressions, whose outputs are softmax'ed (or with mode <code>ovr</code>, simply normalized).</p>\n\n<p>As to the broader question, since your three output classes are ordered, you might benefit from using that information. Either just perform regression (assumes that the numeric 0,1,2 are meaningful) or use \"ordinal regression.\"</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9346",
            "_score": 10.542789,
            "_source": {
                "title": "Vertical and horizontal lines appearing on large confusion matrix?",
                "content": "Vertical and horizontal lines appearing on large confusion matrix? <p>I have produced a large heatmap-like confusion matrix and am seeing horizontal and vertical lines on it, so I'm trying to determine:</p>\n\n<ol>\n<li>What they mean</li>\n<li>Why they are there</li>\n<li>How I can improve on this</li>\n</ol>\n\n<p><a href=\"https://i.stack.imgur.com/jVlSj.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/jVlSj.png\" alt=\"Confusion Matrix Heatmap\"></a></p>\n\n<hr>\n\n<p><strong>Approach</strong></p>\n\n<p>I am relatively new to ML and in the early stages of of a multi-class text classification problem.  I may be a little verbose so you can ensure I'm on track and my question isn't due to a flaw in my approach.</p>\n\n<p>I have 90,000+ samples that I'd like to be able to classify into one of 412 classes.  I've taken a basic look at the data in terms of its class distribution and the unigrams and bigrams that are selected for each class.  Continuing exploration, I trained 4 classifiers on the data, receiving the following levels of accuracy:</p>\n\n<pre><code>LinearSVC                 0.547190\nLogisticRegression        0.530063\nMultinomialNB             0.368121\nRandomForestClassifier    0.200568\n</code></pre>\n\n<p>Having had a lot of trouble plotting a confusion matrix this large with Seaborn or Matplotlib, I used used the following python code to produce a confusion matrix in CSV:</p>\n\n<pre><code>from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVC\n\ndef make_confusion_matrix(a,p,c):\n    cm = pd.DataFrame(0,index=c,columns=c)\n    for count in range(len(p)):\n        cm[int(a[count])][int(p[count])]+=1\n    return cm\n\ntfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\nfeatures = tfidf.fit_transform(df['DetailedDescription'])\n\nmodel = LinearSVC()\nX_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, df['BreakdownAgency'], df.index, test_size=0.33, random_state=0)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)    \n\ncm = make_confusion_matrix(y_test.tolist(),y_pred,labels_df['TOOCS Breakdown Agency'])\ncm.to_csv('ConfusionMatrix.csv')\n</code></pre>\n\n<p>I was finally able to view the confusion matrix in a heatmap style by using Excel conditional formatting, which produced the matrix above.</p>\n\n<p><strong>Interpretation</strong></p>\n\n<p>Given that the X axis is <em>actual</em> and y axis is <em>predicted</em>:</p>\n\n<p>I interpret the horizontal lines as showing incorrect bias of predictions towards a class with a disproportionately large number of samples?</p>\n\n<p>I interpret the vertical lines as showing incorrect predictions away from a class with a disproportionately large number of samples?</p>\n\n<p>Does this show that the model is both overfitting and underfitting the data?\nOr that the samples within my classes are overly diverse?</p>\n\n<p><strong>Action</strong></p>\n\n<p>I'm contemplating:</p>\n\n<ol>\n<li>Manually adding samples to the classes that have very few (a minimum of 10?).</li>\n<li>Using SMOTE to oversample small classes (knn=6).</li>\n<li>Potentially removing some samples that are atypical or incorrect.</li>\n</ol>\n\n<p>Any help on my <em>Interpretation</em> or <em>Action</em> would be greatly appreciated!</p>\n <python><scikit-learn><nlp><pandas><smote><p>If the $x$-axis is actual and the $y$-axis is predicted, then vertical lines means a given input of the class $x$ is not being discriminated sufficiently and as a result is randomly mapped to a number of classes. Whereas a horizontal line signifies that many classes are mapped as belonging to a particular class. </p>\n\n<h1>Class imbalance</h1>\n\n<p>Many reasons can lead to these lines in your confusion matrix. The most common is class imbalance. If you train your model using data that is not well balanced across the different classes this will result in both horizontal and vertical lines. Consider a model trained to distinguish cats, dogs and foxes with 1000, 1000, and 10 instances each. Evidently, you can see how many future instances of foxes may be classified as dogs or cats. </p>\n\n<p>You can remedy this by obtaining more data. This is often not possible, so you can try and weight the model to account for the class imbalance. You can do this by weighting the loss function. Or by oversampling the underrepresented class. Furthermore, you can try and synthesize new instances of the underrepresented class. This can be done with a GAN (hard, requires lots of data, unstable), or you can use k-NN type techniques to find out where the data is concentrated and add novel points to add density to this set. The new technique SMOTE is also highly recommended for its simplicity.</p>\n\n<h1>Overlapping distributions</h1>\n\n<p>Another big reason is a distribution that overlaps. This is when a class' distribution encompasses one or more class distributions. For example, if you are classifying between cats, dogs, shiba inu, corgi. You can see that any amount of training will always cause conflicts between the class dog and shiba inu, corgi. Since these are dogs. </p>\n\n<p>This problem is easy to distinguish for human perceptive classification, like images, but often times we are working with data where the span of these distributions is not as obvious. You can use clustering methods to see if certain classes fall within the distribution cloud of others. I use percent overlap as a metric for this task. </p>\n",
                "codes": [
                    []
                ],
                "question_id:": "33347",
                "question_votes:": "",
                "question_text:": "<p>I have produced a large heatmap-like confusion matrix and am seeing horizontal and vertical lines on it, so I'm trying to determine:</p>\n\n<ol>\n<li>What they mean</li>\n<li>Why they are there</li>\n<li>How I can improve on this</li>\n</ol>\n\n<p><a href=\"https://i.stack.imgur.com/jVlSj.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/jVlSj.png\" alt=\"Confusion Matrix Heatmap\"></a></p>\n\n<hr>\n\n<p><strong>Approach</strong></p>\n\n<p>I am relatively new to ML and in the early stages of of a multi-class text classification problem.  I may be a little verbose so you can ensure I'm on track and my question isn't due to a flaw in my approach.</p>\n\n<p>I have 90,000+ samples that I'd like to be able to classify into one of 412 classes.  I've taken a basic look at the data in terms of its class distribution and the unigrams and bigrams that are selected for each class.  Continuing exploration, I trained 4 classifiers on the data, receiving the following levels of accuracy:</p>\n\n<pre><code>LinearSVC                 0.547190\nLogisticRegression        0.530063\nMultinomialNB             0.368121\nRandomForestClassifier    0.200568\n</code></pre>\n\n<p>Having had a lot of trouble plotting a confusion matrix this large with Seaborn or Matplotlib, I used used the following python code to produce a confusion matrix in CSV:</p>\n\n<pre><code>from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVC\n\ndef make_confusion_matrix(a,p,c):\n    cm = pd.DataFrame(0,index=c,columns=c)\n    for count in range(len(p)):\n        cm[int(a[count])][int(p[count])]+=1\n    return cm\n\ntfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\nfeatures = tfidf.fit_transform(df['DetailedDescription'])\n\nmodel = LinearSVC()\nX_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, df['BreakdownAgency'], df.index, test_size=0.33, random_state=0)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)    \n\ncm = make_confusion_matrix(y_test.tolist(),y_pred,labels_df['TOOCS Breakdown Agency'])\ncm.to_csv('ConfusionMatrix.csv')\n</code></pre>\n\n<p>I was finally able to view the confusion matrix in a heatmap style by using Excel conditional formatting, which produced the matrix above.</p>\n\n<p><strong>Interpretation</strong></p>\n\n<p>Given that the X axis is <em>actual</em> and y axis is <em>predicted</em>:</p>\n\n<p>I interpret the horizontal lines as showing incorrect bias of predictions towards a class with a disproportionately large number of samples?</p>\n\n<p>I interpret the vertical lines as showing incorrect predictions away from a class with a disproportionately large number of samples?</p>\n\n<p>Does this show that the model is both overfitting and underfitting the data?\nOr that the samples within my classes are overly diverse?</p>\n\n<p><strong>Action</strong></p>\n\n<p>I'm contemplating:</p>\n\n<ol>\n<li>Manually adding samples to the classes that have very few (a minimum of 10?).</li>\n<li>Using SMOTE to oversample small classes (knn=6).</li>\n<li>Potentially removing some samples that are atypical or incorrect.</li>\n</ol>\n\n<p>Any help on my <em>Interpretation</em> or <em>Action</em> would be greatly appreciated!</p>\n",
                "tags": "<python><scikit-learn><nlp><pandas><smote>",
                "answers": [
                    [
                        "33349",
                        "2",
                        "33347",
                        "",
                        "",
                        "<p>If the $x$-axis is actual and the $y$-axis is predicted, then vertical lines means a given input of the class $x$ is not being discriminated sufficiently and as a result is randomly mapped to a number of classes. Whereas a horizontal line signifies that many classes are mapped as belonging to a particular class. </p>\n\n<h1>Class imbalance</h1>\n\n<p>Many reasons can lead to these lines in your confusion matrix. The most common is class imbalance. If you train your model using data that is not well balanced across the different classes this will result in both horizontal and vertical lines. Consider a model trained to distinguish cats, dogs and foxes with 1000, 1000, and 10 instances each. Evidently, you can see how many future instances of foxes may be classified as dogs or cats. </p>\n\n<p>You can remedy this by obtaining more data. This is often not possible, so you can try and weight the model to account for the class imbalance. You can do this by weighting the loss function. Or by oversampling the underrepresented class. Furthermore, you can try and synthesize new instances of the underrepresented class. This can be done with a GAN (hard, requires lots of data, unstable), or you can use k-NN type techniques to find out where the data is concentrated and add novel points to add density to this set. The new technique SMOTE is also highly recommended for its simplicity.</p>\n\n<h1>Overlapping distributions</h1>\n\n<p>Another big reason is a distribution that overlaps. This is when a class' distribution encompasses one or more class distributions. For example, if you are classifying between cats, dogs, shiba inu, corgi. You can see that any amount of training will always cause conflicts between the class dog and shiba inu, corgi. Since these are dogs. </p>\n\n<p>This problem is easy to distinguish for human perceptive classification, like images, but often times we are working with data where the span of these distributions is not as obvious. You can use clustering methods to see if certain classes fall within the distribution cloud of others. I use percent overlap as a metric for this task. </p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7984",
            "_score": 10.519481,
            "_source": {
                "title": "How to plot learning curve and validation curve while using pipeline",
                "content": "How to plot learning curve and validation curve while using pipeline <p>I would appreciate if you could let me know in the following example code:</p>\n\n<pre><code>from collections import Counter\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split,StratifiedKFold,learning_curve,validation_curve,GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_learning_curve(train_sizes, train_scores, test_scores, title, alpha=0.1):\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n    plt.plot(train_sizes, train_mean, label='train score', color='blue', marker='o')\n    plt.fill_between(train_sizes, train_mean + train_std,\n                     train_mean - train_std, color='blue', alpha=alpha)\n    plt.plot(train_sizes, test_mean, label='test score', color='red', marker='o')\n    plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, color='red', alpha=alpha)\n    plt.title(title)\n    plt.xlabel('Number of training points')\n    plt.ylabel('F-measure')\n    plt.grid(ls='--')\n    plt.legend(loc='best')\n    plt.show()\n\n\ndef plot_validation_curve(param_range, train_scores, test_scores, title, alpha=0.1):\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n    plt.plot(param_range, train_mean, label='train score', color='blue', marker='o')\n    plt.fill_between(param_range, train_mean + train_std,\n                     train_mean - train_std, color='blue', alpha=alpha)\n    plt.plot(param_range, test_mean, label='test score', color='red', marker='o')\n    plt.fill_between(param_range, test_mean + test_std, test_mean - test_std, color='red', alpha=alpha)\n    plt.title(title)\n    plt.grid(ls='--')\n    plt.xlabel('Parameter value')\n    plt.ylabel('F-measure')\n    plt.legend(loc='best')\n    plt.show()\n\nX, y = make_classification(n_classes=2, class_sep=2,weights=[0.9, 0.1], n_informative=3, n_redundant=1, flip_y=0, n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\nprint('Original dataset shape {}'.format(Counter(y)))\n\nln = X.shape\nnames = [\"x%s\" % i for i in range(1, ln[1] + 1)]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,random_state=0)\nst=StandardScaler()\n\nrg = LogisticRegression(class_weight = { 0:1, 1:6.5 }, random_state = 42, solver = 'saga',max_iter=100,n_jobs=-1)\n\nparam_grid = {'clf__C': [0.001,0.01,0.1,0.002,0.02,0.005,0.0007,.0006,0.0005],\n              'clf__class_weight':[{ 0:1, 1:6 },{ 0:1, 1:4 },{ 0:1, 1:5.5 },{ 0:1, 1:4.5 },{ 0:1, 1:5 }]\n              }\n\npipeline = Pipeline(steps=[('scaler', st),\n                           ('clf', rg )])\n\ncv=StratifiedKFold(n_splits=5,random_state=42)\nrg_cv = GridSearchCV(pipeline, param_grid, cv=cv, scoring =  'f1')\nrg_cv.fit(X_train, y_train)\nprint(\"Tuned rg best params: {}\".format(rg_cv.best_params_))\n\nypred = rg_cv.predict(X_train)\nprint(classification_report(y_train, ypred))\nprint('######################')\nypred2 = rg_cv.predict(X_test)\nprint(classification_report(y_test, ypred2))\n\nplt.figure(figsize=(9,6))\nparam_range1=[i / 10000.0 for i in range(1, 11)]\nparam_range2=[{0: 1, 1: 6}, {0: 1, 1: 4}, {0: 1, 1: 5.5}, {0: 1, 1: 4.5}, {0: 1, 1: 5}]\n\nif __name__ == '__main__':\n    train_sizes, train_scores, test_scores = learning_curve(\n              estimator= rg_cv.best_estimator_ , X= X_train, y = y_train,\n                train_sizes=np.arange(0.1,1.1,0.1), cv= cv,  scoring='f1', n_jobs= - 1)\n\n    plot_learning_curve(train_sizes, train_scores, test_scores, title='Learning curve for Logistic Regression')\n\n    train_scores, test_scores = validation_curve(\n        estimator=rg_cv.best_estimator_, X=X_train, y=y_train, param_name=\"clf__C\", param_range=param_range1,\n        cv=cv, scoring=\"f1\", n_jobs=-1)\n\n    plot_validation_curve(param_range1, train_scores, test_scores, title=\"Validation Curve for C\", alpha=0.1)\n\n    train_scores, test_scores = validation_curve(\n        estimator=rg_cv.best_estimator_, X=X_train, y=y_train, param_name=\"clf__class_weight\", param_range=param_range2,\n        cv=cv, scoring=\"f1\", n_jobs=-1)\n\n    plot_validation_curve(param_range2, train_scores, test_scores, title=\"Validation Curve for class_weight\", alpha=0.1)\n</code></pre>\n\n<ul>\n<li><p>Why when the  best estimator of GridSearchCv is passed into the learning curve function, it prints all the previous print lines several times?</p></li>\n<li><p>How to plot validation curve for class weight? <code>TypeError: float() argument must be a string or a number, not 'dict'</code></p></li>\n</ul>\n <classification><scikit-learn><p>With respect to the first and second question, the code should change into:</p>\n\n<pre><code>from collections import Counter\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, learning_curve, validation_curve, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef plot_learning_curve(train_sizes, train_scores, test_scores, title, alpha=0.1):\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n    plt.plot(train_sizes, train_mean, label='train score', color='blue', marker='o')\n    plt.fill_between(train_sizes, train_mean + train_std,\n                     train_mean - train_std, color='blue', alpha=alpha)\n    plt.plot(train_sizes, test_mean, label='test score', color='red', marker='o')\n\n    plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, color='red', alpha=alpha)\n    plt.title(title)\n    plt.xlabel('Number of training points')\n    plt.ylabel('F-measure')\n    plt.grid(ls='--')\n    plt.legend(loc='best')\n    plt.show()\n\n\ndef plot_validation_curve(param_range, train_scores, test_scores, title, alpha=0.1):\n    param_range = [x[1] for x in param_range] \n    sort_idx = np.argsort(param_range)\n    param_range=np.array(param_range)[sort_idx]\n    train_mean = np.mean(train_scores, axis=1)[sort_idx]\n    train_std = np.std(train_scores, axis=1)[sort_idx]\n    test_mean = np.mean(test_scores, axis=1)[sort_idx]\n    test_std = np.std(test_scores, axis=1)[sort_idx]\n    plt.plot(param_range, train_mean, label='train score', color='blue', marker='o')\n    plt.fill_between(param_range, train_mean + train_std,\n                 train_mean - train_std, color='blue', alpha=alpha)\n    plt.plot(param_range, test_mean, label='test score', color='red', marker='o')\n    plt.fill_between(param_range, test_mean + test_std, test_mean - test_std, color='red', alpha=alpha)\n    plt.title(title)\n    plt.grid(ls='--')\n    plt.xlabel('Weight of class 2')\n    plt.ylabel('Average values and standard deviation for F1-Score')\n    plt.legend(loc='best')\n    plt.show()\n\n\nif __name__ == '__main__':\n    X, y = make_classification(n_classes=2, class_sep=2, weights=[0.9, 0.1], n_informative=3, n_redundant=1, flip_y=0,\n                               n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\n    print('Original dataset shape {}'.format(Counter(y)))\n\n    ln = X.shape\n    names = [\"x%s\" % i for i in range(1, ln[1] + 1)]\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n    st = StandardScaler()\n\n    rg = LogisticRegression(class_weight={0: 1, 1: 6.5}, random_state=42, solver='saga', max_iter=100, n_jobs=-1)\n\n    param_grid = {'clf__C': [0.001, 0.01, 0.1, 0.002, 0.02, 0.005, 0.0007, .0006, 0.0005],\n                  'clf__class_weight': [{0: 1, 1: 6}, {0: 1, 1: 4}, {0: 1, 1: 5.5}, {0: 1, 1: 4.5}, {0: 1, 1: 5}]\n                  }\n\n    pipeline = Pipeline(steps=[('scaler', st),\n                               ('clf', rg)])\n\n    cv = StratifiedKFold(n_splits=5, random_state=42)\n    rg_cv = GridSearchCV(pipeline, param_grid, cv=cv, scoring='f1')\n    rg_cv.fit(X_train, y_train)\n    print(\"Tuned rg best params: {}\".format(rg_cv.best_params_))\n\n    ypred = rg_cv.predict(X_train)\n    print(classification_report(y_train, ypred))\n    print('######################')\n    ypred2 = rg_cv.predict(X_test)\n    print(classification_report(y_test, ypred2))\n\n    plt.figure(figsize=(9, 6))\n    param_range1 = [i / 10000.0 for i in range(1, 11)]\n    param_range2 = [{0: 1, 1: 6}, {0: 1, 1: 4}, {0: 1, 1: 5.5}, {0: 1, 1: 4.5}, {0: 1, 1: 5}]\n\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator=rg_cv.best_estimator_, X=X_train, y=y_train,\n        train_sizes=np.arange(0.1, 1.1, 0.1), cv=cv, scoring='f1', n_jobs=- 1)\n\n    plot_learning_curve(train_sizes, train_scores, test_scores, title='Learning curve for Logistic Regression')\n\n    train_scores, test_scores = validation_curve(\n        estimator=rg_cv.best_estimator_, X=X_train, y=y_train, param_name=\"clf__C\", param_range=param_range1,\n        cv=cv, scoring=\"f1\", n_jobs=-1)\n\n    plot_validation_curve(param_range1, train_scores, test_scores, title=\"Validation Curve for C\", alpha=0.1)\n\n    train_scores, test_scores = validation_curve(\n        estimator=rg_cv.best_estimator_, X=X_train, y=y_train, param_name=\"clf__class_weight\", param_range=param_range2,\n        cv=cv, scoring=\"f1\", n_jobs=-1)\n\n    plot_validation_curve(param_range2, train_scores, test_scores, title=\"Validation Curve for class_weight\", alpha=0.1)\n</code></pre>\n",
                "codes": [
                    [
                        "from collections import Counter\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, learning_curve, validation_curve, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef plot_learning_curve(train_sizes, train_scores, test_scores, title, alpha=0.1):\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n    plt.plot(train_sizes, train_mean, label='train score', color='blue', marker='o')\n    plt.fill_between(train_sizes, train_mean + train_std,\n                     train_mean - train_std, color='blue', alpha=alpha)\n    plt.plot(train_sizes, test_mean, label='test score', color='red', marker='o')\n\n    plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, color='red', alpha=alpha)\n    plt.title(title)\n    plt.xlabel('Number of training points')\n    plt.ylabel('F-measure')\n    plt.grid(ls='--')\n    plt.legend(loc='best')\n    plt.show()\n\n\ndef plot_validation_curve(param_range, train_scores, test_scores, title, alpha=0.1):\n    param_range = [x[1] for x in param_range] \n    sort_idx = np.argsort(param_range)\n    param_range=np.array(param_range)[sort_idx]\n    train_mean = np.mean(train_scores, axis=1)[sort_idx]\n    train_std = np.std(train_scores, axis=1)[sort_idx]\n    test_mean = np.mean(test_scores, axis=1)[sort_idx]\n    test_std = np.std(test_scores, axis=1)[sort_idx]\n    plt.plot(param_range, train_mean, label='train score', color='blue', marker='o')\n    plt.fill_between(param_range, train_mean + train_std,\n                 train_mean - train_std, color='blue', alpha=alpha)\n    plt.plot(param_range, test_mean, label='test score', color='red', marker='o')\n    plt.fill_between(param_range, test_mean + test_std, test_mean - test_std, color='red', alpha=alpha)\n    plt.title(title)\n    plt.grid(ls='--')\n    plt.xlabel('Weight of class 2')\n    plt.ylabel('Average values and standard deviation for F1-Score')\n    plt.legend(loc='best')\n    plt.show()\n\n\nif __name__ == '__main__':\n    X, y = make_classification(n_classes=2, class_sep=2, weights=[0.9, 0.1], n_informative=3, n_redundant=1, flip_y=0,\n                               n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\n    print('Original dataset shape {}'.format(Counter(y)))\n\n    ln = X.shape\n    names = [\"x%s\" % i for i in range(1, ln[1] + 1)]\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n    st = StandardScaler()\n\n    rg = LogisticRegression(class_weight={0: 1, 1: 6.5}, random_state=42, solver='saga', max_iter=100, n_jobs=-1)\n\n    param_grid = {'clf__C': [0.001, 0.01, 0.1, 0.002, 0.02, 0.005, 0.0007, .0006, 0.0005],\n                  'clf__class_weight': [{0: 1, 1: 6}, {0: 1, 1: 4}, {0: 1, 1: 5.5}, {0: 1, 1: 4.5}, {0: 1, 1: 5}]\n                  }\n\n    pipeline = Pipeline(steps=[('scaler', st),\n                               ('clf', rg)])\n\n    cv = StratifiedKFold(n_splits=5, random_state=42)\n    rg_cv = GridSearchCV(pipeline, param_grid, cv=cv, scoring='f1')\n    rg_cv.fit(X_train, y_train)\n    print(\"Tuned rg best params: {}\".format(rg_cv.best_params_))\n\n    ypred = rg_cv.predict(X_train)\n    print(classification_report(y_train, ypred))\n    print('######################')\n    ypred2 = rg_cv.predict(X_test)\n    print(classification_report(y_test, ypred2))\n\n    plt.figure(figsize=(9, 6))\n    param_range1 = [i / 10000.0 for i in range(1, 11)]\n    param_range2 = [{0: 1, 1: 6}, {0: 1, 1: 4}, {0: 1, 1: 5.5}, {0: 1, 1: 4.5}, {0: 1, 1: 5}]\n\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator=rg_cv.best_estimator_, X=X_train, y=y_train,\n        train_sizes=np.arange(0.1, 1.1, 0.1), cv=cv, scoring='f1', n_jobs=- 1)\n\n    plot_learning_curve(train_sizes, train_scores, test_scores, title='Learning curve for Logistic Regression')\n\n    train_scores, test_scores = validation_curve(\n        estimator=rg_cv.best_estimator_, X=X_train, y=y_train, param_name=\"clf__C\", param_range=param_range1,\n        cv=cv, scoring=\"f1\", n_jobs=-1)\n\n    plot_validation_curve(param_range1, train_scores, test_scores, title=\"Validation Curve for C\", alpha=0.1)\n\n    train_scores, test_scores = validation_curve(\n        estimator=rg_cv.best_estimator_, X=X_train, y=y_train, param_name=\"clf__class_weight\", param_range=param_range2,\n        cv=cv, scoring=\"f1\", n_jobs=-1)\n\n    plot_validation_curve(param_range2, train_scores, test_scores, title=\"Validation Curve for class_weight\", alpha=0.1)\n"
                    ]
                ],
                "question_id:": "29520",
                "question_votes:": "3",
                "question_text:": "<p>I would appreciate if you could let me know in the following example code:</p>\n\n<pre><code>from collections import Counter\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split,StratifiedKFold,learning_curve,validation_curve,GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_learning_curve(train_sizes, train_scores, test_scores, title, alpha=0.1):\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n    plt.plot(train_sizes, train_mean, label='train score', color='blue', marker='o')\n    plt.fill_between(train_sizes, train_mean + train_std,\n                     train_mean - train_std, color='blue', alpha=alpha)\n    plt.plot(train_sizes, test_mean, label='test score', color='red', marker='o')\n    plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, color='red', alpha=alpha)\n    plt.title(title)\n    plt.xlabel('Number of training points')\n    plt.ylabel('F-measure')\n    plt.grid(ls='--')\n    plt.legend(loc='best')\n    plt.show()\n\n\ndef plot_validation_curve(param_range, train_scores, test_scores, title, alpha=0.1):\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n    plt.plot(param_range, train_mean, label='train score', color='blue', marker='o')\n    plt.fill_between(param_range, train_mean + train_std,\n                     train_mean - train_std, color='blue', alpha=alpha)\n    plt.plot(param_range, test_mean, label='test score', color='red', marker='o')\n    plt.fill_between(param_range, test_mean + test_std, test_mean - test_std, color='red', alpha=alpha)\n    plt.title(title)\n    plt.grid(ls='--')\n    plt.xlabel('Parameter value')\n    plt.ylabel('F-measure')\n    plt.legend(loc='best')\n    plt.show()\n\nX, y = make_classification(n_classes=2, class_sep=2,weights=[0.9, 0.1], n_informative=3, n_redundant=1, flip_y=0, n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\nprint('Original dataset shape {}'.format(Counter(y)))\n\nln = X.shape\nnames = [\"x%s\" % i for i in range(1, ln[1] + 1)]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,random_state=0)\nst=StandardScaler()\n\nrg = LogisticRegression(class_weight = { 0:1, 1:6.5 }, random_state = 42, solver = 'saga',max_iter=100,n_jobs=-1)\n\nparam_grid = {'clf__C': [0.001,0.01,0.1,0.002,0.02,0.005,0.0007,.0006,0.0005],\n              'clf__class_weight':[{ 0:1, 1:6 },{ 0:1, 1:4 },{ 0:1, 1:5.5 },{ 0:1, 1:4.5 },{ 0:1, 1:5 }]\n              }\n\npipeline = Pipeline(steps=[('scaler', st),\n                           ('clf', rg )])\n\ncv=StratifiedKFold(n_splits=5,random_state=42)\nrg_cv = GridSearchCV(pipeline, param_grid, cv=cv, scoring =  'f1')\nrg_cv.fit(X_train, y_train)\nprint(\"Tuned rg best params: {}\".format(rg_cv.best_params_))\n\nypred = rg_cv.predict(X_train)\nprint(classification_report(y_train, ypred))\nprint('######################')\nypred2 = rg_cv.predict(X_test)\nprint(classification_report(y_test, ypred2))\n\nplt.figure(figsize=(9,6))\nparam_range1=[i / 10000.0 for i in range(1, 11)]\nparam_range2=[{0: 1, 1: 6}, {0: 1, 1: 4}, {0: 1, 1: 5.5}, {0: 1, 1: 4.5}, {0: 1, 1: 5}]\n\nif __name__ == '__main__':\n    train_sizes, train_scores, test_scores = learning_curve(\n              estimator= rg_cv.best_estimator_ , X= X_train, y = y_train,\n                train_sizes=np.arange(0.1,1.1,0.1), cv= cv,  scoring='f1', n_jobs= - 1)\n\n    plot_learning_curve(train_sizes, train_scores, test_scores, title='Learning curve for Logistic Regression')\n\n    train_scores, test_scores = validation_curve(\n        estimator=rg_cv.best_estimator_, X=X_train, y=y_train, param_name=\"clf__C\", param_range=param_range1,\n        cv=cv, scoring=\"f1\", n_jobs=-1)\n\n    plot_validation_curve(param_range1, train_scores, test_scores, title=\"Validation Curve for C\", alpha=0.1)\n\n    train_scores, test_scores = validation_curve(\n        estimator=rg_cv.best_estimator_, X=X_train, y=y_train, param_name=\"clf__class_weight\", param_range=param_range2,\n        cv=cv, scoring=\"f1\", n_jobs=-1)\n\n    plot_validation_curve(param_range2, train_scores, test_scores, title=\"Validation Curve for class_weight\", alpha=0.1)\n</code></pre>\n\n<ul>\n<li><p>Why when the  best estimator of GridSearchCv is passed into the learning curve function, it prints all the previous print lines several times?</p></li>\n<li><p>How to plot validation curve for class weight? <code>TypeError: float() argument must be a string or a number, not 'dict'</code></p></li>\n</ul>\n",
                "tags": "<classification><scikit-learn>",
                "answers": [
                    [
                        "29834",
                        "2",
                        "29520",
                        "",
                        "",
                        "<p>With respect to the first and second question, the code should change into:</p>\n\n<pre><code>from collections import Counter\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, learning_curve, validation_curve, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef plot_learning_curve(train_sizes, train_scores, test_scores, title, alpha=0.1):\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n    plt.plot(train_sizes, train_mean, label='train score', color='blue', marker='o')\n    plt.fill_between(train_sizes, train_mean + train_std,\n                     train_mean - train_std, color='blue', alpha=alpha)\n    plt.plot(train_sizes, test_mean, label='test score', color='red', marker='o')\n\n    plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, color='red', alpha=alpha)\n    plt.title(title)\n    plt.xlabel('Number of training points')\n    plt.ylabel('F-measure')\n    plt.grid(ls='--')\n    plt.legend(loc='best')\n    plt.show()\n\n\ndef plot_validation_curve(param_range, train_scores, test_scores, title, alpha=0.1):\n    param_range = [x[1] for x in param_range] \n    sort_idx = np.argsort(param_range)\n    param_range=np.array(param_range)[sort_idx]\n    train_mean = np.mean(train_scores, axis=1)[sort_idx]\n    train_std = np.std(train_scores, axis=1)[sort_idx]\n    test_mean = np.mean(test_scores, axis=1)[sort_idx]\n    test_std = np.std(test_scores, axis=1)[sort_idx]\n    plt.plot(param_range, train_mean, label='train score', color='blue', marker='o')\n    plt.fill_between(param_range, train_mean + train_std,\n                 train_mean - train_std, color='blue', alpha=alpha)\n    plt.plot(param_range, test_mean, label='test score', color='red', marker='o')\n    plt.fill_between(param_range, test_mean + test_std, test_mean - test_std, color='red', alpha=alpha)\n    plt.title(title)\n    plt.grid(ls='--')\n    plt.xlabel('Weight of class 2')\n    plt.ylabel('Average values and standard deviation for F1-Score')\n    plt.legend(loc='best')\n    plt.show()\n\n\nif __name__ == '__main__':\n    X, y = make_classification(n_classes=2, class_sep=2, weights=[0.9, 0.1], n_informative=3, n_redundant=1, flip_y=0,\n                               n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\n    print('Original dataset shape {}'.format(Counter(y)))\n\n    ln = X.shape\n    names = [\"x%s\" % i for i in range(1, ln[1] + 1)]\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n    st = StandardScaler()\n\n    rg = LogisticRegression(class_weight={0: 1, 1: 6.5}, random_state=42, solver='saga', max_iter=100, n_jobs=-1)\n\n    param_grid = {'clf__C': [0.001, 0.01, 0.1, 0.002, 0.02, 0.005, 0.0007, .0006, 0.0005],\n                  'clf__class_weight': [{0: 1, 1: 6}, {0: 1, 1: 4}, {0: 1, 1: 5.5}, {0: 1, 1: 4.5}, {0: 1, 1: 5}]\n                  }\n\n    pipeline = Pipeline(steps=[('scaler', st),\n                               ('clf', rg)])\n\n    cv = StratifiedKFold(n_splits=5, random_state=42)\n    rg_cv = GridSearchCV(pipeline, param_grid, cv=cv, scoring='f1')\n    rg_cv.fit(X_train, y_train)\n    print(\"Tuned rg best params: {}\".format(rg_cv.best_params_))\n\n    ypred = rg_cv.predict(X_train)\n    print(classification_report(y_train, ypred))\n    print('######################')\n    ypred2 = rg_cv.predict(X_test)\n    print(classification_report(y_test, ypred2))\n\n    plt.figure(figsize=(9, 6))\n    param_range1 = [i / 10000.0 for i in range(1, 11)]\n    param_range2 = [{0: 1, 1: 6}, {0: 1, 1: 4}, {0: 1, 1: 5.5}, {0: 1, 1: 4.5}, {0: 1, 1: 5}]\n\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator=rg_cv.best_estimator_, X=X_train, y=y_train,\n        train_sizes=np.arange(0.1, 1.1, 0.1), cv=cv, scoring='f1', n_jobs=- 1)\n\n    plot_learning_curve(train_sizes, train_scores, test_scores, title='Learning curve for Logistic Regression')\n\n    train_scores, test_scores = validation_curve(\n        estimator=rg_cv.best_estimator_, X=X_train, y=y_train, param_name=\"clf__C\", param_range=param_range1,\n        cv=cv, scoring=\"f1\", n_jobs=-1)\n\n    plot_validation_curve(param_range1, train_scores, test_scores, title=\"Validation Curve for C\", alpha=0.1)\n\n    train_scores, test_scores = validation_curve(\n        estimator=rg_cv.best_estimator_, X=X_train, y=y_train, param_name=\"clf__class_weight\", param_range=param_range2,\n        cv=cv, scoring=\"f1\", n_jobs=-1)\n\n    plot_validation_curve(param_range2, train_scores, test_scores, title=\"Validation Curve for class_weight\", alpha=0.1)\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4581",
            "_score": 10.517924,
            "_source": {
                "title": "How is PCA is different from SubSpace clustering and how do we extract variables responsible for the first PCA component?",
                "content": "How is PCA is different from SubSpace clustering and how do we extract variables responsible for the first PCA component? <p><strong>New update:</strong> </p>\n\n<p>I understand PCA components ensure we select variables responsible for high variance, but I would like to know how to extract key variables responsible only for high variance through PCA components.</p>\n\n<p>Ideally, a simple example would help.</p>\n\n<p>This is my code:</p>\n\n<pre><code>#Implementing PCA for visualizing after Kmeans clustering\n\n`# Interpret 3 cluster solution\nmodel3=KMeans(n_clusters=3)\nmodel3.fit(clus_train)\nclusassign=model3.predict(clus_train)\n# plot clusters\n</code></pre>\n\n<blockquote>\n  <p>'''The new variables, called canonical variables, are ordered in terms\n  of the proportion of variance and the clustering variables that is\n  accounted for by each of the canonical variables.  So the first\n  canonical variable will count for the largest proportion of the\n  variance. The second canonical variable will account for the next\n  largest proportion of variance, and so on. Usually, the majority of\n  the variance in the clustering variables will be accounted for by the\n  first couple of canonical variables and those are the variables that\n  we can plot. '''</p>\n</blockquote>\n\n<pre><code>from sklearn.decomposition import PCA\npca_2 = PCA(2) # Selecting 2 components\nplot_columns = pca_2.fit_transform(clus_train)\nplt.scatter(x=plot_columns[:,0], y=plot_columns[:,1], c=model3.labels_,)\n</code></pre>\n\n<p>Observations are more spread out indicating less correlation among the\n observations and higher within cluster variance.</p>\n\n<pre><code>plt.xlabel('Canonical variable 1')\nplt.ylabel('Canonical variable 2')\nplt.title('Scatterplot of Canonical Variables for 3 Clusters')\nplt.show()`\n</code></pre>\n <clustering><visualization><pca><p>Reducing the dimensionality of a dataset with PCA does not only benefits humans trying to look at the data in a graspable number of dimensions. It is also useful for machine learning algorithms to be trained on a subset of dimensions. Both to reduce the complexity of the data and the computational cost of training such machine learning model.</p>\n<p>PCA is a very common technique, so you might want to google around. PCA is awfully common for data visualisation, but it has many other uses.</p>\n\n<p>For instance, if you want to fit a linear regression on average income. Now, you have collected 500+ predictors, but lots of them are correlated like:</p>\n\n<ul>\n<li>How much the person pays tax last year</li>\n<li>How much the person pays tax the year before</li>\n<li>How much the person pays tax three years ago</li>\n<li>....</li>\n</ul>\n\n<p>Those predictors are highly correlated and might present modelling problems in your linear model. A very common technique is to use PCA to reduce into a set of reduced orthogonal principal components. You can then use those components for building your model.</p>\n\n<blockquote>\n  <p><a href=\"https://stats.stackexchange.com/questions/22665/how-to-use-principal-components-as-predictors-in-glm\">https://stats.stackexchange.com/questions/22665/how-to-use-principal-components-as-predictors-in-glm</a></p>\n</blockquote>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "18067",
                "question_votes:": "",
                "question_text:": "<p><strong>New update:</strong> </p>\n\n<p>I understand PCA components ensure we select variables responsible for high variance, but I would like to know how to extract key variables responsible only for high variance through PCA components.</p>\n\n<p>Ideally, a simple example would help.</p>\n\n<p>This is my code:</p>\n\n<pre><code>#Implementing PCA for visualizing after Kmeans clustering\n\n`# Interpret 3 cluster solution\nmodel3=KMeans(n_clusters=3)\nmodel3.fit(clus_train)\nclusassign=model3.predict(clus_train)\n# plot clusters\n</code></pre>\n\n<blockquote>\n  <p>'''The new variables, called canonical variables, are ordered in terms\n  of the proportion of variance and the clustering variables that is\n  accounted for by each of the canonical variables.  So the first\n  canonical variable will count for the largest proportion of the\n  variance. The second canonical variable will account for the next\n  largest proportion of variance, and so on. Usually, the majority of\n  the variance in the clustering variables will be accounted for by the\n  first couple of canonical variables and those are the variables that\n  we can plot. '''</p>\n</blockquote>\n\n<pre><code>from sklearn.decomposition import PCA\npca_2 = PCA(2) # Selecting 2 components\nplot_columns = pca_2.fit_transform(clus_train)\nplt.scatter(x=plot_columns[:,0], y=plot_columns[:,1], c=model3.labels_,)\n</code></pre>\n\n<p>Observations are more spread out indicating less correlation among the\n observations and higher within cluster variance.</p>\n\n<pre><code>plt.xlabel('Canonical variable 1')\nplt.ylabel('Canonical variable 2')\nplt.title('Scatterplot of Canonical Variables for 3 Clusters')\nplt.show()`\n</code></pre>\n",
                "tags": "<clustering><visualization><pca>",
                "answers": [
                    [
                        "18068",
                        "2",
                        "18067",
                        "",
                        "",
                        "<p>Reducing the dimensionality of a dataset with PCA does not only benefits humans trying to look at the data in a graspable number of dimensions. It is also useful for machine learning algorithms to be trained on a subset of dimensions. Both to reduce the complexity of the data and the computational cost of training such machine learning model.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "18069",
                        "2",
                        "18067",
                        "",
                        "",
                        "<p>PCA is a very common technique, so you might want to google around. PCA is awfully common for data visualisation, but it has many other uses.</p>\n\n<p>For instance, if you want to fit a linear regression on average income. Now, you have collected 500+ predictors, but lots of them are correlated like:</p>\n\n<ul>\n<li>How much the person pays tax last year</li>\n<li>How much the person pays tax the year before</li>\n<li>How much the person pays tax three years ago</li>\n<li>....</li>\n</ul>\n\n<p>Those predictors are highly correlated and might present modelling problems in your linear model. A very common technique is to use PCA to reduce into a set of reduced orthogonal principal components. You can then use those components for building your model.</p>\n\n<blockquote>\n  <p><a href=\"https://stats.stackexchange.com/questions/22665/how-to-use-principal-components-as-predictors-in-glm\">https://stats.stackexchange.com/questions/22665/how-to-use-principal-components-as-predictors-in-glm</a></p>\n</blockquote>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "155",
            "_score": 10.5022135,
            "_source": {
                "title": "Data preparation and machine learning algorithm for click prediction",
                "content": "Data preparation and machine learning algorithm for click prediction <p>I am new to machine learning. I have a task at hand of predicting click probability given user information like city, state, OS version, OS family, device, browser family, browser version, etc. I have been advised to try logit since logit seems to be what MS and Google are using. I have some questions regarding logistic regression:</p>\n\n<p>Click and non click is a very very unbalanced class and the simple GLM predictions do not look good. How can I make the data work better with the GLM?</p>\n\n<p>All the variables I have are categorical and things like device and city can be numerous. Also the frequency of occurrence of some devices or some cities can be very very low. How can I deal with this distribution of categorical variables?</p>\n\n<p>One of the variables that we get is device ID. This is a very unique feature that can be translated to a user's identity. How can I make use of it in logit, or should it be used in a completely different model based on user identity?</p>\n <machine-learning><bigdata><data-mining><dataset><data-cleaning><p>Some suggestions</p>\n\n<ol>\n<li>Remove items appearing too infrequently in the data. That will reduce the dimensionality by several orders of magnitude. If a feature occurs less than say 10 times, it's likely that it's not adding any predictive value, and it may lead to overfitting due to low frequency</li>\n<li>Try a Linear SVM instead. They handle large dimensional data very well in terms of not overfitting. They also often have the option to assign relative weights to different classes, which may help address your unbalanced problem above. The sklearn svm (which simply wraps some other packages such as libsvm) has this option.</li>\n<li>Don't use the ID column. Producing a model per user will most probably lead to overfitting. Instead, feed in attributes that describe the user that allows the model to generalize over similar users. You could try fitting a separate model per user, but you need a lot of data per user to do this well.</li>\n<li>It sounds like you really need to try some feature selection here, to reduce the dimensionality of the problem. But try 1 and 2 first, as they may give you good results sooner (although the end solution may still work better with some good feature selection). Sklearn again has a number of options for feature selection.</li>\n</ol>\n",
                "codes": [
                    []
                ],
                "question_id:": "636",
                "question_votes:": "3",
                "question_text:": "<p>I am new to machine learning. I have a task at hand of predicting click probability given user information like city, state, OS version, OS family, device, browser family, browser version, etc. I have been advised to try logit since logit seems to be what MS and Google are using. I have some questions regarding logistic regression:</p>\n\n<p>Click and non click is a very very unbalanced class and the simple GLM predictions do not look good. How can I make the data work better with the GLM?</p>\n\n<p>All the variables I have are categorical and things like device and city can be numerous. Also the frequency of occurrence of some devices or some cities can be very very low. How can I deal with this distribution of categorical variables?</p>\n\n<p>One of the variables that we get is device ID. This is a very unique feature that can be translated to a user's identity. How can I make use of it in logit, or should it be used in a completely different model based on user identity?</p>\n",
                "tags": "<machine-learning><bigdata><data-mining><dataset><data-cleaning>",
                "answers": [
                    [
                        "656",
                        "2",
                        "636",
                        "",
                        "",
                        "<p>Some suggestions</p>\n\n<ol>\n<li>Remove items appearing too infrequently in the data. That will reduce the dimensionality by several orders of magnitude. If a feature occurs less than say 10 times, it's likely that it's not adding any predictive value, and it may lead to overfitting due to low frequency</li>\n<li>Try a Linear SVM instead. They handle large dimensional data very well in terms of not overfitting. They also often have the option to assign relative weights to different classes, which may help address your unbalanced problem above. The sklearn svm (which simply wraps some other packages such as libsvm) has this option.</li>\n<li>Don't use the ID column. Producing a model per user will most probably lead to overfitting. Instead, feed in attributes that describe the user that allows the model to generalize over similar users. You could try fitting a separate model per user, but you need a lot of data per user to do this well.</li>\n<li>It sounds like you really need to try some feature selection here, to reduce the dimensionality of the problem. But try 1 and 2 first, as they may give you good results sooner (although the end solution may still work better with some good feature selection). Sklearn again has a number of options for feature selection.</li>\n</ol>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4103",
            "_score": 10.459927,
            "_source": {
                "title": "Could not convert string to float error on KDDCup99 dataset",
                "content": "Could not convert string to float error on KDDCup99 dataset <p>I am trying to perform a comparison between 5 algorithms against the KDD Cup 99 dataset and the NSL-KDD datasets using Python and I am having an issue when trying to build and evaluate the models against the KDDCup99 dataset and the NSL-KDD dataset.</p>\n\n<p>Whenever I try to run the algorithms on the datasets I get the following error <strong>'could not convert string to float: S0'</strong></p>\n\n<p>This error is produced during the during the evaluation of the 5 models; Logistic Regression, Linear Discriminant Analysis, K-Nearest Neighbors, Classification and Regression Trees, Gaussian Naive Bayes and Support Vector Machines. </p>\n\n<p>Here is the code that I am using to evaluate the datasets: </p>\n\n<pre><code>#Load KDD dataset\n\ndataset = pandas.read_csv('Datasets/KDDCUP 99/kddcup.csv', names = ['duration','protocol_type','service','src_bytes','dst_bytes','flag','land','wrong_fragment','urgent',\n'hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root','num_file_creations',\n'num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','serror_rate',\n'rerror_rate','same_srv_rate','diff_srv_rate','srv_count','srv_serror_rate','srv_rerror_rate','srv_diff_host_rate',\n'dst_host_count','dst_host_srv_count','dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate',\n'dst_host_srv_diff_host_rate','dst_host_serror_rate','dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate','class'])\n\n\n# split data into X and y\narray = dataset.values\nX = array[:,0:41]\nY = array[:,41]\n\n# Split-out validation dataset\nvalidation_size = 0.20\nseed = 7\nX_train, X_validation, Y_train, Y_validation = cross_validation.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n\n# Test options and evaluation metric\nnum_folds = 7\nnum_instances = len(X_train)\nseed = 7\nscoring = 'accuracy'\n\n#  Algorithms\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC()))\n\n# evaluate each model in turn\nresults = []\nnames = []\nfor name, model in models:\n    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, \n\nrandom_state=seed)\n\n    #Here is where the error is spit out\n{\n            cv_results = cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring) # Could not convert string to float happens here. Scoring uses string. \n            results.append(cv_results)\n            names.append(name)\n            msg = \"%s: %f (%f)\" % (name, cv_results.mean()*100, cv_results.std()*100)#multiplying by 100 to show percentage\n            print(msg)\n}\n\n# Compare Algorithms\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(Y)\nplt.show()\n</code></pre>\n\n<p>Here is a 3 line sample from the KDDcup99 datatset:</p>\n\n<pre><code>0   tcp http    SF  215 45076   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   1   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   normal.\n0   tcp http    SF  162 4528    0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   2   2   0   0   0   0   1   0   0   1   1   1   0   1   0   0   0   0   0   normal.\n0   tcp http    SF  236 1228    0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   1   0   0   0   0   1   0   0   2   2   1   0   0.5 0   0   0   0   0   normal.\n</code></pre>\n\n<p>I have tried using label encoding and it still spits out the same error and when I was looking through the sklearn websites, I noticed that the scoring value was for the string type, is this the cause of the issue? and if not, is there a problem with the way I have loaded the dataset? </p>\n\n<p><strong>EDIT</strong> I tried removing scoring value from the code and still got the same error. </p>\n <machine-learning><python><scikit-learn><pandas><p>I notice you mentioned that you used Label encoding but I did it myself and the code runs just fine. I used the 10 percent version of the <a href=\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\" rel=\"noreferrer\">dataset </a>. Just put this piece of code after you load the dataset:</p>\n\n<pre><code>for column in dataset.columns:\n    if dataset[column].dtype == type(object):\n        le = LabelEncoder()\n        dataset[column] = le.fit_transform(dataset[column])\n</code></pre>\n\n<p>After label encoding you should use a <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" rel=\"noreferrer\">One Hot Encoder</a> to improve the performance of some algorithms. You should also avoid using cross_validation module as it is deprecated, it will be removed in version 0.20.</p>\n",
                "codes": [
                    [
                        "for column in dataset.columns:\n    if dataset[column].dtype == type(object):\n        le = LabelEncoder()\n        dataset[column] = le.fit_transform(dataset[column])\n"
                    ]
                ],
                "question_id:": "16728",
                "question_votes:": "2",
                "question_text:": "<p>I am trying to perform a comparison between 5 algorithms against the KDD Cup 99 dataset and the NSL-KDD datasets using Python and I am having an issue when trying to build and evaluate the models against the KDDCup99 dataset and the NSL-KDD dataset.</p>\n\n<p>Whenever I try to run the algorithms on the datasets I get the following error <strong>'could not convert string to float: S0'</strong></p>\n\n<p>This error is produced during the during the evaluation of the 5 models; Logistic Regression, Linear Discriminant Analysis, K-Nearest Neighbors, Classification and Regression Trees, Gaussian Naive Bayes and Support Vector Machines. </p>\n\n<p>Here is the code that I am using to evaluate the datasets: </p>\n\n<pre><code>#Load KDD dataset\n\ndataset = pandas.read_csv('Datasets/KDDCUP 99/kddcup.csv', names = ['duration','protocol_type','service','src_bytes','dst_bytes','flag','land','wrong_fragment','urgent',\n'hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root','num_file_creations',\n'num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','serror_rate',\n'rerror_rate','same_srv_rate','diff_srv_rate','srv_count','srv_serror_rate','srv_rerror_rate','srv_diff_host_rate',\n'dst_host_count','dst_host_srv_count','dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate',\n'dst_host_srv_diff_host_rate','dst_host_serror_rate','dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate','class'])\n\n\n# split data into X and y\narray = dataset.values\nX = array[:,0:41]\nY = array[:,41]\n\n# Split-out validation dataset\nvalidation_size = 0.20\nseed = 7\nX_train, X_validation, Y_train, Y_validation = cross_validation.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n\n# Test options and evaluation metric\nnum_folds = 7\nnum_instances = len(X_train)\nseed = 7\nscoring = 'accuracy'\n\n#  Algorithms\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC()))\n\n# evaluate each model in turn\nresults = []\nnames = []\nfor name, model in models:\n    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, \n\nrandom_state=seed)\n\n    #Here is where the error is spit out\n{\n            cv_results = cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring) # Could not convert string to float happens here. Scoring uses string. \n            results.append(cv_results)\n            names.append(name)\n            msg = \"%s: %f (%f)\" % (name, cv_results.mean()*100, cv_results.std()*100)#multiplying by 100 to show percentage\n            print(msg)\n}\n\n# Compare Algorithms\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(Y)\nplt.show()\n</code></pre>\n\n<p>Here is a 3 line sample from the KDDcup99 datatset:</p>\n\n<pre><code>0   tcp http    SF  215 45076   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   1   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   normal.\n0   tcp http    SF  162 4528    0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   2   2   0   0   0   0   1   0   0   1   1   1   0   1   0   0   0   0   0   normal.\n0   tcp http    SF  236 1228    0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   1   0   0   0   0   1   0   0   2   2   1   0   0.5 0   0   0   0   0   normal.\n</code></pre>\n\n<p>I have tried using label encoding and it still spits out the same error and when I was looking through the sklearn websites, I noticed that the scoring value was for the string type, is this the cause of the issue? and if not, is there a problem with the way I have loaded the dataset? </p>\n\n<p><strong>EDIT</strong> I tried removing scoring value from the code and still got the same error. </p>\n",
                "tags": "<machine-learning><python><scikit-learn><pandas>",
                "answers": [
                    [
                        "16749",
                        "2",
                        "16728",
                        "",
                        "",
                        "<p>I notice you mentioned that you used Label encoding but I did it myself and the code runs just fine. I used the 10 percent version of the <a href=\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\" rel=\"noreferrer\">dataset </a>. Just put this piece of code after you load the dataset:</p>\n\n<pre><code>for column in dataset.columns:\n    if dataset[column].dtype == type(object):\n        le = LabelEncoder()\n        dataset[column] = le.fit_transform(dataset[column])\n</code></pre>\n\n<p>After label encoding you should use a <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" rel=\"noreferrer\">One Hot Encoder</a> to improve the performance of some algorithms. You should also avoid using cross_validation module as it is deprecated, it will be removed in version 0.20.</p>\n",
                        "",
                        "6"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6821",
            "_score": 10.427001,
            "_source": {
                "title": "How regression algorithm works on categorical features",
                "content": "How regression algorithm works on categorical features <p>I have a dataset with features that most of them are nominal categorical features, I have converted my model to indicator values, </p>\n\n<p>Original</p>\n\n<pre><code>F1,F2,L\n1 ,1 ,50\n2 ,3 ,30\n</code></pre>\n\n<p>After indicator values</p>\n\n<pre><code>F1-1,F1-2,F2-1,F2-3,L\n1   ,0   ,1   ,0   ,50\n0   ,1   ,0   ,1   ,30\n</code></pre>\n\n<p>I used different regression algorithm (Poisson, Bayesian, Decision Tree reg, Decision Forest reg, Boosted decision tree reg, linear regression, neural network), but all of then have low performance (r2 ~ 20-30)</p>\n\n<p>Then I was thinking how regression can find values, then I found something interesting : relation of data with label\nThey are like below picture</p>\n\n<p><a href=\"https://i.stack.imgur.com/dZWAo.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/dZWAo.png\" alt=\"regression categorical features\"></a>\n<a href=\"https://i.stack.imgur.com/bDqAq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/bDqAq.png\" alt=\"regression nominal data\"></a></p>\n\n<p>But in most of the books and examples and samples suitable data for regression are like below</p>\n\n<p><a href=\"https://i.stack.imgur.com/zq6bq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zq6bq.png\" alt=\"regression\"></a></p>\n\n<p>And this is the point I got confused!</p>\n\n<p>So my question is how regression (or which algorithms) are suitable for predicting values in high categorical data</p>\n <machine-learning><regression><algorithms><p>The relation that your graph is showing for you categorical variable versus the numerical label does not look to be very strong as for every value of SGPriorityValue, you have all sorts of values of y it seems. For a categorical variable the relationship might not look as smooth  and continuous (Like the last graph you have) but there has to be pattern for any model to fit.</p>\n\n<p>usually if a categorical variable is related to a numerical value, you can expect a graph like below. </p>\n\n<p><a href=\"https://i.stack.imgur.com/B9lVl.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/B9lVl.png\" alt=\"enter image description here\"></a></p>\n<p>TL;DR: It is a convention to convert categorical features to numeric features before you can use them in regression, or any other machine learning algorithm for that matter. <em>Technically</em>, there is nothing that is stopping ML algorithms from working with categorical features but their software implementation would be prohibitively expensive, hence this convention in ML practice.</p>\n\n<p>Turning to your problem, if you are trying to convert categorical label values into numerical values, there are various methods but it appears the best one for your data would be One-Hot encoder. Both <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" rel=\"nofollow noreferrer\">Scikit-Learn</a> and <a href=\"https://spark.apache.org/docs/2.1.0/ml-features.html#onehotencoder\" rel=\"nofollow noreferrer\">PySpark</a>, and most other libraries provide handy functions for it, as it is very common operation. For example: </p>\n\n<pre><code>from sklearn.preprocessing import OneHotEncoder\none_hot = OneHotEncoder()\none_hot.fit(...your_columns...)\n</code></pre>\n\n<p>Once you have all data in numeric form, you can use pretty much any algorithm. </p>\n\n<p>As for the last figure, it is scatter plot between x and y, and it is not obvious what x and y are. Weirdly enough, it is <em>not</em> one-on-one relationship because a given value of x seems to produce multiple value of y?!!! And I am not sure what you are plotting in earlier figures that is giving you straight lines!</p>\n",
                "codes": [
                    [],
                    [
                        "from sklearn.preprocessing import OneHotEncoder\none_hot = OneHotEncoder()\none_hot.fit(...your_columns...)\n"
                    ]
                ],
                "question_id:": "26153",
                "question_votes:": "",
                "question_text:": "<p>I have a dataset with features that most of them are nominal categorical features, I have converted my model to indicator values, </p>\n\n<p>Original</p>\n\n<pre><code>F1,F2,L\n1 ,1 ,50\n2 ,3 ,30\n</code></pre>\n\n<p>After indicator values</p>\n\n<pre><code>F1-1,F1-2,F2-1,F2-3,L\n1   ,0   ,1   ,0   ,50\n0   ,1   ,0   ,1   ,30\n</code></pre>\n\n<p>I used different regression algorithm (Poisson, Bayesian, Decision Tree reg, Decision Forest reg, Boosted decision tree reg, linear regression, neural network), but all of then have low performance (r2 ~ 20-30)</p>\n\n<p>Then I was thinking how regression can find values, then I found something interesting : relation of data with label\nThey are like below picture</p>\n\n<p><a href=\"https://i.stack.imgur.com/dZWAo.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/dZWAo.png\" alt=\"regression categorical features\"></a>\n<a href=\"https://i.stack.imgur.com/bDqAq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/bDqAq.png\" alt=\"regression nominal data\"></a></p>\n\n<p>But in most of the books and examples and samples suitable data for regression are like below</p>\n\n<p><a href=\"https://i.stack.imgur.com/zq6bq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zq6bq.png\" alt=\"regression\"></a></p>\n\n<p>And this is the point I got confused!</p>\n\n<p>So my question is how regression (or which algorithms) are suitable for predicting values in high categorical data</p>\n",
                "tags": "<machine-learning><regression><algorithms>",
                "answers": [
                    [
                        "26156",
                        "2",
                        "26153",
                        "",
                        "",
                        "<p>The relation that your graph is showing for you categorical variable versus the numerical label does not look to be very strong as for every value of SGPriorityValue, you have all sorts of values of y it seems. For a categorical variable the relationship might not look as smooth  and continuous (Like the last graph you have) but there has to be pattern for any model to fit.</p>\n\n<p>usually if a categorical variable is related to a numerical value, you can expect a graph like below. </p>\n\n<p><a href=\"https://i.stack.imgur.com/B9lVl.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/B9lVl.png\" alt=\"enter image description here\"></a></p>\n",
                        "",
                        ""
                    ],
                    [
                        "26154",
                        "2",
                        "26153",
                        "",
                        "",
                        "<p>TL;DR: It is a convention to convert categorical features to numeric features before you can use them in regression, or any other machine learning algorithm for that matter. <em>Technically</em>, there is nothing that is stopping ML algorithms from working with categorical features but their software implementation would be prohibitively expensive, hence this convention in ML practice.</p>\n\n<p>Turning to your problem, if you are trying to convert categorical label values into numerical values, there are various methods but it appears the best one for your data would be One-Hot encoder. Both <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" rel=\"nofollow noreferrer\">Scikit-Learn</a> and <a href=\"https://spark.apache.org/docs/2.1.0/ml-features.html#onehotencoder\" rel=\"nofollow noreferrer\">PySpark</a>, and most other libraries provide handy functions for it, as it is very common operation. For example: </p>\n\n<pre><code>from sklearn.preprocessing import OneHotEncoder\none_hot = OneHotEncoder()\none_hot.fit(...your_columns...)\n</code></pre>\n\n<p>Once you have all data in numeric form, you can use pretty much any algorithm. </p>\n\n<p>As for the last figure, it is scatter plot between x and y, and it is not obvious what x and y are. Weirdly enough, it is <em>not</em> one-on-one relationship because a given value of x seems to produce multiple value of y?!!! And I am not sure what you are plotting in earlier figures that is giving you straight lines!</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9522",
            "_score": 10.3935175,
            "_source": {
                "title": "Predicting number of cars",
                "content": "Predicting number of cars <p>I am predicting the number of cars from a traffic dataset.</p>\n\n<p>Here is my data dictionary :</p>\n\n<p>The \u2018Traffic-Major-Roads(kilometres)\u2019 file contains the following variables (variable names\nare in bold):</p>\n\n<ul>\n<li>Year - Traffic volumes are shown for each year from 2000 onwards.\n\n<ul>\n<li>CP (count point) \u2013 a unique reference for the road link that links the AADFs to the road\nnetwork.</li>\n<li>ONS GOR Name \u2013 the former Government Office Region that the CP sits within.</li>\n<li>ONS LA Name \u2013 the local authority that the CP sits within.</li>\n<li>Road \u2013 this is the road name (for instance M25 or A3).</li>\n<li>RCat \u2013 the classification of the road type (see data definitions for the full list).</li>\n<li>S Ref E \u2013 Easting coordinates of the CP location.</li>\n<li>S Ref N \u2013 Easting coordinates of the CP location.</li>\n<li>A-Junction \u2013 The road name of the start junction of the link</li>\n<li>B-Junction \u2013 The road name of the end junction of the link</li>\n<li>LenNet \u2013 Total length of the network road link for that CP (in kilometres).</li>\n<li>PC \u2013 Traffic volume (in thousands of vehicle kilometres) for pedal cycles.</li>\n<li>2WMV \u2013 Traffic volume (in thousands of vehicle kilometres) for two-wheeled motor\nvehicles.</li>\n<li>Car - Traffic volume (in thousands of vehicle kilometres) for Cars and Taxis.</li>\n<li>Bus \u2013 Traffic volume (in thousands of vehicle kilometres) for Buses and Coaches</li>\n<li>LGV \u2013 Traffic volume (in thousands of vehicle kilometres) for LGVs.</li>\n<li>HGVR2 \u2013 Traffic volume (in thousands of vehicle kilometres) for two-rigid axle HGVs.</li>\n<li>HGVR3 \u2013 Traffic volume (in thousands of vehicle kilometres) for three-rigid axle HGVs.</li>\n<li>HGVR4 \u2013 Traffic volume (in thousands of vehicle kilometres) for four or more rigid axle\nHGVs.</li>\n<li>HGVA3 \u2013 Traffic volume (in thousands of vehicle kilometres) for three or fourarticulated axle HGVs.</li>\n<li>HGVA5 \u2013 Traffic volume (in thousands of vehicle kilometres) for five-articulated axle\nHGVs.</li>\n<li>HGVA6 \u2013 Traffic volume (in thousands of vehicle kilometres) for six-articulated axle\nHGVs.</li>\n<li>HGV \u2013 Traffic volume (in thousands of vehicle kilometres) for all HGVs.</li>\n<li>AMV \u2013 Traffic volume (in thousands of vehicle kilometres) for all motor vehicles.</li>\n</ul></li>\n</ul>\n\n<p>I need to predict the variable AMV.</p>\n\n<p>So ,I have one-hot encoded Road , and kept date , time in my features.\nBut , number of Roads being very large. I am having too many features. </p>\n\n<p>Can you please suggest how should I proceed ?</p>\n <machine-learning><regression><linear-regression><machine-learning-model><p>From what I understand, your question is regarding feature selection. If that is the case, you could try lasso regression, which is a regularization technique that shrink coefficients of the predictors, thereby helping with feature selection. Hope that helps.</p>\n<blockquote>\n  <p>I am having too many features.</p>\n</blockquote>\n\n<p>No, you don't :).</p>\n\n<p>First of all, it is highly likely that not all of them are important for the prediction that you want to make.</p>\n\n<p>I would highly recommend using a <a href=\"https://machinelearningmastery.com/classification-and-regression-trees-for-machine-learning/\" rel=\"nofollow noreferrer\">CART</a> Random Forest for regression of the variable of interest. It literally requires minimal coding if you choose to do it in python using the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" rel=\"nofollow noreferrer\">RF algorithm</a> from the <code>sklearn</code> package.</p>\n\n<p>It's big advantage is that it is straightforward to use and understand and, moreover, it provides you with the learnt <code>feature_importances_</code> of all inputs\nafter training, so that you can exclude the least important ones and speed up the inference/training in the future.</p>\n\n<p><strong>-EDIT-</strong></p>\n\n<p>To understand the difference between Classification and Regression Decision trees, check this <a href=\"http://www.simafore.com/blog/bid/62482/2-main-differences-between-classification-and-regression-trees\" rel=\"nofollow noreferrer\">helpful link</a>.</p>\n\n<p>The decision tree implementations for regression are commonly the <strong>C4.5</strong>, the <strong>C5.0</strong> or the <strong>CART</strong> algorithm. The one that is used by <code>sklearn</code> is <strong>CART</strong>, please take a look at section <strong>1.10.6</strong> in <a href=\"http://scikit-learn.org/stable/modules/tree.html\" rel=\"nofollow noreferrer\">this link</a>. </p>\n\n<p>A good example of how to use the <code>sklearn</code> Decision Tree for regression is <a href=\"http://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html#sphx-glr-auto-examples-tree-plot-tree-regression-py\" rel=\"nofollow noreferrer\">this</a>.</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "33897",
                "question_votes:": "",
                "question_text:": "<p>I am predicting the number of cars from a traffic dataset.</p>\n\n<p>Here is my data dictionary :</p>\n\n<p>The \u2018Traffic-Major-Roads(kilometres)\u2019 file contains the following variables (variable names\nare in bold):</p>\n\n<ul>\n<li>Year - Traffic volumes are shown for each year from 2000 onwards.\n\n<ul>\n<li>CP (count point) \u2013 a unique reference for the road link that links the AADFs to the road\nnetwork.</li>\n<li>ONS GOR Name \u2013 the former Government Office Region that the CP sits within.</li>\n<li>ONS LA Name \u2013 the local authority that the CP sits within.</li>\n<li>Road \u2013 this is the road name (for instance M25 or A3).</li>\n<li>RCat \u2013 the classification of the road type (see data definitions for the full list).</li>\n<li>S Ref E \u2013 Easting coordinates of the CP location.</li>\n<li>S Ref N \u2013 Easting coordinates of the CP location.</li>\n<li>A-Junction \u2013 The road name of the start junction of the link</li>\n<li>B-Junction \u2013 The road name of the end junction of the link</li>\n<li>LenNet \u2013 Total length of the network road link for that CP (in kilometres).</li>\n<li>PC \u2013 Traffic volume (in thousands of vehicle kilometres) for pedal cycles.</li>\n<li>2WMV \u2013 Traffic volume (in thousands of vehicle kilometres) for two-wheeled motor\nvehicles.</li>\n<li>Car - Traffic volume (in thousands of vehicle kilometres) for Cars and Taxis.</li>\n<li>Bus \u2013 Traffic volume (in thousands of vehicle kilometres) for Buses and Coaches</li>\n<li>LGV \u2013 Traffic volume (in thousands of vehicle kilometres) for LGVs.</li>\n<li>HGVR2 \u2013 Traffic volume (in thousands of vehicle kilometres) for two-rigid axle HGVs.</li>\n<li>HGVR3 \u2013 Traffic volume (in thousands of vehicle kilometres) for three-rigid axle HGVs.</li>\n<li>HGVR4 \u2013 Traffic volume (in thousands of vehicle kilometres) for four or more rigid axle\nHGVs.</li>\n<li>HGVA3 \u2013 Traffic volume (in thousands of vehicle kilometres) for three or fourarticulated axle HGVs.</li>\n<li>HGVA5 \u2013 Traffic volume (in thousands of vehicle kilometres) for five-articulated axle\nHGVs.</li>\n<li>HGVA6 \u2013 Traffic volume (in thousands of vehicle kilometres) for six-articulated axle\nHGVs.</li>\n<li>HGV \u2013 Traffic volume (in thousands of vehicle kilometres) for all HGVs.</li>\n<li>AMV \u2013 Traffic volume (in thousands of vehicle kilometres) for all motor vehicles.</li>\n</ul></li>\n</ul>\n\n<p>I need to predict the variable AMV.</p>\n\n<p>So ,I have one-hot encoded Road , and kept date , time in my features.\nBut , number of Roads being very large. I am having too many features. </p>\n\n<p>Can you please suggest how should I proceed ?</p>\n",
                "tags": "<machine-learning><regression><linear-regression><machine-learning-model>",
                "answers": [
                    [
                        "35671",
                        "2",
                        "33897",
                        "",
                        "",
                        "<p>From what I understand, your question is regarding feature selection. If that is the case, you could try lasso regression, which is a regularization technique that shrink coefficients of the predictors, thereby helping with feature selection. Hope that helps.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "33899",
                        "2",
                        "33897",
                        "",
                        "",
                        "<blockquote>\n  <p>I am having too many features.</p>\n</blockquote>\n\n<p>No, you don't :).</p>\n\n<p>First of all, it is highly likely that not all of them are important for the prediction that you want to make.</p>\n\n<p>I would highly recommend using a <a href=\"https://machinelearningmastery.com/classification-and-regression-trees-for-machine-learning/\" rel=\"nofollow noreferrer\">CART</a> Random Forest for regression of the variable of interest. It literally requires minimal coding if you choose to do it in python using the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" rel=\"nofollow noreferrer\">RF algorithm</a> from the <code>sklearn</code> package.</p>\n\n<p>It's big advantage is that it is straightforward to use and understand and, moreover, it provides you with the learnt <code>feature_importances_</code> of all inputs\nafter training, so that you can exclude the least important ones and speed up the inference/training in the future.</p>\n\n<p><strong>-EDIT-</strong></p>\n\n<p>To understand the difference between Classification and Regression Decision trees, check this <a href=\"http://www.simafore.com/blog/bid/62482/2-main-differences-between-classification-and-regression-trees\" rel=\"nofollow noreferrer\">helpful link</a>.</p>\n\n<p>The decision tree implementations for regression are commonly the <strong>C4.5</strong>, the <strong>C5.0</strong> or the <strong>CART</strong> algorithm. The one that is used by <code>sklearn</code> is <strong>CART</strong>, please take a look at section <strong>1.10.6</strong> in <a href=\"http://scikit-learn.org/stable/modules/tree.html\" rel=\"nofollow noreferrer\">this link</a>. </p>\n\n<p>A good example of how to use the <code>sklearn</code> Decision Tree for regression is <a href=\"http://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html#sphx-glr-auto-examples-tree-plot-tree-regression-py\" rel=\"nofollow noreferrer\">this</a>.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10389",
            "_score": 10.355419,
            "_source": {
                "title": "Weights and Bias set to NaN",
                "content": "Weights and Bias set to NaN <p>I am performing linear regression on one of UCI Machine learning repository data set. Below is the code :-</p>\n\n<pre><code>import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport csv\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nwine_data = pd.read_csv('data/winequality-red.csv', delimiter=';')\nn_samples = wine_data.shape[0]\n\ntrain_x = wine_data.iloc[:, :11].values\ntrain_y = wine_data.iloc[:, 11].values\n\ntraining_epochs = 1000\nlearning_rate = 0.03\nn_input = 11\nn_classes = 1\ndisplay_step = 10\n\nX = tf.placeholder(shape=[None, n_input], dtype=tf.float32)\nY = tf.placeholder(shape=[None], dtype=tf.float32)\n\n# Weights and Biases.\nW = tf.Variable(tf.truncated_normal([n_input, n_classes]))\nb = tf.Variable(np.random.randn())\n\n# Construct Linear Model.\nprediction = tf.matmul(X, W) + b\nloss = tf.reduce_sum(tf.pow(prediction - Y, 2))/(2 * n_samples)\noptimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for step in range(1, training_epochs + 1):\n        sess.run(optimizer, feed_dict = {X: train_x,\n                                         Y: train_y})\n        if step % display_step == 0 or step == 1:\n            cost, x, y = sess.run([loss, W, b], feed_dict = {X: train_x,\n                                                             Y: train_y})\n            print (x)\n            print (y)\n            print ('Step ' + str(step) + ', Minibatch Loss = ' + \\\n                   '{:.4f}'.format(cost))\n    print ('Training Done!!!')\n</code></pre>\n\n<p>Now, weights and biases get set to Nan only after single step.</p>\n\n<pre><code>[[14430.979  ]\n [  918.5443 ]\n [  484.25635]\n [ 4654.437  ]\n [  151.41441]\n [31196.336  ]\n [97207.76   ]\n [ 1732.7361 ]\n [ 5743.218  ]\n [ 1149.8185 ]\n [18074.775  ]]\n1735.9697\nStep 1, Minibatch Loss = 32277641302114304.0000\n[[nan]\n [nan]\n [nan]\n [nan]\n [nan]\n [nan]\n [nan]\n [nan]\n [nan]\n [nan]\n [nan]]\nnan\nStep 10, Minibatch Loss = nan\n</code></pre>\n\n<p>What all reasons could result weight and biases carry Nan?</p>\n <machine-learning><python><tensorflow><p>First of all, I think you should change </p>\n\n<pre><code>train_y = wine_data.iloc[:, 11].values\n</code></pre>\n\n<p>into </p>\n\n<pre><code>train_y = wine_data.iloc[:, :11].values\n</code></pre>\n\n<p>similar to the variable <code>train_x</code>.</p>\n\n<p>Next to that, with your current implimentation you use the same training data in every iteration. You probably want to change <code>train_x</code> and <code>train_y</code> within the for loop. </p>\n<p>I think there is some NaN values in your data set.</p>\n\n<p>First time it is printing the random values which are generated for the weights.  But after first step, that means, after the first update of weights, they are becoming NaN. That means there is some NaN values or some missing data in the training data. </p>\n\n<p>Check your training data. I am not clear how tensorflow handles the NaN or missing data.</p>\n",
                "codes": [
                    [
                        "train_y = wine_data.iloc[:, 11].values\n",
                        "train_y = wine_data.iloc[:, :11].values\n"
                    ],
                    []
                ],
                "question_id:": "37344",
                "question_votes:": "",
                "question_text:": "<p>I am performing linear regression on one of UCI Machine learning repository data set. Below is the code :-</p>\n\n<pre><code>import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport csv\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nwine_data = pd.read_csv('data/winequality-red.csv', delimiter=';')\nn_samples = wine_data.shape[0]\n\ntrain_x = wine_data.iloc[:, :11].values\ntrain_y = wine_data.iloc[:, 11].values\n\ntraining_epochs = 1000\nlearning_rate = 0.03\nn_input = 11\nn_classes = 1\ndisplay_step = 10\n\nX = tf.placeholder(shape=[None, n_input], dtype=tf.float32)\nY = tf.placeholder(shape=[None], dtype=tf.float32)\n\n# Weights and Biases.\nW = tf.Variable(tf.truncated_normal([n_input, n_classes]))\nb = tf.Variable(np.random.randn())\n\n# Construct Linear Model.\nprediction = tf.matmul(X, W) + b\nloss = tf.reduce_sum(tf.pow(prediction - Y, 2))/(2 * n_samples)\noptimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for step in range(1, training_epochs + 1):\n        sess.run(optimizer, feed_dict = {X: train_x,\n                                         Y: train_y})\n        if step % display_step == 0 or step == 1:\n            cost, x, y = sess.run([loss, W, b], feed_dict = {X: train_x,\n                                                             Y: train_y})\n            print (x)\n            print (y)\n            print ('Step ' + str(step) + ', Minibatch Loss = ' + \\\n                   '{:.4f}'.format(cost))\n    print ('Training Done!!!')\n</code></pre>\n\n<p>Now, weights and biases get set to Nan only after single step.</p>\n\n<pre><code>[[14430.979  ]\n [  918.5443 ]\n [  484.25635]\n [ 4654.437  ]\n [  151.41441]\n [31196.336  ]\n [97207.76   ]\n [ 1732.7361 ]\n [ 5743.218  ]\n [ 1149.8185 ]\n [18074.775  ]]\n1735.9697\nStep 1, Minibatch Loss = 32277641302114304.0000\n[[nan]\n [nan]\n [nan]\n [nan]\n [nan]\n [nan]\n [nan]\n [nan]\n [nan]\n [nan]\n [nan]]\nnan\nStep 10, Minibatch Loss = nan\n</code></pre>\n\n<p>What all reasons could result weight and biases carry Nan?</p>\n",
                "tags": "<machine-learning><python><tensorflow>",
                "answers": [
                    [
                        "37475",
                        "2",
                        "37344",
                        "",
                        "",
                        "<p>First of all, I think you should change </p>\n\n<pre><code>train_y = wine_data.iloc[:, 11].values\n</code></pre>\n\n<p>into </p>\n\n<pre><code>train_y = wine_data.iloc[:, :11].values\n</code></pre>\n\n<p>similar to the variable <code>train_x</code>.</p>\n\n<p>Next to that, with your current implimentation you use the same training data in every iteration. You probably want to change <code>train_x</code> and <code>train_y</code> within the for loop. </p>\n",
                        "",
                        ""
                    ],
                    [
                        "41730",
                        "2",
                        "37344",
                        "",
                        "",
                        "<p>I think there is some NaN values in your data set.</p>\n\n<p>First time it is printing the random values which are generated for the weights.  But after first step, that means, after the first update of weights, they are becoming NaN. That means there is some NaN values or some missing data in the training data. </p>\n\n<p>Check your training data. I am not clear how tensorflow handles the NaN or missing data.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13624",
            "_score": 10.326391,
            "_source": {
                "title": "Python code not displaying graph",
                "content": "Python code not displaying graph <p>I am using some python code from kaggle that plots a bar graph. However, when I run it, it does not display the graph. When I run it in the IDE I get the following output:</p>\n\n<p><code>&lt;matplotlib.axes._subplots.AxesSubplot object at 0x1200b9ba8&gt; \n&lt;matplotlib.axes._subplots.AxesSubplot object at 0x1200b9ba8&gt;\n&lt;matplotlib.axes._subplots.AxesSubplot object at 0x1200b9ba8&gt;</code></p>\n\n<p>I have used the <code>.show()</code> method but nothing seems to work.</p>\n\n<p>Here is the link to the code that I am using:</p>\n\n<p><a href=\"https://opendata.socrata.com/Government/Airplane-Crashes-and-Fatalities-Since-1908/q2te-8cvq\" rel=\"nofollow noreferrer\">Code</a></p>\n\n<p>I also have it directly in the question:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd \nfrom matplotlib import pyplot as plt\nimport matplotlib\nfrom sklearn.linear_model import LinearRegression\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n#from subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nframe=pd.read_csv('Project_Airplane_Crashes_and_Fatalities_Since_1908.csv',sep=',')\nmatplotlib.rcParams['figure.figsize'] = (12.0, 8.0)\n\noperator = frame[['Operator','Fatalities']].groupby('Operator').agg(['sum','count'])\n\nfig_ops,((ax1, ax2), (ax3, ax4))=plt.subplots(2,2,sharex=True)\naccidents = operator['Fatalities','count'].sort_values(ascending=False)\ntotalacc = accidents.sum()\naccprop = accidents/totalacc\naccidents.head(10).plot(kind='bar',title='Accidents by Operator',ax=ax1,grid=True,rot=90)\naccprop.head(10).plot(kind='bar',title='Proportion of Total Accidents',ax=ax2,grid=True,rot=90)\n\nfatalities = operator['Fatalities','sum'].sort_values(ascending=False)\nfatalities.head(10).plot(kind='bar',title='Fatalities by Operator',ax=ax3,grid=True,rot=90)\ntotalfatal = fatalities.sum()\nfatalprop = fatalities/totalfatal\n#print(fatalprop)\nfatalprop.head(10).plot(kind='bar',title='Proportion of total Fatalities',ax=ax4,grid=True,rot=90)\n</code></pre>\n\n<p>Any help would be greatly appreciated. </p>\n <python><visualization><p>I have gotten the answer to my question since I keep searching for solution.\nI got the solution here <a href=\"https://stackoverflow.com/questions/7534453/matplotlib-does-not-show-my-drawings-although-i-call-pyplot-show\">enter link description here</a></p>\n\n<p>By StefanM</p>\n\n<p>So all I needed and should have done is to simply do \nplt.show()\nand I was typing fatalprop.head(10).show()\nThank you</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "46412",
                "question_votes:": "",
                "question_text:": "<p>I am using some python code from kaggle that plots a bar graph. However, when I run it, it does not display the graph. When I run it in the IDE I get the following output:</p>\n\n<p><code>&lt;matplotlib.axes._subplots.AxesSubplot object at 0x1200b9ba8&gt; \n&lt;matplotlib.axes._subplots.AxesSubplot object at 0x1200b9ba8&gt;\n&lt;matplotlib.axes._subplots.AxesSubplot object at 0x1200b9ba8&gt;</code></p>\n\n<p>I have used the <code>.show()</code> method but nothing seems to work.</p>\n\n<p>Here is the link to the code that I am using:</p>\n\n<p><a href=\"https://opendata.socrata.com/Government/Airplane-Crashes-and-Fatalities-Since-1908/q2te-8cvq\" rel=\"nofollow noreferrer\">Code</a></p>\n\n<p>I also have it directly in the question:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd \nfrom matplotlib import pyplot as plt\nimport matplotlib\nfrom sklearn.linear_model import LinearRegression\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n#from subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nframe=pd.read_csv('Project_Airplane_Crashes_and_Fatalities_Since_1908.csv',sep=',')\nmatplotlib.rcParams['figure.figsize'] = (12.0, 8.0)\n\noperator = frame[['Operator','Fatalities']].groupby('Operator').agg(['sum','count'])\n\nfig_ops,((ax1, ax2), (ax3, ax4))=plt.subplots(2,2,sharex=True)\naccidents = operator['Fatalities','count'].sort_values(ascending=False)\ntotalacc = accidents.sum()\naccprop = accidents/totalacc\naccidents.head(10).plot(kind='bar',title='Accidents by Operator',ax=ax1,grid=True,rot=90)\naccprop.head(10).plot(kind='bar',title='Proportion of Total Accidents',ax=ax2,grid=True,rot=90)\n\nfatalities = operator['Fatalities','sum'].sort_values(ascending=False)\nfatalities.head(10).plot(kind='bar',title='Fatalities by Operator',ax=ax3,grid=True,rot=90)\ntotalfatal = fatalities.sum()\nfatalprop = fatalities/totalfatal\n#print(fatalprop)\nfatalprop.head(10).plot(kind='bar',title='Proportion of total Fatalities',ax=ax4,grid=True,rot=90)\n</code></pre>\n\n<p>Any help would be greatly appreciated. </p>\n",
                "tags": "<python><visualization>",
                "answers": [
                    [
                        "46413",
                        "2",
                        "46412",
                        "",
                        "",
                        "<p>I have gotten the answer to my question since I keep searching for solution.\nI got the solution here <a href=\"https://stackoverflow.com/questions/7534453/matplotlib-does-not-show-my-drawings-although-i-call-pyplot-show\">enter link description here</a></p>\n\n<p>By StefanM</p>\n\n<p>So all I needed and should have done is to simply do \nplt.show()\nand I was typing fatalprop.head(10).show()\nThank you</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15472",
            "_score": 10.22915,
            "_source": {
                "title": "is it possible to output more than 2 nodes away from a node in a decision tree? if yes, how to do that with sklearn?",
                "content": "is it possible to output more than 2 nodes away from a node in a decision tree? if yes, how to do that with sklearn? <p>usually a decision tree has one root node, some nodes, and some leaves.</p>\n\n<p>lots tutorial illustrate this as something like binary tree.</p>\n\n<p>is it possible more than 2 nodes away from a node in a decision tree?</p>\n\n<p><a href=\"https://i.stack.imgur.com/q7tjI.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/q7tjI.png\" alt=\"enter image description here\"></a></p>\n\n<p>this image comes from this <a href=\"https://medium.com/greyatom/decision-trees-a-simple-way-to-visualize-a-decision-dc506a403aeb\" rel=\"nofollow noreferrer\">post</a></p>\n\n<p>by \"more than 2 nodes\", i mean there are more than 3 splits (in this case, 3, Low, Med, High) away from the root node.</p>\n\n<p>if it is reasonable in real life application, plz provide an open dataset on which a decision tree would spit more than 2 nodes, and a piece of sklearn code.</p>\n <machine-learning><scikit-learn><decision-trees><p>IMO decision trees are - by definition - designed so that the single \"best\" split is chosen in each step (Introduction to Statistical Learning, Ch. 8.1). I think you need to split on values low, medium, high, in which case a first split would e.g. occur at (low) vs. (medium, high) and a later split would be between (medium, high), whatever gives the best fit. </p>\n\n<p>Single decision trees often do not have a very good predictive capacity (see. Introduction to Statistical Learning, Ch. 8.2). If you are interested in accuracy of prediction, you should go a step further and grow a random forest with \"bagging\" or even better \"boosting\" on many trees (or \"ensambles of trees\"). In this case, many trees are grown, and they all together make a \"vote\" on how to predict some outcome.  </p>\n\n<p>Random Forest in scikit-learn: <a href=\"https://scikit-learn.org/stable/modules/ensemble.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/ensemble.html</a></p>\n\n<p>Prominent boosting methods are e.g. catboost (<a href=\"https://catboost.ai/docs/concepts/about.html\" rel=\"nofollow noreferrer\">https://catboost.ai/docs/concepts/about.html</a>) or lightGBM (<a href=\"https://lightgbm.readthedocs.io/en/latest/\" rel=\"nofollow noreferrer\">https://lightgbm.readthedocs.io/en/latest/</a>).</p>\n\n<p>Alternative (non-tree based) models will be able to make a differentiation by three classes without any problem (ISL, Ch. 4). One example is a logistic model (or \"logit\") of form <code>risk = b0 + b1*savings</code>. In this models you can also calculate marginal effects, telling you, in case someone moves from class A to class B, by how much will the probability of being a \"bad risk\" change (marginal effects).\n<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</a></p>\n\n<p>You can find a bunch of good code directly covering topics mentionned here and discussed in the book \"Introduction to Statistical Learning\" online: <a href=\"https://github.com/JWarmenhoven/ISLR-python\" rel=\"nofollow noreferrer\">https://github.com/JWarmenhoven/ISLR-python</a></p>\n\n<p><strong>In summary:</strong> If you are interested in prediction, don't stick to simple decision trees, but move on to something else. </p>\n<p>I think that scikit-learn only implements binary trees. However, you can turn your example into a binary tree so you can use scikit-learn:</p>\n\n<pre><code>Savings == Low\n    True =&gt; Assets == Low\n        True =&gt; Bad Risk\n        False =&gt; Good Risk\n    False =&gt; Savings == Med\n        True =&gt; Good Credit Risk\n        False =&gt; Income &lt;= 30K\n            True =&gt; Bad Risk\n            False =&gt; Good Risk\n</code></pre>\n<blockquote>\n  <p>if it is reasonable in real life application</p>\n</blockquote>\n\n<p>From my understanding of the question, Technically, I think it is perfectly reasonable to have a decision tree/forest splitting into 3 or more nodes from the root node. Kindly check <a href=\"https://web.archive.org/web/20161021062446/https://homepage.cs.uri.edu/faculty/hamel/courses/2016/spring2016/csc581/lecture-notes/32-decision-trees.pdf\" rel=\"nofollow noreferrer\">this</a> example if you not. In this example, the predictor variable is whether to play tennis on a given day or not depending on how the climate is on that day.</p>\n\n<p><a href=\"https://i.stack.imgur.com/GwbwS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/GwbwS.png\" alt=\"enter image description here\"></a></p>\n\n<p>But I'm not sure whether this is practically possible given the tree structure and the splitting strategy involves find the nodes which correspond to the most reduction in entropy in the model or highest gain in information gain.</p>\n\n<p>P.S: If this answer doesn't give you any new information or clarity, please say so. I'll remove it in order not to misguide or anyone.</p>\n<p>It is possible to make more than a binary split in a decision tree. <a href=\"https://en.wikipedia.org/wiki/Chi-square_automatic_interaction_detection\" rel=\"nofollow noreferrer\">Chi-square automatic interaction detection (CHAID)</a> is the only common algorithm for doing more than binary splits.</p>\n\n<p>However, scikit-learn only supports binary splits for many reasons. One primary reason to limit to just binary splits is that the library can support as many splitting criteria as possible with the same API. For example, <a href=\"https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\" rel=\"nofollow noreferrer\">Gini Impurity</a> only supports binary splits. </p>\n\n<p>In practice, only supporting binary splits is not an issue because a series of binary splits can model any number of simultaneous splits.</p>\n",
                "codes": [
                    [],
                    [
                        "Savings == Low\n    True => Assets == Low\n        True => Bad Risk\n        False => Good Risk\n    False => Savings == Med\n        True => Good Credit Risk\n        False => Income <= 30K\n            True => Bad Risk\n            False => Good Risk\n"
                    ],
                    [],
                    []
                ],
                "question_id:": "51983",
                "question_votes:": "",
                "question_text:": "<p>usually a decision tree has one root node, some nodes, and some leaves.</p>\n\n<p>lots tutorial illustrate this as something like binary tree.</p>\n\n<p>is it possible more than 2 nodes away from a node in a decision tree?</p>\n\n<p><a href=\"https://i.stack.imgur.com/q7tjI.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/q7tjI.png\" alt=\"enter image description here\"></a></p>\n\n<p>this image comes from this <a href=\"https://medium.com/greyatom/decision-trees-a-simple-way-to-visualize-a-decision-dc506a403aeb\" rel=\"nofollow noreferrer\">post</a></p>\n\n<p>by \"more than 2 nodes\", i mean there are more than 3 splits (in this case, 3, Low, Med, High) away from the root node.</p>\n\n<p>if it is reasonable in real life application, plz provide an open dataset on which a decision tree would spit more than 2 nodes, and a piece of sklearn code.</p>\n",
                "tags": "<machine-learning><scikit-learn><decision-trees>",
                "answers": [
                    [
                        "52392",
                        "2",
                        "51983",
                        "",
                        "",
                        "<p>IMO decision trees are - by definition - designed so that the single \"best\" split is chosen in each step (Introduction to Statistical Learning, Ch. 8.1). I think you need to split on values low, medium, high, in which case a first split would e.g. occur at (low) vs. (medium, high) and a later split would be between (medium, high), whatever gives the best fit. </p>\n\n<p>Single decision trees often do not have a very good predictive capacity (see. Introduction to Statistical Learning, Ch. 8.2). If you are interested in accuracy of prediction, you should go a step further and grow a random forest with \"bagging\" or even better \"boosting\" on many trees (or \"ensambles of trees\"). In this case, many trees are grown, and they all together make a \"vote\" on how to predict some outcome.  </p>\n\n<p>Random Forest in scikit-learn: <a href=\"https://scikit-learn.org/stable/modules/ensemble.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/ensemble.html</a></p>\n\n<p>Prominent boosting methods are e.g. catboost (<a href=\"https://catboost.ai/docs/concepts/about.html\" rel=\"nofollow noreferrer\">https://catboost.ai/docs/concepts/about.html</a>) or lightGBM (<a href=\"https://lightgbm.readthedocs.io/en/latest/\" rel=\"nofollow noreferrer\">https://lightgbm.readthedocs.io/en/latest/</a>).</p>\n\n<p>Alternative (non-tree based) models will be able to make a differentiation by three classes without any problem (ISL, Ch. 4). One example is a logistic model (or \"logit\") of form <code>risk = b0 + b1*savings</code>. In this models you can also calculate marginal effects, telling you, in case someone moves from class A to class B, by how much will the probability of being a \"bad risk\" change (marginal effects).\n<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</a></p>\n\n<p>You can find a bunch of good code directly covering topics mentionned here and discussed in the book \"Introduction to Statistical Learning\" online: <a href=\"https://github.com/JWarmenhoven/ISLR-python\" rel=\"nofollow noreferrer\">https://github.com/JWarmenhoven/ISLR-python</a></p>\n\n<p><strong>In summary:</strong> If you are interested in prediction, don't stick to simple decision trees, but move on to something else. </p>\n",
                        "",
                        ""
                    ],
                    [
                        "52387",
                        "2",
                        "51983",
                        "",
                        "",
                        "<p>I think that scikit-learn only implements binary trees. However, you can turn your example into a binary tree so you can use scikit-learn:</p>\n\n<pre><code>Savings == Low\n    True =&gt; Assets == Low\n        True =&gt; Bad Risk\n        False =&gt; Good Risk\n    False =&gt; Savings == Med\n        True =&gt; Good Credit Risk\n        False =&gt; Income &lt;= 30K\n            True =&gt; Bad Risk\n            False =&gt; Good Risk\n</code></pre>\n",
                        "",
                        ""
                    ],
                    [
                        "52478",
                        "2",
                        "51983",
                        "",
                        "",
                        "<blockquote>\n  <p>if it is reasonable in real life application</p>\n</blockquote>\n\n<p>From my understanding of the question, Technically, I think it is perfectly reasonable to have a decision tree/forest splitting into 3 or more nodes from the root node. Kindly check <a href=\"https://web.archive.org/web/20161021062446/https://homepage.cs.uri.edu/faculty/hamel/courses/2016/spring2016/csc581/lecture-notes/32-decision-trees.pdf\" rel=\"nofollow noreferrer\">this</a> example if you not. In this example, the predictor variable is whether to play tennis on a given day or not depending on how the climate is on that day.</p>\n\n<p><a href=\"https://i.stack.imgur.com/GwbwS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/GwbwS.png\" alt=\"enter image description here\"></a></p>\n\n<p>But I'm not sure whether this is practically possible given the tree structure and the splitting strategy involves find the nodes which correspond to the most reduction in entropy in the model or highest gain in information gain.</p>\n\n<p>P.S: If this answer doesn't give you any new information or clarity, please say so. I'll remove it in order not to misguide or anyone.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "52408",
                        "2",
                        "51983",
                        "",
                        "",
                        "<p>It is possible to make more than a binary split in a decision tree. <a href=\"https://en.wikipedia.org/wiki/Chi-square_automatic_interaction_detection\" rel=\"nofollow noreferrer\">Chi-square automatic interaction detection (CHAID)</a> is the only common algorithm for doing more than binary splits.</p>\n\n<p>However, scikit-learn only supports binary splits for many reasons. One primary reason to limit to just binary splits is that the library can support as many splitting criteria as possible with the same API. For example, <a href=\"https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\" rel=\"nofollow noreferrer\">Gini Impurity</a> only supports binary splits. </p>\n\n<p>In practice, only supporting binary splits is not an issue because a series of binary splits can model any number of simultaneous splits.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9200",
            "_score": 10.190116,
            "_source": {
                "title": "Using Machine Learning to Predict Temperature",
                "content": "Using Machine Learning to Predict Temperature <p>I am a beginner in ML and I want to create a smart thermostat, that after collecting enough data from the interaction with the user, it will start to set the home temperature by itself.</p>\n\n<p>What I got so far is the hardware prototype that lets the user set the temperature, and in the same time it posts the Environment and the UserSetTemperature to ThingSpeak (to easily store the data for later access)</p>\n\n<p>The other part is a python algorithm that gets the data from ThingSpeak and it converts it into a Pandas DataFrame.</p>\n\n<p>The data frame looks like bellow:</p>\n\n<pre><code>timeStamp                      environment_temp    user_set_temp  \n\n2018-05-27T00:12:43Z               20            21              \n2018-05-27T00:17:27Z               20            22                 \n2018-05-27T00:17:59Z               20            24                \n2018-05-27T00:20:01Z               20            21                  \n2018-05-27T00:23:14Z               20            24                 \n2018-05-28T09:39:07Z               20            22             \n2018-05-28T10:40:17Z               20            23               \n2018-05-28T20:12:47Z               20            25              \n2018-05-28T20:14:16Z               23            25               \n2018-05-30T20:29:30Z               18            24  \n</code></pre>\n\n<p>And here is where I got stuck. I don't know how to use this data with the ML libraries in order to make predictions on how the temperature should be set when the environment temperature is x.</p>\n\n<p>I tried to use the sklearn train_test_split() and LinearRegression(), but with no significant result. I really don't know how to use this data</p>\n\n<p>Every suggestion will be highly appreciated!!</p>\n <machine-learning><python><scipy><p>Let's consider :</p>\n\n<pre><code>t : timeStamp\nx : environment_temp\ny : user_set_temp \n</code></pre>\n\n<ol>\n<li><p>It would be helpful if you test your data to see if it comes from <a href=\"https://en.wikipedia.org/wiki/Stationary_process\" rel=\"nofollow noreferrer\">stationary process</a> o not. The <code>t</code> should play a significant role in predicting <code>y</code>. So, if you want a good prediction model you should keep and use this information alongside with <code>x</code>.</p></li>\n<li><p>You have a time-series, so you should consider a time-window(<code>w</code>): <code>w=1</code> is when you only use current <code>(t,x)</code> for setting current <code>y</code>. If you choose <code>w=10</code>, this means that you use 10 past observations of <code>(t,x)</code> for predicting current <code>y</code>. So, you can create a new dataset for training your model based on the chosen window size: a matrix(size $M\\times W$) as your data and a vector(size $M$) as the labels. </p></li>\n<li><p>Currently, the best choice for working with such data might be <code>ConvNet</code> or <code>LSTM</code>. Look at <a href=\"https://keras.io/getting-started/sequential-model-guide/\" rel=\"nofollow noreferrer\">this blog post</a>. This is not a high-dimensional data and you can find and fit a model which is not so heavy for running on an edge device. </p></li>\n</ol>\n\n<p>Finally, the sampling rate is also very important. Are you collecting data minute-by-minute or you recording data just when the user changes temperature? It is important because we usually name the former case \"<strong>time-series</strong>\" and the latter case \"<strong>sequential</strong>\" data. Techniques are some-time different for each case.</p>\n<p>In my opinion a RNN is too computational heavy. You have to run it on a cloud service or on a GPU. </p>\n\n<p>Furthermore I think that based in the environment temperature you can not predict the wanted temperature by the user. You would need additional data such as humidity, because you have to learn how the user feels the temperature and this depends on several factors. If this aren't fake data, you can obviously see that there is no correlation. And it seems that you only record the environment temperature when the thermostat temperature changes. This is not enough for predicting.</p>\n\n<p>If you don't have any additional data I would suggest that you calculate the gradient of the temperature change over a specific time, as well.</p>\n\n<p>If you have more data I would suggest to start with plotting the data nicely to get an impression. Then I would try a multiple linear regression and a Perceptron or a multi layer Perceptron.</p>\n<p>I would not recommend going ahead with the data that you know might be wrong.</p>\n\n<p>Looking at your current data, the reason you got a bad result with linear regression is because the relation between them is not linear for the current data. For eg. There is high variation in response (i.e. user_set_temp)  for same value of your predictor (i.e. environment_temp).</p>\n\n<p>First, get hold of correct temperature for your recorded timestamps from local weather data to replace environment temp with this data, till you get the issue rectified with your original recorded environment_temp. When you rectify the issue, then I would recommend you to use both weather and environment temp to predict, as a person might set the temperature depending upon a combination of both. </p>\n\n<p>After you get a good representative data, this should be a reasonable procedure to help you predict the temperature:</p>\n\n<ol>\n<li><p><strong><em>Exploratory data analysis for uni-variate timeseries:</em></strong>\nThis will help you observe patterns in data, which will help you decide on which new features to engineer/ create from timestamps <em>(step 2)</em> you have of recordings. Also, look at the acf/ pacf plots to help figure out the lags in data that might help you predict better. Fit a basic uni-variate model like STL or ARIMA model to get a good base model for prediction (this model you will compare new models with to see how they perform)</p></li>\n<li><p><strong><em>Feature Engineering</em></strong>: Time of day, day of week, week of month etc identified in <em>step 1</em>. Also, look for any other features that might help your algorithm find patterns.</p></li>\n<li><p><strong><em>Regression Models:</em></strong> Test with advanced algorithms like RandomForest, Gradient Boosting and RNN-LSTM to check how they perform against each other and the base model.</p></li>\n</ol>\n<p>I would highly recommend using Recurrent Neural Networks for your purpose, because of their demonstrated ability to forecast time series, due to their inherent memory.</p>\n\n<p>A perfect tutorial for your purposes can be found <a href=\"https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/\" rel=\"nofollow noreferrer\">here</a>. I am sure it will help you <strong>a lot</strong> :)</p>\n",
                "codes": [
                    [
                        "t : timeStamp\nx : environment_temp\ny : user_set_temp \n"
                    ],
                    [],
                    [],
                    []
                ],
                "question_id:": "32888",
                "question_votes:": "3",
                "question_text:": "<p>I am a beginner in ML and I want to create a smart thermostat, that after collecting enough data from the interaction with the user, it will start to set the home temperature by itself.</p>\n\n<p>What I got so far is the hardware prototype that lets the user set the temperature, and in the same time it posts the Environment and the UserSetTemperature to ThingSpeak (to easily store the data for later access)</p>\n\n<p>The other part is a python algorithm that gets the data from ThingSpeak and it converts it into a Pandas DataFrame.</p>\n\n<p>The data frame looks like bellow:</p>\n\n<pre><code>timeStamp                      environment_temp    user_set_temp  \n\n2018-05-27T00:12:43Z               20            21              \n2018-05-27T00:17:27Z               20            22                 \n2018-05-27T00:17:59Z               20            24                \n2018-05-27T00:20:01Z               20            21                  \n2018-05-27T00:23:14Z               20            24                 \n2018-05-28T09:39:07Z               20            22             \n2018-05-28T10:40:17Z               20            23               \n2018-05-28T20:12:47Z               20            25              \n2018-05-28T20:14:16Z               23            25               \n2018-05-30T20:29:30Z               18            24  \n</code></pre>\n\n<p>And here is where I got stuck. I don't know how to use this data with the ML libraries in order to make predictions on how the temperature should be set when the environment temperature is x.</p>\n\n<p>I tried to use the sklearn train_test_split() and LinearRegression(), but with no significant result. I really don't know how to use this data</p>\n\n<p>Every suggestion will be highly appreciated!!</p>\n",
                "tags": "<machine-learning><python><scipy>",
                "answers": [
                    [
                        "32911",
                        "2",
                        "32888",
                        "",
                        "",
                        "<p>Let's consider :</p>\n\n<pre><code>t : timeStamp\nx : environment_temp\ny : user_set_temp \n</code></pre>\n\n<ol>\n<li><p>It would be helpful if you test your data to see if it comes from <a href=\"https://en.wikipedia.org/wiki/Stationary_process\" rel=\"nofollow noreferrer\">stationary process</a> o not. The <code>t</code> should play a significant role in predicting <code>y</code>. So, if you want a good prediction model you should keep and use this information alongside with <code>x</code>.</p></li>\n<li><p>You have a time-series, so you should consider a time-window(<code>w</code>): <code>w=1</code> is when you only use current <code>(t,x)</code> for setting current <code>y</code>. If you choose <code>w=10</code>, this means that you use 10 past observations of <code>(t,x)</code> for predicting current <code>y</code>. So, you can create a new dataset for training your model based on the chosen window size: a matrix(size $M\\times W$) as your data and a vector(size $M$) as the labels. </p></li>\n<li><p>Currently, the best choice for working with such data might be <code>ConvNet</code> or <code>LSTM</code>. Look at <a href=\"https://keras.io/getting-started/sequential-model-guide/\" rel=\"nofollow noreferrer\">this blog post</a>. This is not a high-dimensional data and you can find and fit a model which is not so heavy for running on an edge device. </p></li>\n</ol>\n\n<p>Finally, the sampling rate is also very important. Are you collecting data minute-by-minute or you recording data just when the user changes temperature? It is important because we usually name the former case \"<strong>time-series</strong>\" and the latter case \"<strong>sequential</strong>\" data. Techniques are some-time different for each case.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "32894",
                        "2",
                        "32888",
                        "",
                        "",
                        "<p>In my opinion a RNN is too computational heavy. You have to run it on a cloud service or on a GPU. </p>\n\n<p>Furthermore I think that based in the environment temperature you can not predict the wanted temperature by the user. You would need additional data such as humidity, because you have to learn how the user feels the temperature and this depends on several factors. If this aren't fake data, you can obviously see that there is no correlation. And it seems that you only record the environment temperature when the thermostat temperature changes. This is not enough for predicting.</p>\n\n<p>If you don't have any additional data I would suggest that you calculate the gradient of the temperature change over a specific time, as well.</p>\n\n<p>If you have more data I would suggest to start with plotting the data nicely to get an impression. Then I would try a multiple linear regression and a Perceptron or a multi layer Perceptron.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "32922",
                        "2",
                        "32888",
                        "",
                        "",
                        "<p>I would not recommend going ahead with the data that you know might be wrong.</p>\n\n<p>Looking at your current data, the reason you got a bad result with linear regression is because the relation between them is not linear for the current data. For eg. There is high variation in response (i.e. user_set_temp)  for same value of your predictor (i.e. environment_temp).</p>\n\n<p>First, get hold of correct temperature for your recorded timestamps from local weather data to replace environment temp with this data, till you get the issue rectified with your original recorded environment_temp. When you rectify the issue, then I would recommend you to use both weather and environment temp to predict, as a person might set the temperature depending upon a combination of both. </p>\n\n<p>After you get a good representative data, this should be a reasonable procedure to help you predict the temperature:</p>\n\n<ol>\n<li><p><strong><em>Exploratory data analysis for uni-variate timeseries:</em></strong>\nThis will help you observe patterns in data, which will help you decide on which new features to engineer/ create from timestamps <em>(step 2)</em> you have of recordings. Also, look at the acf/ pacf plots to help figure out the lags in data that might help you predict better. Fit a basic uni-variate model like STL or ARIMA model to get a good base model for prediction (this model you will compare new models with to see how they perform)</p></li>\n<li><p><strong><em>Feature Engineering</em></strong>: Time of day, day of week, week of month etc identified in <em>step 1</em>. Also, look for any other features that might help your algorithm find patterns.</p></li>\n<li><p><strong><em>Regression Models:</em></strong> Test with advanced algorithms like RandomForest, Gradient Boosting and RNN-LSTM to check how they perform against each other and the base model.</p></li>\n</ol>\n",
                        "",
                        "6"
                    ],
                    [
                        "32889",
                        "2",
                        "32888",
                        "",
                        "",
                        "<p>I would highly recommend using Recurrent Neural Networks for your purpose, because of their demonstrated ability to forecast time series, due to their inherent memory.</p>\n\n<p>A perfect tutorial for your purposes can be found <a href=\"https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/\" rel=\"nofollow noreferrer\">here</a>. I am sure it will help you <strong>a lot</strong> :)</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3253",
            "_score": 10.150507,
            "_source": {
                "title": "How to deal with a skewed data-set having all the samples almost similar?",
                "content": "How to deal with a skewed data-set having all the samples almost similar? <p>I have a very large <code>skewed</code> training set where every feature's <code>data-points</code> are very similar ?</p>\n\n<p>For example, following is some part of the training data :</p>\n\n<pre><code>93.65034,94.50283,94.6677,94.20174,94.93986,95.21071,1\n94.13783,94.61797,94.50526,95.66091,95.99478,95.12608,1\n94.0238,93.95445,94.77115,94.65469,95.08566,94.97906,1\n94.36343,94.32839,95.33167,95.24738,94.57213,95.05634,1\n94.65813,94.65246,94.64984,95.29596,95.14167,95.39941,1\n95.50876,94.45346,95.23837,95.26877,94.84924,94.8021,0\n94.5774,93.92291,94.96261,95.40926,95.97659,95.17691,0\n93.76617,94.27253,94.38002,94.28448,94.19957,94.98924,0\n</code></pre>\n\n<p>where the last column is the <code>class-label</code> - only 0 and 1.</p>\n\n<p>This only a part of the dataset, but the actual dataset contains about <code>95%</code> of samples with <code>class-label</code> being <code>1</code>, and the rest with <code>class-label</code> being <code>0</code>, despite the fact that more or less all the samples are very much similar.</p>\n\n<p>Please suggest an appropriate <code>classifier</code> (using <code>scikit-learn</code>) as well.</p>\n <machine-learning><classification><bigdata><scikit-learn><random-forest><p>This is the so-called \"Class Imbalance Problem\". Fortunately, there are a number of possible approaches. </p>\n\n<p>Probably easiest is going to be to use the <code>class_weight</code> option present in a number of scikit-learn's classifiers. For example, <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">LogisticRegression</a>.</p>\n\n<p>You can either set this option to <code>\"balanced\"</code> (or <code>\"auto\"</code> if you're using an older version of sklearn), in which case it automatically adjusts weights inversely proportional to class frequency (i.e. it tries to compensate for the class imbalance); or you can manually set the weights for each class label using a dict, e.g. <code>{0:1, 1: 20}</code>.</p>\n\n<p>For a worked example using an SVM, see <a href=\"http://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane_unbalanced.html\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<p>See here for more information: <a href=\"https://stats.stackexchange.com/questions/131255/class-imbalance-in-supervised-machine-learning\">https://stats.stackexchange.com/questions/131255/class-imbalance-in-supervised-machine-learning</a></p>\n<p>I find the proposed answer very good, using a cost sensitive approach would be the first step. Another solution to your issue would be to use some sort of Sampling to balance the two classes, like SMOTE. Have a look at <a href=\"https://github.com/scikit-learn-contrib/imbalanced-learn\" rel=\"nofollow\">imbalance-learn</a> module. Moreover, you may try to use other Classifiers, depends to what extend you want to go. I would give a try with Naive Bayes via Kernel estimation, which is simple and quick. You will have to check. In the end if no approach seems to predict the minority class you could degrade the majority class  via under sampling.</p>\n<p>The question mentions three training data characteristics.</p>\n\n<ul>\n<li>Very large</li>\n<li>Skewed</li>\n<li>Similarity in values for all but the last dimension</li>\n<li>Binary final dimension (~95% 1)</li>\n</ul>\n\n<p>The large N is actually a good thing in terms of classification accuracy, but the volume of data may necessitate distributed computing and/or large memory, disk, network, and CPU provisions.</p>\n\n<p>The narrow range of the real dimensions and the skew of the binary dimensions do not provide any information necessary to decide what classifier from scikit-learn is best.  If you plot any two dimensions and look at the pictures from <a href=\"http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\" rel=\"nofollow noreferrer\">the visual comparison page</a> you may be able to make a few best guesses yourself and try those first.</p>\n\n<p>The key to getting the best performance from these classifiers is to and normalize what you can in three main ways.</p>\n\n<ul>\n<li>Skew</li>\n<li>Range</li>\n<li>Offset</li>\n</ul>\n\n<p>One cannot de-skew the binary dimension since there are no intermediate values and changing a 1 to a 0 makes no sense statistically.  However, if the desired range to use in the classifier is -1 to 1, the data in that 7<sup>th</sup> dimension can be translated using x<sub>7</sub>' = 2 x<sub>7</sub> - 1.</p>\n\n<p>If one of the other dimensions has a skewed distribution and the classifier is known to work best with a normal distribution, it is possible that the data is exponentially distributed, in which case, if it is the 2<sup>nd</sup> dimension, the general translation might be x<sub>2</sub>' = ln (x<sub>2</sub>) / k<sub>1</sub> - k<sub>0</sub> where the constants are chosen to translate the distribution data to within the desired ideal range of the classifier.</p>\n\n<p>Various non-linear functions that compensate for skew can be used to improve classification significantly and the resulting learned behavior (model) can then be re-expressed using the inverse of these non-linear functions</p>\n\n<p>Scatter plots will become clearer indicators of which classifiers are likely to work best after distributions are normalized.</p>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "13990",
                "question_votes:": "",
                "question_text:": "<p>I have a very large <code>skewed</code> training set where every feature's <code>data-points</code> are very similar ?</p>\n\n<p>For example, following is some part of the training data :</p>\n\n<pre><code>93.65034,94.50283,94.6677,94.20174,94.93986,95.21071,1\n94.13783,94.61797,94.50526,95.66091,95.99478,95.12608,1\n94.0238,93.95445,94.77115,94.65469,95.08566,94.97906,1\n94.36343,94.32839,95.33167,95.24738,94.57213,95.05634,1\n94.65813,94.65246,94.64984,95.29596,95.14167,95.39941,1\n95.50876,94.45346,95.23837,95.26877,94.84924,94.8021,0\n94.5774,93.92291,94.96261,95.40926,95.97659,95.17691,0\n93.76617,94.27253,94.38002,94.28448,94.19957,94.98924,0\n</code></pre>\n\n<p>where the last column is the <code>class-label</code> - only 0 and 1.</p>\n\n<p>This only a part of the dataset, but the actual dataset contains about <code>95%</code> of samples with <code>class-label</code> being <code>1</code>, and the rest with <code>class-label</code> being <code>0</code>, despite the fact that more or less all the samples are very much similar.</p>\n\n<p>Please suggest an appropriate <code>classifier</code> (using <code>scikit-learn</code>) as well.</p>\n",
                "tags": "<machine-learning><classification><bigdata><scikit-learn><random-forest>",
                "answers": [
                    [
                        "13999",
                        "2",
                        "13990",
                        "",
                        "",
                        "<p>This is the so-called \"Class Imbalance Problem\". Fortunately, there are a number of possible approaches. </p>\n\n<p>Probably easiest is going to be to use the <code>class_weight</code> option present in a number of scikit-learn's classifiers. For example, <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">LogisticRegression</a>.</p>\n\n<p>You can either set this option to <code>\"balanced\"</code> (or <code>\"auto\"</code> if you're using an older version of sklearn), in which case it automatically adjusts weights inversely proportional to class frequency (i.e. it tries to compensate for the class imbalance); or you can manually set the weights for each class label using a dict, e.g. <code>{0:1, 1: 20}</code>.</p>\n\n<p>For a worked example using an SVM, see <a href=\"http://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane_unbalanced.html\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<p>See here for more information: <a href=\"https://stats.stackexchange.com/questions/131255/class-imbalance-in-supervised-machine-learning\">https://stats.stackexchange.com/questions/131255/class-imbalance-in-supervised-machine-learning</a></p>\n",
                        "",
                        "3"
                    ],
                    [
                        "15096",
                        "2",
                        "13990",
                        "",
                        "",
                        "<p>I find the proposed answer very good, using a cost sensitive approach would be the first step. Another solution to your issue would be to use some sort of Sampling to balance the two classes, like SMOTE. Have a look at <a href=\"https://github.com/scikit-learn-contrib/imbalanced-learn\" rel=\"nofollow\">imbalance-learn</a> module. Moreover, you may try to use other Classifiers, depends to what extend you want to go. I would give a try with Naive Bayes via Kernel estimation, which is simple and quick. You will have to check. In the end if no approach seems to predict the minority class you could degrade the majority class  via under sampling.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "16712",
                        "2",
                        "13990",
                        "",
                        "",
                        "<p>The question mentions three training data characteristics.</p>\n\n<ul>\n<li>Very large</li>\n<li>Skewed</li>\n<li>Similarity in values for all but the last dimension</li>\n<li>Binary final dimension (~95% 1)</li>\n</ul>\n\n<p>The large N is actually a good thing in terms of classification accuracy, but the volume of data may necessitate distributed computing and/or large memory, disk, network, and CPU provisions.</p>\n\n<p>The narrow range of the real dimensions and the skew of the binary dimensions do not provide any information necessary to decide what classifier from scikit-learn is best.  If you plot any two dimensions and look at the pictures from <a href=\"http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\" rel=\"nofollow noreferrer\">the visual comparison page</a> you may be able to make a few best guesses yourself and try those first.</p>\n\n<p>The key to getting the best performance from these classifiers is to and normalize what you can in three main ways.</p>\n\n<ul>\n<li>Skew</li>\n<li>Range</li>\n<li>Offset</li>\n</ul>\n\n<p>One cannot de-skew the binary dimension since there are no intermediate values and changing a 1 to a 0 makes no sense statistically.  However, if the desired range to use in the classifier is -1 to 1, the data in that 7<sup>th</sup> dimension can be translated using x<sub>7</sub>' = 2 x<sub>7</sub> - 1.</p>\n\n<p>If one of the other dimensions has a skewed distribution and the classifier is known to work best with a normal distribution, it is possible that the data is exponentially distributed, in which case, if it is the 2<sup>nd</sup> dimension, the general translation might be x<sub>2</sub>' = ln (x<sub>2</sub>) / k<sub>1</sub> - k<sub>0</sub> where the constants are chosen to translate the distribution data to within the desired ideal range of the classifier.</p>\n\n<p>Various non-linear functions that compensate for skew can be used to improve classification significantly and the resulting learned behavior (model) can then be re-expressed using the inverse of these non-linear functions</p>\n\n<p>Scatter plots will become clearer indicators of which classifiers are likely to work best after distributions are normalized.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16092",
            "_score": 10.137661,
            "_source": {
                "title": "Logistic Regression doesn't predict for the entire test set",
                "content": "Logistic Regression doesn't predict for the entire test set <p>I am working through Kaggle's Titanic competition.  I am mostly done with my model but the problem is that the logistic regression model does not predict for all of 418 rows in the test set but instead just returns predictions for 197 rows.  This is the error PyCharm gives:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"C:/Users/security/Downloads/AP/Titanic-Kaggle/TItanic-Kaggle.py\", line 37, in &lt;module&gt;\n    submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': predictions})\n  File \"C:\\Users\\security\\Anaconda3\\envs\\TItanic-Kaggle.py\\lib\\site-packages\\pandas\\core\\frame.py\", line 392, in __init__\n    mgr = init_dict(data, index, columns, dtype=dtype)\n  File \"C:\\Users\\security\\Anaconda3\\envs\\TItanic-Kaggle.py\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 212, in init_dict\n    return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype)\n  File \"C:\\Users\\security\\Anaconda3\\envs\\TItanic-Kaggle.py\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 51, in arrays_to_mgr\n    index = extract_index(arrays)\n  File \"C:\\Users\\security\\Anaconda3\\envs\\TItanic-Kaggle.py\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 328, in extract_index\n    raise ValueError(msg)\nValueError: array length 197 does not match index length 418\n</code></pre>\n\n<p>When I <code>print(predictions)</code> to confirm, this is what it gives:</p>\n\n<pre><code>[0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0\n 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0\n 0 1 1 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0\n 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 1\n 1 0 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0\n 0 1 0 0 1 1 0 1 1 0 0 0]\n</code></pre>\n\n<p>This is my full code:</p>\n\n<pre><code>import pandas as pd\nimport warnings\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\ntrain = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Titanic-Kaggle/master/train.csv\")\ntest = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Titanic-Kaggle/master/test.csv\")\n\ntrain['Sex'] = train['Sex'].replace(['female', 'male'], [0, 1])\ntrain['Embarked'] = train['Embarked'].replace(['C', 'Q', 'S'], [1, 2, 3])\n\n# Fill missing values in Age feature with each sex\u2019s median value of Age\ntrain['Age'].fillna(train.groupby('Sex')['Age'].transform(\"median\"), inplace=True)\n\n# Creating a new column called \"HasCabin\", where passengers with a cabin will get a score of 1 and those without cabins will get a score of 0\ntrain['HasCabin'] = train['Cabin'].notnull().astype(int)\n\ntrain['Relatives'] = train['SibSp'] + train['Parch']\n\nlogReg = LogisticRegression()\n\ndata = train[['Pclass', 'Sex', 'Relatives', 'Fare', 'Age', 'Embarked', 'HasCabin']]\n\n# implement train_test_split\nx_train, x_test, y_train, y_test = train_test_split(data, train['Survived'], test_size=0.22, random_state=0)\n\n# Training the model with the Logistic Regression algorithm\nlogReg.fit(x_train, y_train)\n\npredictions = logReg.predict(x_test)\nsubmission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': predictions})\n\nfilename = 'Titanic-Submission.csv'\nsubmission.to_csv(filename, index=False)\n</code></pre>\n\n<p><strong>UPDATE</strong></p>\n\n<p>As per what the users have pointed out, I went ahead and tried to remedy my mistake (ignore the code repetition. I'll be solving that later):</p>\n\n<pre><code>import pandas as pd\nimport warnings\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\ntrain = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Titanic-Kaggle/master/train.csv\")\ntest = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Titanic-Kaggle/master/test.csv\")\n\ntrain['Sex'] = train['Sex'].replace(['female', 'male'], [0, 1])\ntrain['Embarked'] = train['Embarked'].replace(['C', 'Q', 'S'], [1, 2, 3])\ntrain['Age'].fillna(train.groupby('Sex')['Age'].transform(\"median\"), inplace=True)\ntrain['HasCabin'] = train['Cabin'].notnull().astype(int)\ntrain['Relatives'] = train['SibSp'] + train['Parch']\ntrain_data = train[['Pclass', 'Sex', 'Relatives', 'Fare', 'Age', 'Embarked', 'HasCabin']]\nx_train, x_validate, y_train, y_validate = train_test_split(train_data, train['Survived'], test_size=0.22, random_state=0)\n\ntest['Sex'] = test['Sex'].replace(['female', 'male'], [0, 1])\ntest['Embarked'] = test['Embarked'].replace(['C', 'Q', 'R'], [1, 2, 3])\ntest['Age'].fillna(test.groupby('Sex')['Age'].transform(\"median\"), inplace=True)\ntest['HasCabin'] = test['Cabin'].notnull().astype(int)\ntest['Relatives'] = test['SibSp'] + test['Parch']\ntest_data = test[['Pclass', 'Sex', 'Relatives', 'Fare', 'Age', 'Embarked', 'HasCabin']]\n\nlogReg = LogisticRegression()\nlogReg.fit(x_train, y_train)\n\npredictions = logReg.predict(test[test_data])\nsubmission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': predictions})\n\nfilename = 'Titanic-Submission.csv'\nsubmission.to_csv(filename, index=False)\n</code></pre>\n\n<p>As you can see, I tried to input the select test features into my algorithm</p>\n\n<pre><code>test_data = test[['Pclass', 'Sex', 'Relatives', 'Fare', 'Age', 'Embarked', 'HasCabin']]\n\n...\n\npredictions = logReg.predict(test[test_data])\n</code></pre>\n\n<p>Right now, I'm getting the following error:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"C:/Users/security/Downloads/AP/Titanic-Kaggle/TItanic-Kaggle.py\", line 29, in &lt;module&gt;\n    predictions = logReg.predict(test[test_data])\n  File \"C:\\Users\\security\\Anaconda3\\envs\\TItanic-Kaggle.py\\lib\\site-packages\\pandas\\core\\frame.py\", line 2914, in __getitem__\n    return self._getitem_frame(key)\n  File \"C:\\Users\\security\\Anaconda3\\envs\\TItanic-Kaggle.py\\lib\\site-packages\\pandas\\core\\frame.py\", line 3009, in _getitem_frame\n    raise ValueError('Must pass DataFrame with boolean values only')\nValueError: Must pass DataFrame with boolean values only\n</code></pre>\n\n<p>Its telling me that I need to pass boolean values into my algorithm but I don't understand why. There wasn't such a prerequisite when I was using the exact same data format while training the model.</p>\n <machine-learning><python><scikit-learn><logistic-regression><kaggle><p>Your <code>predictions</code> are those for <code>x_test</code>, which was split out from <code>train</code>, but your <code>submission</code>'s <code>PassengerId</code>s are those from <code>test</code>.</p>\n\n<p>It appears you want to submit predictions for <code>test</code>, so you need to call <code>logReg.predict</code> on that instead of <code>x_test</code>.  However, as @Peter notes in a comment, that will fail since the columns in <code>test</code> are not the same as in <code>train</code> and therefore <code>x_train</code> and <code>x_test</code>.  Your feature encodings, null replacement, and engineering need to be done for <code>test</code> as well (but take care to to use <code>train</code>'s median when filling <code>test</code>'s missing ages).</p>\n<p>OK, I see your point ... check this code snippet out </p>\n\n<p>you need to adapt it for your 'Titanic-Submission.csv'</p>\n\n<p>the number of predictions will be N = rows</p>\n\n<p>good luck!</p>\n\n<p><a href=\"https://www.kaggle.com/geoffpidcock/example-submission\" rel=\"nofollow noreferrer\">https://www.kaggle.com/geoffpidcock/example-submission</a></p>\n\n<p><a href=\"https://i.stack.imgur.com/dfQYb.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/dfQYb.jpg\" alt=\"enter image description here\"></a></p>\n<p>I feel with you that predictions/submissions are hard for beginners but at the same time, I doubt you can expect anyone here to take you step by step through the solution.</p>\n\n<p>Does this code not help you?</p>\n\n<p><a href=\"https://www.kaggle.com/jlawman/complete-beginner-your-first-titanic-submission\" rel=\"nofollow noreferrer\">https://www.kaggle.com/jlawman/complete-beginner-your-first-titanic-submission</a></p>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "53325",
                "question_votes:": "2",
                "question_text:": "<p>I am working through Kaggle's Titanic competition.  I am mostly done with my model but the problem is that the logistic regression model does not predict for all of 418 rows in the test set but instead just returns predictions for 197 rows.  This is the error PyCharm gives:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"C:/Users/security/Downloads/AP/Titanic-Kaggle/TItanic-Kaggle.py\", line 37, in &lt;module&gt;\n    submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': predictions})\n  File \"C:\\Users\\security\\Anaconda3\\envs\\TItanic-Kaggle.py\\lib\\site-packages\\pandas\\core\\frame.py\", line 392, in __init__\n    mgr = init_dict(data, index, columns, dtype=dtype)\n  File \"C:\\Users\\security\\Anaconda3\\envs\\TItanic-Kaggle.py\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 212, in init_dict\n    return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype)\n  File \"C:\\Users\\security\\Anaconda3\\envs\\TItanic-Kaggle.py\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 51, in arrays_to_mgr\n    index = extract_index(arrays)\n  File \"C:\\Users\\security\\Anaconda3\\envs\\TItanic-Kaggle.py\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 328, in extract_index\n    raise ValueError(msg)\nValueError: array length 197 does not match index length 418\n</code></pre>\n\n<p>When I <code>print(predictions)</code> to confirm, this is what it gives:</p>\n\n<pre><code>[0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0\n 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0\n 0 1 1 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0\n 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 1\n 1 0 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0\n 0 1 0 0 1 1 0 1 1 0 0 0]\n</code></pre>\n\n<p>This is my full code:</p>\n\n<pre><code>import pandas as pd\nimport warnings\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\ntrain = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Titanic-Kaggle/master/train.csv\")\ntest = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Titanic-Kaggle/master/test.csv\")\n\ntrain['Sex'] = train['Sex'].replace(['female', 'male'], [0, 1])\ntrain['Embarked'] = train['Embarked'].replace(['C', 'Q', 'S'], [1, 2, 3])\n\n# Fill missing values in Age feature with each sex\u2019s median value of Age\ntrain['Age'].fillna(train.groupby('Sex')['Age'].transform(\"median\"), inplace=True)\n\n# Creating a new column called \"HasCabin\", where passengers with a cabin will get a score of 1 and those without cabins will get a score of 0\ntrain['HasCabin'] = train['Cabin'].notnull().astype(int)\n\ntrain['Relatives'] = train['SibSp'] + train['Parch']\n\nlogReg = LogisticRegression()\n\ndata = train[['Pclass', 'Sex', 'Relatives', 'Fare', 'Age', 'Embarked', 'HasCabin']]\n\n# implement train_test_split\nx_train, x_test, y_train, y_test = train_test_split(data, train['Survived'], test_size=0.22, random_state=0)\n\n# Training the model with the Logistic Regression algorithm\nlogReg.fit(x_train, y_train)\n\npredictions = logReg.predict(x_test)\nsubmission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': predictions})\n\nfilename = 'Titanic-Submission.csv'\nsubmission.to_csv(filename, index=False)\n</code></pre>\n\n<p><strong>UPDATE</strong></p>\n\n<p>As per what the users have pointed out, I went ahead and tried to remedy my mistake (ignore the code repetition. I'll be solving that later):</p>\n\n<pre><code>import pandas as pd\nimport warnings\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\ntrain = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Titanic-Kaggle/master/train.csv\")\ntest = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Titanic-Kaggle/master/test.csv\")\n\ntrain['Sex'] = train['Sex'].replace(['female', 'male'], [0, 1])\ntrain['Embarked'] = train['Embarked'].replace(['C', 'Q', 'S'], [1, 2, 3])\ntrain['Age'].fillna(train.groupby('Sex')['Age'].transform(\"median\"), inplace=True)\ntrain['HasCabin'] = train['Cabin'].notnull().astype(int)\ntrain['Relatives'] = train['SibSp'] + train['Parch']\ntrain_data = train[['Pclass', 'Sex', 'Relatives', 'Fare', 'Age', 'Embarked', 'HasCabin']]\nx_train, x_validate, y_train, y_validate = train_test_split(train_data, train['Survived'], test_size=0.22, random_state=0)\n\ntest['Sex'] = test['Sex'].replace(['female', 'male'], [0, 1])\ntest['Embarked'] = test['Embarked'].replace(['C', 'Q', 'R'], [1, 2, 3])\ntest['Age'].fillna(test.groupby('Sex')['Age'].transform(\"median\"), inplace=True)\ntest['HasCabin'] = test['Cabin'].notnull().astype(int)\ntest['Relatives'] = test['SibSp'] + test['Parch']\ntest_data = test[['Pclass', 'Sex', 'Relatives', 'Fare', 'Age', 'Embarked', 'HasCabin']]\n\nlogReg = LogisticRegression()\nlogReg.fit(x_train, y_train)\n\npredictions = logReg.predict(test[test_data])\nsubmission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': predictions})\n\nfilename = 'Titanic-Submission.csv'\nsubmission.to_csv(filename, index=False)\n</code></pre>\n\n<p>As you can see, I tried to input the select test features into my algorithm</p>\n\n<pre><code>test_data = test[['Pclass', 'Sex', 'Relatives', 'Fare', 'Age', 'Embarked', 'HasCabin']]\n\n...\n\npredictions = logReg.predict(test[test_data])\n</code></pre>\n\n<p>Right now, I'm getting the following error:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"C:/Users/security/Downloads/AP/Titanic-Kaggle/TItanic-Kaggle.py\", line 29, in &lt;module&gt;\n    predictions = logReg.predict(test[test_data])\n  File \"C:\\Users\\security\\Anaconda3\\envs\\TItanic-Kaggle.py\\lib\\site-packages\\pandas\\core\\frame.py\", line 2914, in __getitem__\n    return self._getitem_frame(key)\n  File \"C:\\Users\\security\\Anaconda3\\envs\\TItanic-Kaggle.py\\lib\\site-packages\\pandas\\core\\frame.py\", line 3009, in _getitem_frame\n    raise ValueError('Must pass DataFrame with boolean values only')\nValueError: Must pass DataFrame with boolean values only\n</code></pre>\n\n<p>Its telling me that I need to pass boolean values into my algorithm but I don't understand why. There wasn't such a prerequisite when I was using the exact same data format while training the model.</p>\n",
                "tags": "<machine-learning><python><scikit-learn><logistic-regression><kaggle>",
                "answers": [
                    [
                        "53338",
                        "2",
                        "53325",
                        "",
                        "",
                        "<p>Your <code>predictions</code> are those for <code>x_test</code>, which was split out from <code>train</code>, but your <code>submission</code>'s <code>PassengerId</code>s are those from <code>test</code>.</p>\n\n<p>It appears you want to submit predictions for <code>test</code>, so you need to call <code>logReg.predict</code> on that instead of <code>x_test</code>.  However, as @Peter notes in a comment, that will fail since the columns in <code>test</code> are not the same as in <code>train</code> and therefore <code>x_train</code> and <code>x_test</code>.  Your feature encodings, null replacement, and engineering need to be done for <code>test</code> as well (but take care to to use <code>train</code>'s median when filling <code>test</code>'s missing ages).</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "53535",
                        "2",
                        "53325",
                        "",
                        "",
                        "<p>OK, I see your point ... check this code snippet out </p>\n\n<p>you need to adapt it for your 'Titanic-Submission.csv'</p>\n\n<p>the number of predictions will be N = rows</p>\n\n<p>good luck!</p>\n\n<p><a href=\"https://www.kaggle.com/geoffpidcock/example-submission\" rel=\"nofollow noreferrer\">https://www.kaggle.com/geoffpidcock/example-submission</a></p>\n\n<p><a href=\"https://i.stack.imgur.com/dfQYb.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/dfQYb.jpg\" alt=\"enter image description here\"></a></p>\n",
                        "",
                        "1"
                    ],
                    [
                        "53339",
                        "2",
                        "53325",
                        "",
                        "",
                        "<p>I feel with you that predictions/submissions are hard for beginners but at the same time, I doubt you can expect anyone here to take you step by step through the solution.</p>\n\n<p>Does this code not help you?</p>\n\n<p><a href=\"https://www.kaggle.com/jlawman/complete-beginner-your-first-titanic-submission\" rel=\"nofollow noreferrer\">https://www.kaggle.com/jlawman/complete-beginner-your-first-titanic-submission</a></p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9727",
            "_score": 10.123885,
            "_source": {
                "title": "Titanic Kaggle Data: Why am I getting lower accuracy on Kaggle submissions than on held-out data?",
                "content": "Titanic Kaggle Data: Why am I getting lower accuracy on Kaggle submissions than on held-out data? <p>I am going through my first solo machine learning project and would like to gain some insight into what I am doing wrong/what is going on here as I am a bit stuck.</p>\n\n<p>I have been applying machine learning to the Titanic data set with SKlearn and have been holding out 10% of the training data to calculate the accuracy of my fitted models. I also use K-fold cross valdation with 10 folds to evaluate the model performance and choose hyper-parameters. I have so far applied logistic regression and a linear Kernel SVM and in both cases I get 78-80% accuracy on the K-fold validation sets and when applying the fitted classifiers to my held-back previously unseen testing data. However when I predict on Kaggle's test data and submit my predictions it comes back with values around 76% which is significantly less than I'd expect, and well outside the variance in the accuracy values I get with K-fold cross validation.</p>\n\n<p>A link to the Jupyter notebook where I do this is provided below: <a href=\"http://nbviewer.jupyter.org/github/AshleySetter/Kaggle_Competitions/blob/master/Titanic_project/Titanic_machine_learning_clean.ipynb\" rel=\"nofollow noreferrer\">http://nbviewer.jupyter.org/github/AshleySetter/Kaggle_Competitions/blob/master/Titanic_project/Titanic_machine_learning_clean.ipynb</a></p>\n\n<p>Could anyone give me some insight into what is going on here and what I am doing wrong?</p>\n <python><scikit-learn><predictive-modeling><cross-validation><accuracy><ol>\n<li><p>It could be because of the percentage of the different class.\nImagine your data is 30% survived and 70% died but in Kaggle's test data this ratio may change, i.e 50%-50%. So your model could not predict kaggle's survived part as well as your test data.</p></li>\n<li><p>you may impute missing by the mean. if you use test data for calculating mean it could be a cheating for your model.</p></li>\n</ol>\n",
                "codes": [
                    []
                ],
                "question_id:": "35504",
                "question_votes:": "",
                "question_text:": "<p>I am going through my first solo machine learning project and would like to gain some insight into what I am doing wrong/what is going on here as I am a bit stuck.</p>\n\n<p>I have been applying machine learning to the Titanic data set with SKlearn and have been holding out 10% of the training data to calculate the accuracy of my fitted models. I also use K-fold cross valdation with 10 folds to evaluate the model performance and choose hyper-parameters. I have so far applied logistic regression and a linear Kernel SVM and in both cases I get 78-80% accuracy on the K-fold validation sets and when applying the fitted classifiers to my held-back previously unseen testing data. However when I predict on Kaggle's test data and submit my predictions it comes back with values around 76% which is significantly less than I'd expect, and well outside the variance in the accuracy values I get with K-fold cross validation.</p>\n\n<p>A link to the Jupyter notebook where I do this is provided below: <a href=\"http://nbviewer.jupyter.org/github/AshleySetter/Kaggle_Competitions/blob/master/Titanic_project/Titanic_machine_learning_clean.ipynb\" rel=\"nofollow noreferrer\">http://nbviewer.jupyter.org/github/AshleySetter/Kaggle_Competitions/blob/master/Titanic_project/Titanic_machine_learning_clean.ipynb</a></p>\n\n<p>Could anyone give me some insight into what is going on here and what I am doing wrong?</p>\n",
                "tags": "<python><scikit-learn><predictive-modeling><cross-validation><accuracy>",
                "answers": [
                    [
                        "35512",
                        "2",
                        "35504",
                        "",
                        "",
                        "<ol>\n<li><p>It could be because of the percentage of the different class.\nImagine your data is 30% survived and 70% died but in Kaggle's test data this ratio may change, i.e 50%-50%. So your model could not predict kaggle's survived part as well as your test data.</p></li>\n<li><p>you may impute missing by the mean. if you use test data for calculating mean it could be a cheating for your model.</p></li>\n</ol>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4020",
            "_score": 10.116948,
            "_source": {
                "title": "Data Science Noob - Customer Scoring based on conversion probability",
                "content": "Data Science Noob - Customer Scoring based on conversion probability <p>I work at a University and have a project to be able to score applicants based on their likelihood to enroll (convert), using their answers to application form questions.</p>\n\n<p>The applications contain name, DOB, date &amp; time of application, country, gender, course selected, English proficiency, funding availability and some other similar fields. There are also various free-text fields, but I think these will complicate things too much to begin with.</p>\n\n<p>My initial thought is to use a regression model to do this, using R. But I am a complete noob - I studied regression at uni 10 years ago.... </p>\n\n<p>I have had a search around and I think once I know I'm on the right path I will be able to figure the process out but I am unsure where to begin, and do not want to start by going down the wrong avenue. My main concerns are:</p>\n\n<ul>\n<li>Is a regression model the correct approach? If not what is?</li>\n<li>Are categorical fields a problem - as opposed to continuous fields?</li>\n<li>There is additional information which is only available for some applicants - can this be included, or do we need to use the same information for all applicants?</li>\n</ul>\n <r><predictive-modeling><regression><p>Let's see (broad strokes ahead)</p>\n\n<p>There are two ways of doing it supervised learning and unsupervised learning.</p>\n\n<p>For supervised learning we either need previous years data (with the final enrollments) or you need to calculate the probability of some of the applications(Enough so that the model can predict accurately for new data). Then it becomes a problem of linear regression(as probability will be a continuous variable). If you decide a certain cutoff(threshold) that probability(y =0 below and y =1 above ) then it becomes a problem of logistic regression.\nOnce the data is ready machine learning can be done in half an hour. \nNow to answer your questions.</p>\n\n<ul>\n<li>Yes, Regression model is a correct approach but it's a broad term.</li>\n<li>Not a problem, you need to make the categorical fields factor using <code>as.factor()</code> in R.</li>\n<li>you should use same information for all the applicants but that doesn't mean you can't use that info. If the fact that information is available has a bearing on the outcome then make a variable and put it 1 or 0 accordingly. If what's available in that information has a bearing then it gets a little tricky, may be count the number of common relevant words and put that number in a variable.</li>\n</ul>\n<p>Your question could be closed for too broad, but let's give a try. You want the enrolment probability, this sounds like a logistic regression for me. Neither categorical nor continuous data type should present a problem. You may model the additional information, applications who don't have one simply be assigned a <code>NA</code> category. You can include the <code>NA</code> category in your model.</p>\n\n<p>I recommend you read the book <code>Applied Predictive Modelling</code>, I think it has a section on credit-card applications, which is close to what you are doing. You should try to learn from it.</p>\n<p>The problem you're trying to solve is called binary classification. There are many algorithms and there's ton of tutorials on it. Actually it is so well studied that ready-made tools are available that try all algorithms and choose the best for your task. <a href=\"https://github.com/paypal/autosklearn-zeroconf\" rel=\"nofollow noreferrer\">https://github.com/paypal/autosklearn-zeroconf</a> is one of them that makes auto-sklearn binary classifier able to run on arbitrary tabular data (like what you have). </p>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "16448",
                "question_votes:": "3",
                "question_text:": "<p>I work at a University and have a project to be able to score applicants based on their likelihood to enroll (convert), using their answers to application form questions.</p>\n\n<p>The applications contain name, DOB, date &amp; time of application, country, gender, course selected, English proficiency, funding availability and some other similar fields. There are also various free-text fields, but I think these will complicate things too much to begin with.</p>\n\n<p>My initial thought is to use a regression model to do this, using R. But I am a complete noob - I studied regression at uni 10 years ago.... </p>\n\n<p>I have had a search around and I think once I know I'm on the right path I will be able to figure the process out but I am unsure where to begin, and do not want to start by going down the wrong avenue. My main concerns are:</p>\n\n<ul>\n<li>Is a regression model the correct approach? If not what is?</li>\n<li>Are categorical fields a problem - as opposed to continuous fields?</li>\n<li>There is additional information which is only available for some applicants - can this be included, or do we need to use the same information for all applicants?</li>\n</ul>\n",
                "tags": "<r><predictive-modeling><regression>",
                "answers": [
                    [
                        "16451",
                        "2",
                        "16448",
                        "",
                        "",
                        "<p>Let's see (broad strokes ahead)</p>\n\n<p>There are two ways of doing it supervised learning and unsupervised learning.</p>\n\n<p>For supervised learning we either need previous years data (with the final enrollments) or you need to calculate the probability of some of the applications(Enough so that the model can predict accurately for new data). Then it becomes a problem of linear regression(as probability will be a continuous variable). If you decide a certain cutoff(threshold) that probability(y =0 below and y =1 above ) then it becomes a problem of logistic regression.\nOnce the data is ready machine learning can be done in half an hour. \nNow to answer your questions.</p>\n\n<ul>\n<li>Yes, Regression model is a correct approach but it's a broad term.</li>\n<li>Not a problem, you need to make the categorical fields factor using <code>as.factor()</code> in R.</li>\n<li>you should use same information for all the applicants but that doesn't mean you can't use that info. If the fact that information is available has a bearing on the outcome then make a variable and put it 1 or 0 accordingly. If what's available in that information has a bearing then it gets a little tricky, may be count the number of common relevant words and put that number in a variable.</li>\n</ul>\n",
                        "",
                        ""
                    ],
                    [
                        "16449",
                        "2",
                        "16448",
                        "",
                        "",
                        "<p>Your question could be closed for too broad, but let's give a try. You want the enrolment probability, this sounds like a logistic regression for me. Neither categorical nor continuous data type should present a problem. You may model the additional information, applications who don't have one simply be assigned a <code>NA</code> category. You can include the <code>NA</code> category in your model.</p>\n\n<p>I recommend you read the book <code>Applied Predictive Modelling</code>, I think it has a section on credit-card applications, which is close to what you are doing. You should try to learn from it.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "18538",
                        "2",
                        "16448",
                        "",
                        "",
                        "<p>The problem you're trying to solve is called binary classification. There are many algorithms and there's ton of tutorials on it. Actually it is so well studied that ready-made tools are available that try all algorithms and choose the best for your task. <a href=\"https://github.com/paypal/autosklearn-zeroconf\" rel=\"nofollow noreferrer\">https://github.com/paypal/autosklearn-zeroconf</a> is one of them that makes auto-sklearn binary classifier able to run on arbitrary tabular data (like what you have). </p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "18074",
            "_score": 10.097311,
            "_source": {
                "title": "Can ridge regression be used for feature selection?",
                "content": "Can ridge regression be used for feature selection? <p>I'm trying to figure out whether using Ridge Regression for regularization can be used to cause a more sparse hypothesis however to me it seems like ridge will never actually bring any coefficients to zero, only really close to it.</p>\n\n<p>So can ridge regression cause any coefficients to become zero? Can the number of zeros in a weights vector change from zero to something else?\nOr maybe to put it simply, are the number of zero coefficients using ridge regression monotonically increasing or possibly decreasing?</p>\n\n<p>Thanks.</p>\n <machine-learning><feature-selection><regularization><ridge-regression><p>Unlike lasso, ridge does not have zeroing coefficients as a goal, and you shouldn't expect applying ridge penalty to have this effect.  So the answer to your title question is \"no.\"</p>\n\n<p>However, in your question body, you ask whether it is <em>possible</em> for the ridge penalty to produce a zero coefficient that was nonzero in an unpenalized solution.  The answer here is \"yes,\" but only as an incredible coincidence (which explains why the answer to the title question is no).</p>\n\n<p>See the image in <a href=\"https://stats.stackexchange.com/a/151960/232706\">this answer</a> (also floating around in plenty of other places).  If the (unpenalized) error's contours happen to meet the constraint circle tangentially on one of the axes, that variable's coefficient will become zero.  This would be an incredible coincidence, but it is theoretically possible.  (<a href=\"https://stats.stackexchange.com/a/63131/232706\">Regularization can even switch the sign on the coefficient!</a>)</p>\n\n<p>I've put together a toy example to show this.  <a href=\"https://github.com/bmreiniger/datascience.stackexchange/blob/master/57604.ipynb\" rel=\"nofollow noreferrer\">GitHub/Colab notebook.</a><br>\n(In <code>sklearn</code>, we're used to thinking about regularized regression in terms of the Lagrangian form; for these kinds of diagrams, it's perhaps better to think in the constrained optimization form.  See the connection e.g. <a href=\"https://math.stackexchange.com/questions/335306/why-are-additional-constraint-and-penalty-term-equivalent-in-ridge-regression\">here</a>)<br>\nLet <span class=\"math-container\">$X=\\begin{pmatrix}1 &amp; 1 \\\\ \\sqrt{5} &amp; -\\sqrt{5} \\end{pmatrix}$</span>, <span class=\"math-container\">$y=\\begin{pmatrix}3 \\\\ -\\sqrt{5}\\end{pmatrix}$</span>.  There is an exact solution, <span class=\"math-container\">$y=X\\begin{pmatrix}1\\\\2\\end{pmatrix}$</span>, so the unpenalized loss contours are (not axis-aligned) ellipses centered at <span class=\"math-container\">$(1,2)$</span>.  When the L2 penalty coefficient <span class=\"math-container\">$\\lambda$</span> is 5, the solution is <span class=\"math-container\">$(0,0.5)$</span>.  When <span class=\"math-container\">$0&lt;\\lambda&lt;5$</span>, the solution has first weight positive, and when <span class=\"math-container\">$\\lambda&gt;5$</span> the first weight is negative(! Taking this coefficient slightly negative allows us to decrease the second coefficient even smaller, lowering the overall penalty).</p>\n<p>Regularization of Ridge causes its weight to become very close to zero, but not zero. In contrast lasso can make weights equal to zero because of the types of regularization they use.</p>\n\n<p>I would recommend to use lasso if you have lots of features, and you think just few of them are important. Otherwise, even though your model becomes simpler you will have a poor accuracy.</p>\n\n<p>There is ElasticNet which combines both, but it is more expensive since it uses two regularization.</p>\n\n<p>I didn't really understand what you ask by </p>\n\n<blockquote>\n  <p>Can the number of zeros in a weights vector change from zero to something else?</p>\n</blockquote>\n\n<p>If you determined number of parameters beforehand their weights are unknown yet, not zero. That's what you are trying to find.</p>\n\n<p>One last thing, for feature selection there are other methods. These(ridge, lasso) are just linear models for regression. If you want to identify which features work best etc. I suggest you to do a research on methods for this.</p>\n<p>As mentioned by others, only Lasso can shrink parameters to exactly zero (while Ridge or Elastic Net will not, see Ch. 6.2.2 in <em>Introduction to Statistical Learning</em>). Lasso has some advantages, i.e. it can be used to deal with high dimensional data. For feature selection, some use a \"<a href=\"https://stats.stackexchange.com/questions/213449/double-lasso-variable-selection\">double Lasso</a>\" approach.</p>\n\n<p>In case you only want to do feature selection (or best subset selection), there are also other possibilities beyond Lasso, namely <a href=\"https://web.stanford.edu/class/stats202/content/lec13.pdf\" rel=\"nofollow noreferrer\">forward or backward stepwise selection</a>. </p>\n\n<p>The book \"Introduction to Statistical Learning\" (Chapter 6: Linear Model Selection\nand Regularization) gives a really instructive overview of model selection techniques. </p>\n\n<p>The code examples are online <a href=\"https://github.com/rghan/ISLR\" rel=\"nofollow noreferrer\">for R</a> and <a href=\"https://github.com/JWarmenhoven/ISLR-python\" rel=\"nofollow noreferrer\">Python</a>. </p>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "57604",
                "question_votes:": "2",
                "question_text:": "<p>I'm trying to figure out whether using Ridge Regression for regularization can be used to cause a more sparse hypothesis however to me it seems like ridge will never actually bring any coefficients to zero, only really close to it.</p>\n\n<p>So can ridge regression cause any coefficients to become zero? Can the number of zeros in a weights vector change from zero to something else?\nOr maybe to put it simply, are the number of zero coefficients using ridge regression monotonically increasing or possibly decreasing?</p>\n\n<p>Thanks.</p>\n",
                "tags": "<machine-learning><feature-selection><regularization><ridge-regression>",
                "answers": [
                    [
                        "57671",
                        "2",
                        "57604",
                        "",
                        "",
                        "<p>Unlike lasso, ridge does not have zeroing coefficients as a goal, and you shouldn't expect applying ridge penalty to have this effect.  So the answer to your title question is \"no.\"</p>\n\n<p>However, in your question body, you ask whether it is <em>possible</em> for the ridge penalty to produce a zero coefficient that was nonzero in an unpenalized solution.  The answer here is \"yes,\" but only as an incredible coincidence (which explains why the answer to the title question is no).</p>\n\n<p>See the image in <a href=\"https://stats.stackexchange.com/a/151960/232706\">this answer</a> (also floating around in plenty of other places).  If the (unpenalized) error's contours happen to meet the constraint circle tangentially on one of the axes, that variable's coefficient will become zero.  This would be an incredible coincidence, but it is theoretically possible.  (<a href=\"https://stats.stackexchange.com/a/63131/232706\">Regularization can even switch the sign on the coefficient!</a>)</p>\n\n<p>I've put together a toy example to show this.  <a href=\"https://github.com/bmreiniger/datascience.stackexchange/blob/master/57604.ipynb\" rel=\"nofollow noreferrer\">GitHub/Colab notebook.</a><br>\n(In <code>sklearn</code>, we're used to thinking about regularized regression in terms of the Lagrangian form; for these kinds of diagrams, it's perhaps better to think in the constrained optimization form.  See the connection e.g. <a href=\"https://math.stackexchange.com/questions/335306/why-are-additional-constraint-and-penalty-term-equivalent-in-ridge-regression\">here</a>)<br>\nLet <span class=\"math-container\">$X=\\begin{pmatrix}1 &amp; 1 \\\\ \\sqrt{5} &amp; -\\sqrt{5} \\end{pmatrix}$</span>, <span class=\"math-container\">$y=\\begin{pmatrix}3 \\\\ -\\sqrt{5}\\end{pmatrix}$</span>.  There is an exact solution, <span class=\"math-container\">$y=X\\begin{pmatrix}1\\\\2\\end{pmatrix}$</span>, so the unpenalized loss contours are (not axis-aligned) ellipses centered at <span class=\"math-container\">$(1,2)$</span>.  When the L2 penalty coefficient <span class=\"math-container\">$\\lambda$</span> is 5, the solution is <span class=\"math-container\">$(0,0.5)$</span>.  When <span class=\"math-container\">$0&lt;\\lambda&lt;5$</span>, the solution has first weight positive, and when <span class=\"math-container\">$\\lambda&gt;5$</span> the first weight is negative(! Taking this coefficient slightly negative allows us to decrease the second coefficient even smaller, lowering the overall penalty).</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "57625",
                        "2",
                        "57604",
                        "",
                        "",
                        "<p>Regularization of Ridge causes its weight to become very close to zero, but not zero. In contrast lasso can make weights equal to zero because of the types of regularization they use.</p>\n\n<p>I would recommend to use lasso if you have lots of features, and you think just few of them are important. Otherwise, even though your model becomes simpler you will have a poor accuracy.</p>\n\n<p>There is ElasticNet which combines both, but it is more expensive since it uses two regularization.</p>\n\n<p>I didn't really understand what you ask by </p>\n\n<blockquote>\n  <p>Can the number of zeros in a weights vector change from zero to something else?</p>\n</blockquote>\n\n<p>If you determined number of parameters beforehand their weights are unknown yet, not zero. That's what you are trying to find.</p>\n\n<p>One last thing, for feature selection there are other methods. These(ridge, lasso) are just linear models for regression. If you want to identify which features work best etc. I suggest you to do a research on methods for this.</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "57649",
                        "2",
                        "57604",
                        "",
                        "",
                        "<p>As mentioned by others, only Lasso can shrink parameters to exactly zero (while Ridge or Elastic Net will not, see Ch. 6.2.2 in <em>Introduction to Statistical Learning</em>). Lasso has some advantages, i.e. it can be used to deal with high dimensional data. For feature selection, some use a \"<a href=\"https://stats.stackexchange.com/questions/213449/double-lasso-variable-selection\">double Lasso</a>\" approach.</p>\n\n<p>In case you only want to do feature selection (or best subset selection), there are also other possibilities beyond Lasso, namely <a href=\"https://web.stanford.edu/class/stats202/content/lec13.pdf\" rel=\"nofollow noreferrer\">forward or backward stepwise selection</a>. </p>\n\n<p>The book \"Introduction to Statistical Learning\" (Chapter 6: Linear Model Selection\nand Regularization) gives a really instructive overview of model selection techniques. </p>\n\n<p>The code examples are online <a href=\"https://github.com/rghan/ISLR\" rel=\"nofollow noreferrer\">for R</a> and <a href=\"https://github.com/JWarmenhoven/ISLR-python\" rel=\"nofollow noreferrer\">Python</a>. </p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16169",
            "_score": 10.056043,
            "_source": {
                "title": "Doc2vec model.docvecs giving varying output",
                "content": "Doc2vec model.docvecs giving varying output <p>I am using doc2vec to vectorize input text. I am converting my input dataset to tagged data and giving it as input.</p>\n\n<p>Initially I tried with a data of 27 input text:</p>\n\n<pre><code>tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(X)]\n\nmax_epochs = 125\nvec_size = 20\nalpha = 0.05\n\nmodel = Doc2Vec(size=vec_size,\n            alpha=alpha, \n            min_alpha=0.00025,\n            min_count=1,\n            dm =0)\n\nmodel.build_vocab(tagged_data)\n\nfor epoch in range(max_epochs):\n    print('iteration {0}'.format(epoch))\n    model.train(tagged_data,\n            total_examples=model.corpus_count,\n            epochs=model.iter)\n    # decrease the learning rate\n    model.alpha -= 0.0002\n    # fix the learning rate, no decay\n    model.min_alpha = model.alpha\n\nmodel.save(\"d2v.model\")\nprint(\"Model Saved\")\n\nprint (\"docvecs\")\nprint(model.docvecs)\nprint(type(model.docvecs))\nprint(len(model.docvecs))\n</code></pre>\n\n<p>I am getting the length of the docvecs as 27 which is correct as I was having 27 input text to the model and tagged 27 unique values.</p>\n\n<p>I later fitted this to a logistic regression model:</p>\n\n<pre><code>train_arrays=np.zeros([27,20])\ntrain_labels=np.zeros(27)\nfor i in range(0,27):\n    #x_train.append(tagged_data[i][0])\n    train_arrays[i]=(model.docvecs[i])\n    train_labels[i]=i\n\n\n\nprint (\"-------------------------\")\nprint (x_train)\nprint(y_train)\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(n_jobs=1, C=1e5)\nlogreg.fit(train_arrays, train_labels)\nprint(\"logistic regression fiitted properly..\")\n</code></pre>\n\n<p>I tested this with an infinite loop and it works fine:</p>\n\n<pre><code> while True:\n    print(\"Enter text : \")\n    usr=input()\n\n    usr=word_tokenize(usr.lower())\n    v1 = model.infer_vector(usr)\n\n    print(\"vector of input text.. \",v1)\n\n    sims = model.docvecs.most_similar([v1])\n    print(sims)\n    test_array=np.zeros([1,20])\n    test_array[0]=v1\n    ans=logreg.predict(test_array)\n    print(ans)\n</code></pre>\n\n<p>I am getting the output correct:</p>\n\n<pre><code>Enter text :\nwhat will my business card carry\nvector of input text..  [-0.36948422 -0.3151284  -0.392992   -0.56482047  0.17411898  0.16804925\n  0.3298428  -0.3225111   0.06729688 -0.02223648 -0.07785773 -0.15621385\n  0.34434605  0.30244747  0.08436651 -0.2911789  -0.02142929  0.14122409\n -0.4378101   0.32535276]\n[('14', 0.9742787480354309), ('4', 0.7727420330047607), ('6', 0.7526462078094482), ('7', 0.7040897011756897), ('21', 0.6696580648422241), ('19', 0.6558915376663208), ('9', 0.6502488851547241), ('22', 0.6467552185058594), ('15', 0.6378635168075562), ('13', 0.6291216611862183)]\n[14.]\n</code></pre>\n\n<p>Now, the problem is that I am using a different data set of 298 input text and there are 29 intent_id's for these 29 groups. So of the 298, the text data has an average of 7-8 in each group. </p>\n\n<p>So when preparing tagged data, I used the intent_id to tag and feed to doc2vec. Groups are from 1-29:</p>\n\n<pre><code>TaggedData=[]\nfor i in range(0,len(train_data)):\n    print(i,train_data['utterance'][i],train_data['intent_id'][i])\n    tagDoc=TaggedDocument(words=word_tokenize(train_data['utterance'][i].lower()),tags=[train_data['intent_id'][i]])\n    TaggedData.append(tagDoc)\n</code></pre>\n\n<p>When I feed this to the doc2vec model and take the length of  len(model.docvecs) it is coming as 30. I have used the same code above.\nIdeally, this should come as 29 (what I was expecting). I would like to feed the vector output of 298 input text to logistic regression. However, here the length is only 30 which I am not able to understand. What is the correct thing to do here?</p>\n <nlp><word2vec><gensim><similar-documents>",
                "codes": [],
                "question_id:": "53520",
                "question_votes:": "",
                "question_text:": "<p>I am using doc2vec to vectorize input text. I am converting my input dataset to tagged data and giving it as input.</p>\n\n<p>Initially I tried with a data of 27 input text:</p>\n\n<pre><code>tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(X)]\n\nmax_epochs = 125\nvec_size = 20\nalpha = 0.05\n\nmodel = Doc2Vec(size=vec_size,\n            alpha=alpha, \n            min_alpha=0.00025,\n            min_count=1,\n            dm =0)\n\nmodel.build_vocab(tagged_data)\n\nfor epoch in range(max_epochs):\n    print('iteration {0}'.format(epoch))\n    model.train(tagged_data,\n            total_examples=model.corpus_count,\n            epochs=model.iter)\n    # decrease the learning rate\n    model.alpha -= 0.0002\n    # fix the learning rate, no decay\n    model.min_alpha = model.alpha\n\nmodel.save(\"d2v.model\")\nprint(\"Model Saved\")\n\nprint (\"docvecs\")\nprint(model.docvecs)\nprint(type(model.docvecs))\nprint(len(model.docvecs))\n</code></pre>\n\n<p>I am getting the length of the docvecs as 27 which is correct as I was having 27 input text to the model and tagged 27 unique values.</p>\n\n<p>I later fitted this to a logistic regression model:</p>\n\n<pre><code>train_arrays=np.zeros([27,20])\ntrain_labels=np.zeros(27)\nfor i in range(0,27):\n    #x_train.append(tagged_data[i][0])\n    train_arrays[i]=(model.docvecs[i])\n    train_labels[i]=i\n\n\n\nprint (\"-------------------------\")\nprint (x_train)\nprint(y_train)\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(n_jobs=1, C=1e5)\nlogreg.fit(train_arrays, train_labels)\nprint(\"logistic regression fiitted properly..\")\n</code></pre>\n\n<p>I tested this with an infinite loop and it works fine:</p>\n\n<pre><code> while True:\n    print(\"Enter text : \")\n    usr=input()\n\n    usr=word_tokenize(usr.lower())\n    v1 = model.infer_vector(usr)\n\n    print(\"vector of input text.. \",v1)\n\n    sims = model.docvecs.most_similar([v1])\n    print(sims)\n    test_array=np.zeros([1,20])\n    test_array[0]=v1\n    ans=logreg.predict(test_array)\n    print(ans)\n</code></pre>\n\n<p>I am getting the output correct:</p>\n\n<pre><code>Enter text :\nwhat will my business card carry\nvector of input text..  [-0.36948422 -0.3151284  -0.392992   -0.56482047  0.17411898  0.16804925\n  0.3298428  -0.3225111   0.06729688 -0.02223648 -0.07785773 -0.15621385\n  0.34434605  0.30244747  0.08436651 -0.2911789  -0.02142929  0.14122409\n -0.4378101   0.32535276]\n[('14', 0.9742787480354309), ('4', 0.7727420330047607), ('6', 0.7526462078094482), ('7', 0.7040897011756897), ('21', 0.6696580648422241), ('19', 0.6558915376663208), ('9', 0.6502488851547241), ('22', 0.6467552185058594), ('15', 0.6378635168075562), ('13', 0.6291216611862183)]\n[14.]\n</code></pre>\n\n<p>Now, the problem is that I am using a different data set of 298 input text and there are 29 intent_id's for these 29 groups. So of the 298, the text data has an average of 7-8 in each group. </p>\n\n<p>So when preparing tagged data, I used the intent_id to tag and feed to doc2vec. Groups are from 1-29:</p>\n\n<pre><code>TaggedData=[]\nfor i in range(0,len(train_data)):\n    print(i,train_data['utterance'][i],train_data['intent_id'][i])\n    tagDoc=TaggedDocument(words=word_tokenize(train_data['utterance'][i].lower()),tags=[train_data['intent_id'][i]])\n    TaggedData.append(tagDoc)\n</code></pre>\n\n<p>When I feed this to the doc2vec model and take the length of  len(model.docvecs) it is coming as 30. I have used the same code above.\nIdeally, this should come as 29 (what I was expecting). I would like to feed the vector output of 298 input text to logistic regression. However, here the length is only 30 which I am not able to understand. What is the correct thing to do here?</p>\n",
                "tags": "<nlp><word2vec><gensim><similar-documents>",
                "answers": []
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9655",
            "_score": 10.03544,
            "_source": {
                "title": "Interpretation of variable or feature importance in Random Forest",
                "content": "Interpretation of variable or feature importance in Random Forest <p>I'm currently using Random Forest to train some models and interpret the obtained results.</p>\n\n<p>One of the features I want to analyze further, is variable importance. The thing is I am not familiar on how to do a proper analysis of the results I got.\nLet's say I have this table:</p>\n\n<pre><code>| Predictor  | Importance |\n----------------------------\n|   var_1    |   num_1    |\n...\n|   var_n    |   num_n    |\n</code></pre>\n\n<p>What is a proper analysis that can be conducted on the values obtained from the table, in addition to saying which variable is more important than another?</p>\n\n<p>I was suggested something like variable ranking or using cumulative density function, but I am not sure how to begin with that.</p>\n <random-forest><predictor-importance><p>I would be reluctant to do too much analysis on the table alone as variable importances can be misleading, but there is something you can do.  The idea is to learn the statistical properties of the feature importances through simulation, and then determine how \"significant\" the observed importances are for each feature.  That is, could a large importance for a feature have arisen purely by chance, or is that feature legitimately predictive?</p>\n\n<p>To do this you take the target of your algorithm $y$ and shuffle its values, so that there is no way to do genuine prediction and all of your features are effectively noise.  Then fit your chosen model $m$ times, observe the importances of your features for every iteration, and record the \"null distribution\" for each.  This is the distribution of the feature's importance when that feature has no predictive power.</p>\n\n<p>Having obtained these distributions you can compare the importances that you actually observed without shuffling $y$ and start to make meaningful statements about which features are genuinely predictive and which are not.  That is, did the importance for a given feature fall into a large quantile (say the 99th percentile) of its null distribution?  In that case you can conclude that it contains genuine information about $y$.  If on the other hand the importance was somewhere in the middle of the distribution, then you can start to assume that the feature is not useful and perhaps start to do feature selection on these grounds.</p>\n\n<p>Here is a simulation you can do in Python to try this idea out.  First we generate data under a linear regression model where only 3 of the 50 features are predictive, and then fit a random forest model to the data.  Now that we have our feature importances we fit 100 more models on permutations of $y$ and record the results.  Then all we have to do is compare the actual importances we saw to their null distributions using the helper function <code>dist_func</code>, which calculates what proportion of the null importances are less than the observed.  These numbers are essentially $p$-values in the classical statistical sense (only inverted so higher means better) and are much easier to interpret than the importance metrics reported by <code>RandomForestRegressor</code>.  Or, you can simply plot the null distributions and see where the actual importance values fall.  In this case it becomes very obvious that only the first three features matter where it may not have been by looking at the raw importances themselves.</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n\n# number of samples\nn = 100\n# number of features\np = 50\n# monte carlo sample size\nm = 100\n\n# simulate data under a linear regression model\n# the first three coefficients are one and the rest zero\nbeta = np.ones(p)\nbeta[3:] = 0\nX = pd.DataFrame(np.random.normal(size=(n, p)), \n                 columns=[\"x\" + str(i+1) for i in range(p)])\ny = np.dot(X, beta) + np.random.randn(n)\n\n# fit a random forest regression to the data\nreg = RandomForestRegressor()\nreg.fit(X, y)\n\n# get the importances\nvar_imp = (pd.DataFrame({\"feature\": X.columns, \n                        \"beta\": beta, \n                       \"importance\": reg.feature_importances_}).\n           sort_values(by=\"importance\", ascending=False).\n           reset_index(drop=True))\n\n# fit many regressions on shuffled versions of y\nsim_imp = pd.DataFrame({c: np.empty(m) for c in X.columns})\n\nfor i in range(m):\n    reg.fit(X, np.random.permutation(y))\n    sim_imp.iloc[i] = reg.feature_importances_\n\n# null distribution function\ndef dist_func(var, x):\n    return np.mean(sim_imp[var] &lt; x)\n</code></pre>\n",
                "codes": [
                    [
                        "import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n\n# number of samples\nn = 100\n# number of features\np = 50\n# monte carlo sample size\nm = 100\n\n# simulate data under a linear regression model\n# the first three coefficients are one and the rest zero\nbeta = np.ones(p)\nbeta[3:] = 0\nX = pd.DataFrame(np.random.normal(size=(n, p)), \n                 columns=[\"x\" + str(i+1) for i in range(p)])\ny = np.dot(X, beta) + np.random.randn(n)\n\n# fit a random forest regression to the data\nreg = RandomForestRegressor()\nreg.fit(X, y)\n\n# get the importances\nvar_imp = (pd.DataFrame({\"feature\": X.columns, \n                        \"beta\": beta, \n                       \"importance\": reg.feature_importances_}).\n           sort_values(by=\"importance\", ascending=False).\n           reset_index(drop=True))\n\n# fit many regressions on shuffled versions of y\nsim_imp = pd.DataFrame({c: np.empty(m) for c in X.columns})\n\nfor i in range(m):\n    reg.fit(X, np.random.permutation(y))\n    sim_imp.iloc[i] = reg.feature_importances_\n\n# null distribution function\ndef dist_func(var, x):\n    return np.mean(sim_imp[var] < x)\n"
                    ]
                ],
                "question_id:": "34268",
                "question_votes:": "3",
                "question_text:": "<p>I'm currently using Random Forest to train some models and interpret the obtained results.</p>\n\n<p>One of the features I want to analyze further, is variable importance. The thing is I am not familiar on how to do a proper analysis of the results I got.\nLet's say I have this table:</p>\n\n<pre><code>| Predictor  | Importance |\n----------------------------\n|   var_1    |   num_1    |\n...\n|   var_n    |   num_n    |\n</code></pre>\n\n<p>What is a proper analysis that can be conducted on the values obtained from the table, in addition to saying which variable is more important than another?</p>\n\n<p>I was suggested something like variable ranking or using cumulative density function, but I am not sure how to begin with that.</p>\n",
                "tags": "<random-forest><predictor-importance>",
                "answers": [
                    [
                        "34282",
                        "2",
                        "34268",
                        "",
                        "",
                        "<p>I would be reluctant to do too much analysis on the table alone as variable importances can be misleading, but there is something you can do.  The idea is to learn the statistical properties of the feature importances through simulation, and then determine how \"significant\" the observed importances are for each feature.  That is, could a large importance for a feature have arisen purely by chance, or is that feature legitimately predictive?</p>\n\n<p>To do this you take the target of your algorithm $y$ and shuffle its values, so that there is no way to do genuine prediction and all of your features are effectively noise.  Then fit your chosen model $m$ times, observe the importances of your features for every iteration, and record the \"null distribution\" for each.  This is the distribution of the feature's importance when that feature has no predictive power.</p>\n\n<p>Having obtained these distributions you can compare the importances that you actually observed without shuffling $y$ and start to make meaningful statements about which features are genuinely predictive and which are not.  That is, did the importance for a given feature fall into a large quantile (say the 99th percentile) of its null distribution?  In that case you can conclude that it contains genuine information about $y$.  If on the other hand the importance was somewhere in the middle of the distribution, then you can start to assume that the feature is not useful and perhaps start to do feature selection on these grounds.</p>\n\n<p>Here is a simulation you can do in Python to try this idea out.  First we generate data under a linear regression model where only 3 of the 50 features are predictive, and then fit a random forest model to the data.  Now that we have our feature importances we fit 100 more models on permutations of $y$ and record the results.  Then all we have to do is compare the actual importances we saw to their null distributions using the helper function <code>dist_func</code>, which calculates what proportion of the null importances are less than the observed.  These numbers are essentially $p$-values in the classical statistical sense (only inverted so higher means better) and are much easier to interpret than the importance metrics reported by <code>RandomForestRegressor</code>.  Or, you can simply plot the null distributions and see where the actual importance values fall.  In this case it becomes very obvious that only the first three features matter where it may not have been by looking at the raw importances themselves.</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n\n# number of samples\nn = 100\n# number of features\np = 50\n# monte carlo sample size\nm = 100\n\n# simulate data under a linear regression model\n# the first three coefficients are one and the rest zero\nbeta = np.ones(p)\nbeta[3:] = 0\nX = pd.DataFrame(np.random.normal(size=(n, p)), \n                 columns=[\"x\" + str(i+1) for i in range(p)])\ny = np.dot(X, beta) + np.random.randn(n)\n\n# fit a random forest regression to the data\nreg = RandomForestRegressor()\nreg.fit(X, y)\n\n# get the importances\nvar_imp = (pd.DataFrame({\"feature\": X.columns, \n                        \"beta\": beta, \n                       \"importance\": reg.feature_importances_}).\n           sort_values(by=\"importance\", ascending=False).\n           reset_index(drop=True))\n\n# fit many regressions on shuffled versions of y\nsim_imp = pd.DataFrame({c: np.empty(m) for c in X.columns})\n\nfor i in range(m):\n    reg.fit(X, np.random.permutation(y))\n    sim_imp.iloc[i] = reg.feature_importances_\n\n# null distribution function\ndef dist_func(var, x):\n    return np.mean(sim_imp[var] &lt; x)\n</code></pre>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "834",
            "_score": 9.969158,
            "_source": {
                "title": "Dimensionality and Manifold",
                "content": "Dimensionality and Manifold <p>A commonly heard sentence in unsupervised Machine learning is</p>\n\n<blockquote>\n  <p>High dimensional inputs typically live on or near a low dimensional\n  manifold</p>\n</blockquote>\n\n<p><strong>What is a dimension? What is a manifold? What is the difference?</strong> </p>\n\n<p><strong>Can you give an example to describe both?</strong></p>\n\n<p><strong>Manifold</strong> from Google/Wikipedia:</p>\n\n<blockquote>\n  <p>In mathematics, a manifold is a topological space that resembles\n  Euclidean space near each point. More precisely, each point of an\n  n-dimensional manifold has a neighbourhood that is homeomorphic to the\n  Euclidean space of dimension n.</p>\n</blockquote>\n\n<p><strong>Dimesion</strong> from Google/Wikipedia:</p>\n\n<blockquote>\n  <p>In physics and mathematics, the dimension of a mathematical space (or\n  object) is informally defined as the minimum number of coordinates\n  needed to specify any point within it.</p>\n</blockquote>\n\n<p>What does the Google/Wikipedia even mean in layman terms? It sounds like some bizarre definition like most machine learning definition?</p>\n\n<p><strong>They are both spaces, so what's the difference between a Euclidean space (i.e. Manifold) and a dimension space (i.e. feature-based)?</strong> </p>\n <machine-learning><dimensionality-reduction><p>One way of doing dimensional reduction is to do feature hashing.  This was known about in the 1960's.  So for example if your data is a sparse set of points in 3 dimensions (x,y,z) you create a (good) hash function h(x,y,z).  You can use that of course for a hash table or a Bloom filter lookup. This is a good form of data compression.  I don't know why the AI community doesn't use it.  It is much more to the point than a neural net. </p>\n<blockquote>\n  <p>What is a dimension?</p>\n</blockquote>\n\n<p>To put it simply, if you have a tabular data set with m rows and n columns, then the dimensionality of your data is n:</p>\n\n<blockquote>\n  <p>What is a manifold? </p>\n</blockquote>\n\n<p>The simplest example is our planet Earth. For us it looks flat, but it really is a sphere. So it's sort of a 2d manifold embedded in the 3d space. </p>\n\n<blockquote>\n  <p>What is the difference? </p>\n</blockquote>\n\n<p>To answer this question, consider another example of a manifold: </p>\n\n<p><img src=\"https://i.stack.imgur.com/FrBXu.png\" alt=\"enter image description here\"></p>\n\n<p>This is so-called \"swiss roll\". The data points are in 3d, but they all lie on 2d manifold, so the dimensionality of the manifold is 2, while the dimensionality of the input space is 3.</p>\n\n<p>There are many techniques to \"unwrap\" these manifolds. One of them is called <a href=\"https://www.google.com/search?q=locally+linear+embedding\" rel=\"nofollow noreferrer\">Locally Linear Embedding</a>, and this is how it would do that:</p>\n\n<p><img src=\"https://i.stack.imgur.com/pagFb.png\" alt=\"enter image description here\"></p>\n\n<p>Here's a scikit-learn snippet for doing that:</p>\n\n<pre class=\"lang-python prettyprint-override\"><code>from sklearn.manifold import LocallyLinearEmbedding\n\nlle = LocallyLinearEmbedding(n_neighbors=k, n_components=2)\nX_lle = lle.fit_transform(data)\nplt.scatter(X_lle[:, 0], X_lle[:, 1], c=color)\nplt.show()\n</code></pre>\n<p>The dimensionality of a dataset is the number of variables used to represent it. For example, if we were interested in describing people in terms of their height and weight, our \"people\" dataset would have 2 dimensions. If instead we had a dataset of images, and each image is a million pixels, then the dimensionality of the dataset would be a million. In fact, in many modern machine learning applications, the dimensionality of a dataset could be massive. </p>\n\n<p>When dimensionality is very large (larger than the number of the samples in the dataset), we could run into some serious problems. Consider a simple classification algorithm that seeks to find a set of weights w such that when dotted with a sample x, gives a negative number for one class and a positive number for another. w will have a length equal to the dimensionality of the data, so it will have more parameters than there are samples in the entire dataset. This means that a learner will be able to overfit the data, and consequently won't generalize well to other samples unseen during training. </p>\n\n<p>A manifold is an object of dimensionality d that is embedded in some higher dimensional space. Imagine a set of points on a sheet of paper. If we crinkle up the paper, the points are now in 3 dimensions. Many manifold learning algorithms seek to \"uncrinkle\" the sheet of paper to put the data back into 2 dimensions. Even if we aren't concerned with overfitting our model, a non-linear manifold learner can produce a space that makes classification and regression problems easier.</p>\n",
                "codes": [
                    [],
                    [
                        "from sklearn.manifold import LocallyLinearEmbedding\n\nlle = LocallyLinearEmbedding(n_neighbors=k, n_components=2)\nX_lle = lle.fit_transform(data)\nplt.scatter(X_lle[:, 0], X_lle[:, 1], c=color)\nplt.show()\n"
                    ],
                    []
                ],
                "question_id:": "5694",
                "question_votes:": "7",
                "question_text:": "<p>A commonly heard sentence in unsupervised Machine learning is</p>\n\n<blockquote>\n  <p>High dimensional inputs typically live on or near a low dimensional\n  manifold</p>\n</blockquote>\n\n<p><strong>What is a dimension? What is a manifold? What is the difference?</strong> </p>\n\n<p><strong>Can you give an example to describe both?</strong></p>\n\n<p><strong>Manifold</strong> from Google/Wikipedia:</p>\n\n<blockquote>\n  <p>In mathematics, a manifold is a topological space that resembles\n  Euclidean space near each point. More precisely, each point of an\n  n-dimensional manifold has a neighbourhood that is homeomorphic to the\n  Euclidean space of dimension n.</p>\n</blockquote>\n\n<p><strong>Dimesion</strong> from Google/Wikipedia:</p>\n\n<blockquote>\n  <p>In physics and mathematics, the dimension of a mathematical space (or\n  object) is informally defined as the minimum number of coordinates\n  needed to specify any point within it.</p>\n</blockquote>\n\n<p>What does the Google/Wikipedia even mean in layman terms? It sounds like some bizarre definition like most machine learning definition?</p>\n\n<p><strong>They are both spaces, so what's the difference between a Euclidean space (i.e. Manifold) and a dimension space (i.e. feature-based)?</strong> </p>\n",
                "tags": "<machine-learning><dimensionality-reduction>",
                "answers": [
                    [
                        "5704",
                        "2",
                        "5694",
                        "",
                        "",
                        "<p>One way of doing dimensional reduction is to do feature hashing.  This was known about in the 1960's.  So for example if your data is a sparse set of points in 3 dimensions (x,y,z) you create a (good) hash function h(x,y,z).  You can use that of course for a hash table or a Bloom filter lookup. This is a good form of data compression.  I don't know why the AI community doesn't use it.  It is much more to the point than a neural net. </p>\n",
                        "",
                        "1"
                    ],
                    [
                        "5698",
                        "2",
                        "5694",
                        "",
                        "",
                        "<blockquote>\n  <p>What is a dimension?</p>\n</blockquote>\n\n<p>To put it simply, if you have a tabular data set with m rows and n columns, then the dimensionality of your data is n:</p>\n\n<blockquote>\n  <p>What is a manifold? </p>\n</blockquote>\n\n<p>The simplest example is our planet Earth. For us it looks flat, but it really is a sphere. So it's sort of a 2d manifold embedded in the 3d space. </p>\n\n<blockquote>\n  <p>What is the difference? </p>\n</blockquote>\n\n<p>To answer this question, consider another example of a manifold: </p>\n\n<p><img src=\"https://i.stack.imgur.com/FrBXu.png\" alt=\"enter image description here\"></p>\n\n<p>This is so-called \"swiss roll\". The data points are in 3d, but they all lie on 2d manifold, so the dimensionality of the manifold is 2, while the dimensionality of the input space is 3.</p>\n\n<p>There are many techniques to \"unwrap\" these manifolds. One of them is called <a href=\"https://www.google.com/search?q=locally+linear+embedding\" rel=\"nofollow noreferrer\">Locally Linear Embedding</a>, and this is how it would do that:</p>\n\n<p><img src=\"https://i.stack.imgur.com/pagFb.png\" alt=\"enter image description here\"></p>\n\n<p>Here's a scikit-learn snippet for doing that:</p>\n\n<pre class=\"lang-python prettyprint-override\"><code>from sklearn.manifold import LocallyLinearEmbedding\n\nlle = LocallyLinearEmbedding(n_neighbors=k, n_components=2)\nX_lle = lle.fit_transform(data)\nplt.scatter(X_lle[:, 0], X_lle[:, 1], c=color)\nplt.show()\n</code></pre>\n",
                        "",
                        "21"
                    ],
                    [
                        "5700",
                        "2",
                        "5694",
                        "",
                        "",
                        "<p>The dimensionality of a dataset is the number of variables used to represent it. For example, if we were interested in describing people in terms of their height and weight, our \"people\" dataset would have 2 dimensions. If instead we had a dataset of images, and each image is a million pixels, then the dimensionality of the dataset would be a million. In fact, in many modern machine learning applications, the dimensionality of a dataset could be massive. </p>\n\n<p>When dimensionality is very large (larger than the number of the samples in the dataset), we could run into some serious problems. Consider a simple classification algorithm that seeks to find a set of weights w such that when dotted with a sample x, gives a negative number for one class and a positive number for another. w will have a length equal to the dimensionality of the data, so it will have more parameters than there are samples in the entire dataset. This means that a learner will be able to overfit the data, and consequently won't generalize well to other samples unseen during training. </p>\n\n<p>A manifold is an object of dimensionality d that is embedded in some higher dimensional space. Imagine a set of points on a sheet of paper. If we crinkle up the paper, the points are now in 3 dimensions. Many manifold learning algorithms seek to \"uncrinkle\" the sheet of paper to put the data back into 2 dimensions. Even if we aren't concerned with overfitting our model, a non-linear manifold learner can produce a space that makes classification and regression problems easier.</p>\n",
                        "",
                        "5"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12434",
            "_score": 9.908105,
            "_source": {
                "title": "Why can't continuous variables be used for the estimator of learning curves, when using StratifiedKFold to split the dataset?",
                "content": "Why can't continuous variables be used for the estimator of learning curves, when using StratifiedKFold to split the dataset? <p>I want to produce learning curves for three regression models run on data containing 200 samples, 10 features and 1 target variable.</p>\n\n<p>The target variable contains two clusters/peaks, making it imbalanced between and within the clusters, so I applied a stratified split to divide the data into training and test sets, using train_test_split, in the following manner:</p>\n\n<pre><code># Stratified Split dataset into Training and Testing\nbins = np.linspace(0, 1.01, 10)\ny_binned = np.digitize(Y_scaled, bins)\n\nX_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y_scaled, stratify=y_binned, test_size=0.3, random_state=0)\n</code></pre>\n\n<p>I then trained and tested each models, using stratified K-fold cross-validation for hyperparameter optimisation.</p>\n\n<p>I would now like to use leaning curves to examine verify that my models are not overfitting, and that the training and test scores have converged.  For this I am turning to sklearn.model_selection.learning_curve.</p>\n\n<p>In the documentation for sklearn's learning curve it says the following:</p>\n\n<blockquote>\n  <p>Learning curve.</p>\n  \n  <p>Determines cross-validated training and test scores for different\n  training set sizes.</p>\n  \n  <p>A cross-validation generator splits the whole dataset k times in\n  training and test data. Subsets of the training set with varying sizes\n  will be used to train the estimator and a score for each training\n  subset size and the test set will be computed. Afterwards, the scores\n  will be averaged over all k runs for each training subset size.</p>\n</blockquote>\n\n<p>I implemented the learning curve using the function defined in <a href=\"https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py\" rel=\"nofollow noreferrer\">Plotting Learning CUrves</a> (with an additional 'scorer' variable) and the following code:</p>\n\n<pre><code>cv = StratifiedKFold(n_splits=5, shuffle=False, random_state=0)\n\ntitle = \"Learning Curves (Linear Regression)\"\nestimator = model_1\nplot_learning_curve(estimator, title, r2_score, X_train_0, Y_train_0, train_sizes=np.linspace(0.1, 1.0, 10), \\\n                    ylim=(0.1, 1.01), cv=cv, n_jobs=-1)\n\ntitle = \"Learning Curves (Ridge Regression)\"\nestimator = model_2\nplot_learning_curve(estimator, title, r2_score, X_train_0, Y_train_0, train_sizes=np.linspace(0.1, 1.0, 10), \\\n                    ylim=(0.1, 1.01), cv=cv, n_jobs=-1)\n\ntitle = \"Learning Curves (Random Forest - Extra Trees)\"\nestimator = model_3\nplot_learning_curve(estimator, title, r2_score, X_train_0, Y_train_0, train_sizes=np.linspace(0.1, 1.0, 10), \\\n                    ylim=(0.1, 1.01), cv=cv, n_jobs=-1)\n\nplt.show()\n</code></pre>\n\n<p>According to the code:\n<code>train_sizes=np.linspace(0.1, 1.0, 10</code>\nand \n<code>cv = StratifiedKFold(n_splits=5, shuffle=False, random_state=0)</code> \nI expected that the training dataset (X_train_0) would be split into 10 sub-sets, that each sub-set would be stratified according to the whole (as it was during training and testing), and that each of the ten sub-sets would be then split into stratified training/test set, with the training set undergoing 5-fold stratified k-fold cross validation.</p>\n\n<p>I passed the training data X_train_0 and targets Y_train_0 to the learning curve function, expecting to obtain mean training and testing scores for each sub-set, however I received the following error:</p>\n\n<blockquote>\n  <p>ValueError: Supported target types are: ('binary', 'multiclass'). Got\n  'continuous' instead.</p>\n</blockquote>\n\n<p>At this point, I can't figure out how I can pass continuous variables for the target of the learning curve the estimator, while producing stratified sub-sets of the training dataset.</p>\n <learning>",
                "codes": [],
                "question_id:": "43658",
                "question_votes:": "1",
                "question_text:": "<p>I want to produce learning curves for three regression models run on data containing 200 samples, 10 features and 1 target variable.</p>\n\n<p>The target variable contains two clusters/peaks, making it imbalanced between and within the clusters, so I applied a stratified split to divide the data into training and test sets, using train_test_split, in the following manner:</p>\n\n<pre><code># Stratified Split dataset into Training and Testing\nbins = np.linspace(0, 1.01, 10)\ny_binned = np.digitize(Y_scaled, bins)\n\nX_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y_scaled, stratify=y_binned, test_size=0.3, random_state=0)\n</code></pre>\n\n<p>I then trained and tested each models, using stratified K-fold cross-validation for hyperparameter optimisation.</p>\n\n<p>I would now like to use leaning curves to examine verify that my models are not overfitting, and that the training and test scores have converged.  For this I am turning to sklearn.model_selection.learning_curve.</p>\n\n<p>In the documentation for sklearn's learning curve it says the following:</p>\n\n<blockquote>\n  <p>Learning curve.</p>\n  \n  <p>Determines cross-validated training and test scores for different\n  training set sizes.</p>\n  \n  <p>A cross-validation generator splits the whole dataset k times in\n  training and test data. Subsets of the training set with varying sizes\n  will be used to train the estimator and a score for each training\n  subset size and the test set will be computed. Afterwards, the scores\n  will be averaged over all k runs for each training subset size.</p>\n</blockquote>\n\n<p>I implemented the learning curve using the function defined in <a href=\"https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py\" rel=\"nofollow noreferrer\">Plotting Learning CUrves</a> (with an additional 'scorer' variable) and the following code:</p>\n\n<pre><code>cv = StratifiedKFold(n_splits=5, shuffle=False, random_state=0)\n\ntitle = \"Learning Curves (Linear Regression)\"\nestimator = model_1\nplot_learning_curve(estimator, title, r2_score, X_train_0, Y_train_0, train_sizes=np.linspace(0.1, 1.0, 10), \\\n                    ylim=(0.1, 1.01), cv=cv, n_jobs=-1)\n\ntitle = \"Learning Curves (Ridge Regression)\"\nestimator = model_2\nplot_learning_curve(estimator, title, r2_score, X_train_0, Y_train_0, train_sizes=np.linspace(0.1, 1.0, 10), \\\n                    ylim=(0.1, 1.01), cv=cv, n_jobs=-1)\n\ntitle = \"Learning Curves (Random Forest - Extra Trees)\"\nestimator = model_3\nplot_learning_curve(estimator, title, r2_score, X_train_0, Y_train_0, train_sizes=np.linspace(0.1, 1.0, 10), \\\n                    ylim=(0.1, 1.01), cv=cv, n_jobs=-1)\n\nplt.show()\n</code></pre>\n\n<p>According to the code:\n<code>train_sizes=np.linspace(0.1, 1.0, 10</code>\nand \n<code>cv = StratifiedKFold(n_splits=5, shuffle=False, random_state=0)</code> \nI expected that the training dataset (X_train_0) would be split into 10 sub-sets, that each sub-set would be stratified according to the whole (as it was during training and testing), and that each of the ten sub-sets would be then split into stratified training/test set, with the training set undergoing 5-fold stratified k-fold cross validation.</p>\n\n<p>I passed the training data X_train_0 and targets Y_train_0 to the learning curve function, expecting to obtain mean training and testing scores for each sub-set, however I received the following error:</p>\n\n<blockquote>\n  <p>ValueError: Supported target types are: ('binary', 'multiclass'). Got\n  'continuous' instead.</p>\n</blockquote>\n\n<p>At this point, I can't figure out how I can pass continuous variables for the target of the learning curve the estimator, while producing stratified sub-sets of the training dataset.</p>\n",
                "tags": "<learning>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4277",
            "_score": 9.7409115,
            "_source": {
                "title": "How to compensate for class imbalance in prediction model?",
                "content": "How to compensate for class imbalance in prediction model? <p>I'm trying to run a prediction model on a customers' data set to predict the likelihood that a new customer would be interested in buying product X, offered by a company that sells products X,Y and Z. E.g. would this guy, non-customer, of this age and salary, be interested in product X?</p>\n\n<p>To train the model, I have a basin of 100K company customers, of which only 5K bought product X - the remaining 95K bought other products. Any prediction model guesses 'nobody will buy product X' accepting those ~5% false negatives.</p>\n\n<p>How can I compensate for this skewness of the data? i.e. 95% vs. 5%? Thanks</p>\n <predictive-modeling><dataset><unbalanced-classes><prediction><p>There is a lot of information and techniques for rare event or imbalanced classes. Sorry to post links but (<a href=\"https://stats.stackexchange.com/search?q=rare+event\">https://stats.stackexchange.com/search?q=rare+event</a> and <a href=\"https://stats.stackexchange.com/search?q=imbalanced\">https://stats.stackexchange.com/search?q=imbalanced</a>) but I do not want to duplicate all of the other work.</p>\n\n<p>In my experiences, often I left the data set alone. I usually got good results. If that is the true ratio, then my model should know that. Sometimes I downsampled the majority class. I played with SMOTE (<a href=\"https://arxiv.org/pdf/1106.1813.pdf\" rel=\"nofollow noreferrer\">https://arxiv.org/pdf/1106.1813.pdf</a>) before as well.</p>\n\n<p>For your questions above, yes - changing the data with weights or over/unsampling may bias the results.  Need to check. If you downsample, make sure you are not tossing out signal from the majority class.</p>\n<p>You can try to set different weights on each samples. For example, you can set 0.05 weight on those who bought other products, and 0.95 weight on those who bought product X.</p>\n\n<p>In <a href=\"http://scikit-learn.org\" rel=\"nofollow noreferrer\">sklearn</a>, there's a <code>sample_weight</code> parameter which provides this method. In R, checkout this <a href=\"http://dpmartin42.github.io/blogposts/r/imbalanced-classes-part-1\" rel=\"nofollow noreferrer\">guide</a>.</p>\n\n<p>If you're using <a href=\"http://xgboost.readthedocs.io/en/latest/\" rel=\"nofollow noreferrer\">XGBoost</a>, here is a <a href=\"http://xgboost.readthedocs.io/en/latest/how_to/param_tuning.html#handle-imbalanced-dataset\" rel=\"nofollow noreferrer\">guide</a> which shows how to deal with imbalanced class in XGBoost.</p>\n<p>You've described a null model for a logistic regression, which in this case would predict P(will buy X)=0.05. Any other model that incorporates your covariates of age and salary, will do better. The fact that there are 19 zeroes for every 1 in your response shouldn't stop you trying to make a model that does <strong>significantly</strong> better than a null model.</p>\n\n<p>So just put age and salary in as linear terms in the regression and go from there.</p>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "17220",
                "question_votes:": "1",
                "question_text:": "<p>I'm trying to run a prediction model on a customers' data set to predict the likelihood that a new customer would be interested in buying product X, offered by a company that sells products X,Y and Z. E.g. would this guy, non-customer, of this age and salary, be interested in product X?</p>\n\n<p>To train the model, I have a basin of 100K company customers, of which only 5K bought product X - the remaining 95K bought other products. Any prediction model guesses 'nobody will buy product X' accepting those ~5% false negatives.</p>\n\n<p>How can I compensate for this skewness of the data? i.e. 95% vs. 5%? Thanks</p>\n",
                "tags": "<predictive-modeling><dataset><unbalanced-classes><prediction>",
                "answers": [
                    [
                        "17248",
                        "2",
                        "17220",
                        "",
                        "",
                        "<p>There is a lot of information and techniques for rare event or imbalanced classes. Sorry to post links but (<a href=\"https://stats.stackexchange.com/search?q=rare+event\">https://stats.stackexchange.com/search?q=rare+event</a> and <a href=\"https://stats.stackexchange.com/search?q=imbalanced\">https://stats.stackexchange.com/search?q=imbalanced</a>) but I do not want to duplicate all of the other work.</p>\n\n<p>In my experiences, often I left the data set alone. I usually got good results. If that is the true ratio, then my model should know that. Sometimes I downsampled the majority class. I played with SMOTE (<a href=\"https://arxiv.org/pdf/1106.1813.pdf\" rel=\"nofollow noreferrer\">https://arxiv.org/pdf/1106.1813.pdf</a>) before as well.</p>\n\n<p>For your questions above, yes - changing the data with weights or over/unsampling may bias the results.  Need to check. If you downsample, make sure you are not tossing out signal from the majority class.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "17229",
                        "2",
                        "17220",
                        "",
                        "",
                        "<p>You can try to set different weights on each samples. For example, you can set 0.05 weight on those who bought other products, and 0.95 weight on those who bought product X.</p>\n\n<p>In <a href=\"http://scikit-learn.org\" rel=\"nofollow noreferrer\">sklearn</a>, there's a <code>sample_weight</code> parameter which provides this method. In R, checkout this <a href=\"http://dpmartin42.github.io/blogposts/r/imbalanced-classes-part-1\" rel=\"nofollow noreferrer\">guide</a>.</p>\n\n<p>If you're using <a href=\"http://xgboost.readthedocs.io/en/latest/\" rel=\"nofollow noreferrer\">XGBoost</a>, here is a <a href=\"http://xgboost.readthedocs.io/en/latest/how_to/param_tuning.html#handle-imbalanced-dataset\" rel=\"nofollow noreferrer\">guide</a> which shows how to deal with imbalanced class in XGBoost.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "17231",
                        "2",
                        "17220",
                        "",
                        "",
                        "<p>You've described a null model for a logistic regression, which in this case would predict P(will buy X)=0.05. Any other model that incorporates your covariates of age and salary, will do better. The fact that there are 19 zeroes for every 1 in your response shouldn't stop you trying to make a model that does <strong>significantly</strong> better than a null model.</p>\n\n<p>So just put age and salary in as linear terms in the regression and go from there.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11417",
            "_score": 9.73014,
            "_source": {
                "title": "sklearn.GridSearchCV predict method not providing the best estimate and accuracy score",
                "content": "sklearn.GridSearchCV predict method not providing the best estimate and accuracy score <p>I was playing around with the credit default dataset in UCI \n(\"<a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\" rel=\"nofollow noreferrer\">https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls</a>\")</p>\n\n<p>These are the steps i have undertaken so far:</p>\n\n<ol>\n<li>Created a Pipeline for Perceptron</li>\n<li>Parameter values were provided for learning rate and epochs.</li>\n<li>Passed the estimator and param grids to GridSearch to get the best estimator</li>\n<li>GridSearch provided me with best score for a particular learning rate and epoch</li>\n<li>used predict method on the gridsearch and recalculated accuracy score</li>\n</ol>\n\n<p>Parameters provided for gridsearch</p>\n\n<p>{'perceptron__max_iter': [1,5,8,10], 'perceptron__eta0': [0.5,.4, .2, .1]}</p>\n\n<p><strong>Question</strong>: The best parameters provided by GridSearch <strong>are not</strong> really the best parameters. I am not getting same scores using predict method on the gridsearch. Why is this the case? WHat am i doing wrong?</p>\n\n<p>So acc to gridsearch best param are :\n{'perceptron__eta0': 0.5, 'perceptron__max_iter': 8}</p>\n\n<p>Accuracy score : 0.7795238095238095</p>\n\n<p>However if i use these best parameters and call predict on gridsearch gives a totally different value, accuracy score dips to  0.5882222222222222</p>\n\n<p>Please find code below.</p>\n\n<pre><code>import pandas as panda\n\n\nfrom sklearn.model_selection import learning_curve, train_test_split,GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.metrics import accuracy_score, mean_absolute_error, classification_report\nfrom sklearn.linear_model import Perceptron, LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\nfrom matplotlib import pyplot as plot\nimport seaborn as sns\n\n\nfrom numpy import bincount, linspace, mean, std\n\nremote_location = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\ndata = panda.read_excel(remote_location,sheet_name = \"Data\", header = 1)\n\ndata.rename(str.lower, inplace = True, axis = 'columns')\n\n\n_y_target = data['default payment next month'].values\n\ncolumns = data.columns.tolist()\ncolumns.remove('default payment next month')\n\n_x_attributes = data[columns].values\n\n\n## meaning of stratify = _y_target. returns test and training data having the same proportions of class label '_y_target'\n_x_train,_x_test,_y_train, _y_test = train_test_split(_x_attributes, _y_target, test_size =0.30, stratify = _y_target, random_state = 1)\n\n## lets check the distribution. we can see 4times the lower value as was the case before as well. train/test set distributed well\nprint(\"label counts in y train %s\" %bincount(_y_train))\nprint(\"label counts in y test %s\" %bincount(_y_test))\nparameter_grid = {'perceptron__max_iter': [1,5,8,10], 'perceptron__eta0': [0.5,.4, .2, .1]}\n\npipeline = make_pipeline( StandardScaler(),Perceptron(random_state = 1))\ngridsearch = GridSearchCV(estimator = pipeline, param_grid = parameter_grid, cv = 10, n_jobs = 1, scoring = 'accuracy')\n\nsearch = gridsearch.fit(_x_train, _y_train)\nprint(search.best_params_)\nprint(search.best_score_)\n\n_y_prediction = gridsearch.predict(_x_test)\n\n\nprint(\"Accuracy score %s\" %accuracy_score(_y_test,_y_prediction))\nprint(\"Classification report  \\n %s\" %(classification_report(_y_test, _y_prediction)))\n</code></pre>\n\n<p>My output is as below:</p>\n\n<pre><code>{'perceptron__eta0': 0.5, 'perceptron__max_iter': 8}\n0.7795238095238095\nAccuracy score 0.5882222222222222\nClassification report  \n              precision    recall  f1-score   support\n\n          0       0.78      0.66      0.71      7009\n          1       0.22      0.35      0.27      1991\n\navg / total       0.66      0.59      0.62      9000\n</code></pre>\n <machine-learning><python><scikit-learn><perceptron><gridsearchcv><p>Summarizing your results - your trained a model using gridsearch.<br>\naccuracy score on the train set is ~0.78.<br>\naccuracy score on the test set is ~0.59.<br>\nRephrasing you questions: why do my model performance on the test set is worse than on my train set?</p>\n\n<p>This phenomena is very common - and I can think of two potential explanations:<br>\n1) <a href=\"https://elitedatascience.com/overfitting-in-machine-learning#signal-vs-noise\" rel=\"nofollow noreferrer\">Overfitting</a>: your trained model had learned the 'noise' in the train set and not the actual pattern.<br>\n Then when you use your model to predict on the test set, it predicts the noise he had encountered(which is not relevant for the train set - thus lower accuracy).<br>\n2) Train set and data set are not generated from the same process/describe different parts of it. In this case - the pattern learnt by the trained model is not relevant to the test set and accuracy will drop.<br>\nThis may happen in situations where the train/test split is done without considering the actual underlying process. For example - an image classification problem where you model whether this picture is an animal or not and the train data has only human and dogs sample and the train set has only fish and airplanes pictures. This is less likely to be the explanation, since your using grid search, which adds randomness to this splitting.  </p>\n",
                "codes": [
                    []
                ],
                "question_id:": "40331",
                "question_votes:": "",
                "question_text:": "<p>I was playing around with the credit default dataset in UCI \n(\"<a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\" rel=\"nofollow noreferrer\">https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls</a>\")</p>\n\n<p>These are the steps i have undertaken so far:</p>\n\n<ol>\n<li>Created a Pipeline for Perceptron</li>\n<li>Parameter values were provided for learning rate and epochs.</li>\n<li>Passed the estimator and param grids to GridSearch to get the best estimator</li>\n<li>GridSearch provided me with best score for a particular learning rate and epoch</li>\n<li>used predict method on the gridsearch and recalculated accuracy score</li>\n</ol>\n\n<p>Parameters provided for gridsearch</p>\n\n<p>{'perceptron__max_iter': [1,5,8,10], 'perceptron__eta0': [0.5,.4, .2, .1]}</p>\n\n<p><strong>Question</strong>: The best parameters provided by GridSearch <strong>are not</strong> really the best parameters. I am not getting same scores using predict method on the gridsearch. Why is this the case? WHat am i doing wrong?</p>\n\n<p>So acc to gridsearch best param are :\n{'perceptron__eta0': 0.5, 'perceptron__max_iter': 8}</p>\n\n<p>Accuracy score : 0.7795238095238095</p>\n\n<p>However if i use these best parameters and call predict on gridsearch gives a totally different value, accuracy score dips to  0.5882222222222222</p>\n\n<p>Please find code below.</p>\n\n<pre><code>import pandas as panda\n\n\nfrom sklearn.model_selection import learning_curve, train_test_split,GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.metrics import accuracy_score, mean_absolute_error, classification_report\nfrom sklearn.linear_model import Perceptron, LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\nfrom matplotlib import pyplot as plot\nimport seaborn as sns\n\n\nfrom numpy import bincount, linspace, mean, std\n\nremote_location = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\ndata = panda.read_excel(remote_location,sheet_name = \"Data\", header = 1)\n\ndata.rename(str.lower, inplace = True, axis = 'columns')\n\n\n_y_target = data['default payment next month'].values\n\ncolumns = data.columns.tolist()\ncolumns.remove('default payment next month')\n\n_x_attributes = data[columns].values\n\n\n## meaning of stratify = _y_target. returns test and training data having the same proportions of class label '_y_target'\n_x_train,_x_test,_y_train, _y_test = train_test_split(_x_attributes, _y_target, test_size =0.30, stratify = _y_target, random_state = 1)\n\n## lets check the distribution. we can see 4times the lower value as was the case before as well. train/test set distributed well\nprint(\"label counts in y train %s\" %bincount(_y_train))\nprint(\"label counts in y test %s\" %bincount(_y_test))\nparameter_grid = {'perceptron__max_iter': [1,5,8,10], 'perceptron__eta0': [0.5,.4, .2, .1]}\n\npipeline = make_pipeline( StandardScaler(),Perceptron(random_state = 1))\ngridsearch = GridSearchCV(estimator = pipeline, param_grid = parameter_grid, cv = 10, n_jobs = 1, scoring = 'accuracy')\n\nsearch = gridsearch.fit(_x_train, _y_train)\nprint(search.best_params_)\nprint(search.best_score_)\n\n_y_prediction = gridsearch.predict(_x_test)\n\n\nprint(\"Accuracy score %s\" %accuracy_score(_y_test,_y_prediction))\nprint(\"Classification report  \\n %s\" %(classification_report(_y_test, _y_prediction)))\n</code></pre>\n\n<p>My output is as below:</p>\n\n<pre><code>{'perceptron__eta0': 0.5, 'perceptron__max_iter': 8}\n0.7795238095238095\nAccuracy score 0.5882222222222222\nClassification report  \n              precision    recall  f1-score   support\n\n          0       0.78      0.66      0.71      7009\n          1       0.22      0.35      0.27      1991\n\navg / total       0.66      0.59      0.62      9000\n</code></pre>\n",
                "tags": "<machine-learning><python><scikit-learn><perceptron><gridsearchcv>",
                "answers": [
                    [
                        "40337",
                        "2",
                        "40331",
                        "",
                        "",
                        "<p>Summarizing your results - your trained a model using gridsearch.<br>\naccuracy score on the train set is ~0.78.<br>\naccuracy score on the test set is ~0.59.<br>\nRephrasing you questions: why do my model performance on the test set is worse than on my train set?</p>\n\n<p>This phenomena is very common - and I can think of two potential explanations:<br>\n1) <a href=\"https://elitedatascience.com/overfitting-in-machine-learning#signal-vs-noise\" rel=\"nofollow noreferrer\">Overfitting</a>: your trained model had learned the 'noise' in the train set and not the actual pattern.<br>\n Then when you use your model to predict on the test set, it predicts the noise he had encountered(which is not relevant for the train set - thus lower accuracy).<br>\n2) Train set and data set are not generated from the same process/describe different parts of it. In this case - the pattern learnt by the trained model is not relevant to the test set and accuracy will drop.<br>\nThis may happen in situations where the train/test split is done without considering the actual underlying process. For example - an image classification problem where you model whether this picture is an animal or not and the train data has only human and dogs sample and the train set has only fish and airplanes pictures. This is less likely to be the explanation, since your using grid search, which adds randomness to this splitting.  </p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14915",
            "_score": 9.461835,
            "_source": {
                "title": "Random forest vs. XGBoost vs. MLP Regressor for estimating claims costs",
                "content": "Random forest vs. XGBoost vs. MLP Regressor for estimating claims costs <h1>Context</h1>\n\n<p>I'm building a (toy) machine learning model estimate the cost of an insurance claim (injury related). Aim is to teach myself machine learning by doing. I have settled on three algorithms to test: Random forest, XGBoost and a multi-layer perceptron.</p>\n\n<h1>Data set</h1>\n\n<p>The data set has the following columns: </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>cols = [ 'AGE_RANGE', 'GENDER', 'TOTAL_PAID', 'INDUSTRY_DESCRIPTION', 'WORKER_AGE', 'NATURE_CODE', 'ACCIDENT_TYPE_CODE', 'INJURY_NATURE']\n</code></pre>\n\n<p>'TOTAL_PAID' is the label ($s). The rest are features. The majority of features are categorical: </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>categoricals = [ 'AGE_RANGE', 'GENDER', 'INDUSTRY_DESCRIPTION', 'NATURE_CODE', 'ACCIDENT_TYPE_CODE', 'INJURY_NATURE']\n</code></pre>\n\n<h1>Code:</h1>\n\n<p>Import: </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nimport numpy as np\n\ncols = [ 'AGE_RANGE', 'GENDER', 'TOTAL_PAID', 'INDUSTRY_DESCRIPTION', 'WORKER_AGE', 'NATURE_CODE', 'ACCIDENT_TYPE_CODE', 'INJURY_NATURE']\nfeatures = pd.read_csv('gs://longtailclaims2/filename.csv', usecols = cols, header=0, encoding='ISO-8859-1')\ncategoricals = [ 'AGE_RANGE', 'GENDER', 'INDUSTRY_DESCRIPTION', 'NATURE_CODE', 'ACCIDENT_TYPE_CODE', 'INJURY_NATURE']\n</code></pre>\n\n<p>First I turn categorical values into 0s and 1s: </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>features2 = pd.get_dummies(features, columns = categoricals)\n</code></pre>\n\n<p>Then I isolate features from labels (TOTAL_PAID):</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>labels = np.array(features['TOTAL_PAID'])\nfeatures = features2.drop('TOTAL_PAID', axis = 1)\nfeature_list = list(features.columns)\nfeature_list_no_facts = list(features.columns)\n</code></pre>\n\n<p>Spit into SK Learn training and test set: </p>\n\n<pre class=\"lang-py prettyprint-override\"><code># Using Skicit-learn to split data into training and testing sets\nfrom sklearn.model_selection import train_test_split\n\n# Split the data into training and testing sets\ntrain_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\ntest_features.head(5)\ntest_features.head(5)\n</code></pre>\n\n<p>Then I explore the data: </p>\n\n<pre><code>print('Training Features Shape:', train_features.shape)\nprint('Training Labels Shape:', train_labels.shape)\nprint('Testing Features Shape:', test_features.shape)\nprint('Testing Labels Shape:', test_labels.shape)\n</code></pre>\n\n<p>Output: </p>\n\n<pre><code>Training Features Shape: (128304, 337)\nTraining Labels Shape: (128304,)\nTesting Features Shape: (42768, 337)\nTesting Labels Shape: (42768,)\n</code></pre>\n\n<h1>1. XGBRegressor</h1>\n\n<p>First we try training XGBoost model. I needed so push # estimates above 10,000 to get a decent accuracy (R2 > 0.94)</p>\n\n<pre class=\"lang-py prettyprint-override\"><code># Import the model we are using\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import ensemble \nfrom sklearn.metrics import mean_squared_error\n\nx = XGBRegressor(random_state = 44, n_jobs = 8, n_estimators = 10000, max_depth=10, verbosity = 3)\nx.fit(train_features, train_labels)\nprint('xgboost train score: ', x.score(train_features, train_labels))\npredictions = x.predict(test_features)\nprint('xgboost test score: ', x.score(test_features, test_labels))\n</code></pre>\n\n<p>Here, train and test score: R2 ~0.94.</p>\n\n<h1>2. Random Forest Regressor</h1>\n\n<p>Then we try Random Forest model. After some fiddling it appears 100 estimators is enough to get a pretty good accuracy (R2 > 0.94)</p>\n\n<pre class=\"lang-py prettyprint-override\"><code># Instantiate model with 100 decision trees\nrf = RandomForestRegressor(n_estimators = 100, criterion='mse', verbose=1, random_state = np.random.RandomState(42), n_jobs = -1)\n# Train the model on training data\nrf.fit(train_features, train_labels);\nprint('random forest train score: ', rf.score(train_features, train_labels))\npredictions = rf.predict(test_features)\nprint('random forest test score: ', rf.score(test_features, test_labels))\n</code></pre>\n\n<p>In this case, train and test score R2 at ~0.94.</p>\n\n<h1>3. MLP Neural Network</h1>\n\n<p>Finally I wanted to compare performance to an MLP Regressor. According to the books I have been reading on deep learning, a neural network should be able to outperform any shallow learning algorithm given enough time and horse power. I am using a pretty beefy machine with 8 cores and 30 GB RAM on Google Cloud. </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from sklearn.neural_network import MLPRegressor\nnn = MLPRegressor(hidden_layer_sizes=(338, 338, 50), \n                  activation='relu', solver='adam', max_iter = 100, random_state = 56, verbose = True)\nnn.fit(train_features, train_labels)\nnn_predictions = nn.predict(test_features)\nprint('nn train score: ', nn.score(train_features, train_labels))\nprint('nn test score: ', nn.score(test_features, test_labels))\n</code></pre>\n\n<p>R2 around 0.4.</p>\n\n<p>I've used 338 neurons in the input layer as this is the exact number of columns. The neural network stalls at 82 iterations and doesn't go any further. Running with 50 iterations I get accuracy at R2 &lt; 0.5, which is not impressive.</p>\n\n<h1>My questions:</h1>\n\n<ol>\n<li>Do I handle the management of categorical features correctly?\nWith the scores above, does it look like model #1 and #2 are\noverfitting? R2 > 0.94 is pretty good and both test and training\naccuracy look good and in same ballpark, so I don't think it is\noverfitting </li>\n<li><p>Why does the neural network not perform that well?</p></li>\n<li><p>Should I consider a different type of neural network for regression?</p></li>\n<li><p>Why do I have to add so many more estimators to XGBoost (10,000) to get the same performance as Random Forest (100)? </p></li>\n<li><p>What would be a fit for purpose neural network to solve this problem with deep learning? I am concerned the ensemble methods may not be appropriate or that I am doing something wrong.</p></li>\n</ol>\n <python><neural-network><scikit-learn><regression><xgboost><p>Regarding the <code>MLPRegressor</code>, you should use the <code>lbfgs</code> optimizer for better results with small datasets. Accuracy should be up to 0.99.  </p>\n<p>Some ideas:</p>\n\n<ol>\n<li><strong>Handling categorical features correctly:</strong> using one-hot encoding is one valid approach. Other approaches include target encoding (or mean encoding), and the hashing trick. There's no real hard and fast rule about when to choose which method.</li>\n<li><strong>Poor performance of neural network:</strong> I don't have much experience with neural networks, but I have read that inputs into neural networks should be scaled in some way - either standardised, or to lie within some narrow and consistent interval. You could also look at other layer structures - e.g. have you tried the default values from Scikit-Learn?</li>\n<li><strong>Considering different kind of network:</strong> Judge based on (2) above</li>\n<li><strong>More estimators in <code>xgboost</code>:</strong> <code>xgboost</code> has many parameters to fine tune. You should also consider that <code>xgboost</code> uses linear regression as a default regression task, which implies that your target insurance losses are normally distributed. This is not usually the case in the real world, where we see that insurance losses usually follow a Tweedie distribution. <code>xgboost</code> offers Tweedie regression capability.</li>\n<li><strong>Optimal neural network for this problem:</strong> Unsure as my experience with neural networks is limited.</li>\n</ol>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "49758",
                "question_votes:": "2",
                "question_text:": "<h1>Context</h1>\n\n<p>I'm building a (toy) machine learning model estimate the cost of an insurance claim (injury related). Aim is to teach myself machine learning by doing. I have settled on three algorithms to test: Random forest, XGBoost and a multi-layer perceptron.</p>\n\n<h1>Data set</h1>\n\n<p>The data set has the following columns: </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>cols = [ 'AGE_RANGE', 'GENDER', 'TOTAL_PAID', 'INDUSTRY_DESCRIPTION', 'WORKER_AGE', 'NATURE_CODE', 'ACCIDENT_TYPE_CODE', 'INJURY_NATURE']\n</code></pre>\n\n<p>'TOTAL_PAID' is the label ($s). The rest are features. The majority of features are categorical: </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>categoricals = [ 'AGE_RANGE', 'GENDER', 'INDUSTRY_DESCRIPTION', 'NATURE_CODE', 'ACCIDENT_TYPE_CODE', 'INJURY_NATURE']\n</code></pre>\n\n<h1>Code:</h1>\n\n<p>Import: </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nimport numpy as np\n\ncols = [ 'AGE_RANGE', 'GENDER', 'TOTAL_PAID', 'INDUSTRY_DESCRIPTION', 'WORKER_AGE', 'NATURE_CODE', 'ACCIDENT_TYPE_CODE', 'INJURY_NATURE']\nfeatures = pd.read_csv('gs://longtailclaims2/filename.csv', usecols = cols, header=0, encoding='ISO-8859-1')\ncategoricals = [ 'AGE_RANGE', 'GENDER', 'INDUSTRY_DESCRIPTION', 'NATURE_CODE', 'ACCIDENT_TYPE_CODE', 'INJURY_NATURE']\n</code></pre>\n\n<p>First I turn categorical values into 0s and 1s: </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>features2 = pd.get_dummies(features, columns = categoricals)\n</code></pre>\n\n<p>Then I isolate features from labels (TOTAL_PAID):</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>labels = np.array(features['TOTAL_PAID'])\nfeatures = features2.drop('TOTAL_PAID', axis = 1)\nfeature_list = list(features.columns)\nfeature_list_no_facts = list(features.columns)\n</code></pre>\n\n<p>Spit into SK Learn training and test set: </p>\n\n<pre class=\"lang-py prettyprint-override\"><code># Using Skicit-learn to split data into training and testing sets\nfrom sklearn.model_selection import train_test_split\n\n# Split the data into training and testing sets\ntrain_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\ntest_features.head(5)\ntest_features.head(5)\n</code></pre>\n\n<p>Then I explore the data: </p>\n\n<pre><code>print('Training Features Shape:', train_features.shape)\nprint('Training Labels Shape:', train_labels.shape)\nprint('Testing Features Shape:', test_features.shape)\nprint('Testing Labels Shape:', test_labels.shape)\n</code></pre>\n\n<p>Output: </p>\n\n<pre><code>Training Features Shape: (128304, 337)\nTraining Labels Shape: (128304,)\nTesting Features Shape: (42768, 337)\nTesting Labels Shape: (42768,)\n</code></pre>\n\n<h1>1. XGBRegressor</h1>\n\n<p>First we try training XGBoost model. I needed so push # estimates above 10,000 to get a decent accuracy (R2 > 0.94)</p>\n\n<pre class=\"lang-py prettyprint-override\"><code># Import the model we are using\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import ensemble \nfrom sklearn.metrics import mean_squared_error\n\nx = XGBRegressor(random_state = 44, n_jobs = 8, n_estimators = 10000, max_depth=10, verbosity = 3)\nx.fit(train_features, train_labels)\nprint('xgboost train score: ', x.score(train_features, train_labels))\npredictions = x.predict(test_features)\nprint('xgboost test score: ', x.score(test_features, test_labels))\n</code></pre>\n\n<p>Here, train and test score: R2 ~0.94.</p>\n\n<h1>2. Random Forest Regressor</h1>\n\n<p>Then we try Random Forest model. After some fiddling it appears 100 estimators is enough to get a pretty good accuracy (R2 > 0.94)</p>\n\n<pre class=\"lang-py prettyprint-override\"><code># Instantiate model with 100 decision trees\nrf = RandomForestRegressor(n_estimators = 100, criterion='mse', verbose=1, random_state = np.random.RandomState(42), n_jobs = -1)\n# Train the model on training data\nrf.fit(train_features, train_labels);\nprint('random forest train score: ', rf.score(train_features, train_labels))\npredictions = rf.predict(test_features)\nprint('random forest test score: ', rf.score(test_features, test_labels))\n</code></pre>\n\n<p>In this case, train and test score R2 at ~0.94.</p>\n\n<h1>3. MLP Neural Network</h1>\n\n<p>Finally I wanted to compare performance to an MLP Regressor. According to the books I have been reading on deep learning, a neural network should be able to outperform any shallow learning algorithm given enough time and horse power. I am using a pretty beefy machine with 8 cores and 30 GB RAM on Google Cloud. </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from sklearn.neural_network import MLPRegressor\nnn = MLPRegressor(hidden_layer_sizes=(338, 338, 50), \n                  activation='relu', solver='adam', max_iter = 100, random_state = 56, verbose = True)\nnn.fit(train_features, train_labels)\nnn_predictions = nn.predict(test_features)\nprint('nn train score: ', nn.score(train_features, train_labels))\nprint('nn test score: ', nn.score(test_features, test_labels))\n</code></pre>\n\n<p>R2 around 0.4.</p>\n\n<p>I've used 338 neurons in the input layer as this is the exact number of columns. The neural network stalls at 82 iterations and doesn't go any further. Running with 50 iterations I get accuracy at R2 &lt; 0.5, which is not impressive.</p>\n\n<h1>My questions:</h1>\n\n<ol>\n<li>Do I handle the management of categorical features correctly?\nWith the scores above, does it look like model #1 and #2 are\noverfitting? R2 > 0.94 is pretty good and both test and training\naccuracy look good and in same ballpark, so I don't think it is\noverfitting </li>\n<li><p>Why does the neural network not perform that well?</p></li>\n<li><p>Should I consider a different type of neural network for regression?</p></li>\n<li><p>Why do I have to add so many more estimators to XGBoost (10,000) to get the same performance as Random Forest (100)? </p></li>\n<li><p>What would be a fit for purpose neural network to solve this problem with deep learning? I am concerned the ensemble methods may not be appropriate or that I am doing something wrong.</p></li>\n</ol>\n",
                "tags": "<python><neural-network><scikit-learn><regression><xgboost>",
                "answers": [
                    [
                        "56749",
                        "2",
                        "49758",
                        "",
                        "",
                        "<p>Regarding the <code>MLPRegressor</code>, you should use the <code>lbfgs</code> optimizer for better results with small datasets. Accuracy should be up to 0.99.  </p>\n",
                        "",
                        ""
                    ],
                    [
                        "49762",
                        "2",
                        "49758",
                        "",
                        "",
                        "<p>Some ideas:</p>\n\n<ol>\n<li><strong>Handling categorical features correctly:</strong> using one-hot encoding is one valid approach. Other approaches include target encoding (or mean encoding), and the hashing trick. There's no real hard and fast rule about when to choose which method.</li>\n<li><strong>Poor performance of neural network:</strong> I don't have much experience with neural networks, but I have read that inputs into neural networks should be scaled in some way - either standardised, or to lie within some narrow and consistent interval. You could also look at other layer structures - e.g. have you tried the default values from Scikit-Learn?</li>\n<li><strong>Considering different kind of network:</strong> Judge based on (2) above</li>\n<li><strong>More estimators in <code>xgboost</code>:</strong> <code>xgboost</code> has many parameters to fine tune. You should also consider that <code>xgboost</code> uses linear regression as a default regression task, which implies that your target insurance losses are normally distributed. This is not usually the case in the real world, where we see that insurance losses usually follow a Tweedie distribution. <code>xgboost</code> offers Tweedie regression capability.</li>\n<li><strong>Optimal neural network for this problem:</strong> Unsure as my experience with neural networks is limited.</li>\n</ol>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3313",
            "_score": 9.453468,
            "_source": {
                "title": "What is the difference between model hyperparameters and model parameters?",
                "content": "What is the difference between model hyperparameters and model parameters? <p>I have noticed that such terms as model <strong>hyperparameter</strong> and model <strong>parameter</strong> have been used interchangeably on the web without prior clarification. I think this is incorrect and needs explanation. Consider a machine learning model, an SVM/NN/NB based classificator or image recognizer, just anything that first springs to mind. </p>\n\n<p>What are the <strong>hyperparameters</strong> and <strong>parameters</strong> of the model?<br>\nGive your examples please.</p>\n <machine-learning><parameter><hyperparameter><language-model><p>Model parameters are estimated from data automatically and model hyperparameters are set manually and are used in processes to help estimate model parameters.</p>\n\n<p>Model hyperparameters are often referred to as parameters because they are the parts of the machine learning that must be set manually and tuned.</p>\n\n<p>Basically, parameters are the ones that the \u201cmodel\u201d uses to make predictions etc. For example, the weight coefficients in a linear regression model. Hyperparameters are the ones that help with the learning process. For example, number of clusters in K-Means, shrinkage factor in Ridge Regression. They won\u2019t appear in the final prediction piece, but they have a large influence on how the parameters would look like after the learning step.</p>\n\n<p>Refer : <a href=\"https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/\" rel=\"nofollow noreferrer\">https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/</a></p>\n<p><strong>Hyper-parameters</strong> are those which we supply to the model, for example: number of hidden Nodes and Layers,input features, Learning Rate, Activation Function etc in Neural Network, while <strong>Parameters</strong> are those which would be learned by the machine like Weights and Biases.</p>\n<p>Hyperparameters and parameters are often used interchangeably but there is a difference between them. You call something a 'hyperparameter' if it cannot be learned within the estimator directly. However, 'parameters' is  more general term. When you say 'passing the parameters to the model', it generally means a combination of hyperparameters along with some other parameters that are not directly related to your estimator but are required for your model.</p>\n\n<p>For example, suppose your are building an SVM classifier in sklearn:</p>\n\n<pre><code>from sklearn import svm\nX = [[0, 0], [1, 1]]\ny = [0, 1]\nclf = svm.SVC(C =0.01, kernel ='rbf', random_state=33)\nclf.fit(X, y) \n</code></pre>\n\n<p>In the above code an instance of SVM is your estimator for your model for which the hyperparameters, in this case, are <code>C</code> and <code>kernel</code>. But your model has another parameter which is not a hyperparameter and that is <code>random_state</code>.</p>\n<p>In addition to the answer above.</p>\n\n<p><em>Model parameters</em> are the properties of the training data that are learnt during training by the classifier or other ml model. For example in case of some NLP task: word frequency, sentence length, noun or verb distribution per sentence, the number of specific character n-grams per word, lexical diversity, etc. <em>Model parameters</em> differ for each experiment and depend on the type of data and task at hand. </p>\n\n<p><em>Model hyperparameters</em>, on the other hand, are common for similar models and cannot be learnt during training but are set beforehand. A typical set of hyperparameters for NN include the number and size of the hidden layers, weight initialization scheme, learning rate and its decay, dropout and gradient clipping threshold, etc. </p>\n<p>In machine learning, a model $M$ with parameters and hyper-parameters looks like,</p>\n\n<p>$Y \\approx M_{\\mathcal{H}}(\\Phi | D)$</p>\n\n<p>where $\\Phi$ are parameters and $\\mathcal{H}$ are hyper-parameters. $D$ is training data and $Y$ is output data (class labels in case of classification task).</p>\n\n<p>The objective during training is to find estimate of parameters $\\hat{\\Phi}$ that optimizes some loss function $\\mathcal{L}$ we have specified. Since, model $M$ and loss-function $\\mathcal{L}$ are based on $\\mathcal{H}$, then the consequent parameters $\\Phi$ are also dependent on hyper-parameters $\\mathcal{H}$. </p>\n\n<p>The hyper-parameters $\\mathcal{H}$ are not 'learnt' during training, but does not mean their values are immutable. Typically, the hyper-parameters are fixed and we think simply of the model $M$, instead of $M_{\\mathcal{H}}$. Herein, the hyper-parameters can also be considers as a-priori parameters.</p>\n\n<p>The source of confusion stems from the use of $M_{\\mathcal{H}}$ and modification of hyper-parameters $\\mathcal{H}$ during training routine in addition to, obviously, the parameters $\\hat{\\Phi}$. There are potentially several motivations to modify $\\mathcal{H}$ during training. An example would be to change the learning-rate during training to improve speed and/or stability of the optimization routine.</p>\n\n<p>The important point of distinction is that, the result, say label prediction, $Y_{pred}$ is based on model parameters $\\Phi$ and not the hyper-parameters $\\mathcal{H}$.</p>\n\n<p>The distinction however has caveats and consequently the lines are blurred. Consider for example the task of clustering, specifically Gaussian Mixture Modeling (GMM). The parameters set here is $\\Phi = \\{\\bar{\\mu}, \\bar{\\sigma} \\}$, where $\\bar{\\mu}$ is set of $N$ cluster means and $\\bar{\\sigma}$ is set of $N$ standard-deviations, for $N$ Gaussian kernels.</p>\n\n<p>You may have intuitively recognized the hyper-parameter here. It is the number of clusters $N$. So $\\mathcal{H} = \\{N \\}$. Typically, cluster validation is used to determine $N$ apriori, using a small sub-sample of the data $D$. However, I could also modify my learning algorithm of Gaussian Mixture Models to modify the number of kernels $N$ during training, based on some criterion. In this scenario, the hyper-parameter, $N$ becomes part of the set of parameters $\\Phi = \\{\\bar{\\mu}, \\bar{\\sigma}, N \\}$.</p>\n\n<p>Nevertheless, it should be pointed out that result, or predicted value, for a data point $d$ in data $D$ is based on $GMM(\\bar{\\mu}, \\bar{\\sigma})$ and not $N$. That is, each of the $N$ Gaussian kernels will contribute some likelihood value to $d$ based on the distance of $d$ from their respective $\\mu$ and their own $\\sigma$. The 'parameter' $N$ is not explicitly involved here, so its arguably not 'really' a parameter of the model.</p>\n\n<p>Summary: the distinction between parameters and hyper-parameters is nuanced due to the way they are utilized by practitioners when designing the model $M$ and loss-function $\\mathcal{L}$. I hope this helps disambiguate between the two terms.</p>\n<p>In simplified words,</p>\n\n<p>Model Parameters are something that a model learns on its own. \nFor example, \n1) Weights or Coefficients of independent variables in Linear regression model. \n2) Weights or Coefficients of independent variables SVM. \n3) Split points in Decision Tree.</p>\n\n<p>Model hyper-parameters are used to optimize the model performance.\nFor example,\n1)Kernel and slack in SVM.\n2)Value of K in KNN.\n3)Depth of tree in Decision trees. </p>\n",
                "codes": [
                    [],
                    [],
                    [
                        "from sklearn import svm\nX = [[0, 0], [1, 1]]\ny = [0, 1]\nclf = svm.SVC(C =0.01, kernel ='rbf', random_state=33)\nclf.fit(X, y) \n"
                    ],
                    [],
                    [],
                    []
                ],
                "question_id:": "14187",
                "question_votes:": "23",
                "question_text:": "<p>I have noticed that such terms as model <strong>hyperparameter</strong> and model <strong>parameter</strong> have been used interchangeably on the web without prior clarification. I think this is incorrect and needs explanation. Consider a machine learning model, an SVM/NN/NB based classificator or image recognizer, just anything that first springs to mind. </p>\n\n<p>What are the <strong>hyperparameters</strong> and <strong>parameters</strong> of the model?<br>\nGive your examples please.</p>\n",
                "tags": "<machine-learning><parameter><hyperparameter><language-model>",
                "answers": [
                    [
                        "42214",
                        "2",
                        "14187",
                        "",
                        "",
                        "<p>Model parameters are estimated from data automatically and model hyperparameters are set manually and are used in processes to help estimate model parameters.</p>\n\n<p>Model hyperparameters are often referred to as parameters because they are the parts of the machine learning that must be set manually and tuned.</p>\n\n<p>Basically, parameters are the ones that the \u201cmodel\u201d uses to make predictions etc. For example, the weight coefficients in a linear regression model. Hyperparameters are the ones that help with the learning process. For example, number of clusters in K-Means, shrinkage factor in Ridge Regression. They won\u2019t appear in the final prediction piece, but they have a large influence on how the parameters would look like after the learning step.</p>\n\n<p>Refer : <a href=\"https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/\" rel=\"nofollow noreferrer\">https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/</a></p>\n",
                        "",
                        ""
                    ],
                    [
                        "32576",
                        "2",
                        "14187",
                        "",
                        "",
                        "<p><strong>Hyper-parameters</strong> are those which we supply to the model, for example: number of hidden Nodes and Layers,input features, Learning Rate, Activation Function etc in Neural Network, while <strong>Parameters</strong> are those which would be learned by the machine like Weights and Biases.</p>\n",
                        "",
                        "6"
                    ],
                    [
                        "14194",
                        "2",
                        "14187",
                        "",
                        "",
                        "<p>Hyperparameters and parameters are often used interchangeably but there is a difference between them. You call something a 'hyperparameter' if it cannot be learned within the estimator directly. However, 'parameters' is  more general term. When you say 'passing the parameters to the model', it generally means a combination of hyperparameters along with some other parameters that are not directly related to your estimator but are required for your model.</p>\n\n<p>For example, suppose your are building an SVM classifier in sklearn:</p>\n\n<pre><code>from sklearn import svm\nX = [[0, 0], [1, 1]]\ny = [0, 1]\nclf = svm.SVC(C =0.01, kernel ='rbf', random_state=33)\nclf.fit(X, y) \n</code></pre>\n\n<p>In the above code an instance of SVM is your estimator for your model for which the hyperparameters, in this case, are <code>C</code> and <code>kernel</code>. But your model has another parameter which is not a hyperparameter and that is <code>random_state</code>.</p>\n",
                        "",
                        "23"
                    ],
                    [
                        "14234",
                        "2",
                        "14187",
                        "",
                        "",
                        "<p>In addition to the answer above.</p>\n\n<p><em>Model parameters</em> are the properties of the training data that are learnt during training by the classifier or other ml model. For example in case of some NLP task: word frequency, sentence length, noun or verb distribution per sentence, the number of specific character n-grams per word, lexical diversity, etc. <em>Model parameters</em> differ for each experiment and depend on the type of data and task at hand. </p>\n\n<p><em>Model hyperparameters</em>, on the other hand, are common for similar models and cannot be learnt during training but are set beforehand. A typical set of hyperparameters for NN include the number and size of the hidden layers, weight initialization scheme, learning rate and its decay, dropout and gradient clipping threshold, etc. </p>\n",
                        "",
                        "18"
                    ],
                    [
                        "23092",
                        "2",
                        "14187",
                        "",
                        "",
                        "<p>In machine learning, a model $M$ with parameters and hyper-parameters looks like,</p>\n\n<p>$Y \\approx M_{\\mathcal{H}}(\\Phi | D)$</p>\n\n<p>where $\\Phi$ are parameters and $\\mathcal{H}$ are hyper-parameters. $D$ is training data and $Y$ is output data (class labels in case of classification task).</p>\n\n<p>The objective during training is to find estimate of parameters $\\hat{\\Phi}$ that optimizes some loss function $\\mathcal{L}$ we have specified. Since, model $M$ and loss-function $\\mathcal{L}$ are based on $\\mathcal{H}$, then the consequent parameters $\\Phi$ are also dependent on hyper-parameters $\\mathcal{H}$. </p>\n\n<p>The hyper-parameters $\\mathcal{H}$ are not 'learnt' during training, but does not mean their values are immutable. Typically, the hyper-parameters are fixed and we think simply of the model $M$, instead of $M_{\\mathcal{H}}$. Herein, the hyper-parameters can also be considers as a-priori parameters.</p>\n\n<p>The source of confusion stems from the use of $M_{\\mathcal{H}}$ and modification of hyper-parameters $\\mathcal{H}$ during training routine in addition to, obviously, the parameters $\\hat{\\Phi}$. There are potentially several motivations to modify $\\mathcal{H}$ during training. An example would be to change the learning-rate during training to improve speed and/or stability of the optimization routine.</p>\n\n<p>The important point of distinction is that, the result, say label prediction, $Y_{pred}$ is based on model parameters $\\Phi$ and not the hyper-parameters $\\mathcal{H}$.</p>\n\n<p>The distinction however has caveats and consequently the lines are blurred. Consider for example the task of clustering, specifically Gaussian Mixture Modeling (GMM). The parameters set here is $\\Phi = \\{\\bar{\\mu}, \\bar{\\sigma} \\}$, where $\\bar{\\mu}$ is set of $N$ cluster means and $\\bar{\\sigma}$ is set of $N$ standard-deviations, for $N$ Gaussian kernels.</p>\n\n<p>You may have intuitively recognized the hyper-parameter here. It is the number of clusters $N$. So $\\mathcal{H} = \\{N \\}$. Typically, cluster validation is used to determine $N$ apriori, using a small sub-sample of the data $D$. However, I could also modify my learning algorithm of Gaussian Mixture Models to modify the number of kernels $N$ during training, based on some criterion. In this scenario, the hyper-parameter, $N$ becomes part of the set of parameters $\\Phi = \\{\\bar{\\mu}, \\bar{\\sigma}, N \\}$.</p>\n\n<p>Nevertheless, it should be pointed out that result, or predicted value, for a data point $d$ in data $D$ is based on $GMM(\\bar{\\mu}, \\bar{\\sigma})$ and not $N$. That is, each of the $N$ Gaussian kernels will contribute some likelihood value to $d$ based on the distance of $d$ from their respective $\\mu$ and their own $\\sigma$. The 'parameter' $N$ is not explicitly involved here, so its arguably not 'really' a parameter of the model.</p>\n\n<p>Summary: the distinction between parameters and hyper-parameters is nuanced due to the way they are utilized by practitioners when designing the model $M$ and loss-function $\\mathcal{L}$. I hope this helps disambiguate between the two terms.</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "20456",
                        "2",
                        "14187",
                        "",
                        "",
                        "<p>In simplified words,</p>\n\n<p>Model Parameters are something that a model learns on its own. \nFor example, \n1) Weights or Coefficients of independent variables in Linear regression model. \n2) Weights or Coefficients of independent variables SVM. \n3) Split points in Decision Tree.</p>\n\n<p>Model hyper-parameters are used to optimize the model performance.\nFor example,\n1)Kernel and slack in SVM.\n2)Value of K in KNN.\n3)Depth of tree in Decision trees. </p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "2960",
            "_score": 9.441455,
            "_source": {
                "title": "To learn machine learning which one is good?",
                "content": "To learn machine learning which one is good? <p>Until now I have implemented linear and logistic regression myself. I have not used any library other than <code>numpy</code> and <code>matplotlib</code>. But in the internet every example is solved using libraries such as <code>sklearn</code>, <code>pandas</code> and etc. My question is, which one is good to learn for machine learning, implementing algorithm yourself or using libraries (sklearn or ...)?</p>\n\n<p>Thanks.</p>\n <machine-learning><p>I second @NeilSlater. If your purpose is to study and understand Machine Learning, implementing algorithms would definitely help. On the other had, if you want to implement a ML algorithm to solve a real-life problem (or in Data Science competitions), I would suggest you try out the machine learning libraries in python, spark, R or any other language. The reason as explained by @ahajib is that these libraries have efficient implementations of the popular Machine Learning algorithms. <strong>So unless there is a purpose, why re-invent the wheel</strong>?</p>\n<p>I can think of the following pros and cons for each. As for learning to code your own machine learning algorithms such as logistic regression:</p>\n\n<ul>\n<li>You will definitely learn more about specific algorithms, their details, role of different parameters and etc. That is also a good practice of coding itself. Then you can validate your implementation by benchmarking it against other packages and implementations.</li>\n<li>You will have more freedom in controlling different aspects of your method. You can add functions and modules as you wish and do not necessary have to deal with predefined variables, methods and etc.</li>\n</ul>\n\n<p>On the other hand, implementing algorithms when it is not necessary and you can just use existing packages is like reinventing the wheel. It normally takes a lot of time and you have to verify your results for each one of them. Packages like <code>sklearn</code> are popular because of the following:</p>\n\n<ul>\n<li>A group of people are working on those, constantly making them up to date, testing the  methods in different situations for different needs. That makes packages like <code>sklearn</code> very dependable and usually scalable.</li>\n<li>If you have a question about them, there are tons of resources out there; documentation, forums, source code, communities like StackOverflow where thousands of people are eager to help you literally for any error you face while running your code. </li>\n<li>Another important feature is automated hyperparameters tuning. Most of machine learning algorithms have a series of hyperparameters that need to be optimized in order to achieve the best performance. Packages like <code>sklearn</code> efficiently search for the optimal tuning parameters (or \"hyperparameters\") for your machine learning model in order to maximize its performance.</li>\n<li>Still if you are interested in implementing machine learning algorithms and like the coding, you can always contribute to the existing packages. They usually have Github repositories where you can raise an issue, ask for a new feature or provide help improving them.</li>\n</ul>\n\n<p>All in all, if you have enough time and you are keen to learn low level details about those models, go ahead and give implementation them a shot. That is certainly fun. However, if you need to get to the results as soon as possible and looking for a reliable package where a huge group of people both in industry and academia are already using, <code>sklearn</code>, <code>pandas</code> and others are you options.</p>\n\n<p>Hope this is helpful and good luck.</p>\n<p>At the end of the day, the value of any Machine Learning Engineer rests on their ability to describe the world and to make predictions. One thing required of you to become a Professional is finding a Good Mentor and Nurturing Genuine Curiosity about it.</p>\n\n<p><a href=\"https://sinxloud.com/machine-learning-tutorial-courses-specialization-beginner/#1-machine-learning-offered-by-stanford--coursera\" rel=\"nofollow noreferrer\">Machine Learning offered by Stanford</a> is the perfect place for beginners to understand the core idea of teaching a computer to learn concepts using data without being explicitly programmed. This course is Created by an AI Pioneer - Andrew Ng and is rated 4.9 out of 5 of 81,708 ratings.</p>\n\n<p>Keep in mind that as you professionally begin your journey in Machine Learning, you\u2019ll have to build Solid Basis in Statistics, Algebra, Applied Mathematics, and Practice Python or R using all the important ML Libraries like scikit-learn, TensorFlow, Numpy, Keras, Theano and more.</p>\n\n<p>Check <a href=\"https://sinxloud.com/machine-learning-tutorial-courses-specialization-beginner/\" rel=\"nofollow noreferrer\">this Section</a> on Best Machine Learning Tutorial, Courses, and Specialization.</p>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "13082",
                "question_votes:": "1",
                "question_text:": "<p>Until now I have implemented linear and logistic regression myself. I have not used any library other than <code>numpy</code> and <code>matplotlib</code>. But in the internet every example is solved using libraries such as <code>sklearn</code>, <code>pandas</code> and etc. My question is, which one is good to learn for machine learning, implementing algorithm yourself or using libraries (sklearn or ...)?</p>\n\n<p>Thanks.</p>\n",
                "tags": "<machine-learning>",
                "answers": [
                    [
                        "13086",
                        "2",
                        "13082",
                        "",
                        "",
                        "<p>I second @NeilSlater. If your purpose is to study and understand Machine Learning, implementing algorithms would definitely help. On the other had, if you want to implement a ML algorithm to solve a real-life problem (or in Data Science competitions), I would suggest you try out the machine learning libraries in python, spark, R or any other language. The reason as explained by @ahajib is that these libraries have efficient implementations of the popular Machine Learning algorithms. <strong>So unless there is a purpose, why re-invent the wheel</strong>?</p>\n",
                        "",
                        ""
                    ],
                    [
                        "13084",
                        "2",
                        "13082",
                        "",
                        "",
                        "<p>I can think of the following pros and cons for each. As for learning to code your own machine learning algorithms such as logistic regression:</p>\n\n<ul>\n<li>You will definitely learn more about specific algorithms, their details, role of different parameters and etc. That is also a good practice of coding itself. Then you can validate your implementation by benchmarking it against other packages and implementations.</li>\n<li>You will have more freedom in controlling different aspects of your method. You can add functions and modules as you wish and do not necessary have to deal with predefined variables, methods and etc.</li>\n</ul>\n\n<p>On the other hand, implementing algorithms when it is not necessary and you can just use existing packages is like reinventing the wheel. It normally takes a lot of time and you have to verify your results for each one of them. Packages like <code>sklearn</code> are popular because of the following:</p>\n\n<ul>\n<li>A group of people are working on those, constantly making them up to date, testing the  methods in different situations for different needs. That makes packages like <code>sklearn</code> very dependable and usually scalable.</li>\n<li>If you have a question about them, there are tons of resources out there; documentation, forums, source code, communities like StackOverflow where thousands of people are eager to help you literally for any error you face while running your code. </li>\n<li>Another important feature is automated hyperparameters tuning. Most of machine learning algorithms have a series of hyperparameters that need to be optimized in order to achieve the best performance. Packages like <code>sklearn</code> efficiently search for the optimal tuning parameters (or \"hyperparameters\") for your machine learning model in order to maximize its performance.</li>\n<li>Still if you are interested in implementing machine learning algorithms and like the coding, you can always contribute to the existing packages. They usually have Github repositories where you can raise an issue, ask for a new feature or provide help improving them.</li>\n</ul>\n\n<p>All in all, if you have enough time and you are keen to learn low level details about those models, go ahead and give implementation them a shot. That is certainly fun. However, if you need to get to the results as soon as possible and looking for a reliable package where a huge group of people both in industry and academia are already using, <code>sklearn</code>, <code>pandas</code> and others are you options.</p>\n\n<p>Hope this is helpful and good luck.</p>\n",
                        "",
                        "5"
                    ],
                    [
                        "38273",
                        "2",
                        "13082",
                        "",
                        "",
                        "<p>At the end of the day, the value of any Machine Learning Engineer rests on their ability to describe the world and to make predictions. One thing required of you to become a Professional is finding a Good Mentor and Nurturing Genuine Curiosity about it.</p>\n\n<p><a href=\"https://sinxloud.com/machine-learning-tutorial-courses-specialization-beginner/#1-machine-learning-offered-by-stanford--coursera\" rel=\"nofollow noreferrer\">Machine Learning offered by Stanford</a> is the perfect place for beginners to understand the core idea of teaching a computer to learn concepts using data without being explicitly programmed. This course is Created by an AI Pioneer - Andrew Ng and is rated 4.9 out of 5 of 81,708 ratings.</p>\n\n<p>Keep in mind that as you professionally begin your journey in Machine Learning, you\u2019ll have to build Solid Basis in Statistics, Algebra, Applied Mathematics, and Practice Python or R using all the important ML Libraries like scikit-learn, TensorFlow, Numpy, Keras, Theano and more.</p>\n\n<p>Check <a href=\"https://sinxloud.com/machine-learning-tutorial-courses-specialization-beginner/\" rel=\"nofollow noreferrer\">this Section</a> on Best Machine Learning Tutorial, Courses, and Specialization.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12397",
            "_score": 9.33685,
            "_source": {
                "title": "Architecture for linear regression with variable input where each input is n-sized one-hot encoded",
                "content": "Architecture for linear regression with variable input where each input is n-sized one-hot encoded <p>I am relatively new to deep learning (got some experience with CNNs in PyTorch), and I am not sure how to tackle the following idea. I want to parse a sentence, e.g. <em>I like trees.</em>, one-hot encoded the parse output of each word, and feed that into a ML system. The output of each sentence is a floating-point number. As an example, the sentence <em>I like trees.</em> could be pre-processed and encoded as fixed-size feature vectors per token:</p>\n\n<pre><code>[[0 1 0 0 1] [1 0 0 0 0] [1 0 1 1 0] [0 0 0 0 1]]\n</code></pre>\n\n<p>or flattened</p>\n\n<pre><code>[0 1 0 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1]\n</code></pre>\n\n<p>However, the length of sentences can differ of course. From what I know there are some fixes to this. Using padding (when shorter than your defined cut-off) or cutting off the length to that cut-off (when longer). Another solution I often see mentioned is the use of an RNN/LSTM but I have no experience with them (only the basic theoretical notion). </p>\n\n<p>The expected output (label) of this sentence could be something like <code>50.2378</code>.</p>\n\n<p>My question, then, is which architecture is best suited for this task? RNNs are popular in NLP so I am leaning towards them, but I am not sure whether a regression task fits well (or how it fits) with the architecture of an RNN. I have looked for RNNs and regression but I can only find use cases involving time series, not NLP or one-hot encoded features.</p>\n\n<p>In essence, what I have is a dataset of sentences that are preprocessed to get some features <em>per token</em>. Let's assume for brevity sake that these features are syntactic, e.g. the word's POS tag and its dependency information (e.g. subj, obj, and so on). These features would then get one-hot encoded (I assume) to get an easy-to-use dataset. The <em>input</em>, thus, are sentences encoded in such a way that the information of tokens is shown, such as the flattened example above. </p>\n\n<p>The output for every sentence is some floating-point number, representing some value that has been calculated beforehand in theory these will indicate the sentence's equivalence with its translation, but that is not at all important for the system. The important part is that every input is a sentence mapped to a number.</p>\n\n<p>Some dummy data. The actual sentence, it's vector representation, and the output.</p>\n\n<pre><code>I like trees.                   [0 1 0 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1]                           50.2378\nWhat is that thing?             [1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 1 0 1]               20.1237\nWho are you?                    [0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 1 0 1]                           1.6589\nThe cookies smell good today.   [0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 1]     18.6295\nI do!                           [0 1 0 0 1 1 0 1 1 0 0 0 1 0 1]                                     24.5489   \n</code></pre>\n\n<p>The goal, then, is that an unseen given sentence can be pre-processed and one-hot encoded and given as input, and that an output (floating-point number) is predicted based on the trained model/function.</p>\n <neural-network><regression><rnn><recurrent-neural-net><pytorch><blockquote>\n  <p>The output for every sentence is some floating-point number, representing some value that has been calculated beforehand (...) the important part is that every input is a sentence mapped to a number.</p>\n</blockquote>\n\n<p>In essense this is a regression problem, i.e. given some input predict the (most likely) numeric output. However you could also see this as a classification problem if you are not interested in real numbers but in some range (=class), or a probability for each class.</p>\n\n<blockquote>\n  <p>RNNs are popular in NLP so I am leaning towards them,</p>\n</blockquote>\n\n<p>RNNs are well suited for sequence processing. The way you present the problem does not seem like there is much sequence processing involved - while you can get this to work with RNNs, I propose to try other less computationally involved approaches first. </p>\n\n<blockquote>\n  <p>I have looked for RNNs and regression but I can only find use cases involving time series, not NLP or one-hot encoded features.</p>\n</blockquote>\n\n<p>Unless there is some specific requirement to use RNNs or in extension LSTMs, I would try random forests, e.g. the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\" rel=\"nofollow noreferrer\"><code>RandomForestRegression</code></a> regressor from scikit-learn. This should work reasonably well using the one-hot encoded sentences (as outlined in the question) as X and the pre-calculated number as Y. Should you decide to instead make this a classificastion problem, you can easily switch to the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\" rel=\"nofollow noreferrer\"><code>RandomForestClassification</code></a> classifier from the same package.</p>\n\n<blockquote>\n  <p>an unseen given sentence can be pre-processed and one-hot encoded and given as input, and that an output (floating-point number) is predicted</p>\n</blockquote>\n\n<p>I suggest to use a Pipeline for both training and prediction, then serve this Pipeline to your application.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "43517",
                "question_votes:": "",
                "question_text:": "<p>I am relatively new to deep learning (got some experience with CNNs in PyTorch), and I am not sure how to tackle the following idea. I want to parse a sentence, e.g. <em>I like trees.</em>, one-hot encoded the parse output of each word, and feed that into a ML system. The output of each sentence is a floating-point number. As an example, the sentence <em>I like trees.</em> could be pre-processed and encoded as fixed-size feature vectors per token:</p>\n\n<pre><code>[[0 1 0 0 1] [1 0 0 0 0] [1 0 1 1 0] [0 0 0 0 1]]\n</code></pre>\n\n<p>or flattened</p>\n\n<pre><code>[0 1 0 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1]\n</code></pre>\n\n<p>However, the length of sentences can differ of course. From what I know there are some fixes to this. Using padding (when shorter than your defined cut-off) or cutting off the length to that cut-off (when longer). Another solution I often see mentioned is the use of an RNN/LSTM but I have no experience with them (only the basic theoretical notion). </p>\n\n<p>The expected output (label) of this sentence could be something like <code>50.2378</code>.</p>\n\n<p>My question, then, is which architecture is best suited for this task? RNNs are popular in NLP so I am leaning towards them, but I am not sure whether a regression task fits well (or how it fits) with the architecture of an RNN. I have looked for RNNs and regression but I can only find use cases involving time series, not NLP or one-hot encoded features.</p>\n\n<p>In essence, what I have is a dataset of sentences that are preprocessed to get some features <em>per token</em>. Let's assume for brevity sake that these features are syntactic, e.g. the word's POS tag and its dependency information (e.g. subj, obj, and so on). These features would then get one-hot encoded (I assume) to get an easy-to-use dataset. The <em>input</em>, thus, are sentences encoded in such a way that the information of tokens is shown, such as the flattened example above. </p>\n\n<p>The output for every sentence is some floating-point number, representing some value that has been calculated beforehand in theory these will indicate the sentence's equivalence with its translation, but that is not at all important for the system. The important part is that every input is a sentence mapped to a number.</p>\n\n<p>Some dummy data. The actual sentence, it's vector representation, and the output.</p>\n\n<pre><code>I like trees.                   [0 1 0 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1]                           50.2378\nWhat is that thing?             [1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 1 0 1]               20.1237\nWho are you?                    [0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 1 0 1]                           1.6589\nThe cookies smell good today.   [0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 1]     18.6295\nI do!                           [0 1 0 0 1 1 0 1 1 0 0 0 1 0 1]                                     24.5489   \n</code></pre>\n\n<p>The goal, then, is that an unseen given sentence can be pre-processed and one-hot encoded and given as input, and that an output (floating-point number) is predicted based on the trained model/function.</p>\n",
                "tags": "<neural-network><regression><rnn><recurrent-neural-net><pytorch>",
                "answers": [
                    [
                        "43526",
                        "2",
                        "43517",
                        "",
                        "",
                        "<blockquote>\n  <p>The output for every sentence is some floating-point number, representing some value that has been calculated beforehand (...) the important part is that every input is a sentence mapped to a number.</p>\n</blockquote>\n\n<p>In essense this is a regression problem, i.e. given some input predict the (most likely) numeric output. However you could also see this as a classification problem if you are not interested in real numbers but in some range (=class), or a probability for each class.</p>\n\n<blockquote>\n  <p>RNNs are popular in NLP so I am leaning towards them,</p>\n</blockquote>\n\n<p>RNNs are well suited for sequence processing. The way you present the problem does not seem like there is much sequence processing involved - while you can get this to work with RNNs, I propose to try other less computationally involved approaches first. </p>\n\n<blockquote>\n  <p>I have looked for RNNs and regression but I can only find use cases involving time series, not NLP or one-hot encoded features.</p>\n</blockquote>\n\n<p>Unless there is some specific requirement to use RNNs or in extension LSTMs, I would try random forests, e.g. the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\" rel=\"nofollow noreferrer\"><code>RandomForestRegression</code></a> regressor from scikit-learn. This should work reasonably well using the one-hot encoded sentences (as outlined in the question) as X and the pre-calculated number as Y. Should you decide to instead make this a classificastion problem, you can easily switch to the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\" rel=\"nofollow noreferrer\"><code>RandomForestClassification</code></a> classifier from the same package.</p>\n\n<blockquote>\n  <p>an unseen given sentence can be pre-processed and one-hot encoded and given as input, and that an output (floating-point number) is predicted</p>\n</blockquote>\n\n<p>I suggest to use a Pipeline for both training and prediction, then serve this Pipeline to your application.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13186",
            "_score": 9.29999,
            "_source": {
                "title": "How to handle features which are not always available?",
                "content": "How to handle features which are not always available? <p>I have a feature in my feature vector that is not always available respectively sometimes (for some samples) it makes no sense to use it. I feed a sklearn MLPClassifier with this feature vector. Does the neural network learn by itself when the feature make sense to use for its decision or do I have to add a flag in the feature vector which says for example \u201c1\u201d if it makes sense or \u201c0\u201d if it does not make sense.</p>\n <neural-network><feature-selection><mlp><p>Depending on the problem, you can solve the problem by deleting these values and imputing them with an estimate if it's possible. Another strategy is to scale features on a -1,1 scale and impite this values with for example -3. Then use some robust methods that completely ignore the \"outliers\". Hope this helps.</p>\n<p>If the features you train with are not the same you want to predict with you have a couple of options:</p>\n\n<ol>\n<li>Retrain the model such that the feature in question is not used, since it won't be in your prediction data set.</li>\n<li>Impute some value for that feature if it is missing in your data set. In your example you might make an assumption that it is \"0\" if it is missing, but you will have to decide this based on the data set and your intuition.</li>\n</ol>\n\n<p>If the feature vector lengths of your training set and prediction set are different, then you are going to run into errors on the prediction set.</p>\n<p>If the feature doesn't make sense in a subset of the samples, doesn't this mean that this is (or should be) a separate dataset, that needs a second model? That's one approach I'd think about.</p>\n\n<p>The second would be to work with the data (feature) itself. It's probably best to use neutral value.</p>\n\n<ul>\n<li>In case of numerical value:\n\n<ul>\n<li>try using a mean or median value, calculated on all entries</li>\n<li>try using an extreme value, e.g. -1 if your feature has only positive values. This should indicate that the feature is missing and the network should be able to handle it.</li>\n</ul></li>\n<li>In case of textual value, e.g. word embeddings, replace the value with a placeholder like <code>N/A</code> that doesn't have an embedding</li>\n</ul>\n<p>You can use dummy variable encoding if the cases. You can enhance this idea to your problem as well. I will illustrate the procedure for a simple linear regression.</p>\n\n<p>Imagine we want to predict the income of a person <span class=\"math-container\">$y_i$</span> by using years of education <span class=\"math-container\">$x_{1i}$</span>, lectures taught <span class=\"math-container\">$x_{2i}$</span>, papers published <span class=\"math-container\">$x_{3i}$</span> and current academic position <span class=\"math-container\">$x_{4i}$</span>. The sample does contain academic as well as non-academic persons.</p>\n\n<p><strong>1. Alternative</strong>: Assign natural void values. E.g. If we are looking for a child it does not make sense to include the income. But Income has a natural void value which is <span class=\"math-container\">$0$</span>. You could check if your variables also allow such a void value.</p>\n\n<p><strong>2. Alternative</strong>: You could split the dataset into two groups (academic and non-academic). And run two separate models.</p>\n\n<p><strong>3. Alternative</strong>: Introduces a new dummy variable <code>is_academic</code> <span class=\"math-container\">$x_{5i}$</span> this variable is <span class=\"math-container\">$0$</span> if the person <span class=\"math-container\">$i$</span> is not academic and the value is <span class=\"math-container\">$1$</span> if the person <span class=\"math-container\">$i$</span> is academic. Then your regression model would look like</p>\n\n<p><span class=\"math-container\">$$y_i = w_0+\\tilde{w}_0x_{5i}+w_1x_{1i}+\\tilde{w}_1x_{5i}x_{1i}+\\tilde{w}_2x_{5i}x_{2i}+\\tilde{w}_3x_{5i}x_{3i}++\\tilde{w}_4x_{5i}x_{4i}+\\varepsilon_i$$</span></p>\n\n<p>So our data set is not <span class=\"math-container\">$x_{1i}, x_{2i}, x_{3i}, x_{4i}, y_i$</span> but <span class=\"math-container\">$x_{1i},x_{5i},x_{5i}x_{1i},x_{5i}x_{2i},x_{5i}x_{3i}, x_{5i}x_{4i}, y_i$</span>.Now the dataset is complete but the model is not using linear basis function anymore. </p>\n\n<p>Similarly, you could think about your dataset and introduce dummy variables when you see that some features are only present/useful for one subsample in your dataset. </p>\n",
                "codes": [
                    [],
                    [],
                    [],
                    []
                ],
                "question_id:": "45434",
                "question_votes:": "7",
                "question_text:": "<p>I have a feature in my feature vector that is not always available respectively sometimes (for some samples) it makes no sense to use it. I feed a sklearn MLPClassifier with this feature vector. Does the neural network learn by itself when the feature make sense to use for its decision or do I have to add a flag in the feature vector which says for example \u201c1\u201d if it makes sense or \u201c0\u201d if it does not make sense.</p>\n",
                "tags": "<neural-network><feature-selection><mlp>",
                "answers": [
                    [
                        "45455",
                        "2",
                        "45434",
                        "",
                        "",
                        "<p>Depending on the problem, you can solve the problem by deleting these values and imputing them with an estimate if it's possible. Another strategy is to scale features on a -1,1 scale and impite this values with for example -3. Then use some robust methods that completely ignore the \"outliers\". Hope this helps.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "45448",
                        "2",
                        "45434",
                        "",
                        "",
                        "<p>If the features you train with are not the same you want to predict with you have a couple of options:</p>\n\n<ol>\n<li>Retrain the model such that the feature in question is not used, since it won't be in your prediction data set.</li>\n<li>Impute some value for that feature if it is missing in your data set. In your example you might make an assumption that it is \"0\" if it is missing, but you will have to decide this based on the data set and your intuition.</li>\n</ol>\n\n<p>If the feature vector lengths of your training set and prediction set are different, then you are going to run into errors on the prediction set.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "45616",
                        "2",
                        "45434",
                        "",
                        "",
                        "<p>If the feature doesn't make sense in a subset of the samples, doesn't this mean that this is (or should be) a separate dataset, that needs a second model? That's one approach I'd think about.</p>\n\n<p>The second would be to work with the data (feature) itself. It's probably best to use neutral value.</p>\n\n<ul>\n<li>In case of numerical value:\n\n<ul>\n<li>try using a mean or median value, calculated on all entries</li>\n<li>try using an extreme value, e.g. -1 if your feature has only positive values. This should indicate that the feature is missing and the network should be able to handle it.</li>\n</ul></li>\n<li>In case of textual value, e.g. word embeddings, replace the value with a placeholder like <code>N/A</code> that doesn't have an embedding</li>\n</ul>\n",
                        "",
                        "1"
                    ],
                    [
                        "47465",
                        "2",
                        "45434",
                        "",
                        "",
                        "<p>You can use dummy variable encoding if the cases. You can enhance this idea to your problem as well. I will illustrate the procedure for a simple linear regression.</p>\n\n<p>Imagine we want to predict the income of a person <span class=\"math-container\">$y_i$</span> by using years of education <span class=\"math-container\">$x_{1i}$</span>, lectures taught <span class=\"math-container\">$x_{2i}$</span>, papers published <span class=\"math-container\">$x_{3i}$</span> and current academic position <span class=\"math-container\">$x_{4i}$</span>. The sample does contain academic as well as non-academic persons.</p>\n\n<p><strong>1. Alternative</strong>: Assign natural void values. E.g. If we are looking for a child it does not make sense to include the income. But Income has a natural void value which is <span class=\"math-container\">$0$</span>. You could check if your variables also allow such a void value.</p>\n\n<p><strong>2. Alternative</strong>: You could split the dataset into two groups (academic and non-academic). And run two separate models.</p>\n\n<p><strong>3. Alternative</strong>: Introduces a new dummy variable <code>is_academic</code> <span class=\"math-container\">$x_{5i}$</span> this variable is <span class=\"math-container\">$0$</span> if the person <span class=\"math-container\">$i$</span> is not academic and the value is <span class=\"math-container\">$1$</span> if the person <span class=\"math-container\">$i$</span> is academic. Then your regression model would look like</p>\n\n<p><span class=\"math-container\">$$y_i = w_0+\\tilde{w}_0x_{5i}+w_1x_{1i}+\\tilde{w}_1x_{5i}x_{1i}+\\tilde{w}_2x_{5i}x_{2i}+\\tilde{w}_3x_{5i}x_{3i}++\\tilde{w}_4x_{5i}x_{4i}+\\varepsilon_i$$</span></p>\n\n<p>So our data set is not <span class=\"math-container\">$x_{1i}, x_{2i}, x_{3i}, x_{4i}, y_i$</span> but <span class=\"math-container\">$x_{1i},x_{5i},x_{5i}x_{1i},x_{5i}x_{2i},x_{5i}x_{3i}, x_{5i}x_{4i}, y_i$</span>.Now the dataset is complete but the model is not using linear basis function anymore. </p>\n\n<p>Similarly, you could think about your dataset and introduce dummy variables when you see that some features are only present/useful for one subsample in your dataset. </p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6404",
            "_score": 9.299499,
            "_source": {
                "title": "Parameterization regression of rotation angle",
                "content": "Parameterization regression of rotation angle <p>Let's say I have a top-down picture of an arrow, and I want to predict the angle this arrow makes. This would be between $0$ and $360$ degrees, or between $0$ and $2\\pi$. The problem is that this target is circular, $0$ and $360$ degrees are exactly the same which is an invariance I would like to incorporate in my target, which should help generalization significantly (this is my assumption). The problem is that I don't see a clean way of solving this, are there any papers that try to tackle this problem (or similar ones)? I do have some ideas with their potential downsides:</p>\n\n<ul>\n<li><p>Use a sigmoid or tanh activation, scale it to the ($0, 2\\pi)$ range and incorporate the circular property in the loss function. I think this will fail fairly hard, because if it's on the border (worst prediction) only a tiny bit of noise will push the weights to go one way or the other. Also, values closer to the border of $0$ and $2\\pi$ will be more difficult to reach because the absolute pre-activation value will need to be close to infinite.</p></li>\n<li><p>Regress to two values, a $x$ and $y$ value and calculate the loss based on the angle these two values make. I think this one has more potential but the norm of this vector is unbounded, which could lead to numeric instability and could lead to blow ups or going to 0 during training. This could potentially be solved by using some weird regularizer to prevent this norm from going too far away from 1.</p></li>\n</ul>\n\n<p>Other options would be doing something with sine and cosine functions but I feel like the fact that multiple pre-activations map to the same output will also make optimization and generalizations very difficult.</p>\n <neural-network><deep-learning><loss-function><parameter-estimation><p>The second way, predicting $x=cos(\\alpha)$ and $y=sin(\\alpha)$ is totally okay. </p>\n\n<p>Yes, the norm of the predicted $(x, y)$ vector is not guaranteed to be near $1$. But it is not likely to blow up, especially if you use sigmoid activation functions (which are bounded by they nature) and/or regularize your model well. Why should your model predict a large value, if all the training samples were in $[-1, 1]$?</p>\n\n<p>Another side is vector $(x,y)$ too close to $(0,0)$. This may sometimes happen, and could indeed result in predicting wrong angles. But it may be seen as a benefit of your model - you can consider norm of $(x,y)$ as a measure of <em>confidence</em> of your model. Indeed, a norm close to 0 means that your model is not sure where the right direction is. </p>\n\n<p>Here is a small example in Python which shows that it is better to predict sin and cos, that to predict the angle directly:</p>\n\n<pre><code># predicting the angle (in radians)\nimport numpy as np\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import r2_score\n# generate toy data\nnp.random.seed(1)\nX = np.random.normal(size=(100, 2))\ny = np.arctan2(np.dot(X, [1,2]), np.dot(X, [3,0.4]))\n# simple prediction\nmodel = MLPRegressor(random_state=42, activation='tanh', max_iter=10000)\ny_simple_pred = cross_val_predict(model, X, y)\n# transformed prediction\njoint = cross_val_predict(model, X, np.column_stack([np.sin(y), np.cos(y)]))\ny_trig_pred = np.arctan2(joint[:,0], joint[:,1])\n# compare\ndef align(y_true, y_pred):\n    \"\"\" Add or remove 2*pi to predicted angle to minimize difference from GT\"\"\"\n    y_pred = y_pred.copy()\n    y_pred[y_true-y_pred &gt;  np.pi] += np.pi*2\n    y_pred[y_true-y_pred &lt; -np.pi] -= np.pi*2\n    return y_pred\nprint(r2_score(y, align(y, y_simple_pred))) # R^2 about 0.57\nprint(r2_score(y, align(y, y_trig_pred)))   # R^2 about 0.99\n</code></pre>\n\n<p>You can go on and plot the predictions, to see that predictions of the sine-cosine model are nearly correct, although may need some further calibration:</p>\n\n<pre><code>import matplotlib.pyplot as plt\nplt.figure(figsize=(12, 3))\nplt.subplot(1,4,1)\nplt.scatter(X[:,0], X[:,1], c=y)\nplt.title('Data (y=color)'); plt.xlabel('x1'); plt.ylabel('x2')\nplt.subplot(1,4,2)\nplt.scatter(y_simple_pred, y)\nplt.title('Direct model'); plt.xlabel('prediction'); plt.ylabel('actual')\nplt.subplot(1,4,3)\nplt.scatter(y_trig_pred, y)\nplt.title('Sine-cosine model'); plt.xlabel('prediction'); plt.ylabel('actual')\nplt.subplot(1,4,4)\nplt.scatter(joint[:,0], joint[:,1], s=5)\nplt.title('Predicted sin and cos'); plt.xlabel('cos'); plt.ylabel('sin')\nplt.tight_layout();\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/T7v4J.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/T7v4J.png\" alt=\"enter image description here\"></a></p>\n\n<p><strong>Update</strong>. A navigation engineer noticed that such a model would be most accurate when the angle is close to $\\frac{\\pi N}{2}$. Indeed, near 0\u00b0 and 180\u00b0 the angle $\\alpha$ is almost linear in $\\cos(\\alpha)$, and near 90\u00b0 and 270\u00b0 it is almost linear in $\\sin(\\alpha)$. Thus, it could be beneficial to add <em>two more</em> outputs, like $z=\\sin(\\alpha+\\frac{\\pi}{4})$ and $w=\\cos(\\alpha+\\frac{\\pi}{4})$, to make model almost-linear near 45\u00b0 and 135\u00b0 respectively. In this case, however, restoring the original angle is not so obvious. </p>\n\n<p>The best solution may be to extract coordinates $(x,y)$ from both representations (in the second one, we need to rotate $(z,w)$ to get $(x,y)$), average them, and only then calculate <code>arctan2</code>.</p>\n<p>Working with Cartesian coordinates works well as mentioned above. Yet, in my opinion, converting polar data to Cartesian creates dependencies between the X and Y coordinates that were not originally present in the data. For example, a robot's path decision model is more intuitive in polar coordinates than Cartesian. The dependency of the robot's velocity vector in polar coordinates between the angle and magnitude might not even exist or be different than the dependency in Cartesian coordinates.</p>\n\n<p>A workaround I've found to continue working with polar coordinates is to create a custom error function to calculate the angle difference using the angdiff() function in MATLAB and the magnitude difference as usual. </p>\n\n<p>This function returns '0' for the difference between -pi and pi. Here is a link to the functions support page on the Mathworks website.</p>\n\n<p><a href=\"https://www.mathworks.com/help/robotics/ref/angdiff.html\" rel=\"nofollow noreferrer\">https://www.mathworks.com/help/robotics/ref/angdiff.html</a></p>\n\n<p>If you are using Sigmoid activation and your angles data is normalized between [0,1] you should return it to the [-pi,pi] range before using the angdiff() function and then normalize the error back to the [0,1] range for the backpropagation process.</p>\n\n<p>In addition, the equivalent function in Python would be:</p>\n\n<pre><code>import numpy as np\n\n\ndef angdiff(a, b):\n    delta = np.arctan2(np.sin(b-a), np.cos(b-a))\n    delta = np.around(delta, 4)  # Since np.sin(pi) result is 1.22e-16\n    delta += 0.  # Since np.around return -0.\n    return delta\n\n\npi = np.pi\na = np.asarray([pi/2, 3*pi/4, 0])\nb = np.asarray([pi, pi/2, -pi])\n\nprint(angdiff(a, b))\nprint(angdiff(pi, -pi))\nprint(angdiff(-pi, pi))\n</code></pre>\n\n<p>This returns similar results as the MATLAB function and works with arrays as well:</p>\n\n<pre><code>[ 1.5708 -0.7854 -3.1416]\n0.0\n0.0\n</code></pre>\n\n<p>Hope that helps.</p>\n",
                "codes": [
                    [
                        "# predicting the angle (in radians)\nimport numpy as np\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import r2_score\n# generate toy data\nnp.random.seed(1)\nX = np.random.normal(size=(100, 2))\ny = np.arctan2(np.dot(X, [1,2]), np.dot(X, [3,0.4]))\n# simple prediction\nmodel = MLPRegressor(random_state=42, activation='tanh', max_iter=10000)\ny_simple_pred = cross_val_predict(model, X, y)\n# transformed prediction\njoint = cross_val_predict(model, X, np.column_stack([np.sin(y), np.cos(y)]))\ny_trig_pred = np.arctan2(joint[:,0], joint[:,1])\n# compare\ndef align(y_true, y_pred):\n    \"\"\" Add or remove 2*pi to predicted angle to minimize difference from GT\"\"\"\n    y_pred = y_pred.copy()\n    y_pred[y_true-y_pred >  np.pi] += np.pi*2\n    y_pred[y_true-y_pred < -np.pi] -= np.pi*2\n    return y_pred\nprint(r2_score(y, align(y, y_simple_pred))) # R^2 about 0.57\nprint(r2_score(y, align(y, y_trig_pred)))   # R^2 about 0.99\n",
                        "import matplotlib.pyplot as plt\nplt.figure(figsize=(12, 3))\nplt.subplot(1,4,1)\nplt.scatter(X[:,0], X[:,1], c=y)\nplt.title('Data (y=color)'); plt.xlabel('x1'); plt.ylabel('x2')\nplt.subplot(1,4,2)\nplt.scatter(y_simple_pred, y)\nplt.title('Direct model'); plt.xlabel('prediction'); plt.ylabel('actual')\nplt.subplot(1,4,3)\nplt.scatter(y_trig_pred, y)\nplt.title('Sine-cosine model'); plt.xlabel('prediction'); plt.ylabel('actual')\nplt.subplot(1,4,4)\nplt.scatter(joint[:,0], joint[:,1], s=5)\nplt.title('Predicted sin and cos'); plt.xlabel('cos'); plt.ylabel('sin')\nplt.tight_layout();\n"
                    ],
                    [
                        "import numpy as np\n\n\ndef angdiff(a, b):\n    delta = np.arctan2(np.sin(b-a), np.cos(b-a))\n    delta = np.around(delta, 4)  # Since np.sin(pi) result is 1.22e-16\n    delta += 0.  # Since np.around return -0.\n    return delta\n\n\npi = np.pi\na = np.asarray([pi/2, 3*pi/4, 0])\nb = np.asarray([pi, pi/2, -pi])\n\nprint(angdiff(a, b))\nprint(angdiff(pi, -pi))\nprint(angdiff(-pi, pi))\n",
                        "[ 1.5708 -0.7854 -3.1416]\n0.0\n0.0\n"
                    ]
                ],
                "question_id:": "24986",
                "question_votes:": "14",
                "question_text:": "<p>Let's say I have a top-down picture of an arrow, and I want to predict the angle this arrow makes. This would be between $0$ and $360$ degrees, or between $0$ and $2\\pi$. The problem is that this target is circular, $0$ and $360$ degrees are exactly the same which is an invariance I would like to incorporate in my target, which should help generalization significantly (this is my assumption). The problem is that I don't see a clean way of solving this, are there any papers that try to tackle this problem (or similar ones)? I do have some ideas with their potential downsides:</p>\n\n<ul>\n<li><p>Use a sigmoid or tanh activation, scale it to the ($0, 2\\pi)$ range and incorporate the circular property in the loss function. I think this will fail fairly hard, because if it's on the border (worst prediction) only a tiny bit of noise will push the weights to go one way or the other. Also, values closer to the border of $0$ and $2\\pi$ will be more difficult to reach because the absolute pre-activation value will need to be close to infinite.</p></li>\n<li><p>Regress to two values, a $x$ and $y$ value and calculate the loss based on the angle these two values make. I think this one has more potential but the norm of this vector is unbounded, which could lead to numeric instability and could lead to blow ups or going to 0 during training. This could potentially be solved by using some weird regularizer to prevent this norm from going too far away from 1.</p></li>\n</ul>\n\n<p>Other options would be doing something with sine and cosine functions but I feel like the fact that multiple pre-activations map to the same output will also make optimization and generalizations very difficult.</p>\n",
                "tags": "<neural-network><deep-learning><loss-function><parameter-estimation>",
                "answers": [
                    [
                        "25102",
                        "2",
                        "24986",
                        "",
                        "",
                        "<p>The second way, predicting $x=cos(\\alpha)$ and $y=sin(\\alpha)$ is totally okay. </p>\n\n<p>Yes, the norm of the predicted $(x, y)$ vector is not guaranteed to be near $1$. But it is not likely to blow up, especially if you use sigmoid activation functions (which are bounded by they nature) and/or regularize your model well. Why should your model predict a large value, if all the training samples were in $[-1, 1]$?</p>\n\n<p>Another side is vector $(x,y)$ too close to $(0,0)$. This may sometimes happen, and could indeed result in predicting wrong angles. But it may be seen as a benefit of your model - you can consider norm of $(x,y)$ as a measure of <em>confidence</em> of your model. Indeed, a norm close to 0 means that your model is not sure where the right direction is. </p>\n\n<p>Here is a small example in Python which shows that it is better to predict sin and cos, that to predict the angle directly:</p>\n\n<pre><code># predicting the angle (in radians)\nimport numpy as np\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import r2_score\n# generate toy data\nnp.random.seed(1)\nX = np.random.normal(size=(100, 2))\ny = np.arctan2(np.dot(X, [1,2]), np.dot(X, [3,0.4]))\n# simple prediction\nmodel = MLPRegressor(random_state=42, activation='tanh', max_iter=10000)\ny_simple_pred = cross_val_predict(model, X, y)\n# transformed prediction\njoint = cross_val_predict(model, X, np.column_stack([np.sin(y), np.cos(y)]))\ny_trig_pred = np.arctan2(joint[:,0], joint[:,1])\n# compare\ndef align(y_true, y_pred):\n    \"\"\" Add or remove 2*pi to predicted angle to minimize difference from GT\"\"\"\n    y_pred = y_pred.copy()\n    y_pred[y_true-y_pred &gt;  np.pi] += np.pi*2\n    y_pred[y_true-y_pred &lt; -np.pi] -= np.pi*2\n    return y_pred\nprint(r2_score(y, align(y, y_simple_pred))) # R^2 about 0.57\nprint(r2_score(y, align(y, y_trig_pred)))   # R^2 about 0.99\n</code></pre>\n\n<p>You can go on and plot the predictions, to see that predictions of the sine-cosine model are nearly correct, although may need some further calibration:</p>\n\n<pre><code>import matplotlib.pyplot as plt\nplt.figure(figsize=(12, 3))\nplt.subplot(1,4,1)\nplt.scatter(X[:,0], X[:,1], c=y)\nplt.title('Data (y=color)'); plt.xlabel('x1'); plt.ylabel('x2')\nplt.subplot(1,4,2)\nplt.scatter(y_simple_pred, y)\nplt.title('Direct model'); plt.xlabel('prediction'); plt.ylabel('actual')\nplt.subplot(1,4,3)\nplt.scatter(y_trig_pred, y)\nplt.title('Sine-cosine model'); plt.xlabel('prediction'); plt.ylabel('actual')\nplt.subplot(1,4,4)\nplt.scatter(joint[:,0], joint[:,1], s=5)\nplt.title('Predicted sin and cos'); plt.xlabel('cos'); plt.ylabel('sin')\nplt.tight_layout();\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/T7v4J.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/T7v4J.png\" alt=\"enter image description here\"></a></p>\n\n<p><strong>Update</strong>. A navigation engineer noticed that such a model would be most accurate when the angle is close to $\\frac{\\pi N}{2}$. Indeed, near 0\u00b0 and 180\u00b0 the angle $\\alpha$ is almost linear in $\\cos(\\alpha)$, and near 90\u00b0 and 270\u00b0 it is almost linear in $\\sin(\\alpha)$. Thus, it could be beneficial to add <em>two more</em> outputs, like $z=\\sin(\\alpha+\\frac{\\pi}{4})$ and $w=\\cos(\\alpha+\\frac{\\pi}{4})$, to make model almost-linear near 45\u00b0 and 135\u00b0 respectively. In this case, however, restoring the original angle is not so obvious. </p>\n\n<p>The best solution may be to extract coordinates $(x,y)$ from both representations (in the second one, we need to rotate $(z,w)$ to get $(x,y)$), average them, and only then calculate <code>arctan2</code>.</p>\n",
                        "",
                        "15"
                    ],
                    [
                        "51162",
                        "2",
                        "24986",
                        "",
                        "",
                        "<p>Working with Cartesian coordinates works well as mentioned above. Yet, in my opinion, converting polar data to Cartesian creates dependencies between the X and Y coordinates that were not originally present in the data. For example, a robot's path decision model is more intuitive in polar coordinates than Cartesian. The dependency of the robot's velocity vector in polar coordinates between the angle and magnitude might not even exist or be different than the dependency in Cartesian coordinates.</p>\n\n<p>A workaround I've found to continue working with polar coordinates is to create a custom error function to calculate the angle difference using the angdiff() function in MATLAB and the magnitude difference as usual. </p>\n\n<p>This function returns '0' for the difference between -pi and pi. Here is a link to the functions support page on the Mathworks website.</p>\n\n<p><a href=\"https://www.mathworks.com/help/robotics/ref/angdiff.html\" rel=\"nofollow noreferrer\">https://www.mathworks.com/help/robotics/ref/angdiff.html</a></p>\n\n<p>If you are using Sigmoid activation and your angles data is normalized between [0,1] you should return it to the [-pi,pi] range before using the angdiff() function and then normalize the error back to the [0,1] range for the backpropagation process.</p>\n\n<p>In addition, the equivalent function in Python would be:</p>\n\n<pre><code>import numpy as np\n\n\ndef angdiff(a, b):\n    delta = np.arctan2(np.sin(b-a), np.cos(b-a))\n    delta = np.around(delta, 4)  # Since np.sin(pi) result is 1.22e-16\n    delta += 0.  # Since np.around return -0.\n    return delta\n\n\npi = np.pi\na = np.asarray([pi/2, 3*pi/4, 0])\nb = np.asarray([pi, pi/2, -pi])\n\nprint(angdiff(a, b))\nprint(angdiff(pi, -pi))\nprint(angdiff(-pi, pi))\n</code></pre>\n\n<p>This returns similar results as the MATLAB function and works with arrays as well:</p>\n\n<pre><code>[ 1.5708 -0.7854 -3.1416]\n0.0\n0.0\n</code></pre>\n\n<p>Hope that helps.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10630",
            "_score": 9.282246,
            "_source": {
                "title": "Super basic logistic regression example",
                "content": "Super basic logistic regression example <p>I am new to ML and I created a super basic logistic regression example with 4 points on the $x$ line that belong to two classes:</p>\n\n<pre><code>points = [[1, 1]]\npoints = points + [[2, 0]] \npoints = points + [[1.5, 1]]\npoints = points + [[2.5, 0]]\n\ndata   = np.array([x[:-1] for x in points])\ntarget = [int(x[-1]) for x in points]\n\nalg = LogisticRegression()\nalg.fit(data, target)\nprint (alg.coef_)\nprint (alg.intercept_)\n\nprint (alg.predict_proba(1))\nprint (alg.predict_proba(1.5))\nprint (alg.predict_proba(2))\nprint (alg.predict_proba(2.5))\n</code></pre>\n\n<p>I expected the model to understand that anything greater than 1.5 belongs to class 0, and anything smaller than 2 belongs to class 0. However, everything is predicted to be in class 0. Also, in this case , what is the meaning for the coef and intercept? More precisely, is there a way to deduce from the coef and intercept where the model thinks the points switch from class 0 to class 1?</p>\n <python><logistic-regression><h1>What is the meaning for the coef and intercept</h1>\n\n<p>A (binary) logistic regression algorithm tries to determine whether the data $x$ belongs to class 0 or class 1 by the value\n$f(x)=\\omega x+b$. If the value $f(x)&gt;0$, the algorithm believe $x$ is more likely to be in class 1; while if $f(x)&lt;0$, then $x$ is more likely to be in class 0.</p>\n\n<p>In your code <code>alg.coef_</code> is the $\\omega$ above, and <code>alg.intercept_</code> is the $b$ above.</p>\n\n<h1>Why everything is predicted to be in class 0</h1>\n\n<p>If you run your code, you should see the result <code>alg.coef_=-0.354, alg.intercept_=0.307</code>. Therefore your <code>alg</code> is calculating $f(x)=-0.354x+0.307$. Now if you plug in your <code>data</code>, i.e. $x=$1, 2, 1.5 and 2.5 respectively, you should get the value $f(x)=$-0.047,-0.401,-0.224 and -0.579 respectively. </p>\n\n<p>As you see, all the four $f(x)$ values are smaller than 0, therefore your <code>alg</code> determines that they all belong be class 0.</p>\n\n<h1>But still why? Why the result is not what I expected?</h1>\n\n<p>Here is were <a href=\"https://en.wikipedia.org/wiki/Regularization_(mathematics)\" rel=\"nofollow noreferrer\">regularization</a> comes in. In the context of logistic regression, the learning algorithm <em>regularizes</em> that the learned parameter, $w$, should not be too large. To be specific, by default it regularizes the <a href=\"http://mathworld.wolfram.com/L2-Norm.html\" rel=\"nofollow noreferrer\">$l_2$ norm</a> norm of $w$. In your case $w$ is a scalar, then $l_2$ norm is its absolute value.</p>\n\n<p>In general, regularization is used to prevent <a href=\"https://en.wikipedia.org/wiki/Overfitting\" rel=\"nofollow noreferrer\">overfitting</a>. But that's another broad topic. </p>\n\n<p>If you want your algorithm to behave as you expected (classify 1 and 1.5 to class 1, and classify 2 and 2.5 to class 0) , there are 2 ways.</p>\n\n<ul>\n<li>You tell you program to use extremely <em>weak</em> regularization. \nThat can be achieved by passing a large value to the <code>C</code> parameter in <code>alg = LogisticRegression()</code> (default value is 1.0, see <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">detail</a>), e.g.</li>\n</ul>\n\n<pre>alg = LogisticRegression(C=1000)</pre>\n\n<p>In this case your algorithm should return <code>alg.coef_=-9.894, alg.intercept_=17.156</code>, and it can classify your four data points correctly. Notice that the absotely value of <code>alg.coef_</code> is now much larger than before.</p>\n\n<ul>\n<li><p>Provide your algorithm with more data.</p>\n\n<p>For example, simply repeat your four data points 100 times:</p></li>\n</ul>\n\n<p><code>data   = [x[:-1] for x in points]*100\ntarget = [int(x[-1]) for x in points]*100\n</code></p>\n\n<p>Then you can get <code>alg.coef_=-4.438, alg.intercept_=7.594</code> without setting <code>C</code>. In this case the same default regularization strength is still applied, but the additional data provide stronger evidence for your algorithm to believe that the <code>alg.coef_</code> should be allowed larger (in absolutely value).</p>\n",
                "codes": [
                    [
                        "data   = [x[:-1] for x in points]*100\ntarget = [int(x[-1]) for x in points]*100\n"
                    ]
                ],
                "question_id:": "38015",
                "question_votes:": "",
                "question_text:": "<p>I am new to ML and I created a super basic logistic regression example with 4 points on the $x$ line that belong to two classes:</p>\n\n<pre><code>points = [[1, 1]]\npoints = points + [[2, 0]] \npoints = points + [[1.5, 1]]\npoints = points + [[2.5, 0]]\n\ndata   = np.array([x[:-1] for x in points])\ntarget = [int(x[-1]) for x in points]\n\nalg = LogisticRegression()\nalg.fit(data, target)\nprint (alg.coef_)\nprint (alg.intercept_)\n\nprint (alg.predict_proba(1))\nprint (alg.predict_proba(1.5))\nprint (alg.predict_proba(2))\nprint (alg.predict_proba(2.5))\n</code></pre>\n\n<p>I expected the model to understand that anything greater than 1.5 belongs to class 0, and anything smaller than 2 belongs to class 0. However, everything is predicted to be in class 0. Also, in this case , what is the meaning for the coef and intercept? More precisely, is there a way to deduce from the coef and intercept where the model thinks the points switch from class 0 to class 1?</p>\n",
                "tags": "<python><logistic-regression>",
                "answers": [
                    [
                        "38017",
                        "2",
                        "38015",
                        "",
                        "",
                        "<h1>What is the meaning for the coef and intercept</h1>\n\n<p>A (binary) logistic regression algorithm tries to determine whether the data $x$ belongs to class 0 or class 1 by the value\n$f(x)=\\omega x+b$. If the value $f(x)&gt;0$, the algorithm believe $x$ is more likely to be in class 1; while if $f(x)&lt;0$, then $x$ is more likely to be in class 0.</p>\n\n<p>In your code <code>alg.coef_</code> is the $\\omega$ above, and <code>alg.intercept_</code> is the $b$ above.</p>\n\n<h1>Why everything is predicted to be in class 0</h1>\n\n<p>If you run your code, you should see the result <code>alg.coef_=-0.354, alg.intercept_=0.307</code>. Therefore your <code>alg</code> is calculating $f(x)=-0.354x+0.307$. Now if you plug in your <code>data</code>, i.e. $x=$1, 2, 1.5 and 2.5 respectively, you should get the value $f(x)=$-0.047,-0.401,-0.224 and -0.579 respectively. </p>\n\n<p>As you see, all the four $f(x)$ values are smaller than 0, therefore your <code>alg</code> determines that they all belong be class 0.</p>\n\n<h1>But still why? Why the result is not what I expected?</h1>\n\n<p>Here is were <a href=\"https://en.wikipedia.org/wiki/Regularization_(mathematics)\" rel=\"nofollow noreferrer\">regularization</a> comes in. In the context of logistic regression, the learning algorithm <em>regularizes</em> that the learned parameter, $w$, should not be too large. To be specific, by default it regularizes the <a href=\"http://mathworld.wolfram.com/L2-Norm.html\" rel=\"nofollow noreferrer\">$l_2$ norm</a> norm of $w$. In your case $w$ is a scalar, then $l_2$ norm is its absolute value.</p>\n\n<p>In general, regularization is used to prevent <a href=\"https://en.wikipedia.org/wiki/Overfitting\" rel=\"nofollow noreferrer\">overfitting</a>. But that's another broad topic. </p>\n\n<p>If you want your algorithm to behave as you expected (classify 1 and 1.5 to class 1, and classify 2 and 2.5 to class 0) , there are 2 ways.</p>\n\n<ul>\n<li>You tell you program to use extremely <em>weak</em> regularization. \nThat can be achieved by passing a large value to the <code>C</code> parameter in <code>alg = LogisticRegression()</code> (default value is 1.0, see <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">detail</a>), e.g.</li>\n</ul>\n\n<pre>alg = LogisticRegression(C=1000)</pre>\n\n<p>In this case your algorithm should return <code>alg.coef_=-9.894, alg.intercept_=17.156</code>, and it can classify your four data points correctly. Notice that the absotely value of <code>alg.coef_</code> is now much larger than before.</p>\n\n<ul>\n<li><p>Provide your algorithm with more data.</p>\n\n<p>For example, simply repeat your four data points 100 times:</p></li>\n</ul>\n\n<p><code>data   = [x[:-1] for x in points]*100\ntarget = [int(x[-1]) for x in points]*100\n</code></p>\n\n<p>Then you can get <code>alg.coef_=-4.438, alg.intercept_=7.594</code> without setting <code>C</code>. In this case the same default regularization strength is still applied, but the additional data provide stronger evidence for your algorithm to believe that the <code>alg.coef_</code> should be allowed larger (in absolutely value).</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3522",
            "_score": 9.221382,
            "_source": {
                "title": "Contrasting logistic regression vs decision tree performance in specific example",
                "content": "Contrasting logistic regression vs decision tree performance in specific example <p>I have a set of 10,000 integers, and another set of 100.\nThe integers in the first set are mapped to integers in the second set according to some rules (not mathematical rules, think of these values as codes for naming certain items, it is some categorical mapping).\nThe mapping is not necessarily 100 to 1, in some case I may have just 30 or so integers from the first set mapped to an integer in the second set, in other cases 300, but on average of course it is 100 to 1.\nUsing sklearn, I created a decision tree that was able to get over 99% accuracy, as I would expect.\nWhen I tried logistic regression, though, accuracy was just 45%. The training sample is about 100,000 example, so, it should be enough to learn.\nWhat is going on?\nIs there something inherently different in the logistic regression method that I am missing?</p>\n <python><scikit-learn><logistic-regression><decision-trees><p>A few assumptions I'm making:</p>\n\n<ol>\n<li><p>I believe you're mapping your input set of integers to another integer, which means your output is discrete, so I think you're using [multinomial logistic regression] (<a href=\"https://en.wikipedia.org/wiki/Multinomial_logistic_regression\" rel=\"nofollow noreferrer\">https://en.wikipedia.org/wiki/Multinomial_logistic_regression</a>).</p></li>\n<li><p>You're treating your discrete inputs (integers) as continuous--i.e., you're not using a one-hot-encoding for each integer. </p></li>\n<li><p>Your underlying function is something to the like of if $\\forall j=2,..,10$ if $x \\in (x_{j-1}, x_j)$ then $y = c_j$, correct?</p></li>\n</ol>\n\n<p>If the above three are true, then it's clear why Logistic won't work and why the Decision Tree will. The Logistic will approximate the relationship between your input and output with a $continuous$ linear relationship, which is not exactly what you have here because you have a discontinuity. It's worth mentioning that Decision Trees will perform better at these points, which means the more discontinuities you have the worse your performance will be.</p>\n\n<p>But after a quick simulation, the magnitudes you quoted are too large to be coming from this. So I'm guessing you're using $binary$ logistic regression, which is just the wrong choice of model (since it's mapping everything to a single class instead of many classes). </p>\n\n<p><strong>So, it sounds like you're just using the wrong model.</strong></p>\n\n<p>Below is a quick demo in R.</p>\n\n<pre><code># Loading packages\nrequire(nnet)\nrequire(rpart)\nset.seed(024)\nbuildData &lt;- function(n){\n  x &lt;- 1:n\n  x_j &lt;- data.frame(vals=quantile(1:n, probs=1:10/10))$vals\n  c_j &lt;- 1:10\n  y &lt;- rep(0, n)\n  for(i in 1:length(c_j)){\n    if(i==1){\n      y &lt;- ifelse(x &lt;= x_j[i], c_j[i], y)\n    } else {\n      y &lt;- ifelse( x &gt;= x_j[i-1] &amp; x &lt;= x_j[i], c_j[i], y)    \n    }\n  }\n  print(table(y))\n  xdf &lt;- data.frame(x, y=factor(y))\n  return( xdf)\n}\n# Building the data\nn &lt;- 1e4\nxdf &lt;- buildData(n)\n# Random 90-10 split\ntrnflt &lt;- runif(n) &lt;= 0.5\n\n# Multinomial Logistic Model\nmultinommod &lt;- multinom(y~x, data=xdf)\nxdf$preds_mult &lt;- predict(multinommod, xdf, type='class')\n\n# Binary Logistic Model\nlogisticmod &lt;- glm(y~x, data=xdf, family='binomial')\nxdf$preds_log &lt;- ifelse(predict(logisticmod, xdf, type='response') &lt;= 0.5, 0, 1)\n\n# Decision Tree Model\ntreemod &lt;- rpart(y~x, data=xdf[trnflt,], method='class')\nxdf$preds_tree &lt;- predict(treemod, xdf, type='class')\n\n# Multinomial Logistic confusion Matrix\nprint(with(xdf[trnflt,], table(y, preds_mult )))\nprint(with(xdf[trnflt==F,], table(y, preds_mult )))\n\n# Binary Logistic confusion Matrix\nprint(with(xdf[trnflt,], table(y, preds_log )))\nprint(with(xdf[trnflt==F,], table(y, preds_log )))\n\n# Decision Tree confusion Matrix\nprint(with(xdf[trnflt,], table(y, preds_tree)))\nprint(with(xdf[trnflt==F,], table(y, preds_tree)))\n\n# Here's the performance of all 3\nprint(c(paste('Multinomial Logistic Regression Accuraccy =', sum(diag(with(xdf[trnflt==F,], table(y, preds_mult )))) / sum(trnflt==F)),\n        paste('Logistic Regression Accuraccy =', sum(diag(with(xdf[trnflt==F,], table(y, preds_log )))) / sum(trnflt==F)), \n        paste('Decision Tree Accuraccy =', sum(diag(with(xdf[trnflt==F,], table(y, preds_tree )))) / sum(trnflt==F))))\n</code></pre>\n<p>A decision tree is designed to make many branches leading to any number of categorical outcomes.  Logistic regression in it's simplest form, however, takes a continuous variable and decides where to apply a threshold in order to model a binary response.  In your case, a decision tree makes sense because you are working with data that has no overall mathematical model, if I understand you correctly.  Logistic regression is going to struggle with deciding between 100 classes with no underlying pattern.</p>\n\n<p>I would suggest reviewing the math behind logistic regression in depth in order to understand the limitations.</p>\n",
                "codes": [
                    [
                        "# Loading packages\nrequire(nnet)\nrequire(rpart)\nset.seed(024)\nbuildData <- function(n){\n  x <- 1:n\n  x_j <- data.frame(vals=quantile(1:n, probs=1:10/10))$vals\n  c_j <- 1:10\n  y <- rep(0, n)\n  for(i in 1:length(c_j)){\n    if(i==1){\n      y <- ifelse(x <= x_j[i], c_j[i], y)\n    } else {\n      y <- ifelse( x >= x_j[i-1] & x <= x_j[i], c_j[i], y)    \n    }\n  }\n  print(table(y))\n  xdf <- data.frame(x, y=factor(y))\n  return( xdf)\n}\n# Building the data\nn <- 1e4\nxdf <- buildData(n)\n# Random 90-10 split\ntrnflt <- runif(n) <= 0.5\n\n# Multinomial Logistic Model\nmultinommod <- multinom(y~x, data=xdf)\nxdf$preds_mult <- predict(multinommod, xdf, type='class')\n\n# Binary Logistic Model\nlogisticmod <- glm(y~x, data=xdf, family='binomial')\nxdf$preds_log <- ifelse(predict(logisticmod, xdf, type='response') <= 0.5, 0, 1)\n\n# Decision Tree Model\ntreemod <- rpart(y~x, data=xdf[trnflt,], method='class')\nxdf$preds_tree <- predict(treemod, xdf, type='class')\n\n# Multinomial Logistic confusion Matrix\nprint(with(xdf[trnflt,], table(y, preds_mult )))\nprint(with(xdf[trnflt==F,], table(y, preds_mult )))\n\n# Binary Logistic confusion Matrix\nprint(with(xdf[trnflt,], table(y, preds_log )))\nprint(with(xdf[trnflt==F,], table(y, preds_log )))\n\n# Decision Tree confusion Matrix\nprint(with(xdf[trnflt,], table(y, preds_tree)))\nprint(with(xdf[trnflt==F,], table(y, preds_tree)))\n\n# Here's the performance of all 3\nprint(c(paste('Multinomial Logistic Regression Accuraccy =', sum(diag(with(xdf[trnflt==F,], table(y, preds_mult )))) / sum(trnflt==F)),\n        paste('Logistic Regression Accuraccy =', sum(diag(with(xdf[trnflt==F,], table(y, preds_log )))) / sum(trnflt==F)), \n        paste('Decision Tree Accuraccy =', sum(diag(with(xdf[trnflt==F,], table(y, preds_tree )))) / sum(trnflt==F))))\n"
                    ],
                    []
                ],
                "question_id:": "14874",
                "question_votes:": "",
                "question_text:": "<p>I have a set of 10,000 integers, and another set of 100.\nThe integers in the first set are mapped to integers in the second set according to some rules (not mathematical rules, think of these values as codes for naming certain items, it is some categorical mapping).\nThe mapping is not necessarily 100 to 1, in some case I may have just 30 or so integers from the first set mapped to an integer in the second set, in other cases 300, but on average of course it is 100 to 1.\nUsing sklearn, I created a decision tree that was able to get over 99% accuracy, as I would expect.\nWhen I tried logistic regression, though, accuracy was just 45%. The training sample is about 100,000 example, so, it should be enough to learn.\nWhat is going on?\nIs there something inherently different in the logistic regression method that I am missing?</p>\n",
                "tags": "<python><scikit-learn><logistic-regression><decision-trees>",
                "answers": [
                    [
                        "14923",
                        "2",
                        "14874",
                        "",
                        "",
                        "<p>A few assumptions I'm making:</p>\n\n<ol>\n<li><p>I believe you're mapping your input set of integers to another integer, which means your output is discrete, so I think you're using [multinomial logistic regression] (<a href=\"https://en.wikipedia.org/wiki/Multinomial_logistic_regression\" rel=\"nofollow noreferrer\">https://en.wikipedia.org/wiki/Multinomial_logistic_regression</a>).</p></li>\n<li><p>You're treating your discrete inputs (integers) as continuous--i.e., you're not using a one-hot-encoding for each integer. </p></li>\n<li><p>Your underlying function is something to the like of if $\\forall j=2,..,10$ if $x \\in (x_{j-1}, x_j)$ then $y = c_j$, correct?</p></li>\n</ol>\n\n<p>If the above three are true, then it's clear why Logistic won't work and why the Decision Tree will. The Logistic will approximate the relationship between your input and output with a $continuous$ linear relationship, which is not exactly what you have here because you have a discontinuity. It's worth mentioning that Decision Trees will perform better at these points, which means the more discontinuities you have the worse your performance will be.</p>\n\n<p>But after a quick simulation, the magnitudes you quoted are too large to be coming from this. So I'm guessing you're using $binary$ logistic regression, which is just the wrong choice of model (since it's mapping everything to a single class instead of many classes). </p>\n\n<p><strong>So, it sounds like you're just using the wrong model.</strong></p>\n\n<p>Below is a quick demo in R.</p>\n\n<pre><code># Loading packages\nrequire(nnet)\nrequire(rpart)\nset.seed(024)\nbuildData &lt;- function(n){\n  x &lt;- 1:n\n  x_j &lt;- data.frame(vals=quantile(1:n, probs=1:10/10))$vals\n  c_j &lt;- 1:10\n  y &lt;- rep(0, n)\n  for(i in 1:length(c_j)){\n    if(i==1){\n      y &lt;- ifelse(x &lt;= x_j[i], c_j[i], y)\n    } else {\n      y &lt;- ifelse( x &gt;= x_j[i-1] &amp; x &lt;= x_j[i], c_j[i], y)    \n    }\n  }\n  print(table(y))\n  xdf &lt;- data.frame(x, y=factor(y))\n  return( xdf)\n}\n# Building the data\nn &lt;- 1e4\nxdf &lt;- buildData(n)\n# Random 90-10 split\ntrnflt &lt;- runif(n) &lt;= 0.5\n\n# Multinomial Logistic Model\nmultinommod &lt;- multinom(y~x, data=xdf)\nxdf$preds_mult &lt;- predict(multinommod, xdf, type='class')\n\n# Binary Logistic Model\nlogisticmod &lt;- glm(y~x, data=xdf, family='binomial')\nxdf$preds_log &lt;- ifelse(predict(logisticmod, xdf, type='response') &lt;= 0.5, 0, 1)\n\n# Decision Tree Model\ntreemod &lt;- rpart(y~x, data=xdf[trnflt,], method='class')\nxdf$preds_tree &lt;- predict(treemod, xdf, type='class')\n\n# Multinomial Logistic confusion Matrix\nprint(with(xdf[trnflt,], table(y, preds_mult )))\nprint(with(xdf[trnflt==F,], table(y, preds_mult )))\n\n# Binary Logistic confusion Matrix\nprint(with(xdf[trnflt,], table(y, preds_log )))\nprint(with(xdf[trnflt==F,], table(y, preds_log )))\n\n# Decision Tree confusion Matrix\nprint(with(xdf[trnflt,], table(y, preds_tree)))\nprint(with(xdf[trnflt==F,], table(y, preds_tree)))\n\n# Here's the performance of all 3\nprint(c(paste('Multinomial Logistic Regression Accuraccy =', sum(diag(with(xdf[trnflt==F,], table(y, preds_mult )))) / sum(trnflt==F)),\n        paste('Logistic Regression Accuraccy =', sum(diag(with(xdf[trnflt==F,], table(y, preds_log )))) / sum(trnflt==F)), \n        paste('Decision Tree Accuraccy =', sum(diag(with(xdf[trnflt==F,], table(y, preds_tree )))) / sum(trnflt==F))))\n</code></pre>\n",
                        "",
                        "1"
                    ],
                    [
                        "14906",
                        "2",
                        "14874",
                        "",
                        "",
                        "<p>A decision tree is designed to make many branches leading to any number of categorical outcomes.  Logistic regression in it's simplest form, however, takes a continuous variable and decides where to apply a threshold in order to model a binary response.  In your case, a decision tree makes sense because you are working with data that has no overall mathematical model, if I understand you correctly.  Logistic regression is going to struggle with deciding between 100 classes with no underlying pattern.</p>\n\n<p>I would suggest reviewing the math behind logistic regression in depth in order to understand the limitations.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4355",
            "_score": 9.189019,
            "_source": {
                "title": "Confusing Offset in my Support Vector Regression and other Models",
                "content": "Confusing Offset in my Support Vector Regression and other Models <p>I am experiencing a weird offset in my Support Vector Regression prediction (code below).  </p>\n\n<p>A brief overview: I have a set of 10 .xls sheets as input data (each with 30 rows and 27 columns), and a 11th .xls sheet that I am using as my testing dataset.  </p>\n\n<p>I am working with an electricity dataset, and I am trying to predict the 11th month of electricity usage using the SVR.  I am using the code written and released by Luke Benning on Github: <a href=\"https://github.com/lbenning/Load-Forecasting\" rel=\"nofollow noreferrer\">https://github.com/lbenning/Load-Forecasting</a></p>\n\n<p>All of my datasets are structured the same, but when I run the prediction model, I am receiving an offset (as shown in the photo below).  The actual data versus the predicted data seem to follow a similar pattern, but the two plots are offset.</p>\n\n<p>Does anyone know of what I may want to explore in order to try and understand the source of this offset?</p>\n\n<p><a href=\"https://github.com/lbenning/Load-Forecasting\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/eBYCh.jpg\" alt=\"enter image description here\"></a></p>\n\n<pre><code>#! /usr/bin/python\n\nimport math\nimport statistics\nimport visualizer\nimport numpy as np\nfrom datagen import constructData\nfrom sklearn import svm\n\n# Applies Support Vector Regression to the electricity dataset,\n# prints out the accuracy rate to the terminal and plots\n# predictions against actual values\ndef suppVectorRegress():\n\n    kernelList = [\"linear\",\"rbf\",polyKernel]\n    names = [\"linear\",\"radial basis\",\"poly\"]\n    preds = []\n\n    # Retrieve time series data &amp; apply preprocessing\n    data = constructData()\n\n    cutoff = len(data)-30\n    xTrain = data[0][0:cutoff]\n    yTrain = data[1][0:cutoff]\n    xTest = data[0][cutoff:]\n    yTest = data[1][cutoff:]\n\n    # Fill in missing values denoted by zeroes as an average of\n    # both neighbors\n    statistics.estimateMissing(xTrain,0.0)\n    statistics.estimateMissing(xTest,0.0)\n\n    # Logarithmically scale the data\n    xTrain = [[math.log(y) for y in x] for x in xTrain]\n    xTest = [[math.log(y) for y in x] for x in xTest]\n    yTrain = [math.log(x) for x in yTrain]\n\n    # Detrend the time series\n    indices = np.arange(len(data[1]))\n    trainIndices = indices[0:cutoff]\n    testIndices = indices[cutoff:]\n    detrended,slope,intercept = statistics.detrend(trainIndices,yTrain)\n    yTrain = detrended\n\n    for gen in range(len(kernelList)):\n\n        # Use SVR to predict test observations based upon training observations\n        pred = svrPredictions(xTrain,yTrain,xTest,kernelList[gen])\n        # Add the trend back into the predictions\n        trendedPred = statistics.reapplyTrend(testIndices,pred,slope,intercept)\n        # Reverse the normalization\n        trendedPred = [math.exp(x) for x in trendedPred]\n        # Compute the NRMSE\n        err = statistics.normRmse(yTest,trendedPred)\n\n        print (\"The Normalized Root-Mean Square Error is \" + str(err) + \" using kernel \" + names[gen] + \"...\")\n\n        preds.append(trendedPred)\n\n    names.append(\"actual\")\n    preds.append(yTest)\n\n    # Change the parameters 2017,2,1 based on the month you want to predict.\n    visualizer.comparisonPlot(2017,2,1,preds,names,plotName=\"Support Vector Regression Load Predictions vs. Actual\", \n        yAxisName=\"Predicted Kilowatts\")\n\n# Construct a support vector machine and get predictions\n# for the test set\n# Returns a 1-d vector of predictions\ndef svrPredictions(xTrain,yTrain,xTest,k):\n    clf = svm.SVR(C=2.0,kernel=k)\n    clf.fit(xTrain,yTrain)\n    return clf.predict(xTest)\n\n# A scale invariant kernel (note only conditionally semi-definite)\ndef polyKernel(x,y):\n    return (np.dot(x,y.T)+1.0)**0.95\n\nif __name__==\"__main__\":\n    suppVectorRegress()\n</code></pre>\n\n<p>I am generating the data as follows:</p>\n\n<pre><code>'''\nFunctions for retrieving Elia dataset \n&amp; forming training/testing datasets\n'''\n\n# constructs dataset for simulations\n# the last dataset in this file list, is the one used as the training set.\ndef constructData():\n  files = [\"data/jan_16_elec_scaled.xls\", \"data/feb_16_elec_scaled.xls\", \n           \"data/mar_16_elec_scaled.xls\", \"data/apr_16_elec_scaled.xls\",\n           \"data/may_16_elec_scaled.xls\",\"data/jun_16_elec_scaled.xls\",\n           \"data/jul_16_elec_scaled.xls\", \"data/aug_16_elec_scaled.xls\",\n           \"data/sep_16_elec_scaled.xls\", \"data/oct_16_elec_scaled.xls\",\n           \"data/nov_16_elec_scaled.xls\"]\n\n#  files = [\"data/jan_16_elec_NOscaled.xls\", \"data/feb_16_elec_NOscaled.xls\", \n#           \"data/mar_16_elec_NOscaled.xls\", \"data/apr_16_elec_NOscaled.xls\",\n#           \"data/may_16_elec_NOscaled.xls\",\"data/jun_16_elec_NOscaled.xls\",\n#           \"data/jul_16_elec_NOscaled.xls\", \"data/aug_16_elec_NOscaled.xls\",\n#           \"data/sep_16_elec_NOscaled.xls\", \"data/oct_16_elec_NOscaled.xls\",\n#           \"data/nov_16_elec_NOscaled.xls\"]         \n  return labelSeries(loadSeries(files))\n\n# constructs labelled data from a\n# univariate time series\nsdef labelSeries(series):\n  xData = []\n  yData = []\n  for x in range(len(series)-1):\n    xData.append(series[x]) # xData contains all of the items up until the last item\n    yData.append(np.mean(series[x+1])) # yData is the last item in the list\n  return (xData,yData)\n\n# arg1 : list of excel spreadsheets filenames\n# returns : load univariate time series\ndef loadSeries(fileList):\n  # Retrieve time series examples\n  xData = []\n  for fileName in fileList:\n    book = xlrd.open_workbook(fileName)\n    sheet = book.sheet_by_index(0)\n    for rx in range(2,sheet.nrows):\n      row = sheet.row(rx)[3:]\n      row = [row[x].value for x in range(0,len(row)-4)]\n      xData.append(row)\n  return xData\n</code></pre>\n <regression><svm><prediction><p>See this <a href=\"http://www.alivelearn.net/?p=1666\" rel=\"nofollow noreferrer\">answer</a> by Xu Cui. The reason, as he stated is simple: the model itself is very simple SVM. He suggests lagging 2 points behind to \"improve\" and get a more powerful model. Let me know what you think of it. We might be overthinking and he might be on point.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "17431",
                "question_votes:": "2",
                "question_text:": "<p>I am experiencing a weird offset in my Support Vector Regression prediction (code below).  </p>\n\n<p>A brief overview: I have a set of 10 .xls sheets as input data (each with 30 rows and 27 columns), and a 11th .xls sheet that I am using as my testing dataset.  </p>\n\n<p>I am working with an electricity dataset, and I am trying to predict the 11th month of electricity usage using the SVR.  I am using the code written and released by Luke Benning on Github: <a href=\"https://github.com/lbenning/Load-Forecasting\" rel=\"nofollow noreferrer\">https://github.com/lbenning/Load-Forecasting</a></p>\n\n<p>All of my datasets are structured the same, but when I run the prediction model, I am receiving an offset (as shown in the photo below).  The actual data versus the predicted data seem to follow a similar pattern, but the two plots are offset.</p>\n\n<p>Does anyone know of what I may want to explore in order to try and understand the source of this offset?</p>\n\n<p><a href=\"https://github.com/lbenning/Load-Forecasting\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/eBYCh.jpg\" alt=\"enter image description here\"></a></p>\n\n<pre><code>#! /usr/bin/python\n\nimport math\nimport statistics\nimport visualizer\nimport numpy as np\nfrom datagen import constructData\nfrom sklearn import svm\n\n# Applies Support Vector Regression to the electricity dataset,\n# prints out the accuracy rate to the terminal and plots\n# predictions against actual values\ndef suppVectorRegress():\n\n    kernelList = [\"linear\",\"rbf\",polyKernel]\n    names = [\"linear\",\"radial basis\",\"poly\"]\n    preds = []\n\n    # Retrieve time series data &amp; apply preprocessing\n    data = constructData()\n\n    cutoff = len(data)-30\n    xTrain = data[0][0:cutoff]\n    yTrain = data[1][0:cutoff]\n    xTest = data[0][cutoff:]\n    yTest = data[1][cutoff:]\n\n    # Fill in missing values denoted by zeroes as an average of\n    # both neighbors\n    statistics.estimateMissing(xTrain,0.0)\n    statistics.estimateMissing(xTest,0.0)\n\n    # Logarithmically scale the data\n    xTrain = [[math.log(y) for y in x] for x in xTrain]\n    xTest = [[math.log(y) for y in x] for x in xTest]\n    yTrain = [math.log(x) for x in yTrain]\n\n    # Detrend the time series\n    indices = np.arange(len(data[1]))\n    trainIndices = indices[0:cutoff]\n    testIndices = indices[cutoff:]\n    detrended,slope,intercept = statistics.detrend(trainIndices,yTrain)\n    yTrain = detrended\n\n    for gen in range(len(kernelList)):\n\n        # Use SVR to predict test observations based upon training observations\n        pred = svrPredictions(xTrain,yTrain,xTest,kernelList[gen])\n        # Add the trend back into the predictions\n        trendedPred = statistics.reapplyTrend(testIndices,pred,slope,intercept)\n        # Reverse the normalization\n        trendedPred = [math.exp(x) for x in trendedPred]\n        # Compute the NRMSE\n        err = statistics.normRmse(yTest,trendedPred)\n\n        print (\"The Normalized Root-Mean Square Error is \" + str(err) + \" using kernel \" + names[gen] + \"...\")\n\n        preds.append(trendedPred)\n\n    names.append(\"actual\")\n    preds.append(yTest)\n\n    # Change the parameters 2017,2,1 based on the month you want to predict.\n    visualizer.comparisonPlot(2017,2,1,preds,names,plotName=\"Support Vector Regression Load Predictions vs. Actual\", \n        yAxisName=\"Predicted Kilowatts\")\n\n# Construct a support vector machine and get predictions\n# for the test set\n# Returns a 1-d vector of predictions\ndef svrPredictions(xTrain,yTrain,xTest,k):\n    clf = svm.SVR(C=2.0,kernel=k)\n    clf.fit(xTrain,yTrain)\n    return clf.predict(xTest)\n\n# A scale invariant kernel (note only conditionally semi-definite)\ndef polyKernel(x,y):\n    return (np.dot(x,y.T)+1.0)**0.95\n\nif __name__==\"__main__\":\n    suppVectorRegress()\n</code></pre>\n\n<p>I am generating the data as follows:</p>\n\n<pre><code>'''\nFunctions for retrieving Elia dataset \n&amp; forming training/testing datasets\n'''\n\n# constructs dataset for simulations\n# the last dataset in this file list, is the one used as the training set.\ndef constructData():\n  files = [\"data/jan_16_elec_scaled.xls\", \"data/feb_16_elec_scaled.xls\", \n           \"data/mar_16_elec_scaled.xls\", \"data/apr_16_elec_scaled.xls\",\n           \"data/may_16_elec_scaled.xls\",\"data/jun_16_elec_scaled.xls\",\n           \"data/jul_16_elec_scaled.xls\", \"data/aug_16_elec_scaled.xls\",\n           \"data/sep_16_elec_scaled.xls\", \"data/oct_16_elec_scaled.xls\",\n           \"data/nov_16_elec_scaled.xls\"]\n\n#  files = [\"data/jan_16_elec_NOscaled.xls\", \"data/feb_16_elec_NOscaled.xls\", \n#           \"data/mar_16_elec_NOscaled.xls\", \"data/apr_16_elec_NOscaled.xls\",\n#           \"data/may_16_elec_NOscaled.xls\",\"data/jun_16_elec_NOscaled.xls\",\n#           \"data/jul_16_elec_NOscaled.xls\", \"data/aug_16_elec_NOscaled.xls\",\n#           \"data/sep_16_elec_NOscaled.xls\", \"data/oct_16_elec_NOscaled.xls\",\n#           \"data/nov_16_elec_NOscaled.xls\"]         \n  return labelSeries(loadSeries(files))\n\n# constructs labelled data from a\n# univariate time series\nsdef labelSeries(series):\n  xData = []\n  yData = []\n  for x in range(len(series)-1):\n    xData.append(series[x]) # xData contains all of the items up until the last item\n    yData.append(np.mean(series[x+1])) # yData is the last item in the list\n  return (xData,yData)\n\n# arg1 : list of excel spreadsheets filenames\n# returns : load univariate time series\ndef loadSeries(fileList):\n  # Retrieve time series examples\n  xData = []\n  for fileName in fileList:\n    book = xlrd.open_workbook(fileName)\n    sheet = book.sheet_by_index(0)\n    for rx in range(2,sheet.nrows):\n      row = sheet.row(rx)[3:]\n      row = [row[x].value for x in range(0,len(row)-4)]\n      xData.append(row)\n  return xData\n</code></pre>\n",
                "tags": "<regression><svm><prediction>",
                "answers": [
                    [
                        "17595",
                        "2",
                        "17431",
                        "",
                        "",
                        "<p>See this <a href=\"http://www.alivelearn.net/?p=1666\" rel=\"nofollow noreferrer\">answer</a> by Xu Cui. The reason, as he stated is simple: the model itself is very simple SVM. He suggests lagging 2 points behind to \"improve\" and get a more powerful model. Let me know what you think of it. We might be overthinking and he might be on point.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "78",
            "_score": 9.164463,
            "_source": {
                "title": "Python vs R for machine learning",
                "content": "Python vs R for machine learning <p>I'm just starting to develop a <a href=\"https://en.wikipedia.org/wiki/Machine_learning\" rel=\"nofollow noreferrer\">machine learning</a> application for academic purposes. I'm currently using <strong>R</strong> and training myself in it. However, in a lot of places, I have seen people using <strong>Python</strong>.</p>\n\n<p>What are people using in academia and industry, and what is the recommendation?</p>\n <machine-learning><r><python><p>Some additional thoughts.</p>\n\n<p>The programming language 'per se' is only a tool. All languages were designed to make some type of constructs more easy to build than others. And the knowledge and mastery of a programming language is more important and effective than the features of that language compared to others.   </p>\n\n<p>As far as I can see there are two dimensions of this question. The first dimension is the ability to explore, build proof of concepts or models at a fast pace, eventually having at hand enough tools to study what is going on (like statistical tests, graphics, measurement tools, etc). This kind of activity is usually preferred by researchers and data scientists (I always wonder what that means, but I use this term for its loose definition). They tend to rely on well-known and verified instruments, which can be used for proofs or arguments.</p>\n\n<p>The second dimension is the ability to extend, change, improve or even create tools, algorithms or models. In order to achieve that you need a proper programming language. Roughly all of them are the same. If you work for a company, than you depend a lot on the company's infrastructure, internal culture and your choices diminish significantly. Also, when you want to implement an algorithm for production use, you have to trust the implementation. And implementing in another language which you do not master will not help you much.</p>\n\n<p>I tend to favor for the first type of activity the R ecosystem. You have a great community, a huge set of tools, proofs that these tools works as expected. Also, you can consider Python, Octave (to name a few), which are reliable candidates.</p>\n\n<p>For the second task, you have to think before at what you really want. If you want robust production ready tools, then C/C++, Java, C# are great candidates. I consider Python as a second citizen in this category, together with Scala and friends. I do not want to start a flame war, it's my opinion only. But after more than 17 years as a developer, I tend to prefer a strict contract and my knowledge, than the freedom to do whatever you might think of (like it happens with a lot of dynamic languages).</p>\n\n<p>Personally, I want to learn as much as possible. I decided that I have to choose the hard way, which means to implement everything from scratch myself. I use R as a model and inspiration. It has great treasures in libraries and a lot of experience distilled. However, R as a programming language is a nightmare for me. So I decided to use Java, and use no additional library. That is only because of my experience, and nothing else.</p>\n\n<p>If you have time, the best thing you can do is to spend some time with all these things. In this way you will earn for yourself the best answer possible, fitted for you. Dijkstra said once that the tools influence the way you think, so it is advisable to know your tools before letting them to model how you think. You can read more about that in his famous paper called <a href=\"http://www.cs.utexas.edu/~EWD/transcriptions/EWD03xx/EWD340.html\" rel=\"nofollow noreferrer\">The Humble Programmer</a></p>\n<p>I prefer Python over R because Python is a complete programming language so I can do end to end machine learning tasks such as gather data using a HTTP server written in Python, perform advanced ML tasks and then publish the results online. This can all be done in Python. I actually found R to be harder to learn and the payoffs for learning Python are much greater because it can be used for pretty much any programming task. </p>\n<p>In my experience, the answer depends on the project at hand. For pure research, I prefer R for two reasons: 1) broad variety of libraries and 2) much of the data science literature includes R samples.</p>\n\n<p>If the project requires an interactive interface to be used by laypersons, I've found R to be too constrained. Shiny is a great start, but it's not flexible enough yet. In these cases, I'll start to look at porting my R work over to Python or js.</p>\n<p>I would add to what others have said till now. There is no single answer that one language is better than other.</p>\n\n<p>Having said that, R has a better community for data exploration and learning. It has extensive visualization capabilities. Python, on the other hand, has become better at data handling since introduction of pandas. Learning and development time is very less in Python, as compared to R (R being a low level language).</p>\n\n<p>I think it ultimately boils down to the eco-system you are in and personal preferences. For more details, you can look at this comparison <a href=\"http://www.analyticsvidhya.com/blog/2014/03/sas-vs-vs-python-tool-learn/\">here</a>.</p>\n<p>There isn't a silver bullet language that can be used to solve each and every data related problem. The language choice depends on the context of the problem, size of data and if you are working at a workplace you have to stick to what they use.</p>\n\n<p>Personally I use R more often than Python due to its visualization libraries and interactive style. But if I need more performance or structured code I definitely use Python since it has some of the best libraries as SciKit-Learn, numpy, scipy etc. I use both R and Python in my projects interchangeably. </p>\n\n<p>So if you are starting on data science work I suggest you to learn both and it's not difficult since Python also provides a similar interface to R with <a href=\"http://pandas.pydata.org/\">Pandas</a>. </p>\n\n<p>If you have to deal with much larger datasets, you can't escape eco-systems built with Java(Hadoop, Pig, Hbase etc).</p>\n<p>An issue all other answers fail to address is <strong>licensing</strong>.</p>\n\n<p>Most of the aforementioned wonderful R libraries are GPL (e.g. <a href=\"https://cran.r-project.org/web/packages/ggplot2/index.html\" rel=\"noreferrer\">ggplot2</a>, <a href=\"https://cran.r-project.org/web/packages/data.table/index.html\" rel=\"noreferrer\">data.table</a>). This <a href=\"https://softwareengineering.stackexchange.com/questions/47032/can-i-use-gpl-software-in-a-commercial-application\">prevents you</a> from distributing your software in a proprietary form.</p>\n\n<p>Although many usages of those libraries do not imply distribution of the software (e.g. to train models offline), the GPL may by itself lure away companies from using them. At least in my experience.</p>\n\n<p>In the python realm, on the other hand, <em>most</em> libraries have business-friendly distribution licenses, such as BSD or MIT.</p>\n\n<p>In academia, licensing issues normally are non-issues.</p>\n<p>There is nothing like \"python is better\" or \"R is much better than x\". </p>\n\n<p>The only fact I know is that in the industry allots of people stick to python because that is what they learned at the university. The python community is really active and have a few great frameworks for ML and data mining etc. </p>\n\n<p>But to be honest, if you get a good c programmer he can do the same as people do in python or r, if you got a good java programmer he can also do (near to) everything in java. </p>\n\n<p>So just stick with the language you are comfortable with.</p>\n<p>I do not think Python has <a href=\"https://alternativeto.net/list/2063/guis-to-save-from-typing-r-code/\" rel=\"nofollow noreferrer\">point-click GUI</a> that turn it into SPSS and SAS. Playing around with those is genuinely fun. </p>\n<p><a href=\"https://i.stack.imgur.com/hc3tp.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/hc3tp.png\" alt=\"enter image description here\"></a></p>\n\n<p>I got this image in a linkedin post. Whenever I get a doubt of using python or R, I look into it and it proves to be very useful. </p>\n<p>Some real important differences to consider when you are choosing <strong>R</strong> or <strong>Python</strong> over one another:</p>\n\n<ul>\n<li><strong>Machine Learning</strong> has 2 phases. Model Building and Prediction phase. Typically, model building is performed as a batch process and <strong>predictions are done realtime</strong>. The model building process is a compute intensive process while the prediction happens in a jiffy. Therefore, performance of an algorithm in Python or R doesn't really affect the turn-around time of the user. Python 1, R 1.</li>\n<li><strong>Production:</strong> The real difference between Python and R comes in being production ready. Python, as such is a full fledged programming language and many organisations use it in their production systems. R is a statistical programming software favoured by many academia and due to the rise in data science and availability of libraries and being open source, the industry has started using R. Many of these organisations have their production systems either in Java, C++, C#, Python etc. So, ideally they would like to have the <strong>prediction system</strong> in the same language to reduce the latency and maintenance issues.\nPython 2, R 1.</li>\n<li><strong>Libraries:</strong> Both the languages have enormous and reliable libraries. R has over 5000 libraries catering to many domains while Python has some incredible packages like <strong>Pandas, NumPy, SciPy, Scikit Learn, Matplotlib</strong>. Python 3, R 2.</li>\n<li><strong>Development:</strong> Both the language are interpreted languages. Many say that python is easy to learn, it's almost like reading english (to put it on a lighter note) but R requires more initial studying effort. Also, both of them have good IDEs (Spyder etc for Python and RStudio for R). Python 4, R 2.</li>\n<li><strong>Speed:</strong> R software initially had problems with large computations (say, like nxn matrix multiplications). But, this issue is addressed with the introduction of R by Revolution Analytics. They have re-written computation intensive operations in C which is blazingly fast. Python being a high level language is relatively slow. Python 4, R 3.</li>\n<li><strong>Visualizations:</strong> In data science, we frequently tend to plot data to showcase patterns to users. Therefore, visualisations become an important criteria in choosing a software and R completely kills Python in this regard. Thanks to Hadley Wickham for an incredible ggplot2 package. R wins hands down. Python 4, R 4.</li>\n<li><strong>Dealing with Big Data:</strong> One of the constraints of R is it stores the data in system memory (RAM). So, RAM capacity becomes a constraint when you are handling Big Data. Python does well, but I would say, as both R and Python have HDFS connectors, leveraging Hadoop infrastructure would give substantial performance improvement. So, Python 5, R 5.</li>\n</ul>\n\n<p>So, both the languages are equally good. Therefore, depending upon your domain and the place you work, you have to smartly choose the right language. The technology world usually prefers using a single language. Business users (marketing analytics, retail analytics) usually go with statistical programming languages like R, since they frequently do quick prototyping and build visualisations (which is faster done in R than Python).</p>\n<p>There is no \"better\" language. I have tried both of them and I am comfortable with Python so I work with Python only. Though I am still learning stuff, but I haven't encounter any roadblock with Python till now. The good thing about Python is community is too good and you can get a lot of help on the Internet easily. Other than that, I would say go with the language you like not the one people recommend. </p>\n<p>One of real challenges, I faced with R is different packages compatible with different versions.. quite a lot R packages are not available for latest version of R.. And R quite a few time gives error  due to library or package was written for older version.. </p>\n<p>I haven't tried R (well, a bit, but not enough to make a good comparison). However, here are some of Pythons strengths:</p>\n\n<ul>\n<li><strong>Very intuitive syntax</strong>: tuple unpacking, <code>element in a_list</code>, <code>for element in sequence</code>, <code>matrix_a * matrix_b</code> (for matrix multiplication), ...</li>\n<li><strong>Many libraries</strong>:\n\n<ul>\n<li><a href=\"http://www.scipy.org/\" rel=\"nofollow noreferrer\">scipy</a>: Scientific computations; many parts of it are only wrappers for pretty fast Fortran code</li>\n<li><a href=\"http://deeplearning.net/software/theano/\" rel=\"nofollow noreferrer\">theano</a> > <a href=\"http://lasagne.readthedocs.org/en/latest/\" rel=\"nofollow noreferrer\">Lasagne</a> > <a href=\"https://github.com/dnouri/nolearn\" rel=\"nofollow noreferrer\">nolearn</a>: Libraries for neural networks - they can be trained on GPU (nvidia, CUDA is required) without any adjustment</li>\n<li><a href=\"http://scikit-learn.org/\" rel=\"nofollow noreferrer\">sklearn</a>: General learning algorithms</li>\n</ul></li>\n<li><strong>Good community</strong>:\n\n<ul>\n<li>Python has <a href=\"https://stackoverflow.com/questions/tagged/python\">448,000+ questions on SO</a> (R has 99,000+)</li>\n<li>Python has <a href=\"https://datascience.stackexchange.com/questions/tagged/python\">103 questions on datascience.SE</a> (R has 140)</li>\n<li><a href=\"https://www.python.org/dev/peps/\" rel=\"nofollow noreferrer\">PEPs</a>, 63,000+ packages on <a href=\"https://pypi.python.org/pypi\" rel=\"nofollow noreferrer\">PyPI</a></li>\n</ul></li>\n<li><a href=\"http://ipython.org/\" rel=\"nofollow noreferrer\">IPython notebooks</a></li>\n<li><strong>Misc</strong>:\n\n<ul>\n<li>0-indexed arrays ... I made that error all the time with R.</li>\n<li>Established package structures</li>\n<li>Good support for testing your code</li>\n</ul></li>\n</ul>\n<p>Not much to add to the provided comments. Only thing is maybe this infographic comparing R vs Python for data science purposes <a href=\"http://blog.datacamp.com/r-or-python-for-data-analysis/\" rel=\"noreferrer\">http://blog.datacamp.com/r-or-python-for-data-analysis/</a></p>\n<p>R: R is the Open source counterpart. which has traditionally been used in academics and research.\n Because of its open source nature, latest techniques get released quickly. \nThere is a lot of documentation available over the internet and it is a very cost-effective option.\nPython: With origination as an open source scripting language,\n Python usage has grown over time. Today, it sports libraries (numpy, scipy and matplotlib) and functions for almost any statistical operation / model building you may want to do. \nSince introduction of pandas, it has become very strong in operations on structured data.</p>\n\n<p>Python Code</p>\n\n<h1>Import Library</h1>\n\n<h1>Import other necessary libraries like pandas, numpy...</h1>\n\n<p>from sklearn import linear_model</p>\n\n<h1>Load Train and Test datasets</h1>\n\n<h1>Identify feature and response variable(s) and values must be numeric and numpy arrays</h1>\n\n<p>x_train=input_variables_values_training_datasets\ny_train=target_variables_values_training_datasets\nx_test=input_variables_values_test_datasets</p>\n\n<h1>Create linear regression object</h1>\n\n<p>linear = linear_model.LinearRegression()</p>\n\n<h1>Train the model using the training sets and check score</h1>\n\n<p>linear.fit(x_train, y_train)\nlinear.score(x_train, y_train)</p>\n\n<h1>Equation coefficient and Intercept</h1>\n\n<p>print('Coefficient: \\n', linear.coef_)\nprint('Intercept: \\n', linear.intercept_)</p>\n\n<h1>Predict Output</h1>\n\n<p>predicted= linear.predict(x_test)\nR Code</p>\n\n<h1>Load Train and Test datasets</h1>\n\n<h1>Identify feature and response variable(s) and values must be numeric and numpy arrays</h1>\n\n<p>x_train &lt;- input_variables_values_training_datasets\ny_train &lt;- target_variables_values_training_datasets\nx_test &lt;- input_variables_values_test_datasets\nx &lt;- cbind(x_train,y_train)</p>\n\n<h1>Train the model using the training sets and check score</h1>\n\n<p>linear &lt;- lm(y_train ~ ., data = x)\nsummary(linear)</p>\n\n<h1>Predict Output</h1>\n\n<p>predicted= predict(linear,x_test) </p>\n",
                "codes": [
                    [],
                    [],
                    [],
                    [],
                    [],
                    [],
                    [],
                    [],
                    [],
                    [],
                    [],
                    [],
                    [],
                    [],
                    []
                ],
                "question_id:": "326",
                "question_votes:": "102",
                "question_text:": "<p>I'm just starting to develop a <a href=\"https://en.wikipedia.org/wiki/Machine_learning\" rel=\"nofollow noreferrer\">machine learning</a> application for academic purposes. I'm currently using <strong>R</strong> and training myself in it. However, in a lot of places, I have seen people using <strong>Python</strong>.</p>\n\n<p>What are people using in academia and industry, and what is the recommendation?</p>\n",
                "tags": "<machine-learning><r><python>",
                "answers": [
                    [
                        "331",
                        "2",
                        "326",
                        "",
                        "",
                        "<p>Some additional thoughts.</p>\n\n<p>The programming language 'per se' is only a tool. All languages were designed to make some type of constructs more easy to build than others. And the knowledge and mastery of a programming language is more important and effective than the features of that language compared to others.   </p>\n\n<p>As far as I can see there are two dimensions of this question. The first dimension is the ability to explore, build proof of concepts or models at a fast pace, eventually having at hand enough tools to study what is going on (like statistical tests, graphics, measurement tools, etc). This kind of activity is usually preferred by researchers and data scientists (I always wonder what that means, but I use this term for its loose definition). They tend to rely on well-known and verified instruments, which can be used for proofs or arguments.</p>\n\n<p>The second dimension is the ability to extend, change, improve or even create tools, algorithms or models. In order to achieve that you need a proper programming language. Roughly all of them are the same. If you work for a company, than you depend a lot on the company's infrastructure, internal culture and your choices diminish significantly. Also, when you want to implement an algorithm for production use, you have to trust the implementation. And implementing in another language which you do not master will not help you much.</p>\n\n<p>I tend to favor for the first type of activity the R ecosystem. You have a great community, a huge set of tools, proofs that these tools works as expected. Also, you can consider Python, Octave (to name a few), which are reliable candidates.</p>\n\n<p>For the second task, you have to think before at what you really want. If you want robust production ready tools, then C/C++, Java, C# are great candidates. I consider Python as a second citizen in this category, together with Scala and friends. I do not want to start a flame war, it's my opinion only. But after more than 17 years as a developer, I tend to prefer a strict contract and my knowledge, than the freedom to do whatever you might think of (like it happens with a lot of dynamic languages).</p>\n\n<p>Personally, I want to learn as much as possible. I decided that I have to choose the hard way, which means to implement everything from scratch myself. I use R as a model and inspiration. It has great treasures in libraries and a lot of experience distilled. However, R as a programming language is a nightmare for me. So I decided to use Java, and use no additional library. That is only because of my experience, and nothing else.</p>\n\n<p>If you have time, the best thing you can do is to spend some time with all these things. In this way you will earn for yourself the best answer possible, fitted for you. Dijkstra said once that the tools influence the way you think, so it is advisable to know your tools before letting them to model how you think. You can read more about that in his famous paper called <a href=\"http://www.cs.utexas.edu/~EWD/transcriptions/EWD03xx/EWD340.html\" rel=\"nofollow noreferrer\">The Humble Programmer</a></p>\n",
                        "",
                        "16"
                    ],
                    [
                        "22534",
                        "2",
                        "326",
                        "",
                        "",
                        "<p>I prefer Python over R because Python is a complete programming language so I can do end to end machine learning tasks such as gather data using a HTTP server written in Python, perform advanced ML tasks and then publish the results online. This can all be done in Python. I actually found R to be harder to learn and the payoffs for learning Python are much greater because it can be used for pretty much any programming task. </p>\n",
                        "",
                        "3"
                    ],
                    [
                        "2338",
                        "2",
                        "326",
                        "",
                        "",
                        "<p>In my experience, the answer depends on the project at hand. For pure research, I prefer R for two reasons: 1) broad variety of libraries and 2) much of the data science literature includes R samples.</p>\n\n<p>If the project requires an interactive interface to be used by laypersons, I've found R to be too constrained. Shiny is a great start, but it's not flexible enough yet. In these cases, I'll start to look at porting my R work over to Python or js.</p>\n",
                        "",
                        "8"
                    ],
                    [
                        "337",
                        "2",
                        "326",
                        "",
                        "",
                        "<p>I would add to what others have said till now. There is no single answer that one language is better than other.</p>\n\n<p>Having said that, R has a better community for data exploration and learning. It has extensive visualization capabilities. Python, on the other hand, has become better at data handling since introduction of pandas. Learning and development time is very less in Python, as compared to R (R being a low level language).</p>\n\n<p>I think it ultimately boils down to the eco-system you are in and personal preferences. For more details, you can look at this comparison <a href=\"http://www.analyticsvidhya.com/blog/2014/03/sas-vs-vs-python-tool-learn/\">here</a>.</p>\n",
                        "",
                        "15"
                    ],
                    [
                        "336",
                        "2",
                        "326",
                        "",
                        "",
                        "<p>There isn't a silver bullet language that can be used to solve each and every data related problem. The language choice depends on the context of the problem, size of data and if you are working at a workplace you have to stick to what they use.</p>\n\n<p>Personally I use R more often than Python due to its visualization libraries and interactive style. But if I need more performance or structured code I definitely use Python since it has some of the best libraries as SciKit-Learn, numpy, scipy etc. I use both R and Python in my projects interchangeably. </p>\n\n<p>So if you are starting on data science work I suggest you to learn both and it's not difficult since Python also provides a similar interface to R with <a href=\"http://pandas.pydata.org/\">Pandas</a>. </p>\n\n<p>If you have to deal with much larger datasets, you can't escape eco-systems built with Java(Hadoop, Pig, Hbase etc).</p>\n",
                        "",
                        "12"
                    ],
                    [
                        "15704",
                        "2",
                        "326",
                        "",
                        "",
                        "<p>An issue all other answers fail to address is <strong>licensing</strong>.</p>\n\n<p>Most of the aforementioned wonderful R libraries are GPL (e.g. <a href=\"https://cran.r-project.org/web/packages/ggplot2/index.html\" rel=\"noreferrer\">ggplot2</a>, <a href=\"https://cran.r-project.org/web/packages/data.table/index.html\" rel=\"noreferrer\">data.table</a>). This <a href=\"https://softwareengineering.stackexchange.com/questions/47032/can-i-use-gpl-software-in-a-commercial-application\">prevents you</a> from distributing your software in a proprietary form.</p>\n\n<p>Although many usages of those libraries do not imply distribution of the software (e.g. to train models offline), the GPL may by itself lure away companies from using them. At least in my experience.</p>\n\n<p>In the python realm, on the other hand, <em>most</em> libraries have business-friendly distribution licenses, such as BSD or MIT.</p>\n\n<p>In academia, licensing issues normally are non-issues.</p>\n",
                        "",
                        "8"
                    ],
                    [
                        "327",
                        "2",
                        "326",
                        "",
                        "",
                        "<p>There is nothing like \"python is better\" or \"R is much better than x\". </p>\n\n<p>The only fact I know is that in the industry allots of people stick to python because that is what they learned at the university. The python community is really active and have a few great frameworks for ML and data mining etc. </p>\n\n<p>But to be honest, if you get a good c programmer he can do the same as people do in python or r, if you got a good java programmer he can also do (near to) everything in java. </p>\n\n<p>So just stick with the language you are comfortable with.</p>\n",
                        "",
                        "23"
                    ],
                    [
                        "28921",
                        "2",
                        "326",
                        "",
                        "",
                        "<p>I do not think Python has <a href=\"https://alternativeto.net/list/2063/guis-to-save-from-typing-r-code/\" rel=\"nofollow noreferrer\">point-click GUI</a> that turn it into SPSS and SAS. Playing around with those is genuinely fun. </p>\n",
                        "",
                        ""
                    ],
                    [
                        "40635",
                        "2",
                        "326",
                        "",
                        "",
                        "<p><a href=\"https://i.stack.imgur.com/hc3tp.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/hc3tp.png\" alt=\"enter image description here\"></a></p>\n\n<p>I got this image in a linkedin post. Whenever I get a doubt of using python or R, I look into it and it proves to be very useful. </p>\n",
                        "",
                        ""
                    ],
                    [
                        "339",
                        "2",
                        "326",
                        "",
                        "",
                        "<p>Some real important differences to consider when you are choosing <strong>R</strong> or <strong>Python</strong> over one another:</p>\n\n<ul>\n<li><strong>Machine Learning</strong> has 2 phases. Model Building and Prediction phase. Typically, model building is performed as a batch process and <strong>predictions are done realtime</strong>. The model building process is a compute intensive process while the prediction happens in a jiffy. Therefore, performance of an algorithm in Python or R doesn't really affect the turn-around time of the user. Python 1, R 1.</li>\n<li><strong>Production:</strong> The real difference between Python and R comes in being production ready. Python, as such is a full fledged programming language and many organisations use it in their production systems. R is a statistical programming software favoured by many academia and due to the rise in data science and availability of libraries and being open source, the industry has started using R. Many of these organisations have their production systems either in Java, C++, C#, Python etc. So, ideally they would like to have the <strong>prediction system</strong> in the same language to reduce the latency and maintenance issues.\nPython 2, R 1.</li>\n<li><strong>Libraries:</strong> Both the languages have enormous and reliable libraries. R has over 5000 libraries catering to many domains while Python has some incredible packages like <strong>Pandas, NumPy, SciPy, Scikit Learn, Matplotlib</strong>. Python 3, R 2.</li>\n<li><strong>Development:</strong> Both the language are interpreted languages. Many say that python is easy to learn, it's almost like reading english (to put it on a lighter note) but R requires more initial studying effort. Also, both of them have good IDEs (Spyder etc for Python and RStudio for R). Python 4, R 2.</li>\n<li><strong>Speed:</strong> R software initially had problems with large computations (say, like nxn matrix multiplications). But, this issue is addressed with the introduction of R by Revolution Analytics. They have re-written computation intensive operations in C which is blazingly fast. Python being a high level language is relatively slow. Python 4, R 3.</li>\n<li><strong>Visualizations:</strong> In data science, we frequently tend to plot data to showcase patterns to users. Therefore, visualisations become an important criteria in choosing a software and R completely kills Python in this regard. Thanks to Hadley Wickham for an incredible ggplot2 package. R wins hands down. Python 4, R 4.</li>\n<li><strong>Dealing with Big Data:</strong> One of the constraints of R is it stores the data in system memory (RAM). So, RAM capacity becomes a constraint when you are handling Big Data. Python does well, but I would say, as both R and Python have HDFS connectors, leveraging Hadoop infrastructure would give substantial performance improvement. So, Python 5, R 5.</li>\n</ul>\n\n<p>So, both the languages are equally good. Therefore, depending upon your domain and the place you work, you have to smartly choose the right language. The technology world usually prefers using a single language. Business users (marketing analytics, retail analytics) usually go with statistical programming languages like R, since they frequently do quick prototyping and build visualisations (which is faster done in R than Python).</p>\n",
                        "",
                        "92"
                    ],
                    [
                        "328",
                        "2",
                        "326",
                        "",
                        "",
                        "<p>There is no \"better\" language. I have tried both of them and I am comfortable with Python so I work with Python only. Though I am still learning stuff, but I haven't encounter any roadblock with Python till now. The good thing about Python is community is too good and you can get a lot of help on the Internet easily. Other than that, I would say go with the language you like not the one people recommend. </p>\n",
                        "",
                        "8"
                    ],
                    [
                        "2299",
                        "2",
                        "326",
                        "",
                        "",
                        "<p>One of real challenges, I faced with R is different packages compatible with different versions.. quite a lot R packages are not available for latest version of R.. And R quite a few time gives error  due to library or package was written for older version.. </p>\n",
                        "",
                        "6"
                    ],
                    [
                        "6503",
                        "2",
                        "326",
                        "",
                        "",
                        "<p>I haven't tried R (well, a bit, but not enough to make a good comparison). However, here are some of Pythons strengths:</p>\n\n<ul>\n<li><strong>Very intuitive syntax</strong>: tuple unpacking, <code>element in a_list</code>, <code>for element in sequence</code>, <code>matrix_a * matrix_b</code> (for matrix multiplication), ...</li>\n<li><strong>Many libraries</strong>:\n\n<ul>\n<li><a href=\"http://www.scipy.org/\" rel=\"nofollow noreferrer\">scipy</a>: Scientific computations; many parts of it are only wrappers for pretty fast Fortran code</li>\n<li><a href=\"http://deeplearning.net/software/theano/\" rel=\"nofollow noreferrer\">theano</a> > <a href=\"http://lasagne.readthedocs.org/en/latest/\" rel=\"nofollow noreferrer\">Lasagne</a> > <a href=\"https://github.com/dnouri/nolearn\" rel=\"nofollow noreferrer\">nolearn</a>: Libraries for neural networks - they can be trained on GPU (nvidia, CUDA is required) without any adjustment</li>\n<li><a href=\"http://scikit-learn.org/\" rel=\"nofollow noreferrer\">sklearn</a>: General learning algorithms</li>\n</ul></li>\n<li><strong>Good community</strong>:\n\n<ul>\n<li>Python has <a href=\"https://stackoverflow.com/questions/tagged/python\">448,000+ questions on SO</a> (R has 99,000+)</li>\n<li>Python has <a href=\"https://datascience.stackexchange.com/questions/tagged/python\">103 questions on datascience.SE</a> (R has 140)</li>\n<li><a href=\"https://www.python.org/dev/peps/\" rel=\"nofollow noreferrer\">PEPs</a>, 63,000+ packages on <a href=\"https://pypi.python.org/pypi\" rel=\"nofollow noreferrer\">PyPI</a></li>\n</ul></li>\n<li><a href=\"http://ipython.org/\" rel=\"nofollow noreferrer\">IPython notebooks</a></li>\n<li><strong>Misc</strong>:\n\n<ul>\n<li>0-indexed arrays ... I made that error all the time with R.</li>\n<li>Established package structures</li>\n<li>Good support for testing your code</li>\n</ul></li>\n</ul>\n",
                        "",
                        "5"
                    ],
                    [
                        "5769",
                        "2",
                        "326",
                        "",
                        "",
                        "<p>Not much to add to the provided comments. Only thing is maybe this infographic comparing R vs Python for data science purposes <a href=\"http://blog.datacamp.com/r-or-python-for-data-analysis/\" rel=\"noreferrer\">http://blog.datacamp.com/r-or-python-for-data-analysis/</a></p>\n",
                        "",
                        "7"
                    ],
                    [
                        "23381",
                        "2",
                        "326",
                        "",
                        "",
                        "<p>R: R is the Open source counterpart. which has traditionally been used in academics and research.\n Because of its open source nature, latest techniques get released quickly. \nThere is a lot of documentation available over the internet and it is a very cost-effective option.\nPython: With origination as an open source scripting language,\n Python usage has grown over time. Today, it sports libraries (numpy, scipy and matplotlib) and functions for almost any statistical operation / model building you may want to do. \nSince introduction of pandas, it has become very strong in operations on structured data.</p>\n\n<p>Python Code</p>\n\n<h1>Import Library</h1>\n\n<h1>Import other necessary libraries like pandas, numpy...</h1>\n\n<p>from sklearn import linear_model</p>\n\n<h1>Load Train and Test datasets</h1>\n\n<h1>Identify feature and response variable(s) and values must be numeric and numpy arrays</h1>\n\n<p>x_train=input_variables_values_training_datasets\ny_train=target_variables_values_training_datasets\nx_test=input_variables_values_test_datasets</p>\n\n<h1>Create linear regression object</h1>\n\n<p>linear = linear_model.LinearRegression()</p>\n\n<h1>Train the model using the training sets and check score</h1>\n\n<p>linear.fit(x_train, y_train)\nlinear.score(x_train, y_train)</p>\n\n<h1>Equation coefficient and Intercept</h1>\n\n<p>print('Coefficient: \\n', linear.coef_)\nprint('Intercept: \\n', linear.intercept_)</p>\n\n<h1>Predict Output</h1>\n\n<p>predicted= linear.predict(x_test)\nR Code</p>\n\n<h1>Load Train and Test datasets</h1>\n\n<h1>Identify feature and response variable(s) and values must be numeric and numpy arrays</h1>\n\n<p>x_train &lt;- input_variables_values_training_datasets\ny_train &lt;- target_variables_values_training_datasets\nx_test &lt;- input_variables_values_test_datasets\nx &lt;- cbind(x_train,y_train)</p>\n\n<h1>Train the model using the training sets and check score</h1>\n\n<p>linear &lt;- lm(y_train ~ ., data = x)\nsummary(linear)</p>\n\n<h1>Predict Output</h1>\n\n<p>predicted= predict(linear,x_test) </p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10335",
            "_score": 9.145069,
            "_source": {
                "title": "How to plot High Dimensional supervised K-means on a 2D plot chart",
                "content": "How to plot High Dimensional supervised K-means on a 2D plot chart <p>I'm Having a ML problem where my data set contains 80 features labelled into 3 groups (0, 1, -1).</p>\n\n<p>I want to plot the data on a 2D surface to see how \"close\" (similar) data with <code>label x</code> is to data with <code>label y</code>, how the data spreads, are the labels separable, etc.</p>\n\n<p>I was thinking about using <em>PCA</em> and transform the data from 80D to 2D, but It only retain 40% of the variance!</p>\n\n<ul>\n<li>Is this a good approach for the problem? </li>\n<li>If so, does 40% suffice?</li>\n<li>Are there any other/better approach for this?</li>\n</ul>\n\n<h2>EDIT:</h2>\n\n<p>Plotting is not the main issue. The transformation from 80D to 2D (for an easy visialization) is whats difficult. </p>\n\n<p>Also, all of this is being made to know how much samples with <code>label 1</code> differs from <code>label 0</code> and <code>label -1</code> and <strong>vice versa</strong> (based on those original 80 features).</p>\n\n<p>If there's a different method, that is not visualizing the \"answer\", I'll also be happy to hear about it!</p>\n <machine-learning><visualization><k-means><pca><plotting><p>You can take a look at this answer in Cross Validated : <a href=\"https://stats.stackexchange.com/a/53194/211338\">https://stats.stackexchange.com/a/53194/211338</a></p>\n\n<p>It explains common techniques to visualize and compare high dimensional data. As you have 3 classes, just plot the different plots 3 times or compare them classes in \"0 vs 1\", \"0 vs -1\" and \"-1 vs 1\" plots, depending on the case.</p>\n\n<hr>\n\n<p>EDIT</p>\n\n<p>I don't really see why you would like to perform feature reduction, nor when. You wrote you want to <em>use K-means on that data</em> (60D data) and then just plot it on 2D plots to visualize the similarity of the labels. Well then, do it... </p>\n\n<p>You can apply K-means on your 60D data (supposing it has already been cleansed and properly analyzed), so you don't loose information. That will yield the class for each observation (0, -1 and 1) and voil\u00e0.</p>\n\n<p>If you really want to perform feature reduction: If you have some knowledge of the data, try to use other technique than PCA (search for Exploratory Data Analysis). If your data is anonymous, you can then perform PCA or any other type of dimensionality reduction method, like t-SNE (which should perform better on lots of cases).</p>\n\n<p>As you have noticed, PCA does not always yield amazing results. 60% of information seems not enough (to me). This means 40% of the information has been lost and will not be used in your algorithm. You can try and take some more principal components. I use an 85% treshold when I have a lot of instances and 95% when the dataset is rather small.</p>\n<p>What you are looking to do is perform some projection or feature compression (both of those terms mean the same thing in this context) onto a 2D plane while maintaining relative similarity. Many of these techniques exist each optimizing a different aspect of relative \"closeness\". </p>\n\n<p>The following code will show you 4 different algorithms which exist which can be used to plot high dimensional data in 2D. Although these algorithms are quite powerful you must remember that through any sort of projection a loss of information will result. Thus you will likely have to tune the parameters of these algorithms in order to best suit it for your data. In essence a good projection maintains relative distances between the in-groups and the out-groups.</p>\n\n<p>The Boston dataset has 13 features and a continuous label $Y$ representing a housing price. We have 339 instances.</p>\n\n<pre><code>from sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.manifold import TSNE, SpectralEmbedding, Isomap, MDS\n\n\nbostonboston  ==  load_bostonload_bo ()\nX = boston.data\nY = boston.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n\n\n# Embed the features into 2 features using TSNE# Embed \nX_embedded_iso  = Isomap(n_components=2).fit_transform(X)\nX_embedded_mds  = MDS(n_components=2, max_iter=100, n_init=1).fit_transform(X)\nX_embedded_tsne = TSNE(n_components=2).fit_transform(X)\nX_embedded_spec = SpectralEmbedding(n_components=2).fit_transform(X)\n\nprint('Description of the dataset: \\n')\n\nprint('Input shape : ', X_train.shape)\nprint('Target shape: ', y_train.shape)\n\nplt.plot(Y)\nplt.title('Distribution of the prices of the homes in the Boston area')\nplt.xlabel('Instance')\nplt.ylabel('Price')\nplt.show()\n\nprint('Embed the features into 2 features using Spectral Embedding: ', X_embedded_spec.shape)\nprint('Embed the features into 2 features using TSNE: ', X_embedded_tsne.shape)\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_iso[:,0], X_embedded_iso[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Isomap \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_mds[:,0], X_embedded_mds[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using MDS \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_spec[:,0], X_embedded_spec[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Spectral Embedding \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_tsne[:,0], X_embedded_tsne[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using TSNE \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n</code></pre>\n\n<p>The target $Y$ looks like:</p>\n\n<p><a href=\"https://i.stack.imgur.com/GrtVE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/GrtVE.png\" alt=\"enter image description here\"></a></p>\n\n<p>The projected data using the 4 techniques is shown below. The color of the points represents the housing price.</p>\n\n<p><a href=\"https://i.stack.imgur.com/kHyRH.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/kHyRH.png\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/OZTnA.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/OZTnA.png\" alt=\"enter image description here\"></a></p>\n\n<p>You can see that these 4 algorithms resulted in vastly different plots, but they all seemed to maintain the similarity between the targets. There are more options than these 4 algorithms of course. Another useful term for these techniques is called manifolds, embeddings, etc.</p>\n\n<p>Check out the sklearn page: <a href=\"http://scikit-learn.org/stable/modules/classes.html#module-sklearn.manifold\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/classes.html#module-sklearn.manifold</a>.</p>\n",
                "codes": [
                    [],
                    [
                        "from sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.manifold import TSNE, SpectralEmbedding, Isomap, MDS\n\n\nbostonboston  ==  load_bostonload_bo ()\nX = boston.data\nY = boston.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n\n\n# Embed the features into 2 features using TSNE# Embed \nX_embedded_iso  = Isomap(n_components=2).fit_transform(X)\nX_embedded_mds  = MDS(n_components=2, max_iter=100, n_init=1).fit_transform(X)\nX_embedded_tsne = TSNE(n_components=2).fit_transform(X)\nX_embedded_spec = SpectralEmbedding(n_components=2).fit_transform(X)\n\nprint('Description of the dataset: \\n')\n\nprint('Input shape : ', X_train.shape)\nprint('Target shape: ', y_train.shape)\n\nplt.plot(Y)\nplt.title('Distribution of the prices of the homes in the Boston area')\nplt.xlabel('Instance')\nplt.ylabel('Price')\nplt.show()\n\nprint('Embed the features into 2 features using Spectral Embedding: ', X_embedded_spec.shape)\nprint('Embed the features into 2 features using TSNE: ', X_embedded_tsne.shape)\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_iso[:,0], X_embedded_iso[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Isomap \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_mds[:,0], X_embedded_mds[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using MDS \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_spec[:,0], X_embedded_spec[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Spectral Embedding \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_tsne[:,0], X_embedded_tsne[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using TSNE \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n"
                    ]
                ],
                "question_id:": "37219",
                "question_votes:": "",
                "question_text:": "<p>I'm Having a ML problem where my data set contains 80 features labelled into 3 groups (0, 1, -1).</p>\n\n<p>I want to plot the data on a 2D surface to see how \"close\" (similar) data with <code>label x</code> is to data with <code>label y</code>, how the data spreads, are the labels separable, etc.</p>\n\n<p>I was thinking about using <em>PCA</em> and transform the data from 80D to 2D, but It only retain 40% of the variance!</p>\n\n<ul>\n<li>Is this a good approach for the problem? </li>\n<li>If so, does 40% suffice?</li>\n<li>Are there any other/better approach for this?</li>\n</ul>\n\n<h2>EDIT:</h2>\n\n<p>Plotting is not the main issue. The transformation from 80D to 2D (for an easy visialization) is whats difficult. </p>\n\n<p>Also, all of this is being made to know how much samples with <code>label 1</code> differs from <code>label 0</code> and <code>label -1</code> and <strong>vice versa</strong> (based on those original 80 features).</p>\n\n<p>If there's a different method, that is not visualizing the \"answer\", I'll also be happy to hear about it!</p>\n",
                "tags": "<machine-learning><visualization><k-means><pca><plotting>",
                "answers": [
                    [
                        "37222",
                        "2",
                        "37219",
                        "",
                        "",
                        "<p>You can take a look at this answer in Cross Validated : <a href=\"https://stats.stackexchange.com/a/53194/211338\">https://stats.stackexchange.com/a/53194/211338</a></p>\n\n<p>It explains common techniques to visualize and compare high dimensional data. As you have 3 classes, just plot the different plots 3 times or compare them classes in \"0 vs 1\", \"0 vs -1\" and \"-1 vs 1\" plots, depending on the case.</p>\n\n<hr>\n\n<p>EDIT</p>\n\n<p>I don't really see why you would like to perform feature reduction, nor when. You wrote you want to <em>use K-means on that data</em> (60D data) and then just plot it on 2D plots to visualize the similarity of the labels. Well then, do it... </p>\n\n<p>You can apply K-means on your 60D data (supposing it has already been cleansed and properly analyzed), so you don't loose information. That will yield the class for each observation (0, -1 and 1) and voil\u00e0.</p>\n\n<p>If you really want to perform feature reduction: If you have some knowledge of the data, try to use other technique than PCA (search for Exploratory Data Analysis). If your data is anonymous, you can then perform PCA or any other type of dimensionality reduction method, like t-SNE (which should perform better on lots of cases).</p>\n\n<p>As you have noticed, PCA does not always yield amazing results. 60% of information seems not enough (to me). This means 40% of the information has been lost and will not be used in your algorithm. You can try and take some more principal components. I use an 85% treshold when I have a lot of instances and 95% when the dataset is rather small.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "37373",
                        "2",
                        "37219",
                        "",
                        "",
                        "<p>What you are looking to do is perform some projection or feature compression (both of those terms mean the same thing in this context) onto a 2D plane while maintaining relative similarity. Many of these techniques exist each optimizing a different aspect of relative \"closeness\". </p>\n\n<p>The following code will show you 4 different algorithms which exist which can be used to plot high dimensional data in 2D. Although these algorithms are quite powerful you must remember that through any sort of projection a loss of information will result. Thus you will likely have to tune the parameters of these algorithms in order to best suit it for your data. In essence a good projection maintains relative distances between the in-groups and the out-groups.</p>\n\n<p>The Boston dataset has 13 features and a continuous label $Y$ representing a housing price. We have 339 instances.</p>\n\n<pre><code>from sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.manifold import TSNE, SpectralEmbedding, Isomap, MDS\n\n\nbostonboston  ==  load_bostonload_bo ()\nX = boston.data\nY = boston.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n\n\n# Embed the features into 2 features using TSNE# Embed \nX_embedded_iso  = Isomap(n_components=2).fit_transform(X)\nX_embedded_mds  = MDS(n_components=2, max_iter=100, n_init=1).fit_transform(X)\nX_embedded_tsne = TSNE(n_components=2).fit_transform(X)\nX_embedded_spec = SpectralEmbedding(n_components=2).fit_transform(X)\n\nprint('Description of the dataset: \\n')\n\nprint('Input shape : ', X_train.shape)\nprint('Target shape: ', y_train.shape)\n\nplt.plot(Y)\nplt.title('Distribution of the prices of the homes in the Boston area')\nplt.xlabel('Instance')\nplt.ylabel('Price')\nplt.show()\n\nprint('Embed the features into 2 features using Spectral Embedding: ', X_embedded_spec.shape)\nprint('Embed the features into 2 features using TSNE: ', X_embedded_tsne.shape)\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_iso[:,0], X_embedded_iso[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Isomap \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_mds[:,0], X_embedded_mds[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using MDS \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_spec[:,0], X_embedded_spec[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Spectral Embedding \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_tsne[:,0], X_embedded_tsne[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using TSNE \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n</code></pre>\n\n<p>The target $Y$ looks like:</p>\n\n<p><a href=\"https://i.stack.imgur.com/GrtVE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/GrtVE.png\" alt=\"enter image description here\"></a></p>\n\n<p>The projected data using the 4 techniques is shown below. The color of the points represents the housing price.</p>\n\n<p><a href=\"https://i.stack.imgur.com/kHyRH.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/kHyRH.png\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/OZTnA.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/OZTnA.png\" alt=\"enter image description here\"></a></p>\n\n<p>You can see that these 4 algorithms resulted in vastly different plots, but they all seemed to maintain the similarity between the targets. There are more options than these 4 algorithms of course. Another useful term for these techniques is called manifolds, embeddings, etc.</p>\n\n<p>Check out the sklearn page: <a href=\"http://scikit-learn.org/stable/modules/classes.html#module-sklearn.manifold\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/classes.html#module-sklearn.manifold</a>.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "116",
            "_score": 9.127981,
            "_source": {
                "title": "Gas consumption outliers detection - Neural network project. Bad results",
                "content": "Gas consumption outliers detection - Neural network project. Bad results <p>I tried to detect outliers in the energy gas consumption of some dutch buildings, building a neural network model. I have very bad results, but I can't find the reason. </p>\n\n<p>I am not an expert so I would like to ask you what I can improve and what I'm doing wrong. This is the complete description: <a href=\"https://github.com/denadai2/Gas-consumption-outliers\" rel=\"nofollow noreferrer\">https://github.com/denadai2/Gas-consumption-outliers</a>.</p>\n\n<p>The neural network is a FeedFoward Network with Back Propagation. As described <a href=\"http://nbviewer.ipython.org/github/denadai2/Gas-consumption-outliers/blob/master/3-%20Regression_NN.ipynb\" rel=\"nofollow noreferrer\">here</a> I splitted the dataset in a \"small\" dataset of 41'000 rows, 9 features and I tried to add more features. </p>\n\n<p>I trained the networks but the results have 14.14 RMSE, so it can't predict so well the gas consumptions, consecutively I can't run a good outlier detection mechanism. I see that in some papers that even if they predict daily or hourly consumption in the electric power, they have errors like MSE = 0.01.</p>\n\n<p>What can I improve? What am I doing wrong? Can you have a look of my description?</p>\n <neural-network><outlier><p>Just an idea - your data is highly seasonal: daily and weekly cycles are quite perceptible. So first of all, try to decompose your variables (gas and electricity consumption, temperature, and solar radiation). <a href=\"http://www.r-bloggers.com/time-series-decomposition/\">Here is</a> a nice tutorial on time series decomposition for R. </p>\n\n<p>After obtaining trend and seasonal components, the most interesting part begins. It's just an assumption, but I think, gas and electricity consumption variables would be quite predictable by means of time series analysis (e.g., <a href=\"http://statsmodels.sourceforge.net/devel/examples/notebooks/generated/tsa_arma_0.html\">ARIMA model</a>). From my point of view, the most exiting part here is to try to predict residuals after decomposition, using available data (temperature anomalies, solar radiation, wind speed). I suppose, these residuals would be outliers, you are looking for. Hope, you will find this useful.</p>\n<p>The main problem here is that even before attempting to apply anomaly detection algorithms, you are not getting good enough predictions of gas consumption using neural networks. </p>\n\n<p>If the main goal here is to reach the stage when anomaly detection algorithms could be used and you state that you have access to examples of successful application of linear regression for this problem, this approach could be more productive. One of the principles of successful machine learning application is that several different algorithms can be tried out before final selection based on results.</p>\n\n<p>It you choose to tune your neural network performance, <a href=\"https://stackoverflow.com/questions/4617365/what-is-a-learning-curve-in-machine-learning\">learning curve</a> plotting the effect of change in different hyperparameters on the error rate can be used. Hyperparameters that can be modified are: </p>\n\n<ul>\n<li>number of features</li>\n<li>order of the polynomial</li>\n<li>regularization parameter </li>\n<li>number of layers in the network</li>\n</ul>\n\n<p>Best settings can be selected by the performance on cross validation set.</p>\n<p>In your training notebook you present results for training with 20 epochs. Have you tried varying that parameter, to see if it affects your performance? This is an important parameter for back-propagation. </p>\n\n<p>For estimating your model parameters, as user tomaskazemekas pointed out, plotting Learning Curves is a very good approach. In addition to that, you could also create a plot using a model parameter (e.g. training epochs or hidden layer size) vs. Training and Validation error. This will allow you to understand the bias/variance tradeoff, and help you pick a good value for your parameters. <a href=\"http://www.astroml.org/sklearn_tutorial/practical.html#cross-validation-and-testing\" rel=\"nofollow\">Some info can be found here</a>. Naturally, it is a good idea to keep a small percentage of your data for a (third) Test set.</p>\n\n<p>As a side note, it seems that increasing the number of neurons in your model show no significant improvement for your RMSE. This suggests that you could also try with a simpler model, i.e. with less neurons and see how your model behaves.</p>\n\n<p>In fact, I would suggest (if you haven't done so already) trying a simple model with few or no parameters first e.g. Linear Regression, and compare your results with the literature, just as a sanity check. </p>\n<p>In your notebooks, I did not see your neural network model, can you point which library is using, how many layers you have and what type of neural network are you using?</p>\n\n<p>In your notebooks, it seems you are using the noisy and outlier dataset to train the neural network, I think you should train the neural network on the dataset that you do not have any outliers so that you could see the observation distance from the prediction of the neural network to label the observation either outlier or not. </p>\n\n<p>I wrote <a href=\"http://bugra.github.io/work/notes/2014-03-31/outlier-detection-in-time-series-signals-fft-median-filtering/\" rel=\"nofollow\">couple</a> of <a href=\"http://bugra.github.io/work/notes/2014-05-11/robust-regression-and-outlier-detection-via-gaussian-processes/\" rel=\"nofollow\">things</a> on outlier detection in time-series signals, your data is highly seasonal as sobach mentioned and you could use FFT(first link above) to get the overall trend in the signal. After you get the frequency component in the gas consumption, you could look at the high frequency components to get the outliers. </p>\n\n<p>Also if you want to insist on using neural network for seasonal data, you may want to check recurrent neural networks out as they could incorporate the past observations better than a vanilla neural network, and supposedly may provide a better result for the data that you have. </p>\n",
                "codes": [
                    [],
                    [],
                    [],
                    []
                ],
                "question_id:": "466",
                "question_votes:": "10",
                "question_text:": "<p>I tried to detect outliers in the energy gas consumption of some dutch buildings, building a neural network model. I have very bad results, but I can't find the reason. </p>\n\n<p>I am not an expert so I would like to ask you what I can improve and what I'm doing wrong. This is the complete description: <a href=\"https://github.com/denadai2/Gas-consumption-outliers\" rel=\"nofollow noreferrer\">https://github.com/denadai2/Gas-consumption-outliers</a>.</p>\n\n<p>The neural network is a FeedFoward Network with Back Propagation. As described <a href=\"http://nbviewer.ipython.org/github/denadai2/Gas-consumption-outliers/blob/master/3-%20Regression_NN.ipynb\" rel=\"nofollow noreferrer\">here</a> I splitted the dataset in a \"small\" dataset of 41'000 rows, 9 features and I tried to add more features. </p>\n\n<p>I trained the networks but the results have 14.14 RMSE, so it can't predict so well the gas consumptions, consecutively I can't run a good outlier detection mechanism. I see that in some papers that even if they predict daily or hourly consumption in the electric power, they have errors like MSE = 0.01.</p>\n\n<p>What can I improve? What am I doing wrong? Can you have a look of my description?</p>\n",
                "tags": "<neural-network><outlier>",
                "answers": [
                    [
                        "470",
                        "2",
                        "466",
                        "",
                        "",
                        "<p>Just an idea - your data is highly seasonal: daily and weekly cycles are quite perceptible. So first of all, try to decompose your variables (gas and electricity consumption, temperature, and solar radiation). <a href=\"http://www.r-bloggers.com/time-series-decomposition/\">Here is</a> a nice tutorial on time series decomposition for R. </p>\n\n<p>After obtaining trend and seasonal components, the most interesting part begins. It's just an assumption, but I think, gas and electricity consumption variables would be quite predictable by means of time series analysis (e.g., <a href=\"http://statsmodels.sourceforge.net/devel/examples/notebooks/generated/tsa_arma_0.html\">ARIMA model</a>). From my point of view, the most exiting part here is to try to predict residuals after decomposition, using available data (temperature anomalies, solar radiation, wind speed). I suppose, these residuals would be outliers, you are looking for. Hope, you will find this useful.</p>\n",
                        "",
                        "8"
                    ],
                    [
                        "519",
                        "2",
                        "466",
                        "",
                        "",
                        "<p>The main problem here is that even before attempting to apply anomaly detection algorithms, you are not getting good enough predictions of gas consumption using neural networks. </p>\n\n<p>If the main goal here is to reach the stage when anomaly detection algorithms could be used and you state that you have access to examples of successful application of linear regression for this problem, this approach could be more productive. One of the principles of successful machine learning application is that several different algorithms can be tried out before final selection based on results.</p>\n\n<p>It you choose to tune your neural network performance, <a href=\"https://stackoverflow.com/questions/4617365/what-is-a-learning-curve-in-machine-learning\">learning curve</a> plotting the effect of change in different hyperparameters on the error rate can be used. Hyperparameters that can be modified are: </p>\n\n<ul>\n<li>number of features</li>\n<li>order of the polynomial</li>\n<li>regularization parameter </li>\n<li>number of layers in the network</li>\n</ul>\n\n<p>Best settings can be selected by the performance on cross validation set.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "520",
                        "2",
                        "466",
                        "",
                        "",
                        "<p>In your training notebook you present results for training with 20 epochs. Have you tried varying that parameter, to see if it affects your performance? This is an important parameter for back-propagation. </p>\n\n<p>For estimating your model parameters, as user tomaskazemekas pointed out, plotting Learning Curves is a very good approach. In addition to that, you could also create a plot using a model parameter (e.g. training epochs or hidden layer size) vs. Training and Validation error. This will allow you to understand the bias/variance tradeoff, and help you pick a good value for your parameters. <a href=\"http://www.astroml.org/sklearn_tutorial/practical.html#cross-validation-and-testing\" rel=\"nofollow\">Some info can be found here</a>. Naturally, it is a good idea to keep a small percentage of your data for a (third) Test set.</p>\n\n<p>As a side note, it seems that increasing the number of neurons in your model show no significant improvement for your RMSE. This suggests that you could also try with a simpler model, i.e. with less neurons and see how your model behaves.</p>\n\n<p>In fact, I would suggest (if you haven't done so already) trying a simple model with few or no parameters first e.g. Linear Regression, and compare your results with the literature, just as a sanity check. </p>\n",
                        "",
                        "3"
                    ],
                    [
                        "523",
                        "2",
                        "466",
                        "",
                        "",
                        "<p>In your notebooks, I did not see your neural network model, can you point which library is using, how many layers you have and what type of neural network are you using?</p>\n\n<p>In your notebooks, it seems you are using the noisy and outlier dataset to train the neural network, I think you should train the neural network on the dataset that you do not have any outliers so that you could see the observation distance from the prediction of the neural network to label the observation either outlier or not. </p>\n\n<p>I wrote <a href=\"http://bugra.github.io/work/notes/2014-03-31/outlier-detection-in-time-series-signals-fft-median-filtering/\" rel=\"nofollow\">couple</a> of <a href=\"http://bugra.github.io/work/notes/2014-05-11/robust-regression-and-outlier-detection-via-gaussian-processes/\" rel=\"nofollow\">things</a> on outlier detection in time-series signals, your data is highly seasonal as sobach mentioned and you could use FFT(first link above) to get the overall trend in the signal. After you get the frequency component in the gas consumption, you could look at the high frequency components to get the outliers. </p>\n\n<p>Also if you want to insist on using neural network for seasonal data, you may want to check recurrent neural networks out as they could incorporate the past observations better than a vanilla neural network, and supposedly may provide a better result for the data that you have. </p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5026",
            "_score": 9.049532,
            "_source": {
                "title": "Machine-learning algorithm / library for outcome prediction",
                "content": "Machine-learning algorithm / library for outcome prediction <p>I am extremely new to this data science world so bear with me if my question is not very clear, I'd be glad to clarify. What I am looking for is simple: train a program with a set of values (5 ordered integer inputs, 1 boolean output). Then I would give it 5 inputs where the outcome is not known, and it has to tell me the outcome. </p>\n <machine-learning><deep-learning><p><code>scikit-learn</code> is a powerful and a very very simple ML library for Python.</p>\n\n<p>Your doubt is about a Classification Problem, where you're going to predict a class (True or False) given some input data.</p>\n\n<p>There are many <a href=\"http://scikit-learn.org/stable/supervised_learning.html#supervised-learning\" rel=\"nofollow noreferrer\">classifiers</a> that you can use.</p>\n\n<p>In this example I've used <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\" rel=\"nofollow noreferrer\">Logistic Regression</a></p>\n\n<pre><code>from sklearn.linear_model import LogisticRegression\n\n# Input data\ndata = [[1.0, 2.0, 3.0, 4.0, 5.0], [6.0, 7.0, 8.0, 9.0, 10.0]]\n\n# Target values for input data\ntarget = [True, False]\n\n# Define the model (default parameters)\nmodel = LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n\n# Train the model\nmodel.fit(data, target)\n\n# Once the model is trained, we make a prediction\nmodel.predict([[1.0, 2.0, 3.0, 4.0, 5.0]])\n</code></pre>\n\n<p>If you execute this code, the prediction for that data is <code>False</code></p>\n<p>It is a basic classification model. Our focus is to train the model using training dataset and evaluate its performance with the test set.</p>\n\n<p>In your case, assume you have 10 numbers as input and a binary output.\nConsider random 8 entries as your training data and train it with any classification algorithm using R/Python. Then test it on the remaining entries which acts as a test data.</p>\n\n<p>Since it is associated with classification we need to consider performance metrics like accuracy, precision and recall based on the labeled feature.</p>\n\n<p>For more details on classification try <a href=\"https://www-users.cs.umn.edu/~kumar/dmbook/ch4.pdf\" rel=\"nofollow noreferrer\">here</a></p>\n<p>It seems overkill, but I gonna tell you how to get strict math dependency from your data:</p>\n\n<ol>\n<li>same sets of inputs should be converted to single set and rate instead of bool, where true increments rate and false decrements the rate for same sets of values.</li>\n<li>input vars set should be converted to system of equations: $v_1=a, v_2=b ... $ where $a,b,c,d,e$ are particular inputs set. And one more var for rate.</li>\n<li>simultaneous equations may be converted to single equation formed by summing it squares: $(v1-a)^2+(v2-b)^2+(v3-c)^2...=0$</li>\n<li>the equation may be used if you insert new set of vars values in equation and see which rate will outcome.</li>\n<li>find the equation that gives best fit to your set of data.</li>\n</ol>\n\n<p>If you have aggressive calculation abilities then you may want to proceed to next level of precision:</p>\n\n<ol>\n<li>Do steps 1-3 of the previous sequence.</li>\n<li>Different sets are non-simultaneous equation of the system you need. Non-simulteneous system may be converted to single equation using multiplication. You'l have big product of all your data like $((v1-a1)^2+(v2-b1)^2+(v3-c1)^2...)((v1-a2)^2+(v2-b2)^2+(v3-c2)^2...)((v1-a3)^2+(v2-b3)^2+(v3-c3)^2...)...=0$</li>\n<li>Use the system and OpenCL or IBM XL C++ compiler OpenMP extension offload to Nvidia GPUs feature to simulteneously calculate members of the product that have all information of flight results. </li>\n</ol>\n\n<p>Similar approach is used in <a href=\"https://github.com/ohhmm/openmind/blob/expression/omnn/extrapolator/test/test_extrapolator.cpp\" rel=\"nofollow noreferrer\">this extrapolator implementation</a> and its math framework.</p>\n",
                "codes": [
                    [
                        "from sklearn.linear_model import LogisticRegression\n\n# Input data\ndata = [[1.0, 2.0, 3.0, 4.0, 5.0], [6.0, 7.0, 8.0, 9.0, 10.0]]\n\n# Target values for input data\ntarget = [True, False]\n\n# Define the model (default parameters)\nmodel = LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n\n# Train the model\nmodel.fit(data, target)\n\n# Once the model is trained, we make a prediction\nmodel.predict([[1.0, 2.0, 3.0, 4.0, 5.0]])\n"
                    ],
                    [],
                    []
                ],
                "question_id:": "19541",
                "question_votes:": "3",
                "question_text:": "<p>I am extremely new to this data science world so bear with me if my question is not very clear, I'd be glad to clarify. What I am looking for is simple: train a program with a set of values (5 ordered integer inputs, 1 boolean output). Then I would give it 5 inputs where the outcome is not known, and it has to tell me the outcome. </p>\n",
                "tags": "<machine-learning><deep-learning>",
                "answers": [
                    [
                        "22867",
                        "2",
                        "19541",
                        "",
                        "",
                        "<p><code>scikit-learn</code> is a powerful and a very very simple ML library for Python.</p>\n\n<p>Your doubt is about a Classification Problem, where you're going to predict a class (True or False) given some input data.</p>\n\n<p>There are many <a href=\"http://scikit-learn.org/stable/supervised_learning.html#supervised-learning\" rel=\"nofollow noreferrer\">classifiers</a> that you can use.</p>\n\n<p>In this example I've used <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\" rel=\"nofollow noreferrer\">Logistic Regression</a></p>\n\n<pre><code>from sklearn.linear_model import LogisticRegression\n\n# Input data\ndata = [[1.0, 2.0, 3.0, 4.0, 5.0], [6.0, 7.0, 8.0, 9.0, 10.0]]\n\n# Target values for input data\ntarget = [True, False]\n\n# Define the model (default parameters)\nmodel = LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n\n# Train the model\nmodel.fit(data, target)\n\n# Once the model is trained, we make a prediction\nmodel.predict([[1.0, 2.0, 3.0, 4.0, 5.0]])\n</code></pre>\n\n<p>If you execute this code, the prediction for that data is <code>False</code></p>\n",
                        "",
                        ""
                    ],
                    [
                        "22878",
                        "2",
                        "19541",
                        "",
                        "",
                        "<p>It is a basic classification model. Our focus is to train the model using training dataset and evaluate its performance with the test set.</p>\n\n<p>In your case, assume you have 10 numbers as input and a binary output.\nConsider random 8 entries as your training data and train it with any classification algorithm using R/Python. Then test it on the remaining entries which acts as a test data.</p>\n\n<p>Since it is associated with classification we need to consider performance metrics like accuracy, precision and recall based on the labeled feature.</p>\n\n<p>For more details on classification try <a href=\"https://www-users.cs.umn.edu/~kumar/dmbook/ch4.pdf\" rel=\"nofollow noreferrer\">here</a></p>\n",
                        "",
                        "1"
                    ],
                    [
                        "25546",
                        "2",
                        "19541",
                        "",
                        "",
                        "<p>It seems overkill, but I gonna tell you how to get strict math dependency from your data:</p>\n\n<ol>\n<li>same sets of inputs should be converted to single set and rate instead of bool, where true increments rate and false decrements the rate for same sets of values.</li>\n<li>input vars set should be converted to system of equations: $v_1=a, v_2=b ... $ where $a,b,c,d,e$ are particular inputs set. And one more var for rate.</li>\n<li>simultaneous equations may be converted to single equation formed by summing it squares: $(v1-a)^2+(v2-b)^2+(v3-c)^2...=0$</li>\n<li>the equation may be used if you insert new set of vars values in equation and see which rate will outcome.</li>\n<li>find the equation that gives best fit to your set of data.</li>\n</ol>\n\n<p>If you have aggressive calculation abilities then you may want to proceed to next level of precision:</p>\n\n<ol>\n<li>Do steps 1-3 of the previous sequence.</li>\n<li>Different sets are non-simultaneous equation of the system you need. Non-simulteneous system may be converted to single equation using multiplication. You'l have big product of all your data like $((v1-a1)^2+(v2-b1)^2+(v3-c1)^2...)((v1-a2)^2+(v2-b2)^2+(v3-c2)^2...)((v1-a3)^2+(v2-b3)^2+(v3-c3)^2...)...=0$</li>\n<li>Use the system and OpenCL or IBM XL C++ compiler OpenMP extension offload to Nvidia GPUs feature to simulteneously calculate members of the product that have all information of flight results. </li>\n</ol>\n\n<p>Similar approach is used in <a href=\"https://github.com/ohhmm/openmind/blob/expression/omnn/extrapolator/test/test_extrapolator.cpp\" rel=\"nofollow noreferrer\">this extrapolator implementation</a> and its math framework.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4168",
            "_score": 8.993513,
            "_source": {
                "title": "Multi-class text classification with LSTM in Keras",
                "content": "Multi-class text classification with LSTM in Keras <p>I'm quite new to Deep Learning and trying to solve the problem of Multi-Class, multi-label text classification using Deep Learning.</p>\n\n<p><a href=\"https://github.com/fchollet/keras/blob/master/examples/imdb_cnn_lstm.py\" rel=\"nofollow noreferrer\">https://github.com/fchollet/keras/blob/master/examples/imdb_cnn_lstm.py</a> .\nI've another dataset. int form of a csv file (\"text\",\"classifier\"), on which i want to perform text classification task. I've tried a few ways to pass my training text to keras but couldn't so I'm stuck at this point. Can anyone suggest me how should I pass my \"train.csv\" and \"test.csv\" file to the X_train, y_train and X_test, y_test?</p>\n\n<p>Typically stuck in this line.</p>\n\n<pre><code>(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n</code></pre>\n\n<p>'train.csv' has this format:</p>\n\n<p>\"Job Description:An ideal fitment would apply his/ her advanced analytics expertise at a cutting edge Industrial Analytics specialized Data Science organization; primarily, in any of the following areas- automotive/ energy/ oil &amp; gas/ aerospace/ marine/ chemical.  Experience in statistical modeling, predictive modeling, Random forests, Decision tree, Linear Regression, Correlation, Time- series.  BE / MS/ PhD in Mechanical/ OR/ IE/ computer science/ EE/ chemical.    Mentor/ Lead a small team of data scientist\",Business Analytics </p>\n\n<p>'test.csv' has same format that is \"job_description\",\"category\"</p>\n <keras><dimensionality-reduction><multiclass-classification><multilabel-classification><p>After I read the <a href=\"https://github.com/fchollet/keras/blob/master/keras/datasets/imdb.py\" rel=\"nofollow noreferrer\">source code</a>, I find out that <code>keras.datasets.imdb.load_data</code> doesn't actually load the plain text data and convert them into vector, it just loads the vector which has been converted before.</p>\n\n<p>As for your problem, I assume you want to convert your <code>job_description</code> into vector. Maybe you can try <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\" rel=\"nofollow noreferrer\">sklearn.feature_extraction.text.CountVectorizer</a>. </p>\n\n<p>I'm no expert on NLP, but I've encountered problems (e.g. <a href=\"https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries\" rel=\"nofollow noreferrer\">Two Sigma Connect: Rental Listing Inquiries</a>) which need such technique.</p>\n\n<p>In the meanwhile, there are other word2vec/embedding techniques you may try. Here is a <a href=\"https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\" rel=\"nofollow noreferrer\">tutorial</a> from keras which shows a detailed example on word embedding.</p>\n\n<h2>References</h2>\n\n<p><a href=\"https://github.com/fchollet/keras/blob/master/keras/datasets/imdb.py\" rel=\"nofollow noreferrer\">https://github.com/fchollet/keras/blob/master/keras/datasets/imdb.py</a></p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html</a></p>\n\n<p><a href=\"https://www.kaggle.com/sudalairajkumar/two-sigma-connect-rental-listing-inquiries/xgb-starter-in-python\" rel=\"nofollow noreferrer\">https://www.kaggle.com/sudalairajkumar/two-sigma-connect-rental-listing-inquiries/xgb-starter-in-python</a></p>\n<p>Something like this:</p>\n\n<pre><code>nb_classes = 3 # the number of categories you have\nx_train = []\ny_train = []\n\nwith open('train.csv', 'r') as train_file:\n    reader = csv.reader(train_file)\n    for row in reader:\n       sentence = row[0]\n       category = row[1]\n\n       x_train.append(sentence)\n       y_train.append(category)\n\nY_train = np_utils.to_categorical(y_train, nb_classes)\nX_train = ? # your choice of tokanization\n</code></pre>\n\n<p>You should do the same with your test dataset. </p>\n\n<p>You should also change the loss to <code>categorical_crossentropy</code>.</p>\n",
                "codes": [
                    [],
                    [
                        "nb_classes = 3 # the number of categories you have\nx_train = []\ny_train = []\n\nwith open('train.csv', 'r') as train_file:\n    reader = csv.reader(train_file)\n    for row in reader:\n       sentence = row[0]\n       category = row[1]\n\n       x_train.append(sentence)\n       y_train.append(category)\n\nY_train = np_utils.to_categorical(y_train, nb_classes)\nX_train = ? # your choice of tokanization\n"
                    ]
                ],
                "question_id:": "16948",
                "question_votes:": "4",
                "question_text:": "<p>I'm quite new to Deep Learning and trying to solve the problem of Multi-Class, multi-label text classification using Deep Learning.</p>\n\n<p><a href=\"https://github.com/fchollet/keras/blob/master/examples/imdb_cnn_lstm.py\" rel=\"nofollow noreferrer\">https://github.com/fchollet/keras/blob/master/examples/imdb_cnn_lstm.py</a> .\nI've another dataset. int form of a csv file (\"text\",\"classifier\"), on which i want to perform text classification task. I've tried a few ways to pass my training text to keras but couldn't so I'm stuck at this point. Can anyone suggest me how should I pass my \"train.csv\" and \"test.csv\" file to the X_train, y_train and X_test, y_test?</p>\n\n<p>Typically stuck in this line.</p>\n\n<pre><code>(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n</code></pre>\n\n<p>'train.csv' has this format:</p>\n\n<p>\"Job Description:An ideal fitment would apply his/ her advanced analytics expertise at a cutting edge Industrial Analytics specialized Data Science organization; primarily, in any of the following areas- automotive/ energy/ oil &amp; gas/ aerospace/ marine/ chemical.  Experience in statistical modeling, predictive modeling, Random forests, Decision tree, Linear Regression, Correlation, Time- series.  BE / MS/ PhD in Mechanical/ OR/ IE/ computer science/ EE/ chemical.    Mentor/ Lead a small team of data scientist\",Business Analytics </p>\n\n<p>'test.csv' has same format that is \"job_description\",\"category\"</p>\n",
                "tags": "<keras><dimensionality-reduction><multiclass-classification><multilabel-classification>",
                "answers": [
                    [
                        "16951",
                        "2",
                        "16948",
                        "",
                        "",
                        "<p>After I read the <a href=\"https://github.com/fchollet/keras/blob/master/keras/datasets/imdb.py\" rel=\"nofollow noreferrer\">source code</a>, I find out that <code>keras.datasets.imdb.load_data</code> doesn't actually load the plain text data and convert them into vector, it just loads the vector which has been converted before.</p>\n\n<p>As for your problem, I assume you want to convert your <code>job_description</code> into vector. Maybe you can try <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\" rel=\"nofollow noreferrer\">sklearn.feature_extraction.text.CountVectorizer</a>. </p>\n\n<p>I'm no expert on NLP, but I've encountered problems (e.g. <a href=\"https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries\" rel=\"nofollow noreferrer\">Two Sigma Connect: Rental Listing Inquiries</a>) which need such technique.</p>\n\n<p>In the meanwhile, there are other word2vec/embedding techniques you may try. Here is a <a href=\"https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\" rel=\"nofollow noreferrer\">tutorial</a> from keras which shows a detailed example on word embedding.</p>\n\n<h2>References</h2>\n\n<p><a href=\"https://github.com/fchollet/keras/blob/master/keras/datasets/imdb.py\" rel=\"nofollow noreferrer\">https://github.com/fchollet/keras/blob/master/keras/datasets/imdb.py</a></p>\n\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html</a></p>\n\n<p><a href=\"https://www.kaggle.com/sudalairajkumar/two-sigma-connect-rental-listing-inquiries/xgb-starter-in-python\" rel=\"nofollow noreferrer\">https://www.kaggle.com/sudalairajkumar/two-sigma-connect-rental-listing-inquiries/xgb-starter-in-python</a></p>\n",
                        "",
                        "3"
                    ],
                    [
                        "19905",
                        "2",
                        "16948",
                        "",
                        "",
                        "<p>Something like this:</p>\n\n<pre><code>nb_classes = 3 # the number of categories you have\nx_train = []\ny_train = []\n\nwith open('train.csv', 'r') as train_file:\n    reader = csv.reader(train_file)\n    for row in reader:\n       sentence = row[0]\n       category = row[1]\n\n       x_train.append(sentence)\n       y_train.append(category)\n\nY_train = np_utils.to_categorical(y_train, nb_classes)\nX_train = ? # your choice of tokanization\n</code></pre>\n\n<p>You should do the same with your test dataset. </p>\n\n<p>You should also change the loss to <code>categorical_crossentropy</code>.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8746",
            "_score": 8.975354,
            "_source": {
                "title": "how to print kmeans cluster python",
                "content": "how to print kmeans cluster python <p>Data-set has 3 features. The number of clusters are two.</p>\n\n<p><em>I am figuring out how to print clusters using scatter plot for the data having 3 feature column and clustered into 2 clusters using kmeans.</em></p>\n\n<p>The train data is in dataframe format and data is of activity data set:</p>\n\n<pre><code>X =  pd.concat([train_data['start'], train_data['end'], train_data  ['duration']], axis=1)  \nkmeans.fit(X)  \nY_pred = kmeans.predict(X)  \nplt.scatter(X.iloc[:,0], X.iloc[:,1], c=Y_pred, cmap=plt.cm.Paired)  \nplt.legend()  \nplt.title('train data')  \nplt.show()  \ngetting following output:\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/xUe3n.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/xUe3n.png\" alt=\"enter image description here\"></a></p>\n <python><h1>3D plot</h1>\n\n<p>3 features indicates that your data is 3 dimensional. Thus you can use a 3D plot. The following code will plot 3 dimensional data. $x$ is a numpy matrix with the 3 features as columns, and the rows are the instances. Then $y$ is the cluster label that you obtain from k-means.</p>\n\n<pre><code>import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nfrom numpy import where\n\n# Plots 2 features, with an output, shows the decision boundary\ndef plot3D(x, y):\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    pos = where(y == 1)\n    neg = where(y == 0)\n\n    color = ['r', 'b', 'y', 'k', 'g', 'c', 'm']\n\n    for i in range(30):\n        ax.scatter(x[i, 0], x[i, 1],x[i, 2], marker='o', c=color[int(y[i])-1])\n    #ax.scatter(x[:,1], x[:,2], y)\n    ax.set_xlabel('X Label')\n    ax.set_ylabel('Y Label')\n    ax.set_zlabel('Z Label')\n\n    axes = plt.axis()\n    plt.show()\n\nplot3D(X, cluster_labels)\n</code></pre>\n\n<p>This will give you the following plot</p>\n\n<p><a href=\"https://i.stack.imgur.com/2G7f7.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/2G7f7.png\" alt=\"enter image description here\"></a></p>\n\n<h1>2D plot</h1>\n\n<p>Alternatively you can project the data into two dimensions. You can do this naively by collapsing any of the three dimensions. For example this will only show the first 2 features, the third would be projected onto the plane of the first and second feature.</p>\n\n<pre><code>plt.scatter(X[:,0], X[:,1], c=cluster_labels)\nplt.show()\n</code></pre>\n\n<p>You can also plot the 2nd and 3rd features, where the first feature is projected as</p>\n\n<pre><code>plt.scatter(X[:,1], X[:,2], c=cluster_labels)\nplt.show()\n</code></pre>\n\n<p>Projecting data naively can lead to problems so instead you can use a feature embedding method. Here I will give an example for 4 different methods: Isomap, MDS, spectral embedding and TSNE (my favorite).</p>\n\n<p>This is continuous data that I have access to but you can easily do the same for clustered data. Just set the labels $y$ as your determined clusters.</p>\n\n<pre><code>from sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.manifold import TSNE, SpectralEmbedding, Isomap, MDS\n\nboston = load_boston()\nX = boston.data\nY = boston.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n\n# Embed the features into 2 features using TSNE\nX_embedded_iso  = Isomap(n_components=2).fit_transform(X)\nX_embedded_mds  = MDS(n_components=2, max_iter=100, n_init=1).fit_transform(X)\nX_embedded_tsne = TSNE(n_components=2).fit_transform(X)\nX_embedded_spec = SpectralEmbedding(n_components=2).fit_transform(X)\n\nprint('Description of the dataset: \\n')\n\nprint('Input shape : ', X_train.shape)\nprint('Target shape: ', y_train.shape)\n\nprint('Embed the features into 2 features using Spectral Embedding: ', X_embedded_spec.shape)\nprint('Embed the features into 2 features using TSNE: ', X_embedded_tsne.shape)\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_iso[:,0], X_embedded_iso[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Isomap \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_mds[:,0], X_embedded_mds[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using MDS \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_spec[:,0], X_embedded_spec[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Spectral Embedding \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_tsne[:,0], X_embedded_tsne[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using TSNE \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/wypl0.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/wypl0.png\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/FGaak.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/FGaak.png\" alt=\"enter image description here\"></a></p>\n<p><strong>Code Is Self Explanatory...</strong></p>\n\n<pre><code>    from sklearn.cluster import KMeans\n    from sklearn.datasets.samples_generator import make_blobs\n    np.random.seed(0)\n    centers = [[1, 1], [-1, -1]]\n    n_clusters = len(centers)\n    X, labels_true = make_blobs(n_samples=3000, \n                                centers=centers, \n                                cluster_std=0.5)\n\ndef plot_cluster_data(X, c=[1]*X.shape[0], mu=None):\n    fig = plt.figure(figsize=(8, 8))\n    ax = fig.add_subplot(1, 1, 1)\n    if len(np.unique(c)) == 1:\n        ax.plot(X[:,0], X[:,1], 'o')\n    else:\n        ix = np.where(c==1)\n        ax.plot(X[ix,0], X[ix,1], 'o', \n                markerfacecolor='red')\n        ax.plot(mu[0,0], mu[0,1], 'o', \n                markerfacecolor='red', \n                markersize=12)\n        ix = np.where(c==0)\n        ax.plot(X[ix,0], X[ix,1], 'o', \n                markerfacecolor='green')\n        ax.plot(mu[1,0], mu[1,1], 'o', \n                markerfacecolor='green', \n                markersize=12)\n    if not mu is None:\n        ax.plot(mu[0,0], mu[0,1], 'o', \n                markerfacecolor='red', \n                markersize=12)\n        ax.plot(mu[1,0], mu[1,1], 'o', \n                markerfacecolor='green', \n                markersize=12)        \n    plt.show()\n\nplot_cluster_data(X)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/Ut3yC.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Ut3yC.png\" alt=\"enter image description here\"></a></p>\n\n<pre><code>clst = KMeans(n_clusters=2, random_state=2342)\nclst.fit(X)\nmu = clst.cluster_centers_\nplot_cluster_data(X, mu = mu)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/Od7mk.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Od7mk.png\" alt=\"enter image description here\"></a></p>\n",
                "codes": [
                    [
                        "import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nfrom numpy import where\n\n# Plots 2 features, with an output, shows the decision boundary\ndef plot3D(x, y):\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    pos = where(y == 1)\n    neg = where(y == 0)\n\n    color = ['r', 'b', 'y', 'k', 'g', 'c', 'm']\n\n    for i in range(30):\n        ax.scatter(x[i, 0], x[i, 1],x[i, 2], marker='o', c=color[int(y[i])-1])\n    #ax.scatter(x[:,1], x[:,2], y)\n    ax.set_xlabel('X Label')\n    ax.set_ylabel('Y Label')\n    ax.set_zlabel('Z Label')\n\n    axes = plt.axis()\n    plt.show()\n\nplot3D(X, cluster_labels)\n",
                        "plt.scatter(X[:,0], X[:,1], c=cluster_labels)\nplt.show()\n",
                        "plt.scatter(X[:,1], X[:,2], c=cluster_labels)\nplt.show()\n",
                        "from sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.manifold import TSNE, SpectralEmbedding, Isomap, MDS\n\nboston = load_boston()\nX = boston.data\nY = boston.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n\n# Embed the features into 2 features using TSNE\nX_embedded_iso  = Isomap(n_components=2).fit_transform(X)\nX_embedded_mds  = MDS(n_components=2, max_iter=100, n_init=1).fit_transform(X)\nX_embedded_tsne = TSNE(n_components=2).fit_transform(X)\nX_embedded_spec = SpectralEmbedding(n_components=2).fit_transform(X)\n\nprint('Description of the dataset: \\n')\n\nprint('Input shape : ', X_train.shape)\nprint('Target shape: ', y_train.shape)\n\nprint('Embed the features into 2 features using Spectral Embedding: ', X_embedded_spec.shape)\nprint('Embed the features into 2 features using TSNE: ', X_embedded_tsne.shape)\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_iso[:,0], X_embedded_iso[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Isomap \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_mds[:,0], X_embedded_mds[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using MDS \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_spec[:,0], X_embedded_spec[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Spectral Embedding \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_tsne[:,0], X_embedded_tsne[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using TSNE \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n"
                    ],
                    [
                        "    from sklearn.cluster import KMeans\n    from sklearn.datasets.samples_generator import make_blobs\n    np.random.seed(0)\n    centers = [[1, 1], [-1, -1]]\n    n_clusters = len(centers)\n    X, labels_true = make_blobs(n_samples=3000, \n                                centers=centers, \n                                cluster_std=0.5)\n\ndef plot_cluster_data(X, c=[1]*X.shape[0], mu=None):\n    fig = plt.figure(figsize=(8, 8))\n    ax = fig.add_subplot(1, 1, 1)\n    if len(np.unique(c)) == 1:\n        ax.plot(X[:,0], X[:,1], 'o')\n    else:\n        ix = np.where(c==1)\n        ax.plot(X[ix,0], X[ix,1], 'o', \n                markerfacecolor='red')\n        ax.plot(mu[0,0], mu[0,1], 'o', \n                markerfacecolor='red', \n                markersize=12)\n        ix = np.where(c==0)\n        ax.plot(X[ix,0], X[ix,1], 'o', \n                markerfacecolor='green')\n        ax.plot(mu[1,0], mu[1,1], 'o', \n                markerfacecolor='green', \n                markersize=12)\n    if not mu is None:\n        ax.plot(mu[0,0], mu[0,1], 'o', \n                markerfacecolor='red', \n                markersize=12)\n        ax.plot(mu[1,0], mu[1,1], 'o', \n                markerfacecolor='green', \n                markersize=12)        \n    plt.show()\n\nplot_cluster_data(X)\n",
                        "clst = KMeans(n_clusters=2, random_state=2342)\nclst.fit(X)\nmu = clst.cluster_centers_\nplot_cluster_data(X, mu = mu)\n"
                    ]
                ],
                "question_id:": "31700",
                "question_votes:": "2",
                "question_text:": "<p>Data-set has 3 features. The number of clusters are two.</p>\n\n<p><em>I am figuring out how to print clusters using scatter plot for the data having 3 feature column and clustered into 2 clusters using kmeans.</em></p>\n\n<p>The train data is in dataframe format and data is of activity data set:</p>\n\n<pre><code>X =  pd.concat([train_data['start'], train_data['end'], train_data  ['duration']], axis=1)  \nkmeans.fit(X)  \nY_pred = kmeans.predict(X)  \nplt.scatter(X.iloc[:,0], X.iloc[:,1], c=Y_pred, cmap=plt.cm.Paired)  \nplt.legend()  \nplt.title('train data')  \nplt.show()  \ngetting following output:\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/xUe3n.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/xUe3n.png\" alt=\"enter image description here\"></a></p>\n",
                "tags": "<python>",
                "answers": [
                    [
                        "31702",
                        "2",
                        "31700",
                        "",
                        "",
                        "<h1>3D plot</h1>\n\n<p>3 features indicates that your data is 3 dimensional. Thus you can use a 3D plot. The following code will plot 3 dimensional data. $x$ is a numpy matrix with the 3 features as columns, and the rows are the instances. Then $y$ is the cluster label that you obtain from k-means.</p>\n\n<pre><code>import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nfrom numpy import where\n\n# Plots 2 features, with an output, shows the decision boundary\ndef plot3D(x, y):\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    pos = where(y == 1)\n    neg = where(y == 0)\n\n    color = ['r', 'b', 'y', 'k', 'g', 'c', 'm']\n\n    for i in range(30):\n        ax.scatter(x[i, 0], x[i, 1],x[i, 2], marker='o', c=color[int(y[i])-1])\n    #ax.scatter(x[:,1], x[:,2], y)\n    ax.set_xlabel('X Label')\n    ax.set_ylabel('Y Label')\n    ax.set_zlabel('Z Label')\n\n    axes = plt.axis()\n    plt.show()\n\nplot3D(X, cluster_labels)\n</code></pre>\n\n<p>This will give you the following plot</p>\n\n<p><a href=\"https://i.stack.imgur.com/2G7f7.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/2G7f7.png\" alt=\"enter image description here\"></a></p>\n\n<h1>2D plot</h1>\n\n<p>Alternatively you can project the data into two dimensions. You can do this naively by collapsing any of the three dimensions. For example this will only show the first 2 features, the third would be projected onto the plane of the first and second feature.</p>\n\n<pre><code>plt.scatter(X[:,0], X[:,1], c=cluster_labels)\nplt.show()\n</code></pre>\n\n<p>You can also plot the 2nd and 3rd features, where the first feature is projected as</p>\n\n<pre><code>plt.scatter(X[:,1], X[:,2], c=cluster_labels)\nplt.show()\n</code></pre>\n\n<p>Projecting data naively can lead to problems so instead you can use a feature embedding method. Here I will give an example for 4 different methods: Isomap, MDS, spectral embedding and TSNE (my favorite).</p>\n\n<p>This is continuous data that I have access to but you can easily do the same for clustered data. Just set the labels $y$ as your determined clusters.</p>\n\n<pre><code>from sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.manifold import TSNE, SpectralEmbedding, Isomap, MDS\n\nboston = load_boston()\nX = boston.data\nY = boston.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n\n# Embed the features into 2 features using TSNE\nX_embedded_iso  = Isomap(n_components=2).fit_transform(X)\nX_embedded_mds  = MDS(n_components=2, max_iter=100, n_init=1).fit_transform(X)\nX_embedded_tsne = TSNE(n_components=2).fit_transform(X)\nX_embedded_spec = SpectralEmbedding(n_components=2).fit_transform(X)\n\nprint('Description of the dataset: \\n')\n\nprint('Input shape : ', X_train.shape)\nprint('Target shape: ', y_train.shape)\n\nprint('Embed the features into 2 features using Spectral Embedding: ', X_embedded_spec.shape)\nprint('Embed the features into 2 features using TSNE: ', X_embedded_tsne.shape)\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_iso[:,0], X_embedded_iso[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Isomap \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_mds[:,0], X_embedded_mds[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using MDS \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_spec[:,0], X_embedded_spec[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Spectral Embedding \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_tsne[:,0], X_embedded_tsne[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using TSNE \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/wypl0.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/wypl0.png\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/FGaak.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/FGaak.png\" alt=\"enter image description here\"></a></p>\n",
                        "",
                        "2"
                    ],
                    [
                        "31701",
                        "2",
                        "31700",
                        "",
                        "",
                        "<p><strong>Code Is Self Explanatory...</strong></p>\n\n<pre><code>    from sklearn.cluster import KMeans\n    from sklearn.datasets.samples_generator import make_blobs\n    np.random.seed(0)\n    centers = [[1, 1], [-1, -1]]\n    n_clusters = len(centers)\n    X, labels_true = make_blobs(n_samples=3000, \n                                centers=centers, \n                                cluster_std=0.5)\n\ndef plot_cluster_data(X, c=[1]*X.shape[0], mu=None):\n    fig = plt.figure(figsize=(8, 8))\n    ax = fig.add_subplot(1, 1, 1)\n    if len(np.unique(c)) == 1:\n        ax.plot(X[:,0], X[:,1], 'o')\n    else:\n        ix = np.where(c==1)\n        ax.plot(X[ix,0], X[ix,1], 'o', \n                markerfacecolor='red')\n        ax.plot(mu[0,0], mu[0,1], 'o', \n                markerfacecolor='red', \n                markersize=12)\n        ix = np.where(c==0)\n        ax.plot(X[ix,0], X[ix,1], 'o', \n                markerfacecolor='green')\n        ax.plot(mu[1,0], mu[1,1], 'o', \n                markerfacecolor='green', \n                markersize=12)\n    if not mu is None:\n        ax.plot(mu[0,0], mu[0,1], 'o', \n                markerfacecolor='red', \n                markersize=12)\n        ax.plot(mu[1,0], mu[1,1], 'o', \n                markerfacecolor='green', \n                markersize=12)        \n    plt.show()\n\nplot_cluster_data(X)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/Ut3yC.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Ut3yC.png\" alt=\"enter image description here\"></a></p>\n\n<pre><code>clst = KMeans(n_clusters=2, random_state=2342)\nclst.fit(X)\nmu = clst.cluster_centers_\nplot_cluster_data(X, mu = mu)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/Od7mk.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Od7mk.png\" alt=\"enter image description here\"></a></p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11326",
            "_score": 8.882747,
            "_source": {
                "title": "Confused about how to graph my high dimensional dataset with Kmeans",
                "content": "Confused about how to graph my high dimensional dataset with Kmeans <p><strong>PLEASE NO SKLEARN ANSWERS</strong></p>\n\n<p>So I have a dataset that is very high dimensional, and I am very confused about to convert it into a form that can be used to plot with Kmeans. Here is an example of what my dataset looks like:</p>\n\n<pre><code>Blk Students %       White Students %     Total Endowment    Full time Students     Tuition Revenue\n\n     35                    60               <span class=\"math-container\">$4,000,000             50000              $</span>4,999,999  \n     50                    50               <span class=\"math-container\">$5,888,888             67899              $</span>200,000,000\n     .                     .                    .                     .       \n     .                     .                    .                     .         \n</code></pre>\n\n<p>.   </p>\n\n<p>I have normalized my variables, converted everything to integers, etc... But I am confused about how I am supposed to take this high dimensional dataset and plot it on a 2D scatterplot for kmeans? Thanks in advance.</p>\n\n<p>To answer a question asked in the comments: there are 60 more columns than shown here.</p>\n <k-means><p>Your k-means should be applied in your high dimensional space. It does not need to be applied in 2D and will give you poorer results if you do this. Once you obtain the cluster label for each instance then you can plot it in 2D. However, we live in a 3D world thus we can only visualize 3D, 2D and 1D spatial dimensions. This means you can at most plot 3 variables in a spatial context, then you can maybe use the color of your points as a fourth dimension. If you really want to stretch it you can use the size of your points for a 5th dimension. But these plots will quickly get very convoluted. </p>\n\n<p>You can use dimensionality reduction techniques to project your high dimensional data onto 2 dimensions. What you are looking to do is perform some projection or feature compression (both of those terms mean the same thing in this context) onto a 2D plane while maintaining relative similarity. Many of these techniques exist each optimizing a different aspect of relative \"closeness\". </p>\n\n<p>The rest of this answer is taken from <a href=\"https://datascience.stackexchange.com/questions/37219/how-to-plot-high-dimensional-supervised-k-means-on-a-2d-plot-chart/37373#37373\">here</a>.</p>\n\n<hr>\n\n<p>The following code will show you 4 different algorithms which exist which can be used to plot high dimensional data in 2D. Although these algorithms are quite powerful you must remember that through any sort of projection a loss of information will result. Thus you will likely have to tune the parameters of these algorithms in order to best suit it for your data. In essence a good projection maintains relative distances between the in-groups and the out-groups.</p>\n\n<p>The Boston dataset has 13 features and a continuous label <span class=\"math-container\">$Y$</span> representing a housing price. We have 339 instances.</p>\n\n<pre><code>from sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.manifold import TSNE, SpectralEmbedding, Isomap, MDS\n\n\nbostonboston  ==  load_bostonload_bo ()\nX = boston.data\nY = boston.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n\n\n# Embed the features into 2 features using TSNE# Embed \nX_embedded_iso  = Isomap(n_components=2).fit_transform(X)\nX_embedded_mds  = MDS(n_components=2, max_iter=100, n_init=1).fit_transform(X)\nX_embedded_tsne = TSNE(n_components=2).fit_transform(X)\nX_embedded_spec = SpectralEmbedding(n_components=2).fit_transform(X)\n\nprint('Description of the dataset: \\n')\n\nprint('Input shape : ', X_train.shape)\nprint('Target shape: ', y_train.shape)\n\nplt.plot(Y)\nplt.title('Distribution of the prices of the homes in the Boston area')\nplt.xlabel('Instance')\nplt.ylabel('Price')\nplt.show()\n\nprint('Embed the features into 2 features using Spectral Embedding: ', X_embedded_spec.shape)\nprint('Embed the features into 2 features using TSNE: ', X_embedded_tsne.shape)\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_iso[:,0], X_embedded_iso[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Isomap \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_mds[:,0], X_embedded_mds[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using MDS \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_spec[:,0], X_embedded_spec[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Spectral Embedding \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_tsne[:,0], X_embedded_tsne[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using TSNE \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n</code></pre>\n\n<p>The target <span class=\"math-container\">$Y$</span> looks like:</p>\n\n<p><a href=\"https://i.stack.imgur.com/GrtVE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/GrtVE.png\" alt=\"enter image description here\"></a></p>\n\n<p>The projected data using the 4 techniques is shown below. The color of the points represents the housing price.</p>\n\n<p><a href=\"https://i.stack.imgur.com/kHyRH.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/kHyRH.png\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/OZTnA.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/OZTnA.png\" alt=\"enter image description here\"></a></p>\n\n<p>You can see that these 4 algorithms resulted in vastly different plots, but they all seemed to maintain the similarity between the targets. There are more options than these 4 algorithms of course. Another useful term for these techniques is called manifolds, embeddings, etc.</p>\n\n<p>Check out the sklearn page: <a href=\"http://scikit-learn.org/stable/modules/classes.html#module-sklearn.manifold\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/classes.html#module-sklearn.manifold</a>.</p>\n<p>There are a number of ways to plot high dimensional data. Matplotlib supports 3D plotting, so I assume you won't be having a problem plotting the 3 dimensions on x, y, and z-axis of the graph. However, for higher dimensions, you can use colors and symbols. For instance, if you plot normalized full-time students along x-axis, total endowment as along y-axis, and tuition revenue as z-axis on a 3D plot, then you can plot, for instance, a colored triangle for the %ge of your first column, and the color can be a heat map value, where blue shows low percentage, red shows a high percentage. Similarly, you can use a color-map square, or a circle to show plots of your second column.</p>\n\n<p>This is, no doubt, one idea to do it. But other techniques can be, that you perform some dimensionality reduction and visualize meaningful information, or you can divide a high-dimensional data into several occurrences of a lower dimensional data, and plot all of them as subplots of a single large plot.</p>\n",
                "codes": [
                    [
                        "from sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.manifold import TSNE, SpectralEmbedding, Isomap, MDS\n\n\nbostonboston  ==  load_bostonload_bo ()\nX = boston.data\nY = boston.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n\n\n# Embed the features into 2 features using TSNE# Embed \nX_embedded_iso  = Isomap(n_components=2).fit_transform(X)\nX_embedded_mds  = MDS(n_components=2, max_iter=100, n_init=1).fit_transform(X)\nX_embedded_tsne = TSNE(n_components=2).fit_transform(X)\nX_embedded_spec = SpectralEmbedding(n_components=2).fit_transform(X)\n\nprint('Description of the dataset: \\n')\n\nprint('Input shape : ', X_train.shape)\nprint('Target shape: ', y_train.shape)\n\nplt.plot(Y)\nplt.title('Distribution of the prices of the homes in the Boston area')\nplt.xlabel('Instance')\nplt.ylabel('Price')\nplt.show()\n\nprint('Embed the features into 2 features using Spectral Embedding: ', X_embedded_spec.shape)\nprint('Embed the features into 2 features using TSNE: ', X_embedded_tsne.shape)\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_iso[:,0], X_embedded_iso[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Isomap \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_mds[:,0], X_embedded_mds[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using MDS \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_spec[:,0], X_embedded_spec[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Spectral Embedding \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_tsne[:,0], X_embedded_tsne[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using TSNE \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n"
                    ],
                    []
                ],
                "question_id:": "39986",
                "question_votes:": "",
                "question_text:": "<p><strong>PLEASE NO SKLEARN ANSWERS</strong></p>\n\n<p>So I have a dataset that is very high dimensional, and I am very confused about to convert it into a form that can be used to plot with Kmeans. Here is an example of what my dataset looks like:</p>\n\n<pre><code>Blk Students %       White Students %     Total Endowment    Full time Students     Tuition Revenue\n\n     35                    60               <span class=\"math-container\">$4,000,000             50000              $</span>4,999,999  \n     50                    50               <span class=\"math-container\">$5,888,888             67899              $</span>200,000,000\n     .                     .                    .                     .       \n     .                     .                    .                     .         \n</code></pre>\n\n<p>.   </p>\n\n<p>I have normalized my variables, converted everything to integers, etc... But I am confused about how I am supposed to take this high dimensional dataset and plot it on a 2D scatterplot for kmeans? Thanks in advance.</p>\n\n<p>To answer a question asked in the comments: there are 60 more columns than shown here.</p>\n",
                "tags": "<k-means>",
                "answers": [
                    [
                        "39990",
                        "2",
                        "39986",
                        "",
                        "",
                        "<p>Your k-means should be applied in your high dimensional space. It does not need to be applied in 2D and will give you poorer results if you do this. Once you obtain the cluster label for each instance then you can plot it in 2D. However, we live in a 3D world thus we can only visualize 3D, 2D and 1D spatial dimensions. This means you can at most plot 3 variables in a spatial context, then you can maybe use the color of your points as a fourth dimension. If you really want to stretch it you can use the size of your points for a 5th dimension. But these plots will quickly get very convoluted. </p>\n\n<p>You can use dimensionality reduction techniques to project your high dimensional data onto 2 dimensions. What you are looking to do is perform some projection or feature compression (both of those terms mean the same thing in this context) onto a 2D plane while maintaining relative similarity. Many of these techniques exist each optimizing a different aspect of relative \"closeness\". </p>\n\n<p>The rest of this answer is taken from <a href=\"https://datascience.stackexchange.com/questions/37219/how-to-plot-high-dimensional-supervised-k-means-on-a-2d-plot-chart/37373#37373\">here</a>.</p>\n\n<hr>\n\n<p>The following code will show you 4 different algorithms which exist which can be used to plot high dimensional data in 2D. Although these algorithms are quite powerful you must remember that through any sort of projection a loss of information will result. Thus you will likely have to tune the parameters of these algorithms in order to best suit it for your data. In essence a good projection maintains relative distances between the in-groups and the out-groups.</p>\n\n<p>The Boston dataset has 13 features and a continuous label <span class=\"math-container\">$Y$</span> representing a housing price. We have 339 instances.</p>\n\n<pre><code>from sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.manifold import TSNE, SpectralEmbedding, Isomap, MDS\n\n\nbostonboston  ==  load_bostonload_bo ()\nX = boston.data\nY = boston.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n\n\n# Embed the features into 2 features using TSNE# Embed \nX_embedded_iso  = Isomap(n_components=2).fit_transform(X)\nX_embedded_mds  = MDS(n_components=2, max_iter=100, n_init=1).fit_transform(X)\nX_embedded_tsne = TSNE(n_components=2).fit_transform(X)\nX_embedded_spec = SpectralEmbedding(n_components=2).fit_transform(X)\n\nprint('Description of the dataset: \\n')\n\nprint('Input shape : ', X_train.shape)\nprint('Target shape: ', y_train.shape)\n\nplt.plot(Y)\nplt.title('Distribution of the prices of the homes in the Boston area')\nplt.xlabel('Instance')\nplt.ylabel('Price')\nplt.show()\n\nprint('Embed the features into 2 features using Spectral Embedding: ', X_embedded_spec.shape)\nprint('Embed the features into 2 features using TSNE: ', X_embedded_tsne.shape)\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_iso[:,0], X_embedded_iso[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Isomap \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_mds[:,0], X_embedded_mds[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using MDS \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n\nfig = plt.figure(figsize=(12,5),facecolor='w')\nplt.subplot(1, 2, 1)\nplt.scatter(X_embedded_spec[:,0], X_embedded_spec[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using Spectral Embedding \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_embedded_tsne[:,0], X_embedded_tsne[:,1], c = Y, cmap = 'hot')\nplt.title('2D embedding using TSNE \\n The color of the points is the price')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.colorbar()\nplt.show()\nplt.tight_layout()\n</code></pre>\n\n<p>The target <span class=\"math-container\">$Y$</span> looks like:</p>\n\n<p><a href=\"https://i.stack.imgur.com/GrtVE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/GrtVE.png\" alt=\"enter image description here\"></a></p>\n\n<p>The projected data using the 4 techniques is shown below. The color of the points represents the housing price.</p>\n\n<p><a href=\"https://i.stack.imgur.com/kHyRH.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/kHyRH.png\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/OZTnA.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/OZTnA.png\" alt=\"enter image description here\"></a></p>\n\n<p>You can see that these 4 algorithms resulted in vastly different plots, but they all seemed to maintain the similarity between the targets. There are more options than these 4 algorithms of course. Another useful term for these techniques is called manifolds, embeddings, etc.</p>\n\n<p>Check out the sklearn page: <a href=\"http://scikit-learn.org/stable/modules/classes.html#module-sklearn.manifold\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/modules/classes.html#module-sklearn.manifold</a>.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "39989",
                        "2",
                        "39986",
                        "",
                        "",
                        "<p>There are a number of ways to plot high dimensional data. Matplotlib supports 3D plotting, so I assume you won't be having a problem plotting the 3 dimensions on x, y, and z-axis of the graph. However, for higher dimensions, you can use colors and symbols. For instance, if you plot normalized full-time students along x-axis, total endowment as along y-axis, and tuition revenue as z-axis on a 3D plot, then you can plot, for instance, a colored triangle for the %ge of your first column, and the color can be a heat map value, where blue shows low percentage, red shows a high percentage. Similarly, you can use a color-map square, or a circle to show plots of your second column.</p>\n\n<p>This is, no doubt, one idea to do it. But other techniques can be, that you perform some dimensionality reduction and visualize meaningful information, or you can divide a high-dimensional data into several occurrences of a lower dimensional data, and plot all of them as subplots of a single large plot.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3736",
            "_score": 8.868832,
            "_source": {
                "title": "How to compare the performance of feature selection methods?",
                "content": "How to compare the performance of feature selection methods? <p>There are several <strong>feature selection</strong> / variable selection approaches (see for example <a href=\"http://www.jmlr.org/papers/v3/guyon03a.html\" rel=\"noreferrer\">Guyon &amp; Elisseeff, 2003</a>; <a href=\"http://www.jmlr.org/proceedings/papers/v10/liu10b/liu10b.pdf\" rel=\"noreferrer\">Liu et al., 2010</a>): </p>\n\n<ul>\n<li>filter methods (e.g., correlation-based, entropy-based, random forest importance based),</li>\n<li>wrapper methods (e.g., forward-search, hill-climbing search), and </li>\n<li>embedded methods where the feature selection is part of the model learning. </li>\n</ul>\n\n<p>Many published algorithms are also implemented in the machine learning tools like R, Python, etc. </p>\n\n<p>What would be an appropriate method to compare different feature selection algorithms and to select the best method for a given problem / dataset? \nA further question would be, whether there are any metrics known that measure the performance of feature selection algorithms?</p>\n <feature-selection><performance><model-selection><p>This is a hard problem and researchers are making a lot of progress.</p>\n\n<p>If you're looking for <strong><em>supervised</em></strong> feature selection, I'd recommend <a href=\"http://statweb.stanford.edu/~tibs/lasso.html\" rel=\"nofollow noreferrer\">LASSO</a> and its variants. Evaluation of the algorithm is very straightforward with supervised learning: the performance of whichever metric you choose on test data.</p>\n\n<p>Two major caveats of LASSO are that (1) the selected features will not automatically detect an interaction, so you have to craft all of your features a priori (i.e., before running them through the model) and (2) LASSO will not identify non-linear relationships (e.g., <a href=\"https://stats.stackexchange.com/questions/211534/how-to-interpret-quadratic-terms\">a quadratic relationship</a>).</p>\n\n<p>A way to try and get past these two caveats is to use <a href=\"http://www-stat.stanford.edu/~jhf/ftp/trebst.pdf\" rel=\"nofollow noreferrer\">Gradient Boosted Machines</a> which does feature selection automatically. It's worth noting the statistical properties of GBM are a little more ambiguous than that of the LASSO. </p>\n\n<p>If you're looking for unsupervised feature selection, it seems there's a similar regularization approach used by <a href=\"http://www.ijcai.org/Proceedings/13/Papers/241.pdf\" rel=\"nofollow noreferrer\">these</a> researchers, but evaluation in this particular case becomes less obvious. People try a lot of different things like PCA/SVD or K-Means which ultimately will try to find a linear approximation to the data. </p>\n\n<p>In that case, the typical measures of performance are the reconstruction error or the RMSE of the clusters.</p>\n\n<p>In terms of software, R and Python both have GBM, LASSO, K-Means, SVD, and PCA. GLMNET and XGBoost in R and Sklearn for Python are the relevant libraries.</p>\n<p>I always consider features selection as a step to a final result.</p>\n\n<p>Hereunder, I somehow mix features selection and dimensionality reduction, which might have some goals and can be confused.</p>\n\n<p>Some typical uses:</p>\n\n<ul>\n<li><p>reduction of computations in machine learning: the quality of the selection is a factor of the final learning result and also, obviously, the speed to get that learning done</p></li>\n<li><p>visualization/understanding of the data, where you combine eventually multiple dimensions. It is good when it doesn't hides interesting stuffs, and when that's understandable</p></li>\n<li><p>simplification of the learning results, still to make them understandable (eg root cause analysis). Good if simple but still sufficient in terms of quality</p></li>\n<li><p>controlling over fitting, as the previous reply suggests</p></li>\n<li><p>...</p></li>\n</ul>\n\n<p>So, I don't think there's general rule (as always in ML), but this is a case by case problem.</p>\n\n<p>Just a personal belief...</p>\n<p>It's very dependent on the specific situation and the problem you want to solve. There exist some general rules, for example <em>wrapper methods</em> are more flexible and also more prone to overfitting.</p>\n\n<p>Feature selection performance can be evaluated by the overall performance of learning task for example one can select features with different methods and then use these different feature sets for classification and compare the precision of obtained classifiers. </p>\n\n<p>Another important factor in some scenarios like some biological applications is the interpretability of selected features and the results, for example  in a clustering problem, meaning of selected features and resulted clusters is a very important measure of performance. </p>\n<p>You would have to run a set of artificial tests, trying to detect relevant features using different methods while knowing in advance which subsets of input variables affect the output variable.</p>\n\n<p>Good trick would be to keep a set of random input variables with different distributions and make sure your feature selection algos indeed tag them as not relevant.</p>\n\n<p>Another trick would be to make sure that after permuting rows the variables tagged as relevant stop being classified as relevant.</p>\n\n<p>Above said applies to both filter and wrapper approaches.</p>\n\n<p>Also be sure to handle cases when if taken separately (one by one) variables do not show any influence on the target, but when taken jointly reveal a strong dependence. Example would be a well-known XOR problem (check out the Python code):</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import f_regression, mutual_info_regression,mutual_info_classif\n\nx=np.random.randn(5000,3)\ny=np.where(np.logical_xor(x[:,0]&gt;0,x[:,1]&gt;0),1,0)\n\nplt.scatter(x[y==1,0],x[y==1,1],c='r',marker='x')\nplt.scatter(x[y==0,0],x[y==0,1],c='b',marker='o')\nplt.show()\nprint(mutual_info_classif(x, y)) \n</code></pre>\n\n<p>Output:</p>\n\n<p><a href=\"https://i.stack.imgur.com/14ry4.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/14ry4.png\" alt=\"Python 3 XOR illustration\"></a></p>\n\n<p>[ 0.          0.          0.00429746]</p>\n\n<p>So, presumably powerful (but univariate) filtering method (computing of mutual information between out- and input variables) was not able to detect any relationships in the dataset. Whereas we know for sure it's a 100% dependency and we can predict Y with 100% accuracy knowing X.</p>\n\n<p>Good idea would be to create a kind of benchmark for features selection methods, does anyone want to participate?</p>\n",
                "codes": [
                    [],
                    [],
                    [],
                    [
                        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import f_regression, mutual_info_regression,mutual_info_classif\n\nx=np.random.randn(5000,3)\ny=np.where(np.logical_xor(x[:,0]>0,x[:,1]>0),1,0)\n\nplt.scatter(x[y==1,0],x[y==1,1],c='r',marker='x')\nplt.scatter(x[y==0,0],x[y==0,1],c='b',marker='o')\nplt.show()\nprint(mutual_info_classif(x, y)) \n"
                    ]
                ],
                "question_id:": "15553",
                "question_votes:": "10",
                "question_text:": "<p>There are several <strong>feature selection</strong> / variable selection approaches (see for example <a href=\"http://www.jmlr.org/papers/v3/guyon03a.html\" rel=\"noreferrer\">Guyon &amp; Elisseeff, 2003</a>; <a href=\"http://www.jmlr.org/proceedings/papers/v10/liu10b/liu10b.pdf\" rel=\"noreferrer\">Liu et al., 2010</a>): </p>\n\n<ul>\n<li>filter methods (e.g., correlation-based, entropy-based, random forest importance based),</li>\n<li>wrapper methods (e.g., forward-search, hill-climbing search), and </li>\n<li>embedded methods where the feature selection is part of the model learning. </li>\n</ul>\n\n<p>Many published algorithms are also implemented in the machine learning tools like R, Python, etc. </p>\n\n<p>What would be an appropriate method to compare different feature selection algorithms and to select the best method for a given problem / dataset? \nA further question would be, whether there are any metrics known that measure the performance of feature selection algorithms?</p>\n",
                "tags": "<feature-selection><performance><model-selection>",
                "answers": [
                    [
                        "15562",
                        "2",
                        "15553",
                        "",
                        "",
                        "<p>This is a hard problem and researchers are making a lot of progress.</p>\n\n<p>If you're looking for <strong><em>supervised</em></strong> feature selection, I'd recommend <a href=\"http://statweb.stanford.edu/~tibs/lasso.html\" rel=\"nofollow noreferrer\">LASSO</a> and its variants. Evaluation of the algorithm is very straightforward with supervised learning: the performance of whichever metric you choose on test data.</p>\n\n<p>Two major caveats of LASSO are that (1) the selected features will not automatically detect an interaction, so you have to craft all of your features a priori (i.e., before running them through the model) and (2) LASSO will not identify non-linear relationships (e.g., <a href=\"https://stats.stackexchange.com/questions/211534/how-to-interpret-quadratic-terms\">a quadratic relationship</a>).</p>\n\n<p>A way to try and get past these two caveats is to use <a href=\"http://www-stat.stanford.edu/~jhf/ftp/trebst.pdf\" rel=\"nofollow noreferrer\">Gradient Boosted Machines</a> which does feature selection automatically. It's worth noting the statistical properties of GBM are a little more ambiguous than that of the LASSO. </p>\n\n<p>If you're looking for unsupervised feature selection, it seems there's a similar regularization approach used by <a href=\"http://www.ijcai.org/Proceedings/13/Papers/241.pdf\" rel=\"nofollow noreferrer\">these</a> researchers, but evaluation in this particular case becomes less obvious. People try a lot of different things like PCA/SVD or K-Means which ultimately will try to find a linear approximation to the data. </p>\n\n<p>In that case, the typical measures of performance are the reconstruction error or the RMSE of the clusters.</p>\n\n<p>In terms of software, R and Python both have GBM, LASSO, K-Means, SVD, and PCA. GLMNET and XGBoost in R and Sklearn for Python are the relevant libraries.</p>\n",
                        "",
                        "4"
                    ],
                    [
                        "15580",
                        "2",
                        "15553",
                        "",
                        "",
                        "<p>I always consider features selection as a step to a final result.</p>\n\n<p>Hereunder, I somehow mix features selection and dimensionality reduction, which might have some goals and can be confused.</p>\n\n<p>Some typical uses:</p>\n\n<ul>\n<li><p>reduction of computations in machine learning: the quality of the selection is a factor of the final learning result and also, obviously, the speed to get that learning done</p></li>\n<li><p>visualization/understanding of the data, where you combine eventually multiple dimensions. It is good when it doesn't hides interesting stuffs, and when that's understandable</p></li>\n<li><p>simplification of the learning results, still to make them understandable (eg root cause analysis). Good if simple but still sufficient in terms of quality</p></li>\n<li><p>controlling over fitting, as the previous reply suggests</p></li>\n<li><p>...</p></li>\n</ul>\n\n<p>So, I don't think there's general rule (as always in ML), but this is a case by case problem.</p>\n\n<p>Just a personal belief...</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "17611",
                        "2",
                        "15553",
                        "",
                        "",
                        "<p>It's very dependent on the specific situation and the problem you want to solve. There exist some general rules, for example <em>wrapper methods</em> are more flexible and also more prone to overfitting.</p>\n\n<p>Feature selection performance can be evaluated by the overall performance of learning task for example one can select features with different methods and then use these different feature sets for classification and compare the precision of obtained classifiers. </p>\n\n<p>Another important factor in some scenarios like some biological applications is the interpretability of selected features and the results, for example  in a clustering problem, meaning of selected features and resulted clusters is a very important measure of performance. </p>\n",
                        "",
                        ""
                    ],
                    [
                        "23337",
                        "2",
                        "15553",
                        "",
                        "",
                        "<p>You would have to run a set of artificial tests, trying to detect relevant features using different methods while knowing in advance which subsets of input variables affect the output variable.</p>\n\n<p>Good trick would be to keep a set of random input variables with different distributions and make sure your feature selection algos indeed tag them as not relevant.</p>\n\n<p>Another trick would be to make sure that after permuting rows the variables tagged as relevant stop being classified as relevant.</p>\n\n<p>Above said applies to both filter and wrapper approaches.</p>\n\n<p>Also be sure to handle cases when if taken separately (one by one) variables do not show any influence on the target, but when taken jointly reveal a strong dependence. Example would be a well-known XOR problem (check out the Python code):</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import f_regression, mutual_info_regression,mutual_info_classif\n\nx=np.random.randn(5000,3)\ny=np.where(np.logical_xor(x[:,0]&gt;0,x[:,1]&gt;0),1,0)\n\nplt.scatter(x[y==1,0],x[y==1,1],c='r',marker='x')\nplt.scatter(x[y==0,0],x[y==0,1],c='b',marker='o')\nplt.show()\nprint(mutual_info_classif(x, y)) \n</code></pre>\n\n<p>Output:</p>\n\n<p><a href=\"https://i.stack.imgur.com/14ry4.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/14ry4.png\" alt=\"Python 3 XOR illustration\"></a></p>\n\n<p>[ 0.          0.          0.00429746]</p>\n\n<p>So, presumably powerful (but univariate) filtering method (computing of mutual information between out- and input variables) was not able to detect any relationships in the dataset. Whereas we know for sure it's a 100% dependency and we can predict Y with 100% accuracy knowing X.</p>\n\n<p>Good idea would be to create a kind of benchmark for features selection methods, does anyone want to participate?</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12370",
            "_score": 8.683941,
            "_source": {
                "title": "how to evaluate feature quality for decision tree model",
                "content": "how to evaluate feature quality for decision tree model <p>Most of the tutorials assume that the features are known before generating the model and give no way to select 'good' feature and to discard 'bad' ones.</p>\n\n<p>The naive method is to test the model with new features and see how the new results change compared to the previous model but it can be complex to interpret when the tree is complex.</p>\n\n<p>Is there an academic way to select good features and to discard bad ones? </p>\n\n<p>(ressources appreciated)</p>\n <feature-selection><decision-trees><feature-engineering><feature-construction><p>Another approach to evaluate features is called <a href=\"https://doi.org/10.1093/bioinformatics/btq134\" rel=\"nofollow noreferrer\">Permutation Importance</a>. In short, this approach is random sampling values of each feature and each time measuring the negative impact this has on the model performance. The feature for which random sampling of its values has highest negative impact on the model performance is considered as most important to the model.</p>\n<p>I have no reputation to add a comment. I think Marcelo Silva gave a very nice answer (don't know how to link his name). In \"Mu\u00f1oz-Mas, R., Fukuda, S., Vezza, P., Mart\u00ednez-Capel, F., 2016. Comparing four methods for decision-tree induction: A case study on the invasive Iberian gudgeon (Gobio lozanoi; Doadrio and Madeira, 2004). Ecol. Inform. 34, 22\u201334. 10.1016/j.ecoinf.2016.04.011\" we used a wrapper approach to simultaneously search for the best hyper-parameters and variables\u2019 subset using cross-validation and a genetic algorithm. We made a nice review in that paper so it maybe deserves a check. The forest-based variant is currently on review. I'm the first author so write me in case you want to discuss anything about trees and forests. An alternative will be to use conditional random forests \u201cStrobl, C., Hothorn, Zeileis, A., 2009. Party on! R J. 1 (2), 14\u201317. (and linked references)\u201d employing the entire variables subset to then use sequentially only those that proved most relevant to train the decision-tree. Nevertheless, take into account that hyper-parameters play a role in the final decision-tree so they will need also some tuning. In case you are not interested on interpretability I would use a forest instead of a single decision-tree.\nGood luck.  </p>\n<p>The main reasons for seeking an efficient feature selection are the machine learning algorithm get faster training, reduces the complexity of a model, facilitates interpretation and improves the accuracy of a model.</p>\n\n<p>Look for Filter Methods , Wrapper Methods and Embedded Methods to learn more about your issue.</p>\n\n<p>Filter methods are generally used as a preprocessing step. The selection of features is independent of any machine learning algorithms. Instead, features are selected on the basis of their scores in various statistical tests for their correlation with the outcome variable.  Here you have to look for Linear discriminant analysis, Pearson\u2019s Correlation, Chi-Square. </p>\n\n<p>Some common examples of wrapper methods are :</p>\n\n<p>Forward Selection: Is an iterative method in which we start with having no feature in the model. In each iteration, we keep adding the feature which best improves our model till an addition of a new variable does not improve the performance of the model.</p>\n\n<p>Backward Elimination: Here, we start with all the features and removes the least significant feature at each iteration which improves the performance of the model. We repeat this until no improvement is observed on removal of features.</p>\n\n<p>Recursive Feature elimination: It is a greedy optimization algorithm which aims to find the best performing feature subset. It repeatedly creates models and keeps aside the best or the worst performing feature at each iteration. It constructs the next model with the left features until all the features are exhausted. It then ranks the features based on the order of their elimination.</p>\n\n<p>Embedded methods combine the qualities\u2019 of filter and wrapper methods. It\u2019s implemented by algorithms that have their own built-in feature selection methods.</p>\n\n<p>Some of the most popular examples of these methods are LASSO and RIDGE regression which have inbuilt penalization functions to reduce overfitting.</p>\n\n<p>Other example of embedded methods that could fits you is Regularized trees.</p>\n\n<p>follow the link with some of these algorithms in sklearn.</p>\n\n<p><a href=\"https://scikit-learn.org/stable/modules/feature_selection.html#feature-selection\" rel=\"nofollow noreferrer\">sklearn - Feature Selection</a></p>\n\n<p>I hope this could help you to start.</p>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "43444",
                "question_votes:": "3",
                "question_text:": "<p>Most of the tutorials assume that the features are known before generating the model and give no way to select 'good' feature and to discard 'bad' ones.</p>\n\n<p>The naive method is to test the model with new features and see how the new results change compared to the previous model but it can be complex to interpret when the tree is complex.</p>\n\n<p>Is there an academic way to select good features and to discard bad ones? </p>\n\n<p>(ressources appreciated)</p>\n",
                "tags": "<feature-selection><decision-trees><feature-engineering><feature-construction>",
                "answers": [
                    [
                        "43478",
                        "2",
                        "43444",
                        "",
                        "",
                        "<p>Another approach to evaluate features is called <a href=\"https://doi.org/10.1093/bioinformatics/btq134\" rel=\"nofollow noreferrer\">Permutation Importance</a>. In short, this approach is random sampling values of each feature and each time measuring the negative impact this has on the model performance. The feature for which random sampling of its values has highest negative impact on the model performance is considered as most important to the model.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "43662",
                        "2",
                        "43444",
                        "",
                        "",
                        "<p>I have no reputation to add a comment. I think Marcelo Silva gave a very nice answer (don't know how to link his name). In \"Mu\u00f1oz-Mas, R., Fukuda, S., Vezza, P., Mart\u00ednez-Capel, F., 2016. Comparing four methods for decision-tree induction: A case study on the invasive Iberian gudgeon (Gobio lozanoi; Doadrio and Madeira, 2004). Ecol. Inform. 34, 22\u201334. 10.1016/j.ecoinf.2016.04.011\" we used a wrapper approach to simultaneously search for the best hyper-parameters and variables\u2019 subset using cross-validation and a genetic algorithm. We made a nice review in that paper so it maybe deserves a check. The forest-based variant is currently on review. I'm the first author so write me in case you want to discuss anything about trees and forests. An alternative will be to use conditional random forests \u201cStrobl, C., Hothorn, Zeileis, A., 2009. Party on! R J. 1 (2), 14\u201317. (and linked references)\u201d employing the entire variables subset to then use sequentially only those that proved most relevant to train the decision-tree. Nevertheless, take into account that hyper-parameters play a role in the final decision-tree so they will need also some tuning. In case you are not interested on interpretability I would use a forest instead of a single decision-tree.\nGood luck.  </p>\n",
                        "",
                        ""
                    ],
                    [
                        "43448",
                        "2",
                        "43444",
                        "",
                        "",
                        "<p>The main reasons for seeking an efficient feature selection are the machine learning algorithm get faster training, reduces the complexity of a model, facilitates interpretation and improves the accuracy of a model.</p>\n\n<p>Look for Filter Methods , Wrapper Methods and Embedded Methods to learn more about your issue.</p>\n\n<p>Filter methods are generally used as a preprocessing step. The selection of features is independent of any machine learning algorithms. Instead, features are selected on the basis of their scores in various statistical tests for their correlation with the outcome variable.  Here you have to look for Linear discriminant analysis, Pearson\u2019s Correlation, Chi-Square. </p>\n\n<p>Some common examples of wrapper methods are :</p>\n\n<p>Forward Selection: Is an iterative method in which we start with having no feature in the model. In each iteration, we keep adding the feature which best improves our model till an addition of a new variable does not improve the performance of the model.</p>\n\n<p>Backward Elimination: Here, we start with all the features and removes the least significant feature at each iteration which improves the performance of the model. We repeat this until no improvement is observed on removal of features.</p>\n\n<p>Recursive Feature elimination: It is a greedy optimization algorithm which aims to find the best performing feature subset. It repeatedly creates models and keeps aside the best or the worst performing feature at each iteration. It constructs the next model with the left features until all the features are exhausted. It then ranks the features based on the order of their elimination.</p>\n\n<p>Embedded methods combine the qualities\u2019 of filter and wrapper methods. It\u2019s implemented by algorithms that have their own built-in feature selection methods.</p>\n\n<p>Some of the most popular examples of these methods are LASSO and RIDGE regression which have inbuilt penalization functions to reduce overfitting.</p>\n\n<p>Other example of embedded methods that could fits you is Regularized trees.</p>\n\n<p>follow the link with some of these algorithms in sklearn.</p>\n\n<p><a href=\"https://scikit-learn.org/stable/modules/feature_selection.html#feature-selection\" rel=\"nofollow noreferrer\">sklearn - Feature Selection</a></p>\n\n<p>I hope this could help you to start.</p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17999",
            "_score": 8.477636,
            "_source": {
                "title": "Modeling strategy for predicting a day/hour based on my dataset",
                "content": "Modeling strategy for predicting a day/hour based on my dataset <p>This is my first time posting here. I'm usually on SO. So I'm not sure if these kind of questions fit into DS stackexchange. I genuinely need opinions on this.</p>\n\n<p><strong>What data do I have -</strong> </p>\n\n<pre><code>+-----------+------------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+------+-------+------+-------+------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------+----------+----------+----------+\n|    Day    |    Date    | 0:0 | 0:30 | 1:0 | 1:30 | 2:0 | 2:30 | 3:0 | 3:30 | 4:0 | 4:30 | 5:0 | 5:30 | 6:0 | 6:30 | 7:0 | 7:30 | 8:0 | 8:30 | 9:0 | 9:30 | 10:0 | 10:30 | 11:0 | 11:30 | 12:0 | 12:30 pm | 1:00 pm | 1:30 pm | 2:00 pm | 2:30 pm | 3:00 pm | 3:30 pm | 4:00 pm | 4:30 pm | 5:00 pm | 5:30 pm | 6:00 pm | 6:30 pm | 7:00 pm | 7:30 pm | 8:00 pm | 8:30 pm | 9:00 pm | 9:30 pm | 10:00 pm | 10:30 pm | 11:00 pm | 11:30 pm |\n+-----------+------------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+------+-------+------+-------+------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------+----------+----------+----------+\n| Tuesday   | 01/01/2019 |   2 |    2 |   2 |    2 |   2 |    2 |   2 |    2 |   2 |    1 |   1 |    1 |   1 |    1 |   1 |    1 |   1 |    1 |   1 |    1 |    1 |     1 |    1 |     1 |    9 |        9 |       8 |       8 |       8 |       8 |       1 |       1 |       9 |       4 |      10 |      10 |       8 |       8 |       8 |       4 |       4 |       8 |       8 |       8 |        4 |        8 |        5 |        5 |\n| Wednesday | 02/01/2019 |   8 |    9 |   1 |    1 |   1 |    1 |   1 |    1 |   1 |    1 |   1 |    1 |   1 |    1 |   1 |    1 |   1 |    1 |   9 |    9 |    5 |     9 |    3 |     3 |    3 |        3 |       3 |       3 |       3 |       3 |       3 |       3 |       3 |       3 |       3 |       9 |       1 |       1 |       1 |       9 |      12 |      12 |       3 |       3 |       10 |       10 |        4 |        4 |\n+-----------+------------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+------+-------+------+-------+------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------+----------+----------+----------+\n</code></pre>\n\n<p>Each row is a day with 48 columns. Each column is half an hour of clock, starting from midnight to 11:30pm. Each number in the column represents a particular category. </p>\n\n<p>For instance, if we see the first row of <code>Tuesday</code> at column <code>0:0</code>, the value is 2. Here 2 represents category - Social Time. Similarly, 1 represents category - sleep and <strong>all numbers state what I was doing at that particular hour of day.</strong></p>\n\n<p>I have this data for about last 2 years so around 700 x 48 data points.</p>\n\n<hr>\n\n<p><strong>What am I aiming for -</strong></p>\n\n<p>Based on this data, I want to predict my next/future day or hour </p>\n\n<p><strong>Where am I stuck -</strong> </p>\n\n<p>My predictor variable is the <code>entire row</code> (the day) or a single <code>column</code> (30 mins). My first thought was to pivot the whole data, do one-hot encoding for each response variable and then think on which classification model to apply. But then each day is also related to the day before it. So it's merely not a classification problem. There's some regression to it as well.</p>\n\n<p>I'm having hard time in which way should I prepare the data and proceed.</p>\n\n<hr>\n\n<p><strong>What am I asking for -</strong></p>\n\n<blockquote>\n  <p>An approach to handle this kind of dataset.</p>\n</blockquote>\n\n<p>I'm not necessarily looking for which model to apply. My primary concern is to understand <code>in which way</code> to prepare my data such that it is ready for consumption in a model.</p>\n\n<p>Any help, guidance, similar Q&amp;A or related article will be helpful.</p>\n <python><classification><regression><predictive-modeling><model-selection><p>I can think of two ways for doing this.</p>\n\n<p>One would be to have the same data structure as you currently have. Then you can train any regression model with all of your columns as features. You can use LinearRegressor or RandomForestRegressor , etc. Then to predict multiple values as in multiple columns you need to use something like \"<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html\" rel=\"nofollow noreferrer\">multioutputregressor</a>\". This way you are feeding the model data of one day and model predicts the next day for you. So you can get multiple predictions (output) out of the model.</p>\n\n<p>The other way that you can do this is to convert your columns into multiple rows. For example you can have something like this:</p>\n\n<pre><code>+-----------+-----------------+-------+\n|    Day    |    Date         | value |\n+-----------+-----------------+-------+ \n| Tuesday   | 01/01/2019 0:0  |   2   |\n| Tuesday   | 02/01/2019 0:30 |   2   |\n| Tuesday   | 02/01/2019 1:0  |   2   |\n| Tuesday   | 02/01/2019 1:30 |   2   |\n| Tuesday   | 02/01/2019 2:0  |   2   |\n| Tuesday   | 02/01/2019 2:30 |   2   |\n+-----------+-----------------+-------+\n</code></pre>\n\n<p>Then you can use one of the Regressor models as mentioned above, to predict one row, that is one half an hour. Then you can put this prediction back into the data, train the model again and predict for the next half an hour. You can continue to do this until you have a complete day of predictions. </p>\n\n<p>Hope this helps,</p>\n",
                "codes": [
                    [
                        "+-----------+-----------------+-------+\n|    Day    |    Date         | value |\n+-----------+-----------------+-------+ \n| Tuesday   | 01/01/2019 0:0  |   2   |\n| Tuesday   | 02/01/2019 0:30 |   2   |\n| Tuesday   | 02/01/2019 1:0  |   2   |\n| Tuesday   | 02/01/2019 1:30 |   2   |\n| Tuesday   | 02/01/2019 2:0  |   2   |\n| Tuesday   | 02/01/2019 2:30 |   2   |\n+-----------+-----------------+-------+\n"
                    ]
                ],
                "question_id:": "57461",
                "question_votes:": "1",
                "question_text:": "<p>This is my first time posting here. I'm usually on SO. So I'm not sure if these kind of questions fit into DS stackexchange. I genuinely need opinions on this.</p>\n\n<p><strong>What data do I have -</strong> </p>\n\n<pre><code>+-----------+------------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+------+-------+------+-------+------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------+----------+----------+----------+\n|    Day    |    Date    | 0:0 | 0:30 | 1:0 | 1:30 | 2:0 | 2:30 | 3:0 | 3:30 | 4:0 | 4:30 | 5:0 | 5:30 | 6:0 | 6:30 | 7:0 | 7:30 | 8:0 | 8:30 | 9:0 | 9:30 | 10:0 | 10:30 | 11:0 | 11:30 | 12:0 | 12:30 pm | 1:00 pm | 1:30 pm | 2:00 pm | 2:30 pm | 3:00 pm | 3:30 pm | 4:00 pm | 4:30 pm | 5:00 pm | 5:30 pm | 6:00 pm | 6:30 pm | 7:00 pm | 7:30 pm | 8:00 pm | 8:30 pm | 9:00 pm | 9:30 pm | 10:00 pm | 10:30 pm | 11:00 pm | 11:30 pm |\n+-----------+------------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+------+-------+------+-------+------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------+----------+----------+----------+\n| Tuesday   | 01/01/2019 |   2 |    2 |   2 |    2 |   2 |    2 |   2 |    2 |   2 |    1 |   1 |    1 |   1 |    1 |   1 |    1 |   1 |    1 |   1 |    1 |    1 |     1 |    1 |     1 |    9 |        9 |       8 |       8 |       8 |       8 |       1 |       1 |       9 |       4 |      10 |      10 |       8 |       8 |       8 |       4 |       4 |       8 |       8 |       8 |        4 |        8 |        5 |        5 |\n| Wednesday | 02/01/2019 |   8 |    9 |   1 |    1 |   1 |    1 |   1 |    1 |   1 |    1 |   1 |    1 |   1 |    1 |   1 |    1 |   1 |    1 |   9 |    9 |    5 |     9 |    3 |     3 |    3 |        3 |       3 |       3 |       3 |       3 |       3 |       3 |       3 |       3 |       3 |       9 |       1 |       1 |       1 |       9 |      12 |      12 |       3 |       3 |       10 |       10 |        4 |        4 |\n+-----------+------------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+-----+------+------+-------+------+-------+------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------+----------+----------+----------+\n</code></pre>\n\n<p>Each row is a day with 48 columns. Each column is half an hour of clock, starting from midnight to 11:30pm. Each number in the column represents a particular category. </p>\n\n<p>For instance, if we see the first row of <code>Tuesday</code> at column <code>0:0</code>, the value is 2. Here 2 represents category - Social Time. Similarly, 1 represents category - sleep and <strong>all numbers state what I was doing at that particular hour of day.</strong></p>\n\n<p>I have this data for about last 2 years so around 700 x 48 data points.</p>\n\n<hr>\n\n<p><strong>What am I aiming for -</strong></p>\n\n<p>Based on this data, I want to predict my next/future day or hour </p>\n\n<p><strong>Where am I stuck -</strong> </p>\n\n<p>My predictor variable is the <code>entire row</code> (the day) or a single <code>column</code> (30 mins). My first thought was to pivot the whole data, do one-hot encoding for each response variable and then think on which classification model to apply. But then each day is also related to the day before it. So it's merely not a classification problem. There's some regression to it as well.</p>\n\n<p>I'm having hard time in which way should I prepare the data and proceed.</p>\n\n<hr>\n\n<p><strong>What am I asking for -</strong></p>\n\n<blockquote>\n  <p>An approach to handle this kind of dataset.</p>\n</blockquote>\n\n<p>I'm not necessarily looking for which model to apply. My primary concern is to understand <code>in which way</code> to prepare my data such that it is ready for consumption in a model.</p>\n\n<p>Any help, guidance, similar Q&amp;A or related article will be helpful.</p>\n",
                "tags": "<python><classification><regression><predictive-modeling><model-selection>",
                "answers": [
                    [
                        "57473",
                        "2",
                        "57461",
                        "",
                        "",
                        "<p>I can think of two ways for doing this.</p>\n\n<p>One would be to have the same data structure as you currently have. Then you can train any regression model with all of your columns as features. You can use LinearRegressor or RandomForestRegressor , etc. Then to predict multiple values as in multiple columns you need to use something like \"<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html\" rel=\"nofollow noreferrer\">multioutputregressor</a>\". This way you are feeding the model data of one day and model predicts the next day for you. So you can get multiple predictions (output) out of the model.</p>\n\n<p>The other way that you can do this is to convert your columns into multiple rows. For example you can have something like this:</p>\n\n<pre><code>+-----------+-----------------+-------+\n|    Day    |    Date         | value |\n+-----------+-----------------+-------+ \n| Tuesday   | 01/01/2019 0:0  |   2   |\n| Tuesday   | 02/01/2019 0:30 |   2   |\n| Tuesday   | 02/01/2019 1:0  |   2   |\n| Tuesday   | 02/01/2019 1:30 |   2   |\n| Tuesday   | 02/01/2019 2:0  |   2   |\n| Tuesday   | 02/01/2019 2:30 |   2   |\n+-----------+-----------------+-------+\n</code></pre>\n\n<p>Then you can use one of the Regressor models as mentioned above, to predict one row, that is one half an hour. Then you can put this prediction back into the data, train the model again and predict for the next half an hour. You can continue to do this until you have a complete day of predictions. </p>\n\n<p>Hope this helps,</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17267",
            "_score": 8.384743,
            "_source": {
                "title": "How to predict a binary output from a dataframe?",
                "content": "How to predict a binary output from a dataframe? <p>I have a data set with a huge amount of variables for an output that can either be <code>A</code> or <code>not A</code>. How can I predict the output to be either .</p>\n\n<h1>Example</h1>\n\n<p>I have a data set of loans which status <code>loan_status</code> are currently <code>Fully Paid</code> or <code>Charged Off</code> Since the data set is very large, I would like to predict <code>loan_status</code>. I know I will split my dataset into training set and test set. As it is binary I thought about using logistic regression. </p>\n\n<pre><code>&gt;&gt;&gt; subset.head()\n\n    id  member_id   loan_amnt   funded_amnt funded_amnt_inv term    int_rate    installment grade   sub_grade   emp_title   emp_length  home_ownership  annual_inc  verification_status issue_d loan_status pymnt_plan  url desc    purpose title   zip_code    addr_state  dti delinq_2yrs earliest_cr_line    inq_last_6mths  mths_since_last_delinq  mths_since_last_record  open_acc    pub_rec revol_bal   revol_util  total_acc   initial_list_status out_prncp   out_prncp_inv   total_pymnt total_pymnt_inv total_rec_prncp total_rec_int   total_rec_late_fee  recoveries  collection_recovery_fee last_pymnt_d    last_pymnt_amnt next_pymnt_d    last_credit_pull_d  collections_12_mths_ex_med  mths_since_last_major_derog policy_code application_type    annual_inc_joint    dti_joint   verification_status_joint   acc_now_delinq  tot_coll_amt    tot_cur_bal open_acc_6m open_act_il open_il_12m open_il_24m mths_since_rcnt_il  total_bal_il    il_util open_rv_12m open_rv_24m max_bal_bc  all_util    total_rev_hi_lim    inq_fi  total_cu_tl inq_last_12m    acc_open_past_24mths    avg_cur_bal bc_open_to_buy  bc_util chargeoff_within_12_mths    delinq_amnt mo_sin_old_il_acct  mo_sin_old_rev_tl_op    mo_sin_rcnt_rev_tl_op   mo_sin_rcnt_tl  mort_acc    mths_since_recent_bc    mths_since_recent_bc_dlq    mths_since_recent_inq   mths_since_recent_revol_delinq  num_accts_ever_120_pd   num_actv_bc_tl  num_actv_rev_tl num_bc_sats num_bc_tl   num_il_tl   num_op_rev_tl   num_rev_accts   num_rev_tl_bal_gt_0 num_sats    num_tl_120dpd_2m    num_tl_30dpd    num_tl_90g_dpd_24m  num_tl_op_past_12m  pct_tl_nvr_dlq  percent_bc_gt_75    pub_rec_bankruptcies    tax_liens   tot_hi_cred_lim total_bal_ex_mort   total_bc_limit  total_il_high_credit_limit  revol_bal_joint sec_app_earliest_cr_line    sec_app_inq_last_6mths  sec_app_mort_acc    sec_app_open_acc    sec_app_revol_util  sec_app_open_act_il sec_app_num_rev_accts   sec_app_chargeoff_within_12_mths    sec_app_collections_12_mths_ex_med  sec_app_mths_since_last_major_derog hardship_flag   hardship_type   hardship_reason hardship_status deferral_term   hardship_amount hardship_start_date hardship_end_date   payment_plan_start_date hardship_length hardship_dpd    hardship_loan_status    orig_projected_additional_accrued_interest  hardship_payoff_balance_amount  hardship_last_payment_amount    debt_settlement_flag    debt_settlement_flag_date   settlement_status   settlement_date settlement_amount   settlement_percentage   settlement_term\n11  NaN NaN 10000   10000   10000.0 60 months   14.07%  233.05  C   C3  Teacher 4 years RENT    42000.0 Source Verified Mar-2018    Fully Paid  n   NaN NaN major_purchase  Major purchase  341xx   FL  24.69   0   Oct-2004    0   32.0    NaN 17  0   707 15.7%   34  w   0.0 0.0 11153.669505    11153.67    10000.00    1153.67 0.0 0.0 0.0 Mar-2019    10.38   NaN Jun-2019    0   40.0    1   Individual  NaN NaN NaN 0   0   93913   0   15  0   0   54.0    93206   116.0   0   1   707 111.0   4500    0   0   0   1   5524.0  3793.0  15.7    0   0   161.0   88  18  18  0   18.0    32.0    18.0    32.0    14  1   1   2   4   30  2   4   1   17  0.0 0   0   0   43.8    0.0 0   0   84930   93913   4500    80430   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN N   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN N   NaN NaN NaN NaN NaN NaN\n16  NaN NaN 7000    7000    7000.0  36 months   11.98%  232.44  B   B5  Parole  &lt; 1 year    MORTGAGE    40000.0 Verified    Mar-2018    Fully Paid  n   NaN NaN home_improvement    Home improvement    797xx   TX  20.25   0   Mar-2007    0   60.0    NaN 13  0   5004    36% 29  w   0.0 0.0 7693.314943 7693.31 7000.00 693.31  0.0 0.0 0.0 Mar-2019    5364.25 NaN Mar-2019    0   60.0    1   Individual  NaN NaN NaN 0   0   131726  1   6   0   2   16.0    126722  102.0   2   2   3944    90.0    13900   2   1   4   4   10977.0 4996.0  50.0    0   0   122.0   132 1   1   0   10.0    64.0    5.0 60.0    3   2   2   3   4   19  7   10  2   13  0.0 0   0   2   89.7    33.3    0   0   132817  131726  10000   118917  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN N   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN N   NaN NaN NaN NaN NaN NaN\n17  NaN NaN 20000   20000   20000.0 60 months   26.77%  607.97  E   E5  Mental Health Provider  3 years RENT    33500.0 Not Verified    Mar-2018    Charged Off n   NaN NaN house   Home buying 604xx   IL  24.40   0   Aug-2008    1   NaN NaN 27  0   7364    46% 34  w   0.0 0.0 7236.150000 7236.15 2195.37 5040.78 0.0 0.0 0.0 Apr-2019    607.97  NaN Jun-2019    0   NaN 1   Individual  NaN NaN NaN 0   308 160804  0   21  0   0   29.0    153440  118.0   0   2   2607    110.0   16000   0   0   2   2   5956.0  2767.0  68.6    0   0   115.0   115 20  20  0   26.0    NaN 5.0 NaN 0   3   6   3   3   27  6   7   6   27  0.0 0   0   0   100.0   33.3    0   0   146514  160804  8800    130514  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN N   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN N   NaN NaN NaN NaN NaN NaN\n20  NaN NaN 21000   21000   21000.0 60 months   20.39%  560.94  D   D4  Machine operator    10+ years   OWN 85000.0 Source Verified Mar-2018    Fully Paid  n   NaN NaN house   Home buying 135xx   NY  15.76   1   Nov-2008    0   2.0 NaN 15  0   14591   34.2%   27  w   0.0 0.0 24217.170915    24217.17    21000.00    3217.17 0.0 0.0 0.0 Feb-2019    183.26  NaN May-2019    0   NaN 1   Individual  NaN NaN NaN 0   0   128270  1   1   2   2   7.0 37076   NaN 2   5   5354    34.0    42700   6   4   13  8   8551.0  16684.0 38.4    0   0   67.0    112 4   4   3   4.0 NaN 0.0 2.0 0   5   7   6   10  3   12  21  7   15  0.0 0   0   4   92.6    16.7    0   0   172433  51667   27100   39733   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN N   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN N   NaN NaN NaN NaN NaN NaN\n...\n</code></pre>\n\n<h1>My attempt</h1>\n\n<p>I don't know a lot about data science but I tried to apply <a href=\"https://stackabuse.com/classification-in-python-with-scikit-learn-and-pandas/\" rel=\"nofollow noreferrer\">this tutorial's code</a>:</p>\n\n<pre><code>from sklearn.linear_model import LogisticRegression\ny = subset[[\"loan_status\"]]\nX = subset.loc[:, subset.columns != 'loan_status']\n\nLR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X, y)\nLR.predict(X.iloc[460:,:])\nround(LR.score(X,y), 4)\n</code></pre>\n\n<p>Yet I had the following error:</p>\n\n<pre><code>---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-95-05b2d88fb90f&gt; in &lt;module&gt;\n----&gt; 1 LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X, y)\n      2 LR.predict(X.iloc[460:,:])\n      3 round(LR.score(X,y), 4)\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py in fit(self, X, y, sample_weight)\n   1283 \n   1284         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n-&gt; 1285                          accept_large_sparse=solver != 'liblinear')\n   1286         check_classification_targets(y)\n   1287         self.classes_ = np.unique(y)\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_X_y(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\n    754                     ensure_min_features=ensure_min_features,\n    755                     warn_on_dtype=warn_on_dtype,\n--&gt; 756                     estimator=estimator)\n    757     if multi_output:\n    758         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\n    525             try:\n    526                 warnings.simplefilter('error', ComplexWarning)\n--&gt; 527                 array = np.asarray(array, dtype=dtype, order=order)\n    528             except ComplexWarning:\n    529                 raise ValueError(\"Complex data not supported\\n\"\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py in asarray(a, dtype, order)\n    499 \n    500     \"\"\"\n--&gt; 501     return array(a, dtype, copy=False, order=order)\n    502 \n    503 \n\nValueError: could not convert string to float: 'N'\n</code></pre>\n\n<h1>Annex : how to recreate the dataset</h1>\n\n<p>I used a csv file that I downloaded <a href=\"https://www.lendingclub.com/info/download-data.action\" rel=\"nofollow noreferrer\">here</a> (bank loans for 2018. They are divided into four quarters). Using Python 3 can be obtained by doing:</p>\n\n<pre><code>import pandas as pd \n# Control delimiters, rows, column names with read_csv (see later) \ndata_Q1 = pd.read_csv(\"LoanStats_2018Q1.csv\", skiprows=1, skipfooter=2, engine='python')\ndata_Q2 = pd.read_csv(\"LoanStats_2018Q2.csv\", skiprows=1, skipfooter=2, engine='python')\ndata_Q3 = pd.read_csv(\"LoanStats_2018Q2.csv\", skiprows=1, skipfooter=2, engine='python')\ndata_Q4 = pd.read_csv(\"LoanStats_2018Q2.csv\", skiprows=1, skipfooter=2, engine='python')\nframes = [data_Q1,data_Q2,data_Q3,data_Q4]\n\nresult = pd.concat(frames)\nsubset = result.loc[result[\"loan_status\"].isin(['Charged Off','Fully Paid'])]\n</code></pre>\n <linear-regression>",
                "codes": [],
                "question_id:": "55870",
                "question_votes:": "",
                "question_text:": "<p>I have a data set with a huge amount of variables for an output that can either be <code>A</code> or <code>not A</code>. How can I predict the output to be either .</p>\n\n<h1>Example</h1>\n\n<p>I have a data set of loans which status <code>loan_status</code> are currently <code>Fully Paid</code> or <code>Charged Off</code> Since the data set is very large, I would like to predict <code>loan_status</code>. I know I will split my dataset into training set and test set. As it is binary I thought about using logistic regression. </p>\n\n<pre><code>&gt;&gt;&gt; subset.head()\n\n    id  member_id   loan_amnt   funded_amnt funded_amnt_inv term    int_rate    installment grade   sub_grade   emp_title   emp_length  home_ownership  annual_inc  verification_status issue_d loan_status pymnt_plan  url desc    purpose title   zip_code    addr_state  dti delinq_2yrs earliest_cr_line    inq_last_6mths  mths_since_last_delinq  mths_since_last_record  open_acc    pub_rec revol_bal   revol_util  total_acc   initial_list_status out_prncp   out_prncp_inv   total_pymnt total_pymnt_inv total_rec_prncp total_rec_int   total_rec_late_fee  recoveries  collection_recovery_fee last_pymnt_d    last_pymnt_amnt next_pymnt_d    last_credit_pull_d  collections_12_mths_ex_med  mths_since_last_major_derog policy_code application_type    annual_inc_joint    dti_joint   verification_status_joint   acc_now_delinq  tot_coll_amt    tot_cur_bal open_acc_6m open_act_il open_il_12m open_il_24m mths_since_rcnt_il  total_bal_il    il_util open_rv_12m open_rv_24m max_bal_bc  all_util    total_rev_hi_lim    inq_fi  total_cu_tl inq_last_12m    acc_open_past_24mths    avg_cur_bal bc_open_to_buy  bc_util chargeoff_within_12_mths    delinq_amnt mo_sin_old_il_acct  mo_sin_old_rev_tl_op    mo_sin_rcnt_rev_tl_op   mo_sin_rcnt_tl  mort_acc    mths_since_recent_bc    mths_since_recent_bc_dlq    mths_since_recent_inq   mths_since_recent_revol_delinq  num_accts_ever_120_pd   num_actv_bc_tl  num_actv_rev_tl num_bc_sats num_bc_tl   num_il_tl   num_op_rev_tl   num_rev_accts   num_rev_tl_bal_gt_0 num_sats    num_tl_120dpd_2m    num_tl_30dpd    num_tl_90g_dpd_24m  num_tl_op_past_12m  pct_tl_nvr_dlq  percent_bc_gt_75    pub_rec_bankruptcies    tax_liens   tot_hi_cred_lim total_bal_ex_mort   total_bc_limit  total_il_high_credit_limit  revol_bal_joint sec_app_earliest_cr_line    sec_app_inq_last_6mths  sec_app_mort_acc    sec_app_open_acc    sec_app_revol_util  sec_app_open_act_il sec_app_num_rev_accts   sec_app_chargeoff_within_12_mths    sec_app_collections_12_mths_ex_med  sec_app_mths_since_last_major_derog hardship_flag   hardship_type   hardship_reason hardship_status deferral_term   hardship_amount hardship_start_date hardship_end_date   payment_plan_start_date hardship_length hardship_dpd    hardship_loan_status    orig_projected_additional_accrued_interest  hardship_payoff_balance_amount  hardship_last_payment_amount    debt_settlement_flag    debt_settlement_flag_date   settlement_status   settlement_date settlement_amount   settlement_percentage   settlement_term\n11  NaN NaN 10000   10000   10000.0 60 months   14.07%  233.05  C   C3  Teacher 4 years RENT    42000.0 Source Verified Mar-2018    Fully Paid  n   NaN NaN major_purchase  Major purchase  341xx   FL  24.69   0   Oct-2004    0   32.0    NaN 17  0   707 15.7%   34  w   0.0 0.0 11153.669505    11153.67    10000.00    1153.67 0.0 0.0 0.0 Mar-2019    10.38   NaN Jun-2019    0   40.0    1   Individual  NaN NaN NaN 0   0   93913   0   15  0   0   54.0    93206   116.0   0   1   707 111.0   4500    0   0   0   1   5524.0  3793.0  15.7    0   0   161.0   88  18  18  0   18.0    32.0    18.0    32.0    14  1   1   2   4   30  2   4   1   17  0.0 0   0   0   43.8    0.0 0   0   84930   93913   4500    80430   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN N   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN N   NaN NaN NaN NaN NaN NaN\n16  NaN NaN 7000    7000    7000.0  36 months   11.98%  232.44  B   B5  Parole  &lt; 1 year    MORTGAGE    40000.0 Verified    Mar-2018    Fully Paid  n   NaN NaN home_improvement    Home improvement    797xx   TX  20.25   0   Mar-2007    0   60.0    NaN 13  0   5004    36% 29  w   0.0 0.0 7693.314943 7693.31 7000.00 693.31  0.0 0.0 0.0 Mar-2019    5364.25 NaN Mar-2019    0   60.0    1   Individual  NaN NaN NaN 0   0   131726  1   6   0   2   16.0    126722  102.0   2   2   3944    90.0    13900   2   1   4   4   10977.0 4996.0  50.0    0   0   122.0   132 1   1   0   10.0    64.0    5.0 60.0    3   2   2   3   4   19  7   10  2   13  0.0 0   0   2   89.7    33.3    0   0   132817  131726  10000   118917  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN N   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN N   NaN NaN NaN NaN NaN NaN\n17  NaN NaN 20000   20000   20000.0 60 months   26.77%  607.97  E   E5  Mental Health Provider  3 years RENT    33500.0 Not Verified    Mar-2018    Charged Off n   NaN NaN house   Home buying 604xx   IL  24.40   0   Aug-2008    1   NaN NaN 27  0   7364    46% 34  w   0.0 0.0 7236.150000 7236.15 2195.37 5040.78 0.0 0.0 0.0 Apr-2019    607.97  NaN Jun-2019    0   NaN 1   Individual  NaN NaN NaN 0   308 160804  0   21  0   0   29.0    153440  118.0   0   2   2607    110.0   16000   0   0   2   2   5956.0  2767.0  68.6    0   0   115.0   115 20  20  0   26.0    NaN 5.0 NaN 0   3   6   3   3   27  6   7   6   27  0.0 0   0   0   100.0   33.3    0   0   146514  160804  8800    130514  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN N   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN N   NaN NaN NaN NaN NaN NaN\n20  NaN NaN 21000   21000   21000.0 60 months   20.39%  560.94  D   D4  Machine operator    10+ years   OWN 85000.0 Source Verified Mar-2018    Fully Paid  n   NaN NaN house   Home buying 135xx   NY  15.76   1   Nov-2008    0   2.0 NaN 15  0   14591   34.2%   27  w   0.0 0.0 24217.170915    24217.17    21000.00    3217.17 0.0 0.0 0.0 Feb-2019    183.26  NaN May-2019    0   NaN 1   Individual  NaN NaN NaN 0   0   128270  1   1   2   2   7.0 37076   NaN 2   5   5354    34.0    42700   6   4   13  8   8551.0  16684.0 38.4    0   0   67.0    112 4   4   3   4.0 NaN 0.0 2.0 0   5   7   6   10  3   12  21  7   15  0.0 0   0   4   92.6    16.7    0   0   172433  51667   27100   39733   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN N   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN N   NaN NaN NaN NaN NaN NaN\n...\n</code></pre>\n\n<h1>My attempt</h1>\n\n<p>I don't know a lot about data science but I tried to apply <a href=\"https://stackabuse.com/classification-in-python-with-scikit-learn-and-pandas/\" rel=\"nofollow noreferrer\">this tutorial's code</a>:</p>\n\n<pre><code>from sklearn.linear_model import LogisticRegression\ny = subset[[\"loan_status\"]]\nX = subset.loc[:, subset.columns != 'loan_status']\n\nLR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X, y)\nLR.predict(X.iloc[460:,:])\nround(LR.score(X,y), 4)\n</code></pre>\n\n<p>Yet I had the following error:</p>\n\n<pre><code>---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-95-05b2d88fb90f&gt; in &lt;module&gt;\n----&gt; 1 LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X, y)\n      2 LR.predict(X.iloc[460:,:])\n      3 round(LR.score(X,y), 4)\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py in fit(self, X, y, sample_weight)\n   1283 \n   1284         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n-&gt; 1285                          accept_large_sparse=solver != 'liblinear')\n   1286         check_classification_targets(y)\n   1287         self.classes_ = np.unique(y)\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_X_y(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\n    754                     ensure_min_features=ensure_min_features,\n    755                     warn_on_dtype=warn_on_dtype,\n--&gt; 756                     estimator=estimator)\n    757     if multi_output:\n    758         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\n    525             try:\n    526                 warnings.simplefilter('error', ComplexWarning)\n--&gt; 527                 array = np.asarray(array, dtype=dtype, order=order)\n    528             except ComplexWarning:\n    529                 raise ValueError(\"Complex data not supported\\n\"\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py in asarray(a, dtype, order)\n    499 \n    500     \"\"\"\n--&gt; 501     return array(a, dtype, copy=False, order=order)\n    502 \n    503 \n\nValueError: could not convert string to float: 'N'\n</code></pre>\n\n<h1>Annex : how to recreate the dataset</h1>\n\n<p>I used a csv file that I downloaded <a href=\"https://www.lendingclub.com/info/download-data.action\" rel=\"nofollow noreferrer\">here</a> (bank loans for 2018. They are divided into four quarters). Using Python 3 can be obtained by doing:</p>\n\n<pre><code>import pandas as pd \n# Control delimiters, rows, column names with read_csv (see later) \ndata_Q1 = pd.read_csv(\"LoanStats_2018Q1.csv\", skiprows=1, skipfooter=2, engine='python')\ndata_Q2 = pd.read_csv(\"LoanStats_2018Q2.csv\", skiprows=1, skipfooter=2, engine='python')\ndata_Q3 = pd.read_csv(\"LoanStats_2018Q2.csv\", skiprows=1, skipfooter=2, engine='python')\ndata_Q4 = pd.read_csv(\"LoanStats_2018Q2.csv\", skiprows=1, skipfooter=2, engine='python')\nframes = [data_Q1,data_Q2,data_Q3,data_Q4]\n\nresult = pd.concat(frames)\nsubset = result.loc[result[\"loan_status\"].isin(['Charged Off','Fully Paid'])]\n</code></pre>\n",
                "tags": "<linear-regression>",
                "answers": []
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8901",
            "_score": 8.366743,
            "_source": {
                "title": "Class Imbalance Problem",
                "content": "Class Imbalance Problem <p>I'm making a multiclassifier model with 5 classes.\n(it is not important in my question whether it has 2 classes or 5 classes, though).</p>\n\n<p>class distribution is very imbalanced.<br>\n<a href=\"https://i.stack.imgur.com/ANCiy.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ANCiy.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>So, I did resampling for oversampling to match each number of classes.\n<a href=\"https://i.stack.imgur.com/ZfWnY.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ZfWnY.png\" alt=\"enter image description here\"></a></p>\n\n<p>MY question is.\nIs there any statistical error or problem\nif I resample classes for oversampling(bootstrap resampling or SMOTE)?</p>\n\n<p>can anyone explain for this approach?</p>\n\n<p>Thanks in advance.</p>\n <classification><unbalanced-classes><class-imbalance><classifier><p>This depends on the data in your minority classes. </p>\n\n<p>The data in each class can be considered as a sample of observations from some population. This sample may or may not represent well the whole population of instances from that class. </p>\n\n<p>If the sample represents the population well, then oversampling will introduce only a small error. However, if the sample does not represent the population well, then oversampling will produce data that have statistical properties different from those of the population. </p>\n\n<p>All estimates (like <a href=\"https://machinelearningmastery.com/confidence-intervals-for-machine-learning/\" rel=\"nofollow noreferrer\">confidence intervals</a>, <a href=\"https://machinelearningmastery.com/prediction-intervals-for-machine-learning/\" rel=\"nofollow noreferrer\">prediction intervals</a>) are calculated from the statistical properties of the sample (mean, variance, etc), the exact calculations being different for different distributions and learning algorithms. If statistical properties of your oversampled data are different from the statistical properties of their populations, you will get wrong estimates of the confidence and prediction intervals for your model.</p>\n\n<p>I will illustrate this with an example.</p>\n\n<p>Let's assume that you have 2-dimensional data (two features in each observaton) that belong to 2 classes. Data in each class are normally distributed with the standard deviation for each feature = 1. The population mean of the class 1 is (-2, 0). The population mean of the class 2 is (1, 0).</p>\n\n<p>I illustrate a large population, taking 500 points for each class. The classes can be separated by logistic regression line as follows:</p>\n\n<p><a href=\"https://i.stack.imgur.com/DTeKI.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/DTeKI.png\" alt=\"enter image description here\"></a></p>\n\n<p>The regression line is almost exactly between the population means and is almost vertical because both ordinates of the population means are zero. If I take a couple of thousand points then it will be vertical.</p>\n\n<p>The code for this picture:</p>\n\n<pre><code>import numpy as np \nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\n\nn_points1 = 500\nn_points2 = 500\nmu1 = np.array([-2,0])\nmu2 = np.array([1,0])\n\nsig = 1\n\ncl1 = sig * np.random.randn(n_points1,2) + mu1\ncl2 = sig * np.random.randn(n_points2,2) + mu2\n\nprint('Red points:')\nprint('mu_x = %.3f, mu_y = %.3f, std_x = %.3f, std_y = %.3f' \n    % (np.mean(cl2[:,0]), np.mean(cl2[:,1]), np.std(cl2[:,0]), np.std(cl2[:,1])) )\n\ny1 = np.zeros((cl1.shape[0],1))\ny2 = np.ones((cl2.shape[0],1))\n\nX = np.vstack((cl1,cl2))\ny = np.vstack((y1,y2))\n\nlogreg = LogisticRegression()\n\nlogreg.fit(X, y.ravel())\nw = logreg.coef_[0]\na = -w[0] / w[1]\n\nxx = np.linspace(-4,4)\nyy = a * xx - (logreg.intercept_[0]) / w[1]\n\nplt.scatter(cl1[:,0], cl1[:,1], s = 50, marker='.', color='green')\nplt.scatter(cl2[:,0], cl2[:,1], s = 50, marker='.', color='red')\nplt.plot(xx, yy, 'b-')\nplt.xlim((-5, 4))   \nplt.ylim((-5, 5))\nplt.grid()\nplt.show() \n</code></pre>\n\n<p>Now, let's assume that the red class is under-represented (a minority class). I take 500 points for the green class, and 10 points for the red class. Then I oversample the red data by two methods. One is duplicating them 50 times, like bootstrap resampling (I color them red), and another is something like SMOTE (they are magenta). This is not exactly SMOTE. I simply added data that are in the middle between red data points. I was too lazy to calculate nearest neighbors for each observation in this simple example but it illustrates SMOTE nevertheless because in SMOTE, synthetic examples are generated inside the convex hull of existing minority examples which reduces the variance of the data.</p>\n\n<p>This is what I get:</p>\n\n<p><a href=\"https://i.stack.imgur.com/POCyb.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/POCyb.png\" alt=\"enter image description here\"></a></p>\n\n<p>The blue line is for bootstrap, and the black line is for SMOTE. The sample means and standard deviations for the minority class are as follows:</p>\n\n<pre><code>Red points:\nmu_x = 1.600, mu_y = -0.182, std_x = 0.719, std_y = 0.753\n\nMagenta points:\nmu_x = 1.625, mu_y = -0.174, std_x = 0.513, std_y = 0.550\n</code></pre>\n\n<p>The x-component of the sample mean is overestimated (it should be = 1) and standard deviations are underestimated (they should be = 1). As a result, the line separating the classes is different from the true line on the previous picture, so a lot of new data will be classified incorrectly.</p>\n\n<p>Let's take a couple of more samples randomly from the same population. Again, the size of the minority class is 10, and I resample them using the same two methods.</p>\n\n<p><a href=\"https://i.stack.imgur.com/3uEZo.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/3uEZo.png\" alt=\"enter image description here\"></a></p>\n\n<pre><code>Red points:\nmu_x = 0.944, mu_y = 0.289, std_x = 0.943, std_y = 0.867\n\nMagenta points:\nmu_x = 0.974, mu_y = 0.298, std_x = 0.700, std_y = 0.617\n</code></pre>\n\n<p>This time x-component of the sample mean is OK, its y-component is a little overestimated, and the standard deviation is underestimated. The separating line is again incorrect. </p>\n\n<p><a href=\"https://i.stack.imgur.com/zpE7q.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zpE7q.png\" alt=\"enter image description here\"></a></p>\n\n<pre><code>Red points:\nmu_x = 0.922, mu_y = -0.236, std_x = 1.066, std_y = 1.097\n\nMagenta points:\nmu_x = 0.924, mu_y = -0.244, std_x = 0.757, std_y = 0.749\n</code></pre>\n\n<p>In the last picture we are lucky to get a sample that has almost the same mean and standard deviation as the population. Therefore, the separating line is very close to the line in the first picture where the data were balanced. Notice that the standard deviation for SMOTE is always smaller because new data are added between the existing data, not outside of them.</p>\n\n<p>You might consider undersampling instead of oversampling. Check this <a href=\"http://www.svds.com/learning-imbalanced-classes/\" rel=\"nofollow noreferrer\">link</a>.</p>\n\n<p>The code for the last 3 pictures:</p>\n\n<pre><code>import numpy as np \nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\n\nn_points1 = 500\nn_points2 = 10\nmu1 = np.array([-2,0])\nmu2 = np.array([1,0])\n\nsig = 1\n\ncl1 = sig * np.random.randn(n_points1,2) + mu1\ncl2 = sig * np.random.randn(n_points2,2) + mu2\n\ncl2 = np.tile(cl2,(n_points1//n_points2,1)) # oversampling \n\n# A kind of SMOTE but not quite\ncl3 = np.zeros_like(cl1)\nfor k in range(len(cl3)):\n    i = np.random.randint(low=0, high=n_points2, size=2)\n    cl3[k,:] = (cl2[i[0]]+cl2[i[1]])/2\n\nprint('Red points:')\nprint('mu_x = %.3f, mu_y = %.3f, std_x = %.3f, std_y = %.3f' \n    % (np.mean(cl2[:,0]), np.mean(cl2[:,1]), np.std(cl2[:,0]), np.std(cl2[:,1])) )\n\nprint('Magenta points:')\nprint('mu_x = %.3f, mu_y = %.3f, std_x = %.3f, std_y = %.3f' \n    % (np.mean(cl3[:,0]), np.mean(cl3[:,1]), np.std(cl3[:,0]), np.std(cl3[:,1])) )\n\ny1 = np.zeros((cl1.shape[0],1))\ny2 = np.ones((cl2.shape[0],1))\n\nX = np.vstack((cl1,cl2))\nX3 = np.vstack((cl1,cl3))\n\ny = np.vstack((y1,y2))\n\nlogreg = LogisticRegression()\n\nlogreg.fit(X, y.ravel())\nw = logreg.coef_[0]\na = -w[0] / w[1]\n\nxx = np.linspace(-4,4)\nyy = a * xx - (logreg.intercept_[0]) / w[1]\n\nplt.scatter(cl1[:,0], cl1[:,1], s = 50, marker='.', color='green')\nplt.scatter(cl2[:,0], cl2[:,1], s = 50, marker='.', color='red')\nplt.plot(xx, yy, 'b-')\n\nlogreg.fit(X3, y.ravel())\nw = logreg.coef_[0]\na = -w[0] / w[1]\nyy = a * xx - (logreg.intercept_[0]) / w[1]\n\nplt.scatter(cl3[:,0], cl3[:,1], s = 10, marker='.', color='magenta')\nplt.plot(xx, yy, 'k-')\nplt.xlim((-5, 4))   \nplt.ylim((-5, 5))\nplt.grid()\nplt.show()\n</code></pre>\n",
                "codes": [
                    [
                        "import numpy as np \nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\n\nn_points1 = 500\nn_points2 = 500\nmu1 = np.array([-2,0])\nmu2 = np.array([1,0])\n\nsig = 1\n\ncl1 = sig * np.random.randn(n_points1,2) + mu1\ncl2 = sig * np.random.randn(n_points2,2) + mu2\n\nprint('Red points:')\nprint('mu_x = %.3f, mu_y = %.3f, std_x = %.3f, std_y = %.3f' \n    % (np.mean(cl2[:,0]), np.mean(cl2[:,1]), np.std(cl2[:,0]), np.std(cl2[:,1])) )\n\ny1 = np.zeros((cl1.shape[0],1))\ny2 = np.ones((cl2.shape[0],1))\n\nX = np.vstack((cl1,cl2))\ny = np.vstack((y1,y2))\n\nlogreg = LogisticRegression()\n\nlogreg.fit(X, y.ravel())\nw = logreg.coef_[0]\na = -w[0] / w[1]\n\nxx = np.linspace(-4,4)\nyy = a * xx - (logreg.intercept_[0]) / w[1]\n\nplt.scatter(cl1[:,0], cl1[:,1], s = 50, marker='.', color='green')\nplt.scatter(cl2[:,0], cl2[:,1], s = 50, marker='.', color='red')\nplt.plot(xx, yy, 'b-')\nplt.xlim((-5, 4))   \nplt.ylim((-5, 5))\nplt.grid()\nplt.show() \n",
                        "Red points:\nmu_x = 1.600, mu_y = -0.182, std_x = 0.719, std_y = 0.753\n\nMagenta points:\nmu_x = 1.625, mu_y = -0.174, std_x = 0.513, std_y = 0.550\n",
                        "Red points:\nmu_x = 0.944, mu_y = 0.289, std_x = 0.943, std_y = 0.867\n\nMagenta points:\nmu_x = 0.974, mu_y = 0.298, std_x = 0.700, std_y = 0.617\n",
                        "Red points:\nmu_x = 0.922, mu_y = -0.236, std_x = 1.066, std_y = 1.097\n\nMagenta points:\nmu_x = 0.924, mu_y = -0.244, std_x = 0.757, std_y = 0.749\n",
                        "import numpy as np \nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\n\nn_points1 = 500\nn_points2 = 10\nmu1 = np.array([-2,0])\nmu2 = np.array([1,0])\n\nsig = 1\n\ncl1 = sig * np.random.randn(n_points1,2) + mu1\ncl2 = sig * np.random.randn(n_points2,2) + mu2\n\ncl2 = np.tile(cl2,(n_points1//n_points2,1)) # oversampling \n\n# A kind of SMOTE but not quite\ncl3 = np.zeros_like(cl1)\nfor k in range(len(cl3)):\n    i = np.random.randint(low=0, high=n_points2, size=2)\n    cl3[k,:] = (cl2[i[0]]+cl2[i[1]])/2\n\nprint('Red points:')\nprint('mu_x = %.3f, mu_y = %.3f, std_x = %.3f, std_y = %.3f' \n    % (np.mean(cl2[:,0]), np.mean(cl2[:,1]), np.std(cl2[:,0]), np.std(cl2[:,1])) )\n\nprint('Magenta points:')\nprint('mu_x = %.3f, mu_y = %.3f, std_x = %.3f, std_y = %.3f' \n    % (np.mean(cl3[:,0]), np.mean(cl3[:,1]), np.std(cl3[:,0]), np.std(cl3[:,1])) )\n\ny1 = np.zeros((cl1.shape[0],1))\ny2 = np.ones((cl2.shape[0],1))\n\nX = np.vstack((cl1,cl2))\nX3 = np.vstack((cl1,cl3))\n\ny = np.vstack((y1,y2))\n\nlogreg = LogisticRegression()\n\nlogreg.fit(X, y.ravel())\nw = logreg.coef_[0]\na = -w[0] / w[1]\n\nxx = np.linspace(-4,4)\nyy = a * xx - (logreg.intercept_[0]) / w[1]\n\nplt.scatter(cl1[:,0], cl1[:,1], s = 50, marker='.', color='green')\nplt.scatter(cl2[:,0], cl2[:,1], s = 50, marker='.', color='red')\nplt.plot(xx, yy, 'b-')\n\nlogreg.fit(X3, y.ravel())\nw = logreg.coef_[0]\na = -w[0] / w[1]\nyy = a * xx - (logreg.intercept_[0]) / w[1]\n\nplt.scatter(cl3[:,0], cl3[:,1], s = 10, marker='.', color='magenta')\nplt.plot(xx, yy, 'k-')\nplt.xlim((-5, 4))   \nplt.ylim((-5, 5))\nplt.grid()\nplt.show()\n"
                    ]
                ],
                "question_id:": "32046",
                "question_votes:": "2",
                "question_text:": "<p>I'm making a multiclassifier model with 5 classes.\n(it is not important in my question whether it has 2 classes or 5 classes, though).</p>\n\n<p>class distribution is very imbalanced.<br>\n<a href=\"https://i.stack.imgur.com/ANCiy.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ANCiy.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>So, I did resampling for oversampling to match each number of classes.\n<a href=\"https://i.stack.imgur.com/ZfWnY.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ZfWnY.png\" alt=\"enter image description here\"></a></p>\n\n<p>MY question is.\nIs there any statistical error or problem\nif I resample classes for oversampling(bootstrap resampling or SMOTE)?</p>\n\n<p>can anyone explain for this approach?</p>\n\n<p>Thanks in advance.</p>\n",
                "tags": "<classification><unbalanced-classes><class-imbalance><classifier>",
                "answers": [
                    [
                        "32393",
                        "2",
                        "32046",
                        "",
                        "",
                        "<p>This depends on the data in your minority classes. </p>\n\n<p>The data in each class can be considered as a sample of observations from some population. This sample may or may not represent well the whole population of instances from that class. </p>\n\n<p>If the sample represents the population well, then oversampling will introduce only a small error. However, if the sample does not represent the population well, then oversampling will produce data that have statistical properties different from those of the population. </p>\n\n<p>All estimates (like <a href=\"https://machinelearningmastery.com/confidence-intervals-for-machine-learning/\" rel=\"nofollow noreferrer\">confidence intervals</a>, <a href=\"https://machinelearningmastery.com/prediction-intervals-for-machine-learning/\" rel=\"nofollow noreferrer\">prediction intervals</a>) are calculated from the statistical properties of the sample (mean, variance, etc), the exact calculations being different for different distributions and learning algorithms. If statistical properties of your oversampled data are different from the statistical properties of their populations, you will get wrong estimates of the confidence and prediction intervals for your model.</p>\n\n<p>I will illustrate this with an example.</p>\n\n<p>Let's assume that you have 2-dimensional data (two features in each observaton) that belong to 2 classes. Data in each class are normally distributed with the standard deviation for each feature = 1. The population mean of the class 1 is (-2, 0). The population mean of the class 2 is (1, 0).</p>\n\n<p>I illustrate a large population, taking 500 points for each class. The classes can be separated by logistic regression line as follows:</p>\n\n<p><a href=\"https://i.stack.imgur.com/DTeKI.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/DTeKI.png\" alt=\"enter image description here\"></a></p>\n\n<p>The regression line is almost exactly between the population means and is almost vertical because both ordinates of the population means are zero. If I take a couple of thousand points then it will be vertical.</p>\n\n<p>The code for this picture:</p>\n\n<pre><code>import numpy as np \nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\n\nn_points1 = 500\nn_points2 = 500\nmu1 = np.array([-2,0])\nmu2 = np.array([1,0])\n\nsig = 1\n\ncl1 = sig * np.random.randn(n_points1,2) + mu1\ncl2 = sig * np.random.randn(n_points2,2) + mu2\n\nprint('Red points:')\nprint('mu_x = %.3f, mu_y = %.3f, std_x = %.3f, std_y = %.3f' \n    % (np.mean(cl2[:,0]), np.mean(cl2[:,1]), np.std(cl2[:,0]), np.std(cl2[:,1])) )\n\ny1 = np.zeros((cl1.shape[0],1))\ny2 = np.ones((cl2.shape[0],1))\n\nX = np.vstack((cl1,cl2))\ny = np.vstack((y1,y2))\n\nlogreg = LogisticRegression()\n\nlogreg.fit(X, y.ravel())\nw = logreg.coef_[0]\na = -w[0] / w[1]\n\nxx = np.linspace(-4,4)\nyy = a * xx - (logreg.intercept_[0]) / w[1]\n\nplt.scatter(cl1[:,0], cl1[:,1], s = 50, marker='.', color='green')\nplt.scatter(cl2[:,0], cl2[:,1], s = 50, marker='.', color='red')\nplt.plot(xx, yy, 'b-')\nplt.xlim((-5, 4))   \nplt.ylim((-5, 5))\nplt.grid()\nplt.show() \n</code></pre>\n\n<p>Now, let's assume that the red class is under-represented (a minority class). I take 500 points for the green class, and 10 points for the red class. Then I oversample the red data by two methods. One is duplicating them 50 times, like bootstrap resampling (I color them red), and another is something like SMOTE (they are magenta). This is not exactly SMOTE. I simply added data that are in the middle between red data points. I was too lazy to calculate nearest neighbors for each observation in this simple example but it illustrates SMOTE nevertheless because in SMOTE, synthetic examples are generated inside the convex hull of existing minority examples which reduces the variance of the data.</p>\n\n<p>This is what I get:</p>\n\n<p><a href=\"https://i.stack.imgur.com/POCyb.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/POCyb.png\" alt=\"enter image description here\"></a></p>\n\n<p>The blue line is for bootstrap, and the black line is for SMOTE. The sample means and standard deviations for the minority class are as follows:</p>\n\n<pre><code>Red points:\nmu_x = 1.600, mu_y = -0.182, std_x = 0.719, std_y = 0.753\n\nMagenta points:\nmu_x = 1.625, mu_y = -0.174, std_x = 0.513, std_y = 0.550\n</code></pre>\n\n<p>The x-component of the sample mean is overestimated (it should be = 1) and standard deviations are underestimated (they should be = 1). As a result, the line separating the classes is different from the true line on the previous picture, so a lot of new data will be classified incorrectly.</p>\n\n<p>Let's take a couple of more samples randomly from the same population. Again, the size of the minority class is 10, and I resample them using the same two methods.</p>\n\n<p><a href=\"https://i.stack.imgur.com/3uEZo.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/3uEZo.png\" alt=\"enter image description here\"></a></p>\n\n<pre><code>Red points:\nmu_x = 0.944, mu_y = 0.289, std_x = 0.943, std_y = 0.867\n\nMagenta points:\nmu_x = 0.974, mu_y = 0.298, std_x = 0.700, std_y = 0.617\n</code></pre>\n\n<p>This time x-component of the sample mean is OK, its y-component is a little overestimated, and the standard deviation is underestimated. The separating line is again incorrect. </p>\n\n<p><a href=\"https://i.stack.imgur.com/zpE7q.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zpE7q.png\" alt=\"enter image description here\"></a></p>\n\n<pre><code>Red points:\nmu_x = 0.922, mu_y = -0.236, std_x = 1.066, std_y = 1.097\n\nMagenta points:\nmu_x = 0.924, mu_y = -0.244, std_x = 0.757, std_y = 0.749\n</code></pre>\n\n<p>In the last picture we are lucky to get a sample that has almost the same mean and standard deviation as the population. Therefore, the separating line is very close to the line in the first picture where the data were balanced. Notice that the standard deviation for SMOTE is always smaller because new data are added between the existing data, not outside of them.</p>\n\n<p>You might consider undersampling instead of oversampling. Check this <a href=\"http://www.svds.com/learning-imbalanced-classes/\" rel=\"nofollow noreferrer\">link</a>.</p>\n\n<p>The code for the last 3 pictures:</p>\n\n<pre><code>import numpy as np \nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\n\nn_points1 = 500\nn_points2 = 10\nmu1 = np.array([-2,0])\nmu2 = np.array([1,0])\n\nsig = 1\n\ncl1 = sig * np.random.randn(n_points1,2) + mu1\ncl2 = sig * np.random.randn(n_points2,2) + mu2\n\ncl2 = np.tile(cl2,(n_points1//n_points2,1)) # oversampling \n\n# A kind of SMOTE but not quite\ncl3 = np.zeros_like(cl1)\nfor k in range(len(cl3)):\n    i = np.random.randint(low=0, high=n_points2, size=2)\n    cl3[k,:] = (cl2[i[0]]+cl2[i[1]])/2\n\nprint('Red points:')\nprint('mu_x = %.3f, mu_y = %.3f, std_x = %.3f, std_y = %.3f' \n    % (np.mean(cl2[:,0]), np.mean(cl2[:,1]), np.std(cl2[:,0]), np.std(cl2[:,1])) )\n\nprint('Magenta points:')\nprint('mu_x = %.3f, mu_y = %.3f, std_x = %.3f, std_y = %.3f' \n    % (np.mean(cl3[:,0]), np.mean(cl3[:,1]), np.std(cl3[:,0]), np.std(cl3[:,1])) )\n\ny1 = np.zeros((cl1.shape[0],1))\ny2 = np.ones((cl2.shape[0],1))\n\nX = np.vstack((cl1,cl2))\nX3 = np.vstack((cl1,cl3))\n\ny = np.vstack((y1,y2))\n\nlogreg = LogisticRegression()\n\nlogreg.fit(X, y.ravel())\nw = logreg.coef_[0]\na = -w[0] / w[1]\n\nxx = np.linspace(-4,4)\nyy = a * xx - (logreg.intercept_[0]) / w[1]\n\nplt.scatter(cl1[:,0], cl1[:,1], s = 50, marker='.', color='green')\nplt.scatter(cl2[:,0], cl2[:,1], s = 50, marker='.', color='red')\nplt.plot(xx, yy, 'b-')\n\nlogreg.fit(X3, y.ravel())\nw = logreg.coef_[0]\na = -w[0] / w[1]\nyy = a * xx - (logreg.intercept_[0]) / w[1]\n\nplt.scatter(cl3[:,0], cl3[:,1], s = 10, marker='.', color='magenta')\nplt.plot(xx, yy, 'k-')\nplt.xlim((-5, 4))   \nplt.ylim((-5, 5))\nplt.grid()\nplt.show()\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14683",
            "_score": 8.081148,
            "_source": {
                "title": "Generate predictions that are orthogonal (uncorrelated) to a given variable",
                "content": "Generate predictions that are orthogonal (uncorrelated) to a given variable <p>I have an <code>X</code> matrix, a <code>y</code> variable, and another variable <code>ORTHO_VAR</code>.  I need to predict the <code>y</code> variable using <code>X</code>, however, the predictions from that model need to be orthogonal to <code>ORTHO_VAR</code> while being as correlated with <code>y</code> as possible.  </p>\n\n<p>I would prefer that the predictions are generated with a non-parametric method such as <code>xgboost.XGBRegressor</code> but I could use a linear method if absolutely necessary.  </p>\n\n<p><strong>This code:</strong></p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import make_regression\nfrom xgboost import XGBRegressor\n\nORTHO_VAR = 'ortho_var'\nTARGET = 'target'\nPRED = 'yhat'\n\n# Create regression dataset with two correlated targets\nX, y = make_regression(n_features=20, random_state=245, n_targets=2)\nindep_vars = ['var{}'.format(i) for i in range(X.shape[1])]\n\n# Pull into dataframe\ndf = pd.DataFrame(X, columns=indep_vars)\ndf[TARGET] = y[:, 0]\ndf[ORTHO_VAR] = y[:, 1]\n\n# Fit a model to predict TARGET\nxgb = XGBRegressor(n_estimators=10)\nxgb.fit(df[indep_vars], df[TARGET])\ndf[PRED] = xgb.predict(df[indep_vars])\n\n# Correlation should be low or preferably zero\npred_corr_w_ortho = df.corr().abs()[PRED][ORTHO_VAR]\nassert pred_corr_w_ortho &lt; 0.01, \"Correlation score: {0} is superior to the given threshold.\".format(pred_corr_w_ortho)\n</code></pre>\n\n<p><strong>Returns this:</strong></p>\n\n<pre><code>---------------------------------------------------------------------------\nAssertionError                           \n      1 pred_corr_w_ortho = df.corr().abs()[PRED][ORTHO_VAR]\n----&gt; 2 assert pred_corr_w_ortho &lt; 0.01, \"Correlation score: {0} is superior to the given threshold.\".format(pred_corr_w_ortho)\n\nAssertionError: Correlation score: 0.5895885756753665 is superior to the given threshold.\n</code></pre>\n\n<p>...and I would like something that maintains as much predictive accuracy as possible while remaining orthogonal to <code>ORTHO_VAR</code></p>\n <correlation><p>This requirement can be satisfied by adding sufficient noise to predictions <span class=\"math-container\">$\\hat{y}$</span> to decorrelate them from orthogonal values <span class=\"math-container\">$v$</span>. Ideally, if <span class=\"math-container\">$\\hat{y}$</span> is already decorrelated from <span class=\"math-container\">$v$</span>, no noise would be added to <span class=\"math-container\">$\\hat{y}$</span>, thus  <span class=\"math-container\">$\\hat{y}$</span> would be maximally correlated with <span class=\"math-container\">$y$</span>.</p>\n\n<p>Mathematically, we want to create <span class=\"math-container\">$\\hat{y}'=\\hat{y}+\\epsilon$</span> from <span class=\"math-container\">$\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon})$</span>, to satisfy <span class=\"math-container\">$$r_{\\hat{y}'v} = \\frac{\\sigma_{\\hat{y}'v}}{\\sigma_{\\hat{y}'}\\sigma_{v}}  &lt; \\delta$$</span> for arbitrary threshold <span class=\"math-container\">$\\delta$</span>. Now, lets expand this inequality to find a lower-bound for std of noise <span class=\"math-container\">$\\epsilon$</span>, i.e. <span class=\"math-container\">$\\sigma_{\\epsilon}$</span>.\n<span class=\"math-container\">$$\\begin{align*}\n\\sigma_{\\hat{y}'}^2&amp;=\\sigma_{\\hat{y}}^2 + \\sigma_{\\epsilon}^2,\\\\\n\\sigma_{\\hat{y}'v}&amp;={\\Bbb E}\\left[(\\hat{y}+\\epsilon - \\mu_{\\hat{y}} - \\overbrace{\\mu_{\\epsilon}}^{=0})(v-\\mu_{v})\\right]\\\\\n&amp;={\\Bbb E}\\left[(\\hat{y} - \\mu_{\\hat{y}})(v-\\mu_{v})\\right]+\\overbrace{{\\Bbb E}\\left[\\epsilon(v-\\mu_{v})\\right]}^{=0}&amp;\\\\\n&amp;=\\sigma_{\\hat{y}v},\\\\\nr_{\\hat{y}'v} &amp;= \\frac{\\sigma_{\\hat{y}'v}}{\\sigma_{\\hat{y}'}\\sigma_{v}} =\\frac{\\sigma_{\\hat{y}v}}{\\sigma_{v} \\sqrt{\\sigma_{\\hat{y}}^2+\\sigma_{\\epsilon}^2}} &lt; \\delta\\\\\n&amp;\\Rightarrow \\sigma_{\\hat{y}}\\sqrt{\\left(\\frac{r_{\\hat{y}v}}{\\delta}\\right)^2 - 1} &lt; \\sigma_{\\epsilon}\n\\end{align*}$$</span></p>\n\n<p>Since all the variables in the left side of inequality can be calculated, we can sample noises from <span class=\"math-container\">$\\mathcal{N}(0, \\sigma_{\\epsilon})$</span> and add them to <span class=\"math-container\">$\\hat{y}$</span> to satisfy the original inequality.</p>\n\n<p>Here is a code that does the exact same thing:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import make_regression\nfrom xgboost import XGBRegressor\n\nORTHO_VAR = 'ortho_var'\nIND_VARNM = 'indep_var'\nTARGET = 'target'\nCORRECTED_VARNM = 'indep_var_fixed'\n\nseed = 245\n# Create regression dataset with two correlated targets\nX, y = make_regression(n_samples=10000, n_features=20, random_state=seed, n_targets=2)\nindep_vars = ['var{}'.format(i) for i in range(X.shape[1])]\n\n# Pull into dataframe\ndf = pd.DataFrame(X, columns=indep_vars)\ndf[TARGET] = y[:, 0]\ndf[ORTHO_VAR] = y[:, 1]\n\n# Fit a model to predict TARGET\nxgb = XGBRegressor(n_estimators=10)\nxgb.fit(df[indep_vars], df[TARGET])\ndf['yhat'] = xgb.predict(df[indep_vars])\n\ndelta = 0.01\n\n# std of noise required to be added to y_hat to bring the correlation\n# of y_hat with ORTHO_VAR below delta\nstd_y_hat = np.std(df['yhat'], ddof=1)\ncorr_y_hat_ortho_var = np.corrcoef(df['yhat'], df[ORTHO_VAR])[1, 0]\ncorr_y_hat_target = np.corrcoef(df['yhat'], df[TARGET])[1, 0]\nstd_noise_lower_bound = std_y_hat * np.sqrt((corr_y_hat_ortho_var / delta)**2 - 1.0)\nstd_noise = max(0, std_noise_lower_bound) + 1\nprint('delta: ', delta)\nprint('std_y_hat: ', std_y_hat)\nprint('corr_y_hat_target: ', corr_y_hat_target)\nprint('corr_y_hat_ortho_var: ', corr_y_hat_ortho_var)\nprint('std_noise_lower_bound: ', std_noise_lower_bound)\nprint('std_noise: ', std_noise)\n\n# add noise\nnp.random.seed(seed)\nnoises = np.random.normal(0, std_noise, len(df['yhat']))\nnoises -= np.mean(noises)  # remove slight deviations from zero mean\nprint('noise_samples: mean:', np.mean(noises), ', std: ', np.std(noises))\ndf['yhat'] = df['yhat'] + noises\n\n# measure new correlation\ncorr_y_hat_ortho_var = np.corrcoef(df['yhat'], df[ORTHO_VAR])[1, 0]\ncorr_y_hat_target = np.corrcoef(df['yhat'], df[TARGET])[1, 0]\nprint('new corr_y_hat_target: ', corr_y_hat_target)\nprint('new corr_y_hat_ortho_var: ', corr_y_hat_ortho_var)\n# Correlation should be low or preferably zero\nassert corr_y_hat_ortho_var &lt; delta, corr_y_hat_ortho_var\nassert -delta &lt; corr_y_hat_ortho_var, corr_y_hat_ortho_var\n</code></pre>\n\n<p>which outputs:</p>\n\n<pre><code>delta:  0.01\nstd_y_hat:  69.48568725585938\ncorr_y_hat_target:  0.8207672834857673\ncorr_y_hat_ortho_var:  0.7663936356880843\nstd_noise_lower_bound:  5324.885500165032\nstd_noise:  5325.885500165032\nnoise_samples: mean: 1.1059455573558807e-13 , std:  5373.914830034988\nnew corr_y_hat_target:  -0.004125016071865934\nnew corr_y_hat_ortho_var:  -0.000541131379457552\n</code></pre>\n\n<p>You can experiment with other <code>delta</code>s. By comparing <code>std_y_hat</code> with <code>std_noise_lower_bound</code>, you can see that a huge noise must be added to <span class=\"math-container\">$\\hat{y}$</span> to decorrelate it from <span class=\"math-container\">$v$</span> bellow <span class=\"math-container\">$0.01$</span>, which dramatically decolerates <span class=\"math-container\">$\\hat{y}$</span> from <span class=\"math-container\">$y$</span> too.</p>\n\n<p>Note: <code>Assertion</code> might fail for too small thresholds <span class=\"math-container\">$\\delta$</span> due to insufficient sample count.</p>\n",
                "codes": [
                    [
                        "import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import make_regression\nfrom xgboost import XGBRegressor\n\nORTHO_VAR = 'ortho_var'\nIND_VARNM = 'indep_var'\nTARGET = 'target'\nCORRECTED_VARNM = 'indep_var_fixed'\n\nseed = 245\n# Create regression dataset with two correlated targets\nX, y = make_regression(n_samples=10000, n_features=20, random_state=seed, n_targets=2)\nindep_vars = ['var{}'.format(i) for i in range(X.shape[1])]\n\n# Pull into dataframe\ndf = pd.DataFrame(X, columns=indep_vars)\ndf[TARGET] = y[:, 0]\ndf[ORTHO_VAR] = y[:, 1]\n\n# Fit a model to predict TARGET\nxgb = XGBRegressor(n_estimators=10)\nxgb.fit(df[indep_vars], df[TARGET])\ndf['yhat'] = xgb.predict(df[indep_vars])\n\ndelta = 0.01\n\n# std of noise required to be added to y_hat to bring the correlation\n# of y_hat with ORTHO_VAR below delta\nstd_y_hat = np.std(df['yhat'], ddof=1)\ncorr_y_hat_ortho_var = np.corrcoef(df['yhat'], df[ORTHO_VAR])[1, 0]\ncorr_y_hat_target = np.corrcoef(df['yhat'], df[TARGET])[1, 0]\nstd_noise_lower_bound = std_y_hat * np.sqrt((corr_y_hat_ortho_var / delta)**2 - 1.0)\nstd_noise = max(0, std_noise_lower_bound) + 1\nprint('delta: ', delta)\nprint('std_y_hat: ', std_y_hat)\nprint('corr_y_hat_target: ', corr_y_hat_target)\nprint('corr_y_hat_ortho_var: ', corr_y_hat_ortho_var)\nprint('std_noise_lower_bound: ', std_noise_lower_bound)\nprint('std_noise: ', std_noise)\n\n# add noise\nnp.random.seed(seed)\nnoises = np.random.normal(0, std_noise, len(df['yhat']))\nnoises -= np.mean(noises)  # remove slight deviations from zero mean\nprint('noise_samples: mean:', np.mean(noises), ', std: ', np.std(noises))\ndf['yhat'] = df['yhat'] + noises\n\n# measure new correlation\ncorr_y_hat_ortho_var = np.corrcoef(df['yhat'], df[ORTHO_VAR])[1, 0]\ncorr_y_hat_target = np.corrcoef(df['yhat'], df[TARGET])[1, 0]\nprint('new corr_y_hat_target: ', corr_y_hat_target)\nprint('new corr_y_hat_ortho_var: ', corr_y_hat_ortho_var)\n# Correlation should be low or preferably zero\nassert corr_y_hat_ortho_var < delta, corr_y_hat_ortho_var\nassert -delta < corr_y_hat_ortho_var, corr_y_hat_ortho_var\n",
                        "delta:  0.01\nstd_y_hat:  69.48568725585938\ncorr_y_hat_target:  0.8207672834857673\ncorr_y_hat_ortho_var:  0.7663936356880843\nstd_noise_lower_bound:  5324.885500165032\nstd_noise:  5325.885500165032\nnoise_samples: mean: 1.1059455573558807e-13 , std:  5373.914830034988\nnew corr_y_hat_target:  -0.004125016071865934\nnew corr_y_hat_ortho_var:  -0.000541131379457552\n"
                    ]
                ],
                "question_id:": "49226",
                "question_votes:": "7",
                "question_text:": "<p>I have an <code>X</code> matrix, a <code>y</code> variable, and another variable <code>ORTHO_VAR</code>.  I need to predict the <code>y</code> variable using <code>X</code>, however, the predictions from that model need to be orthogonal to <code>ORTHO_VAR</code> while being as correlated with <code>y</code> as possible.  </p>\n\n<p>I would prefer that the predictions are generated with a non-parametric method such as <code>xgboost.XGBRegressor</code> but I could use a linear method if absolutely necessary.  </p>\n\n<p><strong>This code:</strong></p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import make_regression\nfrom xgboost import XGBRegressor\n\nORTHO_VAR = 'ortho_var'\nTARGET = 'target'\nPRED = 'yhat'\n\n# Create regression dataset with two correlated targets\nX, y = make_regression(n_features=20, random_state=245, n_targets=2)\nindep_vars = ['var{}'.format(i) for i in range(X.shape[1])]\n\n# Pull into dataframe\ndf = pd.DataFrame(X, columns=indep_vars)\ndf[TARGET] = y[:, 0]\ndf[ORTHO_VAR] = y[:, 1]\n\n# Fit a model to predict TARGET\nxgb = XGBRegressor(n_estimators=10)\nxgb.fit(df[indep_vars], df[TARGET])\ndf[PRED] = xgb.predict(df[indep_vars])\n\n# Correlation should be low or preferably zero\npred_corr_w_ortho = df.corr().abs()[PRED][ORTHO_VAR]\nassert pred_corr_w_ortho &lt; 0.01, \"Correlation score: {0} is superior to the given threshold.\".format(pred_corr_w_ortho)\n</code></pre>\n\n<p><strong>Returns this:</strong></p>\n\n<pre><code>---------------------------------------------------------------------------\nAssertionError                           \n      1 pred_corr_w_ortho = df.corr().abs()[PRED][ORTHO_VAR]\n----&gt; 2 assert pred_corr_w_ortho &lt; 0.01, \"Correlation score: {0} is superior to the given threshold.\".format(pred_corr_w_ortho)\n\nAssertionError: Correlation score: 0.5895885756753665 is superior to the given threshold.\n</code></pre>\n\n<p>...and I would like something that maintains as much predictive accuracy as possible while remaining orthogonal to <code>ORTHO_VAR</code></p>\n",
                "tags": "<correlation>",
                "answers": [
                    [
                        "49322",
                        "2",
                        "49226",
                        "",
                        "",
                        "<p>This requirement can be satisfied by adding sufficient noise to predictions <span class=\"math-container\">$\\hat{y}$</span> to decorrelate them from orthogonal values <span class=\"math-container\">$v$</span>. Ideally, if <span class=\"math-container\">$\\hat{y}$</span> is already decorrelated from <span class=\"math-container\">$v$</span>, no noise would be added to <span class=\"math-container\">$\\hat{y}$</span>, thus  <span class=\"math-container\">$\\hat{y}$</span> would be maximally correlated with <span class=\"math-container\">$y$</span>.</p>\n\n<p>Mathematically, we want to create <span class=\"math-container\">$\\hat{y}'=\\hat{y}+\\epsilon$</span> from <span class=\"math-container\">$\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon})$</span>, to satisfy <span class=\"math-container\">$$r_{\\hat{y}'v} = \\frac{\\sigma_{\\hat{y}'v}}{\\sigma_{\\hat{y}'}\\sigma_{v}}  &lt; \\delta$$</span> for arbitrary threshold <span class=\"math-container\">$\\delta$</span>. Now, lets expand this inequality to find a lower-bound for std of noise <span class=\"math-container\">$\\epsilon$</span>, i.e. <span class=\"math-container\">$\\sigma_{\\epsilon}$</span>.\n<span class=\"math-container\">$$\\begin{align*}\n\\sigma_{\\hat{y}'}^2&amp;=\\sigma_{\\hat{y}}^2 + \\sigma_{\\epsilon}^2,\\\\\n\\sigma_{\\hat{y}'v}&amp;={\\Bbb E}\\left[(\\hat{y}+\\epsilon - \\mu_{\\hat{y}} - \\overbrace{\\mu_{\\epsilon}}^{=0})(v-\\mu_{v})\\right]\\\\\n&amp;={\\Bbb E}\\left[(\\hat{y} - \\mu_{\\hat{y}})(v-\\mu_{v})\\right]+\\overbrace{{\\Bbb E}\\left[\\epsilon(v-\\mu_{v})\\right]}^{=0}&amp;\\\\\n&amp;=\\sigma_{\\hat{y}v},\\\\\nr_{\\hat{y}'v} &amp;= \\frac{\\sigma_{\\hat{y}'v}}{\\sigma_{\\hat{y}'}\\sigma_{v}} =\\frac{\\sigma_{\\hat{y}v}}{\\sigma_{v} \\sqrt{\\sigma_{\\hat{y}}^2+\\sigma_{\\epsilon}^2}} &lt; \\delta\\\\\n&amp;\\Rightarrow \\sigma_{\\hat{y}}\\sqrt{\\left(\\frac{r_{\\hat{y}v}}{\\delta}\\right)^2 - 1} &lt; \\sigma_{\\epsilon}\n\\end{align*}$$</span></p>\n\n<p>Since all the variables in the left side of inequality can be calculated, we can sample noises from <span class=\"math-container\">$\\mathcal{N}(0, \\sigma_{\\epsilon})$</span> and add them to <span class=\"math-container\">$\\hat{y}$</span> to satisfy the original inequality.</p>\n\n<p>Here is a code that does the exact same thing:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import make_regression\nfrom xgboost import XGBRegressor\n\nORTHO_VAR = 'ortho_var'\nIND_VARNM = 'indep_var'\nTARGET = 'target'\nCORRECTED_VARNM = 'indep_var_fixed'\n\nseed = 245\n# Create regression dataset with two correlated targets\nX, y = make_regression(n_samples=10000, n_features=20, random_state=seed, n_targets=2)\nindep_vars = ['var{}'.format(i) for i in range(X.shape[1])]\n\n# Pull into dataframe\ndf = pd.DataFrame(X, columns=indep_vars)\ndf[TARGET] = y[:, 0]\ndf[ORTHO_VAR] = y[:, 1]\n\n# Fit a model to predict TARGET\nxgb = XGBRegressor(n_estimators=10)\nxgb.fit(df[indep_vars], df[TARGET])\ndf['yhat'] = xgb.predict(df[indep_vars])\n\ndelta = 0.01\n\n# std of noise required to be added to y_hat to bring the correlation\n# of y_hat with ORTHO_VAR below delta\nstd_y_hat = np.std(df['yhat'], ddof=1)\ncorr_y_hat_ortho_var = np.corrcoef(df['yhat'], df[ORTHO_VAR])[1, 0]\ncorr_y_hat_target = np.corrcoef(df['yhat'], df[TARGET])[1, 0]\nstd_noise_lower_bound = std_y_hat * np.sqrt((corr_y_hat_ortho_var / delta)**2 - 1.0)\nstd_noise = max(0, std_noise_lower_bound) + 1\nprint('delta: ', delta)\nprint('std_y_hat: ', std_y_hat)\nprint('corr_y_hat_target: ', corr_y_hat_target)\nprint('corr_y_hat_ortho_var: ', corr_y_hat_ortho_var)\nprint('std_noise_lower_bound: ', std_noise_lower_bound)\nprint('std_noise: ', std_noise)\n\n# add noise\nnp.random.seed(seed)\nnoises = np.random.normal(0, std_noise, len(df['yhat']))\nnoises -= np.mean(noises)  # remove slight deviations from zero mean\nprint('noise_samples: mean:', np.mean(noises), ', std: ', np.std(noises))\ndf['yhat'] = df['yhat'] + noises\n\n# measure new correlation\ncorr_y_hat_ortho_var = np.corrcoef(df['yhat'], df[ORTHO_VAR])[1, 0]\ncorr_y_hat_target = np.corrcoef(df['yhat'], df[TARGET])[1, 0]\nprint('new corr_y_hat_target: ', corr_y_hat_target)\nprint('new corr_y_hat_ortho_var: ', corr_y_hat_ortho_var)\n# Correlation should be low or preferably zero\nassert corr_y_hat_ortho_var &lt; delta, corr_y_hat_ortho_var\nassert -delta &lt; corr_y_hat_ortho_var, corr_y_hat_ortho_var\n</code></pre>\n\n<p>which outputs:</p>\n\n<pre><code>delta:  0.01\nstd_y_hat:  69.48568725585938\ncorr_y_hat_target:  0.8207672834857673\ncorr_y_hat_ortho_var:  0.7663936356880843\nstd_noise_lower_bound:  5324.885500165032\nstd_noise:  5325.885500165032\nnoise_samples: mean: 1.1059455573558807e-13 , std:  5373.914830034988\nnew corr_y_hat_target:  -0.004125016071865934\nnew corr_y_hat_ortho_var:  -0.000541131379457552\n</code></pre>\n\n<p>You can experiment with other <code>delta</code>s. By comparing <code>std_y_hat</code> with <code>std_noise_lower_bound</code>, you can see that a huge noise must be added to <span class=\"math-container\">$\\hat{y}$</span> to decorrelate it from <span class=\"math-container\">$v$</span> bellow <span class=\"math-container\">$0.01$</span>, which dramatically decolerates <span class=\"math-container\">$\\hat{y}$</span> from <span class=\"math-container\">$y$</span> too.</p>\n\n<p>Note: <code>Assertion</code> might fail for too small thresholds <span class=\"math-container\">$\\delta$</span> due to insufficient sample count.</p>\n",
                        "",
                        "5"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17656",
            "_score": 7.9656315,
            "_source": {
                "title": "Can machine learning learn a function like finding maximum from a list?",
                "content": "Can machine learning learn a function like finding maximum from a list? <p>I have an input which is a list and the output is the maximum of the elements of the input-list.</p>\n\n<p>Can machine learning learn such a function which always selects the maximum of the input-elements present in the input?</p>\n\n<p>This might seem as a pretty basic question but it might give me an understanding of what machine learning can do in general. Thanks!</p>\n <machine-learning><deep-learning><p>I will exclude educated designs from\nmy answer. <strong>No it is not possible</strong> to use an out of the box machine learning (ML) approach to <strong>fully</strong> represent the maximum function for <strong>arbitrary</strong> lists with arbitrary precision. ML is a data-based method and it is clear that you will not be able to approximate a function at regions where you do not have any data points. Hence, the space of possible observations (which is infinite) cannot be covered by finite observations.</p>\n\n<p>My statements have a theoretical foundation with Cybeko\u2019s Universal Approximation Theorem for neural networks. I will\nquote the theorem\nfrom\nWikipedia:</p>\n\n<blockquote>\n  <p>In the mathematical theory of artificial neural networks, the\n  universal approximation theorem states[1] that a feed-forward network\n  with a single hidden layer containing a finite number of neurons can\n  approximate continuous functions on compact subsets of <span class=\"math-container\">$\\mathbb{R}^n$</span>, under mild\n  assumptions on the activation function. The theorem thus states that\n  simple neural networks can represent a wide variety of interesting\n  functions when given appropriate parameters; however, it does not\n  touch upon the algorithmic learnability of those parameters.</p>\n</blockquote>\n\n<p>The most important part is the bounded subset of <span class=\"math-container\">$\\mathbb{R}^n$</span>. This additional statement restricts the application of approximating the maximum function for <span class=\"math-container\">$x\\in \\mathbb{R}$</span>. This restriction is manifesting itself in the poor fit of the model from the answer with the most upvotes.</p>\n\n<p>If your space of observations is compact then you might be able to approximate the maximum function with a finite data set. As the top voted answer made clear you should not reinvent the wheel!</p>\n<h2>Learning algorithms</h2>\n\n<p>Instead of learning a function as a calculation done by a feed-forward neural network, there's a whole research domain regarding learning <em>algorithms</em> from sample data. For example, one might use something like <a href=\"https://en.wikipedia.org/wiki/Neural_Turing_machine\" rel=\"nofollow noreferrer\">a Neural Turing Machine</a> or some other method where execution of an algorithm is controlled by machine learning at its decision points. Toy algoritms like finding a maximum, or sorting a list, or reversing a list, or filtering a list are commonly used as examples in algorithm learning research.</p>\n<p><strong>Yes.</strong>\nVery importantly, YOU decide the architecture of a machine learning solution. Architectures and training procedures don't write themselves; they must be designed or templated and the training follows as a means of discovering a parameterization of the architecture fitting to a set of data points.</p>\n\n<p>You can construct a very simple architecture that actually includes a maximum function:</p>\n\n<pre><code>net(x) = a * max(x) + b * min(x)\n</code></pre>\n\n<p>where <em>a</em> and <em>b</em> are learned parameters. </p>\n\n<p>Given enough training samples and a reasonable training routine, this very simple architecture will learn very quickly to set a to 1 and b to zero for your task.</p>\n\n<p>Machine learning often takes the form of entertaining multiple hypotheses about featurization and transformation of input data points, and learning to preserve only those hypotheses that are correlated with the target variable. The hypotheses are encoded explicitly in the architecture and sub-functions available in a parameterized algorithm, or as the assumptions encoded in a \"parameterless\" algorithm.</p>\n\n<p>For example, the choice to use dot products and nonlinearities as is common in vanilla neural network ML is somewhat arbitrary; it expresses the encompassing hypothesis that a function can be constructed using a predetermined compositional network structure of linear transformations and threshold functions. Different parameterizations of that network embody different hypotheses about which linear transformations to use. Any toolbox of functions can be used and a machine learner's job is to discover through differentiation or trial and error or some other repeatable signal which functions or features in its array best minimize an error metric. In the example given above, the learned network simply reduces to the maximum function itself, whereas an undifferentiated network could alternatively \"learn\" a minimum function. These functions can be expressed or approximated via other means, as in the linear or neural net regression function in another answer. In sum, it really depends on which functions or LEGO pieces you have in your ML architecture toolbox.</p>\n<p><em>Maybe</em>, but note that this is one of those cases where <em>machine learning is not the answer</em>. There is a tendency to try and shoehorn machine learning into cases where really, bog standard rules-based solutions are faster, simpler and just generally the right choice :P</p>\n\n<blockquote>\n  <p>Just because you can, doesn't mean you should</p>\n</blockquote>\n\n<p><strong>Edit</strong>: I originally wrote this as \"Yes, but note that...\" but then started to doubt myself, having never seen it done. I tried it out this afternoon and it's certainly doable:</p>\n\n<pre><code>import numpy as np\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Dropout\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import EarlyStopping\n\n# Create an input array of 50,000 samples of 20 random numbers each\nx = np.random.randint(0, 100, size=(50000, 20))\n\n# And a one-hot encoded target denoting the index of the maximum of the inputs\ny = to_categorical(np.argmax(x, axis=1), num_classes=20)\n\n# Split into training and testing datasets\nx_train, x_test, y_train, y_test = train_test_split(x, y)\n\n# Build a network, probaly needlessly complicated since it needs a lot of dropout to\n# perform even reasonably well.\n\ni = Input(shape=(20, ))\na = Dense(1024, activation='relu')(i)\nb = Dense(512, activation='relu')(a)\nba = Dropout(0.3)(b)\nc = Dense(256, activation='relu')(ba)\nd = Dense(128, activation='relu')(c)\no = Dense(20, activation='softmax')(d)\n\nmodel = Model(inputs=i, outputs=o)\n\nes = EarlyStopping(monitor='val_loss', patience=3)\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy')\n\nmodel.fit(x_train, y_train, epochs=15, batch_size=8, validation_data=[x_test, y_test], callbacks=[es])\n\nprint(np.where(np.argmax(model.predict(x_test), axis=1) == np.argmax(y_test, axis=1), 1, 0).mean())\n</code></pre>\n\n<p>Output is 0.74576, so it's correctly finding the max 74.5% of the time. I have no doubt that that could be improved, but as I say this is not a usecase I would recommend for ML.</p>\n\n<p><strong>EDIT 2</strong>: Actually I re-ran this this morning using sklearn's RandomForestClassifier and it performed significantly better:</p>\n\n<pre><code># instantiation of the arrays is identical\n\nrfc = RandomForestClassifier(n_estimators=1000, verbose=1)\nrfc.fit(x_train, y_train)\n\nyhat_proba = rfc.predict_proba(x_test)\n\n\n# We have some annoying transformations to do because this .predict_proba() call returns the data in a weird format of shape (20, 12500, 2).\n\nfor i in range(len(yhat_proba)):\n    yhat_proba[i] = yhat_proba[i][:, 1]\n\npyhat = np.reshape(np.ravel(yhat_proba), (12500,20), order='F')\n\nprint(np.where(np.argmax(pyhat, axis=1) == np.argmax(y_test, axis=1), 1, 0).mean())\n</code></pre>\n\n<p>And the score here is 94.4% of samples with the max correctly identified, which is pretty good indeed.</p>\n<p>Here's an expansion on my comment.  To preface, absolutely @DanScally is right that there's no reason to use ML for finding a maximum of a list.  But I think your \"it might give me an understanding of what machine learning can do in general\" is good enough reason to delve into this.</p>\n\n<p>You ask about more general machine learning, but I'll focus on neural networks.  In that context, we must first ask whether the actual functions produced by a neural network can approximate (or evaluate exactly) <span class=\"math-container\">$\\max$</span>, and only then can we further inquire whether any of the (common?) training methods can fit a NN approximating <span class=\"math-container\">$\\max$</span>.</p>\n\n<hr>\n\n<p>The comments, and @MachineLearner's answer brought up universal approximation theorems: on a <em>bounded domain</em>, a neural network can approximate any reasonably nice function like <span class=\"math-container\">$\\max$</span>, but we can't expect a priori to approximate <span class=\"math-container\">$\\max$</span> on arbitrary input, nor to exactly calculate <span class=\"math-container\">$\\max$</span> anywhere.</p>\n\n<p>But, it turns out that a neural network <strong>can exactly</strong> sort arbitrary input numbers.  Indeed, <span class=\"math-container\">$n$</span> <span class=\"math-container\">$n$</span>-bit integers can be sorted by a network with just two hidden layers of quadratic size.  <a href=\"https://core.ac.uk/download/pdf/4894171.pdf\" rel=\"nofollow noreferrer\">Depth Efficient Neural Networks for Division and Related Problems</a>, Theorem 7 on page 955; many thanks to @MaximilianJanisch in <a href=\"https://datascience.stackexchange.com/a/55593/55122\">this answer</a> for finding this reference.</p>\n\n<p>I'll briefly describe a simplification of the approach in that paper to produce the <span class=\"math-container\">$\\operatorname{argmax}$</span> function for <span class=\"math-container\">$n$</span> arbitrary distinct inputs.  The first hidden layer consists of <span class=\"math-container\">$\\binom{n}{2}$</span> neurons, each representing the indicator variable <span class=\"math-container\">$\\delta_{ij} = \\mathbf{1}(x_i &lt; x_j)$</span>, for <span class=\"math-container\">$i&lt;j$</span>.  These are easily built as <span class=\"math-container\">$x_j-x_i$</span> with a step indicator.  The next layer has <span class=\"math-container\">$n$</span> neurons, one for each input <span class=\"math-container\">$x_i$</span>; start with the sum <span class=\"math-container\">$\\sum_{j&lt;i} \\delta_{ji} + \\sum_{j&gt;i} (1-\\delta_{ij})$</span>; that is, the number of <span class=\"math-container\">$j$</span> such that <span class=\"math-container\">$x_i&gt;x_j$</span>, and hence the position of <span class=\"math-container\">$x_i$</span> in the sorted list.  To complete the argmax, just threshold this layer.<br>\nAt this point, if we could multiply, we'd get the actual maximum value pretty easily.  The solution in the paper is to use the binary representation of the numbers, at which point binary multiplication is the same as thresholded addition.  To just get the argmax, it suffices to have a simple linear function multiplying the <span class=\"math-container\">$i$</span>th indicator by <span class=\"math-container\">$i$</span> and summing.</p>\n\n<hr>\n\n<p>Finally, for the subsequent question: can we can train a NN into this state.  @DanScally got us started; maybe knowing the theoretical architecture can help us cheat into the solution?  (Note that if we can learn/approximate the particular set of weights above, the net will actually perform well outside the range of the training samples.)</p>\n\n<p><a href=\"https://github.com/bmreiniger/datascience.stackexchange/blob/master/56676.ipynb\" rel=\"nofollow noreferrer\">Notebook in github / Colab</a></p>\n\n<p>Changing things just a little bit, I get better testing score (0.838), and even testing on a sample outside the original training range gets a decent score (0.698).  Using inputs scaled to <span class=\"math-container\">$[-1,1]$</span> gets the test score up to 0.961, with an out-of-range score of 0.758.  But, I'm scoring with the same method as @DanScally, which seems a little dishonest: the identity function will score perfectly on this metric.  I also printed out a few coefficients to see whether anything close to the above described exact fit appears (not really); and a few raw outputs, which suggest the model is too timid in predicting a maximum, erring on the side of predicting that none of the inputs are the maximum.  Maybe modifying the objective could help, but at this point I've put in too much time already; if anyone cares to improve the approach, feel free to play (in Colab if you like) and let me know.</p>\n<p>Yes, even as simple machine learning as ordinary linear least squares can do this if you use some applied cleverness. </p>\n\n<p>(But most would consider this quite horrible overkill). </p>\n\n<p>(I will assume we want to find max of abs of input vector):</p>\n\n<ol>\n<li>Select a monotonically decreasing function of absolute value, for example <span class=\"math-container\">$$f(x) = \\frac{1}{x^2}$$</span></li>\n<li>Build diagonal matrix of <span class=\"math-container\">$f({\\bf r})$</span>. Let us call it <span class=\"math-container\">$\\bf C_r$</span></li>\n<li>Build vector full of ones <span class=\"math-container\">$\\bf S$</span>.</li>\n<li>Build and solve equation system <span class=\"math-container\">$(\\epsilon {\\bf I}+10^3{\\bf S}^t{\\bf S}+{\\bf C_r})^{-1}(10^3 {\\bf S}^t)$</span></li>\n<li>Let us call result vector <span class=\"math-container\">$\\bf p$</span>, it will be a probability measure (sums to 1), we can reweigh it nonlinearly, for example <span class=\"math-container\">$$p_i = \\frac{p_i^k}{\\sum|p_i|^k}$$</span></li>\n<li>Just calculate scalar product with index vector and round.</li>\n</ol>\n<p>Yes - Machine learning can learn to find the maximum in a list of numbers. </p>\n\n<p>Here is a simple example of learning to find the index of the maximum:</p>\n\n<pre><code>import numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Create training pairs where the input is a list of numbers and the output is the argmax\ntraining_data = np.random.rand(10_000, 5) # Each list is 5 elements; 10K examples\ntraining_targets = np.argmax(input_data, axis=1)\n\n# Train a descision tree with scikit-learn\nclf = DecisionTreeClassifier()\nclf.fit(input_data, targets)\n\n# Let's see if the trained model can correctly predict the argmax for new data\ntest_data = np.random.rand(1, 5)\nprediction = clf.predict(test_data)\nassert prediction == np.argmax(test_data) # The test passes - The model has learned argmax\n</code></pre>\n",
                "codes": [
                    [],
                    [],
                    [
                        "net(x) = a * max(x) + b * min(x)\n"
                    ],
                    [
                        "import numpy as np\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Dropout\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import EarlyStopping\n\n# Create an input array of 50,000 samples of 20 random numbers each\nx = np.random.randint(0, 100, size=(50000, 20))\n\n# And a one-hot encoded target denoting the index of the maximum of the inputs\ny = to_categorical(np.argmax(x, axis=1), num_classes=20)\n\n# Split into training and testing datasets\nx_train, x_test, y_train, y_test = train_test_split(x, y)\n\n# Build a network, probaly needlessly complicated since it needs a lot of dropout to\n# perform even reasonably well.\n\ni = Input(shape=(20, ))\na = Dense(1024, activation='relu')(i)\nb = Dense(512, activation='relu')(a)\nba = Dropout(0.3)(b)\nc = Dense(256, activation='relu')(ba)\nd = Dense(128, activation='relu')(c)\no = Dense(20, activation='softmax')(d)\n\nmodel = Model(inputs=i, outputs=o)\n\nes = EarlyStopping(monitor='val_loss', patience=3)\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy')\n\nmodel.fit(x_train, y_train, epochs=15, batch_size=8, validation_data=[x_test, y_test], callbacks=[es])\n\nprint(np.where(np.argmax(model.predict(x_test), axis=1) == np.argmax(y_test, axis=1), 1, 0).mean())\n",
                        "# instantiation of the arrays is identical\n\nrfc = RandomForestClassifier(n_estimators=1000, verbose=1)\nrfc.fit(x_train, y_train)\n\nyhat_proba = rfc.predict_proba(x_test)\n\n\n# We have some annoying transformations to do because this .predict_proba() call returns the data in a weird format of shape (20, 12500, 2).\n\nfor i in range(len(yhat_proba)):\n    yhat_proba[i] = yhat_proba[i][:, 1]\n\npyhat = np.reshape(np.ravel(yhat_proba), (12500,20), order='F')\n\nprint(np.where(np.argmax(pyhat, axis=1) == np.argmax(y_test, axis=1), 1, 0).mean())\n"
                    ],
                    [],
                    [],
                    [
                        "import numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Create training pairs where the input is a list of numbers and the output is the argmax\ntraining_data = np.random.rand(10_000, 5) # Each list is 5 elements; 10K examples\ntraining_targets = np.argmax(input_data, axis=1)\n\n# Train a descision tree with scikit-learn\nclf = DecisionTreeClassifier()\nclf.fit(input_data, targets)\n\n# Let's see if the trained model can correctly predict the argmax for new data\ntest_data = np.random.rand(1, 5)\nprediction = clf.predict(test_data)\nassert prediction == np.argmax(test_data) # The test passes - The model has learned argmax\n"
                    ]
                ],
                "question_id:": "56676",
                "question_votes:": "26",
                "question_text:": "<p>I have an input which is a list and the output is the maximum of the elements of the input-list.</p>\n\n<p>Can machine learning learn such a function which always selects the maximum of the input-elements present in the input?</p>\n\n<p>This might seem as a pretty basic question but it might give me an understanding of what machine learning can do in general. Thanks!</p>\n",
                "tags": "<machine-learning><deep-learning>",
                "answers": [
                    [
                        "56864",
                        "2",
                        "56676",
                        "",
                        "",
                        "<p>I will exclude educated designs from\nmy answer. <strong>No it is not possible</strong> to use an out of the box machine learning (ML) approach to <strong>fully</strong> represent the maximum function for <strong>arbitrary</strong> lists with arbitrary precision. ML is a data-based method and it is clear that you will not be able to approximate a function at regions where you do not have any data points. Hence, the space of possible observations (which is infinite) cannot be covered by finite observations.</p>\n\n<p>My statements have a theoretical foundation with Cybeko\u2019s Universal Approximation Theorem for neural networks. I will\nquote the theorem\nfrom\nWikipedia:</p>\n\n<blockquote>\n  <p>In the mathematical theory of artificial neural networks, the\n  universal approximation theorem states[1] that a feed-forward network\n  with a single hidden layer containing a finite number of neurons can\n  approximate continuous functions on compact subsets of <span class=\"math-container\">$\\mathbb{R}^n$</span>, under mild\n  assumptions on the activation function. The theorem thus states that\n  simple neural networks can represent a wide variety of interesting\n  functions when given appropriate parameters; however, it does not\n  touch upon the algorithmic learnability of those parameters.</p>\n</blockquote>\n\n<p>The most important part is the bounded subset of <span class=\"math-container\">$\\mathbb{R}^n$</span>. This additional statement restricts the application of approximating the maximum function for <span class=\"math-container\">$x\\in \\mathbb{R}$</span>. This restriction is manifesting itself in the poor fit of the model from the answer with the most upvotes.</p>\n\n<p>If your space of observations is compact then you might be able to approximate the maximum function with a finite data set. As the top voted answer made clear you should not reinvent the wheel!</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "56798",
                        "2",
                        "56676",
                        "",
                        "",
                        "<h2>Learning algorithms</h2>\n\n<p>Instead of learning a function as a calculation done by a feed-forward neural network, there's a whole research domain regarding learning <em>algorithms</em> from sample data. For example, one might use something like <a href=\"https://en.wikipedia.org/wiki/Neural_Turing_machine\" rel=\"nofollow noreferrer\">a Neural Turing Machine</a> or some other method where execution of an algorithm is controlled by machine learning at its decision points. Toy algoritms like finding a maximum, or sorting a list, or reversing a list, or filtering a list are commonly used as examples in algorithm learning research.</p>\n",
                        "",
                        "4"
                    ],
                    [
                        "56725",
                        "2",
                        "56676",
                        "",
                        "",
                        "<p><strong>Yes.</strong>\nVery importantly, YOU decide the architecture of a machine learning solution. Architectures and training procedures don't write themselves; they must be designed or templated and the training follows as a means of discovering a parameterization of the architecture fitting to a set of data points.</p>\n\n<p>You can construct a very simple architecture that actually includes a maximum function:</p>\n\n<pre><code>net(x) = a * max(x) + b * min(x)\n</code></pre>\n\n<p>where <em>a</em> and <em>b</em> are learned parameters. </p>\n\n<p>Given enough training samples and a reasonable training routine, this very simple architecture will learn very quickly to set a to 1 and b to zero for your task.</p>\n\n<p>Machine learning often takes the form of entertaining multiple hypotheses about featurization and transformation of input data points, and learning to preserve only those hypotheses that are correlated with the target variable. The hypotheses are encoded explicitly in the architecture and sub-functions available in a parameterized algorithm, or as the assumptions encoded in a \"parameterless\" algorithm.</p>\n\n<p>For example, the choice to use dot products and nonlinearities as is common in vanilla neural network ML is somewhat arbitrary; it expresses the encompassing hypothesis that a function can be constructed using a predetermined compositional network structure of linear transformations and threshold functions. Different parameterizations of that network embody different hypotheses about which linear transformations to use. Any toolbox of functions can be used and a machine learner's job is to discover through differentiation or trial and error or some other repeatable signal which functions or features in its array best minimize an error metric. In the example given above, the learned network simply reduces to the maximum function itself, whereas an undifferentiated network could alternatively \"learn\" a minimum function. These functions can be expressed or approximated via other means, as in the linear or neural net regression function in another answer. In sum, it really depends on which functions or LEGO pieces you have in your ML architecture toolbox.</p>\n",
                        "",
                        "27"
                    ],
                    [
                        "56677",
                        "2",
                        "56676",
                        "",
                        "",
                        "<p><em>Maybe</em>, but note that this is one of those cases where <em>machine learning is not the answer</em>. There is a tendency to try and shoehorn machine learning into cases where really, bog standard rules-based solutions are faster, simpler and just generally the right choice :P</p>\n\n<blockquote>\n  <p>Just because you can, doesn't mean you should</p>\n</blockquote>\n\n<p><strong>Edit</strong>: I originally wrote this as \"Yes, but note that...\" but then started to doubt myself, having never seen it done. I tried it out this afternoon and it's certainly doable:</p>\n\n<pre><code>import numpy as np\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Dropout\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import EarlyStopping\n\n# Create an input array of 50,000 samples of 20 random numbers each\nx = np.random.randint(0, 100, size=(50000, 20))\n\n# And a one-hot encoded target denoting the index of the maximum of the inputs\ny = to_categorical(np.argmax(x, axis=1), num_classes=20)\n\n# Split into training and testing datasets\nx_train, x_test, y_train, y_test = train_test_split(x, y)\n\n# Build a network, probaly needlessly complicated since it needs a lot of dropout to\n# perform even reasonably well.\n\ni = Input(shape=(20, ))\na = Dense(1024, activation='relu')(i)\nb = Dense(512, activation='relu')(a)\nba = Dropout(0.3)(b)\nc = Dense(256, activation='relu')(ba)\nd = Dense(128, activation='relu')(c)\no = Dense(20, activation='softmax')(d)\n\nmodel = Model(inputs=i, outputs=o)\n\nes = EarlyStopping(monitor='val_loss', patience=3)\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy')\n\nmodel.fit(x_train, y_train, epochs=15, batch_size=8, validation_data=[x_test, y_test], callbacks=[es])\n\nprint(np.where(np.argmax(model.predict(x_test), axis=1) == np.argmax(y_test, axis=1), 1, 0).mean())\n</code></pre>\n\n<p>Output is 0.74576, so it's correctly finding the max 74.5% of the time. I have no doubt that that could be improved, but as I say this is not a usecase I would recommend for ML.</p>\n\n<p><strong>EDIT 2</strong>: Actually I re-ran this this morning using sklearn's RandomForestClassifier and it performed significantly better:</p>\n\n<pre><code># instantiation of the arrays is identical\n\nrfc = RandomForestClassifier(n_estimators=1000, verbose=1)\nrfc.fit(x_train, y_train)\n\nyhat_proba = rfc.predict_proba(x_test)\n\n\n# We have some annoying transformations to do because this .predict_proba() call returns the data in a weird format of shape (20, 12500, 2).\n\nfor i in range(len(yhat_proba)):\n    yhat_proba[i] = yhat_proba[i][:, 1]\n\npyhat = np.reshape(np.ravel(yhat_proba), (12500,20), order='F')\n\nprint(np.where(np.argmax(pyhat, axis=1) == np.argmax(y_test, axis=1), 1, 0).mean())\n</code></pre>\n\n<p>And the score here is 94.4% of samples with the max correctly identified, which is pretty good indeed.</p>\n",
                        "",
                        "36"
                    ],
                    [
                        "57382",
                        "2",
                        "56676",
                        "",
                        "",
                        "<p>Here's an expansion on my comment.  To preface, absolutely @DanScally is right that there's no reason to use ML for finding a maximum of a list.  But I think your \"it might give me an understanding of what machine learning can do in general\" is good enough reason to delve into this.</p>\n\n<p>You ask about more general machine learning, but I'll focus on neural networks.  In that context, we must first ask whether the actual functions produced by a neural network can approximate (or evaluate exactly) <span class=\"math-container\">$\\max$</span>, and only then can we further inquire whether any of the (common?) training methods can fit a NN approximating <span class=\"math-container\">$\\max$</span>.</p>\n\n<hr>\n\n<p>The comments, and @MachineLearner's answer brought up universal approximation theorems: on a <em>bounded domain</em>, a neural network can approximate any reasonably nice function like <span class=\"math-container\">$\\max$</span>, but we can't expect a priori to approximate <span class=\"math-container\">$\\max$</span> on arbitrary input, nor to exactly calculate <span class=\"math-container\">$\\max$</span> anywhere.</p>\n\n<p>But, it turns out that a neural network <strong>can exactly</strong> sort arbitrary input numbers.  Indeed, <span class=\"math-container\">$n$</span> <span class=\"math-container\">$n$</span>-bit integers can be sorted by a network with just two hidden layers of quadratic size.  <a href=\"https://core.ac.uk/download/pdf/4894171.pdf\" rel=\"nofollow noreferrer\">Depth Efficient Neural Networks for Division and Related Problems</a>, Theorem 7 on page 955; many thanks to @MaximilianJanisch in <a href=\"https://datascience.stackexchange.com/a/55593/55122\">this answer</a> for finding this reference.</p>\n\n<p>I'll briefly describe a simplification of the approach in that paper to produce the <span class=\"math-container\">$\\operatorname{argmax}$</span> function for <span class=\"math-container\">$n$</span> arbitrary distinct inputs.  The first hidden layer consists of <span class=\"math-container\">$\\binom{n}{2}$</span> neurons, each representing the indicator variable <span class=\"math-container\">$\\delta_{ij} = \\mathbf{1}(x_i &lt; x_j)$</span>, for <span class=\"math-container\">$i&lt;j$</span>.  These are easily built as <span class=\"math-container\">$x_j-x_i$</span> with a step indicator.  The next layer has <span class=\"math-container\">$n$</span> neurons, one for each input <span class=\"math-container\">$x_i$</span>; start with the sum <span class=\"math-container\">$\\sum_{j&lt;i} \\delta_{ji} + \\sum_{j&gt;i} (1-\\delta_{ij})$</span>; that is, the number of <span class=\"math-container\">$j$</span> such that <span class=\"math-container\">$x_i&gt;x_j$</span>, and hence the position of <span class=\"math-container\">$x_i$</span> in the sorted list.  To complete the argmax, just threshold this layer.<br>\nAt this point, if we could multiply, we'd get the actual maximum value pretty easily.  The solution in the paper is to use the binary representation of the numbers, at which point binary multiplication is the same as thresholded addition.  To just get the argmax, it suffices to have a simple linear function multiplying the <span class=\"math-container\">$i$</span>th indicator by <span class=\"math-container\">$i$</span> and summing.</p>\n\n<hr>\n\n<p>Finally, for the subsequent question: can we can train a NN into this state.  @DanScally got us started; maybe knowing the theoretical architecture can help us cheat into the solution?  (Note that if we can learn/approximate the particular set of weights above, the net will actually perform well outside the range of the training samples.)</p>\n\n<p><a href=\"https://github.com/bmreiniger/datascience.stackexchange/blob/master/56676.ipynb\" rel=\"nofollow noreferrer\">Notebook in github / Colab</a></p>\n\n<p>Changing things just a little bit, I get better testing score (0.838), and even testing on a sample outside the original training range gets a decent score (0.698).  Using inputs scaled to <span class=\"math-container\">$[-1,1]$</span> gets the test score up to 0.961, with an out-of-range score of 0.758.  But, I'm scoring with the same method as @DanScally, which seems a little dishonest: the identity function will score perfectly on this metric.  I also printed out a few coefficients to see whether anything close to the above described exact fit appears (not really); and a few raw outputs, which suggest the model is too timid in predicting a maximum, erring on the side of predicting that none of the inputs are the maximum.  Maybe modifying the objective could help, but at this point I've put in too much time already; if anyone cares to improve the approach, feel free to play (in Colab if you like) and let me know.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "56862",
                        "2",
                        "56676",
                        "",
                        "",
                        "<p>Yes, even as simple machine learning as ordinary linear least squares can do this if you use some applied cleverness. </p>\n\n<p>(But most would consider this quite horrible overkill). </p>\n\n<p>(I will assume we want to find max of abs of input vector):</p>\n\n<ol>\n<li>Select a monotonically decreasing function of absolute value, for example <span class=\"math-container\">$$f(x) = \\frac{1}{x^2}$$</span></li>\n<li>Build diagonal matrix of <span class=\"math-container\">$f({\\bf r})$</span>. Let us call it <span class=\"math-container\">$\\bf C_r$</span></li>\n<li>Build vector full of ones <span class=\"math-container\">$\\bf S$</span>.</li>\n<li>Build and solve equation system <span class=\"math-container\">$(\\epsilon {\\bf I}+10^3{\\bf S}^t{\\bf S}+{\\bf C_r})^{-1}(10^3 {\\bf S}^t)$</span></li>\n<li>Let us call result vector <span class=\"math-container\">$\\bf p$</span>, it will be a probability measure (sums to 1), we can reweigh it nonlinearly, for example <span class=\"math-container\">$$p_i = \\frac{p_i^k}{\\sum|p_i|^k}$$</span></li>\n<li>Just calculate scalar product with index vector and round.</li>\n</ol>\n",
                        "",
                        ""
                    ],
                    [
                        "56684",
                        "2",
                        "56676",
                        "",
                        "",
                        "<p>Yes - Machine learning can learn to find the maximum in a list of numbers. </p>\n\n<p>Here is a simple example of learning to find the index of the maximum:</p>\n\n<pre><code>import numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Create training pairs where the input is a list of numbers and the output is the argmax\ntraining_data = np.random.rand(10_000, 5) # Each list is 5 elements; 10K examples\ntraining_targets = np.argmax(input_data, axis=1)\n\n# Train a descision tree with scikit-learn\nclf = DecisionTreeClassifier()\nclf.fit(input_data, targets)\n\n# Let's see if the trained model can correctly predict the argmax for new data\ntest_data = np.random.rand(1, 5)\nprediction = clf.predict(test_data)\nassert prediction == np.argmax(test_data) # The test passes - The model has learned argmax\n</code></pre>\n",
                        "",
                        "7"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12059",
            "_score": 7.609313,
            "_source": {
                "title": "Meaning of variance in machine learning models",
                "content": "Meaning of variance in machine learning models <p>I know that high variance cause overfitting, and high variance is that the model is sensitive to outliers.</p>\n\n<p>But can I say <strong>Variance</strong> is that when the predicted points are too prolonged lead to high variance (overfitting) and vice versa.</p>\n <machine-learning><machine-learning-model><variance><p>What is variance?</p>\n\n<p>Variance is the variability of model prediction for a given data point or a value which tells us spread of our data. Model with high variance pays a lot of attention to training data and does not generalize on the data which it hasn\u2019t seen before. As a result, such models perform very well on training data but has high error rates on test data.</p>\n\n<p>Error due to variance</p>\n\n<p>Error due to variance is the amount by which the prediction, over one training set, differs from the expected value over all the training sets. In machine learning, di\ufb00erent training data sets will result in a di\ufb00erent estimation. But ideally it should not vary too much between training sets. However, if a method has high variance then small changes in the training data can result in large changes in results.</p>\n\n<p><a href=\"https://www.coursera.org/lecture/machine-learning/diagnosing-bias-vs-variance-yCAup\" rel=\"nofollow noreferrer\">https://www.coursera.org/lecture/machine-learning/diagnosing-bias-vs-variance-yCAup</a></p>\n\n<p><a href=\"https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229\" rel=\"nofollow noreferrer\">https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229</a></p>\n<p>Its a bias variance trade-off problem:</p>\n\n<ul>\n<li>When increase model complexity, variance is increased and bias is reduced</li>\n<li>When regularize the model, bias is increased and variance is reduced.</li>\n</ul>\n\n<p><strong>Mathematically</strong></p>\n\n<p>High Bias:</p>\n\n<ul>\n<li><p>No matter how much data we feed the model, the model cannot represent the underlying relationship and has high systematic errors</p></li>\n<li><p>Poor fit</p></li>\n<li><p>Poor generalization</p></li>\n</ul>\n\n<p><a href=\"https://i.stack.imgur.com/m72Ei.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/m72Ei.png\" alt=\"High Bias\"></a></p>\n\n<p>High Variance:</p>\n\n<ul>\n<li><p>Require data to improve</p></li>\n<li><p>Can simplify the model with fewer or less complex features</p></li>\n</ul>\n\n<p><a href=\"https://i.stack.imgur.com/MOvWu.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/MOvWu.png\" alt=\"High Variance\"></a></p>\n\n<p>To approach the issue we can graph our model's performance based on varying criteria during the analysis process to visualizing behavior that may not have been apparent from the results alone.</p>\n\n<p><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html\" rel=\"nofollow noreferrer\">Learning Curves - Scikit Learn</a></p>\n\n<p>Here is learning curve for a decision tree example.</p>\n\n<p><a href=\"https://i.stack.imgur.com/BCX9V.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/BCX9V.png\" alt=\"enter image description here\"></a></p>\n\n<p>See that the maximum depth 3 is the one that represents the best learning curve.</p>\n\n<p>Note that in this example the maximum depth 3 is the one that represents the best learning curve.</p>\n\n<p>Even with the addition of more training points the score of the training curve reduces your score a little, but gradually tends to decrease this reduction demonstrating stability even with the addition of a high number of training points.</p>\n\n<p>Already in the case of the test curve, with the addition of more training points the score tends to increase significantly at the beginning, denoting the best fit of the model, however even if it converges in high numbers of training points the score of the curve also achieves a stability in the improvement in a certain number of training points.</p>\n\n<p>Having more training points benefits the model until a certain point in time that the scores of your training and test curves stabilize, not requiring further training points increment.</p>\n\n<p>A excelent reference is in the link bellow:\n<a href=\"https://www.ritchieng.com/applying-machine-learning/\" rel=\"nofollow noreferrer\">Andrew Ng Guide</a></p>\n<p><em>Variance</em> is the mean of squared deviations from the mean. Analyzing variance tests, the hypothesis that the means of two or more populations are equal.</p>\n\n<p><code>Bias versus variance trade-off</code></p>\n\n<p>Every model has both bias and variance error components in addition to white noise. Bias\nand variance are inversely related to each other; while trying to reduce one component, the other component of the model will increase. The ideal model will have both low bias and low variance</p>\n\n<p>An example of a high bias model is logistic or linear regression, in which the fit of the\nmodel is merely a straight line and may have a high error component due to the fact that a linear model could not approximate underlying data well.</p>\n\n<p>An example of a high variance model is a decision tree, in which the model may create too\nmuch wiggly curve as a fit, in which even a small change in training data will cause a\ndrastic change in the fit of the curve.</p>\n\n<p>The above information is from the book <code>Statistics for Machine Learning</code> which i used to refer</p>\n<p><em>Variance</em> actually measures the variability of the model prediction (say, for simplification, for a particular sample instance) <strong>if</strong> we would retrain the model multiple times (on different subsets of the data).</p>\n\n<p>To gain an intuitive feeling of variance, suppose you have 100 training examples in your dataset (150 examples in total where 50 examples are reserved for a 50:50 split between validation and test sets). </p>\n\n<p>Pick a specific example from this set of 150 examples, say <span class=\"math-container\">${x}_{i}$</span>. You are required to classify this in any one of the classes: <span class=\"math-container\">${k}_{1}, {k}_{2}, ..., {k}_{n}$</span>.</p>\n\n<p>Now randomly pick 100 samples from your original set of 150 samples (excluding your <span class=\"math-container\">${x}_{i}$</span>). Now suppose you choose a hypothesis that has many higher degree terms, for instance: <span class=\"math-container\">${a}_{1}{x}^8 + {a}_{2}{x}^{7} + ... {a}_{0} = 0$</span> and <strong>do not regularise it</strong>, it will fit the model nicely and you get a low error on your training set.</p>\n\n<p>You now run this model on <span class=\"math-container\">${x}_{i}$</span> and it predicts wrongly. <strong>You repeat the above process of having 100 samples five times and each time you get a different result</strong>, say <span class=\"math-container\">${k}_{a},    {k}_{b}, {k}_{c}, {k}_{d}$</span>, and  <span class=\"math-container\">${k}_{e}$</span>.</p>\n\n<p>This variability in your prediction (coupled with the <strong>low error on your training set</strong>) implies your model is overfitting the data it is given. That's why it is not able to follow the general pattern in your data and is being affected by outliers more than it should.</p>\n\n<p>I guess that answers your question about declaring a model as highly variant when </p>\n\n<blockquote>\n  <p>the predicted points are too prolonged</p>\n</blockquote>\n",
                "codes": [
                    [],
                    [],
                    [],
                    []
                ],
                "question_id:": "42424",
                "question_votes:": "",
                "question_text:": "<p>I know that high variance cause overfitting, and high variance is that the model is sensitive to outliers.</p>\n\n<p>But can I say <strong>Variance</strong> is that when the predicted points are too prolonged lead to high variance (overfitting) and vice versa.</p>\n",
                "tags": "<machine-learning><machine-learning-model><variance>",
                "answers": [
                    [
                        "42447",
                        "2",
                        "42424",
                        "",
                        "",
                        "<p>What is variance?</p>\n\n<p>Variance is the variability of model prediction for a given data point or a value which tells us spread of our data. Model with high variance pays a lot of attention to training data and does not generalize on the data which it hasn\u2019t seen before. As a result, such models perform very well on training data but has high error rates on test data.</p>\n\n<p>Error due to variance</p>\n\n<p>Error due to variance is the amount by which the prediction, over one training set, differs from the expected value over all the training sets. In machine learning, di\ufb00erent training data sets will result in a di\ufb00erent estimation. But ideally it should not vary too much between training sets. However, if a method has high variance then small changes in the training data can result in large changes in results.</p>\n\n<p><a href=\"https://www.coursera.org/lecture/machine-learning/diagnosing-bias-vs-variance-yCAup\" rel=\"nofollow noreferrer\">https://www.coursera.org/lecture/machine-learning/diagnosing-bias-vs-variance-yCAup</a></p>\n\n<p><a href=\"https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229\" rel=\"nofollow noreferrer\">https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229</a></p>\n",
                        "",
                        "2"
                    ],
                    [
                        "43434",
                        "2",
                        "42424",
                        "",
                        "",
                        "<p>Its a bias variance trade-off problem:</p>\n\n<ul>\n<li>When increase model complexity, variance is increased and bias is reduced</li>\n<li>When regularize the model, bias is increased and variance is reduced.</li>\n</ul>\n\n<p><strong>Mathematically</strong></p>\n\n<p>High Bias:</p>\n\n<ul>\n<li><p>No matter how much data we feed the model, the model cannot represent the underlying relationship and has high systematic errors</p></li>\n<li><p>Poor fit</p></li>\n<li><p>Poor generalization</p></li>\n</ul>\n\n<p><a href=\"https://i.stack.imgur.com/m72Ei.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/m72Ei.png\" alt=\"High Bias\"></a></p>\n\n<p>High Variance:</p>\n\n<ul>\n<li><p>Require data to improve</p></li>\n<li><p>Can simplify the model with fewer or less complex features</p></li>\n</ul>\n\n<p><a href=\"https://i.stack.imgur.com/MOvWu.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/MOvWu.png\" alt=\"High Variance\"></a></p>\n\n<p>To approach the issue we can graph our model's performance based on varying criteria during the analysis process to visualizing behavior that may not have been apparent from the results alone.</p>\n\n<p><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html\" rel=\"nofollow noreferrer\">Learning Curves - Scikit Learn</a></p>\n\n<p>Here is learning curve for a decision tree example.</p>\n\n<p><a href=\"https://i.stack.imgur.com/BCX9V.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/BCX9V.png\" alt=\"enter image description here\"></a></p>\n\n<p>See that the maximum depth 3 is the one that represents the best learning curve.</p>\n\n<p>Note that in this example the maximum depth 3 is the one that represents the best learning curve.</p>\n\n<p>Even with the addition of more training points the score of the training curve reduces your score a little, but gradually tends to decrease this reduction demonstrating stability even with the addition of a high number of training points.</p>\n\n<p>Already in the case of the test curve, with the addition of more training points the score tends to increase significantly at the beginning, denoting the best fit of the model, however even if it converges in high numbers of training points the score of the curve also achieves a stability in the improvement in a certain number of training points.</p>\n\n<p>Having more training points benefits the model until a certain point in time that the scores of your training and test curves stabilize, not requiring further training points increment.</p>\n\n<p>A excelent reference is in the link bellow:\n<a href=\"https://www.ritchieng.com/applying-machine-learning/\" rel=\"nofollow noreferrer\">Andrew Ng Guide</a></p>\n",
                        "",
                        ""
                    ],
                    [
                        "42428",
                        "2",
                        "42424",
                        "",
                        "",
                        "<p><em>Variance</em> is the mean of squared deviations from the mean. Analyzing variance tests, the hypothesis that the means of two or more populations are equal.</p>\n\n<p><code>Bias versus variance trade-off</code></p>\n\n<p>Every model has both bias and variance error components in addition to white noise. Bias\nand variance are inversely related to each other; while trying to reduce one component, the other component of the model will increase. The ideal model will have both low bias and low variance</p>\n\n<p>An example of a high bias model is logistic or linear regression, in which the fit of the\nmodel is merely a straight line and may have a high error component due to the fact that a linear model could not approximate underlying data well.</p>\n\n<p>An example of a high variance model is a decision tree, in which the model may create too\nmuch wiggly curve as a fit, in which even a small change in training data will cause a\ndrastic change in the fit of the curve.</p>\n\n<p>The above information is from the book <code>Statistics for Machine Learning</code> which i used to refer</p>\n",
                        "",
                        ""
                    ],
                    [
                        "42437",
                        "2",
                        "42424",
                        "",
                        "",
                        "<p><em>Variance</em> actually measures the variability of the model prediction (say, for simplification, for a particular sample instance) <strong>if</strong> we would retrain the model multiple times (on different subsets of the data).</p>\n\n<p>To gain an intuitive feeling of variance, suppose you have 100 training examples in your dataset (150 examples in total where 50 examples are reserved for a 50:50 split between validation and test sets). </p>\n\n<p>Pick a specific example from this set of 150 examples, say <span class=\"math-container\">${x}_{i}$</span>. You are required to classify this in any one of the classes: <span class=\"math-container\">${k}_{1}, {k}_{2}, ..., {k}_{n}$</span>.</p>\n\n<p>Now randomly pick 100 samples from your original set of 150 samples (excluding your <span class=\"math-container\">${x}_{i}$</span>). Now suppose you choose a hypothesis that has many higher degree terms, for instance: <span class=\"math-container\">${a}_{1}{x}^8 + {a}_{2}{x}^{7} + ... {a}_{0} = 0$</span> and <strong>do not regularise it</strong>, it will fit the model nicely and you get a low error on your training set.</p>\n\n<p>You now run this model on <span class=\"math-container\">${x}_{i}$</span> and it predicts wrongly. <strong>You repeat the above process of having 100 samples five times and each time you get a different result</strong>, say <span class=\"math-container\">${k}_{a},    {k}_{b}, {k}_{c}, {k}_{d}$</span>, and  <span class=\"math-container\">${k}_{e}$</span>.</p>\n\n<p>This variability in your prediction (coupled with the <strong>low error on your training set</strong>) implies your model is overfitting the data it is given. That's why it is not able to follow the general pattern in your data and is being affected by outliers more than it should.</p>\n\n<p>I guess that answers your question about declaring a model as highly variant when </p>\n\n<blockquote>\n  <p>the predicted points are too prolonged</p>\n</blockquote>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7101",
            "_score": 7.5911765,
            "_source": {
                "title": "LSTM Implementation using tensorflow (anaconda)",
                "content": "LSTM Implementation using tensorflow (anaconda) <p>I'm new to <em>TensorFlow</em> and currently I'm trying to implement an <code>LSTM</code> using jupyter notebook.</p>\n\n<p>But when I run the following code segment, I got some errors and couldn't find any solution.</p>\n\n<p>How can I work through this error?</p>\n\n<h3>Code:</h3>\n\n<pre><code>lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\nlstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\nvalue, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)\n</code></pre>\n\n<h3>Error:</h3>\n\n<pre><code>---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n&lt;ipython-input-29-db6a6fc2c55e&gt; in &lt;module&gt;()\n----&gt; 1 lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n      2 lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n      3 value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py in __getattr__(self, item)\n     51 \n     52   def __getattr__(self, item):\n---&gt; 53     module = self._load()\n     54     return getattr(module, item)\n     55 \n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py in _load(self)\n     40   def _load(self):\n     41     # Import the target module and insert it into the parent's namespace\n---&gt; 42     module = importlib.import_module(self.__name__)\n     43     self._parent_module_globals[self._local_name] = module\n     44 \n\nC:\\Anaconda3\\lib\\importlib\\__init__.py in import_module(name, package)\n    124                 break\n    125             level += 1\n--&gt; 126     return _bootstrap._gcd_import(name[level:], package, level)\n    127 \n    128 \n\nC:\\Anaconda3\\lib\\importlib\\_bootstrap.py in _gcd_import(name, package, level)\n\nC:\\Anaconda3\\lib\\importlib\\_bootstrap.py in _find_and_load(name, import_)\n\nC:\\Anaconda3\\lib\\importlib\\_bootstrap.py in _find_and_load_unlocked(name, import_)\n\nC:\\Anaconda3\\lib\\importlib\\_bootstrap.py in _load_unlocked(spec)\n\nC:\\Anaconda3\\lib\\importlib\\_bootstrap_external.py in exec_module(self, module)\n\nC:\\Anaconda3\\lib\\importlib\\_bootstrap.py in _call_with_frames_removed(f, *args, **kwds)\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\__init__.py in &lt;module&gt;()\n     29 from tensorflow.contrib import data\n     30 from tensorflow.contrib import deprecated\n---&gt; 31 from tensorflow.contrib import distributions\n     32 from tensorflow.contrib import estimator\n     33 from tensorflow.contrib import factorization\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\distributions\\__init__.py in &lt;module&gt;()\n     31 from tensorflow.contrib.distributions.python.ops.distribution_util import matrix_diag_transform\n     32 from tensorflow.contrib.distributions.python.ops.distribution_util import softplus_inverse\n---&gt; 33 from tensorflow.contrib.distributions.python.ops.estimator import *\n     34 from tensorflow.contrib.distributions.python.ops.geometric import *\n     35 from tensorflow.contrib.distributions.python.ops.independent import *\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\distributions\\python\\ops\\estimator.py in &lt;module&gt;()\n     19 from __future__ import print_function\n     20 \n---&gt; 21 from tensorflow.contrib.learn.python.learn.estimators.head import _compute_weighted_loss\n     22 from tensorflow.contrib.learn.python.learn.estimators.head import _RegressionHead\n     23 from tensorflow.python.framework import ops\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\__init__.py in &lt;module&gt;()\n     90 \n     91 # pylint: disable=wildcard-import\n---&gt; 92 from tensorflow.contrib.learn.python.learn import *\n     93 # pylint: enable=wildcard-import\n     94 \n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\__init__.py in &lt;module&gt;()\n     21 \n     22 # pylint: disable=wildcard-import\n---&gt; 23 from tensorflow.contrib.learn.python.learn import *\n     24 # pylint: enable=wildcard-import\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\__init__.py in &lt;module&gt;()\n     23 from tensorflow.contrib.learn.python.learn import basic_session_run_hooks\n     24 from tensorflow.contrib.learn.python.learn import datasets\n---&gt; 25 from tensorflow.contrib.learn.python.learn import estimators\n     26 from tensorflow.contrib.learn.python.learn import graph_actions\n     27 from tensorflow.contrib.learn.python.learn import learn_io as io\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\__init__.py in &lt;module&gt;()\n    295 from tensorflow.contrib.learn.python.learn.estimators._sklearn import NotFittedError\n    296 from tensorflow.contrib.learn.python.learn.estimators.constants import ProblemType\n--&gt; 297 from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier\n    298 from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNEstimator\n    299 from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNRegressor\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py in &lt;module&gt;()\n     28 from tensorflow.contrib.layers.python.layers import optimizers\n     29 from tensorflow.contrib.learn.python.learn import metric_spec\n---&gt; 30 from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined\n     31 from tensorflow.contrib.learn.python.learn.estimators import estimator\n     32 from tensorflow.contrib.learn.python.learn.estimators import head as head_lib\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn_linear_combined.py in &lt;module&gt;()\n     29 from tensorflow.contrib.layers.python.layers import optimizers\n     30 from tensorflow.contrib.learn.python.learn import metric_spec\n---&gt; 31 from tensorflow.contrib.learn.python.learn.estimators import estimator\n     32 from tensorflow.contrib.learn.python.learn.estimators import head as head_lib\n     33 from tensorflow.contrib.learn.python.learn.estimators import model_fn\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py in &lt;module&gt;()\n     47 from tensorflow.contrib.learn.python.learn.estimators import tensor_signature\n     48 from tensorflow.contrib.learn.python.learn.estimators._sklearn import NotFittedError\n---&gt; 49 from tensorflow.contrib.learn.python.learn.learn_io import data_feeder\n     50 from tensorflow.contrib.learn.python.learn.utils import export\n     51 from tensorflow.contrib.learn.python.learn.utils import saved_model_export_utils\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\__init__.py in &lt;module&gt;()\n     19 from __future__ import print_function\n     20 \n---&gt; 21 from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data\n     22 from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_labels\n     23 from tensorflow.contrib.learn.python.learn.learn_io.dask_io import HAS_DASK\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\dask_io.py in &lt;module&gt;()\n     24 try:\n     25   # pylint: disable=g-import-not-at-top\n---&gt; 26   import dask.dataframe as dd\n     27   allowed_classes = (dd.Series, dd.DataFrame)\n     28   HAS_DASK = True\n\nC:\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\__init__.py in &lt;module&gt;()\n      1 from __future__ import print_function, division, absolute_import\n      2 \n----&gt; 3 from .core import (DataFrame, Series, Index, _Frame, map_partitions,\n      4                    repartition, to_delayed, to_datetime, to_timedelta)\n      5 from .groupby import Aggregation\n\nC:\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py in &lt;module&gt;()\n     38 if PANDAS_VERSION &gt;= '0.20.0':\n     39     from pandas.util import cache_readonly\n---&gt; 40     pd.core.computation.expressions.set_use_numexpr(False)\n     41 else:\n     42     from pandas.util.decorators import cache_readonly\n\nAttributeError: module 'pandas.core.computation' has no attribute 'expressions'\n</code></pre>\n\n<ul>\n<li>Tensorflow version - '1.4.0'</li>\n<li>Python version - 3.6.3:: Anaconda, Inc.</li>\n</ul>\n <deep-learning><tensorflow><rnn><lstm><p>Based on the solution <a href=\"https://stackoverflow.com/questions/43833081/attributeerror-module-object-has-no-attribute-computation\">here</a> you have different choices:</p>\n\n<p>The simplest solution is to revert back to <code>Pandas 0.19.2</code>. For this purpose use the following command in your command line or terminal.</p>\n\n<pre><code>conda install pandas=0.19.2\n</code></pre>\n",
                "codes": [
                    [
                        "conda install pandas=0.19.2\n"
                    ]
                ],
                "question_id:": "26891",
                "question_votes:": "1",
                "question_text:": "<p>I'm new to <em>TensorFlow</em> and currently I'm trying to implement an <code>LSTM</code> using jupyter notebook.</p>\n\n<p>But when I run the following code segment, I got some errors and couldn't find any solution.</p>\n\n<p>How can I work through this error?</p>\n\n<h3>Code:</h3>\n\n<pre><code>lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\nlstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\nvalue, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)\n</code></pre>\n\n<h3>Error:</h3>\n\n<pre><code>---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n&lt;ipython-input-29-db6a6fc2c55e&gt; in &lt;module&gt;()\n----&gt; 1 lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n      2 lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n      3 value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py in __getattr__(self, item)\n     51 \n     52   def __getattr__(self, item):\n---&gt; 53     module = self._load()\n     54     return getattr(module, item)\n     55 \n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py in _load(self)\n     40   def _load(self):\n     41     # Import the target module and insert it into the parent's namespace\n---&gt; 42     module = importlib.import_module(self.__name__)\n     43     self._parent_module_globals[self._local_name] = module\n     44 \n\nC:\\Anaconda3\\lib\\importlib\\__init__.py in import_module(name, package)\n    124                 break\n    125             level += 1\n--&gt; 126     return _bootstrap._gcd_import(name[level:], package, level)\n    127 \n    128 \n\nC:\\Anaconda3\\lib\\importlib\\_bootstrap.py in _gcd_import(name, package, level)\n\nC:\\Anaconda3\\lib\\importlib\\_bootstrap.py in _find_and_load(name, import_)\n\nC:\\Anaconda3\\lib\\importlib\\_bootstrap.py in _find_and_load_unlocked(name, import_)\n\nC:\\Anaconda3\\lib\\importlib\\_bootstrap.py in _load_unlocked(spec)\n\nC:\\Anaconda3\\lib\\importlib\\_bootstrap_external.py in exec_module(self, module)\n\nC:\\Anaconda3\\lib\\importlib\\_bootstrap.py in _call_with_frames_removed(f, *args, **kwds)\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\__init__.py in &lt;module&gt;()\n     29 from tensorflow.contrib import data\n     30 from tensorflow.contrib import deprecated\n---&gt; 31 from tensorflow.contrib import distributions\n     32 from tensorflow.contrib import estimator\n     33 from tensorflow.contrib import factorization\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\distributions\\__init__.py in &lt;module&gt;()\n     31 from tensorflow.contrib.distributions.python.ops.distribution_util import matrix_diag_transform\n     32 from tensorflow.contrib.distributions.python.ops.distribution_util import softplus_inverse\n---&gt; 33 from tensorflow.contrib.distributions.python.ops.estimator import *\n     34 from tensorflow.contrib.distributions.python.ops.geometric import *\n     35 from tensorflow.contrib.distributions.python.ops.independent import *\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\distributions\\python\\ops\\estimator.py in &lt;module&gt;()\n     19 from __future__ import print_function\n     20 \n---&gt; 21 from tensorflow.contrib.learn.python.learn.estimators.head import _compute_weighted_loss\n     22 from tensorflow.contrib.learn.python.learn.estimators.head import _RegressionHead\n     23 from tensorflow.python.framework import ops\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\__init__.py in &lt;module&gt;()\n     90 \n     91 # pylint: disable=wildcard-import\n---&gt; 92 from tensorflow.contrib.learn.python.learn import *\n     93 # pylint: enable=wildcard-import\n     94 \n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\__init__.py in &lt;module&gt;()\n     21 \n     22 # pylint: disable=wildcard-import\n---&gt; 23 from tensorflow.contrib.learn.python.learn import *\n     24 # pylint: enable=wildcard-import\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\__init__.py in &lt;module&gt;()\n     23 from tensorflow.contrib.learn.python.learn import basic_session_run_hooks\n     24 from tensorflow.contrib.learn.python.learn import datasets\n---&gt; 25 from tensorflow.contrib.learn.python.learn import estimators\n     26 from tensorflow.contrib.learn.python.learn import graph_actions\n     27 from tensorflow.contrib.learn.python.learn import learn_io as io\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\__init__.py in &lt;module&gt;()\n    295 from tensorflow.contrib.learn.python.learn.estimators._sklearn import NotFittedError\n    296 from tensorflow.contrib.learn.python.learn.estimators.constants import ProblemType\n--&gt; 297 from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier\n    298 from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNEstimator\n    299 from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNRegressor\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py in &lt;module&gt;()\n     28 from tensorflow.contrib.layers.python.layers import optimizers\n     29 from tensorflow.contrib.learn.python.learn import metric_spec\n---&gt; 30 from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined\n     31 from tensorflow.contrib.learn.python.learn.estimators import estimator\n     32 from tensorflow.contrib.learn.python.learn.estimators import head as head_lib\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn_linear_combined.py in &lt;module&gt;()\n     29 from tensorflow.contrib.layers.python.layers import optimizers\n     30 from tensorflow.contrib.learn.python.learn import metric_spec\n---&gt; 31 from tensorflow.contrib.learn.python.learn.estimators import estimator\n     32 from tensorflow.contrib.learn.python.learn.estimators import head as head_lib\n     33 from tensorflow.contrib.learn.python.learn.estimators import model_fn\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py in &lt;module&gt;()\n     47 from tensorflow.contrib.learn.python.learn.estimators import tensor_signature\n     48 from tensorflow.contrib.learn.python.learn.estimators._sklearn import NotFittedError\n---&gt; 49 from tensorflow.contrib.learn.python.learn.learn_io import data_feeder\n     50 from tensorflow.contrib.learn.python.learn.utils import export\n     51 from tensorflow.contrib.learn.python.learn.utils import saved_model_export_utils\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\__init__.py in &lt;module&gt;()\n     19 from __future__ import print_function\n     20 \n---&gt; 21 from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data\n     22 from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_labels\n     23 from tensorflow.contrib.learn.python.learn.learn_io.dask_io import HAS_DASK\n\nC:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\dask_io.py in &lt;module&gt;()\n     24 try:\n     25   # pylint: disable=g-import-not-at-top\n---&gt; 26   import dask.dataframe as dd\n     27   allowed_classes = (dd.Series, dd.DataFrame)\n     28   HAS_DASK = True\n\nC:\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\__init__.py in &lt;module&gt;()\n      1 from __future__ import print_function, division, absolute_import\n      2 \n----&gt; 3 from .core import (DataFrame, Series, Index, _Frame, map_partitions,\n      4                    repartition, to_delayed, to_datetime, to_timedelta)\n      5 from .groupby import Aggregation\n\nC:\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py in &lt;module&gt;()\n     38 if PANDAS_VERSION &gt;= '0.20.0':\n     39     from pandas.util import cache_readonly\n---&gt; 40     pd.core.computation.expressions.set_use_numexpr(False)\n     41 else:\n     42     from pandas.util.decorators import cache_readonly\n\nAttributeError: module 'pandas.core.computation' has no attribute 'expressions'\n</code></pre>\n\n<ul>\n<li>Tensorflow version - '1.4.0'</li>\n<li>Python version - 3.6.3:: Anaconda, Inc.</li>\n</ul>\n",
                "tags": "<deep-learning><tensorflow><rnn><lstm>",
                "answers": [
                    [
                        "26893",
                        "2",
                        "26891",
                        "",
                        "",
                        "<p>Based on the solution <a href=\"https://stackoverflow.com/questions/43833081/attributeerror-module-object-has-no-attribute-computation\">here</a> you have different choices:</p>\n\n<p>The simplest solution is to revert back to <code>Pandas 0.19.2</code>. For this purpose use the following command in your command line or terminal.</p>\n\n<pre><code>conda install pandas=0.19.2\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16759",
            "_score": 7.5358243,
            "_source": {
                "title": "Getting 'ValueError: setting an array element with a sequence.' when attempting to fit mixed-type data",
                "content": "Getting 'ValueError: setting an array element with a sequence.' when attempting to fit mixed-type data <p>I have already seen <a href=\"https://stackoverflow.com/questions/53023341/python-scikit-learn-classification-with-mixed-data-types-text-numerical-categ\">this</a>, <a href=\"https://stackoverflow.com/questions/4674473/valueerror-setting-an-array-element-with-a-sequence\">this</a> and <a href=\"https://stackoverflow.com/questions/13310347/numpy-valueerror-setting-an-array-element-with-a-sequence-this-message-may-app/39114489\">this</a> question, but none of the suggestions seemed to fix my problem (so I have reverted them).</p>\n\n<p>I have the following code:</p>\n\n<pre><code>nlp = spacy.load('en_core_web_sm')\nparser = English()\n\nclass CleanTextTransformer(TransformerMixin):\n    def transform(self, X, **transform_params):\n        return [cleanText(text) for text in X]\n\n    def fit(self, X, y=None, **fit_params):\n        return self\n\n    def get_params(self, deep=True):\n        return {}\n\n\ndef cleanText(text):\n    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n    text = text.lower()\n    return text\n\n\ndef tokenizeText(sample):\n    tokens = parser(sample)\n    lemmas = []\n    for tok in tokens:\n        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n    tokens = lemmas\n    tokens = [tok for tok in tokens if tok not in STOPLIST]\n    tokens = [nlp(tok)[0].lemma_ for tok in tokens if tok not in SYMBOLS]\n    return tokens\n\nclass multilabelbin(TransformerMixin):\n    def __init__(self, *args, **kwargs):\n        self.encoder = MultiLabelBinarizer(*args, **kwargs)\n\n    def fit(self, x, y=0):\n        self.encoder.fit(x)\n        return self\n\n    def transform(self, x, y=0):\n        return self.encoder.transform(x)\n\n\ndef represent(rd, ed, number, category, text):\n    doc_train = rd\n    doc_test = ed\n\n    for column in category:\n        doc_train[column] = [tuple(doc.split(\",\")) for doc in rd[column]]\n        doc_test[column] = [tuple(doc.split(\",\")) for doc in ed[column]]\n\n        print(\"columns split\")\n\n        mlb = multilabelbin(sparse_output=False)\n        mlb.fit(doc_train)\n\n        transformed_r = mlb.transform(doc_train)\n        for row in range(len(doc_train[column])):\n            print(doc_train[column][row])\n            doc_train[column][row] = transformed_r[row]\n\n        transformed_e = mlb.transform(doc_test)\n        for row in range(len(doc_test[column])):\n            print(doc_test[column][row])\n            doc_test[column][row] = transformed_e[row]\n\n        print(\"categorical columns encoded using MultiLabelBinarizer()\")\n\n    for column in number:\n        ss = StandardScaler()\n        ss.fit(doc_train[column].values.reshape(-1, 1))\n\n        doc_train[column] = ss.transform(doc_train[column].values.reshape(-1, 1))\n        doc_test[column] = ss.transform(doc_test[column].values.reshape(-1, 1))\n        print(\"numbers scaled using StandardScaler()\")\n\n    for column in text:\n        cleaner = CleanTextTransformer()\n        cleaner.fit(doc_train[column].tolist())\n\n        doc_train[column] = cleaner.transform(doc_train[column])\n        doc_test[column] = cleaner.transform(doc_test[column])\n\n        print(doc_train[column])\n\n        vec = TfidfVectorizer(tokenizer=tokenizeText, ngram_range=(1, 1))\n        vec.fit(doc_train[column].tolist())\n\n        doc_train[column] = vec.transform(doc_train[column]).todense()\n        doc_test[column] = vec.transform(doc_test[column]).todense()\n\n        print(doc_train[column])\n\n        print(\"text vectorized\")\n\n    print(\"preprocessing completed successfully\")\n\n    return doc_train, doc_test\n\n\ndef train_classifier(train_docs, classAxis):\n    clf = OneVsRestClassifier(LogisticRegression(solver='saga'))\n\n    X = [list(train_docs[list(train_docs)[i]]) for i in range(1, len(train_docs))]\n    y = list(train_docs[classAxis])\n\n    classifier = clf.fit(X, y)\n    return classifier\n\ndf = pd.DataFrame(pd.read_csv(\"testdata.csv\", header=0))\ntest_data = pd.DataFrame(pd.read_csv(\"test.csv\", header=0))\n\ntrain, test = represent(df, test_data, [\"Cat2\", \"Cat5\"], [\"Cat6\"], [\"Cat1\", \"Cat3\", \"Cat4\", \"Cat7\"])\n\nprint(train, test)\n\nmodel = train_classifier(train, \"Class\")\n</code></pre>\n\n<p><code>train.csv</code> contains data in this format:</p>\n\n<p><a href=\"https://i.stack.imgur.com/eVGib.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/eVGib.png\" alt=\"format of data\"></a></p>\n\n<p><code>test.csv</code> is of the same format.</p>\n\n<p>As you can see, there are text values, number values and categorical values. My code firstly splits up the categorical values (which are comma-delimited), before running them through <code>MultiLabelBinarizer()</code>. Then, I simply scale the numbers. Finally, I process the text using the <code>spaCy</code> settings found in <a href=\"https://towardsdatascience.com/machine-learning-for-text-classification-using-spacy-in-python-b276b4051a49\" rel=\"nofollow noreferrer\">this tutorial</a>. I make sure to apply transformations to the test data, too, so there can be no inconsistency there. Finally, I <code>list</code>-enise everything in the <code>train_classifier</code> function, which supposedly should help... but it didn't. In the line <code>classifier = clf.fit(list(X), y)</code>, I get the following error:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"&lt;input&gt;\", line 1, in &lt;module&gt;\n  File \"C:\\Users\\User\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\191.7141.48\\helpers\\pydev\\_pydev_bundle\\pydev_umd.py\", line 197, in runfile\n    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script\n  File \"C:\\Users\\User\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\191.7141.48\\helpers\\pydev\\_pydev_imps\\_pydev_execfile.py\", line 18, in execfile\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\n  File \"C:/Users/User/PycharmProjects/ml/ml.py\", line 148, in &lt;module&gt;\n    model = train_classifier(train, \"Class\")\n  File \"C:/Users/User/PycharmProjects/ml/ml.py\", line 124, in train_classifier\n    classifier = clf.fit(list(X), y)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\multiclass.py\", line 215, in fit\n    for i, column in enumerate(columns))\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 917, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 716, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 182, in apply_async\n    result = ImmediateResult(func)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 549, in __init__\n    self.results = batch()\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in &lt;listcomp&gt;\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\multiclass.py\", line 80, in _fit_binary\n    estimator.fit(X, y)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\", line 1288, in fit\n    accept_large_sparse=solver != 'liblinear')\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 756, in check_X_y\n    estimator=estimator)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 527, in check_array\n    array = np.asarray(array, dtype=dtype, order=order)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\numpy\\core\\numeric.py\", line 538, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: setting an array element with a sequence.\n</code></pre>\n\n<p>I have tried to read through docs, and am not one to shy away from reading source code (and PyCharm helped me pinpoint the source of the error), but am no closer to fixing it. I feel like I have honestly tried everything on the first 3 pages of Google, but to no success.</p>\n\n<p>How can I fix this error? Why is it happening? Is my preprocessing wrong? I know it's a bit dodgy in places, but does this make is unfunctional? If so, how could I fix these issues in the preprocessor? Would this fix the <code>ValueError: setting an array element with a sequence.</code> error?</p>\n\n<p>Some notes:</p>\n\n<ul>\n<li>For some reason, <code>spaCy</code> seems to return 0.0 for most values in each column.</li>\n<li>I am unsure if I can just insert my <code>MultiLabelVectorizer()</code> output into the DataFrame like this (simply as the 2D arrays) - is this OK? Are there any more steps required?</li>\n<li>I have tried Pipelines for more semantic code, as well as using different classifiers for the different data types (e.g using Chi^2 for text, and other things for other types), but it always seemed to result in an endless well of bugs.</li>\n<li>I am unable to even pinpoint what throws this error: is it the column data, the text data or the number data? I don't know.</li>\n</ul>\n <machine-learning><python><scikit-learn><vector-space-models>",
                "codes": [],
                "question_id:": "54796",
                "question_votes:": "",
                "question_text:": "<p>I have already seen <a href=\"https://stackoverflow.com/questions/53023341/python-scikit-learn-classification-with-mixed-data-types-text-numerical-categ\">this</a>, <a href=\"https://stackoverflow.com/questions/4674473/valueerror-setting-an-array-element-with-a-sequence\">this</a> and <a href=\"https://stackoverflow.com/questions/13310347/numpy-valueerror-setting-an-array-element-with-a-sequence-this-message-may-app/39114489\">this</a> question, but none of the suggestions seemed to fix my problem (so I have reverted them).</p>\n\n<p>I have the following code:</p>\n\n<pre><code>nlp = spacy.load('en_core_web_sm')\nparser = English()\n\nclass CleanTextTransformer(TransformerMixin):\n    def transform(self, X, **transform_params):\n        return [cleanText(text) for text in X]\n\n    def fit(self, X, y=None, **fit_params):\n        return self\n\n    def get_params(self, deep=True):\n        return {}\n\n\ndef cleanText(text):\n    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n    text = text.lower()\n    return text\n\n\ndef tokenizeText(sample):\n    tokens = parser(sample)\n    lemmas = []\n    for tok in tokens:\n        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n    tokens = lemmas\n    tokens = [tok for tok in tokens if tok not in STOPLIST]\n    tokens = [nlp(tok)[0].lemma_ for tok in tokens if tok not in SYMBOLS]\n    return tokens\n\nclass multilabelbin(TransformerMixin):\n    def __init__(self, *args, **kwargs):\n        self.encoder = MultiLabelBinarizer(*args, **kwargs)\n\n    def fit(self, x, y=0):\n        self.encoder.fit(x)\n        return self\n\n    def transform(self, x, y=0):\n        return self.encoder.transform(x)\n\n\ndef represent(rd, ed, number, category, text):\n    doc_train = rd\n    doc_test = ed\n\n    for column in category:\n        doc_train[column] = [tuple(doc.split(\",\")) for doc in rd[column]]\n        doc_test[column] = [tuple(doc.split(\",\")) for doc in ed[column]]\n\n        print(\"columns split\")\n\n        mlb = multilabelbin(sparse_output=False)\n        mlb.fit(doc_train)\n\n        transformed_r = mlb.transform(doc_train)\n        for row in range(len(doc_train[column])):\n            print(doc_train[column][row])\n            doc_train[column][row] = transformed_r[row]\n\n        transformed_e = mlb.transform(doc_test)\n        for row in range(len(doc_test[column])):\n            print(doc_test[column][row])\n            doc_test[column][row] = transformed_e[row]\n\n        print(\"categorical columns encoded using MultiLabelBinarizer()\")\n\n    for column in number:\n        ss = StandardScaler()\n        ss.fit(doc_train[column].values.reshape(-1, 1))\n\n        doc_train[column] = ss.transform(doc_train[column].values.reshape(-1, 1))\n        doc_test[column] = ss.transform(doc_test[column].values.reshape(-1, 1))\n        print(\"numbers scaled using StandardScaler()\")\n\n    for column in text:\n        cleaner = CleanTextTransformer()\n        cleaner.fit(doc_train[column].tolist())\n\n        doc_train[column] = cleaner.transform(doc_train[column])\n        doc_test[column] = cleaner.transform(doc_test[column])\n\n        print(doc_train[column])\n\n        vec = TfidfVectorizer(tokenizer=tokenizeText, ngram_range=(1, 1))\n        vec.fit(doc_train[column].tolist())\n\n        doc_train[column] = vec.transform(doc_train[column]).todense()\n        doc_test[column] = vec.transform(doc_test[column]).todense()\n\n        print(doc_train[column])\n\n        print(\"text vectorized\")\n\n    print(\"preprocessing completed successfully\")\n\n    return doc_train, doc_test\n\n\ndef train_classifier(train_docs, classAxis):\n    clf = OneVsRestClassifier(LogisticRegression(solver='saga'))\n\n    X = [list(train_docs[list(train_docs)[i]]) for i in range(1, len(train_docs))]\n    y = list(train_docs[classAxis])\n\n    classifier = clf.fit(X, y)\n    return classifier\n\ndf = pd.DataFrame(pd.read_csv(\"testdata.csv\", header=0))\ntest_data = pd.DataFrame(pd.read_csv(\"test.csv\", header=0))\n\ntrain, test = represent(df, test_data, [\"Cat2\", \"Cat5\"], [\"Cat6\"], [\"Cat1\", \"Cat3\", \"Cat4\", \"Cat7\"])\n\nprint(train, test)\n\nmodel = train_classifier(train, \"Class\")\n</code></pre>\n\n<p><code>train.csv</code> contains data in this format:</p>\n\n<p><a href=\"https://i.stack.imgur.com/eVGib.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/eVGib.png\" alt=\"format of data\"></a></p>\n\n<p><code>test.csv</code> is of the same format.</p>\n\n<p>As you can see, there are text values, number values and categorical values. My code firstly splits up the categorical values (which are comma-delimited), before running them through <code>MultiLabelBinarizer()</code>. Then, I simply scale the numbers. Finally, I process the text using the <code>spaCy</code> settings found in <a href=\"https://towardsdatascience.com/machine-learning-for-text-classification-using-spacy-in-python-b276b4051a49\" rel=\"nofollow noreferrer\">this tutorial</a>. I make sure to apply transformations to the test data, too, so there can be no inconsistency there. Finally, I <code>list</code>-enise everything in the <code>train_classifier</code> function, which supposedly should help... but it didn't. In the line <code>classifier = clf.fit(list(X), y)</code>, I get the following error:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"&lt;input&gt;\", line 1, in &lt;module&gt;\n  File \"C:\\Users\\User\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\191.7141.48\\helpers\\pydev\\_pydev_bundle\\pydev_umd.py\", line 197, in runfile\n    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script\n  File \"C:\\Users\\User\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\191.7141.48\\helpers\\pydev\\_pydev_imps\\_pydev_execfile.py\", line 18, in execfile\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\n  File \"C:/Users/User/PycharmProjects/ml/ml.py\", line 148, in &lt;module&gt;\n    model = train_classifier(train, \"Class\")\n  File \"C:/Users/User/PycharmProjects/ml/ml.py\", line 124, in train_classifier\n    classifier = clf.fit(list(X), y)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\multiclass.py\", line 215, in fit\n    for i, column in enumerate(columns))\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 917, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 716, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 182, in apply_async\n    result = ImmediateResult(func)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 549, in __init__\n    self.results = batch()\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in &lt;listcomp&gt;\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\multiclass.py\", line 80, in _fit_binary\n    estimator.fit(X, y)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\", line 1288, in fit\n    accept_large_sparse=solver != 'liblinear')\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 756, in check_X_y\n    estimator=estimator)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 527, in check_array\n    array = np.asarray(array, dtype=dtype, order=order)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\numpy\\core\\numeric.py\", line 538, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: setting an array element with a sequence.\n</code></pre>\n\n<p>I have tried to read through docs, and am not one to shy away from reading source code (and PyCharm helped me pinpoint the source of the error), but am no closer to fixing it. I feel like I have honestly tried everything on the first 3 pages of Google, but to no success.</p>\n\n<p>How can I fix this error? Why is it happening? Is my preprocessing wrong? I know it's a bit dodgy in places, but does this make is unfunctional? If so, how could I fix these issues in the preprocessor? Would this fix the <code>ValueError: setting an array element with a sequence.</code> error?</p>\n\n<p>Some notes:</p>\n\n<ul>\n<li>For some reason, <code>spaCy</code> seems to return 0.0 for most values in each column.</li>\n<li>I am unsure if I can just insert my <code>MultiLabelVectorizer()</code> output into the DataFrame like this (simply as the 2D arrays) - is this OK? Are there any more steps required?</li>\n<li>I have tried Pipelines for more semantic code, as well as using different classifiers for the different data types (e.g using Chi^2 for text, and other things for other types), but it always seemed to result in an endless well of bugs.</li>\n<li>I am unable to even pinpoint what throws this error: is it the column data, the text data or the number data? I don't know.</li>\n</ul>\n",
                "tags": "<machine-learning><python><scikit-learn><vector-space-models>",
                "answers": []
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14732",
            "_score": 7.3526793,
            "_source": {
                "title": "Time Series - Models seem to not learn",
                "content": "Time Series - Models seem to not learn <p>I am doing my undergrad Dissertation on time series prediction, and use various models (linear /ridge regression,  AR(2), Random Forest, SVR, and 4 variations of Neural Networks) to try and 'predict' (for academic only reasons) daily return data, using as input lagged returns and SMA - RSI features (using TA - Lib) built based on those returns. However, I have noticed that my NNs do not learn anything, and upon inspecting the loss graph and the vector of predictions, I noticed it only predicts a single value, with the same applying for the Ridge and AR regressions.</p>\n\n<p>Also, when I try to calculate the correlation between the labels and the predictions (of the NNs) I get 'nan' as a result, no matter what I try, which I suspect has to do with the predictions. I also get wildly varying r2 scores on each re-run (even though I have set multiple seeds, both on Tensorflow backend as well as numpy) and always negative, which I cannot understand as even though my search on the internet and the sklearn's docs say it can be negative, my professor insists it cannot be, and I truly am bewildered.</p>\n\n<p>What can I do about it? Isn't it obviously wrong for an entire NN to predict only a single value? Below I include the code for the ridge / AR regressions as well as the 'Vanilla NN' and a couple of useful graphs. The data itself is quite large, so I don't know if there's much of a point to include it if not asked specifically, given there are no algorithmic errors below.</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def vanillaNN(X_train, y_train,X_test,y_test):\n    n_cols = X_train.shape[1]\n    model = Sequential()\n    model.add(Dense(100,activation='relu', input_shape=(n_cols, )))\n    model.add(Dropout(0.3))\n    model.add(Dense(150, activation='relu'))\n    model.add(Dense(50, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(1))\n\n    model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n\n    history = model.fit(X_train,y_train,epochs=100,verbose=0,\n        shuffle=False, validation_split=0.1)  \n\n    # Use the last loss as the title\n    plt.plot(history.history['loss'])\n    plt.title('last loss:' + str(round(history.history['loss'][-1], 6)))\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.show()\n\n    # Calculate R^2 score and MSE\n    # .... Omitted Code ......\n\n    # it returns those for testing purposes in the IPython shell\n    return (train_scores, test_scores, y_pred_train, y_pred_test, y_train, y_test)\n    VNN_results = vanillaNN(\n        train_features,train_targets,\n        test_features,test_targets)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/tFp3c.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/tFp3c.png\" alt=\"Neural Network Loss History - 100 epochs\"></a></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def AR(X_train, order=2):\n    arma_train = np.array(X_train['returns'])\n    armodel = ARMA(arma_train, order=(order,0))\n    armodel_results = armodel.fit()\n    print(armodel_results.summary())\n    armodel_results.plot_predict(start=8670, end=8698)\n    plt.show()\n    ar_pred = armodel_results.predict(start=8699, end=9665)\n\n    # ...r2 and MSE scores omitted code...\n\n    return [mse_ar2, r2_ar2, ar_pred]\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/XULvD.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/XULvD.png\" alt=\"AR(2) Model out-of-sample predictions\"></a></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def Elastic(X_train, y_train, X_test, y_test):\n    elastic = ElasticNet()\n    param_grid_elastic = {'alpha': [0.001,  0.01, 0.1, 0.5],\n        'l1_ratio': [0.001, 0.01, 0.1, 0.5]\n                              }\n    grid_elastic = GridSearchCV(elastic, param_grid_elastic, \n        cv=tscv.split(X_train),scoring='neg_mean_squared_error')\n\n    grid_elastic.fit(X_train, y_train)\n\n    y_pred_train = grid_elastic.predict(X_train) \n    train_scores = scores(y_train, y_pred_train)\n\n    y_pred_test = grid_elastic.predict(X_test)\n\n    # ...Omitted Code...\n    return [train_scores, test_scores, y_pred_train, y_pred_test]\n</code></pre>\n\n<p>AR(2) sample test and train predictions:\n<a href=\"https://i.stack.imgur.com/RNtmw.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/RNtmw.png\" alt=\"Test Set Predictions\"></a>\n<a href=\"https://i.stack.imgur.com/mmJDy.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/mmJDy.png\" alt=\"Train Set Predictions\"></a></p>\n\n<pre><code>SAMPLE DATA: Train features and Train Targets (future_returns) \n</code></pre>\n\n<p>It looks like a mess, but just copy paste into excel file and it should be good to go!)</p>\n\n<p>Date    returns ma14    rsi14   ma30    rsi30   ma50    rsi50   ma200   rsi200  future_returns\n10/14/1980  3.49E-05    42.76324407 49.21625218 66.6250545  49.69881565 49.45368438 49.93538688 37.78942977 50.51223405 0.013277481\n10/15/1980  0.013277481 0.239711734 53.45799196 0.16387242  51.78260494 0.140801819 51.19194274 0.10545251  50.79944024 -0.011855382\n10/16/1980  -0.011855382    -0.306338818    45.66265303 -0.159676722    47.88773425 -0.115851283    48.81901884 -0.107808537    50.24325364 -0.00414208\n10/17/1980  -0.00414208 -1.154286743    48.16105108 -0.451328445    49.1031414  -0.3083074  49.55134428 -0.299669528    50.4107189  0.007939494\n10/20/1980  0.007939494 0.548806765 51.89223141 0.338253188 50.95654204 0.15403304  50.679274   0.145277255 50.67207082 -0.0050544\n10/21/1980  -0.0050544  -0.580692978    47.89906352 -0.443621598    48.97241743 -0.250429072    49.46553614 -0.227539737    50.38503757 -2.93E-05\n10/22/1980  -2.93E-05   -85.38681662    49.51695915 -69.94007273    49.7551065  -46.09189634    49.93866124 -37.61970911    50.49403171 -0.018135363\n10/23/1980  -0.018135363    -0.020087358    44.19203763 -0.067897836    47.0643223  -0.037135977    48.27685366 -0.05615813 50.09551572 0.000415381\n10/24/1980  0.000415381 -2.422576075    50.11149401 3.125882141 49.93407273 1.480210269 50.01580668 2.418672772 50.49781053 -0.013535864\n10/27/1980  -0.013535864    0.12834969  46.14718747 -0.056014904    47.91325905 -0.053384853    48.75782925 -0.065375964    50.19198915 0.00337859\n10/28/1980  0.00337859  -0.566993349    51.18890074 0.168834456 50.4293269  0.275579337 50.30416736 0.265200747 50.55684672 -0.003396646\n10/29/1980  -0.003396646    0.522213275 49.20187924 0.045438303 49.43972414 -0.207144904    49.69125655 -0.266487054    50.40819543 -0.011421006\n10/30/1980  -0.011421006    0.185961701 46.88078737 0.029632441 48.27895767 -0.018832701    48.97017418 -0.073584097    50.23238873 0.013350935\n10/31/1980  0.013350935 -0.156079209    54.08231943 -0.003988301    51.88647852 0.031510014 51.2008709  0.064478565 50.76515097 0.01758565\n11/3/1980   0.01758565  -0.047207787    55.20045808 0.011243586 52.47271385 0.048876357 51.57016088 0.055301429 50.85553721 0.025052611\n11/5/1980   0.025052611 0.000435129 57.18044487 0.053812694 53.50605621 0.05421219  52.22072289 0.039977524 51.01490125 -0.017722306\n11/6/1980   -0.017722306    0.023031138 44.92992843 -0.03124573 47.39891281 -0.070442975    48.41875471 -0.050855544    50.07992286 0.000581639\n11/7/1980   0.000581639 -0.121650134    49.87840955 1.580058713 49.92880444 2.604518867 50.0080164  1.580277943 50.47031631 0.002508371\n11/10/1980  0.002508371 -0.182865195    50.38381628 0.640792927 50.18967587 0.608670831 50.17291603 0.34700777  50.51126003 0.012129939\n11/11/1980  0.012129939 0.063376989 52.93601236 0.221445976 51.49515928 0.145866445 50.99656886 0.079352102 50.71573089 0.024926655</p>\n <machine-learning><neural-network><deep-learning><time-series><linear-regression><p>Thanks for providing the sample data. I do not really see any severe problems to pin something down as the definite cause of your problem, but I can give you some advice for improvement that could help.</p>\n\n<h2>Standardizing and scaling</h2>\n\n<p>Some of your features have larger values and some have smaller values. If you don't standardize and scale your features and targets, it will result in \"unbalanced\" weights inside your NN which can lead to an unstable model. Therefore, use something like the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\" rel=\"nofollow noreferrer\">StandardScaler</a> to standardize and scale your data after splitting it up into a train and a test dataset.</p>\n\n<h2>Activation function</h2>\n\n<p>It is always worth a try to play around with different activation functions. ReLu is quite simple and computationally inexpensive compared to other activation functions, but in a bad setup, it can lead to many dead neurons. So I would suggest trying out <a href=\"https://stackoverflow.com/a/40775144/9291522\">other activation functions</a> like Tanh or Leaky Relu. <em>Note: That does not mean that ReLu is a bad activation function. For many reasons, it is actually a very popular one.</em></p>\n\n<h2>Learning rate</h2>\n\n<p>Especially if you stick with ReLu, check what difference it makes if you reduce the learning rate and/or set a learning rate decay.</p>\n\n<h2>Neural Network Architecture</h2>\n\n<p>Since you are working with a time-series, it would make sense to use a Recurrent Neural Network which was designed for time-series data like <a href=\"https://keras.io/layers/recurrent/#gru\" rel=\"nofollow noreferrer\">GRU</a> or <a href=\"https://keras.io/layers/recurrent/#lstm\" rel=\"nofollow noreferrer\">LSTM</a>.</p>\n\n<h3>Other</h3>\n\n<p>One side note to prevent you from falling into the same trap I did: If you work with TA-Lib, scale your values before you calculate any features. There is an <a href=\"https://github.com/mrjbq7/ta-lib/issues/151\" rel=\"nofollow noreferrer\">open issue</a> on Github of TA-Lib calculating wrong features if the input-values are too small. I see that your targets also have quite small values, so maybe keep an eye on that.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "49355",
                "question_votes:": "2",
                "question_text:": "<p>I am doing my undergrad Dissertation on time series prediction, and use various models (linear /ridge regression,  AR(2), Random Forest, SVR, and 4 variations of Neural Networks) to try and 'predict' (for academic only reasons) daily return data, using as input lagged returns and SMA - RSI features (using TA - Lib) built based on those returns. However, I have noticed that my NNs do not learn anything, and upon inspecting the loss graph and the vector of predictions, I noticed it only predicts a single value, with the same applying for the Ridge and AR regressions.</p>\n\n<p>Also, when I try to calculate the correlation between the labels and the predictions (of the NNs) I get 'nan' as a result, no matter what I try, which I suspect has to do with the predictions. I also get wildly varying r2 scores on each re-run (even though I have set multiple seeds, both on Tensorflow backend as well as numpy) and always negative, which I cannot understand as even though my search on the internet and the sklearn's docs say it can be negative, my professor insists it cannot be, and I truly am bewildered.</p>\n\n<p>What can I do about it? Isn't it obviously wrong for an entire NN to predict only a single value? Below I include the code for the ridge / AR regressions as well as the 'Vanilla NN' and a couple of useful graphs. The data itself is quite large, so I don't know if there's much of a point to include it if not asked specifically, given there are no algorithmic errors below.</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def vanillaNN(X_train, y_train,X_test,y_test):\n    n_cols = X_train.shape[1]\n    model = Sequential()\n    model.add(Dense(100,activation='relu', input_shape=(n_cols, )))\n    model.add(Dropout(0.3))\n    model.add(Dense(150, activation='relu'))\n    model.add(Dense(50, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(1))\n\n    model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n\n    history = model.fit(X_train,y_train,epochs=100,verbose=0,\n        shuffle=False, validation_split=0.1)  \n\n    # Use the last loss as the title\n    plt.plot(history.history['loss'])\n    plt.title('last loss:' + str(round(history.history['loss'][-1], 6)))\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.show()\n\n    # Calculate R^2 score and MSE\n    # .... Omitted Code ......\n\n    # it returns those for testing purposes in the IPython shell\n    return (train_scores, test_scores, y_pred_train, y_pred_test, y_train, y_test)\n    VNN_results = vanillaNN(\n        train_features,train_targets,\n        test_features,test_targets)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/tFp3c.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/tFp3c.png\" alt=\"Neural Network Loss History - 100 epochs\"></a></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def AR(X_train, order=2):\n    arma_train = np.array(X_train['returns'])\n    armodel = ARMA(arma_train, order=(order,0))\n    armodel_results = armodel.fit()\n    print(armodel_results.summary())\n    armodel_results.plot_predict(start=8670, end=8698)\n    plt.show()\n    ar_pred = armodel_results.predict(start=8699, end=9665)\n\n    # ...r2 and MSE scores omitted code...\n\n    return [mse_ar2, r2_ar2, ar_pred]\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/XULvD.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/XULvD.png\" alt=\"AR(2) Model out-of-sample predictions\"></a></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def Elastic(X_train, y_train, X_test, y_test):\n    elastic = ElasticNet()\n    param_grid_elastic = {'alpha': [0.001,  0.01, 0.1, 0.5],\n        'l1_ratio': [0.001, 0.01, 0.1, 0.5]\n                              }\n    grid_elastic = GridSearchCV(elastic, param_grid_elastic, \n        cv=tscv.split(X_train),scoring='neg_mean_squared_error')\n\n    grid_elastic.fit(X_train, y_train)\n\n    y_pred_train = grid_elastic.predict(X_train) \n    train_scores = scores(y_train, y_pred_train)\n\n    y_pred_test = grid_elastic.predict(X_test)\n\n    # ...Omitted Code...\n    return [train_scores, test_scores, y_pred_train, y_pred_test]\n</code></pre>\n\n<p>AR(2) sample test and train predictions:\n<a href=\"https://i.stack.imgur.com/RNtmw.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/RNtmw.png\" alt=\"Test Set Predictions\"></a>\n<a href=\"https://i.stack.imgur.com/mmJDy.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/mmJDy.png\" alt=\"Train Set Predictions\"></a></p>\n\n<pre><code>SAMPLE DATA: Train features and Train Targets (future_returns) \n</code></pre>\n\n<p>It looks like a mess, but just copy paste into excel file and it should be good to go!)</p>\n\n<p>Date    returns ma14    rsi14   ma30    rsi30   ma50    rsi50   ma200   rsi200  future_returns\n10/14/1980  3.49E-05    42.76324407 49.21625218 66.6250545  49.69881565 49.45368438 49.93538688 37.78942977 50.51223405 0.013277481\n10/15/1980  0.013277481 0.239711734 53.45799196 0.16387242  51.78260494 0.140801819 51.19194274 0.10545251  50.79944024 -0.011855382\n10/16/1980  -0.011855382    -0.306338818    45.66265303 -0.159676722    47.88773425 -0.115851283    48.81901884 -0.107808537    50.24325364 -0.00414208\n10/17/1980  -0.00414208 -1.154286743    48.16105108 -0.451328445    49.1031414  -0.3083074  49.55134428 -0.299669528    50.4107189  0.007939494\n10/20/1980  0.007939494 0.548806765 51.89223141 0.338253188 50.95654204 0.15403304  50.679274   0.145277255 50.67207082 -0.0050544\n10/21/1980  -0.0050544  -0.580692978    47.89906352 -0.443621598    48.97241743 -0.250429072    49.46553614 -0.227539737    50.38503757 -2.93E-05\n10/22/1980  -2.93E-05   -85.38681662    49.51695915 -69.94007273    49.7551065  -46.09189634    49.93866124 -37.61970911    50.49403171 -0.018135363\n10/23/1980  -0.018135363    -0.020087358    44.19203763 -0.067897836    47.0643223  -0.037135977    48.27685366 -0.05615813 50.09551572 0.000415381\n10/24/1980  0.000415381 -2.422576075    50.11149401 3.125882141 49.93407273 1.480210269 50.01580668 2.418672772 50.49781053 -0.013535864\n10/27/1980  -0.013535864    0.12834969  46.14718747 -0.056014904    47.91325905 -0.053384853    48.75782925 -0.065375964    50.19198915 0.00337859\n10/28/1980  0.00337859  -0.566993349    51.18890074 0.168834456 50.4293269  0.275579337 50.30416736 0.265200747 50.55684672 -0.003396646\n10/29/1980  -0.003396646    0.522213275 49.20187924 0.045438303 49.43972414 -0.207144904    49.69125655 -0.266487054    50.40819543 -0.011421006\n10/30/1980  -0.011421006    0.185961701 46.88078737 0.029632441 48.27895767 -0.018832701    48.97017418 -0.073584097    50.23238873 0.013350935\n10/31/1980  0.013350935 -0.156079209    54.08231943 -0.003988301    51.88647852 0.031510014 51.2008709  0.064478565 50.76515097 0.01758565\n11/3/1980   0.01758565  -0.047207787    55.20045808 0.011243586 52.47271385 0.048876357 51.57016088 0.055301429 50.85553721 0.025052611\n11/5/1980   0.025052611 0.000435129 57.18044487 0.053812694 53.50605621 0.05421219  52.22072289 0.039977524 51.01490125 -0.017722306\n11/6/1980   -0.017722306    0.023031138 44.92992843 -0.03124573 47.39891281 -0.070442975    48.41875471 -0.050855544    50.07992286 0.000581639\n11/7/1980   0.000581639 -0.121650134    49.87840955 1.580058713 49.92880444 2.604518867 50.0080164  1.580277943 50.47031631 0.002508371\n11/10/1980  0.002508371 -0.182865195    50.38381628 0.640792927 50.18967587 0.608670831 50.17291603 0.34700777  50.51126003 0.012129939\n11/11/1980  0.012129939 0.063376989 52.93601236 0.221445976 51.49515928 0.145866445 50.99656886 0.079352102 50.71573089 0.024926655</p>\n",
                "tags": "<machine-learning><neural-network><deep-learning><time-series><linear-regression>",
                "answers": [
                    [
                        "49472",
                        "2",
                        "49355",
                        "",
                        "",
                        "<p>Thanks for providing the sample data. I do not really see any severe problems to pin something down as the definite cause of your problem, but I can give you some advice for improvement that could help.</p>\n\n<h2>Standardizing and scaling</h2>\n\n<p>Some of your features have larger values and some have smaller values. If you don't standardize and scale your features and targets, it will result in \"unbalanced\" weights inside your NN which can lead to an unstable model. Therefore, use something like the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\" rel=\"nofollow noreferrer\">StandardScaler</a> to standardize and scale your data after splitting it up into a train and a test dataset.</p>\n\n<h2>Activation function</h2>\n\n<p>It is always worth a try to play around with different activation functions. ReLu is quite simple and computationally inexpensive compared to other activation functions, but in a bad setup, it can lead to many dead neurons. So I would suggest trying out <a href=\"https://stackoverflow.com/a/40775144/9291522\">other activation functions</a> like Tanh or Leaky Relu. <em>Note: That does not mean that ReLu is a bad activation function. For many reasons, it is actually a very popular one.</em></p>\n\n<h2>Learning rate</h2>\n\n<p>Especially if you stick with ReLu, check what difference it makes if you reduce the learning rate and/or set a learning rate decay.</p>\n\n<h2>Neural Network Architecture</h2>\n\n<p>Since you are working with a time-series, it would make sense to use a Recurrent Neural Network which was designed for time-series data like <a href=\"https://keras.io/layers/recurrent/#gru\" rel=\"nofollow noreferrer\">GRU</a> or <a href=\"https://keras.io/layers/recurrent/#lstm\" rel=\"nofollow noreferrer\">LSTM</a>.</p>\n\n<h3>Other</h3>\n\n<p>One side note to prevent you from falling into the same trap I did: If you work with TA-Lib, scale your values before you calculate any features. There is an <a href=\"https://github.com/mrjbq7/ta-lib/issues/151\" rel=\"nofollow noreferrer\">open issue</a> on Github of TA-Lib calculating wrong features if the input-values are too small. I see that your targets also have quite small values, so maybe keep an eye on that.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16163",
            "_score": 7.2349553,
            "_source": {
                "title": "How to create feature representation?",
                "content": "How to create feature representation? <p>Let's say I've a dataset with 800 rows(40 entries for each of 20 users). The entries are user session log ( columns are - browser, os, time, date etc for a specific session).</p>\n\n<p>Now each user has unique id (1-20). Let's say user_id=1 is special one and I need to detect it whenever new data comes. </p>\n\n<p>So for new data I need to predict whether that session is of user_id=1 or not. </p>\n\n<p>My question is How to do that ?</p>\n\n<p>One way I thought is make a feature representation for each of the 20 users, and whenever new data comes, take the distance of the data from each of feature and see the minimum distance.</p>\n\n<p>But the problem is when I make a unique feature representation for each user, how to deal with columns like browser, os - because a user can have used multiple browsers in all those 40 sessions ?  </p>\n <machine-learning><pandas><data-science-model><p>If I understand correctly, you want to create features? there are a few ways to do this. I will first talk about <a href=\"https://towardsdatascience.com/choosing-the-right-encoding-method-label-vs-onehot-encoder-a4434493149b\" rel=\"nofollow noreferrer\">Label Encoding and Hot Label Encoding</a>(link is the first I found on Google). This depends on the model, I will explain below.</p>\n\n<p>Since we want to use categorical data in a model, most models behave better with numerical data. So let's convert categorical -> numeric:</p>\n\n<pre><code>import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndf = pd.DataFrame({'user':['adam','adam','susie','jane'], \n                   'browser':['chrome','firefox','chrome','opera']})\n\n   browser   user\n0   chrome   adam\n1  firefox   adam\n2   chrome  susie\n3    opera   jane\n\nlabel_encoder = LabelEncoder()\n# convert browser to numeric\ndf['browser_encoded'] = label_encoder.fit_transform(df['browser'])\n\n   browser   user  browser_encoded\n0   chrome   adam                0\n1  firefox   adam                1\n2   chrome  susie                0\n3    opera   jane                2\n</code></pre>\n\n<p>In the \"real world\" you would drop <code>browser</code> column as its now encoded. I left it to show you what's happening. </p>\n\n<p>Now notice how our data is now numeric. But now there is a problem. If you're using something like multiple linear regression, you've just assigned a higher weight to the Opera browser since it's a higher number. (2>1 and 2>0). But since this is categorical, and Opera isn't \"weightier\" than other browsers in our model, we need to solve this. This is where One Hot Encoding comes in to play.</p>\n\n<pre><code>pd.concat([df,pd.get_dummies(df['browser'])], axis=1)\n\n   browser   user  browser_encoded  chrome  firefox  opera\n0   chrome   adam                0       1        0      0\n1  firefox   adam                1       0        1      0\n2   chrome  susie                0       1        0      0\n3    opera   jane                2       0        0      1\n</code></pre>\n\n<p>Now we have our data in columns. the 1 value appears when someone has used that browser for that record. See the first record? where <code>chrome</code> column is 1, because adam used 'chrome' in the <code>browser</code> column?. </p>\n\n<p>There is one last thing when it comes to label encoding! You don't want to fall in the <a href=\"https://www.quora.com/When-do-I-fall-in-the-dummy-variable-trap\" rel=\"nofollow noreferrer\">dummy variable trap</a> with certain models. The basic logic is: If you know the browser is <em>not</em> Chrome or Firefox, it must be Opera. If you know the browser <em>is</em> Chrome, you know that it is not Firefox or Opera. So you only need N-1. If you use all the columns, your model may not perform well. You need to drop only one of the columns. you can do that with <code>drop_first=True</code></p>\n\n<pre><code>pd.concat([df,pd.get_dummies(df['browser'], drop_first=True)], axis=1)\n   browser   user  browser_encoded  firefox  opera\n0   chrome   adam                0        0      0\n1  firefox   adam                1        1      0\n2   chrome  susie                0        0      0\n3    opera   jane                2        0      1\n</code></pre>\n\n<p>Another way to create features is to make them yourself. You mentioned that a user can use more than one browser. I'm making something up for the sake of a simple example - but maybe the number of browsers they use can be a feature? You can create one like so:</p>\n\n<pre><code>df['num_of_browsers_used'] = df.groupby('user', as_index=False).transform('nunique')['browser']\n    browser user    browser_encoded num_of_browsers_used\n0   chrome  adam    0   2\n1   firefox adam    1   2\n2   chrome  susie   0   1\n3   opera   jane    2   1\n</code></pre>\n",
                "codes": [
                    [
                        "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndf = pd.DataFrame({'user':['adam','adam','susie','jane'], \n                   'browser':['chrome','firefox','chrome','opera']})\n\n   browser   user\n0   chrome   adam\n1  firefox   adam\n2   chrome  susie\n3    opera   jane\n\nlabel_encoder = LabelEncoder()\n# convert browser to numeric\ndf['browser_encoded'] = label_encoder.fit_transform(df['browser'])\n\n   browser   user  browser_encoded\n0   chrome   adam                0\n1  firefox   adam                1\n2   chrome  susie                0\n3    opera   jane                2\n",
                        "pd.concat([df,pd.get_dummies(df['browser'])], axis=1)\n\n   browser   user  browser_encoded  chrome  firefox  opera\n0   chrome   adam                0       1        0      0\n1  firefox   adam                1       0        1      0\n2   chrome  susie                0       1        0      0\n3    opera   jane                2       0        0      1\n",
                        "pd.concat([df,pd.get_dummies(df['browser'], drop_first=True)], axis=1)\n   browser   user  browser_encoded  firefox  opera\n0   chrome   adam                0        0      0\n1  firefox   adam                1        1      0\n2   chrome  susie                0        0      0\n3    opera   jane                2        0      1\n",
                        "df['num_of_browsers_used'] = df.groupby('user', as_index=False).transform('nunique')['browser']\n    browser user    browser_encoded num_of_browsers_used\n0   chrome  adam    0   2\n1   firefox adam    1   2\n2   chrome  susie   0   1\n3   opera   jane    2   1\n"
                    ]
                ],
                "question_id:": "53507",
                "question_votes:": "1",
                "question_text:": "<p>Let's say I've a dataset with 800 rows(40 entries for each of 20 users). The entries are user session log ( columns are - browser, os, time, date etc for a specific session).</p>\n\n<p>Now each user has unique id (1-20). Let's say user_id=1 is special one and I need to detect it whenever new data comes. </p>\n\n<p>So for new data I need to predict whether that session is of user_id=1 or not. </p>\n\n<p>My question is How to do that ?</p>\n\n<p>One way I thought is make a feature representation for each of the 20 users, and whenever new data comes, take the distance of the data from each of feature and see the minimum distance.</p>\n\n<p>But the problem is when I make a unique feature representation for each user, how to deal with columns like browser, os - because a user can have used multiple browsers in all those 40 sessions ?  </p>\n",
                "tags": "<machine-learning><pandas><data-science-model>",
                "answers": [
                    [
                        "53528",
                        "2",
                        "53507",
                        "",
                        "",
                        "<p>If I understand correctly, you want to create features? there are a few ways to do this. I will first talk about <a href=\"https://towardsdatascience.com/choosing-the-right-encoding-method-label-vs-onehot-encoder-a4434493149b\" rel=\"nofollow noreferrer\">Label Encoding and Hot Label Encoding</a>(link is the first I found on Google). This depends on the model, I will explain below.</p>\n\n<p>Since we want to use categorical data in a model, most models behave better with numerical data. So let's convert categorical -> numeric:</p>\n\n<pre><code>import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndf = pd.DataFrame({'user':['adam','adam','susie','jane'], \n                   'browser':['chrome','firefox','chrome','opera']})\n\n   browser   user\n0   chrome   adam\n1  firefox   adam\n2   chrome  susie\n3    opera   jane\n\nlabel_encoder = LabelEncoder()\n# convert browser to numeric\ndf['browser_encoded'] = label_encoder.fit_transform(df['browser'])\n\n   browser   user  browser_encoded\n0   chrome   adam                0\n1  firefox   adam                1\n2   chrome  susie                0\n3    opera   jane                2\n</code></pre>\n\n<p>In the \"real world\" you would drop <code>browser</code> column as its now encoded. I left it to show you what's happening. </p>\n\n<p>Now notice how our data is now numeric. But now there is a problem. If you're using something like multiple linear regression, you've just assigned a higher weight to the Opera browser since it's a higher number. (2>1 and 2>0). But since this is categorical, and Opera isn't \"weightier\" than other browsers in our model, we need to solve this. This is where One Hot Encoding comes in to play.</p>\n\n<pre><code>pd.concat([df,pd.get_dummies(df['browser'])], axis=1)\n\n   browser   user  browser_encoded  chrome  firefox  opera\n0   chrome   adam                0       1        0      0\n1  firefox   adam                1       0        1      0\n2   chrome  susie                0       1        0      0\n3    opera   jane                2       0        0      1\n</code></pre>\n\n<p>Now we have our data in columns. the 1 value appears when someone has used that browser for that record. See the first record? where <code>chrome</code> column is 1, because adam used 'chrome' in the <code>browser</code> column?. </p>\n\n<p>There is one last thing when it comes to label encoding! You don't want to fall in the <a href=\"https://www.quora.com/When-do-I-fall-in-the-dummy-variable-trap\" rel=\"nofollow noreferrer\">dummy variable trap</a> with certain models. The basic logic is: If you know the browser is <em>not</em> Chrome or Firefox, it must be Opera. If you know the browser <em>is</em> Chrome, you know that it is not Firefox or Opera. So you only need N-1. If you use all the columns, your model may not perform well. You need to drop only one of the columns. you can do that with <code>drop_first=True</code></p>\n\n<pre><code>pd.concat([df,pd.get_dummies(df['browser'], drop_first=True)], axis=1)\n   browser   user  browser_encoded  firefox  opera\n0   chrome   adam                0        0      0\n1  firefox   adam                1        1      0\n2   chrome  susie                0        0      0\n3    opera   jane                2        0      1\n</code></pre>\n\n<p>Another way to create features is to make them yourself. You mentioned that a user can use more than one browser. I'm making something up for the sake of a simple example - but maybe the number of browsers they use can be a feature? You can create one like so:</p>\n\n<pre><code>df['num_of_browsers_used'] = df.groupby('user', as_index=False).transform('nunique')['browser']\n    browser user    browser_encoded num_of_browsers_used\n0   chrome  adam    0   2\n1   firefox adam    1   2\n2   chrome  susie   0   1\n3   opera   jane    2   1\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11847",
            "_score": 7.2116227,
            "_source": {
                "title": "Machine learning algorithm for Low dimension input to high dimension output",
                "content": "Machine learning algorithm for Low dimension input to high dimension output <p>I am plaining on training a network for body generation, i.e. given some specific measurement,(5 features)  the output will be the a set of vertices representing the obj of the bodies. I am wondering what kind of machine learning algorithm is best suited for this scenario.</p>\n <machine-learning><deep-learning><p>One common approach for your problem would be to first learn a low-dimensional representation of your output space in an unsupervised manner, and then a mapping from your inputs to the now-dimensionally-reduced outputs. To put it in a kind of pseudo-SKLearn terms, the overall procedure would look as follows:</p>\n\n<p>Model fitting:</p>\n\n<pre><code>dr = SomeDimensionalityReducer()\nY_dr = dr.fit_transform(Y)\nm = SomeSupervisedModel()\nm.fit(X, Y_dr)\n</code></pre>\n\n<p>Model application:</p>\n\n<pre><code>dr.inverse(m.predict(X_new))\n</code></pre>\n\n<p>For the role of <code>SomeSupervisedModel</code> you are free to choose any standard machine learning regression model, remembering that you may need to predict a vector as an output rather than a single number. In some cases (such as the neural network) it is a natural part of the model, in others it means you would need to train a separate model for each of the components in the output.</p>\n\n<p>The choice of the dimensionality reduction technique is a bit more tricky, as the <code>inverse</code> operation is not normally part of standard implementations, hence you might need to understand and implement it manually. </p>\n\n<p>Your main options are listed in the Wikipedia page on <a href=\"https://en.wikipedia.org/wiki/Dimensionality_reduction\" rel=\"nofollow noreferrer\">dimensionality reduction</a>. Consider <a href=\"https://en.wikipedia.org/wiki/Principal_component_analysis\" rel=\"nofollow noreferrer\">PCA</a>, <a href=\"https://en.wikipedia.org/wiki/Kernel_principal_component_analysis\" rel=\"nofollow noreferrer\">Kernel-PCA</a> and an <a href=\"https://en.wikipedia.org/wiki/Autoencoder\" rel=\"nofollow noreferrer\">Autoencoder</a> as your base choices. </p>\n\n<ul>\n<li>PCA would result in a linear mapping and might not be powerful enough to represent the output space adequately in all but the simplest of tasks. However, it is easy to use and understand and is not too prone to overfitting.</li>\n<li>Kernel-PCA a more flexible nonlinear model, which is still easy to implement, but it has higher memory and computational requirements and may overfit.</li>\n<li>The Autoencoder route might be the best of the three, but, being a neural network-based method it may be fiddly and require a lot of tuning. There is a whole world of different kinds of autoencoders to choose from.</li>\n</ul>\n\n<p>Another possibility, not mentioned in the Wikipedia article above (because it is more of a \"dimensionality expansion\" rather than reduction method) is the <a href=\"https://en.wikipedia.org/wiki/Generative_adversarial_network\" rel=\"nofollow noreferrer\">Generative Adversarial Network</a>. Of all the mentioned approaches it may be the most sophisticated and, if you are lucky and have a lot of data, may give the best results. Unfortunately, it is the fussiest of all to work with, so try other things before trying it.</p>\n\n<p>Note that you do not need your <em>inputs</em> <code>X</code> to perform the dimensionality reduction, hence you can \"help\" your method by feeding more samples from the output space without having to also obtain the corresponding inputs.</p>\n<p>If I'm understanding correctly you want to model a set of data (in a network form in this case) for which you give 5 input parameters and you get N objects as output of your model, with N>5.</p>\n\n<p>A network basically classifies an object based on the input parametersand outputs the predicted value. Putting a basic network generation, you can classify what car you are looking at based on 3 certain features: \"motor size\", \"number of seats\" and \"country where the car was designed\". From the network you can extract the model and production year (if enough data is provided)and predict what car you have. However, due to the method you are obtaining an output with smaller dimensionality than the input (usually N_output=1). </p>\n\n<p>However, you can associate certain information to that output. In the previous example it could be a technical datasheet of the car model the network outputs. This technical datasheet can contain many features that were not considered in the model (network), which result in N_output>N_input.</p>\n\n<p>The critical step in this case is selecting correctly what output do you want for your network (classification algorithm) and how do you want to associate that output to further insight of that classification. </p>\n\n<p>The algorithm itself to create the network depends on the data and what output do you want. For example, in a basic KNN of the previous case, you select the output as a \"compound weighed effect\" of all the inputs that result in the network. </p>\n",
                "codes": [
                    [
                        "dr = SomeDimensionalityReducer()\nY_dr = dr.fit_transform(Y)\nm = SomeSupervisedModel()\nm.fit(X, Y_dr)\n",
                        "dr.inverse(m.predict(X_new))\n"
                    ],
                    []
                ],
                "question_id:": "41725",
                "question_votes:": "1",
                "question_text:": "<p>I am plaining on training a network for body generation, i.e. given some specific measurement,(5 features)  the output will be the a set of vertices representing the obj of the bodies. I am wondering what kind of machine learning algorithm is best suited for this scenario.</p>\n",
                "tags": "<machine-learning><deep-learning>",
                "answers": [
                    [
                        "42106",
                        "2",
                        "41725",
                        "",
                        "",
                        "<p>One common approach for your problem would be to first learn a low-dimensional representation of your output space in an unsupervised manner, and then a mapping from your inputs to the now-dimensionally-reduced outputs. To put it in a kind of pseudo-SKLearn terms, the overall procedure would look as follows:</p>\n\n<p>Model fitting:</p>\n\n<pre><code>dr = SomeDimensionalityReducer()\nY_dr = dr.fit_transform(Y)\nm = SomeSupervisedModel()\nm.fit(X, Y_dr)\n</code></pre>\n\n<p>Model application:</p>\n\n<pre><code>dr.inverse(m.predict(X_new))\n</code></pre>\n\n<p>For the role of <code>SomeSupervisedModel</code> you are free to choose any standard machine learning regression model, remembering that you may need to predict a vector as an output rather than a single number. In some cases (such as the neural network) it is a natural part of the model, in others it means you would need to train a separate model for each of the components in the output.</p>\n\n<p>The choice of the dimensionality reduction technique is a bit more tricky, as the <code>inverse</code> operation is not normally part of standard implementations, hence you might need to understand and implement it manually. </p>\n\n<p>Your main options are listed in the Wikipedia page on <a href=\"https://en.wikipedia.org/wiki/Dimensionality_reduction\" rel=\"nofollow noreferrer\">dimensionality reduction</a>. Consider <a href=\"https://en.wikipedia.org/wiki/Principal_component_analysis\" rel=\"nofollow noreferrer\">PCA</a>, <a href=\"https://en.wikipedia.org/wiki/Kernel_principal_component_analysis\" rel=\"nofollow noreferrer\">Kernel-PCA</a> and an <a href=\"https://en.wikipedia.org/wiki/Autoencoder\" rel=\"nofollow noreferrer\">Autoencoder</a> as your base choices. </p>\n\n<ul>\n<li>PCA would result in a linear mapping and might not be powerful enough to represent the output space adequately in all but the simplest of tasks. However, it is easy to use and understand and is not too prone to overfitting.</li>\n<li>Kernel-PCA a more flexible nonlinear model, which is still easy to implement, but it has higher memory and computational requirements and may overfit.</li>\n<li>The Autoencoder route might be the best of the three, but, being a neural network-based method it may be fiddly and require a lot of tuning. There is a whole world of different kinds of autoencoders to choose from.</li>\n</ul>\n\n<p>Another possibility, not mentioned in the Wikipedia article above (because it is more of a \"dimensionality expansion\" rather than reduction method) is the <a href=\"https://en.wikipedia.org/wiki/Generative_adversarial_network\" rel=\"nofollow noreferrer\">Generative Adversarial Network</a>. Of all the mentioned approaches it may be the most sophisticated and, if you are lucky and have a lot of data, may give the best results. Unfortunately, it is the fussiest of all to work with, so try other things before trying it.</p>\n\n<p>Note that you do not need your <em>inputs</em> <code>X</code> to perform the dimensionality reduction, hence you can \"help\" your method by feeding more samples from the output space without having to also obtain the corresponding inputs.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "41750",
                        "2",
                        "41725",
                        "",
                        "",
                        "<p>If I'm understanding correctly you want to model a set of data (in a network form in this case) for which you give 5 input parameters and you get N objects as output of your model, with N>5.</p>\n\n<p>A network basically classifies an object based on the input parametersand outputs the predicted value. Putting a basic network generation, you can classify what car you are looking at based on 3 certain features: \"motor size\", \"number of seats\" and \"country where the car was designed\". From the network you can extract the model and production year (if enough data is provided)and predict what car you have. However, due to the method you are obtaining an output with smaller dimensionality than the input (usually N_output=1). </p>\n\n<p>However, you can associate certain information to that output. In the previous example it could be a technical datasheet of the car model the network outputs. This technical datasheet can contain many features that were not considered in the model (network), which result in N_output>N_input.</p>\n\n<p>The critical step in this case is selecting correctly what output do you want for your network (classification algorithm) and how do you want to associate that output to further insight of that classification. </p>\n\n<p>The algorithm itself to create the network depends on the data and what output do you want. For example, in a basic KNN of the previous case, you select the output as a \"compound weighed effect\" of all the inputs that result in the network. </p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11673",
            "_score": 7.183925,
            "_source": {
                "title": "multivariate clustering, dimensionality reduction and data scalling for regression",
                "content": "multivariate clustering, dimensionality reduction and data scalling for regression <p>I have a dataset with approximately 20000 observations consisting of 40 independent and 1 dependent variable. My initial objective is to develop a model that will predict the dependent variable. I have tried several models and applied linear regression and other algorithms such as Random Forests, of course by splitting the dataset into training and testing sets.</p>\n\n<p>Unfortunatelly I cannot get any meaningful results; I have very large errors. I believe there is something \"messy\" with the dataset, so I have decided to do some clustering first and then apply regression within each cluster. Considering that my dependent variable may exhibit a lot of variation I believe I should do clustering with all variables (dependent and independent), so as each cluster will have similar values of my dependent variable. I have tried to apply Kmeans and I faced several problems. First of all, it seems I cannot identify the right number of clusters. The \"elbow\" method gives an unclear number and when I use it with less data (about 2000 observations) I get something like this:</p>\n\n<p><a href=\"https://i.stack.imgur.com/AClqx.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/AClqx.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>I also had similar problems with hierarchical clustering. I have already tried to apply regressions within the clusters identified, but the results are still very poor.</p>\n\n<p>Right now I believe I should possibly use some kind of \"weight\" to my data, in order to put more weight on the dependent variable when I do clustering, since I believe that this is the problem. Hence, my questions here are:</p>\n\n<ol>\n<li>is there a way/algorithm where I adjust weights in the variables to be clustered?</li>\n</ol>\n\n<p>Moreover I am confused with two more issues:</p>\n\n<ol start=\"2\">\n<li><p>data scaling:\nis it necessary to scale the data before clustering? does this guarantee more accurate results? when do we scale the data? </p></li>\n<li><p>dimensionality reduction:\nI have read a lot about principal component analysis and dimensionality reduction, but I am still confused. Again; is this necessary? how many variables are too many to consider applying PCA? are 10 variables too many? or maybe 20? or 50? when should we apply dimensionality reduction? a problem with PCA is that I would still need my original variables to extract the coefficients after regression, while to my understanding with PCA I cannot do that.</p></li>\n</ol>\n\n<p>This question is more about discussion in order to understand some particular concepts and find a solution to my problem and does not refer to coding issues. Any example and/or references would be appreciated though. I am coding in R.</p>\n <clustering><regression><pca><dimensionality-reduction><clusters><p>Great question, I will try to answer the aspects related to dimensionality reduction mentioned above.\n<span class=\"math-container\">$Dimensionality\\: Reduction:$</span> The number of dimensions which you want to keep after doing PCA is an experimental value you can experiment with the number of dimensions and check you results. Although you have mentioned all 40 features are independent i would still ask you to do a correlation analysis of the variables.</p>\n\n<p>Pca removes these correlated features and gives you a set of features which amount to explain most of your data. One advantage of dimensionality reduction is in regression. Correlated features often are a cause of multicollinearity. Doing a dimensionality reduction helps us get rid of this problem. Also once we have a reduced set of features we can apply the cluster analysis. The reason is K-means calculates the l2- distance between data points. in very high dimensions the concept of euclidean distance becomes less useful because of the curse of dimensionality. (probably the reason of the problems with your elbow curve.)</p>\n\n<p>Hence bringing down the number of features using pca and clustering later will give a better idea of the groupings of the data.\nThe problem which you mention about PCA can be solved in fact it is not an issue at all. You can do regression with the features obtained by the data and only take the coefficients of the reduced feature set.Some other techniques which you might want to look at are regularization in regression.\nFor example L1-regularization helps in feature selection and helps with correlated variables.</p>\n<p>I will try to answer to your questions one by one. Unfortunately I am not familiar with R, but I will provide some python links whenever relevant - even if you won't use the code you will be able to find there more details on the suggested methods. </p>\n\n<ol>\n<li><p>I suggest you use a Decision Tree Regressor for the clustering. It gives you the ability to set what the target variable is and you can directly select as optimization criterion the minimization of Mean Square Error. You can select as stopping criterion a maximum number of levels according to the number of clusters/MSE that you find acceptable. </p>\n\n<p>The following picture summarizes the logic behind tree-based hierarchical clustering and also shows that you usually have to do some pruning (some samples might be too different to be assigned to any cluster). The picture comes from <a href=\"https://www.oreilly.com/library/view/social-network-analysis/9781449311377/ch04.html\" rel=\"nofollow noreferrer\">this</a> link, where hierarchical clustering is explained; the optimisation criterion there is distance as it fits better with the type of data they are using, but of course you can use the one that fits to your own data.</p>\n\n<p><a href=\"https://i.stack.imgur.com/C7dVC.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/C7dVC.png\" alt=\"enter image description here\"></a></p>\n\n<p>In python, this can been done using <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\" rel=\"nofollow noreferrer\">scikit-learn.DecisionTreeRegressor</a> and you can even plot the tree using <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\" rel=\"nofollow noreferrer\">export_graphviz</a> function (you can read some interesting information about the advantages and limitations of Decision Trees <a href=\"https://scikit-learn.org/stable/modules/tree.html\" rel=\"nofollow noreferrer\">here</a>). For better understanding, the tree below shows an example of clustering results using a Decision Tree Regressor. I have highlighted the end-clusters with red.</p></li>\n</ol>\n\n<p><a href=\"https://i.stack.imgur.com/TSzm4.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/TSzm4.png\" alt=\"enter image description here\"></a></p>\n\n<ol start=\"2\">\n<li><p>Yes, it is advisable to do some kind of data scaling before proceeding with the clustering. This way, you ensure that the clustering results are not biased by the scale of the variables (e.g. a variable that takes large values might influence certain clustering algorithm results more that one with smaller values). Keep in mind though that many clustering algorithms that come from analysis toolkits anyway scale data automatically before clustering (at least in python). There are 2 alternatives for scaling: standardisation and normalisation; you need to choose which one of those fits better to the current problem and clustering algorithm. </p>\n\n<ul>\n<li>Standardization transforms the data in order to have zero mean and unit variance.</li>\n<li>Normalisation rescales the data into the range [0,1].</li>\n</ul>\n\n<p>You can read more about standardisation and normalisation <a href=\"http://www.dataminingblog.com/standardization-vs-normalization/\" rel=\"nofollow noreferrer\">here</a>,\nwhile <a href=\"https://medium.com/@rrfd/standardize-or-normalize-examples-in-python-e3f174b65dfc\" rel=\"nofollow noreferrer\">here</a> you can find some very good examples about their use.</p></li>\n<li><p>As far as I know there is no trustworthy \"rule of thumb\" regarding the number of features for each problem, this is something that depends a lot on the nature of the problem and most importantly on the nature of the features. It is always important though to make sure that the input variables are uncorrelated with each other. PCA is a good way to ensure that - it actually applies some orthogonal transformation to your set of features in order to produce a set of linearly non-correlated variables based on the initial set of features - the new features are ordered based on the amount of information they contain. @Shubham summarised very well the logic behind pca, so I don't have much to add. </p></li>\n</ol>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "41170",
                "question_votes:": "",
                "question_text:": "<p>I have a dataset with approximately 20000 observations consisting of 40 independent and 1 dependent variable. My initial objective is to develop a model that will predict the dependent variable. I have tried several models and applied linear regression and other algorithms such as Random Forests, of course by splitting the dataset into training and testing sets.</p>\n\n<p>Unfortunatelly I cannot get any meaningful results; I have very large errors. I believe there is something \"messy\" with the dataset, so I have decided to do some clustering first and then apply regression within each cluster. Considering that my dependent variable may exhibit a lot of variation I believe I should do clustering with all variables (dependent and independent), so as each cluster will have similar values of my dependent variable. I have tried to apply Kmeans and I faced several problems. First of all, it seems I cannot identify the right number of clusters. The \"elbow\" method gives an unclear number and when I use it with less data (about 2000 observations) I get something like this:</p>\n\n<p><a href=\"https://i.stack.imgur.com/AClqx.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/AClqx.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>I also had similar problems with hierarchical clustering. I have already tried to apply regressions within the clusters identified, but the results are still very poor.</p>\n\n<p>Right now I believe I should possibly use some kind of \"weight\" to my data, in order to put more weight on the dependent variable when I do clustering, since I believe that this is the problem. Hence, my questions here are:</p>\n\n<ol>\n<li>is there a way/algorithm where I adjust weights in the variables to be clustered?</li>\n</ol>\n\n<p>Moreover I am confused with two more issues:</p>\n\n<ol start=\"2\">\n<li><p>data scaling:\nis it necessary to scale the data before clustering? does this guarantee more accurate results? when do we scale the data? </p></li>\n<li><p>dimensionality reduction:\nI have read a lot about principal component analysis and dimensionality reduction, but I am still confused. Again; is this necessary? how many variables are too many to consider applying PCA? are 10 variables too many? or maybe 20? or 50? when should we apply dimensionality reduction? a problem with PCA is that I would still need my original variables to extract the coefficients after regression, while to my understanding with PCA I cannot do that.</p></li>\n</ol>\n\n<p>This question is more about discussion in order to understand some particular concepts and find a solution to my problem and does not refer to coding issues. Any example and/or references would be appreciated though. I am coding in R.</p>\n",
                "tags": "<clustering><regression><pca><dimensionality-reduction><clusters>",
                "answers": [
                    [
                        "41186",
                        "2",
                        "41170",
                        "",
                        "",
                        "<p>Great question, I will try to answer the aspects related to dimensionality reduction mentioned above.\n<span class=\"math-container\">$Dimensionality\\: Reduction:$</span> The number of dimensions which you want to keep after doing PCA is an experimental value you can experiment with the number of dimensions and check you results. Although you have mentioned all 40 features are independent i would still ask you to do a correlation analysis of the variables.</p>\n\n<p>Pca removes these correlated features and gives you a set of features which amount to explain most of your data. One advantage of dimensionality reduction is in regression. Correlated features often are a cause of multicollinearity. Doing a dimensionality reduction helps us get rid of this problem. Also once we have a reduced set of features we can apply the cluster analysis. The reason is K-means calculates the l2- distance between data points. in very high dimensions the concept of euclidean distance becomes less useful because of the curse of dimensionality. (probably the reason of the problems with your elbow curve.)</p>\n\n<p>Hence bringing down the number of features using pca and clustering later will give a better idea of the groupings of the data.\nThe problem which you mention about PCA can be solved in fact it is not an issue at all. You can do regression with the features obtained by the data and only take the coefficients of the reduced feature set.Some other techniques which you might want to look at are regularization in regression.\nFor example L1-regularization helps in feature selection and helps with correlated variables.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "41203",
                        "2",
                        "41170",
                        "",
                        "",
                        "<p>I will try to answer to your questions one by one. Unfortunately I am not familiar with R, but I will provide some python links whenever relevant - even if you won't use the code you will be able to find there more details on the suggested methods. </p>\n\n<ol>\n<li><p>I suggest you use a Decision Tree Regressor for the clustering. It gives you the ability to set what the target variable is and you can directly select as optimization criterion the minimization of Mean Square Error. You can select as stopping criterion a maximum number of levels according to the number of clusters/MSE that you find acceptable. </p>\n\n<p>The following picture summarizes the logic behind tree-based hierarchical clustering and also shows that you usually have to do some pruning (some samples might be too different to be assigned to any cluster). The picture comes from <a href=\"https://www.oreilly.com/library/view/social-network-analysis/9781449311377/ch04.html\" rel=\"nofollow noreferrer\">this</a> link, where hierarchical clustering is explained; the optimisation criterion there is distance as it fits better with the type of data they are using, but of course you can use the one that fits to your own data.</p>\n\n<p><a href=\"https://i.stack.imgur.com/C7dVC.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/C7dVC.png\" alt=\"enter image description here\"></a></p>\n\n<p>In python, this can been done using <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\" rel=\"nofollow noreferrer\">scikit-learn.DecisionTreeRegressor</a> and you can even plot the tree using <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\" rel=\"nofollow noreferrer\">export_graphviz</a> function (you can read some interesting information about the advantages and limitations of Decision Trees <a href=\"https://scikit-learn.org/stable/modules/tree.html\" rel=\"nofollow noreferrer\">here</a>). For better understanding, the tree below shows an example of clustering results using a Decision Tree Regressor. I have highlighted the end-clusters with red.</p></li>\n</ol>\n\n<p><a href=\"https://i.stack.imgur.com/TSzm4.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/TSzm4.png\" alt=\"enter image description here\"></a></p>\n\n<ol start=\"2\">\n<li><p>Yes, it is advisable to do some kind of data scaling before proceeding with the clustering. This way, you ensure that the clustering results are not biased by the scale of the variables (e.g. a variable that takes large values might influence certain clustering algorithm results more that one with smaller values). Keep in mind though that many clustering algorithms that come from analysis toolkits anyway scale data automatically before clustering (at least in python). There are 2 alternatives for scaling: standardisation and normalisation; you need to choose which one of those fits better to the current problem and clustering algorithm. </p>\n\n<ul>\n<li>Standardization transforms the data in order to have zero mean and unit variance.</li>\n<li>Normalisation rescales the data into the range [0,1].</li>\n</ul>\n\n<p>You can read more about standardisation and normalisation <a href=\"http://www.dataminingblog.com/standardization-vs-normalization/\" rel=\"nofollow noreferrer\">here</a>,\nwhile <a href=\"https://medium.com/@rrfd/standardize-or-normalize-examples-in-python-e3f174b65dfc\" rel=\"nofollow noreferrer\">here</a> you can find some very good examples about their use.</p></li>\n<li><p>As far as I know there is no trustworthy \"rule of thumb\" regarding the number of features for each problem, this is something that depends a lot on the nature of the problem and most importantly on the nature of the features. It is always important though to make sure that the input variables are uncorrelated with each other. PCA is a good way to ensure that - it actually applies some orthogonal transformation to your set of features in order to produce a set of linearly non-correlated variables based on the initial set of features - the new features are ordered based on the amount of information they contain. @Shubham summarised very well the logic behind pca, so I don't have much to add. </p></li>\n</ol>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10114",
            "_score": 6.877581,
            "_source": {
                "title": "Python OneHotEncoder Using Many Dummy Variables or better practice?",
                "content": "Python OneHotEncoder Using Many Dummy Variables or better practice? <p>I am building a neural network and am at the point of using OneHotEncoder on many independent(categorical) variables.  I would like to know if I am approaching this properly with dummy variables or if since all of my variables require dummy variables there may be a better way. </p>\n\n<pre><code>df  \n    UserName    Token                       ThreadID    ChildEXE       \n0   TAG     TokenElevationTypeDefault (1)   20788       splunk-MonitorNoHandle.exe  \n1   TAG     TokenElevationTypeDefault (1)   19088       splunk-optimize.exe \n2   TAG     TokenElevationTypeDefault (1)   2840        net.exe \n807 User    TokenElevationTypeFull (2)      18740       E2CheckFileSync.exe \n808 User    TokenElevationTypeFull (2)      18740       E2check.exe \n809 User    TokenElevationTypeFull (2)      18740       E2check.exe \n811 Local   TokenElevationTypeFull (2)      18740       sc.exe  \n\nParentEXE           ChildFilePath               ParentFilePath   \nsplunkd.exe         C:\\Program Files\\Splunk\\bin C:\\Program Files\\Splunk\\bin 0\nsplunkd.exe         C:\\Program Files\\Splunk\\bin C:\\Program Files\\Splunk\\bin 0\ndagent.exe          C:\\Windows\\System32         C:\\Program Files\\Dagent 0\nwscript.exe         \\Device\\Mup\\sysvol          C:\\Windows  1\nE2CheckFileSync.exe C:\\Util                     \\Device\\Mup\\sysvol\\ 1\ncmd.exe             C:\\Windows\\SysWOW64         C:\\Util\\E2Check 1\ncmd.exe             C:\\Windows                  C:\\Windows\\SysWOW64 1\n\nDependentVariable\n0\n0\n0\n1\n1\n1\n1\n</code></pre>\n\n<p>I import the data and using the LabelEncoder on the independent variables</p>\n\n<pre><code>from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\n#IMPORT DATA\n#Matrix x of features\nX = df.iloc[:, 0:7].values\n#Dependent variable\ny = df.iloc[:, 7].values\n\n#Encoding Independent Variable\n#Need a label encoder for every categorical variable\n#Converts categorical into number - set correct index of column\n#Encode \"UserName\"\nlabelencoder_X_1 = LabelEncoder()\nX[:, 0] = labelencoder_X_1.fit_transform(X[:, 0])\n#Encode \"Token\"\nlabelencoder_X_2 = LabelEncoder()\nX[:, 1] = labelencoder_X_2.fit_transform(X[:, 1])\n#Encode \"ChildEXE\"\nlabelencoder_X_3 = LabelEncoder()\nX[:, 3] = labelencoder_X_3.fit_transform(X[:, 3])\n#Encode \"ParentEXE\"\nlabelencoder_X_4 = LabelEncoder()\nX[:, 4] = labelencoder_X_4.fit_transform(X[:, 4])\n#Encode \"ChildFilePath\"\nlabelencoder_X_5 = LabelEncoder()\nX[:, 5] = labelencoder_X_5.fit_transform(X[:, 5])\n#Encode \"ParentFilePath\"\nlabelencoder_X_6 = LabelEncoder()\nX[:, 6] = labelencoder_X_6.fit_transform(X[:, 6])\n</code></pre>\n\n<p>This gives me the following array:</p>\n\n<pre><code>X\narray([[2, 0, 20788, ..., 46, 31, 24],\n       [2, 0, 19088, ..., 46, 31, 24],\n       [2, 0, 2840, ..., 27, 42, 15],\n       ...,\n       [2, 0, 20148, ..., 17, 40, 32],\n       [2, 0, 20148, ..., 47, 23, 0],\n       [2, 0, 3176, ..., 48, 42, 32]], dtype=object)\n</code></pre>\n\n<p>Now for all of the independent variables I have to create dummy variables:</p>\n\n<p>Should I use:</p>\n\n<pre><code>onehotencoder = OneHotEncoder(categorical_features = [0, 1, 2, 3, 4, 5, 6])\nX = onehotencoder.fit_transform(X).toarray() \n</code></pre>\n\n<p>Which gives me:</p>\n\n<pre><code>X\narray([[0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 1., ..., 1., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 1., 0., 0.]])\n</code></pre>\n\n<p>Or is there a better way to approach this this?</p>\n <python><neural-network><machine-learning-model><p>If your categorical variables include variables that suggest some numerical values like ranks, you should consider just label encoding them. (for e.g. First, Second, Third, and so on can be encoded as 1, 2, 3 and so on). </p>\n\n<p>Also, find out if all these categories are important. Plot some graphs(such as histograms, distribution plots) to visualize the dataset. Remove categories that don't seem necessary.(e.g. in the above example, if First occurs more than 80%, you should consider if that certain features really contributes to your model.) </p>\n<p>Yes. You can use <code>get_dummies()</code>. get_dummies() method does what both LabelEncoder and OneHotEncoder do, besides you can drop the first dummy column of each category to prevent dummy variable trap if you intend to build linear regression.</p>\n\n<p>Example:\n1. Create dataframe:</p>\n\n<pre><code>df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['b', 'a', 'c'],\n                 'C': [1, 2, 3]})\ndf.head()\nA   B   C\n0   a   b   1\n1   b   a   2\n2   a   c   3\n</code></pre>\n\n<p>2. Apply get_dummies():</p>\n\n<pre><code>df2 = pd.get_dummies(df, prefix=['A', 'B'], drop_first=True)\ndf2.head()\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>    C   A_b B_b B_c\n0   1   0   1   0\n1   2   1   0   0\n2   3   0   0   1\n</code></pre>\n",
                "codes": [
                    [],
                    [
                        "df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['b', 'a', 'c'],\n                 'C': [1, 2, 3]})\ndf.head()\nA   B   C\n0   a   b   1\n1   b   a   2\n2   a   c   3\n",
                        "df2 = pd.get_dummies(df, prefix=['A', 'B'], drop_first=True)\ndf2.head()\n",
                        "    C   A_b B_b B_c\n0   1   0   1   0\n1   2   1   0   0\n2   3   0   0   1\n"
                    ]
                ],
                "question_id:": "36645",
                "question_votes:": "4",
                "question_text:": "<p>I am building a neural network and am at the point of using OneHotEncoder on many independent(categorical) variables.  I would like to know if I am approaching this properly with dummy variables or if since all of my variables require dummy variables there may be a better way. </p>\n\n<pre><code>df  \n    UserName    Token                       ThreadID    ChildEXE       \n0   TAG     TokenElevationTypeDefault (1)   20788       splunk-MonitorNoHandle.exe  \n1   TAG     TokenElevationTypeDefault (1)   19088       splunk-optimize.exe \n2   TAG     TokenElevationTypeDefault (1)   2840        net.exe \n807 User    TokenElevationTypeFull (2)      18740       E2CheckFileSync.exe \n808 User    TokenElevationTypeFull (2)      18740       E2check.exe \n809 User    TokenElevationTypeFull (2)      18740       E2check.exe \n811 Local   TokenElevationTypeFull (2)      18740       sc.exe  \n\nParentEXE           ChildFilePath               ParentFilePath   \nsplunkd.exe         C:\\Program Files\\Splunk\\bin C:\\Program Files\\Splunk\\bin 0\nsplunkd.exe         C:\\Program Files\\Splunk\\bin C:\\Program Files\\Splunk\\bin 0\ndagent.exe          C:\\Windows\\System32         C:\\Program Files\\Dagent 0\nwscript.exe         \\Device\\Mup\\sysvol          C:\\Windows  1\nE2CheckFileSync.exe C:\\Util                     \\Device\\Mup\\sysvol\\ 1\ncmd.exe             C:\\Windows\\SysWOW64         C:\\Util\\E2Check 1\ncmd.exe             C:\\Windows                  C:\\Windows\\SysWOW64 1\n\nDependentVariable\n0\n0\n0\n1\n1\n1\n1\n</code></pre>\n\n<p>I import the data and using the LabelEncoder on the independent variables</p>\n\n<pre><code>from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\n#IMPORT DATA\n#Matrix x of features\nX = df.iloc[:, 0:7].values\n#Dependent variable\ny = df.iloc[:, 7].values\n\n#Encoding Independent Variable\n#Need a label encoder for every categorical variable\n#Converts categorical into number - set correct index of column\n#Encode \"UserName\"\nlabelencoder_X_1 = LabelEncoder()\nX[:, 0] = labelencoder_X_1.fit_transform(X[:, 0])\n#Encode \"Token\"\nlabelencoder_X_2 = LabelEncoder()\nX[:, 1] = labelencoder_X_2.fit_transform(X[:, 1])\n#Encode \"ChildEXE\"\nlabelencoder_X_3 = LabelEncoder()\nX[:, 3] = labelencoder_X_3.fit_transform(X[:, 3])\n#Encode \"ParentEXE\"\nlabelencoder_X_4 = LabelEncoder()\nX[:, 4] = labelencoder_X_4.fit_transform(X[:, 4])\n#Encode \"ChildFilePath\"\nlabelencoder_X_5 = LabelEncoder()\nX[:, 5] = labelencoder_X_5.fit_transform(X[:, 5])\n#Encode \"ParentFilePath\"\nlabelencoder_X_6 = LabelEncoder()\nX[:, 6] = labelencoder_X_6.fit_transform(X[:, 6])\n</code></pre>\n\n<p>This gives me the following array:</p>\n\n<pre><code>X\narray([[2, 0, 20788, ..., 46, 31, 24],\n       [2, 0, 19088, ..., 46, 31, 24],\n       [2, 0, 2840, ..., 27, 42, 15],\n       ...,\n       [2, 0, 20148, ..., 17, 40, 32],\n       [2, 0, 20148, ..., 47, 23, 0],\n       [2, 0, 3176, ..., 48, 42, 32]], dtype=object)\n</code></pre>\n\n<p>Now for all of the independent variables I have to create dummy variables:</p>\n\n<p>Should I use:</p>\n\n<pre><code>onehotencoder = OneHotEncoder(categorical_features = [0, 1, 2, 3, 4, 5, 6])\nX = onehotencoder.fit_transform(X).toarray() \n</code></pre>\n\n<p>Which gives me:</p>\n\n<pre><code>X\narray([[0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 1., ..., 1., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 1., 0., 0.]])\n</code></pre>\n\n<p>Or is there a better way to approach this this?</p>\n",
                "tags": "<python><neural-network><machine-learning-model>",
                "answers": [
                    [
                        "36760",
                        "2",
                        "36645",
                        "",
                        "",
                        "<p>If your categorical variables include variables that suggest some numerical values like ranks, you should consider just label encoding them. (for e.g. First, Second, Third, and so on can be encoded as 1, 2, 3 and so on). </p>\n\n<p>Also, find out if all these categories are important. Plot some graphs(such as histograms, distribution plots) to visualize the dataset. Remove categories that don't seem necessary.(e.g. in the above example, if First occurs more than 80%, you should consider if that certain features really contributes to your model.) </p>\n",
                        "",
                        "2"
                    ],
                    [
                        "55001",
                        "2",
                        "36645",
                        "",
                        "",
                        "<p>Yes. You can use <code>get_dummies()</code>. get_dummies() method does what both LabelEncoder and OneHotEncoder do, besides you can drop the first dummy column of each category to prevent dummy variable trap if you intend to build linear regression.</p>\n\n<p>Example:\n1. Create dataframe:</p>\n\n<pre><code>df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['b', 'a', 'c'],\n                 'C': [1, 2, 3]})\ndf.head()\nA   B   C\n0   a   b   1\n1   b   a   2\n2   a   c   3\n</code></pre>\n\n<p>2. Apply get_dummies():</p>\n\n<pre><code>df2 = pd.get_dummies(df, prefix=['A', 'B'], drop_first=True)\ndf2.head()\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>    C   A_b B_b B_c\n0   1   0   1   0\n1   2   1   0   0\n2   3   0   0   1\n</code></pre>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11571",
            "_score": 6.77726,
            "_source": {
                "title": "sales price prediction",
                "content": "sales price prediction <p>I have to find make a classifier for price prediction of a item. The question I have is which columns I should choose for price prediction.</p>\n\n<p>Also which machine learning classifier would be good to perform this, at present I choose random forest. </p>\n\n<p>Do I need to use time series concept in here?, I think No</p>\n <classification><regression><prediction><p>So firstly, what do you mean by \"classifier for price prediction\"? You can predict the price as a number, that would like be different for different cars, but if you want to predict a class of price (like, high, low and medium for instance), you would need a column for that (and you can ignore the column for price, as you are not predicting the price, you're predicting the price class).</p>\n\n<p><strong>Stage 1. Pre-processing the data</strong></p>\n\n<p>Assuming you have the column in the dataset which you want to predict for, you first want to do feature selection. That is, not all features in the data would be important or relevant for predicting the price. For example, in your dataset, the first column/feature (\"index\") is irrelevant for the price of the car. But how do we prove that? Or, how do we computationally select them (using some measure), especially when they're not as trivial as \"index\"?</p>\n\n<p>We generally check the statistical properties of the features for that. I copied the data you provided in the question, and here's some things for you to start with:</p>\n\n<pre><code>import pandas as pd\n\ndata = pd.read_csv('ex.csv')\ndata\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/llRbm.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/llRbm.png\" alt=\"enter image description here\"></a></p>\n\n<pre><code>data.describe() # to check the statistical properties of the features, like mean, std dev, etc\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/zln51.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zln51.png\" alt=\"enter image description here\"></a></p>\n\n<p>Then, you could do a simple percentage count of the unique observations in each feature, and maybe you could get some insight about the features that way:</p>\n\n<pre><code>for column in data.select_dtypes(include=['object']).columns:\n    display(pd.crosstab(index=data[column], columns='% observations', normalize='columns'))\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/zJDqM.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zJDqM.png\" alt=\"enter image description here\"></a></p>\n\n<p>Then you could do a histogram analysis of the features and hopefully that gives you some more insight. For example, assuming you have sufficiently enough data, you'd normally expect the histogram of a feature to follow the normal or gaussian distribution. But if its doesn't, then you can further drill down into those features to understand why, and that might lead you to keep or discard those features from the model you're going to build.</p>\n\n<pre><code>hist = data.hist(figsize=(10, 10))\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/ko9D4.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ko9D4.png\" alt=\"enter image description here\"></a></p>\n\n<p>Then we can do correlation analysis of the features:</p>\n\n<pre><code>data.corr().style.background_gradient()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/sfY0P.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/sfY0P.png\" alt=\"enter image description here\"></a></p>\n\n<p>Or, if you want a more fancy visualization:</p>\n\n<pre><code>import seaborn as sns\nsns.heatmap(data.corr(), annot=True)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/afk32.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/afk32.png\" alt=\"enter image description here\"></a></p>\n\n<p>After doing all these, hopefully you have figured out which features to discard and which to keep for your model. These are of course \"manual\" methods of feature selection; there are other more complex methods for feature selection like SHAPLEY values, etc, which you can explore.</p>\n\n<p><strong>Stage 2 - Building a model and training it</strong></p>\n\n<p>Firstly, you need to pick a technique/method using which you want to do the prediction. The simplest one, since you have only one target variable (i.e., only one feature you're predicting, which is the price or the price class), the simplest one would be linear regression, and the most complicated ones would be some deep learning model build with CNN or RNN. So, instead of showing you how to make predictions with the simplest one, i.e., linear regression, let me show you a middle-of-the-road algorithm in terms of complexity which is quite popular and a widely used method in many machine learning tasks, the accelerated gradient boost, or xgboost, algorithm.</p>\n\n<p>We need to import some libraries for this:</p>\n\n<pre><code>from sklearn.model_selection import train_test_split\nimport xgboost\nimport numpy as np\n\nX = data.drop(['price'], axis=1) # take all the features except the target variable\ny = data['price'] # the target variable\n</code></pre>\n\n<p>Then, we create a train/test split with 80-20 split randomly. That is, we randomly take 80% data for training and 20% for testing:</p>\n\n<pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n</code></pre>\n\n<p>You can of course do a 70-30 split if you want, and definitely try out different splits at both ends of the spectrum to see what happens - that way you'll learn more about why a 70-30 or 80-20 split is good and, say, a 50-50 split is not that good.</p>\n\n<p>Then, if there are missing values in your data, fill them with a high negative value so that it doesn't have any impact in the model. You can also choose to fill them with something else, depending on your goal.</p>\n\n<pre><code>X_train.fillna((-999), inplace=True)\nX_test.fillna((-999), inplace=True)\n</code></pre>\n\n<p>Some more preprocessing steps:</p>\n\n<pre><code># Some of values are float or integer and some object. This is why we need to cast them:\nfrom sklearn import preprocessing \nfor f in X_train.columns: \n    if X_train[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder() \n        lbl.fit(list(X_train[f].values)) \n        X_train[f] = lbl.transform(list(X_train[f].values))\n\nfor f in X_test.columns: \n    if X_test[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder() \n        lbl.fit(list(X_test[f].values)) \n        X_test[f] = lbl.transform(list(X_test[f].values))\n\n\nX_train=np.array(X_train) \nX_test=np.array(X_test) \nX_train = X_train.astype(float) \nX_test = X_test.astype(float)\n\nd_train = xgboost.DMatrix(X_train, label=y_train, feature_names=list(X))\nd_test = xgboost.DMatrix(X_test, label=y_test, feature_names=list(X))\n</code></pre>\n\n<p>Finally, we can make our model and train it:</p>\n\n<pre><code>params = {\n    \"eta\": 0.01, # something called the learning rate - read up about optimization and gradient descent to understand more about this\n    \"subsample\": 0.5,\n    \"base_score\": np.mean(y_train)\n}\n\n# these params are optional - if you don't feed the train function below with the params, it will take the default values\n\nmodel = xgboost.train(params, d_train, 5000, evals = [(d_test, \"test\")], verbose_eval=100, early_stopping_rounds=50)\n</code></pre>\n\n<p>You can check the root mean square error (RMSE) that this function returns at the end to see how good or bad the training has been (low RMSE is good, high RMSE is bad - but there's no max RMSE value, it can be arbitrarily high). There are other methods to check the error, and you can explore them (like MAE, etc), but this is probably the simplest one. Anyway, the above code will return something like this:</p>\n\n<pre><code>[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[0] test-rmse:2275\nWill train until test-rmse hasn't improved in 50 rounds.\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\nStopping. Best iteration:\n[0] test-rmse:1571.88\n</code></pre>\n\n<p>It ran the algo iteratively 5000 times, printing out the result every 100 lines (that's what those numbers are in the train method). To see what each of the parameters mean, you can read <a href=\"https://xgboost.readthedocs.io/en/latest/parameter.html#general-parameters\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<p>You can also use linear regression, if you want, with xgboost, like so:</p>\n\n<pre><code>xg_reg = xgboost.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 5, alpha = 10, n_estimators = 10)\n\nxg_reg.fit(X_train,y_train)\n\npreds = xg_reg.predict(X_test) \nprint(preds) # these are the predicted prices for the test data\n&gt;&gt;&gt; array([2293.7073, 2891.9692, 3822.3757], dtype=float32)\n</code></pre>\n\n<p>And we can check the RMSE like so:</p>\n\n<pre><code>from sklearn.metrics import mean_squared_error\n\nrmse = np.sqrt(mean_squared_error(y_test, preds))\nprint(\"RMSE: %f\" % (rmse))\n&gt;&gt;&gt; RMSE: 1542.541395\n</code></pre>\n\n<p>Note that RMSE in the 2 methods is quite close (1571.88 vs 1542.54). This is like a sanity check for us that no matter which method we use, if we use it correctly, we should get similar results.</p>\n\n<p><strong>Stage 3 - testing and evaluation of the model - k-fold Cross Validation</strong></p>\n\n<p>Finally its time to see how our model performs on test data:</p>\n\n<pre><code>params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n                'max_depth': 5, 'alpha': 10}\n\ncv_results = xgboost.cv(dtrain=d_train, params=params, nfold=3,\n                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True)\n</code></pre>\n\n<p>This will again give you quite a few lines of output like when training:</p>\n\n<pre><code>[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n</code></pre>\n\n<p>This is how it looks in each of the rounds of the boosting:</p>\n\n<pre><code>print(cv_results)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/WP6Zs.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WP6Zs.png\" alt=\"enter image description here\"></a></p>\n\n<p>So, that's it. We have the predicted values.</p>\n\n<p><strong>P.S. Stage 2.5 - Visualizing the model (Optional)</strong></p>\n\n<p>Did you know that we can also visualize the model?</p>\n\n<pre><code>import matplotlib.pyplot as plt\n\nxgboost.plot_tree(xg_reg,num_trees=0)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/5OwCw.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/5OwCw.png\" alt=\"enter image description here\"></a></p>\n\n<p>It shows the tree structure following which the model you trained made its decisions.</p>\n\n<p>You can also see the importance of each feature in the dataset with respect to the model:</p>\n\n<pre><code>xgboost.plot_importance(xg_reg)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/Rn7qS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Rn7qS.png\" alt=\"enter image description here\"></a></p>\n\n<p>These visualizations are of course not required for making the predictions, but they may sometimes give you useful insights about your predictions.</p>\n<p>We should not use time series concept here. You have to do a pair plot analysis to find your best predictor. I do not think index column is much useful here. I feel length, width or breadth are features if you classify the vehicles as sedan, suv or small car. Not sure if it be of much help in predicting the price. If you add more breadth to the dataset, make sure you have enough depth or training examples</p>\n\n<p>Do a heat map and find the co-relation between the feature and target variable as well. You can remove those features which does not have good co-relation with the target variable.</p>\n\n<p>Try to start with Linear regression model, since you have to predict the price. then move on to more complex models. Random forest regressor is also a good choice for smaller datasets</p>\n",
                "codes": [
                    [
                        "import pandas as pd\n\ndata = pd.read_csv('ex.csv')\ndata\n",
                        "data.describe() # to check the statistical properties of the features, like mean, std dev, etc\n",
                        "for column in data.select_dtypes(include=['object']).columns:\n    display(pd.crosstab(index=data[column], columns='% observations', normalize='columns'))\n",
                        "hist = data.hist(figsize=(10, 10))\n",
                        "data.corr().style.background_gradient()\n",
                        "import seaborn as sns\nsns.heatmap(data.corr(), annot=True)\n",
                        "from sklearn.model_selection import train_test_split\nimport xgboost\nimport numpy as np\n\nX = data.drop(['price'], axis=1) # take all the features except the target variable\ny = data['price'] # the target variable\n",
                        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
                        "X_train.fillna((-999), inplace=True)\nX_test.fillna((-999), inplace=True)\n",
                        "# Some of values are float or integer and some object. This is why we need to cast them:\nfrom sklearn import preprocessing \nfor f in X_train.columns: \n    if X_train[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder() \n        lbl.fit(list(X_train[f].values)) \n        X_train[f] = lbl.transform(list(X_train[f].values))\n\nfor f in X_test.columns: \n    if X_test[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder() \n        lbl.fit(list(X_test[f].values)) \n        X_test[f] = lbl.transform(list(X_test[f].values))\n\n\nX_train=np.array(X_train) \nX_test=np.array(X_test) \nX_train = X_train.astype(float) \nX_test = X_test.astype(float)\n\nd_train = xgboost.DMatrix(X_train, label=y_train, feature_names=list(X))\nd_test = xgboost.DMatrix(X_test, label=y_test, feature_names=list(X))\n",
                        "params = {\n    \"eta\": 0.01, # something called the learning rate - read up about optimization and gradient descent to understand more about this\n    \"subsample\": 0.5,\n    \"base_score\": np.mean(y_train)\n}\n\n# these params are optional - if you don't feed the train function below with the params, it will take the default values\n\nmodel = xgboost.train(params, d_train, 5000, evals = [(d_test, \"test\")], verbose_eval=100, early_stopping_rounds=50)\n",
                        "[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[0] test-rmse:2275\nWill train until test-rmse hasn't improved in 50 rounds.\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\nStopping. Best iteration:\n[0] test-rmse:1571.88\n",
                        "xg_reg = xgboost.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 5, alpha = 10, n_estimators = 10)\n\nxg_reg.fit(X_train,y_train)\n\npreds = xg_reg.predict(X_test) \nprint(preds) # these are the predicted prices for the test data\n>>> array([2293.7073, 2891.9692, 3822.3757], dtype=float32)\n",
                        "from sklearn.metrics import mean_squared_error\n\nrmse = np.sqrt(mean_squared_error(y_test, preds))\nprint(\"RMSE: %f\" % (rmse))\n>>> RMSE: 1542.541395\n",
                        "params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n                'max_depth': 5, 'alpha': 10}\n\ncv_results = xgboost.cv(dtrain=d_train, params=params, nfold=3,\n                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True)\n",
                        "[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
                        "print(cv_results)\n",
                        "import matplotlib.pyplot as plt\n\nxgboost.plot_tree(xg_reg,num_trees=0)\nplt.show()\n",
                        "xgboost.plot_importance(xg_reg)\nplt.show()\n"
                    ],
                    []
                ],
                "question_id:": "40840",
                "question_votes:": "1",
                "question_text:": "<p>I have to find make a classifier for price prediction of a item. The question I have is which columns I should choose for price prediction.</p>\n\n<p>Also which machine learning classifier would be good to perform this, at present I choose random forest. </p>\n\n<p>Do I need to use time series concept in here?, I think No</p>\n",
                "tags": "<classification><regression><prediction>",
                "answers": [
                    [
                        "40852",
                        "2",
                        "40840",
                        "",
                        "",
                        "<p>So firstly, what do you mean by \"classifier for price prediction\"? You can predict the price as a number, that would like be different for different cars, but if you want to predict a class of price (like, high, low and medium for instance), you would need a column for that (and you can ignore the column for price, as you are not predicting the price, you're predicting the price class).</p>\n\n<p><strong>Stage 1. Pre-processing the data</strong></p>\n\n<p>Assuming you have the column in the dataset which you want to predict for, you first want to do feature selection. That is, not all features in the data would be important or relevant for predicting the price. For example, in your dataset, the first column/feature (\"index\") is irrelevant for the price of the car. But how do we prove that? Or, how do we computationally select them (using some measure), especially when they're not as trivial as \"index\"?</p>\n\n<p>We generally check the statistical properties of the features for that. I copied the data you provided in the question, and here's some things for you to start with:</p>\n\n<pre><code>import pandas as pd\n\ndata = pd.read_csv('ex.csv')\ndata\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/llRbm.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/llRbm.png\" alt=\"enter image description here\"></a></p>\n\n<pre><code>data.describe() # to check the statistical properties of the features, like mean, std dev, etc\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/zln51.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zln51.png\" alt=\"enter image description here\"></a></p>\n\n<p>Then, you could do a simple percentage count of the unique observations in each feature, and maybe you could get some insight about the features that way:</p>\n\n<pre><code>for column in data.select_dtypes(include=['object']).columns:\n    display(pd.crosstab(index=data[column], columns='% observations', normalize='columns'))\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/zJDqM.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zJDqM.png\" alt=\"enter image description here\"></a></p>\n\n<p>Then you could do a histogram analysis of the features and hopefully that gives you some more insight. For example, assuming you have sufficiently enough data, you'd normally expect the histogram of a feature to follow the normal or gaussian distribution. But if its doesn't, then you can further drill down into those features to understand why, and that might lead you to keep or discard those features from the model you're going to build.</p>\n\n<pre><code>hist = data.hist(figsize=(10, 10))\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/ko9D4.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ko9D4.png\" alt=\"enter image description here\"></a></p>\n\n<p>Then we can do correlation analysis of the features:</p>\n\n<pre><code>data.corr().style.background_gradient()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/sfY0P.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/sfY0P.png\" alt=\"enter image description here\"></a></p>\n\n<p>Or, if you want a more fancy visualization:</p>\n\n<pre><code>import seaborn as sns\nsns.heatmap(data.corr(), annot=True)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/afk32.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/afk32.png\" alt=\"enter image description here\"></a></p>\n\n<p>After doing all these, hopefully you have figured out which features to discard and which to keep for your model. These are of course \"manual\" methods of feature selection; there are other more complex methods for feature selection like SHAPLEY values, etc, which you can explore.</p>\n\n<p><strong>Stage 2 - Building a model and training it</strong></p>\n\n<p>Firstly, you need to pick a technique/method using which you want to do the prediction. The simplest one, since you have only one target variable (i.e., only one feature you're predicting, which is the price or the price class), the simplest one would be linear regression, and the most complicated ones would be some deep learning model build with CNN or RNN. So, instead of showing you how to make predictions with the simplest one, i.e., linear regression, let me show you a middle-of-the-road algorithm in terms of complexity which is quite popular and a widely used method in many machine learning tasks, the accelerated gradient boost, or xgboost, algorithm.</p>\n\n<p>We need to import some libraries for this:</p>\n\n<pre><code>from sklearn.model_selection import train_test_split\nimport xgboost\nimport numpy as np\n\nX = data.drop(['price'], axis=1) # take all the features except the target variable\ny = data['price'] # the target variable\n</code></pre>\n\n<p>Then, we create a train/test split with 80-20 split randomly. That is, we randomly take 80% data for training and 20% for testing:</p>\n\n<pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n</code></pre>\n\n<p>You can of course do a 70-30 split if you want, and definitely try out different splits at both ends of the spectrum to see what happens - that way you'll learn more about why a 70-30 or 80-20 split is good and, say, a 50-50 split is not that good.</p>\n\n<p>Then, if there are missing values in your data, fill them with a high negative value so that it doesn't have any impact in the model. You can also choose to fill them with something else, depending on your goal.</p>\n\n<pre><code>X_train.fillna((-999), inplace=True)\nX_test.fillna((-999), inplace=True)\n</code></pre>\n\n<p>Some more preprocessing steps:</p>\n\n<pre><code># Some of values are float or integer and some object. This is why we need to cast them:\nfrom sklearn import preprocessing \nfor f in X_train.columns: \n    if X_train[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder() \n        lbl.fit(list(X_train[f].values)) \n        X_train[f] = lbl.transform(list(X_train[f].values))\n\nfor f in X_test.columns: \n    if X_test[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder() \n        lbl.fit(list(X_test[f].values)) \n        X_test[f] = lbl.transform(list(X_test[f].values))\n\n\nX_train=np.array(X_train) \nX_test=np.array(X_test) \nX_train = X_train.astype(float) \nX_test = X_test.astype(float)\n\nd_train = xgboost.DMatrix(X_train, label=y_train, feature_names=list(X))\nd_test = xgboost.DMatrix(X_test, label=y_test, feature_names=list(X))\n</code></pre>\n\n<p>Finally, we can make our model and train it:</p>\n\n<pre><code>params = {\n    \"eta\": 0.01, # something called the learning rate - read up about optimization and gradient descent to understand more about this\n    \"subsample\": 0.5,\n    \"base_score\": np.mean(y_train)\n}\n\n# these params are optional - if you don't feed the train function below with the params, it will take the default values\n\nmodel = xgboost.train(params, d_train, 5000, evals = [(d_test, \"test\")], verbose_eval=100, early_stopping_rounds=50)\n</code></pre>\n\n<p>You can check the root mean square error (RMSE) that this function returns at the end to see how good or bad the training has been (low RMSE is good, high RMSE is bad - but there's no max RMSE value, it can be arbitrarily high). There are other methods to check the error, and you can explore them (like MAE, etc), but this is probably the simplest one. Anyway, the above code will return something like this:</p>\n\n<pre><code>[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[0] test-rmse:2275\nWill train until test-rmse hasn't improved in 50 rounds.\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[16:56:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\nStopping. Best iteration:\n[0] test-rmse:1571.88\n</code></pre>\n\n<p>It ran the algo iteratively 5000 times, printing out the result every 100 lines (that's what those numbers are in the train method). To see what each of the parameters mean, you can read <a href=\"https://xgboost.readthedocs.io/en/latest/parameter.html#general-parameters\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<p>You can also use linear regression, if you want, with xgboost, like so:</p>\n\n<pre><code>xg_reg = xgboost.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 5, alpha = 10, n_estimators = 10)\n\nxg_reg.fit(X_train,y_train)\n\npreds = xg_reg.predict(X_test) \nprint(preds) # these are the predicted prices for the test data\n&gt;&gt;&gt; array([2293.7073, 2891.9692, 3822.3757], dtype=float32)\n</code></pre>\n\n<p>And we can check the RMSE like so:</p>\n\n<pre><code>from sklearn.metrics import mean_squared_error\n\nrmse = np.sqrt(mean_squared_error(y_test, preds))\nprint(\"RMSE: %f\" % (rmse))\n&gt;&gt;&gt; RMSE: 1542.541395\n</code></pre>\n\n<p>Note that RMSE in the 2 methods is quite close (1571.88 vs 1542.54). This is like a sanity check for us that no matter which method we use, if we use it correctly, we should get similar results.</p>\n\n<p><strong>Stage 3 - testing and evaluation of the model - k-fold Cross Validation</strong></p>\n\n<p>Finally its time to see how our model performs on test data:</p>\n\n<pre><code>params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n                'max_depth': 5, 'alpha': 10}\n\ncv_results = xgboost.cv(dtrain=d_train, params=params, nfold=3,\n                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True)\n</code></pre>\n\n<p>This will again give you quite a few lines of output like when training:</p>\n\n<pre><code>[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[17:38:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n</code></pre>\n\n<p>This is how it looks in each of the rounds of the boosting:</p>\n\n<pre><code>print(cv_results)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/WP6Zs.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WP6Zs.png\" alt=\"enter image description here\"></a></p>\n\n<p>So, that's it. We have the predicted values.</p>\n\n<p><strong>P.S. Stage 2.5 - Visualizing the model (Optional)</strong></p>\n\n<p>Did you know that we can also visualize the model?</p>\n\n<pre><code>import matplotlib.pyplot as plt\n\nxgboost.plot_tree(xg_reg,num_trees=0)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/5OwCw.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/5OwCw.png\" alt=\"enter image description here\"></a></p>\n\n<p>It shows the tree structure following which the model you trained made its decisions.</p>\n\n<p>You can also see the importance of each feature in the dataset with respect to the model:</p>\n\n<pre><code>xgboost.plot_importance(xg_reg)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/Rn7qS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Rn7qS.png\" alt=\"enter image description here\"></a></p>\n\n<p>These visualizations are of course not required for making the predictions, but they may sometimes give you useful insights about your predictions.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "40850",
                        "2",
                        "40840",
                        "",
                        "",
                        "<p>We should not use time series concept here. You have to do a pair plot analysis to find your best predictor. I do not think index column is much useful here. I feel length, width or breadth are features if you classify the vehicles as sedan, suv or small car. Not sure if it be of much help in predicting the price. If you add more breadth to the dataset, make sure you have enough depth or training examples</p>\n\n<p>Do a heat map and find the co-relation between the feature and target variable as well. You can remove those features which does not have good co-relation with the target variable.</p>\n\n<p>Try to start with Linear regression model, since you have to predict the price. then move on to more complex models. Random forest regressor is also a good choice for smaller datasets</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "690",
            "_score": 6.390276,
            "_source": {
                "title": "strings as features in decision tree/random forest",
                "content": "strings as features in decision tree/random forest <p>I am new to <a href=\"https://en.wikipedia.org/wiki/Machine_learning\" rel=\"noreferrer\">machine learning</a>!</p>\n\n<p>Right now I am doing some problems on an application of decision tree/random forest. I am trying to fit a problem which has numbers as well as strings (such as country name) as features. Now the library, <a href=\"http://scikit-learn.org\" rel=\"noreferrer\">scikit-learn</a> takes only numbers as parameters, but I want to inject the strings as well as they carry a significant amount of knowledge.</p>\n\n<p>How do I handle such a scenario?</p>\n\n<p>I can convert a string to numbers by some mechanism such as hashing in python. But I would like to know the best practice on how strings are handled in decision tree problems.</p>\n\n<p>Thanks for your support!</p>\n <machine-learning><python><scikit-learn><random-forest><decision-trees><p>You need to encode your strings as numeric features that sci-kit can use for the ML algorithms. This functionality is handled in the preprocessing module (e.g.,  see <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder\" rel=\"noreferrer\">sklearn.preprocessing.LabelEncoder</a> for an example).</p>\n<p>Turn them to numbers, for example for each unique country assingn a unique number (like 1,2,3 and ...) </p>\n\n<p>also you <strong>Don't</strong> need to use <strong>One-Hot Encoding</strong> (aka dummy variables) when working with random forest, because trees don't work like other algorithm (such as linear/logistic regression) and they don't work by distant (they work with finding good split for your features) so <strong>NO NEED</strong> for One-Hot Encoding</p>\n<p>You can use dummy variables in such scenarios. With panda's <code>panda.get_dummies</code> you can create dummy variables for strings you want to put in Decision Tree or Random Forest.</p>\n\n<p><strong>Example:</strong></p>\n\n<pre><code>import pandas as pd\nd = {'one' : pd.Series([1., 2., 3.,4.], index=['a', 'b', 'c','d']),'two' :pd.Series(['Paul', 'John', 'Micheal','George'], index=['a', 'b', 'c', 'd'])}\ndf = pd.DataFrame(d)\n\ndf_with_dummies= pd.get_dummies(df,columns=[\"two\"],drop_first=False)\ndf_with_dummies\n</code></pre>\n<p>In most of the well-established machine learning systems, categorical variables are handled naturally. For example in R you would use factors, in WEKA you would use nominal variables. This is not the case in scikit-learn. The decision trees implemented in scikit-learn uses only numerical features and these features are interpreted always as <strong>continuous numeric variables</strong>. </p>\n\n<p>Thus, simply replacing the strings with a hash code should be avoided, because being considered as a continuous numerical feature any coding you will use will induce an order which simply does not exist in your data. </p>\n\n<p>One example is to code ['red','green','blue'] with [1,2,3], would produce weird things like 'red' is lower than 'blue', and if you average a 'red' and a 'blue' you will get a 'green'. Another more subtle example might happen when you code ['low', 'medium', 'high'] with [1,2,3]. In the latter case it might happen to have an ordering which makes sense, however, some subtle inconsistencies might happen when 'medium' in not in the middle of 'low' and 'high'.</p>\n\n<p>Finally, the answer to your question lies in coding the categorical feature into <strong>multiple binary features</strong>. For example, you might code ['red','green','blue'] with 3 columns, one for each category, having 1 when the category match and 0 otherwise. This is called <strong>one-hot-encoding</strong>, binary encoding, one-of-k-encoding or whatever. You can check documentation here for <a href=\"http://scikit-learn.org/stable/modules/preprocessing.html\" rel=\"noreferrer\">encoding categorical features</a> and <a href=\"http://scikit-learn.org/stable/modules/feature_extraction.html#dict-feature-extraction\" rel=\"noreferrer\">feature extraction - hashing and dicts</a>. Obviously one-hot-encoding will expand your space requirements and sometimes it hurts the performance as well. </p>\n<p><strong>2018 Update!</strong></p>\n\n<p>You can create an embedding (dense vector) space for your categorical variables.  Many of you are familiar with word2vec and fastext, which embed words in a meaningful dense vector space.  Same idea here-- your categorical variables will map to a vector with some meaning.</p>\n\n<p>From the <a href=\"https://arxiv.org/abs/1604.06737\" rel=\"nofollow noreferrer\">Guo/Berkhahn paper</a>:</p>\n\n<blockquote>\n  <p>Entity embedding not only reduces memory usage and speeds up neural\n  networks compared with one-hot encoding, but more importantly by\n  mapping similar values close to each other in the embedding space it\n  reveals the intrinsic properties of the categorical variables. We\n  applied it successfully in a recent Kaggle competition and were able\n  to reach the third position with relative simple features.</p>\n</blockquote>\n\n<p>The authors found that representing categorical variables this way improved the effectiveness of all machine learning algorithms tested, including random forest.</p>\n\n<p>The best example might be <a href=\"https://medium.com/the-graph/applying-deep-learning-to-related-pins-a6fee3c92f5e\" rel=\"nofollow noreferrer\">Pinterest's application of the technique</a> to group related Pins:</p>\n\n<p><a href=\"https://i.stack.imgur.com/365pZ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/365pZ.png\" alt=\"enter image description here\"></a></p>\n\n<p>The folks at fastai have implemented categorical embeddings and created a very nice <a href=\"http://www.fast.ai/2018/04/29/categorical-embeddings/\" rel=\"nofollow noreferrer\">blog post</a> with companion <a href=\"https://github.com/fastai/fastai/blob/master/courses/dl1/lesson3-rossman.ipynb\" rel=\"nofollow noreferrer\">demo notebook</a>.</p>\n\n<p><strong>Additional Details and Explanation</strong></p>\n\n<p>A neural net is used to create the embeddings i.e. assign a vector to each categorical value. Once you have the vectors, you may use them in any model which accepts numerical values. Each component of vector becomes an input variable. For example, if you used 3-D vectors to embed your categorical list of colors, you might get something like: red=(0, 1.5, -2.3), blue=(1, 1, 0) etc. You would use three input variables in your random forest corresponding to the three components. For red things, c1=0, c2=1.5, and c3=-2.3. For blue things, c1=1, c2=1, and c3=0.</p>\n\n<p>You don't actually <strong>need</strong> to use a neural network to create embeddings (although I don't recommend shying away from the technique).  You're free to create your own embeddings by hand or other means, when possible.  Some examples:</p>\n\n<ol>\n<li>Map colors to RGB vectors.</li>\n<li>Map locations to lat/long vectors.</li>\n<li>In a U.S. political model, map cities to some vector components representing left/right alignment, tax burden, etc.</li>\n</ol>\n<p>You should usually <a href=\"https://en.wikipedia.org/wiki/One-hot\" rel=\"nofollow noreferrer\">one-hot encode</a> categorical variables for scikit-learn models, including random forest. Random forest will often work ok without one-hot encoding but usually performs better if you do one-hot encode. One-hot encoding and \"dummying\" variables mean the same thing in this context. Scikit-learn has <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" rel=\"nofollow noreferrer\">sklearn.preprocessing.OneHotEncoder</a> and Pandas has <a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html\" rel=\"nofollow noreferrer\">pandas.get_dummies</a> to accomplish this.</p>\n\n<p>However, there are alternatives. The article <a href=\"http://www.kdnuggets.com/2015/12/beyond-one-hot-exploration-categorical-variables.html\" rel=\"nofollow noreferrer\">\"Beyond One-Hot\" at KDnuggets</a> does a great job of explaining why you need to encode categorical variables and alternatives to one-hot encoding.</p>\n\n<p>There are alternative implementations of random forest that do not require one-hot encoding such as R or H2O. The implementation in R is <a href=\"https://stats.stackexchange.com/questions/49243/rs-randomforest-can-not-handle-more-than-32-levels-what-is-workaround/96442#96442\">computationally expensive</a> and <a href=\"https://stats.stackexchange.com/questions/49243/rs-randomforest-can-not-handle-more-than-32-levels-what-is-workaround\">will not work if your features have many categories</a>. H2O will work with large numbers of categories. Continuum has made <a href=\"https://www.continuum.io/blog/developer-blog/using-anaconda-h2o-supercharge-machine-learning-predictive-analytics\" rel=\"nofollow noreferrer\">H2O available in Anaconda Python.</a> </p>\n\n<p>There is an <a href=\"https://github.com/scikit-learn/scikit-learn/pull/3346\" rel=\"nofollow noreferrer\">ongoing effort to make scikit-learn handle categorical features directly</a>.</p>\n\n<p><a href=\"http://blog.revolutionanalytics.com/2013/07/rxdtree-a-new-type-of-tree-algorithm.html\" rel=\"nofollow noreferrer\">This article</a> has an explanation of the algorithm used in H2O. It references the academic paper <a href=\"http://jmlr.org/papers/volume11/ben-haim10a/ben-haim10a.pdf\" rel=\"nofollow noreferrer\">A Streaming Parallel Decision Tree Algorithm</a> and a <a href=\"http://largescale.ml.tu-berlin.de/media/abstracts/73_Ben-Haim_Parallel_Decision_Tree.pdf\" rel=\"nofollow noreferrer\">longer version</a> of the same paper.</p>\n",
                "codes": [
                    [],
                    [],
                    [
                        "import pandas as pd\nd = {'one' : pd.Series([1., 2., 3.,4.], index=['a', 'b', 'c','d']),'two' :pd.Series(['Paul', 'John', 'Micheal','George'], index=['a', 'b', 'c', 'd'])}\ndf = pd.DataFrame(d)\n\ndf_with_dummies= pd.get_dummies(df,columns=[\"two\"],drop_first=False)\ndf_with_dummies\n"
                    ],
                    [],
                    [],
                    []
                ],
                "question_id:": "5226",
                "question_votes:": "59",
                "question_text:": "<p>I am new to <a href=\"https://en.wikipedia.org/wiki/Machine_learning\" rel=\"noreferrer\">machine learning</a>!</p>\n\n<p>Right now I am doing some problems on an application of decision tree/random forest. I am trying to fit a problem which has numbers as well as strings (such as country name) as features. Now the library, <a href=\"http://scikit-learn.org\" rel=\"noreferrer\">scikit-learn</a> takes only numbers as parameters, but I want to inject the strings as well as they carry a significant amount of knowledge.</p>\n\n<p>How do I handle such a scenario?</p>\n\n<p>I can convert a string to numbers by some mechanism such as hashing in python. But I would like to know the best practice on how strings are handled in decision tree problems.</p>\n\n<p>Thanks for your support!</p>\n",
                "tags": "<machine-learning><python><scikit-learn><random-forest><decision-trees>",
                "answers": [
                    [
                        "8433",
                        "2",
                        "5226",
                        "",
                        "",
                        "<p>You need to encode your strings as numeric features that sci-kit can use for the ML algorithms. This functionality is handled in the preprocessing module (e.g.,  see <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder\" rel=\"noreferrer\">sklearn.preprocessing.LabelEncoder</a> for an example).</p>\n",
                        "",
                        "12"
                    ],
                    [
                        "29706",
                        "2",
                        "5226",
                        "",
                        "",
                        "<p>Turn them to numbers, for example for each unique country assingn a unique number (like 1,2,3 and ...) </p>\n\n<p>also you <strong>Don't</strong> need to use <strong>One-Hot Encoding</strong> (aka dummy variables) when working with random forest, because trees don't work like other algorithm (such as linear/logistic regression) and they don't work by distant (they work with finding good split for your features) so <strong>NO NEED</strong> for One-Hot Encoding</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "19829",
                        "2",
                        "5226",
                        "",
                        "",
                        "<p>You can use dummy variables in such scenarios. With panda's <code>panda.get_dummies</code> you can create dummy variables for strings you want to put in Decision Tree or Random Forest.</p>\n\n<p><strong>Example:</strong></p>\n\n<pre><code>import pandas as pd\nd = {'one' : pd.Series([1., 2., 3.,4.], index=['a', 'b', 'c','d']),'two' :pd.Series(['Paul', 'John', 'Micheal','George'], index=['a', 'b', 'c', 'd'])}\ndf = pd.DataFrame(d)\n\ndf_with_dummies= pd.get_dummies(df,columns=[\"two\"],drop_first=False)\ndf_with_dummies\n</code></pre>\n",
                        "",
                        "3"
                    ],
                    [
                        "5229",
                        "2",
                        "5226",
                        "",
                        "",
                        "<p>In most of the well-established machine learning systems, categorical variables are handled naturally. For example in R you would use factors, in WEKA you would use nominal variables. This is not the case in scikit-learn. The decision trees implemented in scikit-learn uses only numerical features and these features are interpreted always as <strong>continuous numeric variables</strong>. </p>\n\n<p>Thus, simply replacing the strings with a hash code should be avoided, because being considered as a continuous numerical feature any coding you will use will induce an order which simply does not exist in your data. </p>\n\n<p>One example is to code ['red','green','blue'] with [1,2,3], would produce weird things like 'red' is lower than 'blue', and if you average a 'red' and a 'blue' you will get a 'green'. Another more subtle example might happen when you code ['low', 'medium', 'high'] with [1,2,3]. In the latter case it might happen to have an ordering which makes sense, however, some subtle inconsistencies might happen when 'medium' in not in the middle of 'low' and 'high'.</p>\n\n<p>Finally, the answer to your question lies in coding the categorical feature into <strong>multiple binary features</strong>. For example, you might code ['red','green','blue'] with 3 columns, one for each category, having 1 when the category match and 0 otherwise. This is called <strong>one-hot-encoding</strong>, binary encoding, one-of-k-encoding or whatever. You can check documentation here for <a href=\"http://scikit-learn.org/stable/modules/preprocessing.html\" rel=\"noreferrer\">encoding categorical features</a> and <a href=\"http://scikit-learn.org/stable/modules/feature_extraction.html#dict-feature-extraction\" rel=\"noreferrer\">feature extraction - hashing and dicts</a>. Obviously one-hot-encoding will expand your space requirements and sometimes it hurts the performance as well. </p>\n",
                        "",
                        "54"
                    ],
                    [
                        "31997",
                        "2",
                        "5226",
                        "",
                        "",
                        "<p><strong>2018 Update!</strong></p>\n\n<p>You can create an embedding (dense vector) space for your categorical variables.  Many of you are familiar with word2vec and fastext, which embed words in a meaningful dense vector space.  Same idea here-- your categorical variables will map to a vector with some meaning.</p>\n\n<p>From the <a href=\"https://arxiv.org/abs/1604.06737\" rel=\"nofollow noreferrer\">Guo/Berkhahn paper</a>:</p>\n\n<blockquote>\n  <p>Entity embedding not only reduces memory usage and speeds up neural\n  networks compared with one-hot encoding, but more importantly by\n  mapping similar values close to each other in the embedding space it\n  reveals the intrinsic properties of the categorical variables. We\n  applied it successfully in a recent Kaggle competition and were able\n  to reach the third position with relative simple features.</p>\n</blockquote>\n\n<p>The authors found that representing categorical variables this way improved the effectiveness of all machine learning algorithms tested, including random forest.</p>\n\n<p>The best example might be <a href=\"https://medium.com/the-graph/applying-deep-learning-to-related-pins-a6fee3c92f5e\" rel=\"nofollow noreferrer\">Pinterest's application of the technique</a> to group related Pins:</p>\n\n<p><a href=\"https://i.stack.imgur.com/365pZ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/365pZ.png\" alt=\"enter image description here\"></a></p>\n\n<p>The folks at fastai have implemented categorical embeddings and created a very nice <a href=\"http://www.fast.ai/2018/04/29/categorical-embeddings/\" rel=\"nofollow noreferrer\">blog post</a> with companion <a href=\"https://github.com/fastai/fastai/blob/master/courses/dl1/lesson3-rossman.ipynb\" rel=\"nofollow noreferrer\">demo notebook</a>.</p>\n\n<p><strong>Additional Details and Explanation</strong></p>\n\n<p>A neural net is used to create the embeddings i.e. assign a vector to each categorical value. Once you have the vectors, you may use them in any model which accepts numerical values. Each component of vector becomes an input variable. For example, if you used 3-D vectors to embed your categorical list of colors, you might get something like: red=(0, 1.5, -2.3), blue=(1, 1, 0) etc. You would use three input variables in your random forest corresponding to the three components. For red things, c1=0, c2=1.5, and c3=-2.3. For blue things, c1=1, c2=1, and c3=0.</p>\n\n<p>You don't actually <strong>need</strong> to use a neural network to create embeddings (although I don't recommend shying away from the technique).  You're free to create your own embeddings by hand or other means, when possible.  Some examples:</p>\n\n<ol>\n<li>Map colors to RGB vectors.</li>\n<li>Map locations to lat/long vectors.</li>\n<li>In a U.S. political model, map cities to some vector components representing left/right alignment, tax burden, etc.</li>\n</ol>\n",
                        "",
                        "4"
                    ],
                    [
                        "21983",
                        "2",
                        "5226",
                        "",
                        "",
                        "<p>You should usually <a href=\"https://en.wikipedia.org/wiki/One-hot\" rel=\"nofollow noreferrer\">one-hot encode</a> categorical variables for scikit-learn models, including random forest. Random forest will often work ok without one-hot encoding but usually performs better if you do one-hot encode. One-hot encoding and \"dummying\" variables mean the same thing in this context. Scikit-learn has <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" rel=\"nofollow noreferrer\">sklearn.preprocessing.OneHotEncoder</a> and Pandas has <a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html\" rel=\"nofollow noreferrer\">pandas.get_dummies</a> to accomplish this.</p>\n\n<p>However, there are alternatives. The article <a href=\"http://www.kdnuggets.com/2015/12/beyond-one-hot-exploration-categorical-variables.html\" rel=\"nofollow noreferrer\">\"Beyond One-Hot\" at KDnuggets</a> does a great job of explaining why you need to encode categorical variables and alternatives to one-hot encoding.</p>\n\n<p>There are alternative implementations of random forest that do not require one-hot encoding such as R or H2O. The implementation in R is <a href=\"https://stats.stackexchange.com/questions/49243/rs-randomforest-can-not-handle-more-than-32-levels-what-is-workaround/96442#96442\">computationally expensive</a> and <a href=\"https://stats.stackexchange.com/questions/49243/rs-randomforest-can-not-handle-more-than-32-levels-what-is-workaround\">will not work if your features have many categories</a>. H2O will work with large numbers of categories. Continuum has made <a href=\"https://www.continuum.io/blog/developer-blog/using-anaconda-h2o-supercharge-machine-learning-predictive-analytics\" rel=\"nofollow noreferrer\">H2O available in Anaconda Python.</a> </p>\n\n<p>There is an <a href=\"https://github.com/scikit-learn/scikit-learn/pull/3346\" rel=\"nofollow noreferrer\">ongoing effort to make scikit-learn handle categorical features directly</a>.</p>\n\n<p><a href=\"http://blog.revolutionanalytics.com/2013/07/rxdtree-a-new-type-of-tree-algorithm.html\" rel=\"nofollow noreferrer\">This article</a> has an explanation of the algorithm used in H2O. It references the academic paper <a href=\"http://jmlr.org/papers/volume11/ben-haim10a/ben-haim10a.pdf\" rel=\"nofollow noreferrer\">A Streaming Parallel Decision Tree Algorithm</a> and a <a href=\"http://largescale.ml.tu-berlin.de/media/abstracts/73_Ben-Haim_Parallel_Decision_Tree.pdf\" rel=\"nofollow noreferrer\">longer version</a> of the same paper.</p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4974",
            "_score": 6.3108087,
            "_source": {
                "title": "Using time series data from a sensor for ML",
                "content": "Using time series data from a sensor for ML <p>I have the following data for a little side project. It's from an accelerometer sitting on top of a washer/dryer and I'd like it to tell me when the machine has finished.</p>\n\n<p><a href=\"https://i.stack.imgur.com/BRIO1.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/BRIO1.png\" alt=\"data\"></a></p>\n\n<p>x is the input data (x/y/z movement as one value), y is the label on/off</p>\n\n<p>Because the x values overlap for y=1 and y=0, I was thinking of using x and a rolling 3 minute window as inputs for a SVM:</p>\n\n<pre><code>xyz60=res.xyz.resample(\"60S\").max()\nX[\"x\"]=xyz60\nX[\"max3\"]=xyz60.rolling(window=3, min_periods=1).max()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/VD3T4.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/VD3T4.png\" alt=\"data\"></a></p>\n\n<p>Is this a good approach for this kind of problem? Are there alternatives that might produce better results?</p>\n <machine-learning><time-series><feature-engineering><p>You have time series data which is used to measure the acceleration. You which to identify when the machine is in its nominal state (OFF) and anomalous state (ON). This problem would be best solved using anomaly detection algorithms. But, there are so many ways that you can approach this problem. </p>\n\n<h2>Preparing you data</h2>\n\n<p>All of the methods will rely on the feature extraction method you select. Assuming we continue to use the 3 sample time window as you suggested. In this algorithm you will calculate a statistic for this nominal state $y = 0$. I would suggest the mean as I assume you are already doing, take the average of the three sample resultant accelerations. You will then be left with a large number of values in a training set $S$ defined as</p>\n\n<p>$S = \\{s_0, s_1, ..., s_n \\}$</p>\n\n<p>where $s$ is the mean of the tree samples in a window. $s$ is defined as </p>\n\n<p>$s_i = \\frac{1}{3} \\sum_{k=i-2}^{i} x_k$</p>\n\n<p>where $x$ is your sample observations and $i\\geq2$.</p>\n\n<p>Then collect more data if it is possible with the machine active such that $y = 1$.</p>\n\n<p>Now you can choose if you want to train your algorithm on a one-class dataset (pure anomlay detection). A biased dataset (anomaly detection) or a well-balanced dataset. The balance of the dataset is the ratio between the two classes in your dataset. A perfect dataset for a 2-class classifier would be 1:1. 50% of the data belonging to each class. You seem to have a biased dataset, assuming you don't want to waste a lot of electricity. </p>\n\n<p>Do note that there is nothing stopping you from keeping the neighboring samples split as an instance in your dataset. For example:</p>\n\n<p>$x_i$ $x_{i-1}$ $x_{i-2}$ | $y_i$</p>\n\n<p>This would make a 3-dimensional input space for a specific output which is defined for the currently taken sample.</p>\n\n<hr>\n\n<h2><strong>A Biased Dataset</strong></h2>\n\n<hr>\n\n<p><strong>Easy Solution</strong></p>\n\n<p>The easiest way that i would suggest. Assume you are using a single statistic to define what is happening throughout the 3 sample window. From the collected data get the maximum $s$ of your nominal points ($y=0$) and the minimum $s$ of your anomalous points ($y=1$). Then take the halfway mark between these two and use that as your threshold.</p>\n\n<p>If a new test sample $\\hat{s}$ is larger than the threshold then assign $y=1$.</p>\n\n<p>You can extend this by calculating the mean $s$ for all of your nominal samples $y=0$. Then calculate the mean for your anomalous samples $y=1$. If a new sample falls closer to the mean of the anomalous samples then classify it as $y=1$. </p>\n\n<p><strong>But I want to get fancy!</strong></p>\n\n<p>There are a number of other techniques you can use to do this exact task.</p>\n\n<ul>\n<li>k-Nearest Neighbors</li>\n<li>Neural Networks</li>\n<li>Linear Regression</li>\n<li>SVM</li>\n</ul>\n\n<p>Simply put, almost every machine learning algorithm is well suited for this purpose. It just depends on how much data is available to you and it's distribution. </p>\n\n<hr>\n\n<h2><strong>I really want to use SVM</strong></h2>\n\n<hr>\n\n<p>If this is the case keep the three samples completely separated. Your training matrix will have 3 columns as discussed above. And then you will have your outputs $y$. Using SVM in python is very easy: <a href=\"http://scikit-learn.org/stable/modules/svm.html\" rel=\"noreferrer\">http://scikit-learn.org/stable/modules/svm.html</a>.</p>\n\n<pre><code>from sklearn import svm\n\nX = [[0, 0, 0], [1, 1, 1], ..., [1, 0, 1]] \ny = [0, 1, ..., 1]\nclf = svm.SVC()\nclf.fit(X, y)  \n</code></pre>\n\n<p>This trains your model. Then you will want to predict the outcome for a new sample. </p>\n\n<pre><code>clf.predict([[2., 2., 1]])\n</code></pre>\n",
                "codes": [
                    [
                        "from sklearn import svm\n\nX = [[0, 0, 0], [1, 1, 1], ..., [1, 0, 1]] \ny = [0, 1, ..., 1]\nclf = svm.SVC()\nclf.fit(X, y)  \n",
                        "clf.predict([[2., 2., 1]])\n"
                    ]
                ],
                "question_id:": "19392",
                "question_votes:": "7",
                "question_text:": "<p>I have the following data for a little side project. It's from an accelerometer sitting on top of a washer/dryer and I'd like it to tell me when the machine has finished.</p>\n\n<p><a href=\"https://i.stack.imgur.com/BRIO1.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/BRIO1.png\" alt=\"data\"></a></p>\n\n<p>x is the input data (x/y/z movement as one value), y is the label on/off</p>\n\n<p>Because the x values overlap for y=1 and y=0, I was thinking of using x and a rolling 3 minute window as inputs for a SVM:</p>\n\n<pre><code>xyz60=res.xyz.resample(\"60S\").max()\nX[\"x\"]=xyz60\nX[\"max3\"]=xyz60.rolling(window=3, min_periods=1).max()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/VD3T4.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/VD3T4.png\" alt=\"data\"></a></p>\n\n<p>Is this a good approach for this kind of problem? Are there alternatives that might produce better results?</p>\n",
                "tags": "<machine-learning><time-series><feature-engineering>",
                "answers": [
                    [
                        "19394",
                        "2",
                        "19392",
                        "",
                        "",
                        "<p>You have time series data which is used to measure the acceleration. You which to identify when the machine is in its nominal state (OFF) and anomalous state (ON). This problem would be best solved using anomaly detection algorithms. But, there are so many ways that you can approach this problem. </p>\n\n<h2>Preparing you data</h2>\n\n<p>All of the methods will rely on the feature extraction method you select. Assuming we continue to use the 3 sample time window as you suggested. In this algorithm you will calculate a statistic for this nominal state $y = 0$. I would suggest the mean as I assume you are already doing, take the average of the three sample resultant accelerations. You will then be left with a large number of values in a training set $S$ defined as</p>\n\n<p>$S = \\{s_0, s_1, ..., s_n \\}$</p>\n\n<p>where $s$ is the mean of the tree samples in a window. $s$ is defined as </p>\n\n<p>$s_i = \\frac{1}{3} \\sum_{k=i-2}^{i} x_k$</p>\n\n<p>where $x$ is your sample observations and $i\\geq2$.</p>\n\n<p>Then collect more data if it is possible with the machine active such that $y = 1$.</p>\n\n<p>Now you can choose if you want to train your algorithm on a one-class dataset (pure anomlay detection). A biased dataset (anomaly detection) or a well-balanced dataset. The balance of the dataset is the ratio between the two classes in your dataset. A perfect dataset for a 2-class classifier would be 1:1. 50% of the data belonging to each class. You seem to have a biased dataset, assuming you don't want to waste a lot of electricity. </p>\n\n<p>Do note that there is nothing stopping you from keeping the neighboring samples split as an instance in your dataset. For example:</p>\n\n<p>$x_i$ $x_{i-1}$ $x_{i-2}$ | $y_i$</p>\n\n<p>This would make a 3-dimensional input space for a specific output which is defined for the currently taken sample.</p>\n\n<hr>\n\n<h2><strong>A Biased Dataset</strong></h2>\n\n<hr>\n\n<p><strong>Easy Solution</strong></p>\n\n<p>The easiest way that i would suggest. Assume you are using a single statistic to define what is happening throughout the 3 sample window. From the collected data get the maximum $s$ of your nominal points ($y=0$) and the minimum $s$ of your anomalous points ($y=1$). Then take the halfway mark between these two and use that as your threshold.</p>\n\n<p>If a new test sample $\\hat{s}$ is larger than the threshold then assign $y=1$.</p>\n\n<p>You can extend this by calculating the mean $s$ for all of your nominal samples $y=0$. Then calculate the mean for your anomalous samples $y=1$. If a new sample falls closer to the mean of the anomalous samples then classify it as $y=1$. </p>\n\n<p><strong>But I want to get fancy!</strong></p>\n\n<p>There are a number of other techniques you can use to do this exact task.</p>\n\n<ul>\n<li>k-Nearest Neighbors</li>\n<li>Neural Networks</li>\n<li>Linear Regression</li>\n<li>SVM</li>\n</ul>\n\n<p>Simply put, almost every machine learning algorithm is well suited for this purpose. It just depends on how much data is available to you and it's distribution. </p>\n\n<hr>\n\n<h2><strong>I really want to use SVM</strong></h2>\n\n<hr>\n\n<p>If this is the case keep the three samples completely separated. Your training matrix will have 3 columns as discussed above. And then you will have your outputs $y$. Using SVM in python is very easy: <a href=\"http://scikit-learn.org/stable/modules/svm.html\" rel=\"noreferrer\">http://scikit-learn.org/stable/modules/svm.html</a>.</p>\n\n<pre><code>from sklearn import svm\n\nX = [[0, 0, 0], [1, 1, 1], ..., [1, 0, 1]] \ny = [0, 1, ..., 1]\nclf = svm.SVC()\nclf.fit(X, y)  \n</code></pre>\n\n<p>This trains your model. Then you will want to predict the outcome for a new sample. </p>\n\n<pre><code>clf.predict([[2., 2., 1]])\n</code></pre>\n",
                        "",
                        "6"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "1457",
            "_score": 6.285174,
            "_source": {
                "title": "Trying to understand Logistic Regression Implementation",
                "content": "Trying to understand Logistic Regression Implementation <p>I'm currently using the following code as a starting point to deepen my understanding of regularized logistic regression.  As a first pass I'm just trying to do a binary classification on part of the iris data set.  </p>\n\n<p>One problem I think I have encountered is that the negative log-loss (computed with loss and stored in loss_vec) doesn't change much from one iteration to the next.</p>\n\n<p>Another challenge I am facing is trying to figure out how to plot the decision boundary once I have learned the logistic regression coefficients. Using the coefficients to plot the 0.5 decision boundary is way off.  This makes me think I have made a mistake somewhere</p>\n\n<p><a href=\"http://fa.bianp.net/blog/2013/numerical-optimizers-for-logistic-regression/\" rel=\"noreferrer\">http://fa.bianp.net/blog/2013/numerical-optimizers-for-logistic-regression/</a></p>\n\n\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model, datasets\n\n\niris = datasets.load_iris()\nX = iris.data[:, :2]  # we only take the first two features.\nY = iris.target\n\n\nX = X[:100,:]\nY = Y[:100]\n\ndef phi(t):\n    # logistic function, returns 1 / (1 + exp(-t))\n    idx = t &gt; 0\n    out = np.empty(t.size, dtype=np.float)\n    out[idx] = 1. / (1 + np.exp(-t[idx]))\n    exp_t = np.exp(t[~idx])\n    out[~idx] = exp_t / (1. + exp_t)\n    return out\n\n\ndef loss(x0, X, y, alpha):\n    # logistic loss function, returns Sum{-log(phi(t))}\n    #x0 is the weight vector w are the paramaters, c is the bias term\n    w, c = x0[:X.shape[1]], x0[-1]\n    z = X.dot(w) + c\n    yz = y * z\n    idx = yz &gt; 0\n    out = np.zeros_like(yz)\n    out[idx] = np.log(1 + np.exp(-yz[idx]))\n    out[~idx] = (-yz[~idx] + np.log(1 + np.exp(yz[~idx])))\n    out = out.sum() / X.shape[0] + .5 * alpha * w.dot(w)\n    return out\n\n\ndef gradient(x0, X, y, alpha):\n    # gradient of the logistic loss\n    w, c = x0[:X.shape[1]], x0[-1]\n    z = X.dot(w) + c\n    z = phi(y * z)\n    z0 = (z - 1) * y\n    grad_w = X.T.dot(z0) / X.shape[0] + alpha * w\n    grad_c = z0.sum() / X.shape[0]\n    return np.concatenate((grad_w, [grad_c]))\n\n\ndef bgd(X, y, alpha, max_iter):\n    step_sizes = np.array([100,10,1,.1,.01,.001,.0001,.00001])\n    iter_no = 0\n    x0 = np.random.random(X.shape[1] + 1) #initialize weight vector\n\n    #placeholder for coefficients to test against the loss function\n    next_thetas = np.zeros((step_sizes.shape[0],X.shape[1]+1) )   \n    J = loss(x0,X,y,alpha)\n    running_loss = []\n    while iter_no &lt; max_iter:\n        grad = gradient(x0,X,y,alpha)\n        next_thetas = -(np.outer(step_sizes,grad)-x0)\n        loss_vec = []\n        for i in range(np.shape(next_thetas)[0]):\n            loss_vec.append(loss(next_thetas[i],X,y,alpha))\n        ind = np.argmin(loss_vec)\n        x0 = next_thetas[ind]\n        if iter_no % 500 == 0:\n            running_loss.append(loss(x0,X,y,alpha))\n        iter_no += 1  \n    return next_thetas\n</code></pre>\n <python><logistic-regression><gradient-descent><p>There are several issues I see with the implementation. Some are just unnecessarily complicated ways of doing it, but some are genuine errors. </p>\n\n<p><strong>Primary takeaways</strong></p>\n\n<p>A: <em>Try to start from the math behind the model.</em> The logistic regression is a relatively simple one. Find the two equations you need and stick to them, replicate them letter by letter.</p>\n\n<p>B: <em>Vectorize.</em> It will save you a lot of unnecessary steps and computations, if you step back for a bit and think of the best vectorized implementation.</p>\n\n<p>C: <em>Write more comments in the code.</em> It will help those trying to help you. It will also help you understand each part better and maybe uncover errors yourself.</p>\n\n<p>Now let's go over the code step by step.</p>\n\n<p><strong>1. The sigmoid function</strong></p>\n\n<p>Is there a reason for such a complicate implementation in <code>phi(t)</code>? Assuming that <code>t</code> is a vector (a numpy array), then all you really need is:</p>\n\n<pre><code>def phi(t):\n   1. / (1. + np.exp(-t))\n</code></pre>\n\n<p>As <code>np.exp()</code> operates element-wise over arrays. Ideally, I'd implement it as a function that can also return its derivative (not necessary here, but might be handy if you try to implement a basic neural net with sigmoid activations):</p>\n\n<pre><code>def phi(t, dt = False):\n   if dt:\n      phi(t) * (1. - phi(t))\n   else:\n      1. / (1. + np.exp(-t))\n</code></pre>\n\n<p><strong>2. Cost function</strong></p>\n\n<p>Usually, the logistic cost function is defined as a log cost in the following way (vectorized): $ \\frac{1}{m} (-(y^T \\log{(\\phi(X\\theta))})-(1-y^T)(\\log{(1 - \\phi(X\\theta))}) + \\frac{\\lambda}{2m} \\theta^{1T}\\theta $  where $\\phi(z)$ is the logistic (sigmoid) function, $\\theta$ is the full parameter vector (including bias weight), $\\theta^1$ is parameter vector with $\\theta_1=0$ (by convention, bias is not regularized) and $\\lambda$ is the regularization parameter. </p>\n\n<p>What I really don't understand is the part where you multiply <code>y * z</code>. Assuming <code>y</code> is your label vector $y$, why are you multiplying it with your <code>z</code> before applying the sigmoid function? And why do you need to split the cost function into zeros and ones and calculate losses for either sample separately? \nI think the problem in your code really lies in this part: you must be erroneously multiplying $y$ with $X\\theta$ before applying $\\phi(.)$.</p>\n\n<p>Also, this bit here: <code>X.dot(w) + c</code>. So <code>c</code> is your bias parameter, right? Why are you adding it to every element of $X\\theta$? It shouldn't be added - it should be the first element of the vector $X\\theta$. Yes, you don't regularize it, but you need to use in the \"prediction\" part of the loss function.</p>\n\n<p>In your code, I also see the cost function as being overly complicated. Here's what I would try:</p>\n\n<pre><code>def loss(X,y,w,lam):\n   #calculate \"prediction\"\n   Z = np.dot(X,w)\n   #calculate cost without regularization\n   #shape of X is (m,n), shape of w is (n,1)\n   J = (1./len(X)) * (-np.dot(y.T, np.log(phi(Z))) * np.dot((1-y.T),np.log(1 - phi(Z))))\n   #add regularization\n   #temporary weight vector\n   w1 = copy.copy(w) #import copy to create a true copy\n   w1[0] = 0\n   J += (lam/(2.*len(X))) * np.dot(w1.T, w)\n   return J\n</code></pre>\n\n<p><strong>3. Gradient</strong></p>\n\n<p>Again, let's first go over the formula for the gradient of the logistic loss, again, vectorized: $\\frac{1}{m} ((\\phi(X\\theta) - y)^TX)^T + \\frac{\\lambda}{m}\\theta^1$.\nThis will return a vector of derivatives (i.e. gradient) for all parameters, regularized properly (without the bias term regularized).</p>\n\n<p>Here again, you've multiplied by $y$ way too soon: <code>phi(y * z)</code>. In fact, you shouldn't have multiplied by $y$ in gradient at all. </p>\n\n<p>This is what I would do for the gradient:</p>\n\n<pre><code>def gradient(X, y, w, lam):\n   #calculate the prediction\n   Z = np.dot(X,w)\n   #temporary weight vector\n   w1 = copy.copy(w) #import copy to create a true copy\n   w1[0] = 0\n   #calc gradient\n   grad = (1./len(X)) * (np.dot((phi(Z) - y).T,X).T) + (lam/len(X)) * w1\n   return grad\n</code></pre>\n\n<p>The actual gradient descent implementation seems ok to me, but because there are errors in the gradient and cost function implementations, it fails to deliver :/</p>\n\n<p>Hope this will help you get on track.</p>\n<p>Below is how you can implement gradient descent in Python:</p>\n\n<pre><code>def sigmoid(z):\n    s= 1/(1 + np.exp(-z))\n    return s\n\ndef propagate(w, b, X, Y):\n\n    m = X.shape[1]\n\n    A = sigmoid(np.dot(w.T,X)+b)                                     # compute activation\n\n    cost = -1/m * np.sum(Y * np.log(A) + (1-Y) * (np.log(1-A)))\n\n    dz= (1/m)*(A - Y)\n    dw = np.dot(X, dz.T)\n    db = np.sum(dz)\n\n\n    cost = np.squeeze(cost)\n    grads = {\"dw\": dw,\n             \"db\": db}\n\n    return grads, cost\n\n\ndef optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n\n    costs = []\n\n    for i in range(num_iterations):\n        m = X.shape[1]\n        grads,cost = propagate(w, b, X, Y)\n        b = b - learning_rate*grads[\"db\"]\n        w = w - learning_rate*grads[\"dw\"]\n        if i % 100 == 0:\n            costs.append(cost)\n        if print_cost and i % 100 == 0:\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n\n    params = {\"w\": w,\n              \"b\": b}\n    return params, grads, costs\n\n\n\ndef predict(w, b, X):\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n    A = sigmoid(np.dot(w.T,X)+ b)\n\n    for i in range(A.shape[1]):\n        x_exp = np.exp(A)\n        x_sum = np.sum(x_exp,axis=1,keepdims=True)\n        s = np.divide(x_exp,x_sum)\n\n    Y_prediction = 1. * (A &gt; 0.5)\n\n    return Y_prediction\n\n\n\ndef model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n    w, b = initialize_with_zeros(X_train.shape[0])\n\n    print(\"learning rate:\",learning_rate)\n\n    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost = False)\n\n    w = parameters[\"w\"]\n    b = parameters[\"b\"]\n\n    Y_prediction_train = predict(w,b,X_train)\n    Y_prediction_test = predict(w,b,X_test)\n    d = {\"costs\": costs,\n         \"Y_prediction_test\": Y_prediction_test, \n         \"Y_prediction_train\" : Y_prediction_train, \n         \"w\" : w, \n         \"b\" : b,\n         \"learning_rate\" : learning_rate,\n         \"num_iterations\": num_iterations}\n\n    return d\n\nd = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)\n</code></pre>\n",
                "codes": [
                    [
                        "def phi(t):\n   1. / (1. + np.exp(-t))\n",
                        "def phi(t, dt = False):\n   if dt:\n      phi(t) * (1. - phi(t))\n   else:\n      1. / (1. + np.exp(-t))\n",
                        "def loss(X,y,w,lam):\n   #calculate \"prediction\"\n   Z = np.dot(X,w)\n   #calculate cost without regularization\n   #shape of X is (m,n), shape of w is (n,1)\n   J = (1./len(X)) * (-np.dot(y.T, np.log(phi(Z))) * np.dot((1-y.T),np.log(1 - phi(Z))))\n   #add regularization\n   #temporary weight vector\n   w1 = copy.copy(w) #import copy to create a true copy\n   w1[0] = 0\n   J += (lam/(2.*len(X))) * np.dot(w1.T, w)\n   return J\n",
                        "def gradient(X, y, w, lam):\n   #calculate the prediction\n   Z = np.dot(X,w)\n   #temporary weight vector\n   w1 = copy.copy(w) #import copy to create a true copy\n   w1[0] = 0\n   #calc gradient\n   grad = (1./len(X)) * (np.dot((phi(Z) - y).T,X).T) + (lam/len(X)) * w1\n   return grad\n"
                    ],
                    [
                        "def sigmoid(z):\n    s= 1/(1 + np.exp(-z))\n    return s\n\ndef propagate(w, b, X, Y):\n\n    m = X.shape[1]\n\n    A = sigmoid(np.dot(w.T,X)+b)                                     # compute activation\n\n    cost = -1/m * np.sum(Y * np.log(A) + (1-Y) * (np.log(1-A)))\n\n    dz= (1/m)*(A - Y)\n    dw = np.dot(X, dz.T)\n    db = np.sum(dz)\n\n\n    cost = np.squeeze(cost)\n    grads = {\"dw\": dw,\n             \"db\": db}\n\n    return grads, cost\n\n\ndef optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n\n    costs = []\n\n    for i in range(num_iterations):\n        m = X.shape[1]\n        grads,cost = propagate(w, b, X, Y)\n        b = b - learning_rate*grads[\"db\"]\n        w = w - learning_rate*grads[\"dw\"]\n        if i % 100 == 0:\n            costs.append(cost)\n        if print_cost and i % 100 == 0:\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n\n    params = {\"w\": w,\n              \"b\": b}\n    return params, grads, costs\n\n\n\ndef predict(w, b, X):\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n    A = sigmoid(np.dot(w.T,X)+ b)\n\n    for i in range(A.shape[1]):\n        x_exp = np.exp(A)\n        x_sum = np.sum(x_exp,axis=1,keepdims=True)\n        s = np.divide(x_exp,x_sum)\n\n    Y_prediction = 1. * (A > 0.5)\n\n    return Y_prediction\n\n\n\ndef model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n    w, b = initialize_with_zeros(X_train.shape[0])\n\n    print(\"learning rate:\",learning_rate)\n\n    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost = False)\n\n    w = parameters[\"w\"]\n    b = parameters[\"b\"]\n\n    Y_prediction_train = predict(w,b,X_train)\n    Y_prediction_test = predict(w,b,X_test)\n    d = {\"costs\": costs,\n         \"Y_prediction_test\": Y_prediction_test, \n         \"Y_prediction_train\" : Y_prediction_train, \n         \"w\" : w, \n         \"b\" : b,\n         \"learning_rate\" : learning_rate,\n         \"num_iterations\": num_iterations}\n\n    return d\n\nd = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)\n"
                    ]
                ],
                "question_id:": "8657",
                "question_votes:": "6",
                "question_text:": "<p>I'm currently using the following code as a starting point to deepen my understanding of regularized logistic regression.  As a first pass I'm just trying to do a binary classification on part of the iris data set.  </p>\n\n<p>One problem I think I have encountered is that the negative log-loss (computed with loss and stored in loss_vec) doesn't change much from one iteration to the next.</p>\n\n<p>Another challenge I am facing is trying to figure out how to plot the decision boundary once I have learned the logistic regression coefficients. Using the coefficients to plot the 0.5 decision boundary is way off.  This makes me think I have made a mistake somewhere</p>\n\n<p><a href=\"http://fa.bianp.net/blog/2013/numerical-optimizers-for-logistic-regression/\" rel=\"noreferrer\">http://fa.bianp.net/blog/2013/numerical-optimizers-for-logistic-regression/</a></p>\n\n\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model, datasets\n\n\niris = datasets.load_iris()\nX = iris.data[:, :2]  # we only take the first two features.\nY = iris.target\n\n\nX = X[:100,:]\nY = Y[:100]\n\ndef phi(t):\n    # logistic function, returns 1 / (1 + exp(-t))\n    idx = t &gt; 0\n    out = np.empty(t.size, dtype=np.float)\n    out[idx] = 1. / (1 + np.exp(-t[idx]))\n    exp_t = np.exp(t[~idx])\n    out[~idx] = exp_t / (1. + exp_t)\n    return out\n\n\ndef loss(x0, X, y, alpha):\n    # logistic loss function, returns Sum{-log(phi(t))}\n    #x0 is the weight vector w are the paramaters, c is the bias term\n    w, c = x0[:X.shape[1]], x0[-1]\n    z = X.dot(w) + c\n    yz = y * z\n    idx = yz &gt; 0\n    out = np.zeros_like(yz)\n    out[idx] = np.log(1 + np.exp(-yz[idx]))\n    out[~idx] = (-yz[~idx] + np.log(1 + np.exp(yz[~idx])))\n    out = out.sum() / X.shape[0] + .5 * alpha * w.dot(w)\n    return out\n\n\ndef gradient(x0, X, y, alpha):\n    # gradient of the logistic loss\n    w, c = x0[:X.shape[1]], x0[-1]\n    z = X.dot(w) + c\n    z = phi(y * z)\n    z0 = (z - 1) * y\n    grad_w = X.T.dot(z0) / X.shape[0] + alpha * w\n    grad_c = z0.sum() / X.shape[0]\n    return np.concatenate((grad_w, [grad_c]))\n\n\ndef bgd(X, y, alpha, max_iter):\n    step_sizes = np.array([100,10,1,.1,.01,.001,.0001,.00001])\n    iter_no = 0\n    x0 = np.random.random(X.shape[1] + 1) #initialize weight vector\n\n    #placeholder for coefficients to test against the loss function\n    next_thetas = np.zeros((step_sizes.shape[0],X.shape[1]+1) )   \n    J = loss(x0,X,y,alpha)\n    running_loss = []\n    while iter_no &lt; max_iter:\n        grad = gradient(x0,X,y,alpha)\n        next_thetas = -(np.outer(step_sizes,grad)-x0)\n        loss_vec = []\n        for i in range(np.shape(next_thetas)[0]):\n            loss_vec.append(loss(next_thetas[i],X,y,alpha))\n        ind = np.argmin(loss_vec)\n        x0 = next_thetas[ind]\n        if iter_no % 500 == 0:\n            running_loss.append(loss(x0,X,y,alpha))\n        iter_no += 1  \n    return next_thetas\n</code></pre>\n",
                "tags": "<python><logistic-regression><gradient-descent>",
                "answers": [
                    [
                        "8663",
                        "2",
                        "8657",
                        "",
                        "",
                        "<p>There are several issues I see with the implementation. Some are just unnecessarily complicated ways of doing it, but some are genuine errors. </p>\n\n<p><strong>Primary takeaways</strong></p>\n\n<p>A: <em>Try to start from the math behind the model.</em> The logistic regression is a relatively simple one. Find the two equations you need and stick to them, replicate them letter by letter.</p>\n\n<p>B: <em>Vectorize.</em> It will save you a lot of unnecessary steps and computations, if you step back for a bit and think of the best vectorized implementation.</p>\n\n<p>C: <em>Write more comments in the code.</em> It will help those trying to help you. It will also help you understand each part better and maybe uncover errors yourself.</p>\n\n<p>Now let's go over the code step by step.</p>\n\n<p><strong>1. The sigmoid function</strong></p>\n\n<p>Is there a reason for such a complicate implementation in <code>phi(t)</code>? Assuming that <code>t</code> is a vector (a numpy array), then all you really need is:</p>\n\n<pre><code>def phi(t):\n   1. / (1. + np.exp(-t))\n</code></pre>\n\n<p>As <code>np.exp()</code> operates element-wise over arrays. Ideally, I'd implement it as a function that can also return its derivative (not necessary here, but might be handy if you try to implement a basic neural net with sigmoid activations):</p>\n\n<pre><code>def phi(t, dt = False):\n   if dt:\n      phi(t) * (1. - phi(t))\n   else:\n      1. / (1. + np.exp(-t))\n</code></pre>\n\n<p><strong>2. Cost function</strong></p>\n\n<p>Usually, the logistic cost function is defined as a log cost in the following way (vectorized): $ \\frac{1}{m} (-(y^T \\log{(\\phi(X\\theta))})-(1-y^T)(\\log{(1 - \\phi(X\\theta))}) + \\frac{\\lambda}{2m} \\theta^{1T}\\theta $  where $\\phi(z)$ is the logistic (sigmoid) function, $\\theta$ is the full parameter vector (including bias weight), $\\theta^1$ is parameter vector with $\\theta_1=0$ (by convention, bias is not regularized) and $\\lambda$ is the regularization parameter. </p>\n\n<p>What I really don't understand is the part where you multiply <code>y * z</code>. Assuming <code>y</code> is your label vector $y$, why are you multiplying it with your <code>z</code> before applying the sigmoid function? And why do you need to split the cost function into zeros and ones and calculate losses for either sample separately? \nI think the problem in your code really lies in this part: you must be erroneously multiplying $y$ with $X\\theta$ before applying $\\phi(.)$.</p>\n\n<p>Also, this bit here: <code>X.dot(w) + c</code>. So <code>c</code> is your bias parameter, right? Why are you adding it to every element of $X\\theta$? It shouldn't be added - it should be the first element of the vector $X\\theta$. Yes, you don't regularize it, but you need to use in the \"prediction\" part of the loss function.</p>\n\n<p>In your code, I also see the cost function as being overly complicated. Here's what I would try:</p>\n\n<pre><code>def loss(X,y,w,lam):\n   #calculate \"prediction\"\n   Z = np.dot(X,w)\n   #calculate cost without regularization\n   #shape of X is (m,n), shape of w is (n,1)\n   J = (1./len(X)) * (-np.dot(y.T, np.log(phi(Z))) * np.dot((1-y.T),np.log(1 - phi(Z))))\n   #add regularization\n   #temporary weight vector\n   w1 = copy.copy(w) #import copy to create a true copy\n   w1[0] = 0\n   J += (lam/(2.*len(X))) * np.dot(w1.T, w)\n   return J\n</code></pre>\n\n<p><strong>3. Gradient</strong></p>\n\n<p>Again, let's first go over the formula for the gradient of the logistic loss, again, vectorized: $\\frac{1}{m} ((\\phi(X\\theta) - y)^TX)^T + \\frac{\\lambda}{m}\\theta^1$.\nThis will return a vector of derivatives (i.e. gradient) for all parameters, regularized properly (without the bias term regularized).</p>\n\n<p>Here again, you've multiplied by $y$ way too soon: <code>phi(y * z)</code>. In fact, you shouldn't have multiplied by $y$ in gradient at all. </p>\n\n<p>This is what I would do for the gradient:</p>\n\n<pre><code>def gradient(X, y, w, lam):\n   #calculate the prediction\n   Z = np.dot(X,w)\n   #temporary weight vector\n   w1 = copy.copy(w) #import copy to create a true copy\n   w1[0] = 0\n   #calc gradient\n   grad = (1./len(X)) * (np.dot((phi(Z) - y).T,X).T) + (lam/len(X)) * w1\n   return grad\n</code></pre>\n\n<p>The actual gradient descent implementation seems ok to me, but because there are errors in the gradient and cost function implementations, it fails to deliver :/</p>\n\n<p>Hope this will help you get on track.</p>\n",
                        "",
                        "10"
                    ],
                    [
                        "22445",
                        "2",
                        "8657",
                        "",
                        "",
                        "<p>Below is how you can implement gradient descent in Python:</p>\n\n<pre><code>def sigmoid(z):\n    s= 1/(1 + np.exp(-z))\n    return s\n\ndef propagate(w, b, X, Y):\n\n    m = X.shape[1]\n\n    A = sigmoid(np.dot(w.T,X)+b)                                     # compute activation\n\n    cost = -1/m * np.sum(Y * np.log(A) + (1-Y) * (np.log(1-A)))\n\n    dz= (1/m)*(A - Y)\n    dw = np.dot(X, dz.T)\n    db = np.sum(dz)\n\n\n    cost = np.squeeze(cost)\n    grads = {\"dw\": dw,\n             \"db\": db}\n\n    return grads, cost\n\n\ndef optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n\n    costs = []\n\n    for i in range(num_iterations):\n        m = X.shape[1]\n        grads,cost = propagate(w, b, X, Y)\n        b = b - learning_rate*grads[\"db\"]\n        w = w - learning_rate*grads[\"dw\"]\n        if i % 100 == 0:\n            costs.append(cost)\n        if print_cost and i % 100 == 0:\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n\n    params = {\"w\": w,\n              \"b\": b}\n    return params, grads, costs\n\n\n\ndef predict(w, b, X):\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n    A = sigmoid(np.dot(w.T,X)+ b)\n\n    for i in range(A.shape[1]):\n        x_exp = np.exp(A)\n        x_sum = np.sum(x_exp,axis=1,keepdims=True)\n        s = np.divide(x_exp,x_sum)\n\n    Y_prediction = 1. * (A &gt; 0.5)\n\n    return Y_prediction\n\n\n\ndef model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n    w, b = initialize_with_zeros(X_train.shape[0])\n\n    print(\"learning rate:\",learning_rate)\n\n    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost = False)\n\n    w = parameters[\"w\"]\n    b = parameters[\"b\"]\n\n    Y_prediction_train = predict(w,b,X_train)\n    Y_prediction_test = predict(w,b,X_test)\n    d = {\"costs\": costs,\n         \"Y_prediction_test\": Y_prediction_test, \n         \"Y_prediction_train\" : Y_prediction_train, \n         \"w\" : w, \n         \"b\" : b,\n         \"learning_rate\" : learning_rate,\n         \"num_iterations\": num_iterations}\n\n    return d\n\nd = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "1560",
            "_score": 6.170573,
            "_source": {
                "title": "Purpose of visualizing high dimensional data?",
                "content": "Purpose of visualizing high dimensional data? <p>There are many techniques for visualizing high dimension datasets, such as T-SNE, isomap, PCA, supervised PCA, etc. And we go through the motions of projecting the data down to a 2D or 3D space, so we have a \"pretty pictures\". Some of these embedding (manifold learning) methods are described <a href=\"http://scikit-learn.org/stable/modules/manifold.html\" rel=\"noreferrer\">here</a>.</p>\n\n<p><a href=\"https://i.stack.imgur.com/H3FBv.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/H3FBv.png\" alt=\"enter image description here\"></a></p>\n\n<p><strong>But is this \"pretty picture\" actually meaningful? What possible insights can someone grab by trying to visualize this embedded space?</strong></p>\n\n<p>I ask because the projection down to this embedded space is usually meaningless. For example, if you project your data down to principal components generated by PCA, those principal components (eiganvectors) don't correspond to features in the dataset; they're their own feature space. </p>\n\n<p>Similarly, t-SNE projects your data down to a space, where items are near each other if they minimize some KL divergence. This isn't the original feature space anymore. (Correct me if I'm wrong, but I don't even think there is a large effort by the ML community to use t-SNE to aid classification; that's a different problem than data visualization though.)</p>\n\n<p>I'm just very largely confused why people make such a big deal about some of these visualizations. </p>\n <machine-learning><dimensionality-reduction><visualization><p>Based on the statements and the discussions, I think there is an important point to distinct. A transformation to a lower dimensional space may <em>reduce</em> the information, which is something different from making the information <em>meaningless</em>. Let me use a following analogy:</p>\n\n<p>Observing (2D) pictures of our world (3D) is a usual practice. A visualization method provides only different \u201cglasses\u201d to see a high dimensional space.</p>\n\n<p>A good thing to \u201ctrust\u201d a visualization method is to understand the internals. My favourite example is the <a href=\"https://en.wikipedia.org/wiki/Multidimensional_scaling\" rel=\"nofollow\">MDS</a>  . It is easy possible to implement this method at your own using some optimization tool (e.g. R <em>optim</em>). So you can <em>see</em> how the method words, you may <em>measure the error</em> of the result etc.</p>\n\n<p>At the end you get a picture preserving the similarity of the original data with some degree of precision. Not more, but not less.</p>\n<p>First of all your explanation about the methods are right. The point is that Embedding algorithms are not to only visualize but basically reducing the dimentionality to cope with two main problems in Statistical Data Analysis, namely <strong>Curse of Dimentionaliy</strong> and <strong>Low-Sample Size Problem</strong> so that they are not supposed to depict physically understood features and they are not only <em>meaningful</em> but also necessary for data analysis!</p>\n\n<p>Actually the visualization is almost the last usage of embedding methods. Projecting high-dimensional data into a lower-dimension space helps to preserve the actual pair-wise distances (mainly Euclidean one) which get distorted in the high dimensions or capturing the most information embedded in the variance of different features.</p>\n<p>Sometimes, it is meaningful to visualize high dimensional data since it may tell us physics. </p>\n\n<p>There is at least one example in astrophysics where you project your data down to principal components generated by PCA and those principal components correspond to much physical insight about the galaxies. For detail, see the last figure in <a href=\"http://www.astroml.org/sklearn_tutorial/dimensionality_reduction.html#id2\" rel=\"nofollow\">http://www.astroml.org/sklearn_tutorial/dimensionality_reduction.html#id2</a> </p>\n\n<p>and the paper in </p>\n\n<p><a href=\"http://iopscience.iop.org/article/10.1086/425626/pdf\" rel=\"nofollow\">http://iopscience.iop.org/article/10.1086/425626/pdf</a></p>\n\n<p>Here is the basic idea. The authors apply PCA to many spectra (e.g., 10,000) from a telescope. Each spectrum has ~1000 attributes. Since this data set has large dimensions, it's difficult to visualize it. However, the first 4 components from PCA reveal much physics about the spectra (see sections 4.1-4.4 in the paper above). </p>\n<p>Taking a slightly different approach than the other great answers here, the \"pretty picture\" is worth a thousand words. Ultimately, you will need to convey your findings to someone who is not as statistically literate, or who simply does not have the time, interest, or whatever, to grasp the full situation. That doesn't mean we cannot help the person to understand, at least a general concept or a piece of the reality. This is what books like Freakonomics do - there's little to no math, no data sets, and yet the findings are still presented.</p>\n\n<p>From the arts, look at <a href=\"https://en.wikipedia.org/wiki/Adolphe_Yvon#/media/File:Adolphe_Yvon_%281817-1893%29_-_Marshall_Ney_at_retreat_in_Russia.jpg\" rel=\"nofollow\">Marshal Ney at Retreat in Russia</a>. This massive oversimplification of the Napoleonic wars nevertheless conveys great meaning and allows people with even the most ignorant knowledge of the war to understand the brutality, the climate, the landscape, the death, and decorum that permeated the invasion of Russia.</p>\n\n<p>Ultimately the charts are simply communication, and for better or worse, human communication is often times focused on conflation, simplification, and brevity.</p>\n<p>Richard Hamming is attributed with the sentence: \"The purpose of computing is insight, not numbers.\"  In this 1973 <a href=\"http://ww.w.lithoguru.com/scientist/statistics/Anscombe_Graphs%20in%20Statistical%20Analysis_1973.pdf\" rel=\"nofollow noreferrer\">academic paper</a> (see discussion in <a href=\"https://stats.stackexchange.com/questions/141614/what-is-the-famous-data-set-that-looks-totally-different-but-has-similar-summary/180805\">What is the famous data set that looks totally different but has similar summary stats?</a>), Francis Anscombe argues that \"graphs are essential to good statistical analysis.\" Anscombe's quartet is a long time favorite: same stats and regression, low dimension, yet very different behavior, regarding noise, outliers, dependancy. The projection of data in 11 dimensions onto two dimensions shown below is quite misleading: one has correlation and  dispersion, the second (bottom down) has  exact match, except one outlier. The third has clear relationship, but not linear. The fourth shows the variables are potentially not related, except for a threshold.</p>\n\n<p><a href=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Anscombe&#39;s_quartet_3.svg/500px-Anscombe&#39;s_quartet_3.svg.png\" rel=\"nofollow noreferrer\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Anscombe&#39;s_quartet_3.svg/500px-Anscombe&#39;s_quartet_3.svg.png\" alt=\"enter image description here\"></a></p>\n\n<p>In the book <a href=\"http://eu.wiley.com/WileyCDA/WileyTitle/productCd-EHEP002310.html\" rel=\"nofollow noreferrer\">Multivariate Analysis for the Biobehavioral and Social Sciences</a> by Bruce L. Brown <em>et al.</em>, we can find:</p>\n\n<blockquote>\n  <p>In his 1990 work \"Drawing Things Together,\" Latour claims that the\n  mindset of hard scientists is one of intense \u201cobsession\u201d with graphism</p>\n</blockquote>\n\n<p>Whether limited to 3D space, up to <a href=\"https://www.youtube.com/watch?v=OdnhKE95AqM\" rel=\"nofollow noreferrer\">six dimension plots</a> (space, color, shape and time), or <a href=\"http://www.tenthdimension.com/medialinks.php\" rel=\"nofollow noreferrer\">even imagining the tenth dimension</a>, humans have limited sights. Relationships between observable phenomena: not.</p>\n\n<p>Additionally, the curse of dimensions is assorted with even low dimension paradoxes, to give a few: </p>\n\n<ul>\n<li><a href=\"https://stats.stackexchange.com/questions/149936/why-is-the-curse-of-dimensionality-also-called-the-empty-space-phenomenon\">Why is the curse of dimensionality also called the empty space phenomenon?</a></li>\n<li><a href=\"http://www.slideshare.net/NikhilSharma6/curse-of-dimensionality\" rel=\"nofollow noreferrer\">Curse of dimensionality</a></li>\n<li><a href=\"https://stats.stackexchange.com/questions/29627/euclidean-distance-is-usually-not-good-for-sparse-data\">Why is Euclidean distance not a good metric in high dimensions?</a></li>\n<li><a href=\"https://sbjoshi.wordpress.com/2013/03/27/paradox-about-high-dimensional-spheres/\" rel=\"nofollow noreferrer\">Paradox about high-dimensional spheres!</a></li>\n<li><a href=\"http://bit-player.org/2011/the-n-ball-game\" rel=\"nofollow noreferrer\">The n-ball game</a></li>\n</ul>\n\n<p>Even if all norms are equivalent in finite dimensions, relationships between variables might be misleading. This is one reason for preserving distances from one space to another. Such concepts are at of the heart of lower dimension embeddings for signals (such as <a href=\"https://en.wikipedia.org/wiki/Compressed_sensing\" rel=\"nofollow noreferrer\">compressive sensing</a> and the <a href=\"https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma\" rel=\"nofollow noreferrer\">Johnson-Lindenstauss lemma</a> concerning low-distortion embeddings of points from high-dimensional into low-dimensional Euclidean space) or features (<a href=\"http://www.di.ens.fr/data/scattering/\" rel=\"nofollow noreferrer\">scattering transforms</a> for classifications).</p>\n\n<p>So visualization is another help in getting insights in the data, and it goes hand in hand with calculations, including dimension reduction.</p>\n\n<p>Last example: put touching   $n$-spheres in an $n$-cube (the bubble inside the box, taken from <a href=\"https://www.quora.com/Do-good-mathematicians-visualize-everything-even-algebra\" rel=\"nofollow noreferrer\">Do good mathematicians visualize everything (even algebra)?</a>):</p>\n\n<p><a href=\"https://i.stack.imgur.com/t57Ls.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/t57Ls.png\" alt=\"Pizza box paradox\"></a></p>\n\n<p>In two dimensions, the  center blue  ball is small. In 3D too. But very quickly, the center ball grows and its radius exceeds that of the cube. This insight is vital n clustering, for instance.</p>\n<p>I take Natural Language Processing as an example because that's the field that I have more experience in so I encourage others to share their insights in other fields like in Computer Vision, Biostatistics, time series, etc. I'm sure in those fields there are similar examples.</p>\n\n<p>I agree that sometimes model visualizations can be meaningless but I think the main purpose of visualizations of this kind are to help us check if the model actually relates to human intuition or some other (non-computational) model. Additionally, Exploratory Data Analysis can be performed on the data.</p>\n\n<p>Let's assume we have a word embedding model built from Wikipedia's corpus using <a href=\"https://radimrehurek.com/gensim/models/word2vec.html\" rel=\"nofollow noreferrer\">Gensim</a></p>\n\n<pre><code>model = gensim.models.Word2Vec(sentences, min_count=2)\n</code></pre>\n\n<p>We would then have a 100 dimension vector for each word represented in that corpus that's present at least twice. So if we wanted to visualize these words we would have to reduce them to 2 or 3 dimensions using the t-sne algorithm. Here is where very interesting characteristics arise.</p>\n\n<p>Take the example:</p>\n\n<p>vector(\"king\") + vector(\"man\") - vector(\"woman\") = vector(\"queen\")</p>\n\n<p><img src=\"https://i.stack.imgur.com/OQpTJ.gif\" alt=\"http://multithreaded.stitchfix.com/blog/2015/03/11/word-is-worth-a-thousand-vectors/\"></p>\n\n<p>Here each direction encode certain semantic features. The same can be done in 3d</p>\n\n<p><a href=\"https://i.stack.imgur.com/ZcNDo.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ZcNDo.png\" alt=\"https://www.tensorflow.org/versions/master/images/linear-relationships.png\"></a><br>\n<sub>(source: <a href=\"https://www.tensorflow.org/versions/master/images/linear-relationships.png\" rel=\"nofollow noreferrer\">tensorflow.org</a>)</sub>  </p>\n\n<p>See how in this example past tense is located in a certain position respective to its participle. The same for gender. Same with countries and capitals.</p>\n\n<p>In the word embedding world, older and more naive models, didn't have this property. </p>\n\n<p>See this Stanford lecture for more details.\n<a href=\"https://www.youtube.com/watch?v=T8tQZChniMk\" rel=\"nofollow noreferrer\">Simple Word Vector representations: word2vec, GloVe</a></p>\n\n<p>They only were limited to clustering similar words together without regard for semantics (gender or verb tense weren't encoded as directions). Unsurprisingly models which have a semantic encoding as directions in lower dimensions are more accurate. And more importantly, they can be used to explore each data point in a more appropriate way. </p>\n\n<p>In this particular case, I don't think t-SNE is used to aid classification per se, it's more like a sanity check for your model and sometimes to find insight in the particular corpus you are using. As for the problem of the vectors not being in original feature space anymore. Richard Socher explains in the lecture (link above) that low dimensional vectors share statistical distributions with its own larger representation as well as other statistical properties which make plausible visually analyse in lower dimensions embedding vectors.</p>\n\n<p><strong>Additional resources &amp; Image Sources:</strong></p>\n\n<ol>\n<li><p><a href=\"http://multithreaded.stitchfix.com/blog/2015/03/11/word-is-worth-a-thousand-vectors/\" rel=\"nofollow noreferrer\">http://multithreaded.stitchfix.com/blog/2015/03/11/word-is-worth-a-thousand-vectors/</a></p></li>\n<li><p><a href=\"https://www.tensorflow.org/tutorials/word2vec/index.html#motivation_why_learn_word_embeddings%3F\" rel=\"nofollow noreferrer\">https://www.tensorflow.org/tutorials/word2vec/index.html#motivation_why_learn_word_embeddings%3F</a></p></li>\n<li><p><a href=\"http://deeplearning4j.org/word2vec.html\" rel=\"nofollow noreferrer\">http://deeplearning4j.org/word2vec.html</a></p></li>\n<li><p><a href=\"https://www.tensorflow.org/tutorials/word2vec/index.html#motivation_why_learn_word_embeddings%3F\" rel=\"nofollow noreferrer\">https://www.tensorflow.org/tutorials/word2vec/index.html#motivation_why_learn_word_embeddings%3F</a></p></li>\n</ol>\n<p>Excellent question. In chapter 4 of \"Illuminating the Path, The Research and Development Agenda for Visual Analytics\" by James J. Thomas and Kristin A. Cook is a discussion on data representations and data transformations. In my research I have approached this question in the context of PCA and factor analysis. My brief answer is that the visualizations are useful if one has the data transformation to move from the visualization space to the original data space. This would additionally be conducted within a visual analytics framework.</p>\n",
                "codes": [
                    [],
                    [],
                    [],
                    [],
                    [],
                    [
                        "model = gensim.models.Word2Vec(sentences, min_count=2)\n"
                    ],
                    []
                ],
                "question_id:": "9038",
                "question_votes:": "22",
                "question_text:": "<p>There are many techniques for visualizing high dimension datasets, such as T-SNE, isomap, PCA, supervised PCA, etc. And we go through the motions of projecting the data down to a 2D or 3D space, so we have a \"pretty pictures\". Some of these embedding (manifold learning) methods are described <a href=\"http://scikit-learn.org/stable/modules/manifold.html\" rel=\"noreferrer\">here</a>.</p>\n\n<p><a href=\"https://i.stack.imgur.com/H3FBv.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/H3FBv.png\" alt=\"enter image description here\"></a></p>\n\n<p><strong>But is this \"pretty picture\" actually meaningful? What possible insights can someone grab by trying to visualize this embedded space?</strong></p>\n\n<p>I ask because the projection down to this embedded space is usually meaningless. For example, if you project your data down to principal components generated by PCA, those principal components (eiganvectors) don't correspond to features in the dataset; they're their own feature space. </p>\n\n<p>Similarly, t-SNE projects your data down to a space, where items are near each other if they minimize some KL divergence. This isn't the original feature space anymore. (Correct me if I'm wrong, but I don't even think there is a large effort by the ML community to use t-SNE to aid classification; that's a different problem than data visualization though.)</p>\n\n<p>I'm just very largely confused why people make such a big deal about some of these visualizations. </p>\n",
                "tags": "<machine-learning><dimensionality-reduction><visualization>",
                "answers": [
                    [
                        "9128",
                        "2",
                        "9038",
                        "",
                        "",
                        "<p>Based on the statements and the discussions, I think there is an important point to distinct. A transformation to a lower dimensional space may <em>reduce</em> the information, which is something different from making the information <em>meaningless</em>. Let me use a following analogy:</p>\n\n<p>Observing (2D) pictures of our world (3D) is a usual practice. A visualization method provides only different \u201cglasses\u201d to see a high dimensional space.</p>\n\n<p>A good thing to \u201ctrust\u201d a visualization method is to understand the internals. My favourite example is the <a href=\"https://en.wikipedia.org/wiki/Multidimensional_scaling\" rel=\"nofollow\">MDS</a>  . It is easy possible to implement this method at your own using some optimization tool (e.g. R <em>optim</em>). So you can <em>see</em> how the method words, you may <em>measure the error</em> of the result etc.</p>\n\n<p>At the end you get a picture preserving the similarity of the original data with some degree of precision. Not more, but not less.</p>\n",
                        "",
                        "4"
                    ],
                    [
                        "9126",
                        "2",
                        "9038",
                        "",
                        "",
                        "<p>First of all your explanation about the methods are right. The point is that Embedding algorithms are not to only visualize but basically reducing the dimentionality to cope with two main problems in Statistical Data Analysis, namely <strong>Curse of Dimentionaliy</strong> and <strong>Low-Sample Size Problem</strong> so that they are not supposed to depict physically understood features and they are not only <em>meaningful</em> but also necessary for data analysis!</p>\n\n<p>Actually the visualization is almost the last usage of embedding methods. Projecting high-dimensional data into a lower-dimension space helps to preserve the actual pair-wise distances (mainly Euclidean one) which get distorted in the high dimensions or capturing the most information embedded in the variance of different features.</p>\n",
                        "",
                        "11"
                    ],
                    [
                        "9152",
                        "2",
                        "9038",
                        "",
                        "",
                        "<p>Sometimes, it is meaningful to visualize high dimensional data since it may tell us physics. </p>\n\n<p>There is at least one example in astrophysics where you project your data down to principal components generated by PCA and those principal components correspond to much physical insight about the galaxies. For detail, see the last figure in <a href=\"http://www.astroml.org/sklearn_tutorial/dimensionality_reduction.html#id2\" rel=\"nofollow\">http://www.astroml.org/sklearn_tutorial/dimensionality_reduction.html#id2</a> </p>\n\n<p>and the paper in </p>\n\n<p><a href=\"http://iopscience.iop.org/article/10.1086/425626/pdf\" rel=\"nofollow\">http://iopscience.iop.org/article/10.1086/425626/pdf</a></p>\n\n<p>Here is the basic idea. The authors apply PCA to many spectra (e.g., 10,000) from a telescope. Each spectrum has ~1000 attributes. Since this data set has large dimensions, it's difficult to visualize it. However, the first 4 components from PCA reveal much physics about the spectra (see sections 4.1-4.4 in the paper above). </p>\n",
                        "",
                        "4"
                    ],
                    [
                        "9217",
                        "2",
                        "9038",
                        "",
                        "",
                        "<p>Taking a slightly different approach than the other great answers here, the \"pretty picture\" is worth a thousand words. Ultimately, you will need to convey your findings to someone who is not as statistically literate, or who simply does not have the time, interest, or whatever, to grasp the full situation. That doesn't mean we cannot help the person to understand, at least a general concept or a piece of the reality. This is what books like Freakonomics do - there's little to no math, no data sets, and yet the findings are still presented.</p>\n\n<p>From the arts, look at <a href=\"https://en.wikipedia.org/wiki/Adolphe_Yvon#/media/File:Adolphe_Yvon_%281817-1893%29_-_Marshall_Ney_at_retreat_in_Russia.jpg\" rel=\"nofollow\">Marshal Ney at Retreat in Russia</a>. This massive oversimplification of the Napoleonic wars nevertheless conveys great meaning and allows people with even the most ignorant knowledge of the war to understand the brutality, the climate, the landscape, the death, and decorum that permeated the invasion of Russia.</p>\n\n<p>Ultimately the charts are simply communication, and for better or worse, human communication is often times focused on conflation, simplification, and brevity.</p>\n",
                        "",
                        "4"
                    ],
                    [
                        "9130",
                        "2",
                        "9038",
                        "",
                        "",
                        "<p>Richard Hamming is attributed with the sentence: \"The purpose of computing is insight, not numbers.\"  In this 1973 <a href=\"http://ww.w.lithoguru.com/scientist/statistics/Anscombe_Graphs%20in%20Statistical%20Analysis_1973.pdf\" rel=\"nofollow noreferrer\">academic paper</a> (see discussion in <a href=\"https://stats.stackexchange.com/questions/141614/what-is-the-famous-data-set-that-looks-totally-different-but-has-similar-summary/180805\">What is the famous data set that looks totally different but has similar summary stats?</a>), Francis Anscombe argues that \"graphs are essential to good statistical analysis.\" Anscombe's quartet is a long time favorite: same stats and regression, low dimension, yet very different behavior, regarding noise, outliers, dependancy. The projection of data in 11 dimensions onto two dimensions shown below is quite misleading: one has correlation and  dispersion, the second (bottom down) has  exact match, except one outlier. The third has clear relationship, but not linear. The fourth shows the variables are potentially not related, except for a threshold.</p>\n\n<p><a href=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Anscombe&#39;s_quartet_3.svg/500px-Anscombe&#39;s_quartet_3.svg.png\" rel=\"nofollow noreferrer\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Anscombe&#39;s_quartet_3.svg/500px-Anscombe&#39;s_quartet_3.svg.png\" alt=\"enter image description here\"></a></p>\n\n<p>In the book <a href=\"http://eu.wiley.com/WileyCDA/WileyTitle/productCd-EHEP002310.html\" rel=\"nofollow noreferrer\">Multivariate Analysis for the Biobehavioral and Social Sciences</a> by Bruce L. Brown <em>et al.</em>, we can find:</p>\n\n<blockquote>\n  <p>In his 1990 work \"Drawing Things Together,\" Latour claims that the\n  mindset of hard scientists is one of intense \u201cobsession\u201d with graphism</p>\n</blockquote>\n\n<p>Whether limited to 3D space, up to <a href=\"https://www.youtube.com/watch?v=OdnhKE95AqM\" rel=\"nofollow noreferrer\">six dimension plots</a> (space, color, shape and time), or <a href=\"http://www.tenthdimension.com/medialinks.php\" rel=\"nofollow noreferrer\">even imagining the tenth dimension</a>, humans have limited sights. Relationships between observable phenomena: not.</p>\n\n<p>Additionally, the curse of dimensions is assorted with even low dimension paradoxes, to give a few: </p>\n\n<ul>\n<li><a href=\"https://stats.stackexchange.com/questions/149936/why-is-the-curse-of-dimensionality-also-called-the-empty-space-phenomenon\">Why is the curse of dimensionality also called the empty space phenomenon?</a></li>\n<li><a href=\"http://www.slideshare.net/NikhilSharma6/curse-of-dimensionality\" rel=\"nofollow noreferrer\">Curse of dimensionality</a></li>\n<li><a href=\"https://stats.stackexchange.com/questions/29627/euclidean-distance-is-usually-not-good-for-sparse-data\">Why is Euclidean distance not a good metric in high dimensions?</a></li>\n<li><a href=\"https://sbjoshi.wordpress.com/2013/03/27/paradox-about-high-dimensional-spheres/\" rel=\"nofollow noreferrer\">Paradox about high-dimensional spheres!</a></li>\n<li><a href=\"http://bit-player.org/2011/the-n-ball-game\" rel=\"nofollow noreferrer\">The n-ball game</a></li>\n</ul>\n\n<p>Even if all norms are equivalent in finite dimensions, relationships between variables might be misleading. This is one reason for preserving distances from one space to another. Such concepts are at of the heart of lower dimension embeddings for signals (such as <a href=\"https://en.wikipedia.org/wiki/Compressed_sensing\" rel=\"nofollow noreferrer\">compressive sensing</a> and the <a href=\"https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma\" rel=\"nofollow noreferrer\">Johnson-Lindenstauss lemma</a> concerning low-distortion embeddings of points from high-dimensional into low-dimensional Euclidean space) or features (<a href=\"http://www.di.ens.fr/data/scattering/\" rel=\"nofollow noreferrer\">scattering transforms</a> for classifications).</p>\n\n<p>So visualization is another help in getting insights in the data, and it goes hand in hand with calculations, including dimension reduction.</p>\n\n<p>Last example: put touching   $n$-spheres in an $n$-cube (the bubble inside the box, taken from <a href=\"https://www.quora.com/Do-good-mathematicians-visualize-everything-even-algebra\" rel=\"nofollow noreferrer\">Do good mathematicians visualize everything (even algebra)?</a>):</p>\n\n<p><a href=\"https://i.stack.imgur.com/t57Ls.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/t57Ls.png\" alt=\"Pizza box paradox\"></a></p>\n\n<p>In two dimensions, the  center blue  ball is small. In 3D too. But very quickly, the center ball grows and its radius exceeds that of the cube. This insight is vital n clustering, for instance.</p>\n",
                        "",
                        "10"
                    ],
                    [
                        "9157",
                        "2",
                        "9038",
                        "",
                        "",
                        "<p>I take Natural Language Processing as an example because that's the field that I have more experience in so I encourage others to share their insights in other fields like in Computer Vision, Biostatistics, time series, etc. I'm sure in those fields there are similar examples.</p>\n\n<p>I agree that sometimes model visualizations can be meaningless but I think the main purpose of visualizations of this kind are to help us check if the model actually relates to human intuition or some other (non-computational) model. Additionally, Exploratory Data Analysis can be performed on the data.</p>\n\n<p>Let's assume we have a word embedding model built from Wikipedia's corpus using <a href=\"https://radimrehurek.com/gensim/models/word2vec.html\" rel=\"nofollow noreferrer\">Gensim</a></p>\n\n<pre><code>model = gensim.models.Word2Vec(sentences, min_count=2)\n</code></pre>\n\n<p>We would then have a 100 dimension vector for each word represented in that corpus that's present at least twice. So if we wanted to visualize these words we would have to reduce them to 2 or 3 dimensions using the t-sne algorithm. Here is where very interesting characteristics arise.</p>\n\n<p>Take the example:</p>\n\n<p>vector(\"king\") + vector(\"man\") - vector(\"woman\") = vector(\"queen\")</p>\n\n<p><img src=\"https://i.stack.imgur.com/OQpTJ.gif\" alt=\"http://multithreaded.stitchfix.com/blog/2015/03/11/word-is-worth-a-thousand-vectors/\"></p>\n\n<p>Here each direction encode certain semantic features. The same can be done in 3d</p>\n\n<p><a href=\"https://i.stack.imgur.com/ZcNDo.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ZcNDo.png\" alt=\"https://www.tensorflow.org/versions/master/images/linear-relationships.png\"></a><br>\n<sub>(source: <a href=\"https://www.tensorflow.org/versions/master/images/linear-relationships.png\" rel=\"nofollow noreferrer\">tensorflow.org</a>)</sub>  </p>\n\n<p>See how in this example past tense is located in a certain position respective to its participle. The same for gender. Same with countries and capitals.</p>\n\n<p>In the word embedding world, older and more naive models, didn't have this property. </p>\n\n<p>See this Stanford lecture for more details.\n<a href=\"https://www.youtube.com/watch?v=T8tQZChniMk\" rel=\"nofollow noreferrer\">Simple Word Vector representations: word2vec, GloVe</a></p>\n\n<p>They only were limited to clustering similar words together without regard for semantics (gender or verb tense weren't encoded as directions). Unsurprisingly models which have a semantic encoding as directions in lower dimensions are more accurate. And more importantly, they can be used to explore each data point in a more appropriate way. </p>\n\n<p>In this particular case, I don't think t-SNE is used to aid classification per se, it's more like a sanity check for your model and sometimes to find insight in the particular corpus you are using. As for the problem of the vectors not being in original feature space anymore. Richard Socher explains in the lecture (link above) that low dimensional vectors share statistical distributions with its own larger representation as well as other statistical properties which make plausible visually analyse in lower dimensions embedding vectors.</p>\n\n<p><strong>Additional resources &amp; Image Sources:</strong></p>\n\n<ol>\n<li><p><a href=\"http://multithreaded.stitchfix.com/blog/2015/03/11/word-is-worth-a-thousand-vectors/\" rel=\"nofollow noreferrer\">http://multithreaded.stitchfix.com/blog/2015/03/11/word-is-worth-a-thousand-vectors/</a></p></li>\n<li><p><a href=\"https://www.tensorflow.org/tutorials/word2vec/index.html#motivation_why_learn_word_embeddings%3F\" rel=\"nofollow noreferrer\">https://www.tensorflow.org/tutorials/word2vec/index.html#motivation_why_learn_word_embeddings%3F</a></p></li>\n<li><p><a href=\"http://deeplearning4j.org/word2vec.html\" rel=\"nofollow noreferrer\">http://deeplearning4j.org/word2vec.html</a></p></li>\n<li><p><a href=\"https://www.tensorflow.org/tutorials/word2vec/index.html#motivation_why_learn_word_embeddings%3F\" rel=\"nofollow noreferrer\">https://www.tensorflow.org/tutorials/word2vec/index.html#motivation_why_learn_word_embeddings%3F</a></p></li>\n</ol>\n",
                        "",
                        "10"
                    ],
                    [
                        "9120",
                        "2",
                        "9038",
                        "",
                        "",
                        "<p>Excellent question. In chapter 4 of \"Illuminating the Path, The Research and Development Agenda for Visual Analytics\" by James J. Thomas and Kristin A. Cook is a discussion on data representations and data transformations. In my research I have approached this question in the context of PCA and factor analysis. My brief answer is that the visualizations are useful if one has the data transformation to move from the visualization space to the original data space. This would additionally be conducted within a visual analytics framework.</p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "False"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "1333",
            "_score": 5.1791377,
            "_source": {
                "title": "Classifier and Technique to use for large number of categories",
                "content": "Classifier and Technique to use for large number of categories <p>I am designing a scikit learn classifier for a sequence labelling task which has 5000+ categories and training data is at least 80 million and may grow upto an additional 100 million each year. I have already tried with all the categories but it generates classifiers in the order of 100s of GBs binary file. So I think that having one classifier for each category would be helpful and would also help me to fine tune features for each category thereby improving accuracy, but this means 5k+ classifiers for each of these categories. So how to handle this large data requirements and which incremental classifiers to use for this case , considering the fact that I will keep on getting additional training data as well as may discover new categories?</p>\n\n<p>The number of features are about 100+ and due to the sequence labelling task contiguous sequence of training samples share same features values. The feature values are mostly text based and most are categorical with long text based values  with large cardinality i.e many features may have huge number of possible values. </p>\n\n<p>The available RAM IS 32gb with 8 core CPU. On a small scale I tried Multinomial NB and linear SGD with sparse matrices which are extremely sparse. Used the scikit learns Dictvectorizer to vectorize the feature dictionary. Also will pandas dataframes help to optimize the overall configuration?</p>\n\n<p>Due to the scale of data involved I have only used about 20% of the data. And the features itself are 56GB of data from the 500MB input data. For the restricted training data, The precision too is very low does not reach above 12% with a very low  recall too(1-2%). Have gone through vowpal wabbit and  found the SEARN task but it seems that it is now no longer available in the latest version .</p>\n <machine-learning><bigdata><dataset><scikit-learn><categorical-data><p>This sounds like a pretty gnarly problem, so a lot of finesse will be needed to solve it.  @J\u00e9r\u00e9mie Clos has some good points, but I wanted to add some more general thoughts...</p>\n\n<p>With the size of your problem, you might want to think about a scalable framework like <a href=\"http://mahout.apache.org/\" rel=\"nofollow\">Mahout</a> or <a href=\"http://h2o.ai/\" rel=\"nofollow\">H2O</a> rather than scikit-learn, which is an awesome shared memory library, but does have <a href=\"http://scikit-learn.org/stable/auto_examples/neighbors/plot_approximate_nearest_neighbors_scalability.html\" rel=\"nofollow\">scalability limitations</a>.</p>\n\n<p>With a categorical feature with cardinality of 5000 and 80 million training cases, a uniform distribution will only give you 16,000 training cases for each positive result.  However, <strong>the distribution probably isn't uniform</strong>.  I suggest that you eliminate the least common categories until you have thrown out 5% of the data and assess the cardinality of the remaining 95%.  This may give you a better clue about how to proceed i.e. what percent of the cardinality remains? </p>\n\n<p>Most <a href=\"http://scikit-learn.org/stable/modules/multiclass.html\" rel=\"nofollow\">multiclass classification algorithms</a> are just lots of binary classifiers that are combined to produce a composite result, so will essentially do the work for you of splitting up the problem, binarizing the data (aka one-hot encoding), and training the classifiers, so you may not need to explicitly perform this splitting step.  Two exceptions to this, i.e. classifiers that can handle the multi-class problem intrinsically are <a href=\"http://scikit-learn.org/stable/modules/tree.html\" rel=\"nofollow\">decision trees</a> and <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" rel=\"nofollow\">random forests</a> (<a href=\"https://mahout.apache.org/users/classification/partial-implementation.html\" rel=\"nofollow\">Mahout version</a>). I would try both of these and hold them as benchmarks moving forward.</p>\n\n<p>In terms of handling the addition of categories as data is added to the system, you will have to retrain sometimes.  This is sometimes referred to as the <a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3732997/\" rel=\"nofollow\">stability-plasticity dilemma</a>.  The best way to handle this is probably only to make predictions on categories that comprise some threshold of the data and throw out the rest as outlier categories that are not powered well enough to predict on e.g. similar to the sanity check I suggest above.</p>\n\n<p>Hope this helps!</p>\n<p>As a complement to J\u00e9r\u00e9mie Clos' and AN6U5's answers, there are at least two methods helping to cope with a large number of classes:</p>\n\n<ul>\n<li>use a hierarchy, like <em>hierarchical softmax</em>. Instead of having a flat list of categories, one builds a tree of them, then on each node predicts if the correct category is on the left or on the right branch.</li>\n<li>do not classify directly, but first learn an <em>embedding</em> into a lower-dimensional space, where instances of the same class should have close representations. A famous example for this is FaceNet (the use case is face recognition) : they embed the image of a face into a 128 dimensional byte vector. The algorithm to learn this embedding is triplet loss (I've heard of magnet loss as well). Then when presented with a new request, compute its representation (a small vector), and look for the closest vectors in the trainset. This is similar to kNN, or to <a href=\"https://arxiv.org/abs/1607.05691\" rel=\"nofollow noreferrer\">label embedding</a> if each instance belongs to several classes: \"Our method consists in embedding high-dimensional sparse labels onto a lower-dimensional dense sphere of unit-normed vectors, and treating the classification problem as a cosine proximity regression problem on this sphere.\"</li>\n</ul>\n\n<p>The work of <a href=\"http://manikvarma.org/index.html\" rel=\"nofollow noreferrer\">http://manikvarma.org/index.html</a> might be relevant to your problem as well.</p>\n\n<p>Alos of potential use: <a href=\"http://jmlr.org/papers/volume15/gupta14a/gupta14a.pdf\" rel=\"nofollow noreferrer\">http://jmlr.org/papers/volume15/gupta14a/gupta14a.pdf</a> .</p>\n<blockquote>\n  <p>So how to handle this large data requirements and which incremental classifiers to use for this case , considering the fact that I will keep on getting additional training data as well as may discover new categories?</p>\n</blockquote>\n\n<p>I am not familiar with the task you are solving, but have you considered a lazy distance-based learner like k-nn and its variations? It could handle an arbitrary number of categories, learn incrementally and you could keep your model small-ish by using one of the case base maintenance algorithms out there. As for learning new categories, you could use an outlier detection algorithm to see when a new test example doesn't fit in its category (i.e. when it significantly reduces its intra-class consistency).</p>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "8213",
                "question_votes:": "6",
                "question_text:": "<p>I am designing a scikit learn classifier for a sequence labelling task which has 5000+ categories and training data is at least 80 million and may grow upto an additional 100 million each year. I have already tried with all the categories but it generates classifiers in the order of 100s of GBs binary file. So I think that having one classifier for each category would be helpful and would also help me to fine tune features for each category thereby improving accuracy, but this means 5k+ classifiers for each of these categories. So how to handle this large data requirements and which incremental classifiers to use for this case , considering the fact that I will keep on getting additional training data as well as may discover new categories?</p>\n\n<p>The number of features are about 100+ and due to the sequence labelling task contiguous sequence of training samples share same features values. The feature values are mostly text based and most are categorical with long text based values  with large cardinality i.e many features may have huge number of possible values. </p>\n\n<p>The available RAM IS 32gb with 8 core CPU. On a small scale I tried Multinomial NB and linear SGD with sparse matrices which are extremely sparse. Used the scikit learns Dictvectorizer to vectorize the feature dictionary. Also will pandas dataframes help to optimize the overall configuration?</p>\n\n<p>Due to the scale of data involved I have only used about 20% of the data. And the features itself are 56GB of data from the 500MB input data. For the restricted training data, The precision too is very low does not reach above 12% with a very low  recall too(1-2%). Have gone through vowpal wabbit and  found the SEARN task but it seems that it is now no longer available in the latest version .</p>\n",
                "tags": "<machine-learning><bigdata><dataset><scikit-learn><categorical-data>",
                "answers": [
                    [
                        "8239",
                        "2",
                        "8213",
                        "",
                        "",
                        "<p>This sounds like a pretty gnarly problem, so a lot of finesse will be needed to solve it.  @J\u00e9r\u00e9mie Clos has some good points, but I wanted to add some more general thoughts...</p>\n\n<p>With the size of your problem, you might want to think about a scalable framework like <a href=\"http://mahout.apache.org/\" rel=\"nofollow\">Mahout</a> or <a href=\"http://h2o.ai/\" rel=\"nofollow\">H2O</a> rather than scikit-learn, which is an awesome shared memory library, but does have <a href=\"http://scikit-learn.org/stable/auto_examples/neighbors/plot_approximate_nearest_neighbors_scalability.html\" rel=\"nofollow\">scalability limitations</a>.</p>\n\n<p>With a categorical feature with cardinality of 5000 and 80 million training cases, a uniform distribution will only give you 16,000 training cases for each positive result.  However, <strong>the distribution probably isn't uniform</strong>.  I suggest that you eliminate the least common categories until you have thrown out 5% of the data and assess the cardinality of the remaining 95%.  This may give you a better clue about how to proceed i.e. what percent of the cardinality remains? </p>\n\n<p>Most <a href=\"http://scikit-learn.org/stable/modules/multiclass.html\" rel=\"nofollow\">multiclass classification algorithms</a> are just lots of binary classifiers that are combined to produce a composite result, so will essentially do the work for you of splitting up the problem, binarizing the data (aka one-hot encoding), and training the classifiers, so you may not need to explicitly perform this splitting step.  Two exceptions to this, i.e. classifiers that can handle the multi-class problem intrinsically are <a href=\"http://scikit-learn.org/stable/modules/tree.html\" rel=\"nofollow\">decision trees</a> and <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" rel=\"nofollow\">random forests</a> (<a href=\"https://mahout.apache.org/users/classification/partial-implementation.html\" rel=\"nofollow\">Mahout version</a>). I would try both of these and hold them as benchmarks moving forward.</p>\n\n<p>In terms of handling the addition of categories as data is added to the system, you will have to retrain sometimes.  This is sometimes referred to as the <a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3732997/\" rel=\"nofollow\">stability-plasticity dilemma</a>.  The best way to handle this is probably only to make predictions on categories that comprise some threshold of the data and throw out the rest as outlier categories that are not powered well enough to predict on e.g. similar to the sanity check I suggest above.</p>\n\n<p>Hope this helps!</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "24200",
                        "2",
                        "8213",
                        "",
                        "",
                        "<p>As a complement to J\u00e9r\u00e9mie Clos' and AN6U5's answers, there are at least two methods helping to cope with a large number of classes:</p>\n\n<ul>\n<li>use a hierarchy, like <em>hierarchical softmax</em>. Instead of having a flat list of categories, one builds a tree of them, then on each node predicts if the correct category is on the left or on the right branch.</li>\n<li>do not classify directly, but first learn an <em>embedding</em> into a lower-dimensional space, where instances of the same class should have close representations. A famous example for this is FaceNet (the use case is face recognition) : they embed the image of a face into a 128 dimensional byte vector. The algorithm to learn this embedding is triplet loss (I've heard of magnet loss as well). Then when presented with a new request, compute its representation (a small vector), and look for the closest vectors in the trainset. This is similar to kNN, or to <a href=\"https://arxiv.org/abs/1607.05691\" rel=\"nofollow noreferrer\">label embedding</a> if each instance belongs to several classes: \"Our method consists in embedding high-dimensional sparse labels onto a lower-dimensional dense sphere of unit-normed vectors, and treating the classification problem as a cosine proximity regression problem on this sphere.\"</li>\n</ul>\n\n<p>The work of <a href=\"http://manikvarma.org/index.html\" rel=\"nofollow noreferrer\">http://manikvarma.org/index.html</a> might be relevant to your problem as well.</p>\n\n<p>Alos of potential use: <a href=\"http://jmlr.org/papers/volume15/gupta14a/gupta14a.pdf\" rel=\"nofollow noreferrer\">http://jmlr.org/papers/volume15/gupta14a/gupta14a.pdf</a> .</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "8233",
                        "2",
                        "8213",
                        "",
                        "",
                        "<blockquote>\n  <p>So how to handle this large data requirements and which incremental classifiers to use for this case , considering the fact that I will keep on getting additional training data as well as may discover new categories?</p>\n</blockquote>\n\n<p>I am not familiar with the task you are solving, but have you considered a lazy distance-based learner like k-nn and its variations? It could handle an arbitrary number of categories, learn incrementally and you could keep your model small-ish by using one of the case base maintenance algorithms out there. As for learning new categories, you could use an outlier detection algorithm to see when a new test example doesn't fit in its category (i.e. when it significantly reduces its intra-class consistency).</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "False"
        }
    ]
}