{
    "module": "numpy",
    "function": "numpy.reshape",
    "stackoverflow": [
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10119",
            "_score": 12.338657,
            "_source": {
                "title": "Are view() in Pytorch and reshape() in Numpy similar?",
                "content": "Are view() in Pytorch and reshape() in Numpy similar? <p>Are <code>view()</code> in torch and <code>reshape()</code> in Numpy similar?</p>\n\n<p><code>view()</code> is applied on torch tensors to change their shape and <code>reshape()</code> is a numpy function to change shape of ndarrays.</p>\n <deep-learning><numpy><pytorch><reshape><p>Yes, for most intents and purposes, they can do the same job. From <a href=\"https://discuss.pytorch.org/t/equivalent-of-np-reshape-in-pytorch/144\" rel=\"nofollow noreferrer\">this link</a>, an example:</p>\n\n<pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; t = torch.ones((2, 3, 4))\n&gt;&gt;&gt; t.size()\ntorch.Size([2, 3, 4])\n&gt;&gt;&gt; t.view(-1, 12).size()\ntorch.Size([2, 12])\n</code></pre>\n\n<hr>\n\n<p>If you are concerned with memory allocation, here is <a href=\"https://stackoverflow.com/questions/42479902/how-view-method-works-for-tensor-in-torch\">another answer on StackOverflow</a> with a little more information. PyTorch's <code>view</code> function actually does what the name suggests - <a href=\"https://stackoverflow.com/questions/42479902/how-view-method-works-for-tensor-in-torch\">returns a <em>view</em></a> to the data. The data is not altered in memory as far as I can see.</p>\n\n<p>In <em>numpy</em>, the <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html#numpy.reshape\" rel=\"nofollow noreferrer\"><code>reshape</code></a> function does not guarantee that a copy of the data is made or not. It will depend on the original shape of the array and the target shape. Have a <a href=\"https://stackoverflow.com/questions/36995289/when-will-numpy-copy-the-array-when-using-reshape\">look here</a> for further information.</p>\n",
                "codes": [
                    [
                        ">>> import torch\n>>> t = torch.ones((2, 3, 4))\n>>> t.size()\ntorch.Size([2, 3, 4])\n>>> t.view(-1, 12).size()\ntorch.Size([2, 12])\n"
                    ]
                ],
                "question_id:": "36655",
                "question_votes:": "2",
                "question_text:": "<p>Are <code>view()</code> in torch and <code>reshape()</code> in Numpy similar?</p>\n\n<p><code>view()</code> is applied on torch tensors to change their shape and <code>reshape()</code> is a numpy function to change shape of ndarrays.</p>\n",
                "tags": "<deep-learning><numpy><pytorch><reshape>",
                "answers": [
                    [
                        "36657",
                        "2",
                        "36655",
                        "",
                        "",
                        "<p>Yes, for most intents and purposes, they can do the same job. From <a href=\"https://discuss.pytorch.org/t/equivalent-of-np-reshape-in-pytorch/144\" rel=\"nofollow noreferrer\">this link</a>, an example:</p>\n\n<pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; t = torch.ones((2, 3, 4))\n&gt;&gt;&gt; t.size()\ntorch.Size([2, 3, 4])\n&gt;&gt;&gt; t.view(-1, 12).size()\ntorch.Size([2, 12])\n</code></pre>\n\n<hr>\n\n<p>If you are concerned with memory allocation, here is <a href=\"https://stackoverflow.com/questions/42479902/how-view-method-works-for-tensor-in-torch\">another answer on StackOverflow</a> with a little more information. PyTorch's <code>view</code> function actually does what the name suggests - <a href=\"https://stackoverflow.com/questions/42479902/how-view-method-works-for-tensor-in-torch\">returns a <em>view</em></a> to the data. The data is not altered in memory as far as I can see.</p>\n\n<p>In <em>numpy</em>, the <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html#numpy.reshape\" rel=\"nofollow noreferrer\"><code>reshape</code></a> function does not guarantee that a copy of the data is made or not. It will depend on the original shape of the array and the target shape. Have a <a href=\"https://stackoverflow.com/questions/36995289/when-will-numpy-copy-the-array-when-using-reshape\">look here</a> for further information.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16771",
            "_score": 11.618893,
            "_source": {
                "title": "numpy array reshape question",
                "content": "numpy array reshape question <p>Let's say that I have image data with shape <span class=\"math-container\">$(32, 32, 3)$</span> and <span class=\"math-container\">$50000$</span></p>\n\n<ol>\n<li>If I would like to reshape it to <span class=\"math-container\">$(50000, 3, 32, 32)$</span> what should I do? </li>\n</ol>\n\n<p>I tried <code>np.transpose(0, 3, 1, 2)</code> but it failed.</p>\n\n<ol start=\"2\">\n<li>If I would like to print the number <span class=\"math-container\">$3$</span> from <span class=\"math-container\">$(50000, 3, 32, 32)$</span> what should I do?</li>\n</ol>\n <numpy><image-preprocessing><reshape><p>If <code>image</code> is a numpy object:</p>\n\n<pre><code>image = image.reshape((50000,3,32,32))\n</code></pre>\n\n<p>and then print:</p>\n\n<pre><code>print(image[:,3,:,:])\n</code></pre>\n",
                "codes": [
                    [
                        "image = image.reshape((50000,3,32,32))\n",
                        "print(image[:,3,:,:])\n"
                    ]
                ],
                "question_id:": "54815",
                "question_votes:": "1",
                "question_text:": "<p>Let's say that I have image data with shape <span class=\"math-container\">$(32, 32, 3)$</span> and <span class=\"math-container\">$50000$</span></p>\n\n<ol>\n<li>If I would like to reshape it to <span class=\"math-container\">$(50000, 3, 32, 32)$</span> what should I do? </li>\n</ol>\n\n<p>I tried <code>np.transpose(0, 3, 1, 2)</code> but it failed.</p>\n\n<ol start=\"2\">\n<li>If I would like to print the number <span class=\"math-container\">$3$</span> from <span class=\"math-container\">$(50000, 3, 32, 32)$</span> what should I do?</li>\n</ol>\n",
                "tags": "<numpy><image-preprocessing><reshape>",
                "answers": [
                    [
                        "54822",
                        "2",
                        "54815",
                        "",
                        "",
                        "<p>If <code>image</code> is a numpy object:</p>\n\n<pre><code>image = image.reshape((50000,3,32,32))\n</code></pre>\n\n<p>and then print:</p>\n\n<pre><code>print(image[:,3,:,:])\n</code></pre>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17827",
            "_score": 10.974089,
            "_source": {
                "title": "Error in changing datetime format",
                "content": "Error in changing datetime format <p>I am getting errors trying to convert datetime format. My code is:</p>\n\n<pre><code>data = pd.read_csv('s3://sagemaker-us-east-1-881385135648/all_data.csv', encoding='utf8',parse_dates=True, low_memory=False,na_filter=True)\n</code></pre>\n\n<p>then I turn it into a numpy array with <code>data=data.values</code> and then to <code>data=np.datetime64()</code> datetime but I get this error:</p>\n\n<blockquote>\n  <p>Expected 2D array, got scalar array instead:\n  array=-9.223372036854776e+18. Reshape your data either using\n  array.reshape(-1, 1) if your data has a single feature or\n  array.reshape(1, -1) if it contains a single sample.\"</p>\n</blockquote>\n\n<p>What is causing this error and what can I do about it?</p>\n <pandas><numpy>",
                "codes": [],
                "question_id:": "57074",
                "question_votes:": "",
                "question_text:": "<p>I am getting errors trying to convert datetime format. My code is:</p>\n\n<pre><code>data = pd.read_csv('s3://sagemaker-us-east-1-881385135648/all_data.csv', encoding='utf8',parse_dates=True, low_memory=False,na_filter=True)\n</code></pre>\n\n<p>then I turn it into a numpy array with <code>data=data.values</code> and then to <code>data=np.datetime64()</code> datetime but I get this error:</p>\n\n<blockquote>\n  <p>Expected 2D array, got scalar array instead:\n  array=-9.223372036854776e+18. Reshape your data either using\n  array.reshape(-1, 1) if your data has a single feature or\n  array.reshape(1, -1) if it contains a single sample.\"</p>\n</blockquote>\n\n<p>What is causing this error and what can I do about it?</p>\n",
                "tags": "<pandas><numpy>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12703",
            "_score": 10.545555,
            "_source": {
                "title": "predict future value in every one hour using (t+60 minutes) LSTM neural network in python",
                "content": "predict future value in every one hour using (t+60 minutes) LSTM neural network in python <p>I have a data csv file including with three inputs and two output with time series. Here data took an every one hour one hour. So I need to predict my next future value at t+60 according to the previous input value and at that time period if having new input value using regression neural network. So I choose LSTM neural network to predict next future value. But I don't know how to give time period to predict my future value.\nCan anyone suggest me how to solve this problem? \nCan anyone give me any examples to clear out this problem?\nHere that prediction value will come as input value (g).</p>\n\n<p>subset of my csv file </p>\n\n<p><a href=\"https://i.stack.imgur.com/ET1KL.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ET1KL.png\" alt=\"enter image description here\"></a></p>\n\n<p>here I upload my code;</p>\n\n<pre><code>def create_data(data, look_back=1):\ndataX, dataY = [], []\nfor i in range(len(data) - look_back - 1):\n    a = data[i:(i + look_back), :]\n    dataX.append(a)\n    dataY.append(data[i + look_back, 2])\nreturn numpy.array(dataX), numpy.array(dataY)\n\ndata = pd.DataFrame(data,columns=['g','p','c'])\nnumpy.random.seed(7)\ndata = data.values\nscaler = MinMaxScaler(feature_range=(0, 1))\ndata = scaler.fit_transform(data)\ntrain_size = int(len(data) * 0.67) \ntest_size = len(data) - train_size\ntrain, test = data[0:train_size, :], data[train_size:len(data), :]\n# reshape into X=t and Y=t+1\nlook_back = 3\ntrainX, trainY = create_data(train, look_back)  \ntestX, testY = create_data(test, look_back)\n# reshape input to be  [samples, time steps, features]\ntrainX = numpy.reshape(trainX, (trainX.shape[0], look_back, 3))\ntestX = numpy.reshape(testX, (testX.shape[0],look_back, 3))\nmodel = Sequential()\nmodel.add(LSTM(6, input_shape=(look_back,3)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nhistory= model.fit(trainX, trainY,validation_split=0.33, nb_epoch=10, \nbatch_size=30)\ntrainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\ntrainPredict_extended = numpy.zeros((len(trainPredict),3))\ntrainPredict_extended[:,2] = trainPredict[:,0]\ntrainPredict = scaler.inverse_transform(trainPredict_extended) [:,2]  \nprint(trainPredict)\ntestPredict_extended = numpy.zeros((len(testPredict),3))\ntestPredict_extended[:,2] = testPredict[:,0]\ntestPredict = scaler.inverse_transform(testPredict_extended)[:,2]   \ntrainY_extended = numpy.zeros((len(trainY),3))\ntrainY_extended[:,2]=trainY\ntrainY=scaler.inverse_transform(trainY_extended)[:,2]\ntestY_extended = numpy.zeros((len(testY),3))\ntestY_extended[:,2]=testY\ntestY=scaler.inverse_transform(testY_extended)[:,2]\ntrainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY, testPredict))\nprint('Test Score: %.2f RMSE' % (testScore))\n# shift train predictions for plotting\ntrainPredictPlot = numpy.empty_like(data)\ntrainPredictPlot[:, :] = numpy.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, 2] = trainPredict\n\n# shift test predictions for plotting\ntestPredictPlot = numpy.empty_like(data)\ntestPredictPlot[:, :] = numpy.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(data)-1, 2] = \ntestPredict\n</code></pre>\n <python><neural-network><keras><regression><lstm><p>One option is to :</p>\n\n<ol>\n<li>Break data into constant-frequency observations (E.g.: Assume that g,p,c,out are same for all time periods between two observations). With this, you will get samples every N minutes. </li>\n<li>Training data will then be a set of [Last M observations till T, Observation for T + 60]</li>\n</ol>\n\n<p>This Train and test data can be fed into a network.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "44360",
                "question_votes:": "",
                "question_text:": "<p>I have a data csv file including with three inputs and two output with time series. Here data took an every one hour one hour. So I need to predict my next future value at t+60 according to the previous input value and at that time period if having new input value using regression neural network. So I choose LSTM neural network to predict next future value. But I don't know how to give time period to predict my future value.\nCan anyone suggest me how to solve this problem? \nCan anyone give me any examples to clear out this problem?\nHere that prediction value will come as input value (g).</p>\n\n<p>subset of my csv file </p>\n\n<p><a href=\"https://i.stack.imgur.com/ET1KL.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ET1KL.png\" alt=\"enter image description here\"></a></p>\n\n<p>here I upload my code;</p>\n\n<pre><code>def create_data(data, look_back=1):\ndataX, dataY = [], []\nfor i in range(len(data) - look_back - 1):\n    a = data[i:(i + look_back), :]\n    dataX.append(a)\n    dataY.append(data[i + look_back, 2])\nreturn numpy.array(dataX), numpy.array(dataY)\n\ndata = pd.DataFrame(data,columns=['g','p','c'])\nnumpy.random.seed(7)\ndata = data.values\nscaler = MinMaxScaler(feature_range=(0, 1))\ndata = scaler.fit_transform(data)\ntrain_size = int(len(data) * 0.67) \ntest_size = len(data) - train_size\ntrain, test = data[0:train_size, :], data[train_size:len(data), :]\n# reshape into X=t and Y=t+1\nlook_back = 3\ntrainX, trainY = create_data(train, look_back)  \ntestX, testY = create_data(test, look_back)\n# reshape input to be  [samples, time steps, features]\ntrainX = numpy.reshape(trainX, (trainX.shape[0], look_back, 3))\ntestX = numpy.reshape(testX, (testX.shape[0],look_back, 3))\nmodel = Sequential()\nmodel.add(LSTM(6, input_shape=(look_back,3)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nhistory= model.fit(trainX, trainY,validation_split=0.33, nb_epoch=10, \nbatch_size=30)\ntrainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\ntrainPredict_extended = numpy.zeros((len(trainPredict),3))\ntrainPredict_extended[:,2] = trainPredict[:,0]\ntrainPredict = scaler.inverse_transform(trainPredict_extended) [:,2]  \nprint(trainPredict)\ntestPredict_extended = numpy.zeros((len(testPredict),3))\ntestPredict_extended[:,2] = testPredict[:,0]\ntestPredict = scaler.inverse_transform(testPredict_extended)[:,2]   \ntrainY_extended = numpy.zeros((len(trainY),3))\ntrainY_extended[:,2]=trainY\ntrainY=scaler.inverse_transform(trainY_extended)[:,2]\ntestY_extended = numpy.zeros((len(testY),3))\ntestY_extended[:,2]=testY\ntestY=scaler.inverse_transform(testY_extended)[:,2]\ntrainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY, testPredict))\nprint('Test Score: %.2f RMSE' % (testScore))\n# shift train predictions for plotting\ntrainPredictPlot = numpy.empty_like(data)\ntrainPredictPlot[:, :] = numpy.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, 2] = trainPredict\n\n# shift test predictions for plotting\ntestPredictPlot = numpy.empty_like(data)\ntestPredictPlot[:, :] = numpy.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(data)-1, 2] = \ntestPredict\n</code></pre>\n",
                "tags": "<python><neural-network><keras><regression><lstm>",
                "answers": [
                    [
                        "44365",
                        "2",
                        "44360",
                        "",
                        "",
                        "<p>One option is to :</p>\n\n<ol>\n<li>Break data into constant-frequency observations (E.g.: Assume that g,p,c,out are same for all time periods between two observations). With this, you will get samples every N minutes. </li>\n<li>Training data will then be a set of [Last M observations till T, Observation for T + 60]</li>\n</ol>\n\n<p>This Train and test data can be fed into a network.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8474",
            "_score": 10.204697,
            "_source": {
                "title": "Keras: apply masking to non-sequential data",
                "content": "Keras: apply masking to non-sequential data <p>I am trying to do multi-label classification via LSTM in Keras.</p>\n\n<p>As a simple example, suppose I have sequences of length 4. Each sequence element is a 3x3 numpy array with values 0, 1, or -1, like this:</p>\n\n<pre><code>-1  1 -1\n 0 -1  0\n 1  0 -1 \n</code></pre>\n\n<p>The -1 values indicate that this position of the numpy array should be ignored (no weight calculation, no associated gradient update, no contribution to the cost function, etc). The positions of the -1 values are the same in each 3x3 numpy array. The 0/1 values are the labels for each position.</p>\n\n<p>How can I tell Keras to ignore the values -1 in my input? I have tried one-hot encoding each 0/1/-1 value and using a mask that way (since masking does not accept 1D input). I also saw that masking is applied to dimension 1 of the (num_samples, num_timesteps, num_features) input shape, which is not what I want: I want it applied to the features (the 3x3 numpy arrays). </p>\n\n<p>Does the below code do what I want it to do?</p>\n\n<pre><code>from keras.layers import Input, Masking, LSTM, Dense, Flatten\nfrom keras.models import Model\nimport numpy as np\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.utils import to_categorical\nfrom keras.optimizers import adam\n\n#Creating some sample data\n\n#Matrix has size 3*3, values -1, 0, 1\nX = np.random.rand(3, 3).flatten()\nX[X &lt; 0.2] = 0.\nX[(X &gt;= 0.2) &amp; (X &lt; 0.4)] = 1.\nX[X &gt;= 0.4] = -1\n\nX2 = np.random.rand(4, 3*3)\nfor i in range(X2.shape[0]):\n    X2[i,:][(X==-1.)] = -1.\n    X2[i,:][(X !=-1.)] = 0.\n    tobeone = int(len(np.where(X2[i,:] == 0.)[0])*0.5)\n    selected_ones = np.random.choice(np.where(X2[i,:] == 0.)[0], tobeone)\n    X2[i,selected_ones] = 1.\n\nX = np.reshape(X, ((1, 3*3)))\nX_new = np.concatenate((X, X2), axis=0)\nY = X_new[4,:]\nX = X_new[:4,:]\n\n#Categories are 0, 1, -1 one-hot encoded\nX = to_categorical(X, num_classes=3)\nX = np.reshape(X, (4, 3, 3*3)) #X needs to be shape (num_samples, num_timesteps, num_features), not sure if I have this right\n\nY = to_categorical(Y, num_classes=3)\ny_true = np.reshape(Y, (1, 3, 3*3)) #predicting a single timestep\n\n#Building the model\n\nmask_val = np.tile([0,0,1], 3*3).reshape((3, 3*3))\ninput_tensor = Input(shape=(3, 3*3))\nmasking_input = Masking(mask_value=mask_val)(input_tensor)\nlstm = LSTM(1, return_sequences=True)(masking_input)\noutput = Dense(3*3, activation='sigmoid')(lstm)\n\nmodel = Model(input_tensor, output)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\nprint(model.summary())\n\ny_pred = model.predict(X)\n\n#See if the model's loss is the same as the unmasked loss (shouldn't be)\nprint(model.evaluate(np.expand_dims(X[0,:,:], axis=0), y_true))\n</code></pre>\n <keras><time-series><lstm><multilabel-classification>",
                "codes": [],
                "question_id:": "30981",
                "question_votes:": "1",
                "question_text:": "<p>I am trying to do multi-label classification via LSTM in Keras.</p>\n\n<p>As a simple example, suppose I have sequences of length 4. Each sequence element is a 3x3 numpy array with values 0, 1, or -1, like this:</p>\n\n<pre><code>-1  1 -1\n 0 -1  0\n 1  0 -1 \n</code></pre>\n\n<p>The -1 values indicate that this position of the numpy array should be ignored (no weight calculation, no associated gradient update, no contribution to the cost function, etc). The positions of the -1 values are the same in each 3x3 numpy array. The 0/1 values are the labels for each position.</p>\n\n<p>How can I tell Keras to ignore the values -1 in my input? I have tried one-hot encoding each 0/1/-1 value and using a mask that way (since masking does not accept 1D input). I also saw that masking is applied to dimension 1 of the (num_samples, num_timesteps, num_features) input shape, which is not what I want: I want it applied to the features (the 3x3 numpy arrays). </p>\n\n<p>Does the below code do what I want it to do?</p>\n\n<pre><code>from keras.layers import Input, Masking, LSTM, Dense, Flatten\nfrom keras.models import Model\nimport numpy as np\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.utils import to_categorical\nfrom keras.optimizers import adam\n\n#Creating some sample data\n\n#Matrix has size 3*3, values -1, 0, 1\nX = np.random.rand(3, 3).flatten()\nX[X &lt; 0.2] = 0.\nX[(X &gt;= 0.2) &amp; (X &lt; 0.4)] = 1.\nX[X &gt;= 0.4] = -1\n\nX2 = np.random.rand(4, 3*3)\nfor i in range(X2.shape[0]):\n    X2[i,:][(X==-1.)] = -1.\n    X2[i,:][(X !=-1.)] = 0.\n    tobeone = int(len(np.where(X2[i,:] == 0.)[0])*0.5)\n    selected_ones = np.random.choice(np.where(X2[i,:] == 0.)[0], tobeone)\n    X2[i,selected_ones] = 1.\n\nX = np.reshape(X, ((1, 3*3)))\nX_new = np.concatenate((X, X2), axis=0)\nY = X_new[4,:]\nX = X_new[:4,:]\n\n#Categories are 0, 1, -1 one-hot encoded\nX = to_categorical(X, num_classes=3)\nX = np.reshape(X, (4, 3, 3*3)) #X needs to be shape (num_samples, num_timesteps, num_features), not sure if I have this right\n\nY = to_categorical(Y, num_classes=3)\ny_true = np.reshape(Y, (1, 3, 3*3)) #predicting a single timestep\n\n#Building the model\n\nmask_val = np.tile([0,0,1], 3*3).reshape((3, 3*3))\ninput_tensor = Input(shape=(3, 3*3))\nmasking_input = Masking(mask_value=mask_val)(input_tensor)\nlstm = LSTM(1, return_sequences=True)(masking_input)\noutput = Dense(3*3, activation='sigmoid')(lstm)\n\nmodel = Model(input_tensor, output)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\nprint(model.summary())\n\ny_pred = model.predict(X)\n\n#See if the model's loss is the same as the unmasked loss (shouldn't be)\nprint(model.evaluate(np.expand_dims(X[0,:,:], axis=0), y_true))\n</code></pre>\n",
                "tags": "<keras><time-series><lstm><multilabel-classification>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11079",
            "_score": 10.194614,
            "_source": {
                "title": "Python - Converting 3D numpy array to 2D",
                "content": "Python - Converting 3D numpy array to 2D <p>I have a 3D matrix like this:</p>\n\n<pre><code>array([[[ 0,  1],\n      [ 2,  3]],\n\n      [[ 4,  5],\n      [ 6,  7]],\n\n      [[ 8,  9],\n      [10, 11]],\n\n      [[12, 13],\n      [14, 15]]])\n</code></pre>\n\n<p>and would like to stack them in a grid format, ending up with:</p>\n\n<pre><code> array([[ 0,  1],\n        [ 2,  3],\n        [ 4,  5],\n        [ 6,  7],\n        [ 8,  9],\n        [10, 11],\n        [12, 13],\n        [14, 15]])\n</code></pre>\n\n<p>Currently, I'm using numpy as a library.</p>\n <python><numpy><p>I suggest you to visit this <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.squeeze.html\" rel=\"nofollow noreferrer\">link</a>\nalso for this case would work np.reshape((-1,2))</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "39121",
                "question_votes:": "2",
                "question_text:": "<p>I have a 3D matrix like this:</p>\n\n<pre><code>array([[[ 0,  1],\n      [ 2,  3]],\n\n      [[ 4,  5],\n      [ 6,  7]],\n\n      [[ 8,  9],\n      [10, 11]],\n\n      [[12, 13],\n      [14, 15]]])\n</code></pre>\n\n<p>and would like to stack them in a grid format, ending up with:</p>\n\n<pre><code> array([[ 0,  1],\n        [ 2,  3],\n        [ 4,  5],\n        [ 6,  7],\n        [ 8,  9],\n        [10, 11],\n        [12, 13],\n        [14, 15]])\n</code></pre>\n\n<p>Currently, I'm using numpy as a library.</p>\n",
                "tags": "<python><numpy>",
                "answers": [
                    [
                        "39122",
                        "2",
                        "39121",
                        "",
                        "",
                        "<p>I suggest you to visit this <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.squeeze.html\" rel=\"nofollow noreferrer\">link</a>\nalso for this case would work np.reshape((-1,2))</p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9997",
            "_score": 9.955563,
            "_source": {
                "title": "understanding the filter function in convolution neural network",
                "content": "understanding the filter function in convolution neural network <p>I am trying to follow following tutorial accessible with <a href=\"https://github.com/udacity/aind2-cnn/blob/master/conv-visualization/conv_visualization.ipynb\" rel=\"nofollow noreferrer\">This Link</a></p>\n\n<p>Under 3rd Heading, \"3. Visualize the Activation Maps for Each Filter\" we can see the following function</p>\n\n<pre><code>def apply_filter(img, index, filter_list, ax):\n    # set the weights of the filter in the convolutional layer to filter_list[i]\n    model.layers[0].set_weights([np.reshape(filter_list[i], (4,4,1,1)), np.array([0])])\n    # plot the corresponding activation map\n    ax.imshow(np.squeeze(model.predict(np.reshape(img, (1, img.shape[0], img.shape[1], 1)))), cmap='gray')\n</code></pre>\n\n<p>I understood what they are trying to do. They are applying the filter's and trying to show the output after applying the filter. But, what i don't understand is the following line</p>\n\n<pre><code>model.layers[0].set_weights([np.reshape(filter_list[i], (4,4,1,1)), np.array([0])])\n</code></pre>\n\n<p>What does it mean to assign weights here and also, why are they reshaping the filter which is of <code>4x4</code> to <code>4x4x1x1</code>. </p>\n <cnn><convolution><p>That line of code is turning the filters from the <code>filter_vals</code> list into the weights corresponding to a 2D convolutional layer so you can see what it looks like to apply some traditional filters from computer vision to an image. The output you see is what that layer would produce after applying the displayed filter on an image passed through that layer.</p>\n\n<p>The reshape is necessary as Keras expects a dimension for the channel (we only have one channel since it's a grayscale image) and for the batch, which is why the code adds those two dummy dimensions. </p>\n\n<p>Also there's a bug in that function:</p>\n\n<p><code>model.layers[0].set_weights([np.reshape(filter_list[i], (4,4,1,1)), np.array([0])])</code></p>\n\n<p>should be</p>\n\n<p><code>model.layers[0].set_weights([np.reshape(filter_list[index], (4,4,1,1)), np.array([0])])</code></p>\n\n<p>Hope that helps!</p>\n<p>The function <code>set_weights</code> on a Keras layer requires the shape of the inputs to match the shape of the weights which you are replacing. You can find out which dimensions these are by calling the <code>get_weights</code> method on the layer in which you are interested.</p>\n\n<p>In that tutorial, it would look something like the following. We only need the first element returned by get_weights(), hence the <code>[0]</code>. We then see the shape of it:</p>\n\n<pre><code>In [7]: model.layers[0].get_weights[0].shape\n(4, 4, 1, 1)\n</code></pre>\n\n<p>So the person who wrote that tutorial needed to match that shape and, as it is only considering one layer of the defined model, it is able to be hard-coded in their example.</p>\n\n<hr>\n\n<p>Here are the docstrings for the two main functions I mentioned above:</p>\n\n<p><strong>set_weights()</strong></p>\n\n<pre><code>In [8]: l1.set_weights?\n\nSignature: l1.set_weights(weights)\nDocstring:\nSets the weights of the layer, from Numpy arrays.\n\n# Arguments\n    weights: a list of Numpy arrays. The number\n        of arrays and their shape must match\n        number of the dimensions of the weights\n        of the layer (i.e. it should match the\n        output of `get_weights`).\n\n# Raises\n    ValueError: If the provided weights list does not match the\n        layer's specifications.\n</code></pre>\n\n<p><strong>get_weights()</strong></p>\n\n<pre><code>In [9]: l1.get_weights?\nSignature: l1.get_weights()\nDocstring:\nReturns the current weights of the layer.\n\n# Returns\n    Weights values as a list of numpy arrays\n</code></pre>\n",
                "codes": [
                    [],
                    [
                        "In [7]: model.layers[0].get_weights[0].shape\n(4, 4, 1, 1)\n",
                        "In [8]: l1.set_weights?\n\nSignature: l1.set_weights(weights)\nDocstring:\nSets the weights of the layer, from Numpy arrays.\n\n# Arguments\n    weights: a list of Numpy arrays. The number\n        of arrays and their shape must match\n        number of the dimensions of the weights\n        of the layer (i.e. it should match the\n        output of `get_weights`).\n\n# Raises\n    ValueError: If the provided weights list does not match the\n        layer's specifications.\n",
                        "In [9]: l1.get_weights?\nSignature: l1.get_weights()\nDocstring:\nReturns the current weights of the layer.\n\n# Returns\n    Weights values as a list of numpy arrays\n"
                    ]
                ],
                "question_id:": "36365",
                "question_votes:": "2",
                "question_text:": "<p>I am trying to follow following tutorial accessible with <a href=\"https://github.com/udacity/aind2-cnn/blob/master/conv-visualization/conv_visualization.ipynb\" rel=\"nofollow noreferrer\">This Link</a></p>\n\n<p>Under 3rd Heading, \"3. Visualize the Activation Maps for Each Filter\" we can see the following function</p>\n\n<pre><code>def apply_filter(img, index, filter_list, ax):\n    # set the weights of the filter in the convolutional layer to filter_list[i]\n    model.layers[0].set_weights([np.reshape(filter_list[i], (4,4,1,1)), np.array([0])])\n    # plot the corresponding activation map\n    ax.imshow(np.squeeze(model.predict(np.reshape(img, (1, img.shape[0], img.shape[1], 1)))), cmap='gray')\n</code></pre>\n\n<p>I understood what they are trying to do. They are applying the filter's and trying to show the output after applying the filter. But, what i don't understand is the following line</p>\n\n<pre><code>model.layers[0].set_weights([np.reshape(filter_list[i], (4,4,1,1)), np.array([0])])\n</code></pre>\n\n<p>What does it mean to assign weights here and also, why are they reshaping the filter which is of <code>4x4</code> to <code>4x4x1x1</code>. </p>\n",
                "tags": "<cnn><convolution>",
                "answers": [
                    [
                        "36374",
                        "2",
                        "36365",
                        "",
                        "",
                        "<p>That line of code is turning the filters from the <code>filter_vals</code> list into the weights corresponding to a 2D convolutional layer so you can see what it looks like to apply some traditional filters from computer vision to an image. The output you see is what that layer would produce after applying the displayed filter on an image passed through that layer.</p>\n\n<p>The reshape is necessary as Keras expects a dimension for the channel (we only have one channel since it's a grayscale image) and for the batch, which is why the code adds those two dummy dimensions. </p>\n\n<p>Also there's a bug in that function:</p>\n\n<p><code>model.layers[0].set_weights([np.reshape(filter_list[i], (4,4,1,1)), np.array([0])])</code></p>\n\n<p>should be</p>\n\n<p><code>model.layers[0].set_weights([np.reshape(filter_list[index], (4,4,1,1)), np.array([0])])</code></p>\n\n<p>Hope that helps!</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "36373",
                        "2",
                        "36365",
                        "",
                        "",
                        "<p>The function <code>set_weights</code> on a Keras layer requires the shape of the inputs to match the shape of the weights which you are replacing. You can find out which dimensions these are by calling the <code>get_weights</code> method on the layer in which you are interested.</p>\n\n<p>In that tutorial, it would look something like the following. We only need the first element returned by get_weights(), hence the <code>[0]</code>. We then see the shape of it:</p>\n\n<pre><code>In [7]: model.layers[0].get_weights[0].shape\n(4, 4, 1, 1)\n</code></pre>\n\n<p>So the person who wrote that tutorial needed to match that shape and, as it is only considering one layer of the defined model, it is able to be hard-coded in their example.</p>\n\n<hr>\n\n<p>Here are the docstrings for the two main functions I mentioned above:</p>\n\n<p><strong>set_weights()</strong></p>\n\n<pre><code>In [8]: l1.set_weights?\n\nSignature: l1.set_weights(weights)\nDocstring:\nSets the weights of the layer, from Numpy arrays.\n\n# Arguments\n    weights: a list of Numpy arrays. The number\n        of arrays and their shape must match\n        number of the dimensions of the weights\n        of the layer (i.e. it should match the\n        output of `get_weights`).\n\n# Raises\n    ValueError: If the provided weights list does not match the\n        layer's specifications.\n</code></pre>\n\n<p><strong>get_weights()</strong></p>\n\n<pre><code>In [9]: l1.get_weights?\nSignature: l1.get_weights()\nDocstring:\nReturns the current weights of the layer.\n\n# Returns\n    Weights values as a list of numpy arrays\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17221",
            "_score": 9.921406,
            "_source": {
                "title": "ValueError: Cannot feed value of shape (3,) for Tensor 'X:0', which has shape '(1, 3)'",
                "content": "ValueError: Cannot feed value of shape (3,) for Tensor 'X:0', which has shape '(1, 3)' <p>I am trying to do a multivariate linear regression and I am having some issues. Namely, I am getting the following error:</p>\n\n<pre><code>ValueError: Cannot feed value of shape (3,) for Tensor 'X:0', which has shape '(1, 3)'\n</code></pre>\n\n<p>I have 3 feature variables, which I call trainX and 1 label, which I call trainY. Their shapes are the following (they are numpy arrays):</p>\n\n<pre><code>trainX.shape:\n(2500, 3)\ntrainY.shape:\n(2500,)\n</code></pre>\n\n<p>The following piece of code defines the tensors that I use to compute the model:</p>\n\n<pre><code>X = tf.compat.v1.placeholder(\"float\", [1, 3], name=\"X\")\nY = tf.compat.v1.placeholder(\"float\", [1], name=\"Y\")\n\nW = tf.Variable(tf.zeros([3, 1]), name=\"W\")\nb = tf.Variable(tf.zeros([1]), name=\"b\")\n</code></pre>\n\n<p>I calculate the predicted label and the cost function and the optimizer by doing:</p>\n\n<pre><code>predicted_y = tf.matmul(X, W) + b\ncost = tf.reduce_sum(tf.pow(predicted_y-Y, 2)) / (2 * n)\noptimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n</code></pre>\n\n<p>I am getting the error in the tensor-flow session, namely in the following piece of code:</p>\n\n<pre><code>with tf.Session() as sess:\n    sess.run(init)\n    for epoch in range(training_epochs):\n        for (_x, _y) in zip(trainX, trainY):\n            sess.run(optimizer, feed_dict={X: _x, Y: _y})\n        if (epoch + 1) % 100 == 0:\n            c = sess.run(cost, feed_dict={X: trainX, Y: trainY})\n            print(\"Epoch\", (epoch + 1), \": cost =\", c, \"W =\", sess.run(W), \"b =\", sess.run(b))\n    # Storing necessary values to be used outside the Session\n    training_cost = sess.run(cost, feed_dict={X: trainX, Y: trainY})\n    weight = sess.run(W)\n    bias = sess.run(b)\n</code></pre>\n\n<p>Any help would be greatly appreciated.</p>\n <tensorflow><p><code>trainX</code> has shape <code>(2500, 3)</code>, so when you iterate over <code>trainX</code> you get values with shape <code>(3,)</code>.  To match the shape of your placeholder \"X\", you need them to have shape <code>(1, 3)</code>.  This can be accomplished with <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html\" rel=\"nofollow noreferrer\"><code>numpy.reshape</code></a>:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code># do this after loading trainX\ntrainX = trainX.reshape((-1, 1, 3))\n# new shape: (2500, 1, 3)\n</code></pre>\n",
                "codes": [
                    [
                        "# do this after loading trainX\ntrainX = trainX.reshape((-1, 1, 3))\n# new shape: (2500, 1, 3)\n"
                    ]
                ],
                "question_id:": "55777",
                "question_votes:": "1",
                "question_text:": "<p>I am trying to do a multivariate linear regression and I am having some issues. Namely, I am getting the following error:</p>\n\n<pre><code>ValueError: Cannot feed value of shape (3,) for Tensor 'X:0', which has shape '(1, 3)'\n</code></pre>\n\n<p>I have 3 feature variables, which I call trainX and 1 label, which I call trainY. Their shapes are the following (they are numpy arrays):</p>\n\n<pre><code>trainX.shape:\n(2500, 3)\ntrainY.shape:\n(2500,)\n</code></pre>\n\n<p>The following piece of code defines the tensors that I use to compute the model:</p>\n\n<pre><code>X = tf.compat.v1.placeholder(\"float\", [1, 3], name=\"X\")\nY = tf.compat.v1.placeholder(\"float\", [1], name=\"Y\")\n\nW = tf.Variable(tf.zeros([3, 1]), name=\"W\")\nb = tf.Variable(tf.zeros([1]), name=\"b\")\n</code></pre>\n\n<p>I calculate the predicted label and the cost function and the optimizer by doing:</p>\n\n<pre><code>predicted_y = tf.matmul(X, W) + b\ncost = tf.reduce_sum(tf.pow(predicted_y-Y, 2)) / (2 * n)\noptimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n</code></pre>\n\n<p>I am getting the error in the tensor-flow session, namely in the following piece of code:</p>\n\n<pre><code>with tf.Session() as sess:\n    sess.run(init)\n    for epoch in range(training_epochs):\n        for (_x, _y) in zip(trainX, trainY):\n            sess.run(optimizer, feed_dict={X: _x, Y: _y})\n        if (epoch + 1) % 100 == 0:\n            c = sess.run(cost, feed_dict={X: trainX, Y: trainY})\n            print(\"Epoch\", (epoch + 1), \": cost =\", c, \"W =\", sess.run(W), \"b =\", sess.run(b))\n    # Storing necessary values to be used outside the Session\n    training_cost = sess.run(cost, feed_dict={X: trainX, Y: trainY})\n    weight = sess.run(W)\n    bias = sess.run(b)\n</code></pre>\n\n<p>Any help would be greatly appreciated.</p>\n",
                "tags": "<tensorflow>",
                "answers": [
                    [
                        "55780",
                        "2",
                        "55777",
                        "",
                        "",
                        "<p><code>trainX</code> has shape <code>(2500, 3)</code>, so when you iterate over <code>trainX</code> you get values with shape <code>(3,)</code>.  To match the shape of your placeholder \"X\", you need them to have shape <code>(1, 3)</code>.  This can be accomplished with <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html\" rel=\"nofollow noreferrer\"><code>numpy.reshape</code></a>:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code># do this after loading trainX\ntrainX = trainX.reshape((-1, 1, 3))\n# new shape: (2500, 1, 3)\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15996",
            "_score": 9.792345,
            "_source": {
                "title": "File converter: from CSV to HDF5",
                "content": "File converter: from CSV to HDF5 <p>Can anyone recommend any command line tool for converting large CSV file into HDF5 format?</p>\n <csv><ul>\n<li><strong>1st approach:</strong> Use <a href=\"http://pandas.pydata.org/pandas-docs/version/0.15.1/io.html#id2\" rel=\"nofollow noreferrer\">append=True</a> in the call to <code>to_hdf</code>:</li>\n</ul>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\n\n#filename = '/tmp/test.hdf5'\nfilename = 'D:\\test.hdf5'\n\ndf = pd.DataFrame(np.arange(10).reshape((4,2)), columns=['C1', 'C2'])\nprint(df)\n#    C1  C2\n# 0  0   1\n# 1  2   3\n# 2  4   5\n# 3  6   7\n\n# Save to HDF5\ndf.to_hdf(filename, 'data', mode='w', format='table')\ndel df    # allow df to be garbage collected\n\n# Append more data\ndf2 = pd.DataFrame(np.arange(10).reshape((4,2))*10, columns=['C1', 'C2'])\ndf2.to_hdf(filename, 'data', append=True)\n\nprint(pd.read_hdf(filename, 'data'))\n\n</code></pre>\n\n<ul>\n<li><strong>2nd approach:</strong>  you could append to a <a href=\"http://pandas.pydata.org/pandas-docs/version/0.15.1/io.html#table-format\" rel=\"nofollow noreferrer\">HDFStore</a> instead of calling <code>df.to_hdf</code>:</li>\n</ul>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\n\n#filename = '/tmp/test.hdf5'\nfilename = 'D:\\test.hdf5'\nstore = pd.HDFStore(filename)\n\nfor i in range(2):\n    df = pd.DataFrame(np.arange(10).reshape((4,2)) * 10**i, columns=['C1', 'C2'])\n    store.append('data', df)\n\nstore.close()\n\nstore = pd.HDFStore(filename)\ndata = store['data']\nprint(data)\nstore.close()\n</code></pre>\n\n<ul>\n<li><strong>3rd approach:</strong>  using <code>chunksize</code> parameter and append each chunk to the HDF file which  was answered <a href=\"https://stackoverflow.com/a/46620538/10452700\">here</a>.</li>\n</ul>\n\n<p>Personally I like 1st and 2nd approach. </p>\n",
                "codes": [
                    [
                        "import numpy as np\nimport pandas as pd\n\n#filename = '/tmp/test.hdf5'\nfilename = 'D:\\test.hdf5'\n\ndf = pd.DataFrame(np.arange(10).reshape((4,2)), columns=['C1', 'C2'])\nprint(df)\n#    C1  C2\n# 0  0   1\n# 1  2   3\n# 2  4   5\n# 3  6   7\n\n# Save to HDF5\ndf.to_hdf(filename, 'data', mode='w', format='table')\ndel df    # allow df to be garbage collected\n\n# Append more data\ndf2 = pd.DataFrame(np.arange(10).reshape((4,2))*10, columns=['C1', 'C2'])\ndf2.to_hdf(filename, 'data', append=True)\n\nprint(pd.read_hdf(filename, 'data'))\n\n",
                        "import numpy as np\nimport pandas as pd\n\n#filename = '/tmp/test.hdf5'\nfilename = 'D:\\test.hdf5'\nstore = pd.HDFStore(filename)\n\nfor i in range(2):\n    df = pd.DataFrame(np.arange(10).reshape((4,2)) * 10**i, columns=['C1', 'C2'])\n    store.append('data', df)\n\nstore.close()\n\nstore = pd.HDFStore(filename)\ndata = store['data']\nprint(data)\nstore.close()\n"
                    ]
                ],
                "question_id:": "53125",
                "question_votes:": "2",
                "question_text:": "<p>Can anyone recommend any command line tool for converting large CSV file into HDF5 format?</p>\n",
                "tags": "<csv>",
                "answers": [
                    [
                        "53129",
                        "2",
                        "53125",
                        "",
                        "",
                        "<ul>\n<li><strong>1st approach:</strong> Use <a href=\"http://pandas.pydata.org/pandas-docs/version/0.15.1/io.html#id2\" rel=\"nofollow noreferrer\">append=True</a> in the call to <code>to_hdf</code>:</li>\n</ul>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\n\n#filename = '/tmp/test.hdf5'\nfilename = 'D:\\test.hdf5'\n\ndf = pd.DataFrame(np.arange(10).reshape((4,2)), columns=['C1', 'C2'])\nprint(df)\n#    C1  C2\n# 0  0   1\n# 1  2   3\n# 2  4   5\n# 3  6   7\n\n# Save to HDF5\ndf.to_hdf(filename, 'data', mode='w', format='table')\ndel df    # allow df to be garbage collected\n\n# Append more data\ndf2 = pd.DataFrame(np.arange(10).reshape((4,2))*10, columns=['C1', 'C2'])\ndf2.to_hdf(filename, 'data', append=True)\n\nprint(pd.read_hdf(filename, 'data'))\n\n</code></pre>\n\n<ul>\n<li><strong>2nd approach:</strong>  you could append to a <a href=\"http://pandas.pydata.org/pandas-docs/version/0.15.1/io.html#table-format\" rel=\"nofollow noreferrer\">HDFStore</a> instead of calling <code>df.to_hdf</code>:</li>\n</ul>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\n\n#filename = '/tmp/test.hdf5'\nfilename = 'D:\\test.hdf5'\nstore = pd.HDFStore(filename)\n\nfor i in range(2):\n    df = pd.DataFrame(np.arange(10).reshape((4,2)) * 10**i, columns=['C1', 'C2'])\n    store.append('data', df)\n\nstore.close()\n\nstore = pd.HDFStore(filename)\ndata = store['data']\nprint(data)\nstore.close()\n</code></pre>\n\n<ul>\n<li><strong>3rd approach:</strong>  using <code>chunksize</code> parameter and append each chunk to the HDF file which  was answered <a href=\"https://stackoverflow.com/a/46620538/10452700\">here</a>.</li>\n</ul>\n\n<p>Personally I like 1st and 2nd approach. </p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11521",
            "_score": 9.777056,
            "_source": {
                "title": "model.predict in Keras, Python error",
                "content": "model.predict in Keras, Python error <p>I trained a model in Keras with input dimension 15 and output dimension 1. Then I tried to predict the output for a single input np.array, which I chose to be a toy example np.arange(15). However, the input is not accepted. Can someone tell me where the problem is?\nHere is the code for a simplified problem: </p>\n\n<pre><code>import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nX = np.arange(15)\nY = 0\nmodel = Sequential()\nmodel.add(Dense(32, input_dim=15, activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(X, Y, epochs=10, verbose=1, batch_size=batch_size)\nmodel.predict(X)\n</code></pre>\n\n<p>The following error occurs: \nValueError: Error when checking input: expected dense_4_input to have shape (15,) but got array with shape (1,). \nBut then again, the input clearly has the correct shape. What is going on here?\nThanks for your help!</p>\n <python><keras><blockquote>\n  <p>But then again, the input clearly has the correct shape.</p>\n</blockquote>\n\n<pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; X = np.arange(15)\n&gt;&gt;&gt; X.shape\n(15,)\n</code></pre>\n\n<p>In Keras, <code>input_dim</code> represents the number of input parameters, in your case that would be the number of columns of <code>X</code> or its second dimension (sometimes also referred to as number of features). It is clearly not 15. It is the first dimension that is 15. That means: <code>X</code> consists of 15 rows, also called samples (of one and the same feature).</p>\n\n<p>So in that case, <code>input_dim=1</code>. </p>\n\n<p>However, you will then run into the problem of having specified <code>Y = 0</code>. First, Keras will throw an error because it is an integer. You could do <code>Y = [0]</code>, but then you will get</p>\n\n<pre><code>ValueError: Input arrays should have the same number of samples as target arrays. Found 15 input samples and 1 target samples.\n</code></pre>\n\n<p>So you have to turn this into an array-like object containing 15 samples, e.g. a list of length 15.</p>\n\n<p>However, in case you meant to feed <strong>one single sample</strong> <code>X</code> to your model, that maps to one single output <code>Y = [0]</code>, then you need to <a href=\"https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.reshape.html\" rel=\"nofollow noreferrer\">reshape</a> <code>X</code> accordingly, for example via </p>\n\n<pre><code>X = np.arange(15).reshape(n_samples, n_features)\n</code></pre>\n\n<p>Can you figure out now what <code>n_samples, n_features</code> needs to be?</p>\n",
                "codes": [
                    [
                        ">>> import numpy as np\n>>> X = np.arange(15)\n>>> X.shape\n(15,)\n",
                        "ValueError: Input arrays should have the same number of samples as target arrays. Found 15 input samples and 1 target samples.\n",
                        "X = np.arange(15).reshape(n_samples, n_features)\n"
                    ]
                ],
                "question_id:": "40679",
                "question_votes:": "",
                "question_text:": "<p>I trained a model in Keras with input dimension 15 and output dimension 1. Then I tried to predict the output for a single input np.array, which I chose to be a toy example np.arange(15). However, the input is not accepted. Can someone tell me where the problem is?\nHere is the code for a simplified problem: </p>\n\n<pre><code>import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nX = np.arange(15)\nY = 0\nmodel = Sequential()\nmodel.add(Dense(32, input_dim=15, activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(X, Y, epochs=10, verbose=1, batch_size=batch_size)\nmodel.predict(X)\n</code></pre>\n\n<p>The following error occurs: \nValueError: Error when checking input: expected dense_4_input to have shape (15,) but got array with shape (1,). \nBut then again, the input clearly has the correct shape. What is going on here?\nThanks for your help!</p>\n",
                "tags": "<python><keras>",
                "answers": [
                    [
                        "40680",
                        "2",
                        "40679",
                        "",
                        "",
                        "<blockquote>\n  <p>But then again, the input clearly has the correct shape.</p>\n</blockquote>\n\n<pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; X = np.arange(15)\n&gt;&gt;&gt; X.shape\n(15,)\n</code></pre>\n\n<p>In Keras, <code>input_dim</code> represents the number of input parameters, in your case that would be the number of columns of <code>X</code> or its second dimension (sometimes also referred to as number of features). It is clearly not 15. It is the first dimension that is 15. That means: <code>X</code> consists of 15 rows, also called samples (of one and the same feature).</p>\n\n<p>So in that case, <code>input_dim=1</code>. </p>\n\n<p>However, you will then run into the problem of having specified <code>Y = 0</code>. First, Keras will throw an error because it is an integer. You could do <code>Y = [0]</code>, but then you will get</p>\n\n<pre><code>ValueError: Input arrays should have the same number of samples as target arrays. Found 15 input samples and 1 target samples.\n</code></pre>\n\n<p>So you have to turn this into an array-like object containing 15 samples, e.g. a list of length 15.</p>\n\n<p>However, in case you meant to feed <strong>one single sample</strong> <code>X</code> to your model, that maps to one single output <code>Y = [0]</code>, then you need to <a href=\"https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.reshape.html\" rel=\"nofollow noreferrer\">reshape</a> <code>X</code> accordingly, for example via </p>\n\n<pre><code>X = np.arange(15).reshape(n_samples, n_features)\n</code></pre>\n\n<p>Can you figure out now what <code>n_samples, n_features</code> needs to be?</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16355",
            "_score": 9.7079735,
            "_source": {
                "title": "Derivative of the Jacobian",
                "content": "Derivative of the Jacobian <p>I want to take the derivate of the jacobian using pytorch, but it seems like I am doing the wrong thing. Here is part of my code:</p>\n\n<pre><code>x_1 = np.arange(1,4,1)\nx_1 = torch.from_numpy(x_1).reshape(len(x_1),1)\nx_1 = x_1.float()\nx_2 = np.arange(1,4,1)\nx_2 = torch.from_numpy(x_2).reshape(len(x_2),1)\nx_2 = x_2.float()\nx = torch.cat((x_1,x_2),1)\n\nx.requires_grad = True\n\nw1 = nn.Linear(2, 2, bias=False)\n\ny = w1(x)\n\ndef jacobian(inputs, outputs):\n    return torch.stack([torch.autograd.grad([outputs[:, i].sum()], [inputs], create_graph=True)[0]\n                        for i in range(outputs.size(1))], dim=-1)\njac = jacobian(x,y)\n</code></pre>\n\n<p>So at this point jac contains the jacobian matrix of my system, which works just fine. But I want to take the derivative of jac with respect to x (basically second order partial derivatives). But when I do this: <code>d_jac = jacobian(x,jac)</code> I get this error: <code>RuntimeError: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.</code> I am not sure why, as obviously jac is derived from y, so it should still depend on x. Can someone help me? Thank you!</p>\n <pytorch>",
                "codes": [],
                "question_id:": "53904",
                "question_votes:": "1",
                "question_text:": "<p>I want to take the derivate of the jacobian using pytorch, but it seems like I am doing the wrong thing. Here is part of my code:</p>\n\n<pre><code>x_1 = np.arange(1,4,1)\nx_1 = torch.from_numpy(x_1).reshape(len(x_1),1)\nx_1 = x_1.float()\nx_2 = np.arange(1,4,1)\nx_2 = torch.from_numpy(x_2).reshape(len(x_2),1)\nx_2 = x_2.float()\nx = torch.cat((x_1,x_2),1)\n\nx.requires_grad = True\n\nw1 = nn.Linear(2, 2, bias=False)\n\ny = w1(x)\n\ndef jacobian(inputs, outputs):\n    return torch.stack([torch.autograd.grad([outputs[:, i].sum()], [inputs], create_graph=True)[0]\n                        for i in range(outputs.size(1))], dim=-1)\njac = jacobian(x,y)\n</code></pre>\n\n<p>So at this point jac contains the jacobian matrix of my system, which works just fine. But I want to take the derivative of jac with respect to x (basically second order partial derivatives). But when I do this: <code>d_jac = jacobian(x,jac)</code> I get this error: <code>RuntimeError: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.</code> I am not sure why, as obviously jac is derived from y, so it should still depend on x. Can someone help me? Thank you!</p>\n",
                "tags": "<pytorch>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11462",
            "_score": 9.707163,
            "_source": {
                "title": "keras Sequential CNN for image data reshaping data issues",
                "content": "keras Sequential CNN for image data reshaping data issues <p>I am new at keras and CNN and am working on building at CNN  for sequential analysis of movement in a image. What I am having issues with is the reshaping the data and the labels that go into the fitting and testing the data for the model.\nSo the original size/shape of the numpy file is (18, 50,50,16) which is saved in a text file from another program.  I know the text file is ok because I can read it in and display it correctly with the debug_potion method. So that looks good. There are 18 images in the folder for the data and otherData variable. I dont really know what the 16 is but the image size are 50*50. </p>\n\n<p>The issue is the reshaping of that data is the problem. Can anyone suggest how to reshape this data in a way that I can train it. I think I need to do onehot encoding but not quite sure how. Any help will be appreciated. Here is what I have so far.</p>\n\n<pre><code>def debug_potion(data):\n    for i in range(0, 16):\n        # get for each joint\n        potion = Potion(data)\n        plt.show(potion.display(joints=[i, i], channels=[0, 1, 2]))\n\n# Build Model for sequential building\ndef create_model(input_shape):\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='softmax'))\n\n    model.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n    return model\n\n\ndef read_in_data(file):\n    with open(file, \"rb\") as f:\n        return pickle.load(f)\n\n\nbatch_size = 1\nnum_classes = 2\nepochs = 12\n\n# input image dimensions\nimg_rows, img_cols = 50, 50\ninput_shape = (img_rows, img_cols, 16)\n\ndata = read_in_data(\"heatmap.txt\")\notherData = read_in_data(\"othermove.txt\")\n\n\ndata = np.array(data)\notherData = np.array(otherData)\nprint(\"Data shape\", otherData.shape)\n\n\nxtrain = []\nytrain = []\nxtest  = []\nytest  = []\n\nfor x in range(0,len(data)):\n    if x &lt; 15:\n        xtrain.append(data)\n        ytrain.append((\"FWAC\", num_classes))\n    else:\n        xtest.append(data)\n        ytest.append((\"FWAC\", num_classes))\n\nfor x in range(0,len(otherData)):\n    if x &lt; 15:\n        xtrain.append(otherData)\n        ytrain.append((\"Other\", num_classes))\n    else:\n        xtest.append(otherData)\n        ytest.append((\"Other\", num_classes))\n\n#Create x test and train arrays\nxtrain = np.array(xtrain)\nxtrain = xtrain.reshape(30,img_rows, img_cols,16)\nytrain = np.array(ytrain)\n\nxtest = np.array(xtest)\nxtest = xtest.reshape(108, img_rows, img_cols,16)\nytest = np.array(ytest)\nprint(xtrain.shape)\nprint(xtest.shape)\nprint(ytrain.shape)\nprint(ytest.shape)\n\n# Build Model\nmodel = create_model(input_shape)\n\nmodel.fit(xtrain, ytrain,\n          batch_size = batch_size,\n          epochs = epochs,\n          verbose=1,\n          validation_data=(xtest, ytest))\n\nscore = model.evaluate(xtest,ytest, verbose=0)\nprint((\"Test loss\", score[0]))\nprint(\"Test Accuracy\", score[1])\n</code></pre>\n <python><keras><cnn><numpy><reshape><p>As far as labels are concerned, you can one-hot-encode by using (assuming ytrain is converted to numpy array) the below code. Image reshaping looks fine but if you are having issues with image reshaping then, you might be giving the first argument i.e., the number of images wrong. So try this</p>\n\n<pre><code>    xtrain = xtrain.reshape(xtrain.shape[0],img_rows,img_cols,16)\n\n    ytrain = keras.utils.to_categorical(ytrain, num_classes)\n</code></pre>\n\n<p>Make sure you import to_categorical from keras.utils </p>\n",
                "codes": [
                    [
                        "    xtrain = xtrain.reshape(xtrain.shape[0],img_rows,img_cols,16)\n\n    ytrain = keras.utils.to_categorical(ytrain, num_classes)\n"
                    ]
                ],
                "question_id:": "40477",
                "question_votes:": "",
                "question_text:": "<p>I am new at keras and CNN and am working on building at CNN  for sequential analysis of movement in a image. What I am having issues with is the reshaping the data and the labels that go into the fitting and testing the data for the model.\nSo the original size/shape of the numpy file is (18, 50,50,16) which is saved in a text file from another program.  I know the text file is ok because I can read it in and display it correctly with the debug_potion method. So that looks good. There are 18 images in the folder for the data and otherData variable. I dont really know what the 16 is but the image size are 50*50. </p>\n\n<p>The issue is the reshaping of that data is the problem. Can anyone suggest how to reshape this data in a way that I can train it. I think I need to do onehot encoding but not quite sure how. Any help will be appreciated. Here is what I have so far.</p>\n\n<pre><code>def debug_potion(data):\n    for i in range(0, 16):\n        # get for each joint\n        potion = Potion(data)\n        plt.show(potion.display(joints=[i, i], channels=[0, 1, 2]))\n\n# Build Model for sequential building\ndef create_model(input_shape):\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='softmax'))\n\n    model.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n    return model\n\n\ndef read_in_data(file):\n    with open(file, \"rb\") as f:\n        return pickle.load(f)\n\n\nbatch_size = 1\nnum_classes = 2\nepochs = 12\n\n# input image dimensions\nimg_rows, img_cols = 50, 50\ninput_shape = (img_rows, img_cols, 16)\n\ndata = read_in_data(\"heatmap.txt\")\notherData = read_in_data(\"othermove.txt\")\n\n\ndata = np.array(data)\notherData = np.array(otherData)\nprint(\"Data shape\", otherData.shape)\n\n\nxtrain = []\nytrain = []\nxtest  = []\nytest  = []\n\nfor x in range(0,len(data)):\n    if x &lt; 15:\n        xtrain.append(data)\n        ytrain.append((\"FWAC\", num_classes))\n    else:\n        xtest.append(data)\n        ytest.append((\"FWAC\", num_classes))\n\nfor x in range(0,len(otherData)):\n    if x &lt; 15:\n        xtrain.append(otherData)\n        ytrain.append((\"Other\", num_classes))\n    else:\n        xtest.append(otherData)\n        ytest.append((\"Other\", num_classes))\n\n#Create x test and train arrays\nxtrain = np.array(xtrain)\nxtrain = xtrain.reshape(30,img_rows, img_cols,16)\nytrain = np.array(ytrain)\n\nxtest = np.array(xtest)\nxtest = xtest.reshape(108, img_rows, img_cols,16)\nytest = np.array(ytest)\nprint(xtrain.shape)\nprint(xtest.shape)\nprint(ytrain.shape)\nprint(ytest.shape)\n\n# Build Model\nmodel = create_model(input_shape)\n\nmodel.fit(xtrain, ytrain,\n          batch_size = batch_size,\n          epochs = epochs,\n          verbose=1,\n          validation_data=(xtest, ytest))\n\nscore = model.evaluate(xtest,ytest, verbose=0)\nprint((\"Test loss\", score[0]))\nprint(\"Test Accuracy\", score[1])\n</code></pre>\n",
                "tags": "<python><keras><cnn><numpy><reshape>",
                "answers": [
                    [
                        "40543",
                        "2",
                        "40477",
                        "",
                        "",
                        "<p>As far as labels are concerned, you can one-hot-encode by using (assuming ytrain is converted to numpy array) the below code. Image reshaping looks fine but if you are having issues with image reshaping then, you might be giving the first argument i.e., the number of images wrong. So try this</p>\n\n<pre><code>    xtrain = xtrain.reshape(xtrain.shape[0],img_rows,img_cols,16)\n\n    ytrain = keras.utils.to_categorical(ytrain, num_classes)\n</code></pre>\n\n<p>Make sure you import to_categorical from keras.utils </p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15957",
            "_score": 9.6446,
            "_source": {
                "title": "Expected 2D array, got scalar array instead",
                "content": "Expected 2D array, got scalar array instead <p>Can anyone help me with this error. I did the following code but it does not work and I am getting the following error:</p>\n\n<pre><code>ValueError: Expected 2D array, got scalar array instead:\narray=6.5. Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample. \n</code></pre>\n\n<p>My code:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport pandas\ndataset = pandas.read_excel('PEG RATIOS.xlsx')\n\nX = dataset.iloc[:, 2].values\nX =X.reshape(-1,1)\ny = dataset.iloc[:, 3].values\ny = y.reshape (-1,1)\n\n\nfrom sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\nfrom sklearn.preprocessing import PolynomialFeatures\npoly_reg = PolynomialFeatures(degree = 4)\nX_poly = poly_reg.fit_transform(X)\npoly_reg.fit(X_poly, y)\nlin_reg_2 = LinearRegression()\nlin_reg_2.fit(X_poly, y)\n\nX_grid = np.arange(min(X), max(X), 0.1)\nX_grid = X_grid.reshape((len(X_grid), 1))\nplt.scatter(X, y, color = 'red')\nplt.plot(X_grid, lin_reg_2.predict(poly_reg.fit_transform(X_grid)), color = 'blue')\nplt.title('PEG Ratios verrus Exoected Growth: Semiconductor Firms')\nplt.xlabel('Expected Growth rate')\nplt.ylabel('PEGH Ratio')\nplt.show()\nlin_reg_2.predict(poly_reg.fit_transform(6.5))\n</code></pre>\n <machine-learning><python><p>The error itself solves your problem. Just follow what it says. The predict() method takes a 2d array of values you want to predict on. Each item in the array is a \"point\" you want your model to predict on. So try,</p>\n\n<pre><code>lin_reg_2.predict(poly_reg.fit_transform([[6.5]]))\n</code></pre>\n\n<p>Here the input is a 2D array of shape <code>(1,1)</code>.</p>\n\n<p>Or as the error suggest try:</p>\n\n<pre><code>lin_reg_2.predict(np.array([6.5]).reshape(1, 1))\n</code></pre>\n",
                "codes": [
                    [
                        "lin_reg_2.predict(poly_reg.fit_transform([[6.5]]))\n",
                        "lin_reg_2.predict(np.array([6.5]).reshape(1, 1))\n"
                    ]
                ],
                "question_id:": "53048",
                "question_votes:": "2",
                "question_text:": "<p>Can anyone help me with this error. I did the following code but it does not work and I am getting the following error:</p>\n\n<pre><code>ValueError: Expected 2D array, got scalar array instead:\narray=6.5. Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample. \n</code></pre>\n\n<p>My code:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport pandas\ndataset = pandas.read_excel('PEG RATIOS.xlsx')\n\nX = dataset.iloc[:, 2].values\nX =X.reshape(-1,1)\ny = dataset.iloc[:, 3].values\ny = y.reshape (-1,1)\n\n\nfrom sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\nfrom sklearn.preprocessing import PolynomialFeatures\npoly_reg = PolynomialFeatures(degree = 4)\nX_poly = poly_reg.fit_transform(X)\npoly_reg.fit(X_poly, y)\nlin_reg_2 = LinearRegression()\nlin_reg_2.fit(X_poly, y)\n\nX_grid = np.arange(min(X), max(X), 0.1)\nX_grid = X_grid.reshape((len(X_grid), 1))\nplt.scatter(X, y, color = 'red')\nplt.plot(X_grid, lin_reg_2.predict(poly_reg.fit_transform(X_grid)), color = 'blue')\nplt.title('PEG Ratios verrus Exoected Growth: Semiconductor Firms')\nplt.xlabel('Expected Growth rate')\nplt.ylabel('PEGH Ratio')\nplt.show()\nlin_reg_2.predict(poly_reg.fit_transform(6.5))\n</code></pre>\n",
                "tags": "<machine-learning><python>",
                "answers": [
                    [
                        "53054",
                        "2",
                        "53048",
                        "",
                        "",
                        "<p>The error itself solves your problem. Just follow what it says. The predict() method takes a 2d array of values you want to predict on. Each item in the array is a \"point\" you want your model to predict on. So try,</p>\n\n<pre><code>lin_reg_2.predict(poly_reg.fit_transform([[6.5]]))\n</code></pre>\n\n<p>Here the input is a 2D array of shape <code>(1,1)</code>.</p>\n\n<p>Or as the error suggest try:</p>\n\n<pre><code>lin_reg_2.predict(np.array([6.5]).reshape(1, 1))\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9526",
            "_score": 9.632441,
            "_source": {
                "title": "Number of features of the model must match the input. Model n_features is `N` and input n_features is `X`.",
                "content": "Number of features of the model must match the input. Model n_features is `N` and input n_features is `X`. <p>I am new to data science and trying get some results. I'm applying <code>Decision Tree Classifier</code>. When my train and test datasets' size are not equal I get an error `Number of features of the model must match the input. Model n_features is <strong>N</strong> (no. of entries in training datasets) and input n_features is <strong>X</strong> (no. of entries in test datasets). </p>\n\n<p>If I have 100 entries in my dataset and parameter for split is <code>test_size=0.30</code> as:</p>\n\n<pre><code>import pandas as pd\nfrom pandas import Series, DataFrame\nimport numpy as np\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\n\n\n\ndata=pd.read_csv(\"ndata.csv\")\n\nX_train, X_test, y_train, y_test = train_test_split(data.dis, data.gen, test_size=0.30, random_state=42)\n\n\nc = tree.DecisionTreeClassifier()\n\ny_test_size = y_test.size\ny_train_size = y_train.size\nX_train = [X_train]\ny_train = [y_train]\nX_test = [X_test]\ny_test = [y_test]\n\nc.fit(X_train, y_train)\n\naccu_train = np.sum(c.predict(X_train) == y_train)/y_train_size\naccu_test = np.sum(c.predict(X_test) == y_test)/y_test_size\n\nprint(\"Accuracy on Train: \", accu_train)\nprint(\"Accuracy on Test: \", accu_test)\n</code></pre>\n\n<p>And the error occurs as follows:</p>\n\n<pre><code>ValueError                                Traceback (most recent call last)\n&lt;ipython-input-33-f6cc77390526&gt; in &lt;module&gt;()\n     24 \n     25 accu_train = np.sum(c.predict(X_train) == y_train)/y_train_size\n---&gt; 26 accu_test = np.sum(c.predict(X_test) == y_test)/y_test_size\n     27 \n     28 print(\"Accuracy on Train: \", accu_train)\n\n~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in predict(self, X, check_input)\n    410         \"\"\"\n    411         check_is_fitted(self, 'tree_')\n--&gt; 412         X = self._validate_X_predict(X, check_input)\n    413         proba = self.tree_.predict(X)\n    414         n_samples = X.shape[0]\n\n~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)\n    382                              \"match the input. Model n_features is %s and \"\n    383                              \"input n_features is %s \"\n--&gt; 384                              % (self.n_features_, n_features))\n    385 \n    386         return X\n\nValueError: Number of features of the model must match the input. Model n_features is 70 and input n_features is 30 \n</code></pre>\n\n<p>Link to data file: <a href=\"https://gist.github.com/mutafaf/7715ad67bc3cf4e08985afefcc0ce08a#file-ndata-csv\" rel=\"nofollow noreferrer\">https://gist.github.com/mutafaf/7715ad67bc3cf4e08985afefcc0ce08a#file-ndata-csv</a></p>\n\n<p>Why do I'm getting this error. Is it necessary to have <strong>dataset size</strong> of both train and test equal? </p>\n <python><scikit-learn><feature-selection><training><p>You are supposed to pass <code>numpy</code> arrays and not lists as arguments to the <code>DecisionTree</code>, since your input was a list it gets trained as 70 features (1D list) and your test had <code>list</code> of 30 elements and the classifier sees it as 30 features.</p>\n\n<p>Nonetheless, you need to reshape your input <code>numpy</code> array and pass it as a <strong>matrix</strong></p>\n\n<p>meaning: <code>X_train.values.reshape(-1, 1)</code> instead of <code>X_train</code> (it should be a <code>numpy</code> array not a <code>list</code>)</p>\n\n<p>this is the entire gist:</p>\n\n<pre><code>data=pd.read_csv(\"ndata.csv\")\n\nX_train, X_test, y_train, y_test = train_test_split(data.dis, data.gen, test_size=0.30, random_state=42)\n\nfrom sklearn import tree\n\nc = tree.DecisionTreeClassifier()\nc.fit(X_train.values.reshape(-1, 1), y_train)\n\naccu_train = np.sum(c.predict(X_train.values.reshape(-1, 1)) == y_train)/y_train_size\naccu_test = np.sum(c.predict(X_test.values.reshape(-1, 1)) == y_test)/y_test_size\n\nprint(\"Accuracy on Train: \", accu_train)\nprint(\"Accuracy on Test: \", accu_test)\n</code></pre>\n\n<p>I'm getting the following output:</p>\n\n<pre><code>Accuracy on Train:  0.8857142857142857\nAccuracy on Test:  0.7333333333333333\n</code></pre>\n\n<p>Thanks for sharing the dataset. It was helpful for testing.</p>\n",
                "codes": [
                    [
                        "data=pd.read_csv(\"ndata.csv\")\n\nX_train, X_test, y_train, y_test = train_test_split(data.dis, data.gen, test_size=0.30, random_state=42)\n\nfrom sklearn import tree\n\nc = tree.DecisionTreeClassifier()\nc.fit(X_train.values.reshape(-1, 1), y_train)\n\naccu_train = np.sum(c.predict(X_train.values.reshape(-1, 1)) == y_train)/y_train_size\naccu_test = np.sum(c.predict(X_test.values.reshape(-1, 1)) == y_test)/y_test_size\n\nprint(\"Accuracy on Train: \", accu_train)\nprint(\"Accuracy on Test: \", accu_test)\n",
                        "Accuracy on Train:  0.8857142857142857\nAccuracy on Test:  0.7333333333333333\n"
                    ]
                ],
                "question_id:": "33910",
                "question_votes:": "3",
                "question_text:": "<p>I am new to data science and trying get some results. I'm applying <code>Decision Tree Classifier</code>. When my train and test datasets' size are not equal I get an error `Number of features of the model must match the input. Model n_features is <strong>N</strong> (no. of entries in training datasets) and input n_features is <strong>X</strong> (no. of entries in test datasets). </p>\n\n<p>If I have 100 entries in my dataset and parameter for split is <code>test_size=0.30</code> as:</p>\n\n<pre><code>import pandas as pd\nfrom pandas import Series, DataFrame\nimport numpy as np\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\n\n\n\ndata=pd.read_csv(\"ndata.csv\")\n\nX_train, X_test, y_train, y_test = train_test_split(data.dis, data.gen, test_size=0.30, random_state=42)\n\n\nc = tree.DecisionTreeClassifier()\n\ny_test_size = y_test.size\ny_train_size = y_train.size\nX_train = [X_train]\ny_train = [y_train]\nX_test = [X_test]\ny_test = [y_test]\n\nc.fit(X_train, y_train)\n\naccu_train = np.sum(c.predict(X_train) == y_train)/y_train_size\naccu_test = np.sum(c.predict(X_test) == y_test)/y_test_size\n\nprint(\"Accuracy on Train: \", accu_train)\nprint(\"Accuracy on Test: \", accu_test)\n</code></pre>\n\n<p>And the error occurs as follows:</p>\n\n<pre><code>ValueError                                Traceback (most recent call last)\n&lt;ipython-input-33-f6cc77390526&gt; in &lt;module&gt;()\n     24 \n     25 accu_train = np.sum(c.predict(X_train) == y_train)/y_train_size\n---&gt; 26 accu_test = np.sum(c.predict(X_test) == y_test)/y_test_size\n     27 \n     28 print(\"Accuracy on Train: \", accu_train)\n\n~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in predict(self, X, check_input)\n    410         \"\"\"\n    411         check_is_fitted(self, 'tree_')\n--&gt; 412         X = self._validate_X_predict(X, check_input)\n    413         proba = self.tree_.predict(X)\n    414         n_samples = X.shape[0]\n\n~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)\n    382                              \"match the input. Model n_features is %s and \"\n    383                              \"input n_features is %s \"\n--&gt; 384                              % (self.n_features_, n_features))\n    385 \n    386         return X\n\nValueError: Number of features of the model must match the input. Model n_features is 70 and input n_features is 30 \n</code></pre>\n\n<p>Link to data file: <a href=\"https://gist.github.com/mutafaf/7715ad67bc3cf4e08985afefcc0ce08a#file-ndata-csv\" rel=\"nofollow noreferrer\">https://gist.github.com/mutafaf/7715ad67bc3cf4e08985afefcc0ce08a#file-ndata-csv</a></p>\n\n<p>Why do I'm getting this error. Is it necessary to have <strong>dataset size</strong> of both train and test equal? </p>\n",
                "tags": "<python><scikit-learn><feature-selection><training>",
                "answers": [
                    [
                        "33925",
                        "2",
                        "33910",
                        "",
                        "",
                        "<p>You are supposed to pass <code>numpy</code> arrays and not lists as arguments to the <code>DecisionTree</code>, since your input was a list it gets trained as 70 features (1D list) and your test had <code>list</code> of 30 elements and the classifier sees it as 30 features.</p>\n\n<p>Nonetheless, you need to reshape your input <code>numpy</code> array and pass it as a <strong>matrix</strong></p>\n\n<p>meaning: <code>X_train.values.reshape(-1, 1)</code> instead of <code>X_train</code> (it should be a <code>numpy</code> array not a <code>list</code>)</p>\n\n<p>this is the entire gist:</p>\n\n<pre><code>data=pd.read_csv(\"ndata.csv\")\n\nX_train, X_test, y_train, y_test = train_test_split(data.dis, data.gen, test_size=0.30, random_state=42)\n\nfrom sklearn import tree\n\nc = tree.DecisionTreeClassifier()\nc.fit(X_train.values.reshape(-1, 1), y_train)\n\naccu_train = np.sum(c.predict(X_train.values.reshape(-1, 1)) == y_train)/y_train_size\naccu_test = np.sum(c.predict(X_test.values.reshape(-1, 1)) == y_test)/y_test_size\n\nprint(\"Accuracy on Train: \", accu_train)\nprint(\"Accuracy on Test: \", accu_test)\n</code></pre>\n\n<p>I'm getting the following output:</p>\n\n<pre><code>Accuracy on Train:  0.8857142857142857\nAccuracy on Test:  0.7333333333333333\n</code></pre>\n\n<p>Thanks for sharing the dataset. It was helpful for testing.</p>\n",
                        "",
                        "7"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9626",
            "_score": 9.544471,
            "_source": {
                "title": "Appending to numpy array for creating dataset",
                "content": "Appending to numpy array for creating dataset <p>I want to create a dataset from three numpy matrices - train1 = (204,), train2 = (204,) and train3 = (204,). Basically all sets are of same length. I am applying a sliding window function on each of window 4. Each set become of shape =(201,4) I want a new array in which all these values are appended row wise. Like for first train1 then train2 then train3. And final output set is of size =(603,4). </p>\n\n<p>This is a sliding window function which converts array of shape (204,) to (201,4)</p>\n\n<pre><code>def moving_window(x, length, step=1):\n    streams = it.tee(x, length) \n    return zip(*[it.islice(stream, i, None, step) for stream, i in zip(streams, it.count(step=step))]) \n</code></pre>\n\n<p>Create dataset fucntion is:</p>\n\n<pre><code>def create_dataset(dataset1,dataset2):\n    dataX=[]       \n    x=list(moving_window(dataset1,4))\n    x=np.asarray(x) \n    dataX.append(x)\n    y=list(moving_window(dataset2,4)) \n    y=np.asarray(y) \n    dataX.append(y) \n    return np.array(dataX)\n\ndata_new=create_dataset(train1,train2)\n</code></pre>\n\n<p>It is returning a dataset of shape 0(2,201,4). I think this is appending differently, but I want row wise appending. so that the new _dataset is of shape= (402,4) with two sets and (603,4) with three sets. I want to generalize as well like if I want for 10 training sets or twenty training sets. How can I do that?</p>\n <python><deep-learning><numpy><p>I think its because of the way you are appending the datasets in list and then converting it to numpy array.</p>\n\n<p><strong>Solution 1</strong></p>\n\n<p>One quick solution is to reshape your array as -</p>\n\n<p><code>data_new = data_new.reshape(data_new.shape[0]*data_new.shape[1], data_new.shape[2])</code></p>\n\n<p>So, your data of shape (2,201,4) will become (2*201,4) = (402,4).</p>\n\n<p><strong>Solution 2</strong></p>\n\n<p>Another solution is to append the arrays in the function you have defined, instead of returning <code>np.array(dataX)</code>, use -</p>\n\n<pre><code>return np.append(x, y, axis = 0)\n</code></pre>\n\n<p>So, you don't have to use <code>dataX</code> anywhere.</p>\n",
                "codes": [
                    [
                        "return np.append(x, y, axis = 0)\n"
                    ]
                ],
                "question_id:": "34181",
                "question_votes:": "",
                "question_text:": "<p>I want to create a dataset from three numpy matrices - train1 = (204,), train2 = (204,) and train3 = (204,). Basically all sets are of same length. I am applying a sliding window function on each of window 4. Each set become of shape =(201,4) I want a new array in which all these values are appended row wise. Like for first train1 then train2 then train3. And final output set is of size =(603,4). </p>\n\n<p>This is a sliding window function which converts array of shape (204,) to (201,4)</p>\n\n<pre><code>def moving_window(x, length, step=1):\n    streams = it.tee(x, length) \n    return zip(*[it.islice(stream, i, None, step) for stream, i in zip(streams, it.count(step=step))]) \n</code></pre>\n\n<p>Create dataset fucntion is:</p>\n\n<pre><code>def create_dataset(dataset1,dataset2):\n    dataX=[]       \n    x=list(moving_window(dataset1,4))\n    x=np.asarray(x) \n    dataX.append(x)\n    y=list(moving_window(dataset2,4)) \n    y=np.asarray(y) \n    dataX.append(y) \n    return np.array(dataX)\n\ndata_new=create_dataset(train1,train2)\n</code></pre>\n\n<p>It is returning a dataset of shape 0(2,201,4). I think this is appending differently, but I want row wise appending. so that the new _dataset is of shape= (402,4) with two sets and (603,4) with three sets. I want to generalize as well like if I want for 10 training sets or twenty training sets. How can I do that?</p>\n",
                "tags": "<python><deep-learning><numpy>",
                "answers": [
                    [
                        "34195",
                        "2",
                        "34181",
                        "",
                        "",
                        "<p>I think its because of the way you are appending the datasets in list and then converting it to numpy array.</p>\n\n<p><strong>Solution 1</strong></p>\n\n<p>One quick solution is to reshape your array as -</p>\n\n<p><code>data_new = data_new.reshape(data_new.shape[0]*data_new.shape[1], data_new.shape[2])</code></p>\n\n<p>So, your data of shape (2,201,4) will become (2*201,4) = (402,4).</p>\n\n<p><strong>Solution 2</strong></p>\n\n<p>Another solution is to append the arrays in the function you have defined, instead of returning <code>np.array(dataX)</code>, use -</p>\n\n<pre><code>return np.append(x, y, axis = 0)\n</code></pre>\n\n<p>So, you don't have to use <code>dataX</code> anywhere.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11365",
            "_score": 9.520309,
            "_source": {
                "title": "how to make new columns using another column in pandas?",
                "content": "how to make new columns using another column in pandas? <p>i have a dataframe like this<a href=\"https://i.stack.imgur.com/HC13y.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/HC13y.png\" alt=\"enter image description here\"></a></p>\n\n<p>i want to add new column and my desire format is like this<a href=\"https://i.stack.imgur.com/RcxqE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/RcxqE.png\" alt=\"enter image description here\"></a></p>\n\n<p>i use indexing eg\n dll.loc[:6,'category'] = \"sectowise\"\ndll.loc[7:11,'category'] = \"productwise\"\ndll.loc[12:16,'category'] = \"collateral wise\"\nbut which is risky because data index can change anytime \nis there any method to do this?</p>\n <python><pandas><p>Here is an example (I just through it together hastily). You can probably do this a little bit smoother.</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom random import shuffle\n\na = np.repeat(['a', 'b', 'c', 'd', 'e'], 6)\nx = np.random.randn(30)\ny = np.random.randn(30)\nz = np.random.randn(30)\n\nshuffle(a)\n\na = a.reshape(30, 1)\nx = x.reshape(30, 1)\ny = y.reshape(30, 1)\nz = z.reshape(30, 1)\n\ndata = np.concatenate((a, x, y, z), axis=1)\ndf = pd.DataFrame(data, columns=['item', 'x', 'y', 'z'])\n\nmapping = {'1': ['a', 'b'], '2': ['d'], '3': ['c', 'e']}\n\nfor k in mapping:\n    df.loc[df[df['item'].mask(\n        ~df.item.isin(mapping[k])).notnull()].index.tolist(), 'category'] = k\n</code></pre>\n",
                "codes": [
                    [
                        "import pandas as pd\nimport numpy as np\nfrom random import shuffle\n\na = np.repeat(['a', 'b', 'c', 'd', 'e'], 6)\nx = np.random.randn(30)\ny = np.random.randn(30)\nz = np.random.randn(30)\n\nshuffle(a)\n\na = a.reshape(30, 1)\nx = x.reshape(30, 1)\ny = y.reshape(30, 1)\nz = z.reshape(30, 1)\n\ndata = np.concatenate((a, x, y, z), axis=1)\ndf = pd.DataFrame(data, columns=['item', 'x', 'y', 'z'])\n\nmapping = {'1': ['a', 'b'], '2': ['d'], '3': ['c', 'e']}\n\nfor k in mapping:\n    df.loc[df[df['item'].mask(\n        ~df.item.isin(mapping[k])).notnull()].index.tolist(), 'category'] = k\n"
                    ]
                ],
                "question_id:": "40133",
                "question_votes:": "",
                "question_text:": "<p>i have a dataframe like this<a href=\"https://i.stack.imgur.com/HC13y.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/HC13y.png\" alt=\"enter image description here\"></a></p>\n\n<p>i want to add new column and my desire format is like this<a href=\"https://i.stack.imgur.com/RcxqE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/RcxqE.png\" alt=\"enter image description here\"></a></p>\n\n<p>i use indexing eg\n dll.loc[:6,'category'] = \"sectowise\"\ndll.loc[7:11,'category'] = \"productwise\"\ndll.loc[12:16,'category'] = \"collateral wise\"\nbut which is risky because data index can change anytime \nis there any method to do this?</p>\n",
                "tags": "<python><pandas>",
                "answers": [
                    [
                        "40210",
                        "2",
                        "40133",
                        "",
                        "",
                        "<p>Here is an example (I just through it together hastily). You can probably do this a little bit smoother.</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom random import shuffle\n\na = np.repeat(['a', 'b', 'c', 'd', 'e'], 6)\nx = np.random.randn(30)\ny = np.random.randn(30)\nz = np.random.randn(30)\n\nshuffle(a)\n\na = a.reshape(30, 1)\nx = x.reshape(30, 1)\ny = y.reshape(30, 1)\nz = z.reshape(30, 1)\n\ndata = np.concatenate((a, x, y, z), axis=1)\ndf = pd.DataFrame(data, columns=['item', 'x', 'y', 'z'])\n\nmapping = {'1': ['a', 'b'], '2': ['d'], '3': ['c', 'e']}\n\nfor k in mapping:\n    df.loc[df[df['item'].mask(\n        ~df.item.isin(mapping[k])).notnull()].index.tolist(), 'category'] = k\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7813",
            "_score": 9.482446,
            "_source": {
                "title": "SVM with multiple features",
                "content": "SVM with multiple features <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nstyle.use(\"ggplot\")\nfrom sklearn import svm\n\n\nX=[[1,0,0,0,0],\n           [0,1,0,0,0],\n           [0,0,1,0,0],\n           [1,0,0,1,0],\n           [1,0,0,0,1]] \n\ny=[0,1,1,1,0]\n\nmodel=svm.SVC()\nmodel.fit(X,y)\nprint(model.predict([1,0,1,0,0]))\n</code></pre>\n\n<p>I was working on this but Iam getting an error as </p>\n\n<pre><code>\"if it contains a single sample.\".format(array))\nValueError: Expected 2D array, got 1D array instead:\narray=[1. 0. 1. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single fe\nature or array.reshape(1, -1) if it contains a single sample.\n</code></pre>\n\n<p>Iam new to this can u guys help me out?</p>\n <python><classification><scikit-learn><svm><p>Your inputs are lists but they need to be arrays. </p>\n\n<pre><code>X=np.array([[1,0,0,0,0],\n           [0,1,0,0,0],\n           [0,0,1,0,0],\n           [1,0,0,1,0],\n           [1,0,0,0,1]])\n\ny=np.array([0,1,1,1,0])\n</code></pre>\n<p>After having performed </p>\n\n<pre><code>X=np.array([[1,0,0,0,0],\n           [0,1,0,0,0],\n           [0,0,1,0,0],\n           [1,0,0,1,0],\n           [1,0,0,0,1]])\n\ny=np.array([0,1,1,1,0])\n</code></pre>\n\n<p>you have to do the following:</p>\n\n<pre><code>y = y.reshape(1, -1)\n\nmodel=svm.SVC()\nmodel.fit(X,y)\ntest = np.array([1,0,1,0,0])\ntest = test.reshape(1,-1)\nprint(model.predict(test))\n</code></pre>\n\n<p>In future you have to scale your dataset. You can use either Standard Scaler (suggested) or MinMax Scaler. </p>\n",
                "codes": [
                    [
                        "X=np.array([[1,0,0,0,0],\n           [0,1,0,0,0],\n           [0,0,1,0,0],\n           [1,0,0,1,0],\n           [1,0,0,0,1]])\n\ny=np.array([0,1,1,1,0])\n"
                    ],
                    [
                        "X=np.array([[1,0,0,0,0],\n           [0,1,0,0,0],\n           [0,0,1,0,0],\n           [1,0,0,1,0],\n           [1,0,0,0,1]])\n\ny=np.array([0,1,1,1,0])\n",
                        "y = y.reshape(1, -1)\n\nmodel=svm.SVC()\nmodel.fit(X,y)\ntest = np.array([1,0,1,0,0])\ntest = test.reshape(1,-1)\nprint(model.predict(test))\n"
                    ]
                ],
                "question_id:": "28987",
                "question_votes:": "1",
                "question_text:": "<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nstyle.use(\"ggplot\")\nfrom sklearn import svm\n\n\nX=[[1,0,0,0,0],\n           [0,1,0,0,0],\n           [0,0,1,0,0],\n           [1,0,0,1,0],\n           [1,0,0,0,1]] \n\ny=[0,1,1,1,0]\n\nmodel=svm.SVC()\nmodel.fit(X,y)\nprint(model.predict([1,0,1,0,0]))\n</code></pre>\n\n<p>I was working on this but Iam getting an error as </p>\n\n<pre><code>\"if it contains a single sample.\".format(array))\nValueError: Expected 2D array, got 1D array instead:\narray=[1. 0. 1. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single fe\nature or array.reshape(1, -1) if it contains a single sample.\n</code></pre>\n\n<p>Iam new to this can u guys help me out?</p>\n",
                "tags": "<python><classification><scikit-learn><svm>",
                "answers": [
                    [
                        "28991",
                        "2",
                        "28987",
                        "",
                        "",
                        "<p>Your inputs are lists but they need to be arrays. </p>\n\n<pre><code>X=np.array([[1,0,0,0,0],\n           [0,1,0,0,0],\n           [0,0,1,0,0],\n           [1,0,0,1,0],\n           [1,0,0,0,1]])\n\ny=np.array([0,1,1,1,0])\n</code></pre>\n",
                        "",
                        ""
                    ],
                    [
                        "30228",
                        "2",
                        "28987",
                        "",
                        "",
                        "<p>After having performed </p>\n\n<pre><code>X=np.array([[1,0,0,0,0],\n           [0,1,0,0,0],\n           [0,0,1,0,0],\n           [1,0,0,1,0],\n           [1,0,0,0,1]])\n\ny=np.array([0,1,1,1,0])\n</code></pre>\n\n<p>you have to do the following:</p>\n\n<pre><code>y = y.reshape(1, -1)\n\nmodel=svm.SVC()\nmodel.fit(X,y)\ntest = np.array([1,0,1,0,0])\ntest = test.reshape(1,-1)\nprint(model.predict(test))\n</code></pre>\n\n<p>In future you have to scale your dataset. You can use either Standard Scaler (suggested) or MinMax Scaler. </p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10181",
            "_score": 9.371016,
            "_source": {
                "title": "Preprocessing of Sudoku Dataset from Kaggle",
                "content": "Preprocessing of Sudoku Dataset from Kaggle <p>Dataset: <a href=\"https://www.kaggle.com/bryanpark/sudoku\" rel=\"nofollow noreferrer\">https://www.kaggle.com/bryanpark/sudoku</a></p>\n\n<p>I would like to create a neural network for this Dataset.</p>\n\n<p>Feature:</p>\n\n<p><code>X:  [ '004300209005009001070060043006002087190007400050083000600000105003508690042910300'\n '040100050107003960520008000000000017000906800803050620090060543600080700250097100']\n</code></p>\n\n<p>Output:</p>\n\n<p><code>Y:  [ '864371259325849761971265843436192587198657432257483916689734125713528694542916378'\n '346179258187523964529648371965832417472916835813754629798261543631485792254397186']</code></p>\n\n<p>The zeros represent a blank box, and the data is a flattened grid of 9x9.</p>\n\n<p>I tried using the following code, but I found out that the data needs a significant amount of preprocessing.</p>\n\n<pre><code>def preprocess():\n\ndata = pd.read_csv('Sudoku/sudoku.csv')\nprint('Data: ', data.head())\n\nx = data[data.columns[0]].values\ny = data[data.columns[1]].values\n\nx = x.reshape(-1, 1)\ny = y.reshape(-1, 1)\n\nprint('\\nx: ', x[0])\nprint('\\ny: ', y[0])\n\nreturn x, y\n\n\nx, y = preprocess()\ntrain_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2)\n\nscl = StandardScaler()\ntrain_x = scl.fit_transform(train_x)\ntrain_y = scl.fit_transform(train_y)\ntest_x = scl.fit_transform(test_x)\ntest_y = scl.fit_transform(test_y)\n\nmodel = Sequential()\nmodel.add(Dense(100, input_dim=1, activation='relu'))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(1, activation='linear'))\nmodel.compile(optimizer='adam', loss='mean_squared_error')\nmodel.fit(train_x, train_y, epochs=3, validation_split=0.1, verbose=2)\n</code></pre>\n\n<p>I would like to know how to work with this data and of course, also the structure of my neural network.</p>\n <machine-learning><neural-network><keras><regression><preprocessing><p>You need to convert this large list of strings to a numpy array containing lists of integers. Here is how you can get the data into the correct format for a neural network:</p>\n\n<pre><code>import pandas as pd\nfrom numpy import array\n\ndef preprocess():\n\n    data = pd.read_csv('sudoku.csv')\n\n    x = data[data.columns[0]].values\n    y = data[data.columns[1]].values\n\n    x = x.reshape(-1, 1)\n    y = y.reshape(-1, 1)\n\n    x = array([list(map(int,set[0])) for set in x])\n    y = array([list(map(int,set[0])) for set in y])\n\n    return x, y\n\nx, y = preprocess()\n\nprint('\\nx: ', x[0])\nprint('\\ny: ', y[0])\n</code></pre>\n\n<p>I haven't thought enough about the problem to advise on how best to go about solving it, but at least this should get you started on playing around with different methods. Be aware that it will take a minute or so to run, as the script is now converting a large amount of strings to integers.</p>\n<p><a href=\"https://www.kaggle.com/dithyrambe/neural-nets-as-sudoku-solvers\" rel=\"nofollow noreferrer\">here</a> you can see a very good answer.\nFor kaggle competition see kernels.</p>\n",
                "codes": [
                    [
                        "import pandas as pd\nfrom numpy import array\n\ndef preprocess():\n\n    data = pd.read_csv('sudoku.csv')\n\n    x = data[data.columns[0]].values\n    y = data[data.columns[1]].values\n\n    x = x.reshape(-1, 1)\n    y = y.reshape(-1, 1)\n\n    x = array([list(map(int,set[0])) for set in x])\n    y = array([list(map(int,set[0])) for set in y])\n\n    return x, y\n\nx, y = preprocess()\n\nprint('\\nx: ', x[0])\nprint('\\ny: ', y[0])\n"
                    ],
                    []
                ],
                "question_id:": "36818",
                "question_votes:": "1",
                "question_text:": "<p>Dataset: <a href=\"https://www.kaggle.com/bryanpark/sudoku\" rel=\"nofollow noreferrer\">https://www.kaggle.com/bryanpark/sudoku</a></p>\n\n<p>I would like to create a neural network for this Dataset.</p>\n\n<p>Feature:</p>\n\n<p><code>X:  [ '004300209005009001070060043006002087190007400050083000600000105003508690042910300'\n '040100050107003960520008000000000017000906800803050620090060543600080700250097100']\n</code></p>\n\n<p>Output:</p>\n\n<p><code>Y:  [ '864371259325849761971265843436192587198657432257483916689734125713528694542916378'\n '346179258187523964529648371965832417472916835813754629798261543631485792254397186']</code></p>\n\n<p>The zeros represent a blank box, and the data is a flattened grid of 9x9.</p>\n\n<p>I tried using the following code, but I found out that the data needs a significant amount of preprocessing.</p>\n\n<pre><code>def preprocess():\n\ndata = pd.read_csv('Sudoku/sudoku.csv')\nprint('Data: ', data.head())\n\nx = data[data.columns[0]].values\ny = data[data.columns[1]].values\n\nx = x.reshape(-1, 1)\ny = y.reshape(-1, 1)\n\nprint('\\nx: ', x[0])\nprint('\\ny: ', y[0])\n\nreturn x, y\n\n\nx, y = preprocess()\ntrain_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2)\n\nscl = StandardScaler()\ntrain_x = scl.fit_transform(train_x)\ntrain_y = scl.fit_transform(train_y)\ntest_x = scl.fit_transform(test_x)\ntest_y = scl.fit_transform(test_y)\n\nmodel = Sequential()\nmodel.add(Dense(100, input_dim=1, activation='relu'))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(1, activation='linear'))\nmodel.compile(optimizer='adam', loss='mean_squared_error')\nmodel.fit(train_x, train_y, epochs=3, validation_split=0.1, verbose=2)\n</code></pre>\n\n<p>I would like to know how to work with this data and of course, also the structure of my neural network.</p>\n",
                "tags": "<machine-learning><neural-network><keras><regression><preprocessing>",
                "answers": [
                    [
                        "36893",
                        "2",
                        "36818",
                        "",
                        "",
                        "<p>You need to convert this large list of strings to a numpy array containing lists of integers. Here is how you can get the data into the correct format for a neural network:</p>\n\n<pre><code>import pandas as pd\nfrom numpy import array\n\ndef preprocess():\n\n    data = pd.read_csv('sudoku.csv')\n\n    x = data[data.columns[0]].values\n    y = data[data.columns[1]].values\n\n    x = x.reshape(-1, 1)\n    y = y.reshape(-1, 1)\n\n    x = array([list(map(int,set[0])) for set in x])\n    y = array([list(map(int,set[0])) for set in y])\n\n    return x, y\n\nx, y = preprocess()\n\nprint('\\nx: ', x[0])\nprint('\\ny: ', y[0])\n</code></pre>\n\n<p>I haven't thought enough about the problem to advise on how best to go about solving it, but at least this should get you started on playing around with different methods. Be aware that it will take a minute or so to run, as the script is now converting a large amount of strings to integers.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "36912",
                        "2",
                        "36818",
                        "",
                        "",
                        "<p><a href=\"https://www.kaggle.com/dithyrambe/neural-nets-as-sudoku-solvers\" rel=\"nofollow noreferrer\">here</a> you can see a very good answer.\nFor kaggle competition see kernels.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17527",
            "_score": 9.281776,
            "_source": {
                "title": "Performing LSTM on multiple columns in Python",
                "content": "Performing LSTM on multiple columns in Python <p>I have a LSTM neural network to test the prediction ability of this network and it works for one column.  But now I want to use several columns for different items and calculate the 'ABSE' for every column. For example if I have two columns:</p>\n\n<p><a href=\"https://i.stack.imgur.com/op6P4.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/op6P4.png\" alt=\"enter image description here\"></a></p>\n\n<p>It needs to calculate the 'ABSE' function for every column separately. </p>\n\n<p>My code below fails. Can somebody help me?</p>\n\n<p>This is what I tried, but I get a value error:</p>\n\n<pre><code>ValueError: non-broadcastable output operand with shape (1,1) doesn't \nmatch the broadcast shape (1,2)\n</code></pre>\n\n<p>This happens on the line: </p>\n\n<pre><code> ---&gt; 51     trainPredict = scaler.inverse_transform(trainPredict)\n</code></pre>\n\n<p>the code:</p>\n\n<pre><code>def create_dataset(dataset, look_back=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1):\n        a = dataset[i:(i+look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n        return numpy.array(dataX), numpy.array(dataY)\n\ndef ABSE(a,b):\n    ABSE = abs((b-a)/b)\n    return numpy.mean(ABSE)\n\ncolumns = df[['Item1','Item2']]\n\nfor i in columns:\n    # normalize the dataset\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    dataset = scaler.fit_transform(dataset)\n    # split into train and test sets\n    train_size = int(len(dataset) * 0.5)\n    test_size = 1- train_size\n    train, test = dataset[0:train_size,:], \n    dataset[train_size:len(dataset),:]\n    look_back = 1\n    trainX, trainY = create_dataset(train, look_back)\n    testX, testY = create_dataset(test, look_back)\n    trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n    testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n    # create and fit the LSTM network\n    model = Sequential()\n    model.add(LSTM(1, input_shape=(1, look_back)))\n    model.add(Dense(1))\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    model.fit(trainX, trainY, epochs=1, batch_size = 1, verbose = 0)\n    # make predictions\n    trainPredict = model.predict(trainX)\n    testPredict = model.predict(testX)\n    # invert predictions\n    trainPredict = scaler.inverse_transform(trainPredict)\n    trainY = scaler.inverse_transform([trainY])\n    testPredict = scaler.inverse_transform(testPredict)\n    testY = scaler.inverse_transform([testY])\n    # calculate root mean squared error\n    trainScore = ABSE(trainY[0], trainPredict[:,0])\n    print('Train Score: %.2f ABSE' % (trainScore))\n    testScore = ABSE(testY[0], testPredict[:,0])\n    print('Test Score: %.2f ABSE' % (testScore))\n    print(testY[0].T,testPredict[:,0].T)\n</code></pre>\n <machine-learning><python>",
                "codes": [],
                "question_id:": "56398",
                "question_votes:": "",
                "question_text:": "<p>I have a LSTM neural network to test the prediction ability of this network and it works for one column.  But now I want to use several columns for different items and calculate the 'ABSE' for every column. For example if I have two columns:</p>\n\n<p><a href=\"https://i.stack.imgur.com/op6P4.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/op6P4.png\" alt=\"enter image description here\"></a></p>\n\n<p>It needs to calculate the 'ABSE' function for every column separately. </p>\n\n<p>My code below fails. Can somebody help me?</p>\n\n<p>This is what I tried, but I get a value error:</p>\n\n<pre><code>ValueError: non-broadcastable output operand with shape (1,1) doesn't \nmatch the broadcast shape (1,2)\n</code></pre>\n\n<p>This happens on the line: </p>\n\n<pre><code> ---&gt; 51     trainPredict = scaler.inverse_transform(trainPredict)\n</code></pre>\n\n<p>the code:</p>\n\n<pre><code>def create_dataset(dataset, look_back=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1):\n        a = dataset[i:(i+look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n        return numpy.array(dataX), numpy.array(dataY)\n\ndef ABSE(a,b):\n    ABSE = abs((b-a)/b)\n    return numpy.mean(ABSE)\n\ncolumns = df[['Item1','Item2']]\n\nfor i in columns:\n    # normalize the dataset\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    dataset = scaler.fit_transform(dataset)\n    # split into train and test sets\n    train_size = int(len(dataset) * 0.5)\n    test_size = 1- train_size\n    train, test = dataset[0:train_size,:], \n    dataset[train_size:len(dataset),:]\n    look_back = 1\n    trainX, trainY = create_dataset(train, look_back)\n    testX, testY = create_dataset(test, look_back)\n    trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n    testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n    # create and fit the LSTM network\n    model = Sequential()\n    model.add(LSTM(1, input_shape=(1, look_back)))\n    model.add(Dense(1))\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    model.fit(trainX, trainY, epochs=1, batch_size = 1, verbose = 0)\n    # make predictions\n    trainPredict = model.predict(trainX)\n    testPredict = model.predict(testX)\n    # invert predictions\n    trainPredict = scaler.inverse_transform(trainPredict)\n    trainY = scaler.inverse_transform([trainY])\n    testPredict = scaler.inverse_transform(testPredict)\n    testY = scaler.inverse_transform([testY])\n    # calculate root mean squared error\n    trainScore = ABSE(trainY[0], trainPredict[:,0])\n    print('Train Score: %.2f ABSE' % (trainScore))\n    testScore = ABSE(testY[0], testPredict[:,0])\n    print('Test Score: %.2f ABSE' % (testScore))\n    print(testY[0].T,testPredict[:,0].T)\n</code></pre>\n",
                "tags": "<machine-learning><python>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3087",
            "_score": 9.27024,
            "_source": {
                "title": "How can I get prediction for only one instance in Keras?",
                "content": "How can I get prediction for only one instance in Keras? <p>When I request Keras to apply prediction with a fitted model to a new dataset without label like this:</p>\n\n<pre><code>model1.predict_classes(X_test)\n</code></pre>\n\n<p>it works fine. But when I try to make prediction for only one row, it fails:</p>\n\n<pre><code>model1.predict_classes(X_test[10])\n\nException: Error when checking : expected dense_input_6 to have shape (None, 784) but got array with shape (784, 1)\n</code></pre>\n\n<p>I wonder, why?</p>\n <neural-network><keras><p>You should pass a list with just 1 example, I can't test right now but this should work:</p>\n\n<pre><code>model1.predict_classes([X_test[10]])\n</code></pre>\n<p>This would be how to predict for one element, this time number 17.</p>\n\n<pre><code>model.predict_classes(X_test[17:18])\n</code></pre>\n<p>Currently (Keras v2.0.8) it takes a bit more effort to get predictions on single rows after training in batch. </p>\n\n<p>Basically, the batch_size is fixed at training time, and has to be the same at prediction time. </p>\n\n<p>The workaround right now is to take the weights from the trained model, and use those as the weights in a new model you've just created, which has a batch_size of 1.</p>\n\n<p>The quick code for that is</p>\n\n<pre><code>model = create_model(batch_size=64)\nmode.fit(X, y)\nweights = model.get_weights()\nsingle_item_model = create_model(batch_size=1)\nsingle_item_model.set_weights(weights)\nsingle_item_model.compile(compile_params)\n</code></pre>\n\n<p>Here's a blog post that goes into more depth: \n<a href=\"https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/\" rel=\"nofollow noreferrer\">https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/</a></p>\n\n<p>I've used this approach in the past to have multiple models at prediction time- one that makes predictions on big batches, one that makes predictions on small batches, and one that makes predictions on single items. Since batch predictions are much more efficient, this gives us the flexibility to take in any number of prediction rows (not just a number that is evenly divisible by batch_size), while still getting predictions pretty rapidly.</p>\n<p>if you try to print out the instance you will see this:</p>\n\n<pre><code>x_test:\\n\narray([[0., 1., 1., ..., 0., 0., 0.],\n        [0., 1., 1., ..., 0., 0., 0.],\n        [0., 1., 1., ..., 0., 0., 0.],\n        ...,\n        [0., 1., 0., ..., 0., 0., 0.],\n        [0., 1., 1., ..., 0., 0., 0.],\n        [0., 1., 1., ..., 0., 0., 0.]])\n\nx_test[0]:\narray([0., 1., 1., ..., 0., 0., 0.])\n</code></pre>\n\n<p>so I think we can just add back a dimension using np.array:</p>\n\n<pre><code>mode.predict(np.array(x_test[0],ndmin=2))\n</code></pre>\n<p>It means that your training data had the shape of (784, 1). You can just reshape it as the following. It worked for me. </p>\n\n<pre><code>model1.predict_classes(X_test[10].reshape(784,1))\n</code></pre>\n\n<p>You can also do <code>transpose()</code> if shape is (1,784), </p>\n\n<pre><code>model1.predict_classes(X_test[10].transpose())\n</code></pre>\n<pre><code>self.result = self.model.predict(X)\n</code></pre>\n\n<p>where X is numpy array. That is all I did and it worked.</p>\n<p>I have fixed this by using the following approach:</p>\n\n<pre><code>single_test = X_test[10]\nsingle_test = single_test.reshape(1,784)\n</code></pre>\n\n<p>Please note that amount of features (784) in the reshape function is based on your example above, if you have fewer features then you need to adjust it.</p>\n\n<p>Hope it will work for you too.</p>\n<p>You can do:</p>\n\n<pre><code>q = model.predict( np.array( [single_x_test,] )  )\n</code></pre>\n<p><code>predict_classes</code> is expecting a 2D array of shape <code>(num_instances, features)</code>, like <code>X_test</code> is. But indexing a single instance as in <code>X_test[10]</code> returns a 1D array of shape <code>(features,)</code>.</p>\n\n<p>To add back the extra axis, you can use <a href=\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.expand_dims.html#numpy.expand_dims\" rel=\"noreferrer\"><code>np.expand_dims</code></a><code>(X_test[10], axis=0)</code>, or <code>X_test[10][np.newaxis,:]</code>, or don't get rid of it in the first place (e.g., by using <code>X_test[10:11]</code>).</p>\n",
                "codes": [
                    [
                        "model1.predict_classes([X_test[10]])\n"
                    ],
                    [
                        "model.predict_classes(X_test[17:18])\n"
                    ],
                    [
                        "model = create_model(batch_size=64)\nmode.fit(X, y)\nweights = model.get_weights()\nsingle_item_model = create_model(batch_size=1)\nsingle_item_model.set_weights(weights)\nsingle_item_model.compile(compile_params)\n"
                    ],
                    [
                        "x_test:\\n\narray([[0., 1., 1., ..., 0., 0., 0.],\n        [0., 1., 1., ..., 0., 0., 0.],\n        [0., 1., 1., ..., 0., 0., 0.],\n        ...,\n        [0., 1., 0., ..., 0., 0., 0.],\n        [0., 1., 1., ..., 0., 0., 0.],\n        [0., 1., 1., ..., 0., 0., 0.]])\n\nx_test[0]:\narray([0., 1., 1., ..., 0., 0., 0.])\n",
                        "mode.predict(np.array(x_test[0],ndmin=2))\n"
                    ],
                    [
                        "model1.predict_classes(X_test[10].reshape(784,1))\n",
                        "model1.predict_classes(X_test[10].transpose())\n"
                    ],
                    [
                        "self.result = self.model.predict(X)\n"
                    ],
                    [
                        "single_test = X_test[10]\nsingle_test = single_test.reshape(1,784)\n"
                    ],
                    [
                        "q = model.predict( np.array( [single_x_test,] )  )\n"
                    ],
                    []
                ],
                "question_id:": "13461",
                "question_votes:": "7",
                "question_text:": "<p>When I request Keras to apply prediction with a fitted model to a new dataset without label like this:</p>\n\n<pre><code>model1.predict_classes(X_test)\n</code></pre>\n\n<p>it works fine. But when I try to make prediction for only one row, it fails:</p>\n\n<pre><code>model1.predict_classes(X_test[10])\n\nException: Error when checking : expected dense_input_6 to have shape (None, 784) but got array with shape (784, 1)\n</code></pre>\n\n<p>I wonder, why?</p>\n",
                "tags": "<neural-network><keras>",
                "answers": [
                    [
                        "13462",
                        "2",
                        "13461",
                        "",
                        "",
                        "<p>You should pass a list with just 1 example, I can't test right now but this should work:</p>\n\n<pre><code>model1.predict_classes([X_test[10]])\n</code></pre>\n",
                        "",
                        "1"
                    ],
                    [
                        "26191",
                        "2",
                        "13461",
                        "",
                        "",
                        "<p>This would be how to predict for one element, this time number 17.</p>\n\n<pre><code>model.predict_classes(X_test[17:18])\n</code></pre>\n",
                        "",
                        "3"
                    ],
                    [
                        "23121",
                        "2",
                        "13461",
                        "",
                        "",
                        "<p>Currently (Keras v2.0.8) it takes a bit more effort to get predictions on single rows after training in batch. </p>\n\n<p>Basically, the batch_size is fixed at training time, and has to be the same at prediction time. </p>\n\n<p>The workaround right now is to take the weights from the trained model, and use those as the weights in a new model you've just created, which has a batch_size of 1.</p>\n\n<p>The quick code for that is</p>\n\n<pre><code>model = create_model(batch_size=64)\nmode.fit(X, y)\nweights = model.get_weights()\nsingle_item_model = create_model(batch_size=1)\nsingle_item_model.set_weights(weights)\nsingle_item_model.compile(compile_params)\n</code></pre>\n\n<p>Here's a blog post that goes into more depth: \n<a href=\"https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/\" rel=\"nofollow noreferrer\">https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/</a></p>\n\n<p>I've used this approach in the past to have multiple models at prediction time- one that makes predictions on big batches, one that makes predictions on small batches, and one that makes predictions on single items. Since batch predictions are much more efficient, this gives us the flexibility to take in any number of prediction rows (not just a number that is evenly divisible by batch_size), while still getting predictions pretty rapidly.</p>\n",
                        "",
                        "4"
                    ],
                    [
                        "43204",
                        "2",
                        "13461",
                        "",
                        "",
                        "<p>if you try to print out the instance you will see this:</p>\n\n<pre><code>x_test:\\n\narray([[0., 1., 1., ..., 0., 0., 0.],\n        [0., 1., 1., ..., 0., 0., 0.],\n        [0., 1., 1., ..., 0., 0., 0.],\n        ...,\n        [0., 1., 0., ..., 0., 0., 0.],\n        [0., 1., 1., ..., 0., 0., 0.],\n        [0., 1., 1., ..., 0., 0., 0.]])\n\nx_test[0]:\narray([0., 1., 1., ..., 0., 0., 0.])\n</code></pre>\n\n<p>so I think we can just add back a dimension using np.array:</p>\n\n<pre><code>mode.predict(np.array(x_test[0],ndmin=2))\n</code></pre>\n",
                        "",
                        "1"
                    ],
                    [
                        "56187",
                        "2",
                        "13461",
                        "",
                        "",
                        "<p>It means that your training data had the shape of (784, 1). You can just reshape it as the following. It worked for me. </p>\n\n<pre><code>model1.predict_classes(X_test[10].reshape(784,1))\n</code></pre>\n\n<p>You can also do <code>transpose()</code> if shape is (1,784), </p>\n\n<pre><code>model1.predict_classes(X_test[10].transpose())\n</code></pre>\n",
                        "",
                        ""
                    ],
                    [
                        "24582",
                        "2",
                        "13461",
                        "",
                        "",
                        "<pre><code>self.result = self.model.predict(X)\n</code></pre>\n\n<p>where X is numpy array. That is all I did and it worked.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "39527",
                        "2",
                        "13461",
                        "",
                        "",
                        "<p>I have fixed this by using the following approach:</p>\n\n<pre><code>single_test = X_test[10]\nsingle_test = single_test.reshape(1,784)\n</code></pre>\n\n<p>Please note that amount of features (784) in the reshape function is based on your example above, if you have fewer features then you need to adjust it.</p>\n\n<p>Hope it will work for you too.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "23630",
                        "2",
                        "13461",
                        "",
                        "",
                        "<p>You can do:</p>\n\n<pre><code>q = model.predict( np.array( [single_x_test,] )  )\n</code></pre>\n",
                        "",
                        "10"
                    ],
                    [
                        "13463",
                        "2",
                        "13461",
                        "",
                        "",
                        "<p><code>predict_classes</code> is expecting a 2D array of shape <code>(num_instances, features)</code>, like <code>X_test</code> is. But indexing a single instance as in <code>X_test[10]</code> returns a 1D array of shape <code>(features,)</code>.</p>\n\n<p>To add back the extra axis, you can use <a href=\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.expand_dims.html#numpy.expand_dims\" rel=\"noreferrer\"><code>np.expand_dims</code></a><code>(X_test[10], axis=0)</code>, or <code>X_test[10][np.newaxis,:]</code>, or don't get rid of it in the first place (e.g., by using <code>X_test[10:11]</code>).</p>\n",
                        "",
                        "6"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12215",
            "_score": 9.27024,
            "_source": {
                "title": "How to solve this ? Value Error : operands could not be broadcast together with shapes (0,) (100,522)",
                "content": "How to solve this ? Value Error : operands could not be broadcast together with shapes (0,) (100,522) <p>I am trying to apply a PSO algorithm to train a neural network applied to \"User Identification From Walking Activity Data Set\" problem. Can be found <a href=\"https://archive.ics.uci.edu/ml/datasets/User+Identification+From+Walking+Activity\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<p>So i extrated the dataset, and calculated average value and standard deviation between aceleration x,y and z at every 5 seconds for each person that would be the input of my neural network. After this i try to optimize the weights and bias of the neural network with Pyswarms functions, but i get an error which i dont know where it is coming from.</p>\n\n<p>The Code : </p>\n\n<pre><code>import numpy as np\nimport statistics as st\nimport pyswarms as ps\nimport matplotlib.pyplot as plt\nfrom sklearn.neural_network import MLPClassifier\n\n#EXTRACTING THE DATASET AND CREATING INPUTS AND TARGETS/LABELS\ndef load_input():\n  data = np.empty((0,3),float)\n  for x in range(1,23):\n        fich = np.loadtxt(\"%d.csv\" %x,delimiter=\",\");\n        aux = []\n        value = 5.0;#5 seconds for each person\n        for y in range(0,len(fich)):\n            if fich[y][0] &lt;= value :\n                aux.append(fich[y,1])\n                aux.append(fich[y,2])\n                aux.append(fich[y,3])\n            elif fich[y,0] &gt; value or y == len(fich): \n                data = np.append(data,np.asfarray([[np.mean(aux),np.std(aux),x-1]]), axis =0);\n                y = y-1;\n                aux[:] = []\n                value = value + 5;\n  return data\n\n\n#OPTIMIZING WEIGHTS AND BIAS\ndef forward_prop(params):\n n_inputs = 2\n n_hidden = 20\n n_classes = 22\n\n W1 = params[0:40].reshape((n_inputs,n_hidden))\n b1 = params[40:60].reshape((n_hidden,))\n W2 = params[60:500].reshape((n_hidden,n_classes))\n b2 = params[500:522].reshape((n_classes,))\n\n z1 = X.dot(W1) + b1 # Pre-activation in Layer 1\n a1 = np.tanh(z1) # Activation in Layer 1\n z2 = a1.dot(W2) + b2 # Pre-activation in Layer 2\n logits = z2 # Logits for Layer 2\n\n exp_scores = np.exp(logits)\n probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n # Compute for the negative log likelihood\n N = 923 # Number of samples\n corect_logprobs = -np.log(probs[range(N), Y])\n loss = np.sum(corect_logprobs) / N\n return loss\n\n\ndef f(x):\n \"\"\"Higher-level method to do forward_prop in the\n whole swarm.\n Inputs\n ------\n x: numpy.ndarray of shape (n_particles, dimensions)\n The swarm that will perform the search\n Returns\n -------\n numpy.ndarray of shape (n_particles, )\n The computed loss for each particle\n \"\"\"\n n_particles = x.shape[0]\n j = [forward_prop(x[i]) for i in range(n_particles)]\n return np.array(j)\n\n\n##### MAIN FUNCTION #####   \ndata = load_input();\nX = data[:,[0,1]];\nY = data[:,2].astype(int)\n# Initialize swarm\noptions = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n# Call instance of PSO\ndimensions = (2 * 20) + (20 * 22) + 20 + 22\noptimizer = ps.single.GlobalBestPSO(n_particles=100, \ndimensions=dimensions,options=options)\n# Perform optimization\ncost, pos = optimizer.optimize(f, print_step=100, iters=1000, verbose=3)\n</code></pre>\n\n<p>Examples of Inputs and target matrixes : \n<a href=\"https://i.stack.imgur.com/O7gMo.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/O7gMo.png\" alt=\"enter image description here\"></a></p>\n <python><neural-network><p>This should be on stackoverflow, with a precise description of the error (line, traceback...), but the error seems to be here:</p>\n\n<pre><code>np.empty((0,3),float)\n</code></pre>\n\n<p>And then not appending the data as expected.</p>\n\n<p>If you are doing this, use a list, and then at the end, transform your data in a numpy array:</p>\n\n<pre><code>data = []\n\nfor...\n    data.append(new array)\ndata = np.array(data) # add the Fortran flags if you need to\n</code></pre>\n\n<p>There would be just one memory copy instead of O(n-squared) with <code>np.append</code>.</p>\n\n<p>Also the shape for X or Y (?) seems to be 2D ((100,522)), where as you only have 1D. Check your data (which we don't have, so impossible for me to tell you exactly where to look for) so that you can ensure that the dimensions are correct.</p>\n",
                "codes": [
                    [
                        "np.empty((0,3),float)\n",
                        "data = []\n\nfor...\n    data.append(new array)\ndata = np.array(data) # add the Fortran flags if you need to\n"
                    ]
                ],
                "question_id:": "42968",
                "question_votes:": "1",
                "question_text:": "<p>I am trying to apply a PSO algorithm to train a neural network applied to \"User Identification From Walking Activity Data Set\" problem. Can be found <a href=\"https://archive.ics.uci.edu/ml/datasets/User+Identification+From+Walking+Activity\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<p>So i extrated the dataset, and calculated average value and standard deviation between aceleration x,y and z at every 5 seconds for each person that would be the input of my neural network. After this i try to optimize the weights and bias of the neural network with Pyswarms functions, but i get an error which i dont know where it is coming from.</p>\n\n<p>The Code : </p>\n\n<pre><code>import numpy as np\nimport statistics as st\nimport pyswarms as ps\nimport matplotlib.pyplot as plt\nfrom sklearn.neural_network import MLPClassifier\n\n#EXTRACTING THE DATASET AND CREATING INPUTS AND TARGETS/LABELS\ndef load_input():\n  data = np.empty((0,3),float)\n  for x in range(1,23):\n        fich = np.loadtxt(\"%d.csv\" %x,delimiter=\",\");\n        aux = []\n        value = 5.0;#5 seconds for each person\n        for y in range(0,len(fich)):\n            if fich[y][0] &lt;= value :\n                aux.append(fich[y,1])\n                aux.append(fich[y,2])\n                aux.append(fich[y,3])\n            elif fich[y,0] &gt; value or y == len(fich): \n                data = np.append(data,np.asfarray([[np.mean(aux),np.std(aux),x-1]]), axis =0);\n                y = y-1;\n                aux[:] = []\n                value = value + 5;\n  return data\n\n\n#OPTIMIZING WEIGHTS AND BIAS\ndef forward_prop(params):\n n_inputs = 2\n n_hidden = 20\n n_classes = 22\n\n W1 = params[0:40].reshape((n_inputs,n_hidden))\n b1 = params[40:60].reshape((n_hidden,))\n W2 = params[60:500].reshape((n_hidden,n_classes))\n b2 = params[500:522].reshape((n_classes,))\n\n z1 = X.dot(W1) + b1 # Pre-activation in Layer 1\n a1 = np.tanh(z1) # Activation in Layer 1\n z2 = a1.dot(W2) + b2 # Pre-activation in Layer 2\n logits = z2 # Logits for Layer 2\n\n exp_scores = np.exp(logits)\n probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n # Compute for the negative log likelihood\n N = 923 # Number of samples\n corect_logprobs = -np.log(probs[range(N), Y])\n loss = np.sum(corect_logprobs) / N\n return loss\n\n\ndef f(x):\n \"\"\"Higher-level method to do forward_prop in the\n whole swarm.\n Inputs\n ------\n x: numpy.ndarray of shape (n_particles, dimensions)\n The swarm that will perform the search\n Returns\n -------\n numpy.ndarray of shape (n_particles, )\n The computed loss for each particle\n \"\"\"\n n_particles = x.shape[0]\n j = [forward_prop(x[i]) for i in range(n_particles)]\n return np.array(j)\n\n\n##### MAIN FUNCTION #####   \ndata = load_input();\nX = data[:,[0,1]];\nY = data[:,2].astype(int)\n# Initialize swarm\noptions = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n# Call instance of PSO\ndimensions = (2 * 20) + (20 * 22) + 20 + 22\noptimizer = ps.single.GlobalBestPSO(n_particles=100, \ndimensions=dimensions,options=options)\n# Perform optimization\ncost, pos = optimizer.optimize(f, print_step=100, iters=1000, verbose=3)\n</code></pre>\n\n<p>Examples of Inputs and target matrixes : \n<a href=\"https://i.stack.imgur.com/O7gMo.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/O7gMo.png\" alt=\"enter image description here\"></a></p>\n",
                "tags": "<python><neural-network>",
                "answers": [
                    [
                        "42969",
                        "2",
                        "42968",
                        "",
                        "",
                        "<p>This should be on stackoverflow, with a precise description of the error (line, traceback...), but the error seems to be here:</p>\n\n<pre><code>np.empty((0,3),float)\n</code></pre>\n\n<p>And then not appending the data as expected.</p>\n\n<p>If you are doing this, use a list, and then at the end, transform your data in a numpy array:</p>\n\n<pre><code>data = []\n\nfor...\n    data.append(new array)\ndata = np.array(data) # add the Fortran flags if you need to\n</code></pre>\n\n<p>There would be just one memory copy instead of O(n-squared) with <code>np.append</code>.</p>\n\n<p>Also the shape for X or Y (?) seems to be 2D ((100,522)), where as you only have 1D. Check your data (which we don't have, so impossible for me to tell you exactly where to look for) so that you can ensure that the dimensions are correct.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4018",
            "_score": 9.225759,
            "_source": {
                "title": "feature extraction for a pretrained model in keras",
                "content": "feature extraction for a pretrained model in keras <p>Keras has a way to extract the features of a pretrained model, described here <a href=\"https://keras.io/applications/\" rel=\"noreferrer\">https://keras.io/applications/</a></p>\n\n<pre><code>from keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\nimport numpy as np\n\nmodel = VGG16(weights='imagenet', include_top=False)\n\nimg_path = 'elephant.jpg'\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\nfeatures = model.predict(x)\n</code></pre>\n\n<p>I tried this with some sample images. My vector x is of shape (100, 3, 224, 224) for 100 observations, 3 for RGB and 224x224 pixel size.\nthe <code>preprocess_input</code> reshapes this for the VGG model (it expects a different order).</p>\n\n<p>However, the output shape of <code>features</code> is (100, 512, 7, 7). What is this shape?\nI want to use the features as input for a logistic regression. So I need a shape like (100, n): one row for each observation and the features in the columns.\nHow do I reshape the output to this dimension?</p>\n\n<p>Say I now want to build my own simple Convnet:</p>\n\n<pre><code>from keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\n\nmodel = Sequential()\nmodel.add(Convolution2D(32, 3, 3, input_shape=(1, 299, 299)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(32, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(64, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n</code></pre>\n\n<p>This model expects grayscale images as input, hence the shape.</p>\n\n<p>What kind of layer do I have to add to get features of this model (something I can input in a logistic regression or random forest).</p>\n\n<p>Thanks</p>\n <deep-learning><keras><image-classification><p>The <code>features</code> variable contains the outputs of the final convolutional layers of your network. The final convolutional layer of VGG16 outputs 512 7x7 feature maps. All you need to do in order to use these features in a logistic regression model (or any other model) is reshape it to a 2D tensor, as you say. </p>\n\n<pre><code>reshaped_features = features.reshape(100, 512*7*7)\n</code></pre>\n\n<p>This will flatten out the feature maps to a long one-dimensional vector for each instance.</p>\n\n<p>Tip: If you can't be bothered working out the actual dimensions for your reshape, you can replace <code>512*7*7</code> with <code>-1</code> and <code>numpy</code> will figure out how big the final dimension should be.</p>\n",
                "codes": [
                    [
                        "reshaped_features = features.reshape(100, 512*7*7)\n"
                    ]
                ],
                "question_id:": "16444",
                "question_votes:": "7",
                "question_text:": "<p>Keras has a way to extract the features of a pretrained model, described here <a href=\"https://keras.io/applications/\" rel=\"noreferrer\">https://keras.io/applications/</a></p>\n\n<pre><code>from keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\nimport numpy as np\n\nmodel = VGG16(weights='imagenet', include_top=False)\n\nimg_path = 'elephant.jpg'\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\nfeatures = model.predict(x)\n</code></pre>\n\n<p>I tried this with some sample images. My vector x is of shape (100, 3, 224, 224) for 100 observations, 3 for RGB and 224x224 pixel size.\nthe <code>preprocess_input</code> reshapes this for the VGG model (it expects a different order).</p>\n\n<p>However, the output shape of <code>features</code> is (100, 512, 7, 7). What is this shape?\nI want to use the features as input for a logistic regression. So I need a shape like (100, n): one row for each observation and the features in the columns.\nHow do I reshape the output to this dimension?</p>\n\n<p>Say I now want to build my own simple Convnet:</p>\n\n<pre><code>from keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\n\nmodel = Sequential()\nmodel.add(Convolution2D(32, 3, 3, input_shape=(1, 299, 299)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(32, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(64, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n</code></pre>\n\n<p>This model expects grayscale images as input, hence the shape.</p>\n\n<p>What kind of layer do I have to add to get features of this model (something I can input in a logistic regression or random forest).</p>\n\n<p>Thanks</p>\n",
                "tags": "<deep-learning><keras><image-classification>",
                "answers": [
                    [
                        "16445",
                        "2",
                        "16444",
                        "",
                        "",
                        "<p>The <code>features</code> variable contains the outputs of the final convolutional layers of your network. The final convolutional layer of VGG16 outputs 512 7x7 feature maps. All you need to do in order to use these features in a logistic regression model (or any other model) is reshape it to a 2D tensor, as you say. </p>\n\n<pre><code>reshaped_features = features.reshape(100, 512*7*7)\n</code></pre>\n\n<p>This will flatten out the feature maps to a long one-dimensional vector for each instance.</p>\n\n<p>Tip: If you can't be bothered working out the actual dimensions for your reshape, you can replace <code>512*7*7</code> with <code>-1</code> and <code>numpy</code> will figure out how big the final dimension should be.</p>\n",
                        "",
                        "7"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7658",
            "_score": 9.216688,
            "_source": {
                "title": "Data augmentation: rotating images and zero values",
                "content": "Data augmentation: rotating images and zero values <p>A lot of people rotate images to create a larger training set for neural networks. For most nets, all of the inputs have to be the same size so the image rotation function has to crop the newly rotated images to match the input size. So, say you have <span class=\"math-container\">$32x32$</span> resolution images and do 45 degree rotations. Some of the output images will look diamond shaped with black (zero values) in the corners. So, my question is: should you leave these zero values alone or change them in some way and if so, how?</p>\n <neural-network><data-augmentation><p>Keeping the values as zeros will introduce some bias to your network. Given, you have this corner effect for the majority of your dataset, you do not want the network to identify a high probability of making the corners black. Thus, you should fill them, you can extend the edge, do a reflection, wrapping. You can also do some more complex function, like take average of a few patches in your image then place them in the missing areas. </p>\n\n<p>Keras has a very nice function that can do all this for you.</p>\n\n<pre><code>import numpy as np\nfrom keras.datasets import mnist\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# load data\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nX_train = X_train.astype('float32')\n\n# set up your data generator\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip = False)\n\n# Fit the generator using your data\ndatagen.fit(X_train.reshape((len(X_train), 28, 28, 1)))\n\n# Black images\nimage = X_train[5]\nplt.imshow(image,  cmap='gray')\nplt.show()\n\nplt.figure(figsize=(12,12))\nplt.subplot(4, 4, 1)\nplt.imshow(image.reshape((28,28)),  cmap='gray')\n\nfor j in range(15):\n    augmented = datagen.random_transform(image.reshape((28,28,1)))\n    plt.subplot(4, 4, j+2)\n    plt.imshow(augmented.reshape((28,28)),  cmap='gray')\nplt.tight_layout()\nplt.show()\n\n# White images\nimage = -1*X_train[5]\nplt.imshow(image,  cmap='gray')\nplt.show()\n\nplt.figure(figsize=(12,12))\nplt.subplot(4, 4, 1)\nplt.imshow(image.reshape((28,28)),  cmap='gray')\n\nfor j in range(15):\n    augmented = datagen.random_transform(image.reshape((28,28,1)))\n    plt.subplot(4, 4, j+2)\n    plt.imshow(augmented.reshape((28,28)),  cmap='gray')\nplt.tight_layout()\nplt.show()\n</code></pre>\n",
                "codes": [
                    [
                        "import numpy as np\nfrom keras.datasets import mnist\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# load data\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nX_train = X_train.astype('float32')\n\n# set up your data generator\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip = False)\n\n# Fit the generator using your data\ndatagen.fit(X_train.reshape((len(X_train), 28, 28, 1)))\n\n# Black images\nimage = X_train[5]\nplt.imshow(image,  cmap='gray')\nplt.show()\n\nplt.figure(figsize=(12,12))\nplt.subplot(4, 4, 1)\nplt.imshow(image.reshape((28,28)),  cmap='gray')\n\nfor j in range(15):\n    augmented = datagen.random_transform(image.reshape((28,28,1)))\n    plt.subplot(4, 4, j+2)\n    plt.imshow(augmented.reshape((28,28)),  cmap='gray')\nplt.tight_layout()\nplt.show()\n\n# White images\nimage = -1*X_train[5]\nplt.imshow(image,  cmap='gray')\nplt.show()\n\nplt.figure(figsize=(12,12))\nplt.subplot(4, 4, 1)\nplt.imshow(image.reshape((28,28)),  cmap='gray')\n\nfor j in range(15):\n    augmented = datagen.random_transform(image.reshape((28,28,1)))\n    plt.subplot(4, 4, j+2)\n    plt.imshow(augmented.reshape((28,28)),  cmap='gray')\nplt.tight_layout()\nplt.show()\n"
                    ]
                ],
                "question_id:": "28491",
                "question_votes:": "1",
                "question_text:": "<p>A lot of people rotate images to create a larger training set for neural networks. For most nets, all of the inputs have to be the same size so the image rotation function has to crop the newly rotated images to match the input size. So, say you have <span class=\"math-container\">$32x32$</span> resolution images and do 45 degree rotations. Some of the output images will look diamond shaped with black (zero values) in the corners. So, my question is: should you leave these zero values alone or change them in some way and if so, how?</p>\n",
                "tags": "<neural-network><data-augmentation>",
                "answers": [
                    [
                        "28503",
                        "2",
                        "28491",
                        "",
                        "",
                        "<p>Keeping the values as zeros will introduce some bias to your network. Given, you have this corner effect for the majority of your dataset, you do not want the network to identify a high probability of making the corners black. Thus, you should fill them, you can extend the edge, do a reflection, wrapping. You can also do some more complex function, like take average of a few patches in your image then place them in the missing areas. </p>\n\n<p>Keras has a very nice function that can do all this for you.</p>\n\n<pre><code>import numpy as np\nfrom keras.datasets import mnist\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# load data\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nX_train = X_train.astype('float32')\n\n# set up your data generator\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip = False)\n\n# Fit the generator using your data\ndatagen.fit(X_train.reshape((len(X_train), 28, 28, 1)))\n\n# Black images\nimage = X_train[5]\nplt.imshow(image,  cmap='gray')\nplt.show()\n\nplt.figure(figsize=(12,12))\nplt.subplot(4, 4, 1)\nplt.imshow(image.reshape((28,28)),  cmap='gray')\n\nfor j in range(15):\n    augmented = datagen.random_transform(image.reshape((28,28,1)))\n    plt.subplot(4, 4, j+2)\n    plt.imshow(augmented.reshape((28,28)),  cmap='gray')\nplt.tight_layout()\nplt.show()\n\n# White images\nimage = -1*X_train[5]\nplt.imshow(image,  cmap='gray')\nplt.show()\n\nplt.figure(figsize=(12,12))\nplt.subplot(4, 4, 1)\nplt.imshow(image.reshape((28,28)),  cmap='gray')\n\nfor j in range(15):\n    augmented = datagen.random_transform(image.reshape((28,28,1)))\n    plt.subplot(4, 4, j+2)\n    plt.imshow(augmented.reshape((28,28)),  cmap='gray')\nplt.tight_layout()\nplt.show()\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11711",
            "_score": 9.175325,
            "_source": {
                "title": "Why isn't my model learning?",
                "content": "Why isn't my model learning? <pre><code>import numpy as np\nfrom keras.datasets import cifar10\nfrom keras.layers import Dense, Activation\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nfrom keras import backend as k\nfrom keras.models import Sequential\n\n(Xtr,Ytr),(Xte,Yte)=cifar10.load_data()\n\nXtr = Xtr.astype('float32')\nXte = Xte.astype('float32')\n\nXtr = Xtr.reshape(50000, 3072)\nXte = Xte.reshape(10000, 3072)\n\nYtr = np_utils.to_categorical(Ytr, 10)\nYte = np_utils.to_categorical(Yte, 10)\n\nmodel=Sequential()\nmodel.add(Dense(100, input_shape=Xtr.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(Dense(10))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer=\"sgd\", metrics=['accuracy'])\n\nmodel.fit(Xtr, Ytr, batch_size=200, epochs=30, shuffle=True,verbose=1)\n\nscores = model.evaluate(Xte, Yte, verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1] * 100))\n</code></pre>\n\n<p>And the result:</p>\n\n<p><a href=\"https://i.stack.imgur.com/Yn537.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Yn537.png\" alt=\"enter image description here\"></a></p>\n\n<p>I am trying to creat a pretty basic 2 layer NN on cifar-10. I know that the data is not preprocessed. But that can't be the reason for learning nothing. Where am I making the mistake?</p>\n <keras><p>I'll go through an example that will help you get started. It should get approximately 50% accuracy. </p>\n\n<p>So I keep the code the same as yours for loading the data. The only difference is that I normalize the data to lie between 0 and 1. This is usually recommended to bound the weights more tightly. </p>\n\n<pre><code>import numpy as np\nfrom keras.datasets import cifar10\nfrom keras.layers import Dense, Activation\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nfrom keras import backend as k\nfrom keras.models import Sequential\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n\n(x_train, y_train), (x_test, y_test)=cifar10.load_data()\n</code></pre>\n\n<blockquote>\n  <p>Downloading data from <a href=\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\" rel=\"nofollow noreferrer\">https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz</a> <br/>170500096/170498071 [==============================] - 71s 0us/step</p>\n</blockquote>\n\n<pre><code>(x_train, y_train), (x_test, y_test)=cifar10.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\nx_train = x_train.reshape(50000, 3072)\nx_test = x_test.reshape(10000, 3072)\n\n# The known number of output classes.\nnum_classes = 10\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], x_train.shape[1],)\nx_test_reshaped = x_test.reshape(x_test.shape[0], x_test.shape[1],)\ninput_shape = (x_train.shape[1],)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n</code></pre>\n\n<p>Now let's make our model. Here I do make the hidden layers have more neurons per layer.</p>\n\n<pre><code>model = Sequential()\nmodel.add(Dense(32,\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<p>Now we can train the model</p>\n\n<pre><code>epochs = 4\nbatch_size = 128\n# Fit the model weights.\nmodel.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n</code></pre>\n\n<blockquote>\n  <p>50000/50000 [==============================] - 3s 58us/step - loss: 1.6716 - acc: 0.4038 - val_loss: 1.6566 - val_acc: 0.4094</p>\n</blockquote>\n",
                "codes": [
                    [
                        "import numpy as np\nfrom keras.datasets import cifar10\nfrom keras.layers import Dense, Activation\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nfrom keras import backend as k\nfrom keras.models import Sequential\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n\n(x_train, y_train), (x_test, y_test)=cifar10.load_data()\n",
                        "(x_train, y_train), (x_test, y_test)=cifar10.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\nx_train = x_train.reshape(50000, 3072)\nx_test = x_test.reshape(10000, 3072)\n\n# The known number of output classes.\nnum_classes = 10\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], x_train.shape[1],)\nx_test_reshaped = x_test.reshape(x_test.shape[0], x_test.shape[1],)\ninput_shape = (x_train.shape[1],)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n",
                        "model = Sequential()\nmodel.add(Dense(32,\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n",
                        "epochs = 4\nbatch_size = 128\n# Fit the model weights.\nmodel.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n"
                    ]
                ],
                "question_id:": "41278",
                "question_votes:": "2",
                "question_text:": "<pre><code>import numpy as np\nfrom keras.datasets import cifar10\nfrom keras.layers import Dense, Activation\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nfrom keras import backend as k\nfrom keras.models import Sequential\n\n(Xtr,Ytr),(Xte,Yte)=cifar10.load_data()\n\nXtr = Xtr.astype('float32')\nXte = Xte.astype('float32')\n\nXtr = Xtr.reshape(50000, 3072)\nXte = Xte.reshape(10000, 3072)\n\nYtr = np_utils.to_categorical(Ytr, 10)\nYte = np_utils.to_categorical(Yte, 10)\n\nmodel=Sequential()\nmodel.add(Dense(100, input_shape=Xtr.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(Dense(10))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer=\"sgd\", metrics=['accuracy'])\n\nmodel.fit(Xtr, Ytr, batch_size=200, epochs=30, shuffle=True,verbose=1)\n\nscores = model.evaluate(Xte, Yte, verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1] * 100))\n</code></pre>\n\n<p>And the result:</p>\n\n<p><a href=\"https://i.stack.imgur.com/Yn537.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Yn537.png\" alt=\"enter image description here\"></a></p>\n\n<p>I am trying to creat a pretty basic 2 layer NN on cifar-10. I know that the data is not preprocessed. But that can't be the reason for learning nothing. Where am I making the mistake?</p>\n",
                "tags": "<keras>",
                "answers": [
                    [
                        "41292",
                        "2",
                        "41278",
                        "",
                        "",
                        "<p>I'll go through an example that will help you get started. It should get approximately 50% accuracy. </p>\n\n<p>So I keep the code the same as yours for loading the data. The only difference is that I normalize the data to lie between 0 and 1. This is usually recommended to bound the weights more tightly. </p>\n\n<pre><code>import numpy as np\nfrom keras.datasets import cifar10\nfrom keras.layers import Dense, Activation\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nfrom keras import backend as k\nfrom keras.models import Sequential\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n\n(x_train, y_train), (x_test, y_test)=cifar10.load_data()\n</code></pre>\n\n<blockquote>\n  <p>Downloading data from <a href=\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\" rel=\"nofollow noreferrer\">https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz</a> <br/>170500096/170498071 [==============================] - 71s 0us/step</p>\n</blockquote>\n\n<pre><code>(x_train, y_train), (x_test, y_test)=cifar10.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\nx_train = x_train.reshape(50000, 3072)\nx_test = x_test.reshape(10000, 3072)\n\n# The known number of output classes.\nnum_classes = 10\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], x_train.shape[1],)\nx_test_reshaped = x_test.reshape(x_test.shape[0], x_test.shape[1],)\ninput_shape = (x_train.shape[1],)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n</code></pre>\n\n<p>Now let's make our model. Here I do make the hidden layers have more neurons per layer.</p>\n\n<pre><code>model = Sequential()\nmodel.add(Dense(32,\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<p>Now we can train the model</p>\n\n<pre><code>epochs = 4\nbatch_size = 128\n# Fit the model weights.\nmodel.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n</code></pre>\n\n<blockquote>\n  <p>50000/50000 [==============================] - 3s 58us/step - loss: 1.6716 - acc: 0.4038 - val_loss: 1.6566 - val_acc: 0.4094</p>\n</blockquote>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16921",
            "_score": 9.164995,
            "_source": {
                "title": "Low accuracy on MNIST Dataset",
                "content": "Low accuracy on MNIST Dataset <p>Hi downloaded the MNIST dataset images and labels and I am trying to train but I am getting low accuracy which is very low . not Even 50 %.</p>\n\n<p>below is my code. </p>\n\n<pre><code>import glob\nimport imageio\nimport cv2\nimport pandas as pd\nimport numpy as np \nimages=[]\nfor image_path in glob.glob(r\"C:\\\\Users\\\\Downloads\\\\tmnist_bundle_rgb\\\\tmnist_bundle_rgb\\\\imgs\\\\*.png\"):\n    im = imageio.imread(image_path)\n    a= cv2.imread(image_path)\n    gray_img = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n    images.append(gray_img)\n\nimages = np.asarray(images,dtype=np.float32)\n\nlables = pd.read_csv('C:\\\\Users\\\\Downloads\\\\tmnist_bundle_rgb\\\\tmnist_bundle_rgb\\\\index.csv',encoding='utf-8')\n\nlables=lables.iloc[:, 0] # slicing the column\n\nlables = np.asarray(lables) #Array\n\nlables = np.asarray(lables,dtype=np.float32)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(images, lables, test_size=0.1) # split\n\nX_train = X_train.reshape(54252,28,28,1)\nX_test = X_test.reshape(6028,28,28,1)\n\nX_train = X_train/ 255\nX_test = X_test/ 255\n\nfrom keras.utils import to_categorical\n\nnumber_of_classes=10\ny_train = to_categorical(y_train,number_of_classes)\ny_test = to_categorical(y_test,number_of_classes)\n\n\n#Model Buidling \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Convolution2D, Flatten\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers import Dropout\n\nmodel = Sequential()\nmodel = Sequential()\nmodel.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Convolution2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(number_of_classes, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n\nmodel.fit(X_train, y_train,batch_size=32, nb_epoch=5, verbose=1\n</code></pre>\n\n<p>Output:</p>\n\n<blockquote>\n  <p>Epoch 1/5 54252/54252 [==============================] - 36s\n  663us/step - loss: 2.3024 - acc: 0.1093</p>\n  \n  <p>Epoch 2/5 54252/54252 [==============================] - 36s\n  664us/step - loss: 2.3017 - acc: 0.1111</p>\n  \n  <p>Epoch 3/5 54252/54252 [==============================] - 39s\n  721us/step - loss: 2.3016 - acc: 0.1115</p>\n  \n  <p>Epoch 4/5 54252/54252 [==============================] - 40s\n  733us/step - loss: 2.3018 - acc: 0.1110</p>\n  \n  <p>Epoch 5/5 54252/54252 [==============================] - 50s\n  912us/step - loss: 2.3015 - acc: 0.1115</p>\n</blockquote>\n <machine-learning><deep-learning><mnist><p>I'm fairly certain there is something wrong with the way you load the data. I modified the code like this: </p>\n\n<pre><code>import numpy as np \nfrom keras.datasets import mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train =  x_train.reshape([x_train.shape[0], x_train.shape[1], x_train.shape[2], 1])\nx_test =  x_test.reshape([x_test.shape[0], x_test.shape[1], x_test.shape[2], 1])\n\nx_train = x_train / 255\nx_test = x_test / 255\n\nfrom keras.utils import to_categorical\n\nnumber_of_classes=10\ny_train = to_categorical(y_train,number_of_classes)\ny_test = to_categorical(y_test,number_of_classes)\n\n\n#Model Buidling \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Convolution2D, Flatten\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers import Dropout\n\n#model = Sequential()\nmodel = Sequential()\nmodel.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Convolution2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(number_of_classes, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n\nmodel.fit(x_train, y_train,batch_size=32, epochs=5, verbose=1)\n</code></pre>\n\n<p>This gives accuracy of >97%</p>\n<p>Your model have an accuracy of 0.10 so he is correct 10% of the time, a random model would do the same. It means your model doesn't learn at all. Even a bad model learn a little. So the problem come from your dataset.</p>\n\n<p>I tested your model and got 97% accuracy.</p>\n\n<p>Your problem probably come from how you import your dataset.\nHere is how i imported:</p>\n\n<pre><code>import idx2numpy\nimport numpy as np\nfileImg = 'data/train-images.idx3-ubyte'\nfileLabel= 'data/train-labels.idx1-ubyte'\narrImg = idx2numpy.convert_from_file(fileImg)\narrLabels = idx2numpy.convert_from_file(fileLabel)\n</code></pre>\n\n<p>the dataset come from: <a href=\"http://yann.lecun.com/exdb/mnist/\" rel=\"nofollow noreferrer\">http://yann.lecun.com/exdb/mnist/</a></p>\n\n<p>You should test if you imported an processed your dataset correctly. For example :</p>\n\n<pre><code>import matplotlib.pyplot as plt\nimage = np.asarray(arrImg[1000])\nplt.imshow(image)\nplt.show()\nprint(arrLabels[1000])\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/NlA4A.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/NlA4A.png\" alt=\"enter image description here\"></a></p>\n",
                "codes": [
                    [
                        "import numpy as np \nfrom keras.datasets import mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train =  x_train.reshape([x_train.shape[0], x_train.shape[1], x_train.shape[2], 1])\nx_test =  x_test.reshape([x_test.shape[0], x_test.shape[1], x_test.shape[2], 1])\n\nx_train = x_train / 255\nx_test = x_test / 255\n\nfrom keras.utils import to_categorical\n\nnumber_of_classes=10\ny_train = to_categorical(y_train,number_of_classes)\ny_test = to_categorical(y_test,number_of_classes)\n\n\n#Model Buidling \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Convolution2D, Flatten\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers import Dropout\n\n#model = Sequential()\nmodel = Sequential()\nmodel.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Convolution2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(number_of_classes, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n\nmodel.fit(x_train, y_train,batch_size=32, epochs=5, verbose=1)\n"
                    ],
                    [
                        "import idx2numpy\nimport numpy as np\nfileImg = 'data/train-images.idx3-ubyte'\nfileLabel= 'data/train-labels.idx1-ubyte'\narrImg = idx2numpy.convert_from_file(fileImg)\narrLabels = idx2numpy.convert_from_file(fileLabel)\n",
                        "import matplotlib.pyplot as plt\nimage = np.asarray(arrImg[1000])\nplt.imshow(image)\nplt.show()\nprint(arrLabels[1000])\n"
                    ]
                ],
                "question_id:": "55116",
                "question_votes:": "",
                "question_text:": "<p>Hi downloaded the MNIST dataset images and labels and I am trying to train but I am getting low accuracy which is very low . not Even 50 %.</p>\n\n<p>below is my code. </p>\n\n<pre><code>import glob\nimport imageio\nimport cv2\nimport pandas as pd\nimport numpy as np \nimages=[]\nfor image_path in glob.glob(r\"C:\\\\Users\\\\Downloads\\\\tmnist_bundle_rgb\\\\tmnist_bundle_rgb\\\\imgs\\\\*.png\"):\n    im = imageio.imread(image_path)\n    a= cv2.imread(image_path)\n    gray_img = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n    images.append(gray_img)\n\nimages = np.asarray(images,dtype=np.float32)\n\nlables = pd.read_csv('C:\\\\Users\\\\Downloads\\\\tmnist_bundle_rgb\\\\tmnist_bundle_rgb\\\\index.csv',encoding='utf-8')\n\nlables=lables.iloc[:, 0] # slicing the column\n\nlables = np.asarray(lables) #Array\n\nlables = np.asarray(lables,dtype=np.float32)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(images, lables, test_size=0.1) # split\n\nX_train = X_train.reshape(54252,28,28,1)\nX_test = X_test.reshape(6028,28,28,1)\n\nX_train = X_train/ 255\nX_test = X_test/ 255\n\nfrom keras.utils import to_categorical\n\nnumber_of_classes=10\ny_train = to_categorical(y_train,number_of_classes)\ny_test = to_categorical(y_test,number_of_classes)\n\n\n#Model Buidling \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Convolution2D, Flatten\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers import Dropout\n\nmodel = Sequential()\nmodel = Sequential()\nmodel.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Convolution2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(number_of_classes, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n\nmodel.fit(X_train, y_train,batch_size=32, nb_epoch=5, verbose=1\n</code></pre>\n\n<p>Output:</p>\n\n<blockquote>\n  <p>Epoch 1/5 54252/54252 [==============================] - 36s\n  663us/step - loss: 2.3024 - acc: 0.1093</p>\n  \n  <p>Epoch 2/5 54252/54252 [==============================] - 36s\n  664us/step - loss: 2.3017 - acc: 0.1111</p>\n  \n  <p>Epoch 3/5 54252/54252 [==============================] - 39s\n  721us/step - loss: 2.3016 - acc: 0.1115</p>\n  \n  <p>Epoch 4/5 54252/54252 [==============================] - 40s\n  733us/step - loss: 2.3018 - acc: 0.1110</p>\n  \n  <p>Epoch 5/5 54252/54252 [==============================] - 50s\n  912us/step - loss: 2.3015 - acc: 0.1115</p>\n</blockquote>\n",
                "tags": "<machine-learning><deep-learning><mnist>",
                "answers": [
                    [
                        "55129",
                        "2",
                        "55116",
                        "",
                        "",
                        "<p>I'm fairly certain there is something wrong with the way you load the data. I modified the code like this: </p>\n\n<pre><code>import numpy as np \nfrom keras.datasets import mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train =  x_train.reshape([x_train.shape[0], x_train.shape[1], x_train.shape[2], 1])\nx_test =  x_test.reshape([x_test.shape[0], x_test.shape[1], x_test.shape[2], 1])\n\nx_train = x_train / 255\nx_test = x_test / 255\n\nfrom keras.utils import to_categorical\n\nnumber_of_classes=10\ny_train = to_categorical(y_train,number_of_classes)\ny_test = to_categorical(y_test,number_of_classes)\n\n\n#Model Buidling \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Convolution2D, Flatten\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers import Dropout\n\n#model = Sequential()\nmodel = Sequential()\nmodel.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Convolution2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(number_of_classes, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n\nmodel.fit(x_train, y_train,batch_size=32, epochs=5, verbose=1)\n</code></pre>\n\n<p>This gives accuracy of >97%</p>\n",
                        "",
                        ""
                    ],
                    [
                        "55126",
                        "2",
                        "55116",
                        "",
                        "",
                        "<p>Your model have an accuracy of 0.10 so he is correct 10% of the time, a random model would do the same. It means your model doesn't learn at all. Even a bad model learn a little. So the problem come from your dataset.</p>\n\n<p>I tested your model and got 97% accuracy.</p>\n\n<p>Your problem probably come from how you import your dataset.\nHere is how i imported:</p>\n\n<pre><code>import idx2numpy\nimport numpy as np\nfileImg = 'data/train-images.idx3-ubyte'\nfileLabel= 'data/train-labels.idx1-ubyte'\narrImg = idx2numpy.convert_from_file(fileImg)\narrLabels = idx2numpy.convert_from_file(fileLabel)\n</code></pre>\n\n<p>the dataset come from: <a href=\"http://yann.lecun.com/exdb/mnist/\" rel=\"nofollow noreferrer\">http://yann.lecun.com/exdb/mnist/</a></p>\n\n<p>You should test if you imported an processed your dataset correctly. For example :</p>\n\n<pre><code>import matplotlib.pyplot as plt\nimage = np.asarray(arrImg[1000])\nplt.imshow(image)\nplt.show()\nprint(arrLabels[1000])\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/NlA4A.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/NlA4A.png\" alt=\"enter image description here\"></a></p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "2161",
            "_score": 9.158384,
            "_source": {
                "title": "K Means giving poor results",
                "content": "K Means giving poor results <p>I have several user names and their salaries. \nNow I need to cluster user based on their salaries.\nI am using KMeans clustering and following is my code</p>\n\n<pre><code>from sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nimport pandas as pd\n\nle = LabelEncoder()\ndata = pd.read_csv('kmeans.data',header=None, names =['user', 'salary'])\n\n# Numerical conversion\ndata['user'] = le.fit_transform(data['user'])\nkm = KMeans(n_clusters=4, random_state= 10, n_init=10, max_iter=500)\nkm.fit(data)\n\ndata['labels'] = le.inverse_transform(data['user'])\ndata['cluster'] = km.labels_\n\nprint data\n</code></pre>\n\n<p>But my results are bad and there are lot of overlapping salaries.</p>\n\n<p>Is there anything wrong in the code ? How to improve the results ?</p>\n\n<p>Or whether clustering is not a right approach here ?\nThen how can I cluster users only based on salary ?</p>\n\n<pre><code> km.fit(data['salary'])\n</code></pre>\n\n<p>EDIT:</p>\n\n<p>I figured out a way to solve my problem using <a href=\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html\" rel=\"nofollow\">numpy.reshape</a></p>\n\n<pre><code>km.fit(data['salary'].reshape(-1,1))\n</code></pre>\n <machine-learning><python><clustering><k-means><scikit-learn><p>K-means is based on the assumption that the data is \"translation invariant\" (more precisely: variance does, and k-means is variance minimization).</p>\n\n<p>In other words, it assumes that a difference of d=(x-y)^2 is of the <em>same</em> importance everywhere. Because of this, <strong>k-means does not work on skewed data</strong>. Furthermore, because of the square, it is <strong>sensitive to outliers and other extreme values</strong>.</p>\n\n<p>For salaries and other monetary values, this usually does not hold. The difference between \\$0 and \\$1000 is massive, and not the same as a salary difference of \\$100000 to \\$101000. Salaries are usually rather skewed, and you often have some extreme values.</p>\n\n<p><strong>Converting the \"user\" attribute to a numerical value is outright statistical nonsense</strong>. What's variance worth in this attribute? <strong>K-means is for continuous numerical data only</strong>, and converting data does not chnage the <em>nature</em>, only the encoding - it's still inappropriate.</p>\n<p>This is not a 'clustering' problem as much at is it an 'interval' problem since you only have 1 dimension.</p>\n\n<p>You can use an iterative process like <a href=\"https://en.wikipedia.org/wiki/Jenks_natural_breaks_optimization\" rel=\"nofollow\">Jenk's natural break optimization</a> in order to figure out how large to make your intervals.</p>\n\n<p>As other posters have said, do not user names as a clustering dimension unless you really think that variations in letters of a name are meaningful in some way (do you really think all the Dan's are paid similarly?). </p>\n<p>I think the problem here is using the name as a dimension. You can, but you have to use a more robust distance metric between names (string). As far as I know, LabelEncoder just assign an int considering the element's order of ocurrence in a unique list. You could try a different hashing (string to int) or <a href=\"https://en.wikipedia.org/wiki/Levenshtein_distance\" rel=\"nofollow\" title=\"Levenshtein_distance\">Levenshtein_distance</a> as a distance metric</p>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "10739",
                "question_votes:": "1",
                "question_text:": "<p>I have several user names and their salaries. \nNow I need to cluster user based on their salaries.\nI am using KMeans clustering and following is my code</p>\n\n<pre><code>from sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nimport pandas as pd\n\nle = LabelEncoder()\ndata = pd.read_csv('kmeans.data',header=None, names =['user', 'salary'])\n\n# Numerical conversion\ndata['user'] = le.fit_transform(data['user'])\nkm = KMeans(n_clusters=4, random_state= 10, n_init=10, max_iter=500)\nkm.fit(data)\n\ndata['labels'] = le.inverse_transform(data['user'])\ndata['cluster'] = km.labels_\n\nprint data\n</code></pre>\n\n<p>But my results are bad and there are lot of overlapping salaries.</p>\n\n<p>Is there anything wrong in the code ? How to improve the results ?</p>\n\n<p>Or whether clustering is not a right approach here ?\nThen how can I cluster users only based on salary ?</p>\n\n<pre><code> km.fit(data['salary'])\n</code></pre>\n\n<p>EDIT:</p>\n\n<p>I figured out a way to solve my problem using <a href=\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html\" rel=\"nofollow\">numpy.reshape</a></p>\n\n<pre><code>km.fit(data['salary'].reshape(-1,1))\n</code></pre>\n",
                "tags": "<machine-learning><python><clustering><k-means><scikit-learn>",
                "answers": [
                    [
                        "10747",
                        "2",
                        "10739",
                        "",
                        "",
                        "<p>K-means is based on the assumption that the data is \"translation invariant\" (more precisely: variance does, and k-means is variance minimization).</p>\n\n<p>In other words, it assumes that a difference of d=(x-y)^2 is of the <em>same</em> importance everywhere. Because of this, <strong>k-means does not work on skewed data</strong>. Furthermore, because of the square, it is <strong>sensitive to outliers and other extreme values</strong>.</p>\n\n<p>For salaries and other monetary values, this usually does not hold. The difference between \\$0 and \\$1000 is massive, and not the same as a salary difference of \\$100000 to \\$101000. Salaries are usually rather skewed, and you often have some extreme values.</p>\n\n<p><strong>Converting the \"user\" attribute to a numerical value is outright statistical nonsense</strong>. What's variance worth in this attribute? <strong>K-means is for continuous numerical data only</strong>, and converting data does not chnage the <em>nature</em>, only the encoding - it's still inappropriate.</p>\n",
                        "",
                        "6"
                    ],
                    [
                        "10748",
                        "2",
                        "10739",
                        "",
                        "",
                        "<p>This is not a 'clustering' problem as much at is it an 'interval' problem since you only have 1 dimension.</p>\n\n<p>You can use an iterative process like <a href=\"https://en.wikipedia.org/wiki/Jenks_natural_breaks_optimization\" rel=\"nofollow\">Jenk's natural break optimization</a> in order to figure out how large to make your intervals.</p>\n\n<p>As other posters have said, do not user names as a clustering dimension unless you really think that variations in letters of a name are meaningful in some way (do you really think all the Dan's are paid similarly?). </p>\n",
                        "",
                        "2"
                    ],
                    [
                        "10740",
                        "2",
                        "10739",
                        "",
                        "",
                        "<p>I think the problem here is using the name as a dimension. You can, but you have to use a more robust distance metric between names (string). As far as I know, LabelEncoder just assign an int considering the element's order of ocurrence in a unique list. You could try a different hashing (string to int) or <a href=\"https://en.wikipedia.org/wiki/Levenshtein_distance\" rel=\"nofollow\" title=\"Levenshtein_distance\">Levenshtein_distance</a> as a distance metric</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14571",
            "_score": 9.15174,
            "_source": {
                "title": "TypeError: 'tuple' object cannot be interpreted as an integer",
                "content": "TypeError: 'tuple' object cannot be interpreted as an integer <p>I have an image (480,640,3) and I am trying to resize it to (150,150,1). Since my Keras model has been trained on images of shape (150,150,1), unfortunately I cannot seem to resize it using the PIL library. Any suggestions on how to fix this?</p>\n\n<p>This is the code I am using right now:</p>\n\n<p>The error is caused on the line <code>image5.resize()</code></p>\n\n<pre><code>    stream.seek(0)\n    data = numpy.fromstring(stream.getvalue() , dtype = numpy.uint8)\n    image5 = cv.imdecode(data , 1)\n    print(image5.shape)\n    #cv.imwrite('uhhu.png',image5)\n    img = image5.resize((150,150,1 ), Image.ANTIALIAS)\n    cv.imwrite('hhh.png',img)\n    x = img_to_array(img)\n    x = x.reshape((1,) + x.shape)\n    x = x/255\n    x = numpy.array(x)\n    print(x.shape)\n    #score = loaded_model.predict(img)\n    #print(score)\n</code></pre>\n <deep-learning><keras><tensorflow><opencv><p>The solution to the problem is to resize using openCV instead of using PIL and specifying the appropriate pixel width and height.</p>\n\n<pre><code>img = cv.resize(image5 , (150,150))\n</code></pre>\n",
                "codes": [
                    [
                        "img = cv.resize(image5 , (150,150))\n"
                    ]
                ],
                "question_id:": "48946",
                "question_votes:": "1",
                "question_text:": "<p>I have an image (480,640,3) and I am trying to resize it to (150,150,1). Since my Keras model has been trained on images of shape (150,150,1), unfortunately I cannot seem to resize it using the PIL library. Any suggestions on how to fix this?</p>\n\n<p>This is the code I am using right now:</p>\n\n<p>The error is caused on the line <code>image5.resize()</code></p>\n\n<pre><code>    stream.seek(0)\n    data = numpy.fromstring(stream.getvalue() , dtype = numpy.uint8)\n    image5 = cv.imdecode(data , 1)\n    print(image5.shape)\n    #cv.imwrite('uhhu.png',image5)\n    img = image5.resize((150,150,1 ), Image.ANTIALIAS)\n    cv.imwrite('hhh.png',img)\n    x = img_to_array(img)\n    x = x.reshape((1,) + x.shape)\n    x = x/255\n    x = numpy.array(x)\n    print(x.shape)\n    #score = loaded_model.predict(img)\n    #print(score)\n</code></pre>\n",
                "tags": "<deep-learning><keras><tensorflow><opencv>",
                "answers": [
                    [
                        "48980",
                        "2",
                        "48946",
                        "",
                        "",
                        "<p>The solution to the problem is to resize using openCV instead of using PIL and specifying the appropriate pixel width and height.</p>\n\n<pre><code>img = cv.resize(image5 , (150,150))\n</code></pre>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14508",
            "_score": 9.114763,
            "_source": {
                "title": "Diffirent results in a function approximation problem using MLPRegressor and Keras",
                "content": "Diffirent results in a function approximation problem using MLPRegressor and Keras <p>I have different results in a function approximation problem. I am trying to approximate a sine wave using MLPRegressor and Keras (um dense layer) \nHere is the code for the MLPRegressor:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import mean_squared_error\n\n#Cria um dataset\nX_train = np.arange(0.0, 1, 0.01).reshape(-1, 1)\nnoise= np.random.normal(0,0.1,100).reshape(-1,1)\n\n\n\ny_train =  np.sin(2*np.pi*X_train) \ny_train=y_train + noise\ny_train=y_train.ravel() # transfoprma em 1D array\n\n#X_train = np.arange(0.0, 1, 0.01).reshape(-1, 1)\n#y_train = np.sin(2 * np.pi * X_train).ravel()\n\n\n# Experimentos \n#hidden_layer sizes : 1,3, 100\n#max_iter=10,100,1000\n#\nnn = MLPRegressor(\n    hidden_layer_sizes=(3,),  activation='tanh', solver='lbfgs', alpha=0.000, batch_size='auto',\n    learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=80, shuffle=True,\n    random_state=0, tol=0.0001, verbose=True, warm_start=False, momentum=0.0, nesterovs_momentum=False,\n    early_stopping=False, validation_fraction=0.0, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n\n#Treina a Rede\nn = nn.fit(X_train, y_train)\n\n#previsoes na rede no conjunto de treinamento\npredict_train =nn.predict(X_train)\n\n#Plota o treinamento\nfig = plt.figure()\nax1 = fig.add_subplot(111)\nax1.scatter(X_train, y_train, s=5, c='b', marker=\"o\", label='real')\nax1.plot(X_train,predict_train, c='r', label='NN Prediction')\n\n\n#Conjunto de Teste\nX_test = np.arange(0.0, 1, 0.01).reshape(-1, 1)\ny_test = np.sin(2*np.pi*X_test) + np.random.normal(0,0.2,100).reshape(-1,1)\ny_test=y_test.ravel()\n\n\n#Calcula as previsoes no conjunto de teste\n\npredict_test= nn.predict(X_test)\n\nfig = plt.figure()\nax1 = fig.add_subplot(111)\nax1.scatter(X_test, y_test, s=5, c='b', marker=\"o\", label='real')\nax1.plot(X_test,predict_test, c='r', label='NN Prediction')\n\nplt.legend()\nplt.show()\n\nprint('MSE training : {:.3f}'.format(mean_squared_error(y_train, predict_train)))\nprint('MSE testing : {:.3f}'.format(mean_squared_error(y_test, predict_test)))\n</code></pre>\n\n<p>Using MLPRegressor, I found satisfactory results with just 3 neurons. However, when I try to use Keras, I can not get reasonably results. The code is very similar with the exception of the optmizer and the activation function. Here is the code for Keras:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.metrics import mean_squared_error\n\n\n\n\n\n#\n#Cria um dataset\n\n#Cria um dataset\nX_train = np.arange(0.0, 1, 0.01).reshape(-1, 1)\nnoise= np.random.normal(0,0.1,100).reshape(-1,1)\n\n\n\ny_train =  np.sin(2*np.pi*X_train) \ny_train=y_train + noise\ny_train=y_train.ravel() # transfoprma em 1D array\n\n\n#Construir a Rede\nnn = Sequential() # sequencia de camada\n#activation\n# sigmoid, tanh, relu, linear\n# units: numero de neuronios na camada\n#primeira camada escondida tem input_dim\nnn.add(Dense(units = 100, activation = 'relu',\n                        kernel_initializer = 'random_uniform', input_dim = 1))\nnn.add(Dense(units = 1, activation = 'linear'))\n\n# Algorritmo de aprendizado\n#sgd = keras.optimizers.SGD(lr=0.1, decay=0, momentum=0, nesterov=False)\nadam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n\n#determina a funcao de custo e a metrica utilizada\nnn.compile(loss = 'mean_squared_error', optimizer = adam,\n                  metrics = ['mean_squared_error'])\nhistory= nn.fit(X_train, y_train, batch_size = 1, epochs = 1000)\n\n#previsoes na rede no conjunto de treinamento\npredict_train =nn.predict(X_train)\n\n\n\n#Plota o treinamento\nfig = plt.figure()\nax1 = fig.add_subplot(111)\nax1.scatter(X_train, y_train, s=5, c='b', marker=\"o\", label='real')\nax1.plot(X_train,predict_train, c='r', label='NN Prediction')\n\n\n#Conjunto de Teste\nX_test = np.arange(0.0, 1, 0.01).reshape(-1, 1)\ny_test = np.sin(2*np.pi*X_test) + np.random.normal(0,0.2,100).reshape(-1,1)\ny_test=y_test.ravel()\n\n\n#Calcula as previsoes no conjunto de teste\n\npredict_test= nn.predict(X_test)\n\nfig = plt.figure()\nax1 = fig.add_subplot(111)\nax1.scatter(X_test, y_test, s=5, c='b', marker=\"o\", label='real')\nax1.plot(X_test,predict_test, c='r', label='NN Prediction')\n\nplt.legend()\nplt.show()\n\nprint('MSE training : {:.3f}'.format(mean_squared_error(y_train, predict_train)))\nprint('MSE testing : {:.3f}'.format(mean_squared_error(y_test, predict_test)))\n</code></pre>\n\n<p>I already tried sgd as optimizer and also tanh for activation function. I do not undestand what I am missing, that is why I cann make the code for function approximation using Keras work.</p>\n <keras><mlp>",
                "codes": [],
                "question_id:": "48773",
                "question_votes:": "",
                "question_text:": "<p>I have different results in a function approximation problem. I am trying to approximate a sine wave using MLPRegressor and Keras (um dense layer) \nHere is the code for the MLPRegressor:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import mean_squared_error\n\n#Cria um dataset\nX_train = np.arange(0.0, 1, 0.01).reshape(-1, 1)\nnoise= np.random.normal(0,0.1,100).reshape(-1,1)\n\n\n\ny_train =  np.sin(2*np.pi*X_train) \ny_train=y_train + noise\ny_train=y_train.ravel() # transfoprma em 1D array\n\n#X_train = np.arange(0.0, 1, 0.01).reshape(-1, 1)\n#y_train = np.sin(2 * np.pi * X_train).ravel()\n\n\n# Experimentos \n#hidden_layer sizes : 1,3, 100\n#max_iter=10,100,1000\n#\nnn = MLPRegressor(\n    hidden_layer_sizes=(3,),  activation='tanh', solver='lbfgs', alpha=0.000, batch_size='auto',\n    learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=80, shuffle=True,\n    random_state=0, tol=0.0001, verbose=True, warm_start=False, momentum=0.0, nesterovs_momentum=False,\n    early_stopping=False, validation_fraction=0.0, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n\n#Treina a Rede\nn = nn.fit(X_train, y_train)\n\n#previsoes na rede no conjunto de treinamento\npredict_train =nn.predict(X_train)\n\n#Plota o treinamento\nfig = plt.figure()\nax1 = fig.add_subplot(111)\nax1.scatter(X_train, y_train, s=5, c='b', marker=\"o\", label='real')\nax1.plot(X_train,predict_train, c='r', label='NN Prediction')\n\n\n#Conjunto de Teste\nX_test = np.arange(0.0, 1, 0.01).reshape(-1, 1)\ny_test = np.sin(2*np.pi*X_test) + np.random.normal(0,0.2,100).reshape(-1,1)\ny_test=y_test.ravel()\n\n\n#Calcula as previsoes no conjunto de teste\n\npredict_test= nn.predict(X_test)\n\nfig = plt.figure()\nax1 = fig.add_subplot(111)\nax1.scatter(X_test, y_test, s=5, c='b', marker=\"o\", label='real')\nax1.plot(X_test,predict_test, c='r', label='NN Prediction')\n\nplt.legend()\nplt.show()\n\nprint('MSE training : {:.3f}'.format(mean_squared_error(y_train, predict_train)))\nprint('MSE testing : {:.3f}'.format(mean_squared_error(y_test, predict_test)))\n</code></pre>\n\n<p>Using MLPRegressor, I found satisfactory results with just 3 neurons. However, when I try to use Keras, I can not get reasonably results. The code is very similar with the exception of the optmizer and the activation function. Here is the code for Keras:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.metrics import mean_squared_error\n\n\n\n\n\n#\n#Cria um dataset\n\n#Cria um dataset\nX_train = np.arange(0.0, 1, 0.01).reshape(-1, 1)\nnoise= np.random.normal(0,0.1,100).reshape(-1,1)\n\n\n\ny_train =  np.sin(2*np.pi*X_train) \ny_train=y_train + noise\ny_train=y_train.ravel() # transfoprma em 1D array\n\n\n#Construir a Rede\nnn = Sequential() # sequencia de camada\n#activation\n# sigmoid, tanh, relu, linear\n# units: numero de neuronios na camada\n#primeira camada escondida tem input_dim\nnn.add(Dense(units = 100, activation = 'relu',\n                        kernel_initializer = 'random_uniform', input_dim = 1))\nnn.add(Dense(units = 1, activation = 'linear'))\n\n# Algorritmo de aprendizado\n#sgd = keras.optimizers.SGD(lr=0.1, decay=0, momentum=0, nesterov=False)\nadam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n\n#determina a funcao de custo e a metrica utilizada\nnn.compile(loss = 'mean_squared_error', optimizer = adam,\n                  metrics = ['mean_squared_error'])\nhistory= nn.fit(X_train, y_train, batch_size = 1, epochs = 1000)\n\n#previsoes na rede no conjunto de treinamento\npredict_train =nn.predict(X_train)\n\n\n\n#Plota o treinamento\nfig = plt.figure()\nax1 = fig.add_subplot(111)\nax1.scatter(X_train, y_train, s=5, c='b', marker=\"o\", label='real')\nax1.plot(X_train,predict_train, c='r', label='NN Prediction')\n\n\n#Conjunto de Teste\nX_test = np.arange(0.0, 1, 0.01).reshape(-1, 1)\ny_test = np.sin(2*np.pi*X_test) + np.random.normal(0,0.2,100).reshape(-1,1)\ny_test=y_test.ravel()\n\n\n#Calcula as previsoes no conjunto de teste\n\npredict_test= nn.predict(X_test)\n\nfig = plt.figure()\nax1 = fig.add_subplot(111)\nax1.scatter(X_test, y_test, s=5, c='b', marker=\"o\", label='real')\nax1.plot(X_test,predict_test, c='r', label='NN Prediction')\n\nplt.legend()\nplt.show()\n\nprint('MSE training : {:.3f}'.format(mean_squared_error(y_train, predict_train)))\nprint('MSE testing : {:.3f}'.format(mean_squared_error(y_test, predict_test)))\n</code></pre>\n\n<p>I already tried sgd as optimizer and also tanh for activation function. I do not undestand what I am missing, that is why I cann make the code for function approximation using Keras work.</p>\n",
                "tags": "<keras><mlp>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17696",
            "_score": 9.083834,
            "_source": {
                "title": "test accuracy with tensorflow==2.0.0-beta1 vs TensorFlow version: 2.0.0-alpha0",
                "content": "test accuracy with tensorflow==2.0.0-beta1 vs TensorFlow version: 2.0.0-alpha0 <p>I am trying run same piece of code on both Tensorflow==2.0.0-beta1 and TensorFlow version: 2.0.0-alpha0</p>\n\n<p>In TensorFlow version: 2.0.0-alpha0 I am getting Test accuracy: 85.08% but on Tensorflow==2.0.0-beta1 test accuracy:50.08%. Can some one please help me why this model in beta is show less accuracy? Thanks in Advance.</p>\n\n<pre><code>##Import the relevant packages\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\n\nimport tensorflow_datasets as tfds\n\n\n#from datetime import datetime\nfrom datetime import datetime as dt\nfrom packaging import version\n\nfrom tensorflow import keras\n\nimport numpy as np\n\nprint(\"TensorFlow version: \", tf.__version__)\nassert version.parse(tf.__version__).release[0] &gt;= 2, \\\n    \"This notebook requires TensorFlow 2.0 or above.\"\n\n#pip install tensorflow==2.0.0-beta1\n\n(x_train, y_train), (x_val, y_val) = keras.datasets.fashion_mnist.load_data()\n\n\n## Reshape to 4d\nx_train = x_train.reshape((60000, 28, 28, 1))\nx_val = x_val.reshape((10000, 28, 28, 1))\n\n#log_dir=\"D:/DS/logs/scalars/\"\nimport os as os\nlog_dir = os.path.join(\"logs\", \"fit\", dt.now().strftime(\"%Y%m%d-%H%M%S\"))\ntensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1)\n\nNUM_EPOCHS = 20\ndata_size = 1000\n# 80% of the data is for training.\ntrain_pct = 0.8\n\ntrain_size = int(data_size * train_pct)\nBATCH_SIZE = 100\n\ninput_size = 784\noutput_size = 10\nhidden_layer_size = 50\n\nmodel = tf.keras.Sequential([\n                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n                                tf.keras.layers.Flatten(),\n                                tf.keras.layers.Dropout(0.1),\n                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n                            tf.keras.layers.Dense(output_size, activation='softmax')   \n                            ])\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nprint(\"Training ... With parameters, this may take more than 10 seconds.\")\ntraining_history = model.fit(\n    x_train, # input\n    y_train, # output\n    batch_size=BATCH_SIZE,\n    verbose=2, # Suppress chatty output; use Tensorboard instead\n    epochs=NUM_EPOCHS,\n    validation_data=(x_val, y_val),\n    callbacks=[tensorboard_callback],\n)\n\nprint(\"Average test loss: \", np.average(training_history.history['loss']))\n\nmodel.summary()\n\n##Test the model##\ntest_loss, test_accuracy = model.evaluate(x_val, y_val)\n\nprint('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))\n\n</code></pre>\n <tensorflow><accuracy>",
                "codes": [],
                "question_id:": "56765",
                "question_votes:": "",
                "question_text:": "<p>I am trying run same piece of code on both Tensorflow==2.0.0-beta1 and TensorFlow version: 2.0.0-alpha0</p>\n\n<p>In TensorFlow version: 2.0.0-alpha0 I am getting Test accuracy: 85.08% but on Tensorflow==2.0.0-beta1 test accuracy:50.08%. Can some one please help me why this model in beta is show less accuracy? Thanks in Advance.</p>\n\n<pre><code>##Import the relevant packages\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\n\nimport tensorflow_datasets as tfds\n\n\n#from datetime import datetime\nfrom datetime import datetime as dt\nfrom packaging import version\n\nfrom tensorflow import keras\n\nimport numpy as np\n\nprint(\"TensorFlow version: \", tf.__version__)\nassert version.parse(tf.__version__).release[0] &gt;= 2, \\\n    \"This notebook requires TensorFlow 2.0 or above.\"\n\n#pip install tensorflow==2.0.0-beta1\n\n(x_train, y_train), (x_val, y_val) = keras.datasets.fashion_mnist.load_data()\n\n\n## Reshape to 4d\nx_train = x_train.reshape((60000, 28, 28, 1))\nx_val = x_val.reshape((10000, 28, 28, 1))\n\n#log_dir=\"D:/DS/logs/scalars/\"\nimport os as os\nlog_dir = os.path.join(\"logs\", \"fit\", dt.now().strftime(\"%Y%m%d-%H%M%S\"))\ntensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1)\n\nNUM_EPOCHS = 20\ndata_size = 1000\n# 80% of the data is for training.\ntrain_pct = 0.8\n\ntrain_size = int(data_size * train_pct)\nBATCH_SIZE = 100\n\ninput_size = 784\noutput_size = 10\nhidden_layer_size = 50\n\nmodel = tf.keras.Sequential([\n                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n                                tf.keras.layers.Flatten(),\n                                tf.keras.layers.Dropout(0.1),\n                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n                            tf.keras.layers.Dense(output_size, activation='softmax')   \n                            ])\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nprint(\"Training ... With parameters, this may take more than 10 seconds.\")\ntraining_history = model.fit(\n    x_train, # input\n    y_train, # output\n    batch_size=BATCH_SIZE,\n    verbose=2, # Suppress chatty output; use Tensorboard instead\n    epochs=NUM_EPOCHS,\n    validation_data=(x_val, y_val),\n    callbacks=[tensorboard_callback],\n)\n\nprint(\"Average test loss: \", np.average(training_history.history['loss']))\n\nmodel.summary()\n\n##Test the model##\ntest_loss, test_accuracy = model.evaluate(x_val, y_val)\n\nprint('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))\n\n</code></pre>\n",
                "tags": "<tensorflow><accuracy>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6207",
            "_score": 9.057749,
            "_source": {
                "title": "Pre-process data images before training OneClassSVM and decrease number of features",
                "content": "Pre-process data images before training OneClassSVM and decrease number of features <p>I want to train a OneClassSVM() using sklearn, and I have a set of around 800 images in my training set.</p>\n\n<p>I am using opencv to read the images and resize them to constant dimensions (960x540) and then adding them to a numpy-array. The images are RGB and thus have 3-dimensions. For that, I am reshaping the numpy array after reading all the images:</p>\n\n<pre><code>#Assume X is my numpy array which contains all the images before reshaping\n#Now I reshape X\nn_samples = len(X)\nX = X.reshape(n_samples, 950*540*3)\n</code></pre>\n\n<p>As you can see, the number of features is huge (1,539,000 to be exact).</p>\n\n<p>Now I try to train my model:</p>\n\n<pre><code>model = OneClassSVM(kernel='rbf', gamma=0.001)\nmodel.fit(X)\n</code></pre>\n\n<p>After running my code, it crashed due to <code>MemoryError</code>. If I'm not mistaken this is obvious due the large number of features? So, is there a better way to pre-process the images before fitting them, or to decrease the number of features? </p>\n <machine-learning><python><scikit-learn><preprocessing><numpy><p>One approach is to use an artificial neural network to extract features representing the images. This can be done either by using a pre-configured network with pre-trained weights and extracting the output of one of the hidden layers, or by constructing and training your own network for this purpose. </p>\n\n<p>To use a pre-configured, pre-trained module can be accomplished easily with Keras and TensorFlow, where you can import InceptionV3 or MobileNet with weights pre-trained on ImageNet, which would net you 2048 or 1024 features per image, respectively. </p>\n\n<p>An article discussing such an approach can be found <a href=\"https://medium.com/@franky07724_57962/using-keras-pre-trained-models-for-feature-extraction-in-image-clustering-a142c6cdf5b1\" rel=\"nofollow noreferrer\">here</a>. This could hopefully give you better performance than using something like PCA to conduct dimensionality reduction.</p>\n<p>You should try converting them to Principle Components using PCA. Please refer this <a href=\"https://www.analyticsvidhya.com/blog/2016/03/practical-guide-principal-component-analysis-python/\" rel=\"nofollow noreferrer\">Analytics Vidya PCA</a>, this should give give you a good understanding.</p>\n\n<p>PCA converts n large vector into p Principle components. </p>\n\n<blockquote>\n  <p>First principal component is a linear combination of original predictor variables which captures the maximum variance in the data set</p>\n</blockquote>\n\n<p>Second PC is also a linear combination of original predictor variables which captures remaining variance. All the succeeding ones follow the same concept.</p>\n\n<p>This way you can select top Principle components which explains good enough cumulative variance in your data</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "24363",
                "question_votes:": "1",
                "question_text:": "<p>I want to train a OneClassSVM() using sklearn, and I have a set of around 800 images in my training set.</p>\n\n<p>I am using opencv to read the images and resize them to constant dimensions (960x540) and then adding them to a numpy-array. The images are RGB and thus have 3-dimensions. For that, I am reshaping the numpy array after reading all the images:</p>\n\n<pre><code>#Assume X is my numpy array which contains all the images before reshaping\n#Now I reshape X\nn_samples = len(X)\nX = X.reshape(n_samples, 950*540*3)\n</code></pre>\n\n<p>As you can see, the number of features is huge (1,539,000 to be exact).</p>\n\n<p>Now I try to train my model:</p>\n\n<pre><code>model = OneClassSVM(kernel='rbf', gamma=0.001)\nmodel.fit(X)\n</code></pre>\n\n<p>After running my code, it crashed due to <code>MemoryError</code>. If I'm not mistaken this is obvious due the large number of features? So, is there a better way to pre-process the images before fitting them, or to decrease the number of features? </p>\n",
                "tags": "<machine-learning><python><scikit-learn><preprocessing><numpy>",
                "answers": [
                    [
                        "32606",
                        "2",
                        "24363",
                        "",
                        "",
                        "<p>One approach is to use an artificial neural network to extract features representing the images. This can be done either by using a pre-configured network with pre-trained weights and extracting the output of one of the hidden layers, or by constructing and training your own network for this purpose. </p>\n\n<p>To use a pre-configured, pre-trained module can be accomplished easily with Keras and TensorFlow, where you can import InceptionV3 or MobileNet with weights pre-trained on ImageNet, which would net you 2048 or 1024 features per image, respectively. </p>\n\n<p>An article discussing such an approach can be found <a href=\"https://medium.com/@franky07724_57962/using-keras-pre-trained-models-for-feature-extraction-in-image-clustering-a142c6cdf5b1\" rel=\"nofollow noreferrer\">here</a>. This could hopefully give you better performance than using something like PCA to conduct dimensionality reduction.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "24366",
                        "2",
                        "24363",
                        "",
                        "",
                        "<p>You should try converting them to Principle Components using PCA. Please refer this <a href=\"https://www.analyticsvidhya.com/blog/2016/03/practical-guide-principal-component-analysis-python/\" rel=\"nofollow noreferrer\">Analytics Vidya PCA</a>, this should give give you a good understanding.</p>\n\n<p>PCA converts n large vector into p Principle components. </p>\n\n<blockquote>\n  <p>First principal component is a linear combination of original predictor variables which captures the maximum variance in the data set</p>\n</blockquote>\n\n<p>Second PC is also a linear combination of original predictor variables which captures remaining variance. All the succeeding ones follow the same concept.</p>\n\n<p>This way you can select top Principle components which explains good enough cumulative variance in your data</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15801",
            "_score": 9.043197,
            "_source": {
                "title": "Fixed: Keras Neural Network on handwritten digits labeling: Model reads the surrounding space instead of digit",
                "content": "Fixed: Keras Neural Network on handwritten digits labeling: Model reads the surrounding space instead of digit <p>Our assignment consists of labeling handwritten numbers, ranging from 0 to 9.</p>\n\n<p>We build a Convolutional Neural Network that achieves a good accuracy on our labeled testset. We now want to use this model to predict the numbers on our unlabeled dataset, called Z.</p>\n\n<p>When printing out the predictions, it seems that the model predicts the number 0 way too often and that it scores a very low accuracy. </p>\n\n<p>We have:</p>\n\n<p>X_train of float64 and shape(42000, 28, 28, 1)\nY_train of float32 and shape(42000, 10)\nX_test of float64 and shape(28000, 28, 28, 1)\nZ_test(the unlabeled set) of floats64 and shape(15000, 28, 28, 1)</p>\n\n<p>When printing out the digits I saw that our train and test datasets look like this: </p>\n\n<p><a href=\"https://i.stack.imgur.com/vei4U.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/vei4U.png\" alt=\"enter image description here\"></a></p>\n\n<p>Our unlabeled dataset, Z, looks like this:</p>\n\n<p><a href=\"https://i.stack.imgur.com/12tpU.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/12tpU.png\" alt=\"enter image description here\"></a></p>\n\n<pre><code>Our code looks like this:\n\nY_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1)\nX_train = X_train / 255.0\nX_test = test / 255.0\nX_train = X_train.values.reshape(-1,28,28,1)\nX_test = X_test.values.reshape(-1,28,28,1)\nY_train = to_categorical(Y_train, num_classes = 10)\nZ_test = unlabeleddata / 255.0\nZ_test2 = Z_test.reshape(-1,28,28,1)\n</code></pre>\n\n<p>Is there a solution to fix this problem?</p>\n\n<p>Thanks!</p>\n\n<p>Edit: The problem was fixed with this code:</p>\n\n<pre><code>Z_test = unlabeleddata - 255.0\nZ_test = unlabeleddata / 255.0\nZ_test = Z_test - 1\nZ_test = np.absolute(Z_test)\nZ_test2 = Z_test.reshape(-1,28,28,1)\n\n</code></pre>\n <machine-learning><python><numpy>",
                "codes": [],
                "question_id:": "52712",
                "question_votes:": "",
                "question_text:": "<p>Our assignment consists of labeling handwritten numbers, ranging from 0 to 9.</p>\n\n<p>We build a Convolutional Neural Network that achieves a good accuracy on our labeled testset. We now want to use this model to predict the numbers on our unlabeled dataset, called Z.</p>\n\n<p>When printing out the predictions, it seems that the model predicts the number 0 way too often and that it scores a very low accuracy. </p>\n\n<p>We have:</p>\n\n<p>X_train of float64 and shape(42000, 28, 28, 1)\nY_train of float32 and shape(42000, 10)\nX_test of float64 and shape(28000, 28, 28, 1)\nZ_test(the unlabeled set) of floats64 and shape(15000, 28, 28, 1)</p>\n\n<p>When printing out the digits I saw that our train and test datasets look like this: </p>\n\n<p><a href=\"https://i.stack.imgur.com/vei4U.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/vei4U.png\" alt=\"enter image description here\"></a></p>\n\n<p>Our unlabeled dataset, Z, looks like this:</p>\n\n<p><a href=\"https://i.stack.imgur.com/12tpU.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/12tpU.png\" alt=\"enter image description here\"></a></p>\n\n<pre><code>Our code looks like this:\n\nY_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1)\nX_train = X_train / 255.0\nX_test = test / 255.0\nX_train = X_train.values.reshape(-1,28,28,1)\nX_test = X_test.values.reshape(-1,28,28,1)\nY_train = to_categorical(Y_train, num_classes = 10)\nZ_test = unlabeleddata / 255.0\nZ_test2 = Z_test.reshape(-1,28,28,1)\n</code></pre>\n\n<p>Is there a solution to fix this problem?</p>\n\n<p>Thanks!</p>\n\n<p>Edit: The problem was fixed with this code:</p>\n\n<pre><code>Z_test = unlabeleddata - 255.0\nZ_test = unlabeleddata / 255.0\nZ_test = Z_test - 1\nZ_test = np.absolute(Z_test)\nZ_test2 = Z_test.reshape(-1,28,28,1)\n\n</code></pre>\n",
                "tags": "<machine-learning><python><numpy>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15031",
            "_score": 8.988856,
            "_source": {
                "title": "Splitting and training multiple datasets at the same time",
                "content": "Splitting and training multiple datasets at the same time <p>I've got 15 different datasets at about 10GB each. Each dataset comes with a binary 2D ground truth (10486147ish, 1) that I pull from it. I'm trying to figure out how to load each dataset, split them all with scikitlearn's train_test_split, then iterate over all 15 datasets per epoch. Under normal circumstances, the datasets would be shuffled as well, but I cannot figure out how to even do that since the data is too large to load all at once to shuffle (as such shuffling them is on the back burner for now).</p>\n\n<p>Here's what my code looks like for one dataset.</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import sequence\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection imporrt train_test_split\n\n\n\narr = np.load ('source/dir/dataset1.npy', allow_pickle = True, fix_imports = True)\narr[arr == -inf = -9999]\nrehape = arr.reshape(((arr.shape[0])*(arr.shape[1])), (arr.shape[2]))\ndrop = reshape[~np.all(reshape == -9999, axis = 1)]\n#additional work done with -9999 here\ntruth = drop[:,46]\ndata = drop[:,0:45]\n\n#callbacks deleted in code sample\n\nencoder = LabelEncoder()\nencoder.fit(truth)\nY = encoder.transform(truth)\nY = Y.reshape(10486147, 1)\nX = data.reshape(10486147, 45, 3)\n\nseed = 7\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.33, random_state = seed)\n\nmodel = sequential()\nmodel.add(LSTM(units = 32, activation = relu, input_shape = (45, 3), return_sequences = True))\nmodel.add(LSTM(units = 32, activation = relu, input_shape = (45, 3), return_sequences = True))\nmodel.add(LSTM(units = 32, activation = relu, input_shape = (45, 3)))\nmodel.add(Dense(1, kernel_initializer = 'normal', activation = 'sigmoid'))\n\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n\nmodel.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 500, batch_size = 1000, callbacks = [deleted callbacks])\n</code></pre>\n\n<p>So that makes sense for one dataset, but as I've said before I've got 15 datasets to iterate through, and I don't think retraining on new data is the right step.\nIs there a way through dataset1.npy through dataset15.npy while properly splitting the ground truth as well.</p>\n\n<p>Any suggestions?</p>\n <python><keras><scikit-learn><tensorflow><stacked-lstm>",
                "codes": [],
                "question_id:": "51043",
                "question_votes:": "1",
                "question_text:": "<p>I've got 15 different datasets at about 10GB each. Each dataset comes with a binary 2D ground truth (10486147ish, 1) that I pull from it. I'm trying to figure out how to load each dataset, split them all with scikitlearn's train_test_split, then iterate over all 15 datasets per epoch. Under normal circumstances, the datasets would be shuffled as well, but I cannot figure out how to even do that since the data is too large to load all at once to shuffle (as such shuffling them is on the back burner for now).</p>\n\n<p>Here's what my code looks like for one dataset.</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import sequence\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection imporrt train_test_split\n\n\n\narr = np.load ('source/dir/dataset1.npy', allow_pickle = True, fix_imports = True)\narr[arr == -inf = -9999]\nrehape = arr.reshape(((arr.shape[0])*(arr.shape[1])), (arr.shape[2]))\ndrop = reshape[~np.all(reshape == -9999, axis = 1)]\n#additional work done with -9999 here\ntruth = drop[:,46]\ndata = drop[:,0:45]\n\n#callbacks deleted in code sample\n\nencoder = LabelEncoder()\nencoder.fit(truth)\nY = encoder.transform(truth)\nY = Y.reshape(10486147, 1)\nX = data.reshape(10486147, 45, 3)\n\nseed = 7\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.33, random_state = seed)\n\nmodel = sequential()\nmodel.add(LSTM(units = 32, activation = relu, input_shape = (45, 3), return_sequences = True))\nmodel.add(LSTM(units = 32, activation = relu, input_shape = (45, 3), return_sequences = True))\nmodel.add(LSTM(units = 32, activation = relu, input_shape = (45, 3)))\nmodel.add(Dense(1, kernel_initializer = 'normal', activation = 'sigmoid'))\n\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n\nmodel.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 500, batch_size = 1000, callbacks = [deleted callbacks])\n</code></pre>\n\n<p>So that makes sense for one dataset, but as I've said before I've got 15 datasets to iterate through, and I don't think retraining on new data is the right step.\nIs there a way through dataset1.npy through dataset15.npy while properly splitting the ground truth as well.</p>\n\n<p>Any suggestions?</p>\n",
                "tags": "<python><keras><scikit-learn><tensorflow><stacked-lstm>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11256",
            "_score": 8.93055,
            "_source": {
                "title": "Keras input shape error",
                "content": "Keras input shape error <p>I am trying to load a Keras model and make predictions with it and run into a strange error. An minimal example is the following:</p>\n\n<pre><code>from keras import models\nimport numpy as np\n\nmodel = models.load_model('model_4hiddenLayers_16unitsPerLayer_relu_learningRate0p0001.h5')\nx = np.ones(36, dtype=float)\nprediction = model.predict(x )\n</code></pre>\n\n<p>The model expects an input shape of (36,), which should be the shape of x, which I verified: </p>\n\n<pre><code>print('x.shape={}'.format(x.shape) )\n</code></pre>\n\n<p>gives : </p>\n\n<blockquote>\n  <p>x.shape=(36,)</p>\n</blockquote>\n\n<p>However when running this code I get the following error message:</p>\n\n<blockquote>\n  <p>ValueError: Error when checking : expected batch_normalization_1_input to have shape (36,) but got array with shape (1,)</p>\n</blockquote>\n\n<p>What am I missing here? Thanks for the help. </p>\n\n<p>Some additional info : I am using keras version 2.1.4 with TensorFlow as backend. </p>\n <keras><tensorflow><reshape><p>I figured out the issue. The \"predict\" function expects a batch of input arrays, so it expects x to have shape (n, 36) where n is the number of examples. After adding :</p>\n\n<pre><code>x = x.reshape( (1,36) )\n</code></pre>\n\n<p>the code works fine</p>\n",
                "codes": [
                    [
                        "x = x.reshape( (1,36) )\n"
                    ]
                ],
                "question_id:": "39721",
                "question_votes:": "1",
                "question_text:": "<p>I am trying to load a Keras model and make predictions with it and run into a strange error. An minimal example is the following:</p>\n\n<pre><code>from keras import models\nimport numpy as np\n\nmodel = models.load_model('model_4hiddenLayers_16unitsPerLayer_relu_learningRate0p0001.h5')\nx = np.ones(36, dtype=float)\nprediction = model.predict(x )\n</code></pre>\n\n<p>The model expects an input shape of (36,), which should be the shape of x, which I verified: </p>\n\n<pre><code>print('x.shape={}'.format(x.shape) )\n</code></pre>\n\n<p>gives : </p>\n\n<blockquote>\n  <p>x.shape=(36,)</p>\n</blockquote>\n\n<p>However when running this code I get the following error message:</p>\n\n<blockquote>\n  <p>ValueError: Error when checking : expected batch_normalization_1_input to have shape (36,) but got array with shape (1,)</p>\n</blockquote>\n\n<p>What am I missing here? Thanks for the help. </p>\n\n<p>Some additional info : I am using keras version 2.1.4 with TensorFlow as backend. </p>\n",
                "tags": "<keras><tensorflow><reshape>",
                "answers": [
                    [
                        "39722",
                        "2",
                        "39721",
                        "",
                        "",
                        "<p>I figured out the issue. The \"predict\" function expects a batch of input arrays, so it expects x to have shape (n, 36) where n is the number of examples. After adding :</p>\n\n<pre><code>x = x.reshape( (1,36) )\n</code></pre>\n\n<p>the code works fine</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14610",
            "_score": 8.923016,
            "_source": {
                "title": "Saving multiple numpy arrays to multiple image files",
                "content": "Saving multiple numpy arrays to multiple image files <p>I have some CSV data that I have extracted in chunks of 375. Since I have 20 columns of data (7500 elements total), I have then reshaped these chunks into an image in the form of (3,50,50) to represent the 3 RGB channels and the 50x50 pixel image. </p>\n\n<p>So now each chunk of 375 from my CSV file is one 50x50 RGB image. However I can only get one image to output currently, how would i loop through to save each image (each chunk)?</p>\n\n<p>My code so far is below. Any suggestions would be appreciated. Thanks! :)</p>\n\n<pre><code>import glob\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\n\nmycsvdir = '/home/path/'\n\ncsvfiles = glob.glob(os.path.join(mycsvdir, '*.csv'))\n\nchunksize = 375\ndata_array = np.empty((0, 2))\n\nfor file in csvfiles:\n\n    df_data = pd.read_csv(file, sep = ',', usecols = ['Dst Port', 'Protocol', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'Flow IAT Mean', \n 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Flow Pkts/s', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', \n 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Label'],  dtype=None, low_memory=False, chunksize = chunksize)\n\n\n    for chunk in df_data:\n        chunk['Label'] = np.where( chunk.Label == 'Benign', 0, 1)\n\n        if (chunk['Label'] == 0).all():\n            benign_chunk_drop = chunk.drop(columns='Label')\n            np_benign = benign_chunk_drop.to_numpy(dtype=np.float64)\n            np_flat_benign = np_benign.flatten()\n\n\n            normalised_np = np.interp(np_flat_benign, (np_flat_benign.min(), np_flat_benign.max()), (-10, 0))\n            normalised_np = (normalised_np/-10)*255\n            image_numpy = np.reshape(normalised_np, (3, 50, 50))\n\n\n            # arr = np.random.uniform(size=(3,50,50))*255\n            # print(arr)\n\n            for x in image_numpy:\n                img = Image.fromarray(x, 'RGB')\n                img.save('out' + '.png')   \n</code></pre>\n <python><data-cleaning><numpy>",
                "codes": [],
                "question_id:": "49059",
                "question_votes:": "",
                "question_text:": "<p>I have some CSV data that I have extracted in chunks of 375. Since I have 20 columns of data (7500 elements total), I have then reshaped these chunks into an image in the form of (3,50,50) to represent the 3 RGB channels and the 50x50 pixel image. </p>\n\n<p>So now each chunk of 375 from my CSV file is one 50x50 RGB image. However I can only get one image to output currently, how would i loop through to save each image (each chunk)?</p>\n\n<p>My code so far is below. Any suggestions would be appreciated. Thanks! :)</p>\n\n<pre><code>import glob\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\n\nmycsvdir = '/home/path/'\n\ncsvfiles = glob.glob(os.path.join(mycsvdir, '*.csv'))\n\nchunksize = 375\ndata_array = np.empty((0, 2))\n\nfor file in csvfiles:\n\n    df_data = pd.read_csv(file, sep = ',', usecols = ['Dst Port', 'Protocol', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'Flow IAT Mean', \n 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Flow Pkts/s', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', \n 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Label'],  dtype=None, low_memory=False, chunksize = chunksize)\n\n\n    for chunk in df_data:\n        chunk['Label'] = np.where( chunk.Label == 'Benign', 0, 1)\n\n        if (chunk['Label'] == 0).all():\n            benign_chunk_drop = chunk.drop(columns='Label')\n            np_benign = benign_chunk_drop.to_numpy(dtype=np.float64)\n            np_flat_benign = np_benign.flatten()\n\n\n            normalised_np = np.interp(np_flat_benign, (np_flat_benign.min(), np_flat_benign.max()), (-10, 0))\n            normalised_np = (normalised_np/-10)*255\n            image_numpy = np.reshape(normalised_np, (3, 50, 50))\n\n\n            # arr = np.random.uniform(size=(3,50,50))*255\n            # print(arr)\n\n            for x in image_numpy:\n                img = Image.fromarray(x, 'RGB')\n                img.save('out' + '.png')   \n</code></pre>\n",
                "tags": "<python><data-cleaning><numpy>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4293",
            "_score": 8.868212,
            "_source": {
                "title": "How to model segmentation of a sequence to similar parts?",
                "content": "How to model segmentation of a sequence to similar parts? <p>I guess LSTM is good for sequence modeling but how would you model \"clustering\" with it? Meaning, the input is a sequence and the output is labels with similar properties (I have labeled data). For example: </p>\n\n<pre><code>input:  1 2 1 1 2 1 2 5 6 5 4 5 1 1 2 1 1 2 1 \noutput: 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1\n</code></pre>\n\n<p>The problem is how to tell the model to learn differences and not the particular example, as a new example could have totally different values. I could have taught it to predict the N*(N-1)/2 pairwise differences (similar non similar) but it will not learn the dynamics.</p>\n <machine-learning><neural-network><deep-learning><p>The problem can be reframed as a binary classification by ignoring the order, and then a decision tree algorithm can learn to separate the groups with perfect accuracy.</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Define training data\ntraining_data    = np.array([1, 2, 1, 1, 2, 1, 2, 5, 6, 5, 4, 5, 1, 1, 2, 1, 1, 2, 1]).reshape(-1, 1)\ntraining_targets = np.array([1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1]).reshape(-1, 1)\n\n# Train a descision tree with scikit-learn\nclf = DecisionTreeClassifier(max_depth=1)\nclf.fit(training_data, training_targets)\n\n# Let's if the model can predict unseen data\ntest_data_low = np.array([0]).reshape(1, -1)\nprediction = clf.predict(test_data_low)\nassert prediction == 1\n\ntest_data_high = np.array([7]).reshape(1, -1)\nprediction = clf.predict(test_data_high)\nassert prediction == 2\n</code></pre>\n\n<p>The ability of a model to learn to generalize (i.e., predict total new values) can be increased by increasing regularization. In the above example, one method to increase regularization is limiting the depth of the decision tree. I have set the depth to be a single split, aka decision stump. A decision stump is the most regularized version of a decision tree.</p>\n",
                "codes": [
                    [
                        "import numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Define training data\ntraining_data    = np.array([1, 2, 1, 1, 2, 1, 2, 5, 6, 5, 4, 5, 1, 1, 2, 1, 1, 2, 1]).reshape(-1, 1)\ntraining_targets = np.array([1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1]).reshape(-1, 1)\n\n# Train a descision tree with scikit-learn\nclf = DecisionTreeClassifier(max_depth=1)\nclf.fit(training_data, training_targets)\n\n# Let's if the model can predict unseen data\ntest_data_low = np.array([0]).reshape(1, -1)\nprediction = clf.predict(test_data_low)\nassert prediction == 1\n\ntest_data_high = np.array([7]).reshape(1, -1)\nprediction = clf.predict(test_data_high)\nassert prediction == 2\n"
                    ]
                ],
                "question_id:": "17266",
                "question_votes:": "5",
                "question_text:": "<p>I guess LSTM is good for sequence modeling but how would you model \"clustering\" with it? Meaning, the input is a sequence and the output is labels with similar properties (I have labeled data). For example: </p>\n\n<pre><code>input:  1 2 1 1 2 1 2 5 6 5 4 5 1 1 2 1 1 2 1 \noutput: 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1\n</code></pre>\n\n<p>The problem is how to tell the model to learn differences and not the particular example, as a new example could have totally different values. I could have taught it to predict the N*(N-1)/2 pairwise differences (similar non similar) but it will not learn the dynamics.</p>\n",
                "tags": "<machine-learning><neural-network><deep-learning>",
                "answers": [
                    [
                        "57763",
                        "2",
                        "17266",
                        "",
                        "",
                        "<p>The problem can be reframed as a binary classification by ignoring the order, and then a decision tree algorithm can learn to separate the groups with perfect accuracy.</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Define training data\ntraining_data    = np.array([1, 2, 1, 1, 2, 1, 2, 5, 6, 5, 4, 5, 1, 1, 2, 1, 1, 2, 1]).reshape(-1, 1)\ntraining_targets = np.array([1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1]).reshape(-1, 1)\n\n# Train a descision tree with scikit-learn\nclf = DecisionTreeClassifier(max_depth=1)\nclf.fit(training_data, training_targets)\n\n# Let's if the model can predict unseen data\ntest_data_low = np.array([0]).reshape(1, -1)\nprediction = clf.predict(test_data_low)\nassert prediction == 1\n\ntest_data_high = np.array([7]).reshape(1, -1)\nprediction = clf.predict(test_data_high)\nassert prediction == 2\n</code></pre>\n\n<p>The ability of a model to learn to generalize (i.e., predict total new values) can be increased by increasing regularization. In the above example, one method to increase regularization is limiting the depth of the decision tree. I have set the depth to be a single split, aka decision stump. A decision stump is the most regularized version of a decision tree.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13811",
            "_score": 8.868212,
            "_source": {
                "title": "how to reshape xtrain array and what about input shape?",
                "content": "how to reshape xtrain array and what about input shape? <pre><code>from keras.datasets import mnist\nfrom keras.layers import Activation,Dense,Convolution2D\nfrom keras.models import save_model,load_model,Sequential\nfrom keras.callbacks import TensorBoard\nimport matplotlib.pyplot as pl\n\n(xtrain,ytrain),(xtest,ytest)=mnist.load_data()\nmodel = Sequential()\nmodel.add(Convolution2D(32,3,activation='relu',input_shape=(60000,28,28)))\nmodel.add(Dense(10, activation='relu'))\n\nmodel.summary()\n\nmodel.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              &lt;space&gt;metrics=['accuracy'])\n\nmodel.fit(xtrain, ytrain, epochs=10, batch_size=60000)\n</code></pre>\n <python><keras><p>Keras requires you to set the input_shape of the network. This is the shape of a single instance of your data which would be <code>(28,28)</code>. However, Keras also needs a channel dimension thus the input shape for the MNIST dataset would be <code>(28,28,1)</code>.</p>\n\n<hr>\n\n<p>First we load the data as you did,</p>\n\n<pre><code>from keras.datasets import mnist\nimport numpy as np\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nprint('Training data shape: ', x_train.shape)\nprint('Testing data shape : ', x_test.shape)\n</code></pre>\n\n<blockquote>\n  <p>Training data shape:  (60000, 28, 28) <br>\n  Testing data shape :  (10000, 28, 28)</p>\n</blockquote>\n\n<p>Then we reshape the examples in the MNIST dataset to have the additional channel dimension</p>\n\n<pre><code># Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test_reshaped = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n</code></pre>\n\n<p>And now we can define our model as you did. Do note the necessary Flatten layer between the Convolutional layers and the Dense layer.</p>\n\n<pre><code>model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nmodel.fit(xtrain, ytrain, epochs=10, batch_size=60000)\n</code></pre>\n",
                "codes": [
                    [
                        "from keras.datasets import mnist\nimport numpy as np\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nprint('Training data shape: ', x_train.shape)\nprint('Testing data shape : ', x_test.shape)\n",
                        "# Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test_reshaped = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n",
                        "model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nmodel.fit(xtrain, ytrain, epochs=10, batch_size=60000)\n"
                    ]
                ],
                "question_id:": "46885",
                "question_votes:": "1",
                "question_text:": "<pre><code>from keras.datasets import mnist\nfrom keras.layers import Activation,Dense,Convolution2D\nfrom keras.models import save_model,load_model,Sequential\nfrom keras.callbacks import TensorBoard\nimport matplotlib.pyplot as pl\n\n(xtrain,ytrain),(xtest,ytest)=mnist.load_data()\nmodel = Sequential()\nmodel.add(Convolution2D(32,3,activation='relu',input_shape=(60000,28,28)))\nmodel.add(Dense(10, activation='relu'))\n\nmodel.summary()\n\nmodel.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              &lt;space&gt;metrics=['accuracy'])\n\nmodel.fit(xtrain, ytrain, epochs=10, batch_size=60000)\n</code></pre>\n",
                "tags": "<python><keras>",
                "answers": [
                    [
                        "46895",
                        "2",
                        "46885",
                        "",
                        "",
                        "<p>Keras requires you to set the input_shape of the network. This is the shape of a single instance of your data which would be <code>(28,28)</code>. However, Keras also needs a channel dimension thus the input shape for the MNIST dataset would be <code>(28,28,1)</code>.</p>\n\n<hr>\n\n<p>First we load the data as you did,</p>\n\n<pre><code>from keras.datasets import mnist\nimport numpy as np\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nprint('Training data shape: ', x_train.shape)\nprint('Testing data shape : ', x_test.shape)\n</code></pre>\n\n<blockquote>\n  <p>Training data shape:  (60000, 28, 28) <br>\n  Testing data shape :  (10000, 28, 28)</p>\n</blockquote>\n\n<p>Then we reshape the examples in the MNIST dataset to have the additional channel dimension</p>\n\n<pre><code># Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test_reshaped = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n</code></pre>\n\n<p>And now we can define our model as you did. Do note the necessary Flatten layer between the Convolutional layers and the Dense layer.</p>\n\n<pre><code>model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nmodel.fit(xtrain, ytrain, epochs=10, batch_size=60000)\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17766",
            "_score": 8.868212,
            "_source": {
                "title": "When I use SHAP for classification problem, it shows an output that is not 0 or 1. How can I overcome this?",
                "content": "When I use SHAP for classification problem, it shows an output that is not 0 or 1. How can I overcome this? <p>I'm using Pima Indians Diabetes Database(<a href=\"https://www.kaggle.com/uciml/pima-indians-diabetes-database\" rel=\"nofollow noreferrer\">https://www.kaggle.com/uciml/pima-indians-diabetes-database</a>). I made predictions using XGboost and I'm trying to analyze the features using SHAP. </p>\n\n<p>However when I use force_plot with just one training example(a 1x8 vector) it shows that my output is -2.02. This is a classification problem, I shouldn't be seeing such a value. I'm new in SHAP and I don't know what the problem is.</p>\n\n<p>Here is my code: </p>\n\n<pre><code>import numpy as np\nimport xgboost as xgb\nimport sklearn as skl\nimport shap\n\ndataset=np.loadtxt(\"diabetes.csv\", delimiter=\",\")\nX=dataset[:,0:8]\nY=dataset[:,8]\nseed=7\ntest_size=0.33\nX_train, X_test, y_train, y_test=skl.model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n\nshap.initjs()\nmodel=xgb.XGBClassifier()\nmodel.fit(X_train, y_train)\n\npredictions=model.predict(X_test)\naccuracy=skl.metrics.accuracy_score(y_test, predictions)\nprint(accuracy*100)\n\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X_train)\nshap.force_plot(explainer.expected_value, shap_values[0,:].reshape(1, 8), X_train[0,:].reshape(1, 8))\n</code></pre>\n\n<p>Accuracy of my model is: 77,95.</p>\n\n<p><a href=\"https://i.stack.imgur.com/aOz3i.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/aOz3i.png\" alt=\"Here is the result of my plot\"></a></p>\n <classification><xgboost><p>The default link function is the identity, so you are seeing log-odds rather than probabilities. To see the probability, try adding <code>link='logit'</code> to your call of <code>force_plot</code> like so:</p>\n\n<pre><code>shap.force_plot(explainer.expected_value,\n                shap_values[0,:].reshape(1, 8),\n                X_train[0,:].reshape(1, 8),\n                link='logit')\n</code></pre>\n\n<p>You can read more at the <a href=\"https://shap.readthedocs.io/en/latest/#shap.force_plot\" rel=\"nofollow noreferrer\">SHAP documentation</a> site.</p>\n",
                "codes": [
                    [
                        "shap.force_plot(explainer.expected_value,\n                shap_values[0,:].reshape(1, 8),\n                X_train[0,:].reshape(1, 8),\n                link='logit')\n"
                    ]
                ],
                "question_id:": "56923",
                "question_votes:": "1",
                "question_text:": "<p>I'm using Pima Indians Diabetes Database(<a href=\"https://www.kaggle.com/uciml/pima-indians-diabetes-database\" rel=\"nofollow noreferrer\">https://www.kaggle.com/uciml/pima-indians-diabetes-database</a>). I made predictions using XGboost and I'm trying to analyze the features using SHAP. </p>\n\n<p>However when I use force_plot with just one training example(a 1x8 vector) it shows that my output is -2.02. This is a classification problem, I shouldn't be seeing such a value. I'm new in SHAP and I don't know what the problem is.</p>\n\n<p>Here is my code: </p>\n\n<pre><code>import numpy as np\nimport xgboost as xgb\nimport sklearn as skl\nimport shap\n\ndataset=np.loadtxt(\"diabetes.csv\", delimiter=\",\")\nX=dataset[:,0:8]\nY=dataset[:,8]\nseed=7\ntest_size=0.33\nX_train, X_test, y_train, y_test=skl.model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n\nshap.initjs()\nmodel=xgb.XGBClassifier()\nmodel.fit(X_train, y_train)\n\npredictions=model.predict(X_test)\naccuracy=skl.metrics.accuracy_score(y_test, predictions)\nprint(accuracy*100)\n\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X_train)\nshap.force_plot(explainer.expected_value, shap_values[0,:].reshape(1, 8), X_train[0,:].reshape(1, 8))\n</code></pre>\n\n<p>Accuracy of my model is: 77,95.</p>\n\n<p><a href=\"https://i.stack.imgur.com/aOz3i.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/aOz3i.png\" alt=\"Here is the result of my plot\"></a></p>\n",
                "tags": "<classification><xgboost>",
                "answers": [
                    [
                        "56929",
                        "2",
                        "56923",
                        "",
                        "",
                        "<p>The default link function is the identity, so you are seeing log-odds rather than probabilities. To see the probability, try adding <code>link='logit'</code> to your call of <code>force_plot</code> like so:</p>\n\n<pre><code>shap.force_plot(explainer.expected_value,\n                shap_values[0,:].reshape(1, 8),\n                X_train[0,:].reshape(1, 8),\n                link='logit')\n</code></pre>\n\n<p>You can read more at the <a href=\"https://shap.readthedocs.io/en/latest/#shap.force_plot\" rel=\"nofollow noreferrer\">SHAP documentation</a> site.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7237",
            "_score": 8.842371,
            "_source": {
                "title": "Please help me out with this Python error - 'invalid syntax'",
                "content": "Please help me out with this Python error - 'invalid syntax' <h3>Code:</h3>\n\n<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import datasets, linear_model\nhouse_price = [245, 312, 279, 308, 199, 219, 405, 324, 319, 255]\nsize = [1400, 1600, 1700, 1875, 1100, 1550, 2350, 2450, 1425, 1700]\nsize2 = np.array(size).reshape((-1, 1))\n#fitting into the model\nregr = linear_model.LinearRegression()\nregr.fit(size2, house_price)\nprint(\"Coefficients: \\n\", regr.coef_)\nprint(\"intercept: \\n\", regr.intercept_)\n#############################\n#formula obtained for the trained model\ndef graph(formula, x_range):\n   x = np.array(x_range)\n   y = eval(formula)\n   plt.plot(x, y)\n#plotting the prediction line \ngraph('regr.coef_*x + regr.intercept_', range(1000, 2700))\nprint(regr.score(size2, house_price))\nplt.scatter (size,house_price, color='black')\nplt.ylabel('house price')\nplt.xlabel('size of house')\nplt.show()\n</code></pre>\n\n<h3>Error</h3>\n\n<blockquote>\n<pre><code>**Error Line:print regr.predict([2000])**\nError: File \"&lt;ipython-input-4-9afa91ca7f9e&gt;\", line 1\n    print regr.predict([2000])\n             ^\nSyntaxError: invalid syntax\n</code></pre>\n</blockquote>\n <machine-learning><python><linear-regression><p>In your current line </p>\n\n<pre><code>print regr.predict([2000])\n</code></pre>\n\n<p>This will not work. The first error is the lack of brackets around the contents of your print statement which is required in Python 3. Change this first to</p>\n\n<pre><code>print(regr.predict([2000]))\n</code></pre>\n\n<p>However, you will see that this does not work either. I suspect you are attempting to evaluate the price for a new $size = 2000$. You will need to reshape the input to your regression for this to work. </p>\n\n<pre><code>new_size = np.array([2000]).reshape((-1, 1))\nprint(regr.predict(new_size))\n</code></pre>\n\n<blockquote>\n  <p>[ 317.78380528]</p>\n</blockquote>\n",
                "codes": [
                    [
                        "print regr.predict([2000])\n",
                        "print(regr.predict([2000]))\n",
                        "new_size = np.array([2000]).reshape((-1, 1))\nprint(regr.predict(new_size))\n"
                    ]
                ],
                "question_id:": "27278",
                "question_votes:": "1",
                "question_text:": "<h3>Code:</h3>\n\n<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import datasets, linear_model\nhouse_price = [245, 312, 279, 308, 199, 219, 405, 324, 319, 255]\nsize = [1400, 1600, 1700, 1875, 1100, 1550, 2350, 2450, 1425, 1700]\nsize2 = np.array(size).reshape((-1, 1))\n#fitting into the model\nregr = linear_model.LinearRegression()\nregr.fit(size2, house_price)\nprint(\"Coefficients: \\n\", regr.coef_)\nprint(\"intercept: \\n\", regr.intercept_)\n#############################\n#formula obtained for the trained model\ndef graph(formula, x_range):\n   x = np.array(x_range)\n   y = eval(formula)\n   plt.plot(x, y)\n#plotting the prediction line \ngraph('regr.coef_*x + regr.intercept_', range(1000, 2700))\nprint(regr.score(size2, house_price))\nplt.scatter (size,house_price, color='black')\nplt.ylabel('house price')\nplt.xlabel('size of house')\nplt.show()\n</code></pre>\n\n<h3>Error</h3>\n\n<blockquote>\n<pre><code>**Error Line:print regr.predict([2000])**\nError: File \"&lt;ipython-input-4-9afa91ca7f9e&gt;\", line 1\n    print regr.predict([2000])\n             ^\nSyntaxError: invalid syntax\n</code></pre>\n</blockquote>\n",
                "tags": "<machine-learning><python><linear-regression>",
                "answers": [
                    [
                        "27281",
                        "2",
                        "27278",
                        "",
                        "",
                        "<p>In your current line </p>\n\n<pre><code>print regr.predict([2000])\n</code></pre>\n\n<p>This will not work. The first error is the lack of brackets around the contents of your print statement which is required in Python 3. Change this first to</p>\n\n<pre><code>print(regr.predict([2000]))\n</code></pre>\n\n<p>However, you will see that this does not work either. I suspect you are attempting to evaluate the price for a new $size = 2000$. You will need to reshape the input to your regression for this to work. </p>\n\n<pre><code>new_size = np.array([2000]).reshape((-1, 1))\nprint(regr.predict(new_size))\n</code></pre>\n\n<blockquote>\n  <p>[ 317.78380528]</p>\n</blockquote>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8530",
            "_score": 8.817097,
            "_source": {
                "title": "Python sklearn - average classification reports",
                "content": "Python sklearn - average classification reports <p>Using Python's sklearn module,</p>\n\n<pre><code> from sklearn.metrics import classification_report\n y1_predict = [0, 1, 1, 0]\n y1_dev = [0, 1, 1, 0]\n report_1 = classification_report(y1_dev, y1_predict)\n y2_predict = [1, 0, 1, 0]\n y2_dev = [1, 1, 0, 0]\n report_2 = classification_report(y2_dev, y2_predict)\n</code></pre>\n\n<p>Is there a way to combine (maybe just an average) <code>report_1</code> and <code>report_2</code> I'm looking for an implementation like:</p>\n\n<pre><code> report_average = average(report_1,report_2)\n</code></pre>\n\n<p>Or does this have to be done manually? I was hoping that printing the <code>report_average</code> would have average values between the two reports.</p>\n\n<p>Here's a MWE of the accepted answer:</p>\n\n<pre><code>    from sklearn.metrics import classification_report\n    import pandas as pd\n    import numpy as np\n    from functools import reduce\n    def report_average(*args):\n        report_list = list()\n        for report in args:\n            splited = [' '.join(x.split()) for x in report.split('\\n\\n')]\n            header = [x for x in splited[0].split(' ')]\n            data = np.array(splited[1].split(' ')).reshape(-1, len(header) + 1)\n            data = np.delete(data, 0, 1).astype(float)\n            avg_total = np.array([x for x in splited[2].split(' ')][3:]).astype(float).reshape(-1, len(header))\n            df = pd.DataFrame(np.concatenate((data, avg_total)), columns=header)\n            report_list.append(df)\n        res = reduce(lambda x, y: x.add(y, fill_value=0), report_list) / len(report_list)\n        return res.rename(index={res.index[-1]: 'avg / total'})\n\n\n    y1_predict = [0, 1, 1, 0]\n    y1_dev = [0, 1, 1, 0]\n    report_1 = classification_report(y1_dev, y1_predict)\n    y2_predict = [1, 0, 1, 0]\n    y2_dev = [1, 1, 0, 0]\n    report_2 = classification_report(y2_dev, y2_predict)\n\n    report_ave = report_average(report_1,report_2)\n\n    print(report_ave)\n</code></pre>\n\n<p>Which yields</p>\n\n<pre><code>             precision  recall  f1-score  support\n0                 0.75    0.75      0.75      2.0\n1                 0.75    0.75      0.75      2.0\navg / total       0.75    0.75      0.75      4.0\n</code></pre>\n <python><scikit-learn><p>It maybe a little bit complicated, since I convert the reports to pandas.DataFrame for calculation. But I think it's worth it, because it works well with two or more report as well. Try below:</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom functools import reduce\ndef report_average(*args):\n    report_list = list()\n    for report in args:\n        splited = [' '.join(x.split()) for x in report.split('\\n\\n')]\n        header = [x for x in splited[0].split(' ')]\n        data = np.array(splited[1].split(' ')).reshape(-1, len(header) + 1)\n        data = np.delete(data, 0, 1).astype(float)\n        avg_total = np.array([x for x in splited[2].split(' ')][3:]).astype(float).reshape(-1, len(header))\n        df = pd.DataFrame(np.concatenate((data, avg_total)), columns=header)\n        report_list.append(df)\n    res = reduce(lambda x, y: x.add(y, fill_value=0), report_list) / len(report_list)\n    return res.rename(index={res.index[-1]: 'avg / total'})\n</code></pre>\n\n<p><strong>output:</strong></p>\n\n<pre><code>report_average  = report_average(report_1, report_2)\nprint(report_average)\n             precision  recall  f1-score  support\n0                 0.75    0.75      0.75      2.0\n1                 0.75    0.75      0.75      2.0\navg / total       0.75    0.75      0.75      4.0\n\nreport_3 = report_2\nreport_average  = report_average(report_1, report_2,report_3)\nprint(report_average)\n             precision    recall  f1-score  support\n0             0.666667  0.666667  0.666667      2.0\n1             0.666667  0.666667  0.666667      2.0\navg / total   0.666667  0.666667  0.666667      4.0\n</code></pre>\n",
                "codes": [
                    [
                        "import pandas as pd\nimport numpy as np\nfrom functools import reduce\ndef report_average(*args):\n    report_list = list()\n    for report in args:\n        splited = [' '.join(x.split()) for x in report.split('\\n\\n')]\n        header = [x for x in splited[0].split(' ')]\n        data = np.array(splited[1].split(' ')).reshape(-1, len(header) + 1)\n        data = np.delete(data, 0, 1).astype(float)\n        avg_total = np.array([x for x in splited[2].split(' ')][3:]).astype(float).reshape(-1, len(header))\n        df = pd.DataFrame(np.concatenate((data, avg_total)), columns=header)\n        report_list.append(df)\n    res = reduce(lambda x, y: x.add(y, fill_value=0), report_list) / len(report_list)\n    return res.rename(index={res.index[-1]: 'avg / total'})\n",
                        "report_average  = report_average(report_1, report_2)\nprint(report_average)\n             precision  recall  f1-score  support\n0                 0.75    0.75      0.75      2.0\n1                 0.75    0.75      0.75      2.0\navg / total       0.75    0.75      0.75      4.0\n\nreport_3 = report_2\nreport_average  = report_average(report_1, report_2,report_3)\nprint(report_average)\n             precision    recall  f1-score  support\n0             0.666667  0.666667  0.666667      2.0\n1             0.666667  0.666667  0.666667      2.0\navg / total   0.666667  0.666667  0.666667      4.0\n"
                    ]
                ],
                "question_id:": "31134",
                "question_votes:": "3",
                "question_text:": "<p>Using Python's sklearn module,</p>\n\n<pre><code> from sklearn.metrics import classification_report\n y1_predict = [0, 1, 1, 0]\n y1_dev = [0, 1, 1, 0]\n report_1 = classification_report(y1_dev, y1_predict)\n y2_predict = [1, 0, 1, 0]\n y2_dev = [1, 1, 0, 0]\n report_2 = classification_report(y2_dev, y2_predict)\n</code></pre>\n\n<p>Is there a way to combine (maybe just an average) <code>report_1</code> and <code>report_2</code> I'm looking for an implementation like:</p>\n\n<pre><code> report_average = average(report_1,report_2)\n</code></pre>\n\n<p>Or does this have to be done manually? I was hoping that printing the <code>report_average</code> would have average values between the two reports.</p>\n\n<p>Here's a MWE of the accepted answer:</p>\n\n<pre><code>    from sklearn.metrics import classification_report\n    import pandas as pd\n    import numpy as np\n    from functools import reduce\n    def report_average(*args):\n        report_list = list()\n        for report in args:\n            splited = [' '.join(x.split()) for x in report.split('\\n\\n')]\n            header = [x for x in splited[0].split(' ')]\n            data = np.array(splited[1].split(' ')).reshape(-1, len(header) + 1)\n            data = np.delete(data, 0, 1).astype(float)\n            avg_total = np.array([x for x in splited[2].split(' ')][3:]).astype(float).reshape(-1, len(header))\n            df = pd.DataFrame(np.concatenate((data, avg_total)), columns=header)\n            report_list.append(df)\n        res = reduce(lambda x, y: x.add(y, fill_value=0), report_list) / len(report_list)\n        return res.rename(index={res.index[-1]: 'avg / total'})\n\n\n    y1_predict = [0, 1, 1, 0]\n    y1_dev = [0, 1, 1, 0]\n    report_1 = classification_report(y1_dev, y1_predict)\n    y2_predict = [1, 0, 1, 0]\n    y2_dev = [1, 1, 0, 0]\n    report_2 = classification_report(y2_dev, y2_predict)\n\n    report_ave = report_average(report_1,report_2)\n\n    print(report_ave)\n</code></pre>\n\n<p>Which yields</p>\n\n<pre><code>             precision  recall  f1-score  support\n0                 0.75    0.75      0.75      2.0\n1                 0.75    0.75      0.75      2.0\navg / total       0.75    0.75      0.75      4.0\n</code></pre>\n",
                "tags": "<python><scikit-learn>",
                "answers": [
                    [
                        "31311",
                        "2",
                        "31134",
                        "",
                        "",
                        "<p>It maybe a little bit complicated, since I convert the reports to pandas.DataFrame for calculation. But I think it's worth it, because it works well with two or more report as well. Try below:</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom functools import reduce\ndef report_average(*args):\n    report_list = list()\n    for report in args:\n        splited = [' '.join(x.split()) for x in report.split('\\n\\n')]\n        header = [x for x in splited[0].split(' ')]\n        data = np.array(splited[1].split(' ')).reshape(-1, len(header) + 1)\n        data = np.delete(data, 0, 1).astype(float)\n        avg_total = np.array([x for x in splited[2].split(' ')][3:]).astype(float).reshape(-1, len(header))\n        df = pd.DataFrame(np.concatenate((data, avg_total)), columns=header)\n        report_list.append(df)\n    res = reduce(lambda x, y: x.add(y, fill_value=0), report_list) / len(report_list)\n    return res.rename(index={res.index[-1]: 'avg / total'})\n</code></pre>\n\n<p><strong>output:</strong></p>\n\n<pre><code>report_average  = report_average(report_1, report_2)\nprint(report_average)\n             precision  recall  f1-score  support\n0                 0.75    0.75      0.75      2.0\n1                 0.75    0.75      0.75      2.0\navg / total       0.75    0.75      0.75      4.0\n\nreport_3 = report_2\nreport_average  = report_average(report_1, report_2,report_3)\nprint(report_average)\n             precision    recall  f1-score  support\n0             0.666667  0.666667  0.666667      2.0\n1             0.666667  0.666667  0.666667      2.0\navg / total   0.666667  0.666667  0.666667      4.0\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7931",
            "_score": 8.795037,
            "_source": {
                "title": "How to sort numbers using Convolutional Neural Network?",
                "content": "How to sort numbers using Convolutional Neural Network? <p>Recently, in an interview I got this question:</p>\n\n<p><em>Design a convnet that sorts numbers. Operators are ReLU, Conv, and Pooling. E.g. input: 5, 3, 6, 2; output: 2, 3, 5, 6</em></p>\n\n<p>I am not sure how can you sort a list of numbers using CNN. I know it is possible using RNN. Is it even possible? </p>\n <deep-learning><convnet><rnn><p>I have a solution however I use a densely connected layer at the output to simplify the reshaping. If you can manipulate the sizes of this model such that you have 4 output parameters this should work as well. </p>\n\n<pre><code>from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv1D, MaxPooling1D, Reshape\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n</code></pre>\n\n<h1>Preparing the data</h1>\n\n<p>We will generate some random lists containing integers between [0,49], we will take a random permutation of the list and then take the first 4 values. We will then set our targets $y$ as the sorted rows of $x$.</p>\n\n<pre><code>import numpy as np\n\nn = 100000\nx_train = np.zeros((n,4))\nfor i in range(n):\n    x_train[i,:] = np.random.permutation(50)[0:4]\n\nx_train = x_train.reshape(n, 4, 1)\ny_train = np.sort(x_train, axis=1).reshape(n, 4,)\n\nn = 1000\nx_test = np.zeros((n,4))\nfor i in range(n):\n    x_test[i,:] = np.random.permutation(50)[0:4]\n\nx_test = x_test.reshape(n, 4, 1)\ny_test = np.sort(x_test, axis=1).reshape(n, 4,)\n\nprint(x_test[0][0].T)\nprint(y_test[0])\n</code></pre>\n\n<blockquote>\n  <p>[ 44.  36.  13.   0.] <br/> [  0.  13.  36.  44.]</p>\n</blockquote>\n\n<h1>The model</h1>\n\n<p>I tried different combinations of parameters. This worked out not bad.</p>\n\n<pre><code>input_shape = (4,1)\n\nmodel = Sequential()\nmodel.add(Conv1D(32, kernel_size=(2),\n                 activation='relu',\n                 input_shape=input_shape,\n                 padding='same'))\n\nmodel.add(Conv1D(64, (2), activation='relu', padding='same'))\nmodel.add(MaxPooling1D(pool_size=(2)))\nmodel.add(Reshape((64,2)))\n\nmodel.add(Conv1D(32, (2), activation='relu', padding='same'))\nmodel.add(MaxPooling1D(pool_size=(2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(4))\n\nmodel.compile(loss=keras.losses.mean_squared_error,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nepochs = 10\nbatch_size = 128\n# Fit the model weights.\nhistory = model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\n</code></pre>\n\n<blockquote>\n  <p>Epoch 10/10 <br/> 100000/100000 [==============================] - 6s\n  56us/step - loss: 0.9061 - acc: 0.9973 - val_loss: 0.5302 - val_acc:\n  0.9950</p>\n</blockquote>\n\n<p><a href=\"https://i.stack.imgur.com/jDHZJ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/jDHZJ.png\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/GWwN0.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/GWwN0.png\" alt=\"enter image description here\"></a></p>\n\n<h1>Results</h1>\n\n<p>So for a new list of values, I get the predicted output. Then I determine which value in the original list is closest to each of these and replace them. I could have just rounded the predicted values, however this caused so +/-1 errors due to rounding the wrong way. </p>\n\n<pre><code>test_list = [1,45,3,18]\npred = model.predict(np.asarray(test_list).reshape(1,4,1))\nprint(test_list)\nprint(pred)\n\nprint([np.asarray(test_list).reshape(4,)[np.abs(np.asarray(test_list).reshape(4,) - i).argmin()] for i in list(pred[0])])\n</code></pre>\n\n<blockquote>\n  <p>[1, 45, 3, 18] <br/> [[  0.87599814   3.43058085  17.36335754  45.21624374]] <br/>\n  [1, 3, 18, 45]</p>\n</blockquote>\n\n<p>And for the sequence you suggested as a test case</p>\n\n<pre><code>test_list = [5,3,6,2]\npred = model.predict(np.asarray(test_list).reshape(1,4,1))\nprint(test_list)\nprint(pred)\n\nprint([np.asarray(test_list).reshape(4,)[np.abs(np.asarray(test_list).reshape(4,) - i).argmin()] for i in list(pred[0])])\n</code></pre>\n\n<blockquote>\n  <p>[5, 3, 6, 2] <br/> [[ 1.85080266  2.95598722  4.92955017  5.88561296]] <br/>[2,\n  3, 5, 6]</p>\n</blockquote>\n",
                "codes": [
                    [
                        "from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv1D, MaxPooling1D, Reshape\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n",
                        "import numpy as np\n\nn = 100000\nx_train = np.zeros((n,4))\nfor i in range(n):\n    x_train[i,:] = np.random.permutation(50)[0:4]\n\nx_train = x_train.reshape(n, 4, 1)\ny_train = np.sort(x_train, axis=1).reshape(n, 4,)\n\nn = 1000\nx_test = np.zeros((n,4))\nfor i in range(n):\n    x_test[i,:] = np.random.permutation(50)[0:4]\n\nx_test = x_test.reshape(n, 4, 1)\ny_test = np.sort(x_test, axis=1).reshape(n, 4,)\n\nprint(x_test[0][0].T)\nprint(y_test[0])\n",
                        "input_shape = (4,1)\n\nmodel = Sequential()\nmodel.add(Conv1D(32, kernel_size=(2),\n                 activation='relu',\n                 input_shape=input_shape,\n                 padding='same'))\n\nmodel.add(Conv1D(64, (2), activation='relu', padding='same'))\nmodel.add(MaxPooling1D(pool_size=(2)))\nmodel.add(Reshape((64,2)))\n\nmodel.add(Conv1D(32, (2), activation='relu', padding='same'))\nmodel.add(MaxPooling1D(pool_size=(2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(4))\n\nmodel.compile(loss=keras.losses.mean_squared_error,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nepochs = 10\nbatch_size = 128\n# Fit the model weights.\nhistory = model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\n",
                        "test_list = [1,45,3,18]\npred = model.predict(np.asarray(test_list).reshape(1,4,1))\nprint(test_list)\nprint(pred)\n\nprint([np.asarray(test_list).reshape(4,)[np.abs(np.asarray(test_list).reshape(4,) - i).argmin()] for i in list(pred[0])])\n",
                        "test_list = [5,3,6,2]\npred = model.predict(np.asarray(test_list).reshape(1,4,1))\nprint(test_list)\nprint(pred)\n\nprint([np.asarray(test_list).reshape(4,)[np.abs(np.asarray(test_list).reshape(4,) - i).argmin()] for i in list(pred[0])])\n"
                    ]
                ],
                "question_id:": "29345",
                "question_votes:": "2",
                "question_text:": "<p>Recently, in an interview I got this question:</p>\n\n<p><em>Design a convnet that sorts numbers. Operators are ReLU, Conv, and Pooling. E.g. input: 5, 3, 6, 2; output: 2, 3, 5, 6</em></p>\n\n<p>I am not sure how can you sort a list of numbers using CNN. I know it is possible using RNN. Is it even possible? </p>\n",
                "tags": "<deep-learning><convnet><rnn>",
                "answers": [
                    [
                        "29351",
                        "2",
                        "29345",
                        "",
                        "",
                        "<p>I have a solution however I use a densely connected layer at the output to simplify the reshaping. If you can manipulate the sizes of this model such that you have 4 output parameters this should work as well. </p>\n\n<pre><code>from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv1D, MaxPooling1D, Reshape\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n</code></pre>\n\n<h1>Preparing the data</h1>\n\n<p>We will generate some random lists containing integers between [0,49], we will take a random permutation of the list and then take the first 4 values. We will then set our targets $y$ as the sorted rows of $x$.</p>\n\n<pre><code>import numpy as np\n\nn = 100000\nx_train = np.zeros((n,4))\nfor i in range(n):\n    x_train[i,:] = np.random.permutation(50)[0:4]\n\nx_train = x_train.reshape(n, 4, 1)\ny_train = np.sort(x_train, axis=1).reshape(n, 4,)\n\nn = 1000\nx_test = np.zeros((n,4))\nfor i in range(n):\n    x_test[i,:] = np.random.permutation(50)[0:4]\n\nx_test = x_test.reshape(n, 4, 1)\ny_test = np.sort(x_test, axis=1).reshape(n, 4,)\n\nprint(x_test[0][0].T)\nprint(y_test[0])\n</code></pre>\n\n<blockquote>\n  <p>[ 44.  36.  13.   0.] <br/> [  0.  13.  36.  44.]</p>\n</blockquote>\n\n<h1>The model</h1>\n\n<p>I tried different combinations of parameters. This worked out not bad.</p>\n\n<pre><code>input_shape = (4,1)\n\nmodel = Sequential()\nmodel.add(Conv1D(32, kernel_size=(2),\n                 activation='relu',\n                 input_shape=input_shape,\n                 padding='same'))\n\nmodel.add(Conv1D(64, (2), activation='relu', padding='same'))\nmodel.add(MaxPooling1D(pool_size=(2)))\nmodel.add(Reshape((64,2)))\n\nmodel.add(Conv1D(32, (2), activation='relu', padding='same'))\nmodel.add(MaxPooling1D(pool_size=(2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(4))\n\nmodel.compile(loss=keras.losses.mean_squared_error,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nepochs = 10\nbatch_size = 128\n# Fit the model weights.\nhistory = model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\n</code></pre>\n\n<blockquote>\n  <p>Epoch 10/10 <br/> 100000/100000 [==============================] - 6s\n  56us/step - loss: 0.9061 - acc: 0.9973 - val_loss: 0.5302 - val_acc:\n  0.9950</p>\n</blockquote>\n\n<p><a href=\"https://i.stack.imgur.com/jDHZJ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/jDHZJ.png\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/GWwN0.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/GWwN0.png\" alt=\"enter image description here\"></a></p>\n\n<h1>Results</h1>\n\n<p>So for a new list of values, I get the predicted output. Then I determine which value in the original list is closest to each of these and replace them. I could have just rounded the predicted values, however this caused so +/-1 errors due to rounding the wrong way. </p>\n\n<pre><code>test_list = [1,45,3,18]\npred = model.predict(np.asarray(test_list).reshape(1,4,1))\nprint(test_list)\nprint(pred)\n\nprint([np.asarray(test_list).reshape(4,)[np.abs(np.asarray(test_list).reshape(4,) - i).argmin()] for i in list(pred[0])])\n</code></pre>\n\n<blockquote>\n  <p>[1, 45, 3, 18] <br/> [[  0.87599814   3.43058085  17.36335754  45.21624374]] <br/>\n  [1, 3, 18, 45]</p>\n</blockquote>\n\n<p>And for the sequence you suggested as a test case</p>\n\n<pre><code>test_list = [5,3,6,2]\npred = model.predict(np.asarray(test_list).reshape(1,4,1))\nprint(test_list)\nprint(pred)\n\nprint([np.asarray(test_list).reshape(4,)[np.abs(np.asarray(test_list).reshape(4,) - i).argmin()] for i in list(pred[0])])\n</code></pre>\n\n<blockquote>\n  <p>[5, 3, 6, 2] <br/> [[ 1.85080266  2.95598722  4.92955017  5.88561296]] <br/>[2,\n  3, 5, 6]</p>\n</blockquote>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14065",
            "_score": 8.775988,
            "_source": {
                "title": "Can a Neural Network Measure the Random Error in a Linear Series?",
                "content": "Can a Neural Network Measure the Random Error in a Linear Series? <p>I have been trying to develop a neural network to measure the error in a linear series. What I would like the model to do is infer a linear regression line and then measure the mean absolute error around that line.</p>\n\n<p>I have tried a number of neural network model configurations, including recurrent configurations, but the network learns a weak relationship and then overfits. I have also tried L1 and L2 regularization but neither work.</p>\n\n<p>Any thoughts? Thanks!</p>\n\n<p>Below is the code I am using to simulate the data and a fit sample model:</p>\n\n<pre><code>import numpy as np, matplotlib.pyplot as plt\n\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.backend import clear_session\n\n## Simulate the data:\n\nnp.random.seed(20190318)\n\nX = np.array(()).reshape(0, 50)\n\nY = np.array(()).reshape(0, 1)\n\nfor _ in range(500):\n\n    i = np.random.randint(100, 110) # Intercept.\n\n    s = np.random.randint(1, 10) # Slope.\n\n    e = np.random.normal(0, 25, 50) # Error.\n\n    X_i = np.round(i + (s * np.arange(0, 50)) + e, 2).reshape(1, 50)\n\n    Y_i = np.sum(np.abs(e)).reshape(1, 1)\n\n    X = np.concatenate((X, X_i), axis = 0)\n\n    Y = np.concatenate((Y, Y_i), axis = 0)\n\n## Training and validation data:\n\nsplit = 400\n\nX_train = X[:split, :-1]\nY_train = Y[:split, -1:]\n\nX_valid = X[split:, :-1]\nY_valid = Y[split:, -1:]\n\nprint(X_train.shape)\nprint(Y_train.shape)\nprint()\nprint(X_valid.shape)\nprint(Y_valid.shape)\n\n## Graph of one of the series:\n\nplt.plot(X_train[0])\n\n## Sample model (takes about a minute to run):\n\nclear_session()\n\nmodel_fnn = Sequential()\nmodel_fnn.add(layers.Dense(512, activation = 'relu', input_shape = (X_train.shape[1],)))\nmodel_fnn.add(layers.Dense(512, activation = 'relu'))\nmodel_fnn.add(layers.Dense(  1, activation = None))\n\n# Compile model.\n\nmodel_fnn.compile(optimizer = Adam(lr = 1e-4), loss = 'mse')\n\n# Fit model.\n\nhistory_fnn = model_fnn.fit(X_train, Y_train, batch_size = 32, epochs = 100, verbose = False,\n    validation_data = (X_valid, Y_valid))\n\n## Sample model learning curves:\n\nloss_fnn = history_fnn.history['loss']\nval_loss_fnn = history_fnn.history['val_loss']\nepochs_fnn = range(1, len(loss_fnn) + 1)\n\nplt.plot(epochs_fnn, loss_fnn, 'black', label = 'Training Loss')\nplt.plot(epochs_fnn, val_loss_fnn, 'red', label = 'Validation Loss')\nplt.title('FNN: Training and Validation Loss')\nplt.legend()\nplt.show()\n</code></pre>\n\n<p>UPDATE:</p>\n\n<pre><code>## Predict.\n\nY_train_fnn = model_fnn.predict(X_train)\nY_valid_fnn = model_fnn.predict(X_valid)\n\n## Evaluate predictions with training data.\n\nplt.scatter(Y_train, Y_train_fnn)\nplt.xlabel(\"Actual\")\nplt.ylabel(\"Predicted\")\n\n## Evaluate predictions with training data.\n\nplt.scatter(Y_valid, Y_valid_fnn)\nplt.xlabel(\"Actual\")\nplt.ylabel(\"Predicted\")\n</code></pre>\n <python><neural-network><keras><linear-regression><p>This problem is naturally hard. The underlying function that we try to learn is\n<span class=\"math-container\">$$\\mathbf{X}=i+s+\\mathbf{e} \\rightarrow Y=\\left \\| \\mathbf{X} - i - s \\right \\|_1 = \\left \\| \\mathbf{e} \\right \\|_1=\\sum_d|e_d|$$</span></p>\n\n<p>where <span class=\"math-container\">$i$</span> and <span class=\"math-container\">$s$</span> are <em>unknown</em> random variables. For large <span class=\"math-container\">$i$</span> and <span class=\"math-container\">$s$</span>, <span class=\"math-container\">$\\left \\| \\mathbf{e} \\right \\|_1$</span> is naturally hard to recover from <span class=\"math-container\">$\\mathbf{X}$</span>. I found a working example (training error <strong>almost zero</strong>) by setting the intercept <span class=\"math-container\">$i$</span> and slope <span class=\"math-container\">$s$</span> to zero!, drastically shrinking the network size to work better with a small sample size (800), and increased the number of epochs to 800, which was crucial. Also, (true value, error) is plotted at the end for training data. </p>\n\n<p>You can work up from this point to see the effect of increasing <span class=\"math-container\">$i$</span> and <span class=\"math-container\">$s$</span> on performance.</p>\n\n<pre><code>import numpy as np, matplotlib.pyplot as plt\n\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.backend import clear_session\n\n## Simulate the data:\n\nnp.random.seed(20190318)\n\ndimension = 50\n\nX = np.array(()).reshape(0, dimension)\n\nY = np.array(()).reshape(0, 1)\n\nfor _ in range(1000):\n\n    i = 0   # np.random.randint(100, 110) # Intercept.\n\n    s = 0   # np.random.randint(1, 10) # Slope.\n\n    e = np.random.normal(0, 25, dimension) # Error.\n\n    X_i = np.round(i + (s * np.arange(0, dimension)) + e, 2).reshape(1, dimension)\n\n    Y_i = np.sum(np.abs(e)).reshape(1, 1)\n\n    X = np.concatenate((X, X_i), axis = 0)\n\n    Y = np.concatenate((Y, Y_i), axis = 0)\n\n## Training and validation data:\n\nsplit = 800\n\nX_train = X[:split, :-1]\nY_train = Y[:split, -1:]\n\nX_valid = X[split:, :-1]\nY_valid = Y[split:, -1:]\n\nprint(X_train.shape)\nprint(Y_train.shape)\nprint()\nprint(X_valid.shape)\nprint(Y_valid.shape)\n\n## Graph of one of the series:\n\nplt.plot(X_train[0])\n\n## Sample model (takes about a minute to run):\n\nclear_session()\n\nmodel_fnn = Sequential()\nmodel_fnn.add(layers.Dense(dimension, activation = 'relu', input_shape = (X_train.shape[1],)))\nmodel_fnn.add(layers.Dense(dimension, activation = 'relu'))\nmodel_fnn.add(layers.Dense(  1, activation = 'linear'))\n\n# Compile model.\n\nmodel_fnn.compile(optimizer = Adam(lr = 1e-4), loss = 'mse')\n\n# Fit model.\n\nhistory_fnn = model_fnn.fit(X_train, Y_train, batch_size = 32, epochs = 800, verbose = True,\n    validation_data = (X_valid, Y_valid))\n\n# Sample model learning curves:\n\nloss_fnn = history_fnn.history['loss']\nval_loss_fnn = history_fnn.history['val_loss']\nepochs_fnn = range(1, len(loss_fnn) + 1)\n\nplt.figure(1)\noffset = 5\nplt.plot(epochs_fnn[offset:], loss_fnn[offset:], 'black', label = 'Training Loss')\nplt.plot(epochs_fnn[offset:], val_loss_fnn[offset:], 'red', label = 'Validation Loss')\nplt.title('FNN: Training and Validation Loss')\nplt.legend()\n\n## Predict.\n\nplt.figure(2)\n\nY_train_fnn = model_fnn.predict(X_train)\n\n## Evaluate predictions with training data.\nsorted_index = Y_train.argsort(axis=0)\nY_train_sorted = np.reshape(Y_train[sorted_index], (-1, 1))\nY_train_fnn_sorted = np.reshape(Y_train_fnn[sorted_index], (-1, 1))\nplt.plot(Y_train_sorted, Y_train_sorted - Y_train_fnn_sorted)\nplt.xlabel(\"Y(true) train\")\nplt.ylabel(\"Y(true) - Y(predicted) train\")\nplt.show()\n</code></pre>\n",
                "codes": [
                    [
                        "import numpy as np, matplotlib.pyplot as plt\n\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.backend import clear_session\n\n## Simulate the data:\n\nnp.random.seed(20190318)\n\ndimension = 50\n\nX = np.array(()).reshape(0, dimension)\n\nY = np.array(()).reshape(0, 1)\n\nfor _ in range(1000):\n\n    i = 0   # np.random.randint(100, 110) # Intercept.\n\n    s = 0   # np.random.randint(1, 10) # Slope.\n\n    e = np.random.normal(0, 25, dimension) # Error.\n\n    X_i = np.round(i + (s * np.arange(0, dimension)) + e, 2).reshape(1, dimension)\n\n    Y_i = np.sum(np.abs(e)).reshape(1, 1)\n\n    X = np.concatenate((X, X_i), axis = 0)\n\n    Y = np.concatenate((Y, Y_i), axis = 0)\n\n## Training and validation data:\n\nsplit = 800\n\nX_train = X[:split, :-1]\nY_train = Y[:split, -1:]\n\nX_valid = X[split:, :-1]\nY_valid = Y[split:, -1:]\n\nprint(X_train.shape)\nprint(Y_train.shape)\nprint()\nprint(X_valid.shape)\nprint(Y_valid.shape)\n\n## Graph of one of the series:\n\nplt.plot(X_train[0])\n\n## Sample model (takes about a minute to run):\n\nclear_session()\n\nmodel_fnn = Sequential()\nmodel_fnn.add(layers.Dense(dimension, activation = 'relu', input_shape = (X_train.shape[1],)))\nmodel_fnn.add(layers.Dense(dimension, activation = 'relu'))\nmodel_fnn.add(layers.Dense(  1, activation = 'linear'))\n\n# Compile model.\n\nmodel_fnn.compile(optimizer = Adam(lr = 1e-4), loss = 'mse')\n\n# Fit model.\n\nhistory_fnn = model_fnn.fit(X_train, Y_train, batch_size = 32, epochs = 800, verbose = True,\n    validation_data = (X_valid, Y_valid))\n\n# Sample model learning curves:\n\nloss_fnn = history_fnn.history['loss']\nval_loss_fnn = history_fnn.history['val_loss']\nepochs_fnn = range(1, len(loss_fnn) + 1)\n\nplt.figure(1)\noffset = 5\nplt.plot(epochs_fnn[offset:], loss_fnn[offset:], 'black', label = 'Training Loss')\nplt.plot(epochs_fnn[offset:], val_loss_fnn[offset:], 'red', label = 'Validation Loss')\nplt.title('FNN: Training and Validation Loss')\nplt.legend()\n\n## Predict.\n\nplt.figure(2)\n\nY_train_fnn = model_fnn.predict(X_train)\n\n## Evaluate predictions with training data.\nsorted_index = Y_train.argsort(axis=0)\nY_train_sorted = np.reshape(Y_train[sorted_index], (-1, 1))\nY_train_fnn_sorted = np.reshape(Y_train_fnn[sorted_index], (-1, 1))\nplt.plot(Y_train_sorted, Y_train_sorted - Y_train_fnn_sorted)\nplt.xlabel(\"Y(true) train\")\nplt.ylabel(\"Y(true) - Y(predicted) train\")\nplt.show()\n"
                    ]
                ],
                "question_id:": "47550",
                "question_votes:": "",
                "question_text:": "<p>I have been trying to develop a neural network to measure the error in a linear series. What I would like the model to do is infer a linear regression line and then measure the mean absolute error around that line.</p>\n\n<p>I have tried a number of neural network model configurations, including recurrent configurations, but the network learns a weak relationship and then overfits. I have also tried L1 and L2 regularization but neither work.</p>\n\n<p>Any thoughts? Thanks!</p>\n\n<p>Below is the code I am using to simulate the data and a fit sample model:</p>\n\n<pre><code>import numpy as np, matplotlib.pyplot as plt\n\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.backend import clear_session\n\n## Simulate the data:\n\nnp.random.seed(20190318)\n\nX = np.array(()).reshape(0, 50)\n\nY = np.array(()).reshape(0, 1)\n\nfor _ in range(500):\n\n    i = np.random.randint(100, 110) # Intercept.\n\n    s = np.random.randint(1, 10) # Slope.\n\n    e = np.random.normal(0, 25, 50) # Error.\n\n    X_i = np.round(i + (s * np.arange(0, 50)) + e, 2).reshape(1, 50)\n\n    Y_i = np.sum(np.abs(e)).reshape(1, 1)\n\n    X = np.concatenate((X, X_i), axis = 0)\n\n    Y = np.concatenate((Y, Y_i), axis = 0)\n\n## Training and validation data:\n\nsplit = 400\n\nX_train = X[:split, :-1]\nY_train = Y[:split, -1:]\n\nX_valid = X[split:, :-1]\nY_valid = Y[split:, -1:]\n\nprint(X_train.shape)\nprint(Y_train.shape)\nprint()\nprint(X_valid.shape)\nprint(Y_valid.shape)\n\n## Graph of one of the series:\n\nplt.plot(X_train[0])\n\n## Sample model (takes about a minute to run):\n\nclear_session()\n\nmodel_fnn = Sequential()\nmodel_fnn.add(layers.Dense(512, activation = 'relu', input_shape = (X_train.shape[1],)))\nmodel_fnn.add(layers.Dense(512, activation = 'relu'))\nmodel_fnn.add(layers.Dense(  1, activation = None))\n\n# Compile model.\n\nmodel_fnn.compile(optimizer = Adam(lr = 1e-4), loss = 'mse')\n\n# Fit model.\n\nhistory_fnn = model_fnn.fit(X_train, Y_train, batch_size = 32, epochs = 100, verbose = False,\n    validation_data = (X_valid, Y_valid))\n\n## Sample model learning curves:\n\nloss_fnn = history_fnn.history['loss']\nval_loss_fnn = history_fnn.history['val_loss']\nepochs_fnn = range(1, len(loss_fnn) + 1)\n\nplt.plot(epochs_fnn, loss_fnn, 'black', label = 'Training Loss')\nplt.plot(epochs_fnn, val_loss_fnn, 'red', label = 'Validation Loss')\nplt.title('FNN: Training and Validation Loss')\nplt.legend()\nplt.show()\n</code></pre>\n\n<p>UPDATE:</p>\n\n<pre><code>## Predict.\n\nY_train_fnn = model_fnn.predict(X_train)\nY_valid_fnn = model_fnn.predict(X_valid)\n\n## Evaluate predictions with training data.\n\nplt.scatter(Y_train, Y_train_fnn)\nplt.xlabel(\"Actual\")\nplt.ylabel(\"Predicted\")\n\n## Evaluate predictions with training data.\n\nplt.scatter(Y_valid, Y_valid_fnn)\nplt.xlabel(\"Actual\")\nplt.ylabel(\"Predicted\")\n</code></pre>\n",
                "tags": "<python><neural-network><keras><linear-regression>",
                "answers": [
                    [
                        "47555",
                        "2",
                        "47550",
                        "",
                        "",
                        "<p>This problem is naturally hard. The underlying function that we try to learn is\n<span class=\"math-container\">$$\\mathbf{X}=i+s+\\mathbf{e} \\rightarrow Y=\\left \\| \\mathbf{X} - i - s \\right \\|_1 = \\left \\| \\mathbf{e} \\right \\|_1=\\sum_d|e_d|$$</span></p>\n\n<p>where <span class=\"math-container\">$i$</span> and <span class=\"math-container\">$s$</span> are <em>unknown</em> random variables. For large <span class=\"math-container\">$i$</span> and <span class=\"math-container\">$s$</span>, <span class=\"math-container\">$\\left \\| \\mathbf{e} \\right \\|_1$</span> is naturally hard to recover from <span class=\"math-container\">$\\mathbf{X}$</span>. I found a working example (training error <strong>almost zero</strong>) by setting the intercept <span class=\"math-container\">$i$</span> and slope <span class=\"math-container\">$s$</span> to zero!, drastically shrinking the network size to work better with a small sample size (800), and increased the number of epochs to 800, which was crucial. Also, (true value, error) is plotted at the end for training data. </p>\n\n<p>You can work up from this point to see the effect of increasing <span class=\"math-container\">$i$</span> and <span class=\"math-container\">$s$</span> on performance.</p>\n\n<pre><code>import numpy as np, matplotlib.pyplot as plt\n\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.backend import clear_session\n\n## Simulate the data:\n\nnp.random.seed(20190318)\n\ndimension = 50\n\nX = np.array(()).reshape(0, dimension)\n\nY = np.array(()).reshape(0, 1)\n\nfor _ in range(1000):\n\n    i = 0   # np.random.randint(100, 110) # Intercept.\n\n    s = 0   # np.random.randint(1, 10) # Slope.\n\n    e = np.random.normal(0, 25, dimension) # Error.\n\n    X_i = np.round(i + (s * np.arange(0, dimension)) + e, 2).reshape(1, dimension)\n\n    Y_i = np.sum(np.abs(e)).reshape(1, 1)\n\n    X = np.concatenate((X, X_i), axis = 0)\n\n    Y = np.concatenate((Y, Y_i), axis = 0)\n\n## Training and validation data:\n\nsplit = 800\n\nX_train = X[:split, :-1]\nY_train = Y[:split, -1:]\n\nX_valid = X[split:, :-1]\nY_valid = Y[split:, -1:]\n\nprint(X_train.shape)\nprint(Y_train.shape)\nprint()\nprint(X_valid.shape)\nprint(Y_valid.shape)\n\n## Graph of one of the series:\n\nplt.plot(X_train[0])\n\n## Sample model (takes about a minute to run):\n\nclear_session()\n\nmodel_fnn = Sequential()\nmodel_fnn.add(layers.Dense(dimension, activation = 'relu', input_shape = (X_train.shape[1],)))\nmodel_fnn.add(layers.Dense(dimension, activation = 'relu'))\nmodel_fnn.add(layers.Dense(  1, activation = 'linear'))\n\n# Compile model.\n\nmodel_fnn.compile(optimizer = Adam(lr = 1e-4), loss = 'mse')\n\n# Fit model.\n\nhistory_fnn = model_fnn.fit(X_train, Y_train, batch_size = 32, epochs = 800, verbose = True,\n    validation_data = (X_valid, Y_valid))\n\n# Sample model learning curves:\n\nloss_fnn = history_fnn.history['loss']\nval_loss_fnn = history_fnn.history['val_loss']\nepochs_fnn = range(1, len(loss_fnn) + 1)\n\nplt.figure(1)\noffset = 5\nplt.plot(epochs_fnn[offset:], loss_fnn[offset:], 'black', label = 'Training Loss')\nplt.plot(epochs_fnn[offset:], val_loss_fnn[offset:], 'red', label = 'Validation Loss')\nplt.title('FNN: Training and Validation Loss')\nplt.legend()\n\n## Predict.\n\nplt.figure(2)\n\nY_train_fnn = model_fnn.predict(X_train)\n\n## Evaluate predictions with training data.\nsorted_index = Y_train.argsort(axis=0)\nY_train_sorted = np.reshape(Y_train[sorted_index], (-1, 1))\nY_train_fnn_sorted = np.reshape(Y_train_fnn[sorted_index], (-1, 1))\nplt.plot(Y_train_sorted, Y_train_sorted - Y_train_fnn_sorted)\nplt.xlabel(\"Y(true) train\")\nplt.ylabel(\"Y(true) - Y(predicted) train\")\nplt.show()\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8541",
            "_score": 8.767307,
            "_source": {
                "title": "how to predict an image using saved model",
                "content": "how to predict an image using saved model <pre><code>from keras import optimizers\nfrom keras.models import load_model\nfrom keras.preprocessing import image\nimport numpy as np\nimport cv2\nimport scipy.misc\nfrom keras.wrappers.scikit_learn import KerasClassifier\n# dimensions of our images\nimg_width, img_height = 313, 220\n# load the model we saved\nmodel = load_model('model.h5')\nsgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy','mse'])\ntest_image= image.load_img('/Images/1.jpg',target_size = (img_width, img_height))\n#x= scipy.misc.imread('/Images/1.jpg').shape\ntest_image = image.img_to_array(test_image)\nprint test_image\ntest_image = np.expand_dims(test_image, axis = 0)\ntest_image = test_image.reshape(img_width, img_height*3)\nresult = model.predict(test_image)\nprint result\n</code></pre>\n\n<p>When I ran the above code I get this error: </p>\n\n<blockquote>\n  <p>ValueError: Error when checking : expected dense_1_input to have shape (36,) but got array with shape (660,)</p>\n</blockquote>\n <machine-learning><python><keras><p>Having problems with dimensions is very common. As others have mentioned, the method <code>predict</code> expects to get a batch of images. You should run <code>model.summary()</code> to see what the expected dimensions of the input are. The batch size itself might have been designed to be flexible during training, by specifying <code>None</code> in the first dimension on the model <code>input_shape</code> parameter.</p>\n\n<p>Without knowing more of the dimensions, I cannot say exactly where your problems lies. You could include that information by editing your question.</p>\n\n<hr>\n\n<p>It will likely help to have a look at the <a href=\"https://keras.io/models/sequential/#predict\" rel=\"nofollow noreferrer\">documentation</a> for predict function of the model objects.</p>\n\n<p>There is an argument: <code>batch_size</code>, which defaults to <strong>32</strong> if not fixed by the model itself, which you can see from the <code>model.summary()</code>. If you set this equal to 1, perhaps you will get a prediction.</p>\n\n<p>Below is a modified version of your code that I would expect to return a prediction.</p>\n\n<pre><code>from keras.models import load_model\nfrom keras.preprocessing import image\nimport numpy as np\n\n# dimensions of our images    -----   are these then grayscale (black and white)?\nimg_width, img_height = 313, 220\n\n# load the model we saved\nmodel = load_model('model.h5')\n\n# Get test image ready\ntest_image = image.load_img('/Images/1.jpg', target_size=(img_width, img_height))\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis=0)\n\ntest_image = test_image.reshape(img_width, img_height*3)    # Ambiguity!\n# Should this instead be: test_image.reshape(img_width, img_height, 3) ??\n\nresult = model.predict(test_image, batch_size=1)\nprint result\n</code></pre>\n\n<p><strong>Note</strong>: there is ambiguity in the dimensions where I highlight it. A colour image will have three dimensions: (height, width, 3). Black and white will have only two dimensions: (height, width).</p>\n",
                "codes": [
                    [
                        "from keras.models import load_model\nfrom keras.preprocessing import image\nimport numpy as np\n\n# dimensions of our images    -----   are these then grayscale (black and white)?\nimg_width, img_height = 313, 220\n\n# load the model we saved\nmodel = load_model('model.h5')\n\n# Get test image ready\ntest_image = image.load_img('/Images/1.jpg', target_size=(img_width, img_height))\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis=0)\n\ntest_image = test_image.reshape(img_width, img_height*3)    # Ambiguity!\n# Should this instead be: test_image.reshape(img_width, img_height, 3) ??\n\nresult = model.predict(test_image, batch_size=1)\nprint result\n"
                    ]
                ],
                "question_id:": "31167",
                "question_votes:": "1",
                "question_text:": "<pre><code>from keras import optimizers\nfrom keras.models import load_model\nfrom keras.preprocessing import image\nimport numpy as np\nimport cv2\nimport scipy.misc\nfrom keras.wrappers.scikit_learn import KerasClassifier\n# dimensions of our images\nimg_width, img_height = 313, 220\n# load the model we saved\nmodel = load_model('model.h5')\nsgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy','mse'])\ntest_image= image.load_img('/Images/1.jpg',target_size = (img_width, img_height))\n#x= scipy.misc.imread('/Images/1.jpg').shape\ntest_image = image.img_to_array(test_image)\nprint test_image\ntest_image = np.expand_dims(test_image, axis = 0)\ntest_image = test_image.reshape(img_width, img_height*3)\nresult = model.predict(test_image)\nprint result\n</code></pre>\n\n<p>When I ran the above code I get this error: </p>\n\n<blockquote>\n  <p>ValueError: Error when checking : expected dense_1_input to have shape (36,) but got array with shape (660,)</p>\n</blockquote>\n",
                "tags": "<machine-learning><python><keras>",
                "answers": [
                    [
                        "31189",
                        "2",
                        "31167",
                        "",
                        "",
                        "<p>Having problems with dimensions is very common. As others have mentioned, the method <code>predict</code> expects to get a batch of images. You should run <code>model.summary()</code> to see what the expected dimensions of the input are. The batch size itself might have been designed to be flexible during training, by specifying <code>None</code> in the first dimension on the model <code>input_shape</code> parameter.</p>\n\n<p>Without knowing more of the dimensions, I cannot say exactly where your problems lies. You could include that information by editing your question.</p>\n\n<hr>\n\n<p>It will likely help to have a look at the <a href=\"https://keras.io/models/sequential/#predict\" rel=\"nofollow noreferrer\">documentation</a> for predict function of the model objects.</p>\n\n<p>There is an argument: <code>batch_size</code>, which defaults to <strong>32</strong> if not fixed by the model itself, which you can see from the <code>model.summary()</code>. If you set this equal to 1, perhaps you will get a prediction.</p>\n\n<p>Below is a modified version of your code that I would expect to return a prediction.</p>\n\n<pre><code>from keras.models import load_model\nfrom keras.preprocessing import image\nimport numpy as np\n\n# dimensions of our images    -----   are these then grayscale (black and white)?\nimg_width, img_height = 313, 220\n\n# load the model we saved\nmodel = load_model('model.h5')\n\n# Get test image ready\ntest_image = image.load_img('/Images/1.jpg', target_size=(img_width, img_height))\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis=0)\n\ntest_image = test_image.reshape(img_width, img_height*3)    # Ambiguity!\n# Should this instead be: test_image.reshape(img_width, img_height, 3) ??\n\nresult = model.predict(test_image, batch_size=1)\nprint result\n</code></pre>\n\n<p><strong>Note</strong>: there is ambiguity in the dimensions where I highlight it. A colour image will have three dimensions: (height, width, 3). Black and white will have only two dimensions: (height, width).</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10205",
            "_score": 8.745573,
            "_source": {
                "title": "Plotting in Multiple Linear Regression in Python 3",
                "content": "Plotting in Multiple Linear Regression in Python 3 <p>So I'm working on linear regression. So far I've managed to plot in linear regression, but currently I'm on Multiple Linear Regression and I couldn't manage to plot it, I can get some results if I enter the values manually, but I couldn't manage to plot it. Below is my code block and dataset and error, what can i change to plot it?</p>\n\n<p>Dataset: </p>\n\n<pre><code>deneyim maas    yas\n0.5 2500    22\n0   2250    21\n1   2750    23\n5   8000    25\n8   9000    28\n4   6900    23\n15  20000   35\n7   8500    29\n3   6000    22\n2   3500    23\n12  15000   32\n10  13000   30\n14  18000   34\n6   7500    27\n</code></pre>\n\n<p>Code block:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndataset = pd.read_csv(\"multiple-linear-regression-dataset.csv\",sep = \";\")\n\nx = dataset.iloc[:,[0,2]].values\ny = dataset.maas.values.reshape(-1,1)\n\nmultiple_lr = LinearRegression()\nmultiple_lr.fit(x,y)\n\nb0 = multiple_lr.intercept_\nb1 = multiple_lr.coef_\nb2 = b1\n\nmultiple_lr.predict(np.array([[10,35],[5,35]]))\n\narray = np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]).reshape(-1,1)\ny_head = multiple_lr.predict(array)\n\nplt.scatter(x,y)\nplt.plot(array, y_head, color = \"red\")\nplt.show()\n</code></pre>\n\n<p>It says <code>ValueError: shapes (16,1) and (2,1) not aligned: 1 (dim 1) != 2 (dim 0)</code> when I try to compile it.</p>\n <machine-learning><python><numpy><matplotlib><p>You cannot plot graph for multiple regression like that. Multiple regression yields graph with many dimensions. The dimension of the graph increases as your features increases. In your case, X has two features. Scatter plot takes argument with only one feature in X and only one class in y.Try taking only one feature for X and plot a scatter plot. By doing so you will be able to study the effect of each feature on the dependent variable (which i think is more easy to comprehend than multidimensional plots).I think your issue should resolve.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "36874",
                "question_votes:": "3",
                "question_text:": "<p>So I'm working on linear regression. So far I've managed to plot in linear regression, but currently I'm on Multiple Linear Regression and I couldn't manage to plot it, I can get some results if I enter the values manually, but I couldn't manage to plot it. Below is my code block and dataset and error, what can i change to plot it?</p>\n\n<p>Dataset: </p>\n\n<pre><code>deneyim maas    yas\n0.5 2500    22\n0   2250    21\n1   2750    23\n5   8000    25\n8   9000    28\n4   6900    23\n15  20000   35\n7   8500    29\n3   6000    22\n2   3500    23\n12  15000   32\n10  13000   30\n14  18000   34\n6   7500    27\n</code></pre>\n\n<p>Code block:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndataset = pd.read_csv(\"multiple-linear-regression-dataset.csv\",sep = \";\")\n\nx = dataset.iloc[:,[0,2]].values\ny = dataset.maas.values.reshape(-1,1)\n\nmultiple_lr = LinearRegression()\nmultiple_lr.fit(x,y)\n\nb0 = multiple_lr.intercept_\nb1 = multiple_lr.coef_\nb2 = b1\n\nmultiple_lr.predict(np.array([[10,35],[5,35]]))\n\narray = np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]).reshape(-1,1)\ny_head = multiple_lr.predict(array)\n\nplt.scatter(x,y)\nplt.plot(array, y_head, color = \"red\")\nplt.show()\n</code></pre>\n\n<p>It says <code>ValueError: shapes (16,1) and (2,1) not aligned: 1 (dim 1) != 2 (dim 0)</code> when I try to compile it.</p>\n",
                "tags": "<machine-learning><python><numpy><matplotlib>",
                "answers": [
                    [
                        "36887",
                        "2",
                        "36874",
                        "",
                        "",
                        "<p>You cannot plot graph for multiple regression like that. Multiple regression yields graph with many dimensions. The dimension of the graph increases as your features increases. In your case, X has two features. Scatter plot takes argument with only one feature in X and only one class in y.Try taking only one feature for X and plot a scatter plot. By doing so you will be able to study the effect of each feature on the dependent variable (which i think is more easy to comprehend than multidimensional plots).I think your issue should resolve.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17936",
            "_score": 8.741512,
            "_source": {
                "title": "I am trying to replace a nan value in my dataset using numpy or imputer class, but am unable to do so!",
                "content": "I am trying to replace a nan value in my dataset using numpy or imputer class, but am unable to do so! <pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n#importing dataset\ntrain = pd.read_csv(\"train.csv\")\ntest = pd.read_csv(\"test.csv\")\ntrain_X = train.iloc[:, :-1].values\ntrain_Y = train.iloc[:,1].values\ntest_X = test.iloc[:, :-1].values\ntest_Y = test.iloc[:,1].values\n\n\n#getting column names in dataset\n\nnp.isnan(train_Y).sum()\nnp.where(np.isnan(train_Y))\nnp.nan_to_num(train_Y)\ntrain_Y.reshape(-1,1)\n#replace null values\nfrom sklearn.preprocessing import Imputer\nimputer = Imputer(missing_values = 0,strategy = \"mean\", axis = 0)\nimputer = imputer.fit(train_Y)\ntrain_Y = imputer.transform(train_Y)\n\n\n#plotting train dataset\nplt.scatter(train['x'],train['y'], color = \"red\")\n\n#madelling the train dataset\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression()\nreg.fit(train_X,train_Y)\n\n# predicting test dataset\ny_pred = reg.predict(test_X)\n</code></pre>\n\n<p>I am not getting any errors but just that the nan value is not getting replaced.\nThanks in advance!</p>\n <machine-learning><linear-regression>",
                "codes": [],
                "question_id:": "57328",
                "question_votes:": "",
                "question_text:": "<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n#importing dataset\ntrain = pd.read_csv(\"train.csv\")\ntest = pd.read_csv(\"test.csv\")\ntrain_X = train.iloc[:, :-1].values\ntrain_Y = train.iloc[:,1].values\ntest_X = test.iloc[:, :-1].values\ntest_Y = test.iloc[:,1].values\n\n\n#getting column names in dataset\n\nnp.isnan(train_Y).sum()\nnp.where(np.isnan(train_Y))\nnp.nan_to_num(train_Y)\ntrain_Y.reshape(-1,1)\n#replace null values\nfrom sklearn.preprocessing import Imputer\nimputer = Imputer(missing_values = 0,strategy = \"mean\", axis = 0)\nimputer = imputer.fit(train_Y)\ntrain_Y = imputer.transform(train_Y)\n\n\n#plotting train dataset\nplt.scatter(train['x'],train['y'], color = \"red\")\n\n#madelling the train dataset\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression()\nreg.fit(train_X,train_Y)\n\n# predicting test dataset\ny_pred = reg.predict(test_X)\n</code></pre>\n\n<p>I am not getting any errors but just that the nan value is not getting replaced.\nThanks in advance!</p>\n",
                "tags": "<machine-learning><linear-regression>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4087",
            "_score": 8.719034,
            "_source": {
                "title": "Shape Error in Tensorflow",
                "content": "Shape Error in Tensorflow <p>I am just trying to assign value to a placeholder but i m am getting error:Cannot feed value of shape () for Tensor 'image_input_22:0', which has shape '(1, 51, 51, 64)'</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\nres=np.random.random([1,51,51,64])\nimage=tf.placeholder(tf.float32,shape=[1,51,51,64],name=\"image_input\")\nreshaped_image=tf.reshape(image,[1,51,51,64])\ninit=tf.global_variables_initializer()\nres=0\nwith tf.Session() as sess:\n sess.run(init)\n res=sess.run(reshaped_image,feed_dict={image:res})\n</code></pre>\n <python><neural-network><tensorflow><p>You reinitialized res to 0, which is a scalar, hence the error. </p>\n",
                "codes": [
                    []
                ],
                "question_id:": "16676",
                "question_votes:": "",
                "question_text:": "<p>I am just trying to assign value to a placeholder but i m am getting error:Cannot feed value of shape () for Tensor 'image_input_22:0', which has shape '(1, 51, 51, 64)'</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\nres=np.random.random([1,51,51,64])\nimage=tf.placeholder(tf.float32,shape=[1,51,51,64],name=\"image_input\")\nreshaped_image=tf.reshape(image,[1,51,51,64])\ninit=tf.global_variables_initializer()\nres=0\nwith tf.Session() as sess:\n sess.run(init)\n res=sess.run(reshaped_image,feed_dict={image:res})\n</code></pre>\n",
                "tags": "<python><neural-network><tensorflow>",
                "answers": [
                    [
                        "16677",
                        "2",
                        "16676",
                        "",
                        "",
                        "<p>You reinitialized res to 0, which is a scalar, hence the error. </p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13279",
            "_score": 8.694864,
            "_source": {
                "title": "How to add three csv file into one LSTM using python",
                "content": "How to add three csv file into one LSTM using python <p>I have three csv files with same inputs but values are different. I want to add these three csv file into one  LSTM model  to predict value. Hare I upload the three different csv file and my LSTM code. Can anyone suggest me an idea how to add  that three csv file data into the LSTM model.\nmy code:</p>\n\n<pre><code> import pandas as pd\nimport numpy as np\ndata = pd.read_csv('data1.csv')\ndata = pd.DataFrame(data,columns=['x','x1','x2','y'])\ndata.columns = ['x', 'x1', 'x2','y']\npd.options.display.float_format = '{:,.0f}'.format\ndata = data.dropna ()\nd = ['y']\ny=data['y'].astype(int)\ncols=['x', 'x1', 'x2']\nx=data[cols].astype(int)\nscaler_x = preprocessing.MinMaxScaler(feature_range =(-1, 1))\nx = np.array(x).reshape ((len(x),3 ))\nx = scaler_x.fit_transform(x)\nscaler_y = preprocessing.MinMaxScaler(feature_range =(-1, 1))\ny = np.array(y).reshape ((len(y), 1))\ny = scaler_y.fit_transform(y)\nprint(\"row\",len(y))\nn = data.shape[0]\np = data.shape[1]\nfill_missing(data.values)\ntrain_start = 0\ntrain_end = int(np.floor(0.65*n))\ntest_start = train_end+1 \ntest_end = n\nx_train = x[np.arange(train_start, train_end), :]\nx_test = x[np.arange(test_start, test_end), :]\ny_train = y[np.arange(train_start, train_end), :]\ny_test = y[np.arange(test_start, test_end), :]\nx_train=x_train.reshape(x_train.shape +(1,))\nx_test=x_test.reshape(x_test.shape + (1,))\nseed = 20\nnp.random.seed(seed)\nfit1 = Sequential ()\nfit1.add(LSTM(\noutput_dim = 10,\nactivation='relu',\ninput_shape =(3,1)))\nfit1.add(Dense(output_dim =1))\nfit1.add(Activation(linear))\nbatchsize = 10\nfit1.compile(loss=\"mean_squared_error\",optimizer=\"adam\")\nfit1.fit(x_train , y_train , batch_size = batchsize, nb_epoch =10,   shuffle=True)\nprint(fit1.summary ())\npred1=fit1.predict(x_test)\npred1=fit1.predict(x_test)\nreal_test = scaler_y.inverse_transform(np.array(y_test).reshape ((len(y_test), 1))).astype(int)\n</code></pre>\n\n<p>my three csv file :\ndata1.csv</p>\n\n<p><a href=\"https://i.stack.imgur.com/vIJio.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/vIJio.png\" alt=\"enter image description here\"></a></p>\n\n<p>data2.csv :</p>\n\n<p><a href=\"https://i.stack.imgur.com/M6fEj.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/M6fEj.png\" alt=\"enter image description here\"></a></p>\n\n<p>data3.csv :</p>\n\n<p><a href=\"https://i.stack.imgur.com/3E5pW.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/3E5pW.png\" alt=\"enter image description here\"></a></p>\n <python><keras><tensorflow><lstm>",
                "codes": [],
                "question_id:": "45604",
                "question_votes:": "1",
                "question_text:": "<p>I have three csv files with same inputs but values are different. I want to add these three csv file into one  LSTM model  to predict value. Hare I upload the three different csv file and my LSTM code. Can anyone suggest me an idea how to add  that three csv file data into the LSTM model.\nmy code:</p>\n\n<pre><code> import pandas as pd\nimport numpy as np\ndata = pd.read_csv('data1.csv')\ndata = pd.DataFrame(data,columns=['x','x1','x2','y'])\ndata.columns = ['x', 'x1', 'x2','y']\npd.options.display.float_format = '{:,.0f}'.format\ndata = data.dropna ()\nd = ['y']\ny=data['y'].astype(int)\ncols=['x', 'x1', 'x2']\nx=data[cols].astype(int)\nscaler_x = preprocessing.MinMaxScaler(feature_range =(-1, 1))\nx = np.array(x).reshape ((len(x),3 ))\nx = scaler_x.fit_transform(x)\nscaler_y = preprocessing.MinMaxScaler(feature_range =(-1, 1))\ny = np.array(y).reshape ((len(y), 1))\ny = scaler_y.fit_transform(y)\nprint(\"row\",len(y))\nn = data.shape[0]\np = data.shape[1]\nfill_missing(data.values)\ntrain_start = 0\ntrain_end = int(np.floor(0.65*n))\ntest_start = train_end+1 \ntest_end = n\nx_train = x[np.arange(train_start, train_end), :]\nx_test = x[np.arange(test_start, test_end), :]\ny_train = y[np.arange(train_start, train_end), :]\ny_test = y[np.arange(test_start, test_end), :]\nx_train=x_train.reshape(x_train.shape +(1,))\nx_test=x_test.reshape(x_test.shape + (1,))\nseed = 20\nnp.random.seed(seed)\nfit1 = Sequential ()\nfit1.add(LSTM(\noutput_dim = 10,\nactivation='relu',\ninput_shape =(3,1)))\nfit1.add(Dense(output_dim =1))\nfit1.add(Activation(linear))\nbatchsize = 10\nfit1.compile(loss=\"mean_squared_error\",optimizer=\"adam\")\nfit1.fit(x_train , y_train , batch_size = batchsize, nb_epoch =10,   shuffle=True)\nprint(fit1.summary ())\npred1=fit1.predict(x_test)\npred1=fit1.predict(x_test)\nreal_test = scaler_y.inverse_transform(np.array(y_test).reshape ((len(y_test), 1))).astype(int)\n</code></pre>\n\n<p>my three csv file :\ndata1.csv</p>\n\n<p><a href=\"https://i.stack.imgur.com/vIJio.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/vIJio.png\" alt=\"enter image description here\"></a></p>\n\n<p>data2.csv :</p>\n\n<p><a href=\"https://i.stack.imgur.com/M6fEj.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/M6fEj.png\" alt=\"enter image description here\"></a></p>\n\n<p>data3.csv :</p>\n\n<p><a href=\"https://i.stack.imgur.com/3E5pW.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/3E5pW.png\" alt=\"enter image description here\"></a></p>\n",
                "tags": "<python><keras><tensorflow><lstm>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15889",
            "_score": 8.694864,
            "_source": {
                "title": "ValueError: Expected 2D array, got scalar array instead using predict method",
                "content": "ValueError: Expected 2D array, got scalar array instead using predict method <p>I am trying to get a predicted value instead of whole features for a particular level using predict method.    </p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n#Importing Dataset\ndataset = pd.read_csv('C:/Users/Rupali Singh/Desktop/ML A-Z/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 7 - Support Vector Regression (SVR)/Position_Salaries.csv')\nprint(dataset)\nX = dataset.iloc[:, 1:2].values\nY = dataset.iloc[:, 2].values\n\n# Feature Scaling\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc_X = StandardScaler()\nsc_Y = StandardScaler()\nX = sc_X.fit_transform(X)\nY = sc_Y.fit_transform(Y.reshape(-1,1))\n#Fitting SVR model to dataset\n\nfrom sklearn.svm import SVR\n\nregressor = SVR(kernel='rbf')\nregressor.fit(X,Y)\n\n#Visualizing the dataset\n\nplt.scatter(X, Y, color = 'red')\nplt.plot(X, regressor.predict(X), color = 'blue')\nplt.show()\n\n# Predicting a new Result\n\nY_pred = regressor.predict(6.5)\nprint(Y_pred)\n</code></pre>\n\n<p>This is my dataset, here I am trying to predict value only for level 6</p>\n\n<pre><code>Position  Level   Salary\n0   Business Analyst      1    45000\n1  Junior Consultant      2    50000\n2  Senior Consultant      3    60000\n3            Manager      4    80000\n4    Country Manager      5   110000\n5     Region Manager      6   150000\n6            Partner      7   200000\n7     Senior Partner      8   300000\n8            C-level      9   500000\n9                CEO     10  1000000\n</code></pre>\n\n<p>This is the error message I am getting:</p>\n\n<pre><code>File \"C:/Users/Rupali Singh/PycharmProjects/Machine_Learning/SVR.py\", line 34, in &lt;module&gt;\n    Y_pred = regressor.predict(6.5)\n  File \"C:\\Users\\Rupali Singh\\PycharmProjects\\Machine_Learning\\venv\\lib\\site-packages\\sklearn\\svm\\base.py\", line 322, in predict\n    X = self._validate_for_predict(X)\n  File \"C:\\Users\\Rupali Singh\\PycharmProjects\\Machine_Learning\\venv\\lib\\site-packages\\sklearn\\svm\\base.py\", line 454, in _validate_for_predict\n    accept_large_sparse=False)\n  File \"C:\\Users\\Rupali Singh\\PycharmProjects\\Machine_Learning\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 514, in check_array\n    \"if it contains a single sample.\".format(array))\nValueError: Expected 2D array, got scalar array instead:\narray=6.5.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n</code></pre>\n\n<p>I would be really grateful for any kind of help.</p>\n <machine-learning><regression><prediction><p>Try:</p>\n\n<pre><code>Y_pred = regressor.predict(np.array([6.5]).reshape(1, 1))\n</code></pre>\n\n<p>Scikit does not work with scalars (just one single value). It expects a shape <span class=\"math-container\">$(m\\times n)$</span> where <span class=\"math-container\">$m$</span> is the number of features and <span class=\"math-container\">$n$</span> is the number of observations, both are 1 in your case.</p>\n",
                "codes": [
                    [
                        "Y_pred = regressor.predict(np.array([6.5]).reshape(1, 1))\n"
                    ]
                ],
                "question_id:": "52902",
                "question_votes:": "",
                "question_text:": "<p>I am trying to get a predicted value instead of whole features for a particular level using predict method.    </p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n#Importing Dataset\ndataset = pd.read_csv('C:/Users/Rupali Singh/Desktop/ML A-Z/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 7 - Support Vector Regression (SVR)/Position_Salaries.csv')\nprint(dataset)\nX = dataset.iloc[:, 1:2].values\nY = dataset.iloc[:, 2].values\n\n# Feature Scaling\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc_X = StandardScaler()\nsc_Y = StandardScaler()\nX = sc_X.fit_transform(X)\nY = sc_Y.fit_transform(Y.reshape(-1,1))\n#Fitting SVR model to dataset\n\nfrom sklearn.svm import SVR\n\nregressor = SVR(kernel='rbf')\nregressor.fit(X,Y)\n\n#Visualizing the dataset\n\nplt.scatter(X, Y, color = 'red')\nplt.plot(X, regressor.predict(X), color = 'blue')\nplt.show()\n\n# Predicting a new Result\n\nY_pred = regressor.predict(6.5)\nprint(Y_pred)\n</code></pre>\n\n<p>This is my dataset, here I am trying to predict value only for level 6</p>\n\n<pre><code>Position  Level   Salary\n0   Business Analyst      1    45000\n1  Junior Consultant      2    50000\n2  Senior Consultant      3    60000\n3            Manager      4    80000\n4    Country Manager      5   110000\n5     Region Manager      6   150000\n6            Partner      7   200000\n7     Senior Partner      8   300000\n8            C-level      9   500000\n9                CEO     10  1000000\n</code></pre>\n\n<p>This is the error message I am getting:</p>\n\n<pre><code>File \"C:/Users/Rupali Singh/PycharmProjects/Machine_Learning/SVR.py\", line 34, in &lt;module&gt;\n    Y_pred = regressor.predict(6.5)\n  File \"C:\\Users\\Rupali Singh\\PycharmProjects\\Machine_Learning\\venv\\lib\\site-packages\\sklearn\\svm\\base.py\", line 322, in predict\n    X = self._validate_for_predict(X)\n  File \"C:\\Users\\Rupali Singh\\PycharmProjects\\Machine_Learning\\venv\\lib\\site-packages\\sklearn\\svm\\base.py\", line 454, in _validate_for_predict\n    accept_large_sparse=False)\n  File \"C:\\Users\\Rupali Singh\\PycharmProjects\\Machine_Learning\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 514, in check_array\n    \"if it contains a single sample.\".format(array))\nValueError: Expected 2D array, got scalar array instead:\narray=6.5.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n</code></pre>\n\n<p>I would be really grateful for any kind of help.</p>\n",
                "tags": "<machine-learning><regression><prediction>",
                "answers": [
                    [
                        "52903",
                        "2",
                        "52902",
                        "",
                        "",
                        "<p>Try:</p>\n\n<pre><code>Y_pred = regressor.predict(np.array([6.5]).reshape(1, 1))\n</code></pre>\n\n<p>Scikit does not work with scalars (just one single value). It expects a shape <span class=\"math-container\">$(m\\times n)$</span> where <span class=\"math-container\">$m$</span> is the number of features and <span class=\"math-container\">$n$</span> is the number of observations, both are 1 in your case.</p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15155",
            "_score": 8.609732,
            "_source": {
                "title": "Keras input shape error on predicting vectors",
                "content": "Keras input shape error on predicting vectors <p>I have trained a Keras model (autoencoder) on embeddings that are 52,388-dimensional. I am trying to use that model to make predictions on a held-out data set that I am loading into Spark. The code to do this is a bit convoluted but in the step before the inference it seems to produce the correct input:</p>\n\n<pre><code>def predict_vectors(self, df_name:str=None, model_name:str=None):\n    try:\n        df = getattr(self, df_name)\n        df.printSchema()\n        model = getattr(self, model_name)\n        pdf = df.toPandas()\n        series = pdf['embedding'].apply(lambda x : np.array(x.toArray())).as_matrix().reshape(1,-1).transpose()\n        logging.info(series.shape)\n        for row in series:\n            logging.info((type(row[0]),row[0], row[0].shape))\n        return self\n    except AttributeError as e:\n        logging.error(e)\n    except ReferenceError as e:\n        logging.error(e)\n    except ValueError as e:\n        logging.error(e)\n    except Py4JJavaError as e:\n        logging.error(e)\n    return None\n</code></pre>\n\n<p>Here are some rows of logging:</p>\n\n<pre><code>2019-05-02 13:03:33,985 root INFO (&lt;class 'numpy.ndarray'&gt;, array([0., 0., 0., ..., 0., 0., 0.]), (52388,))\n2019-05-02 13:03:33,986 root INFO (&lt;class 'numpy.ndarray'&gt;, array([15.,  0.,  0., ...,  0.,  0.,  0.]), (52388,))\n2019-05-02 13:03:33,986 root INFO (&lt;class 'numpy.ndarray'&gt;, array([0., 0., 1., ..., 0., 0., 0.]), (52388,))\n2019-05-02 13:03:33,986 root INFO (&lt;class 'numpy.ndarray'&gt;, array([0., 4., 5., ..., 0., 0., 0.]), (52388,))\n2019-05-02 13:03:33,986 root INFO (&lt;class 'numpy.ndarray'&gt;, array([0., 0., 0., ..., 0., 0., 0.]), (52388,))\n2019-05-02 13:03:33,987 root INFO (&lt;class 'numpy.ndarray'&gt;, array([0., 0., 3., ..., 0., 0., 0.]), (52388,))\n2019-05-02 13:03:33,987 root INFO (&lt;class 'numpy.ndarray'&gt;, array([11.,  0.,  0., ...,  0.,  0.,  0.]), (52388,))\n</code></pre>\n\n<p>Now, when I try to model predict (eg in the for loop <code>model.predict(row[0])</code>) I get the following error:</p>\n\n<pre><code>2019-05-02 13:21:43,678 root ERROR Error when checking input: expected input_1 to have shape (52388,) but got array with shape (1,)\n</code></pre>\n\n<p>This error doesn't make sense to me, because it clearly seems to be outputting the correct <code>(52388,)</code> dimension in the logging statements. Anyone know what's going on here?</p>\n <keras><numpy>",
                "codes": [],
                "question_id:": "51294",
                "question_votes:": "",
                "question_text:": "<p>I have trained a Keras model (autoencoder) on embeddings that are 52,388-dimensional. I am trying to use that model to make predictions on a held-out data set that I am loading into Spark. The code to do this is a bit convoluted but in the step before the inference it seems to produce the correct input:</p>\n\n<pre><code>def predict_vectors(self, df_name:str=None, model_name:str=None):\n    try:\n        df = getattr(self, df_name)\n        df.printSchema()\n        model = getattr(self, model_name)\n        pdf = df.toPandas()\n        series = pdf['embedding'].apply(lambda x : np.array(x.toArray())).as_matrix().reshape(1,-1).transpose()\n        logging.info(series.shape)\n        for row in series:\n            logging.info((type(row[0]),row[0], row[0].shape))\n        return self\n    except AttributeError as e:\n        logging.error(e)\n    except ReferenceError as e:\n        logging.error(e)\n    except ValueError as e:\n        logging.error(e)\n    except Py4JJavaError as e:\n        logging.error(e)\n    return None\n</code></pre>\n\n<p>Here are some rows of logging:</p>\n\n<pre><code>2019-05-02 13:03:33,985 root INFO (&lt;class 'numpy.ndarray'&gt;, array([0., 0., 0., ..., 0., 0., 0.]), (52388,))\n2019-05-02 13:03:33,986 root INFO (&lt;class 'numpy.ndarray'&gt;, array([15.,  0.,  0., ...,  0.,  0.,  0.]), (52388,))\n2019-05-02 13:03:33,986 root INFO (&lt;class 'numpy.ndarray'&gt;, array([0., 0., 1., ..., 0., 0., 0.]), (52388,))\n2019-05-02 13:03:33,986 root INFO (&lt;class 'numpy.ndarray'&gt;, array([0., 4., 5., ..., 0., 0., 0.]), (52388,))\n2019-05-02 13:03:33,986 root INFO (&lt;class 'numpy.ndarray'&gt;, array([0., 0., 0., ..., 0., 0., 0.]), (52388,))\n2019-05-02 13:03:33,987 root INFO (&lt;class 'numpy.ndarray'&gt;, array([0., 0., 3., ..., 0., 0., 0.]), (52388,))\n2019-05-02 13:03:33,987 root INFO (&lt;class 'numpy.ndarray'&gt;, array([11.,  0.,  0., ...,  0.,  0.,  0.]), (52388,))\n</code></pre>\n\n<p>Now, when I try to model predict (eg in the for loop <code>model.predict(row[0])</code>) I get the following error:</p>\n\n<pre><code>2019-05-02 13:21:43,678 root ERROR Error when checking input: expected input_1 to have shape (52388,) but got array with shape (1,)\n</code></pre>\n\n<p>This error doesn't make sense to me, because it clearly seems to be outputting the correct <code>(52388,)</code> dimension in the logging statements. Anyone know what's going on here?</p>\n",
                "tags": "<keras><numpy>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12029",
            "_score": 8.565109,
            "_source": {
                "title": "Fitting a Hidden Markov model with Pyro",
                "content": "Fitting a Hidden Markov model with Pyro <p>\nHi everybody, I am trying to fit an HMM (hidden markov model) with the pyro, a probabilistic programming library. </p>\n\n<p>I generated a dataset to test my model with those rules </p>\n\n<ul>\n<li>hidden states : <span class=\"math-container\">$z_{t+1} = a z_t + b \\epsilon_t$</span> where <span class=\"math-container\">$a, b = 0.1, 0.1$</span>  </li>\n<li>observable states: <span class=\"math-container\">$x_t = z_t + 0.1 \\tilde{\\epsilon}_t$</span>\nwhere <span class=\"math-container\">$\\epsilon_t. \\tilde{\\epsilon_t}$</span> are gaussian noises with mean 0 and variance 1</li>\n</ul>\n\n<p>Then, I want to infer the coeficients <span class=\"math-container\">$a$</span> and <span class=\"math-container\">$b$</span> with the variational inference tool of the Pyro library: </p>\n\n<pre><code>import numpy as np\nimport torch\nimport pyro\nimport pyro.distributions as dist\nimport torch.nn as nn\n\ntransition = lambda z: 0.1 * z - 1 +   0.1 * np.random.normal(0,1)\nemission = lambda x:  x  + 0.1 * np.random.normal(0,1)\n\nimport pylab as plt\n%matplotlib inline\ndef generate_one_sample(n=100):\n    z_tp = [0]\n    x_tp = [0]\n    for i in range(n):\n        z_tp.append(transition(z_tp[-1]))\n        x_tp.append(emission(z_tp[-1]))\n    return x_tp, z_tp\ndef generate_many_samples(n_samples=10, n_points=100):\n    return np.array([generate_one_sample(n_points)[1] for _ in range(n_samples)])\n\ntransition = lambda z: 0.1 * z - 1 +   0.1 * np.random.normal(0,1)\nemission = lambda x:  x  + 0.1 * np.random.normal(0,1)\n\n\n\nclass Transition(nn.Module):\n    \"\"\"\n    Parameterizes the bernoulli observation likelihood p(x_t | z_t)\n    \"\"\"\n    def __init__(self):\n        super(Transition, self).__init__()\n        # initialize the three linear transformations used in the neural network\n        self.layer1= nn.Linear(1, 1)\n        self.layer2= nn.Linear(1, 1)\n        self.softplus = nn.Softplus()\n    def forward(self, z_t):\n        \"\"\"\n        Given the latent z at a particular time step t we return the vector of\n        probabilities `ps` that parameterizes the bernoulli distribution p(x_t|z_t)\n        \"\"\"\n        return self.layer1(z_t), self.softplus(self.layer2(z_t))\n\nclass DMM(nn.Module): \n    def __init__(self): \n        super(DMM, self).__init__()\n        self.transition = Transition().cuda()\n        self = self.cuda()\n    def model(self, data): \n        pyro.module(\"dmm\", self)\n        n_sample = data.shape[0]\n        loc_z = 0 * torch.ones(n_sample).cuda()\n        scale_z =  torch.ones(n_sample).cuda()*0.1\n        for t in range(data.shape[1]):\n            if t != 0:\n                loc_z, scale_z = self.transition(z_t.reshape(-1, 1))\n            with pyro.poutine.scale(None, .1):\n                z_t = pyro.sample('z_{}'.format(t), pyro.distributions.Normal(loc_z, scale_z).independent(1))\n            loc_x = z_t; # self.emission(z_t.reshape(-1, 1))\n            x_t = pyro.sample('x_{}'.format(t), pyro.distributions.Normal(loc_x, .1).independent(1), \n                              obs=data[:,t])\n\n    def guide(self, data): \n        pyro.module(\"dmm\", self)\n        n_sample = data.shape[0]\n        loc_z = 0 * torch.ones(n_sample).cuda()\n        scale_z = torch.ones(n_sample).cuda()\n        for t in range(data.shape[1]): \n            z_t = pyro.sample('z_{}'.format(t), pyro.distributions.Normal(loc_z, scale_z).independent(1))\n            loc_z, scale_z = self.transition(z_t.reshape(-1, 1))\ndmm = DMM().cuda()\nfrom pyro.optim import Adam, ClippedAdam\n\nadam_params = {\"lr\": 0.01, \"betas\": (0.95, 0.999)}\noptimizer = Adam(adam_params)\nfrom pyro.infer import SVI, Trace_ELBO\nsvi = SVI(dmm.model, dmm.guide, optimizer, loss=Trace_ELBO())\n\nimport sys \ntorch.cuda.empty_cache\nfor i in range(500):\n    if i % 5000 == 0: \n        test_me_im_famous = torch.tensor(generate_many_samples(n_samples=100, n_points=7),dtype=torch.float32).cuda()\n        print('\\n')\n    sys.stdout.write('epoch {},   {}    \\r'.format(i, svi.step(test_me_im_famous))) \nimport pylab as plt\n%matplotlib inline\nx = np.arange(0,1, 0.01)\nplt.plot(x, \n         dmm.transition(torch.arange(0,1,0.01).cuda().reshape(-1, 1))[0].cpu().flatten().detach().numpy(),\n         label='transition')\nplt.plot(x, 0.1 * x - 1 , ls='--', label='real transition')\nplt.legend(loc='best')\n</code></pre>\n\n<p>unfortunately after 500 iterations, I do not converge the correct coefficients. \nHas anybody already encountered such kind of problems ? </p>\n <python><markov-hidden-model>",
                "codes": [],
                "question_id:": "42290",
                "question_votes:": "",
                "question_text:": "<p>\nHi everybody, I am trying to fit an HMM (hidden markov model) with the pyro, a probabilistic programming library. </p>\n\n<p>I generated a dataset to test my model with those rules </p>\n\n<ul>\n<li>hidden states : <span class=\"math-container\">$z_{t+1} = a z_t + b \\epsilon_t$</span> where <span class=\"math-container\">$a, b = 0.1, 0.1$</span>  </li>\n<li>observable states: <span class=\"math-container\">$x_t = z_t + 0.1 \\tilde{\\epsilon}_t$</span>\nwhere <span class=\"math-container\">$\\epsilon_t. \\tilde{\\epsilon_t}$</span> are gaussian noises with mean 0 and variance 1</li>\n</ul>\n\n<p>Then, I want to infer the coeficients <span class=\"math-container\">$a$</span> and <span class=\"math-container\">$b$</span> with the variational inference tool of the Pyro library: </p>\n\n<pre><code>import numpy as np\nimport torch\nimport pyro\nimport pyro.distributions as dist\nimport torch.nn as nn\n\ntransition = lambda z: 0.1 * z - 1 +   0.1 * np.random.normal(0,1)\nemission = lambda x:  x  + 0.1 * np.random.normal(0,1)\n\nimport pylab as plt\n%matplotlib inline\ndef generate_one_sample(n=100):\n    z_tp = [0]\n    x_tp = [0]\n    for i in range(n):\n        z_tp.append(transition(z_tp[-1]))\n        x_tp.append(emission(z_tp[-1]))\n    return x_tp, z_tp\ndef generate_many_samples(n_samples=10, n_points=100):\n    return np.array([generate_one_sample(n_points)[1] for _ in range(n_samples)])\n\ntransition = lambda z: 0.1 * z - 1 +   0.1 * np.random.normal(0,1)\nemission = lambda x:  x  + 0.1 * np.random.normal(0,1)\n\n\n\nclass Transition(nn.Module):\n    \"\"\"\n    Parameterizes the bernoulli observation likelihood p(x_t | z_t)\n    \"\"\"\n    def __init__(self):\n        super(Transition, self).__init__()\n        # initialize the three linear transformations used in the neural network\n        self.layer1= nn.Linear(1, 1)\n        self.layer2= nn.Linear(1, 1)\n        self.softplus = nn.Softplus()\n    def forward(self, z_t):\n        \"\"\"\n        Given the latent z at a particular time step t we return the vector of\n        probabilities `ps` that parameterizes the bernoulli distribution p(x_t|z_t)\n        \"\"\"\n        return self.layer1(z_t), self.softplus(self.layer2(z_t))\n\nclass DMM(nn.Module): \n    def __init__(self): \n        super(DMM, self).__init__()\n        self.transition = Transition().cuda()\n        self = self.cuda()\n    def model(self, data): \n        pyro.module(\"dmm\", self)\n        n_sample = data.shape[0]\n        loc_z = 0 * torch.ones(n_sample).cuda()\n        scale_z =  torch.ones(n_sample).cuda()*0.1\n        for t in range(data.shape[1]):\n            if t != 0:\n                loc_z, scale_z = self.transition(z_t.reshape(-1, 1))\n            with pyro.poutine.scale(None, .1):\n                z_t = pyro.sample('z_{}'.format(t), pyro.distributions.Normal(loc_z, scale_z).independent(1))\n            loc_x = z_t; # self.emission(z_t.reshape(-1, 1))\n            x_t = pyro.sample('x_{}'.format(t), pyro.distributions.Normal(loc_x, .1).independent(1), \n                              obs=data[:,t])\n\n    def guide(self, data): \n        pyro.module(\"dmm\", self)\n        n_sample = data.shape[0]\n        loc_z = 0 * torch.ones(n_sample).cuda()\n        scale_z = torch.ones(n_sample).cuda()\n        for t in range(data.shape[1]): \n            z_t = pyro.sample('z_{}'.format(t), pyro.distributions.Normal(loc_z, scale_z).independent(1))\n            loc_z, scale_z = self.transition(z_t.reshape(-1, 1))\ndmm = DMM().cuda()\nfrom pyro.optim import Adam, ClippedAdam\n\nadam_params = {\"lr\": 0.01, \"betas\": (0.95, 0.999)}\noptimizer = Adam(adam_params)\nfrom pyro.infer import SVI, Trace_ELBO\nsvi = SVI(dmm.model, dmm.guide, optimizer, loss=Trace_ELBO())\n\nimport sys \ntorch.cuda.empty_cache\nfor i in range(500):\n    if i % 5000 == 0: \n        test_me_im_famous = torch.tensor(generate_many_samples(n_samples=100, n_points=7),dtype=torch.float32).cuda()\n        print('\\n')\n    sys.stdout.write('epoch {},   {}    \\r'.format(i, svi.step(test_me_im_famous))) \nimport pylab as plt\n%matplotlib inline\nx = np.arange(0,1, 0.01)\nplt.plot(x, \n         dmm.transition(torch.arange(0,1,0.01).cuda().reshape(-1, 1))[0].cpu().flatten().detach().numpy(),\n         label='transition')\nplt.plot(x, 0.1 * x - 1 , ls='--', label='real transition')\nplt.legend(loc='best')\n</code></pre>\n\n<p>unfortunately after 500 iterations, I do not converge the correct coefficients. \nHas anybody already encountered such kind of problems ? </p>\n",
                "tags": "<python><markov-hidden-model>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13012",
            "_score": 8.5568285,
            "_source": {
                "title": "Can I save prediction value in same csv file as a another column using panda python",
                "content": "Can I save prediction value in same csv file as a another column using panda python <p>I have csv data file and I design LSTM model to predict values. Then I want to save that prediction value in same csv file. Can I do that? I tried using one code then in my csv file only had prediction values and delete other columns. Can anyone give me a suggestion for that.</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\ndata = pd.read_csv('data1.csv')\ndata = pd.DataFrame(data,columns=['x','x1','x2','y'])\ndata.columns = ['x', 'x1', 'x2','y']\npd.options.display.float_format = '{:,.0f}'.format\ndata = data.dropna ()\nd = ['y']\ny=data['y'].astype(int)\ncols=['x', 'x1', 'x2']\nx=data[cols].astype(int)\nscaler_x = preprocessing.MinMaxScaler(feature_range =(-1, 1))\nx = np.array(x).reshape ((len(x),3 ))\nx = scaler_x.fit_transform(x)\nscaler_y = preprocessing.MinMaxScaler(feature_range =(-1, 1))\ny = np.array(y).reshape ((len(y), 1))\ny = scaler_y.fit_transform(y)\nprint(\"row\",len(y))\nn = data.shape[0]\np = data.shape[1]\nfill_missing(data.values)\ntrain_start = 0\ntrain_end = int(np.floor(0.65*n))\ntest_start = train_end+1 \ntest_end = n\nx_train = x[np.arange(train_start, train_end), :]\nx_test = x[np.arange(test_start, test_end), :]\ny_train = y[np.arange(train_start, train_end), :]\ny_test = y[np.arange(test_start, test_end), :]\nx_train=x_train.reshape(x_train.shape +(1,))\nx_test=x_test.reshape(x_test.shape + (1,))\nseed = 20\nnp.random.seed(seed)\nfit1 = Sequential ()\nfit1.add(LSTM(\noutput_dim = 10,\nactivation='relu',\ninput_shape =(3,1)))\nfit1.add(Dense(output_dim =1))\nfit1.add(Activation(linear))\nbatchsize = 10\nfit1.compile(loss=\"mean_squared_error\",optimizer=\"adam\")\nfit1.fit(x_train , y_train , batch_size = batchsize, nb_epoch =10,   shuffle=True)\nprint(fit1.summary ())\npred1=fit1.predict(x_test)\npred1=fit1.predict(x_test)\nreal_test = scaler_y.inverse_transform(np.array(y_test).reshape ((len(y_test), 1))).astype(int)\npred1 = pd.DataFrame(pred1, columns=['pred1']).to_csv('data1.csv')\n</code></pre>\n <python><pandas><p>There is no direct method for it but you can do it by the following simple manipulation. Instead of directly appending to the csv file you can open it in python and then append it. Here is the code for the same:</p>\n\n<pre><code>data = pd.read_csv(\"data1.csv\")\ndata['pred1'] = pred1\ndf.to_csv('data1.csv')\n</code></pre>\n<p>if you want this column in the same dataframe just do</p>\n\n<pre><code>data['pred'] = pred1\ndata.to_csv('data1.csv')\n</code></pre>\n\n<p>The first line automatically adds a column called 'pred' to the dataframe with values coming from pred1.</p>\n\n<p>Hope it helps. Good luck!</p>\n",
                "codes": [
                    [
                        "data = pd.read_csv(\"data1.csv\")\ndata['pred1'] = pred1\ndf.to_csv('data1.csv')\n"
                    ],
                    [
                        "data['pred'] = pred1\ndata.to_csv('data1.csv')\n"
                    ]
                ],
                "question_id:": "45074",
                "question_votes:": "2",
                "question_text:": "<p>I have csv data file and I design LSTM model to predict values. Then I want to save that prediction value in same csv file. Can I do that? I tried using one code then in my csv file only had prediction values and delete other columns. Can anyone give me a suggestion for that.</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\ndata = pd.read_csv('data1.csv')\ndata = pd.DataFrame(data,columns=['x','x1','x2','y'])\ndata.columns = ['x', 'x1', 'x2','y']\npd.options.display.float_format = '{:,.0f}'.format\ndata = data.dropna ()\nd = ['y']\ny=data['y'].astype(int)\ncols=['x', 'x1', 'x2']\nx=data[cols].astype(int)\nscaler_x = preprocessing.MinMaxScaler(feature_range =(-1, 1))\nx = np.array(x).reshape ((len(x),3 ))\nx = scaler_x.fit_transform(x)\nscaler_y = preprocessing.MinMaxScaler(feature_range =(-1, 1))\ny = np.array(y).reshape ((len(y), 1))\ny = scaler_y.fit_transform(y)\nprint(\"row\",len(y))\nn = data.shape[0]\np = data.shape[1]\nfill_missing(data.values)\ntrain_start = 0\ntrain_end = int(np.floor(0.65*n))\ntest_start = train_end+1 \ntest_end = n\nx_train = x[np.arange(train_start, train_end), :]\nx_test = x[np.arange(test_start, test_end), :]\ny_train = y[np.arange(train_start, train_end), :]\ny_test = y[np.arange(test_start, test_end), :]\nx_train=x_train.reshape(x_train.shape +(1,))\nx_test=x_test.reshape(x_test.shape + (1,))\nseed = 20\nnp.random.seed(seed)\nfit1 = Sequential ()\nfit1.add(LSTM(\noutput_dim = 10,\nactivation='relu',\ninput_shape =(3,1)))\nfit1.add(Dense(output_dim =1))\nfit1.add(Activation(linear))\nbatchsize = 10\nfit1.compile(loss=\"mean_squared_error\",optimizer=\"adam\")\nfit1.fit(x_train , y_train , batch_size = batchsize, nb_epoch =10,   shuffle=True)\nprint(fit1.summary ())\npred1=fit1.predict(x_test)\npred1=fit1.predict(x_test)\nreal_test = scaler_y.inverse_transform(np.array(y_test).reshape ((len(y_test), 1))).astype(int)\npred1 = pd.DataFrame(pred1, columns=['pred1']).to_csv('data1.csv')\n</code></pre>\n",
                "tags": "<python><pandas>",
                "answers": [
                    [
                        "45076",
                        "2",
                        "45074",
                        "",
                        "",
                        "<p>There is no direct method for it but you can do it by the following simple manipulation. Instead of directly appending to the csv file you can open it in python and then append it. Here is the code for the same:</p>\n\n<pre><code>data = pd.read_csv(\"data1.csv\")\ndata['pred1'] = pred1\ndf.to_csv('data1.csv')\n</code></pre>\n",
                        "",
                        "1"
                    ],
                    [
                        "45077",
                        "2",
                        "45074",
                        "",
                        "",
                        "<p>if you want this column in the same dataframe just do</p>\n\n<pre><code>data['pred'] = pred1\ndata.to_csv('data1.csv')\n</code></pre>\n\n<p>The first line automatically adds a column called 'pred' to the dataframe with values coming from pred1.</p>\n\n<p>Hope it helps. Good luck!</p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12298",
            "_score": 8.551172,
            "_source": {
                "title": "Using the Python Keras multi_gpu_model with LSTM / GRU to predict Timeseries data",
                "content": "Using the Python Keras multi_gpu_model with LSTM / GRU to predict Timeseries data <p>I'm having an issue with python keras LSTM / GRU layers with <code>multi_gpu_model</code> for machine learning. </p>\n\n<p>When I use a single GPU, the predictions work correctly matching the sinusoidal data in the script below. See image labeled \"1 GPUs\".</p>\n\n<p><a href=\"https://i.stack.imgur.com/N4ANi.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/N4ANi.png\" alt=\"Using 1 GPU\"></a></p>\n\n<p>When I use multiple GPUs, the inverse transforms of both the training and test data return results that cluster around the lows of the original data  See image labeled \"4 GPUs\".</p>\n\n<p><a href=\"https://i.stack.imgur.com/WEbFn.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WEbFn.png\" alt=\"Using 4 GPUs\"></a></p>\n\n<p>Is this:</p>\n\n<ol>\n<li>a bug? </li>\n<li>a case where I'm missing a multiplier that should be used\nwhen <code>multi_gpu_model</code> is used? </li>\n<li>an example where the\n<code>multi_gpu_model</code> documentation isn't complete with a\ncaveat to cover this specific case.</li>\n<li>the result of flaw(s) in my code?</li>\n</ol>\n\n<hr>\n\n<p>Versions</p>\n\n<pre><code>Keras                   2.2.4  \nKeras-Applications      1.0.6  \nKeras-Preprocessing     1.0.5  \ntensorboard             1.12.0 \ntensorflow-gpu          1.12.0 \n</code></pre>\n\n<p>GPUs</p>\n\n<pre><code>+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 410.79       Driver Version: 410.79       CUDA Version: 10.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 107...  Off  | 00000000:08:00.0 Off |                  N/A |\n| 30%   42C    P0    36W / 180W |      0MiB /  8119MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX 107...  Off  | 00000000:09:00.0 Off |                  N/A |\n| 36%   48C    P0    37W / 180W |      0MiB /  8119MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX 107...  Off  | 00000000:41:00.0 Off |                  N/A |\n| 34%   44C    P0    34W / 180W |      0MiB /  8119MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  GeForce GTX 107...  Off  | 00000000:42:00.0 Off |                  N/A |\n| 31%   42C    P0    32W / 180W |      0MiB /  8112MiB |      5%      Default |\n+-------------------------------+----------------------+----------------------+\n</code></pre>\n\n<p>Script</p>\n\n<pre><code>#!/usr/bin/env python3\n\"\"\"LSTM for sinusoidal data problem with regression framing.\n\nBased on:\n\nhttps://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n\n\"\"\"\n\n# Standard imports\nimport argparse\nimport math\n\n# PIP3 imports\nimport numpy\nimport matplotlib.pyplot as plt\nfrom pandas import DataFrame\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.utils import multi_gpu_model\n\nimport tensorflow as tf\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\n# convert an array of values into a dataset matrix\ndef create_dataset(dataset, look_back=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1):\n        a = dataset[i:(i+look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return numpy.array(dataX), numpy.array(dataY)\n\ndef main():\n    # fix random seed for reproducibility\n    numpy.random.seed(7)\n\n    # Get CLI arguments\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '--gpus',\n        help='Number of GPUs to use.',\n        type=int, default=1)\n    args = parser.parse_args()\n    gpus = args.gpus\n\n    # load the dataset\n    dataframe = DataFrame(\n        [0.00000, 5.99000, 11.92016, 17.73121, 23.36510, 28.76553, 33.87855,\n         38.65306, 43.04137, 46.99961, 50.48826, 53.47244, 55.92235, 57.81349,\n         59.12698, 59.84970, 59.97442, 59.49989, 58.43086, 56.77801, 54.55785,\n         51.79256, 48.50978, 44.74231, 40.52779, 35.90833, 30.93008, 25.64279,\n         20.09929, 14.35496, 8.46720, 2.49484, -3.50245, -9.46474, -15.33247,\n         -21.04699, -26.55123, -31.79017, -36.71147, -41.26597, -45.40815,\n         -49.09663, -52.29455, -54.96996, -57.09612, -58.65181, -59.62146,\n         -59.99540, -59.76988, -58.94716, -57.53546, -55.54888, -53.00728,\n         -49.93605, -46.36587, -42.33242, -37.87600, -33.04113, -27.87613,\n         -22.43260, -16.76493, -10.92975, -4.98536, 1.00883, 6.99295, 12.90720,\n         18.69248, 24.29100, 29.64680, 34.70639, 39.41920, 43.73814, 47.62007,\n         51.02620, 53.92249, 56.28000, 58.07518, 59.29009, 59.91260, 59.93648,\n         59.36149, 58.19339, 56.44383, 54.13031, 51.27593, 47.90923, 44.06383,\n         39.77815, 35.09503, 30.06125, 24.72711, 19.14590, 13.37339, 7.46727,\n         1.48653, -4.50907, -10.45961, -16.30564, -21.98875, -27.45215,\n         -32.64127, -37.50424, -41.99248, -46.06115, -49.66959, -52.78175,\n         -55.36653, -57.39810, -58.85617, -59.72618, -59.99941, -59.67316,\n         -58.75066, -57.24115, -55.15971, -52.52713, -49.36972, -45.71902,\n         -41.61151, -37.08823, -32.19438, -26.97885, -21.49376, -15.79391,\n         -9.93625, -3.97931, 2.01738, 7.99392, 13.89059, 19.64847, 25.21002,\n         30.51969, 35.52441, 40.17419, 44.42255, 48.22707, 51.54971, 54.35728,\n         56.62174, 58.32045, 59.43644, 59.95856, 59.88160, 59.20632, 57.93947,\n         56.09370, 53.68747, 50.74481, 47.29512, 43.37288, 39.01727, 34.27181,\n         29.18392, 23.80443, 18.18710, 12.38805, 6.46522, 0.47779, -5.51441,\n         -11.45151])\n    dataset = dataframe.values\n    dataset = dataset.astype('float32')\n\n    # normalize the dataset\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    dataset = scaler.fit_transform(dataset)\n\n    # split into train and test sets\n    train_size = int(len(dataset) * 0.67)\n    test_size = len(dataset) - train_size\n    train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n\n    # reshape into X=t and Y=t+1\n    look_back = 1\n    trainX, trainY = create_dataset(train, look_back)\n    testX, testY = create_dataset(test, look_back)\n\n    # reshape input to be [samples, time steps, features]\n    trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n    testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n\n    # create and fit the LSTM network\n    with tf.device('/cpu:0'):\n        serial_model = Sequential()\n    serial_model.add(LSTM(4, input_shape=(1, look_back)))\n    serial_model.add(Dense(1))\n    if gpus == 1:\n        parallel_model = serial_model\n    else:\n        parallel_model = multi_gpu_model(\n            serial_model,\n            cpu_relocation=True,\n            gpus=gpus)\n    parallel_model.compile(\n        loss='mean_squared_error', optimizer='adam')\n    parallel_model.fit(\n        trainX, trainY,\n        epochs=100,\n        batch_size=int(dataset.size * gpus / 20),\n        verbose=2)\n\n    # make predictions\n    if gpus == 1:\n        trainPredict = parallel_model.predict(trainX)\n        testPredict = parallel_model.predict(testX)\n    else:\n        trainPredict = serial_model.predict(trainX)\n        testPredict = serial_model.predict(testX)\n\n    # invert predictions\n    trainPredict = scaler.inverse_transform(trainPredict)\n    trainY = scaler.inverse_transform([trainY])\n    testPredict = scaler.inverse_transform(testPredict)\n    testY = scaler.inverse_transform([testY])\n\n    # calculate root mean squared error\n    trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:, 0]))\n    print('Train Score: %.2f RMSE' % (trainScore))\n    testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:, 0]))\n    print('Test Score: %.2f RMSE' % (testScore))\n\n    # shift train predictions for plotting\n    trainPredictPlot = numpy.empty_like(dataset)\n    trainPredictPlot[:, :] = numpy.nan\n    trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n\n    # shift test predictions for plotting\n    testPredictPlot = numpy.empty_like(dataset)\n    testPredictPlot[:, :] = numpy.nan\n    testPredictPlot[\n        len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n\n    # plot baseline and predictions\n    plt.plot(scaler.inverse_transform(dataset), label='Complete Data')\n    plt.plot(trainPredictPlot, label='Training Data')\n    plt.plot(testPredictPlot, label='Prediction Data')\n    plt.legend(loc='upper left')\n    plt.title('Using {} GPUs'.format(gpus))\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>\n\n<p>I thought it may have something to do with the Sequential model, but I get the same results when I replace:</p>\n\n<pre><code># create and fit the LSTM network\nwith tf.device('/cpu:0'):\n    serial_model = Sequential()\nserial_model.add(LSTM(4, input_shape=(1, look_back)))\nserial_model.add(Dense(1))\n</code></pre>\n\n<p>with:</p>\n\n<pre><code>from keras import Model, Input\n\n# Create layers for model\nx_tensor = Input(shape=(1, look_back))\nlayer_1 = LSTM(4)(x_tensor)\ny_tensor = Dense(1)(layer_1)\n\n# Create and fit the LSTM network\nwith tf.device('/cpu:0'):\n    serial_model = Model(inputs=x_tensor, outputs=y_tensor)\n</code></pre>\n\n<p>I now think it has something to do with the way <code>multi_gpu_model</code> splits the timeseries data across the GPUs. The RMSE error rates are noticeably different.</p>\n\n<p><strong>RMSE - I GPU</strong></p>\n\n<pre><code>Train Score: 4.49 RMSE\nTest Score: 4.79 RMSE\n</code></pre>\n\n<p><strong>RMSE - 4 GPUs</strong></p>\n\n<pre><code>Train Score: 76.54 RMSE\nTest Score: 77.55 RMSE\n</code></pre>\n <python><keras><tensorflow><lstm><gpu>",
                "codes": [],
                "question_id:": "43236",
                "question_votes:": "2",
                "question_text:": "<p>I'm having an issue with python keras LSTM / GRU layers with <code>multi_gpu_model</code> for machine learning. </p>\n\n<p>When I use a single GPU, the predictions work correctly matching the sinusoidal data in the script below. See image labeled \"1 GPUs\".</p>\n\n<p><a href=\"https://i.stack.imgur.com/N4ANi.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/N4ANi.png\" alt=\"Using 1 GPU\"></a></p>\n\n<p>When I use multiple GPUs, the inverse transforms of both the training and test data return results that cluster around the lows of the original data  See image labeled \"4 GPUs\".</p>\n\n<p><a href=\"https://i.stack.imgur.com/WEbFn.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WEbFn.png\" alt=\"Using 4 GPUs\"></a></p>\n\n<p>Is this:</p>\n\n<ol>\n<li>a bug? </li>\n<li>a case where I'm missing a multiplier that should be used\nwhen <code>multi_gpu_model</code> is used? </li>\n<li>an example where the\n<code>multi_gpu_model</code> documentation isn't complete with a\ncaveat to cover this specific case.</li>\n<li>the result of flaw(s) in my code?</li>\n</ol>\n\n<hr>\n\n<p>Versions</p>\n\n<pre><code>Keras                   2.2.4  \nKeras-Applications      1.0.6  \nKeras-Preprocessing     1.0.5  \ntensorboard             1.12.0 \ntensorflow-gpu          1.12.0 \n</code></pre>\n\n<p>GPUs</p>\n\n<pre><code>+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 410.79       Driver Version: 410.79       CUDA Version: 10.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 107...  Off  | 00000000:08:00.0 Off |                  N/A |\n| 30%   42C    P0    36W / 180W |      0MiB /  8119MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX 107...  Off  | 00000000:09:00.0 Off |                  N/A |\n| 36%   48C    P0    37W / 180W |      0MiB /  8119MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX 107...  Off  | 00000000:41:00.0 Off |                  N/A |\n| 34%   44C    P0    34W / 180W |      0MiB /  8119MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  GeForce GTX 107...  Off  | 00000000:42:00.0 Off |                  N/A |\n| 31%   42C    P0    32W / 180W |      0MiB /  8112MiB |      5%      Default |\n+-------------------------------+----------------------+----------------------+\n</code></pre>\n\n<p>Script</p>\n\n<pre><code>#!/usr/bin/env python3\n\"\"\"LSTM for sinusoidal data problem with regression framing.\n\nBased on:\n\nhttps://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n\n\"\"\"\n\n# Standard imports\nimport argparse\nimport math\n\n# PIP3 imports\nimport numpy\nimport matplotlib.pyplot as plt\nfrom pandas import DataFrame\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.utils import multi_gpu_model\n\nimport tensorflow as tf\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\n# convert an array of values into a dataset matrix\ndef create_dataset(dataset, look_back=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1):\n        a = dataset[i:(i+look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return numpy.array(dataX), numpy.array(dataY)\n\ndef main():\n    # fix random seed for reproducibility\n    numpy.random.seed(7)\n\n    # Get CLI arguments\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '--gpus',\n        help='Number of GPUs to use.',\n        type=int, default=1)\n    args = parser.parse_args()\n    gpus = args.gpus\n\n    # load the dataset\n    dataframe = DataFrame(\n        [0.00000, 5.99000, 11.92016, 17.73121, 23.36510, 28.76553, 33.87855,\n         38.65306, 43.04137, 46.99961, 50.48826, 53.47244, 55.92235, 57.81349,\n         59.12698, 59.84970, 59.97442, 59.49989, 58.43086, 56.77801, 54.55785,\n         51.79256, 48.50978, 44.74231, 40.52779, 35.90833, 30.93008, 25.64279,\n         20.09929, 14.35496, 8.46720, 2.49484, -3.50245, -9.46474, -15.33247,\n         -21.04699, -26.55123, -31.79017, -36.71147, -41.26597, -45.40815,\n         -49.09663, -52.29455, -54.96996, -57.09612, -58.65181, -59.62146,\n         -59.99540, -59.76988, -58.94716, -57.53546, -55.54888, -53.00728,\n         -49.93605, -46.36587, -42.33242, -37.87600, -33.04113, -27.87613,\n         -22.43260, -16.76493, -10.92975, -4.98536, 1.00883, 6.99295, 12.90720,\n         18.69248, 24.29100, 29.64680, 34.70639, 39.41920, 43.73814, 47.62007,\n         51.02620, 53.92249, 56.28000, 58.07518, 59.29009, 59.91260, 59.93648,\n         59.36149, 58.19339, 56.44383, 54.13031, 51.27593, 47.90923, 44.06383,\n         39.77815, 35.09503, 30.06125, 24.72711, 19.14590, 13.37339, 7.46727,\n         1.48653, -4.50907, -10.45961, -16.30564, -21.98875, -27.45215,\n         -32.64127, -37.50424, -41.99248, -46.06115, -49.66959, -52.78175,\n         -55.36653, -57.39810, -58.85617, -59.72618, -59.99941, -59.67316,\n         -58.75066, -57.24115, -55.15971, -52.52713, -49.36972, -45.71902,\n         -41.61151, -37.08823, -32.19438, -26.97885, -21.49376, -15.79391,\n         -9.93625, -3.97931, 2.01738, 7.99392, 13.89059, 19.64847, 25.21002,\n         30.51969, 35.52441, 40.17419, 44.42255, 48.22707, 51.54971, 54.35728,\n         56.62174, 58.32045, 59.43644, 59.95856, 59.88160, 59.20632, 57.93947,\n         56.09370, 53.68747, 50.74481, 47.29512, 43.37288, 39.01727, 34.27181,\n         29.18392, 23.80443, 18.18710, 12.38805, 6.46522, 0.47779, -5.51441,\n         -11.45151])\n    dataset = dataframe.values\n    dataset = dataset.astype('float32')\n\n    # normalize the dataset\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    dataset = scaler.fit_transform(dataset)\n\n    # split into train and test sets\n    train_size = int(len(dataset) * 0.67)\n    test_size = len(dataset) - train_size\n    train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n\n    # reshape into X=t and Y=t+1\n    look_back = 1\n    trainX, trainY = create_dataset(train, look_back)\n    testX, testY = create_dataset(test, look_back)\n\n    # reshape input to be [samples, time steps, features]\n    trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n    testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n\n    # create and fit the LSTM network\n    with tf.device('/cpu:0'):\n        serial_model = Sequential()\n    serial_model.add(LSTM(4, input_shape=(1, look_back)))\n    serial_model.add(Dense(1))\n    if gpus == 1:\n        parallel_model = serial_model\n    else:\n        parallel_model = multi_gpu_model(\n            serial_model,\n            cpu_relocation=True,\n            gpus=gpus)\n    parallel_model.compile(\n        loss='mean_squared_error', optimizer='adam')\n    parallel_model.fit(\n        trainX, trainY,\n        epochs=100,\n        batch_size=int(dataset.size * gpus / 20),\n        verbose=2)\n\n    # make predictions\n    if gpus == 1:\n        trainPredict = parallel_model.predict(trainX)\n        testPredict = parallel_model.predict(testX)\n    else:\n        trainPredict = serial_model.predict(trainX)\n        testPredict = serial_model.predict(testX)\n\n    # invert predictions\n    trainPredict = scaler.inverse_transform(trainPredict)\n    trainY = scaler.inverse_transform([trainY])\n    testPredict = scaler.inverse_transform(testPredict)\n    testY = scaler.inverse_transform([testY])\n\n    # calculate root mean squared error\n    trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:, 0]))\n    print('Train Score: %.2f RMSE' % (trainScore))\n    testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:, 0]))\n    print('Test Score: %.2f RMSE' % (testScore))\n\n    # shift train predictions for plotting\n    trainPredictPlot = numpy.empty_like(dataset)\n    trainPredictPlot[:, :] = numpy.nan\n    trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n\n    # shift test predictions for plotting\n    testPredictPlot = numpy.empty_like(dataset)\n    testPredictPlot[:, :] = numpy.nan\n    testPredictPlot[\n        len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n\n    # plot baseline and predictions\n    plt.plot(scaler.inverse_transform(dataset), label='Complete Data')\n    plt.plot(trainPredictPlot, label='Training Data')\n    plt.plot(testPredictPlot, label='Prediction Data')\n    plt.legend(loc='upper left')\n    plt.title('Using {} GPUs'.format(gpus))\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>\n\n<p>I thought it may have something to do with the Sequential model, but I get the same results when I replace:</p>\n\n<pre><code># create and fit the LSTM network\nwith tf.device('/cpu:0'):\n    serial_model = Sequential()\nserial_model.add(LSTM(4, input_shape=(1, look_back)))\nserial_model.add(Dense(1))\n</code></pre>\n\n<p>with:</p>\n\n<pre><code>from keras import Model, Input\n\n# Create layers for model\nx_tensor = Input(shape=(1, look_back))\nlayer_1 = LSTM(4)(x_tensor)\ny_tensor = Dense(1)(layer_1)\n\n# Create and fit the LSTM network\nwith tf.device('/cpu:0'):\n    serial_model = Model(inputs=x_tensor, outputs=y_tensor)\n</code></pre>\n\n<p>I now think it has something to do with the way <code>multi_gpu_model</code> splits the timeseries data across the GPUs. The RMSE error rates are noticeably different.</p>\n\n<p><strong>RMSE - I GPU</strong></p>\n\n<pre><code>Train Score: 4.49 RMSE\nTest Score: 4.79 RMSE\n</code></pre>\n\n<p><strong>RMSE - 4 GPUs</strong></p>\n\n<pre><code>Train Score: 76.54 RMSE\nTest Score: 77.55 RMSE\n</code></pre>\n",
                "tags": "<python><keras><tensorflow><lstm><gpu>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "978",
            "_score": 8.54154,
            "_source": {
                "title": "Implementing sklearn.linear_model.SGDClassifier using python",
                "content": "Implementing sklearn.linear_model.SGDClassifier using python <p>I have an excel file that contains details related to determining the quality of a wine and I want to implement the linear model concept using the function <strong>sklearn.linear_model.SGDClassifier(SVM => Hinge loss) and (Logarithmic regression =>log loss)</strong> using python. I learned the basics about these function through the <em>scikit learn</em> website and I am not able to implement the model using excel file. I am very new to python and machine learning and I finding it hard to implement the model. I opened the excel file in python and tried to take two columns [randomly] from the file and use that as an input to call the <strong>fit</strong> function available in the model. But, I got an error stating <strong>Unknown label type: array</strong>. I tried a couple of other methods too, but, nothing worked. Can someone guide me with the implementation process? </p>\n\n<pre><code>from xlrd import open_workbook\nfrom sklearn import linear_model\ni = 0\nfa = []\nph = []\n\nbook = open_workbook('F:/BIG DATA/winequality.xlsx')\nsheet = book.sheet_by_name('Sheet1')\nnum_rows = sheet.nrows - 1\nnum_cols = sheet.ncols - 1\ncurr_row = 0\nwhile curr_row &lt;num_rows:\n    curr_row += 1\n    cell_val = sheet.cell_value(curr_row,0)\n    cell_val1 = sheet.cell_value(curr_row,10)\n\n    fa.append([float(cell_val),float(cell_val1)])\n    cell_val2 = sheet.cell_value(curr_row,8)\n    ph.append(float(cell_val2))\n\nmodel = linear_model.SGDClassifier()\nprint(model.fit(fa,ph))\n</code></pre>\n\n<p><img src=\"https://i.stack.imgur.com/I9J8u.png\" alt=\"Screenshot\"></p>\n\n<p>The error message screenshot:</p>\n\n<p><img src=\"https://i.stack.imgur.com/lCJTu.png\" alt=\"ERROR\"></p>\n <machine-learning><classification><python><svm><regression><p>I think that this is the same issue as in this question: <a href=\"https://stackoverflow.com/questions/24923143/x-and-y-have-incompatible-shapes\">https://stackoverflow.com/questions/24923143/x-and-y-have-incompatible-shapes</a></p>\n\n<pre><code>The shape of X must be (n_samples, n_features) as explained in the SVC.fit\ndocstring. A 1-d array is interpreted as a single sample (for convenience when      \ndoing predictions on single samples). Reshape your X to (n_samples, 1).\n</code></pre>\n\n<p>That means you should use numpy.reshape to reshape the X column. If the data frame has n rows, you should use</p>\n\n<pre><code>X_new = X.reshape(n, 1)\n</code></pre>\n\n<p>Then use the fit method with X_new. Note: you probably don't need to do this if you use two or more X columns for your model fitting.</p>\n",
                "codes": [
                    [
                        "The shape of X must be (n_samples, n_features) as explained in the SVC.fit\ndocstring. A 1-d array is interpreted as a single sample (for convenience when      \ndoing predictions on single samples). Reshape your X to (n_samples, 1).\n",
                        "X_new = X.reshape(n, 1)\n"
                    ]
                ],
                "question_id:": "6123",
                "question_votes:": "2",
                "question_text:": "<p>I have an excel file that contains details related to determining the quality of a wine and I want to implement the linear model concept using the function <strong>sklearn.linear_model.SGDClassifier(SVM => Hinge loss) and (Logarithmic regression =>log loss)</strong> using python. I learned the basics about these function through the <em>scikit learn</em> website and I am not able to implement the model using excel file. I am very new to python and machine learning and I finding it hard to implement the model. I opened the excel file in python and tried to take two columns [randomly] from the file and use that as an input to call the <strong>fit</strong> function available in the model. But, I got an error stating <strong>Unknown label type: array</strong>. I tried a couple of other methods too, but, nothing worked. Can someone guide me with the implementation process? </p>\n\n<pre><code>from xlrd import open_workbook\nfrom sklearn import linear_model\ni = 0\nfa = []\nph = []\n\nbook = open_workbook('F:/BIG DATA/winequality.xlsx')\nsheet = book.sheet_by_name('Sheet1')\nnum_rows = sheet.nrows - 1\nnum_cols = sheet.ncols - 1\ncurr_row = 0\nwhile curr_row &lt;num_rows:\n    curr_row += 1\n    cell_val = sheet.cell_value(curr_row,0)\n    cell_val1 = sheet.cell_value(curr_row,10)\n\n    fa.append([float(cell_val),float(cell_val1)])\n    cell_val2 = sheet.cell_value(curr_row,8)\n    ph.append(float(cell_val2))\n\nmodel = linear_model.SGDClassifier()\nprint(model.fit(fa,ph))\n</code></pre>\n\n<p><img src=\"https://i.stack.imgur.com/I9J8u.png\" alt=\"Screenshot\"></p>\n\n<p>The error message screenshot:</p>\n\n<p><img src=\"https://i.stack.imgur.com/lCJTu.png\" alt=\"ERROR\"></p>\n",
                "tags": "<machine-learning><classification><python><svm><regression>",
                "answers": [
                    [
                        "6124",
                        "2",
                        "6123",
                        "",
                        "",
                        "<p>I think that this is the same issue as in this question: <a href=\"https://stackoverflow.com/questions/24923143/x-and-y-have-incompatible-shapes\">https://stackoverflow.com/questions/24923143/x-and-y-have-incompatible-shapes</a></p>\n\n<pre><code>The shape of X must be (n_samples, n_features) as explained in the SVC.fit\ndocstring. A 1-d array is interpreted as a single sample (for convenience when      \ndoing predictions on single samples). Reshape your X to (n_samples, 1).\n</code></pre>\n\n<p>That means you should use numpy.reshape to reshape the X column. If the data frame has n rows, you should use</p>\n\n<pre><code>X_new = X.reshape(n, 1)\n</code></pre>\n\n<p>Then use the fit method with X_new. Note: you probably don't need to do this if you use two or more X columns for your model fitting.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "2489",
            "_score": 8.455338,
            "_source": {
                "title": "Reshaping of data for deep learning using Keras",
                "content": "Reshaping of data for deep learning using Keras <p>I am a beginner to Keras and I have started with the MNIST example to understand how the library actually works. The code snippet of MNIST problem in Keras example folder is given as :</p>\n\n<pre><code>import numpy as np\nnp.random.seed(1337)  # for reproducibility\n\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten  \nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.utils import np_utils\n\nbatch_size = 128\nnb_classes = 10\nnb_epoch = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n# number of convolutional filters to use\nnb_filters = 32\n# size of pooling area for max pooling\nnb_pool = 2\n# convolution kernel size\nnb_conv = 3\n\n# the data, shuffled and split between train and test sets\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nX_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\nX_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n..........\n</code></pre>\n\n<p>I am unable to understand the reshape function here. What is it doing and why we have applied it? </p>\n <python><neural-network><deep-learning><keras><p><code>mnist.load_data()</code> supplies the MNIST digits with structure <code>(nb_samples, 28, 28)</code> i.e. with 2 dimensions per example representing a greyscale image 28x28.</p>\n\n<p>The Convolution2D layers in Keras however, are designed to work with 3 dimensions per example. They have 4-dimensional inputs and outputs. This covers colour images <code>(nb_samples, nb_channels, width, height)</code>, but more importantly, it covers deeper layers of the network, where each example has become a set of feature maps i.e. <code>(nb_samples, nb_features, width, height)</code>.</p>\n\n<p>The greyscale image for MNIST digits input would either need a different CNN layer design (or a param to the layer constructor to accept a different shape), or the design could simply use a standard CNN and you must explicitly express the examples as 1-channel images. The Keras team chose the latter approach, which needs the re-shape.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "11704",
                "question_votes:": "10",
                "question_text:": "<p>I am a beginner to Keras and I have started with the MNIST example to understand how the library actually works. The code snippet of MNIST problem in Keras example folder is given as :</p>\n\n<pre><code>import numpy as np\nnp.random.seed(1337)  # for reproducibility\n\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten  \nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.utils import np_utils\n\nbatch_size = 128\nnb_classes = 10\nnb_epoch = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n# number of convolutional filters to use\nnb_filters = 32\n# size of pooling area for max pooling\nnb_pool = 2\n# convolution kernel size\nnb_conv = 3\n\n# the data, shuffled and split between train and test sets\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nX_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\nX_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n..........\n</code></pre>\n\n<p>I am unable to understand the reshape function here. What is it doing and why we have applied it? </p>\n",
                "tags": "<python><neural-network><deep-learning><keras>",
                "answers": [
                    [
                        "11705",
                        "2",
                        "11704",
                        "",
                        "",
                        "<p><code>mnist.load_data()</code> supplies the MNIST digits with structure <code>(nb_samples, 28, 28)</code> i.e. with 2 dimensions per example representing a greyscale image 28x28.</p>\n\n<p>The Convolution2D layers in Keras however, are designed to work with 3 dimensions per example. They have 4-dimensional inputs and outputs. This covers colour images <code>(nb_samples, nb_channels, width, height)</code>, but more importantly, it covers deeper layers of the network, where each example has become a set of feature maps i.e. <code>(nb_samples, nb_features, width, height)</code>.</p>\n\n<p>The greyscale image for MNIST digits input would either need a different CNN layer design (or a param to the layer constructor to accept a different shape), or the design could simply use a standard CNN and you must explicitly express the examples as 1-channel images. The Keras team chose the latter approach, which needs the re-shape.</p>\n",
                        "",
                        "8"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14366",
            "_score": 8.422999,
            "_source": {
                "title": "How to \"reshape\" into square matrix for numpy.linalg.solve()?",
                "content": "How to \"reshape\" into square matrix for numpy.linalg.solve()? <p>I'm trying to find the intersection of lines <span class=\"math-container\">$y=a_1x+b_1$</span> and <span class=\"math-container\">$y=a_2x+b_2$</span> using <code>numpy.linalg.solve()</code>. What I can't get my head around is how to correctly make <span class=\"math-container\">$A$</span> a square matrix for <code>solve()</code> to work. I'm familiar with solving linear equation systems, but there's something here I don't get.</p>\n\n<p>What I'd like to do is:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def meeting_lines(a1, b1, a2, b2):\n    a = np.array([[a1], [a2]])\n    b = np.array([b1, b2])\n    return np.linalg.solve(a, b)\n\ndef main():\n    a1=1\n    b1=4\n    a2=3\n    b2=2\n\n    y, x = meeting_lines(a1, b1, a2, b2)\n</code></pre>\n\n<p>Where I expect <span class=\"math-container\">$y=-3$</span> and <span class=\"math-container\">$x=1$</span>. However, this fails with <code>numpy.linalg.LinAlgError: Last 2 dimensions of the array must be square</code>.</p>\n\n<p>Thank you very much for your help, trying to figure this out has messed up my day already!</p>\n <numpy><linear-algebra><p>You should formulate your lines as follows to have <span class=\"math-container\">$(x, y)$</span> as unknowns:\n<span class=\"math-container\">$$\\begin{align}\n\\left.\\begin{matrix}\na_1x-y=-b_1\\\\\na_2x-y=-b_2\n\\end{matrix}\\right\\}\n\\rightarrow\n\\overbrace{\n\\begin{bmatrix}\n a_1&amp; -1\\\\ \n a_2&amp; -1\n\\end{bmatrix}\n}^{\\boldsymbol{a}}\n\\overbrace{\n\\begin{bmatrix}\n x\\\\ \n y\n\\end{bmatrix}\n}^{\\boldsymbol{x}}\n=\n\\overbrace{\n\\begin{bmatrix}\n -b_1\\\\ \n -b_2\n\\end{bmatrix}\n}^{\\boldsymbol{b}}\n\\end{align}$$</span>\nTherefore, the code should be:</p>\n\n<pre><code>import numpy as np\n\ndef meeting_lines(a1, b1, a2, b2):\n    a = np.array([[a1, -1], [a2, -1]])\n    b = np.array([-b1, -b2])\n    return np.linalg.solve(a, b)\n\na1=1\nb1=4\na2=3\nb2=2\nx, y = meeting_lines(a1, b1, a2, b2)\nprint(x, y)\n</code></pre>\n\n<p>which outputs:</p>\n\n<pre><code>1.0 5.0\n</code></pre>\n",
                "codes": [
                    [
                        "import numpy as np\n\ndef meeting_lines(a1, b1, a2, b2):\n    a = np.array([[a1, -1], [a2, -1]])\n    b = np.array([-b1, -b2])\n    return np.linalg.solve(a, b)\n\na1=1\nb1=4\na2=3\nb2=2\nx, y = meeting_lines(a1, b1, a2, b2)\nprint(x, y)\n",
                        "1.0 5.0\n"
                    ]
                ],
                "question_id:": "48345",
                "question_votes:": "1",
                "question_text:": "<p>I'm trying to find the intersection of lines <span class=\"math-container\">$y=a_1x+b_1$</span> and <span class=\"math-container\">$y=a_2x+b_2$</span> using <code>numpy.linalg.solve()</code>. What I can't get my head around is how to correctly make <span class=\"math-container\">$A$</span> a square matrix for <code>solve()</code> to work. I'm familiar with solving linear equation systems, but there's something here I don't get.</p>\n\n<p>What I'd like to do is:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def meeting_lines(a1, b1, a2, b2):\n    a = np.array([[a1], [a2]])\n    b = np.array([b1, b2])\n    return np.linalg.solve(a, b)\n\ndef main():\n    a1=1\n    b1=4\n    a2=3\n    b2=2\n\n    y, x = meeting_lines(a1, b1, a2, b2)\n</code></pre>\n\n<p>Where I expect <span class=\"math-container\">$y=-3$</span> and <span class=\"math-container\">$x=1$</span>. However, this fails with <code>numpy.linalg.LinAlgError: Last 2 dimensions of the array must be square</code>.</p>\n\n<p>Thank you very much for your help, trying to figure this out has messed up my day already!</p>\n",
                "tags": "<numpy><linear-algebra>",
                "answers": [
                    [
                        "48352",
                        "2",
                        "48345",
                        "",
                        "",
                        "<p>You should formulate your lines as follows to have <span class=\"math-container\">$(x, y)$</span> as unknowns:\n<span class=\"math-container\">$$\\begin{align}\n\\left.\\begin{matrix}\na_1x-y=-b_1\\\\\na_2x-y=-b_2\n\\end{matrix}\\right\\}\n\\rightarrow\n\\overbrace{\n\\begin{bmatrix}\n a_1&amp; -1\\\\ \n a_2&amp; -1\n\\end{bmatrix}\n}^{\\boldsymbol{a}}\n\\overbrace{\n\\begin{bmatrix}\n x\\\\ \n y\n\\end{bmatrix}\n}^{\\boldsymbol{x}}\n=\n\\overbrace{\n\\begin{bmatrix}\n -b_1\\\\ \n -b_2\n\\end{bmatrix}\n}^{\\boldsymbol{b}}\n\\end{align}$$</span>\nTherefore, the code should be:</p>\n\n<pre><code>import numpy as np\n\ndef meeting_lines(a1, b1, a2, b2):\n    a = np.array([[a1, -1], [a2, -1]])\n    b = np.array([-b1, -b2])\n    return np.linalg.solve(a, b)\n\na1=1\nb1=4\na2=3\nb2=2\nx, y = meeting_lines(a1, b1, a2, b2)\nprint(x, y)\n</code></pre>\n\n<p>which outputs:</p>\n\n<pre><code>1.0 5.0\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7240",
            "_score": 8.418906,
            "_source": {
                "title": "TensorFlow: trainable_variables() is empty",
                "content": "TensorFlow: trainable_variables() is empty <p>I want to retrieve the list of trainable variables/weights in my model (wrapped in a <code>tf.Estimator</code>). However, <code>tf.trainable_variables</code> always returns an empty list, what am I doing wrong?</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport sys\nimport globals\nimport pkg_resources\nimport numpy as np\n\nimport tensorflow as tf\n\n\ndef cnn_model_fn(features, labels, mode):\n\n    input_layer = tf.reshape(features[\"x\"], [-1, 51, 13])\n    input_layer = tf.cast(input_layer, tf.float32)\n\n    # Convolutional Layer #1\n    conv1 = tf.layers.conv1d(inputs=input_layer, filters=32, kernel_size=5, padding=\"same\", activation=tf.nn.relu)\n\n    # Pooling Layer #1\n    pool1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2)\n\n    # Convolutional Layer #2 and Pooling Layer #2\n    conv2 = tf.layers.conv1d(inputs=pool1, filters=64, kernel_size=5, padding=\"same\", activation=tf.nn.relu)\n\n    # Pooling layer #2\n    pool2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2)\n\n    # flatten the feature map\n    pool2_flat = tf.reshape(pool2, [-1, 12 * 64])\n\n    # Dense Layer\n    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n\n    # Logits Layer\n    logits = tf.layers.dense(inputs=dropout, units=5)\n\n    predictions = {\n        # Generate predictions (for PREDICT and EVAL mode)\n        \"classes\": tf.argmax(input=logits, axis=1),\n        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the `logging_hook`.\n        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n    }\n\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n    # Calculate Loss (for both TRAIN and EVAL modes)\n    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\n    # Configure the Training Op (for TRAIN mode)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n    # Add evaluation metrics (for EVAL mode)\n    eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n\ndef main(unused_argv):\n\n    total = pd.read_feather('testfile.feather')\n    labels = total['labels']\n    features = total.iloc[:, 16:679]\n\n    mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"/tmp/gait_convnet_model\")\n\n    # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n    logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)    \n\n    # Train the model\n    train_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": np.array(features)}, y=np.array(labels), batch_size=100, num_epochs=None, shuffle=True)\n    mnist_classifier.train(input_fn=train_input_fn, steps=1, hooks=[logging_hook])\n\n    temp_list = tf.trainable_variables()\n    print(temp_list)\n\nif __name__ == '__main__':\n    tf.app.run()\n</code></pre>\n <python><neural-network><tensorflow><convolution><p>There are functions in the Estimator class that handle this, namely: <code>get_variable_names</code> and <code>get_variable_value</code>. </p>\n\n<p>I guess they want to avoid polluting the global scope. Note that you can pass a <code>name</code> parameter to your layers on creation to disambiguate them.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "27288",
                "question_votes:": "1",
                "question_text:": "<p>I want to retrieve the list of trainable variables/weights in my model (wrapped in a <code>tf.Estimator</code>). However, <code>tf.trainable_variables</code> always returns an empty list, what am I doing wrong?</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport sys\nimport globals\nimport pkg_resources\nimport numpy as np\n\nimport tensorflow as tf\n\n\ndef cnn_model_fn(features, labels, mode):\n\n    input_layer = tf.reshape(features[\"x\"], [-1, 51, 13])\n    input_layer = tf.cast(input_layer, tf.float32)\n\n    # Convolutional Layer #1\n    conv1 = tf.layers.conv1d(inputs=input_layer, filters=32, kernel_size=5, padding=\"same\", activation=tf.nn.relu)\n\n    # Pooling Layer #1\n    pool1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2)\n\n    # Convolutional Layer #2 and Pooling Layer #2\n    conv2 = tf.layers.conv1d(inputs=pool1, filters=64, kernel_size=5, padding=\"same\", activation=tf.nn.relu)\n\n    # Pooling layer #2\n    pool2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2)\n\n    # flatten the feature map\n    pool2_flat = tf.reshape(pool2, [-1, 12 * 64])\n\n    # Dense Layer\n    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n\n    # Logits Layer\n    logits = tf.layers.dense(inputs=dropout, units=5)\n\n    predictions = {\n        # Generate predictions (for PREDICT and EVAL mode)\n        \"classes\": tf.argmax(input=logits, axis=1),\n        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the `logging_hook`.\n        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n    }\n\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n    # Calculate Loss (for both TRAIN and EVAL modes)\n    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\n    # Configure the Training Op (for TRAIN mode)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n    # Add evaluation metrics (for EVAL mode)\n    eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n\ndef main(unused_argv):\n\n    total = pd.read_feather('testfile.feather')\n    labels = total['labels']\n    features = total.iloc[:, 16:679]\n\n    mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"/tmp/gait_convnet_model\")\n\n    # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n    logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)    \n\n    # Train the model\n    train_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": np.array(features)}, y=np.array(labels), batch_size=100, num_epochs=None, shuffle=True)\n    mnist_classifier.train(input_fn=train_input_fn, steps=1, hooks=[logging_hook])\n\n    temp_list = tf.trainable_variables()\n    print(temp_list)\n\nif __name__ == '__main__':\n    tf.app.run()\n</code></pre>\n",
                "tags": "<python><neural-network><tensorflow><convolution>",
                "answers": [
                    [
                        "30632",
                        "2",
                        "27288",
                        "",
                        "",
                        "<p>There are functions in the Estimator class that handle this, namely: <code>get_variable_names</code> and <code>get_variable_value</code>. </p>\n\n<p>I guess they want to avoid polluting the global scope. Note that you can pass a <code>name</code> parameter to your layers on creation to disambiguate them.</p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12976",
            "_score": 8.406087,
            "_source": {
                "title": "Faster 3D Matrix Operation - Python",
                "content": "Faster 3D Matrix Operation - Python <p>I am working with 3D matrix in Python, for example, given matrix like this with size of 2x3x4:</p>\n\n<pre><code>[[[1 2 1 4]\n  [3 2 1 1]\n  [4 3 1 4]]\n\n [[2 1 3 3]\n  [1 4 2 1]\n  [3 2 3 3]]]\n</code></pre>\n\n<p>I have task to find the value of entropy in each row in each dimension matrix. For example, in row 1 of dimension 1 of the matrix above <code>[1,2,1,4]</code>, the normalized value (as such the total sum is 1) is <code>[0.125, 0.25, 0.125, 0.5]</code> and the value of entropy is calculated by the formula <code>-sum(i*log(i))</code> where i is the normalized value. The resulting matrix is a 2x3 matrix where in each dimension there are 3 values of entropy (because there are 3 rows).</p>\n\n<p>Here is the working example of my code using random matrix each time:</p>\n\n<pre><code>from scipy.stats import entropy\nimport numpy as np\n\nmatrix = np.random.randint(low=1,high=5,size=(2,3,4)) #how if size is (200,50,1000)\nentropy_matrix=np.zeros((matrix.shape[0],matrix.shape[1]))\nfor i in range(matrix.shape[0]):\n    normalized = np.array([float(k)/np.sum(j) for j in matrix[i] for k in j]).reshape(matrix.shape[1],matrix.shape[2])\n    entropy_matrix[i] = np.array([entropy(m) for m in normalized])\n</code></pre>\n\n<p>My question is how do I scale-up this program to work with very large 3D matrix (for example with size of 200x50x1000) ?</p>\n\n<p>I am using Python in Windows 10 (with Anaconda distribution). \nUsing 3D matrix size of 200x50x1000, I got running time of 290 s on my computer.</p>\n <python><numpy><scipy><matrix><p>It is faster if you use the built-in functions of numpy (instead of reimplementing them yourself):</p>\n\n<pre><code>import numpy as np\nfrom scipy.stats import entropy\n\nnp.apply_along_axis(func1d=entropy, axis=2, arr=matrix)\n</code></pre>\n",
                "codes": [
                    [
                        "import numpy as np\nfrom scipy.stats import entropy\n\nnp.apply_along_axis(func1d=entropy, axis=2, arr=matrix)\n"
                    ]
                ],
                "question_id:": "44999",
                "question_votes:": "",
                "question_text:": "<p>I am working with 3D matrix in Python, for example, given matrix like this with size of 2x3x4:</p>\n\n<pre><code>[[[1 2 1 4]\n  [3 2 1 1]\n  [4 3 1 4]]\n\n [[2 1 3 3]\n  [1 4 2 1]\n  [3 2 3 3]]]\n</code></pre>\n\n<p>I have task to find the value of entropy in each row in each dimension matrix. For example, in row 1 of dimension 1 of the matrix above <code>[1,2,1,4]</code>, the normalized value (as such the total sum is 1) is <code>[0.125, 0.25, 0.125, 0.5]</code> and the value of entropy is calculated by the formula <code>-sum(i*log(i))</code> where i is the normalized value. The resulting matrix is a 2x3 matrix where in each dimension there are 3 values of entropy (because there are 3 rows).</p>\n\n<p>Here is the working example of my code using random matrix each time:</p>\n\n<pre><code>from scipy.stats import entropy\nimport numpy as np\n\nmatrix = np.random.randint(low=1,high=5,size=(2,3,4)) #how if size is (200,50,1000)\nentropy_matrix=np.zeros((matrix.shape[0],matrix.shape[1]))\nfor i in range(matrix.shape[0]):\n    normalized = np.array([float(k)/np.sum(j) for j in matrix[i] for k in j]).reshape(matrix.shape[1],matrix.shape[2])\n    entropy_matrix[i] = np.array([entropy(m) for m in normalized])\n</code></pre>\n\n<p>My question is how do I scale-up this program to work with very large 3D matrix (for example with size of 200x50x1000) ?</p>\n\n<p>I am using Python in Windows 10 (with Anaconda distribution). \nUsing 3D matrix size of 200x50x1000, I got running time of 290 s on my computer.</p>\n",
                "tags": "<python><numpy><scipy><matrix>",
                "answers": [
                    [
                        "45000",
                        "2",
                        "44999",
                        "",
                        "",
                        "<p>It is faster if you use the built-in functions of numpy (instead of reimplementing them yourself):</p>\n\n<pre><code>import numpy as np\nfrom scipy.stats import entropy\n\nnp.apply_along_axis(func1d=entropy, axis=2, arr=matrix)\n</code></pre>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "2100",
            "_score": 8.400698,
            "_source": {
                "title": "Error with Convolutional Neural Network (SGD?)",
                "content": "Error with Convolutional Neural Network (SGD?) <p>I'm implementing a CNN with Numpy and Scipy to solidify my understanding, but I'm encountering a rather strange problem.</p>\n\n<p>My layers are: input -> conv -> pool -> FC</p>\n\n<p>Here are the relevant functions:</p>\n\n<pre><code>def unpackTheta (theta, filterSize, numFilters, pooledDim, outputSize):\n    a = filterSize ** 2 * numFilters\n    b = a + numFilters\n    c = b + pooledDim ** 2 * numFilters * outputSize\n    d = c + outputSize\n    return (np.reshape(theta[0 : a], (filterSize, filterSize, numFilters)),\n            np.reshape(theta[a : b], (numFilters)),\n            np.reshape(theta[b : c], (pooledDim ** 2 * numFilters, outputSize)),\n            np.reshape(theta[c : d], (outputSize)))\n\ndef getConvolution (features, Wc, Bc, numFilters, numImages, filteredSize):\n    conv = np.zeros((filteredSize, filteredSize, numFilters, numImages))\n    for imageNum in range(numImages):\n        image = features[:, :, imageNum]\n        for filterNum in range(numFilters):\n            filterLayer = np.rot90(Wc[:, :, filterNum], 2)\n            conv[:, :, filterNum, imageNum] = sigmoid(convolve2d(image, filterLayer, 'valid') + Bc[filterNum])\n    return conv\n\ndef getPooled (features, poolSize, pooledSize, filteredSize, numFilters, numImages):\n    ret = np.empty((pooledSize, pooledSize, numFilters, numImages))\n    poolFilter = np.ones((poolSize, poolSize)) / poolSize ** 2\n    for i in range(numFilters): \n        for j in range(numImages):\n            pooledLayer = convolve2d(features[:, :, i, j], poolFilter, 'valid')\n            for x in range(0, filteredSize, poolSize):\n                for y in range(0, filteredSize, poolSize):\n                    ret[x / poolSize, y / poolSize, i, j] = pooledLayer[x, y]\n    return ret\n\ndef getCost (theta, *args) :\n    ## Initializing variables\n    features, inputSize, filterSize, numFilters, poolSize, outputSize, reg = args\n    filteredSize = inputSize - filterSize + 1\n    pooledSize = filteredSize / poolSize\n    (Wc, Bc, Wr, Br) = unpackTheta(theta, filterSize, numFilters, pooledSize, outputSize)\n    numImages = np.size(features, 0)\n\n    actualValues = np.eye(outputSize)[features[:, 0]]\n    features = np.reshape(features[:, 1:] / 255.0, (inputSize, inputSize, numImages))\n\n    ## Forward propagation\n    # Convolution\n    conv = getConvolution(features, Wc, Bc, numFilters, numImages, filteredSize)\n\n    # Mean pooling\n    pooled = np.reshape(getPooled(conv, poolSize, pooledSize, filteredSize, numFilters, numImages), (-1, numImages))\n\n    # Logistic regression\n    calcValues = sigmoid(pooled.transpose().dot(Wr) + Br)\n\n    ## Calculating cost\n    cost = -np.sum(actualValues * np.log(calcValues) + (1 - actualValues) * np.log(1 - calcValues)) / numImages\n    cost += reg * (np.sum(Wc ** 2) + np.sum(Wr ** 2)) / (2 * numImages)\n\n    ## Back propagation\n\n    #print Wr\n    #print Br\n    outputError = (calcValues - actualValues) \n\n    pooledError = Wr.dot(outputError.transpose())\n    pooledError = np.reshape(pooledError, (pooledSize, pooledSize, numFilters, numImages))\n\n    convError = np.empty((filteredSize, filteredSize, numFilters, numImages))\n    convErrorFilter = np.ones((poolSize, poolSize)) / (poolSize ** 2)\n    for i in range(numFilters):\n        for j in range(numImages):\n            convError[:, :, i, j] = np.kron(pooledError[:, :, i, j], convErrorFilter)\n\n    convError *= conv * (1 - conv)\n\n    ## Gradient\n\n    WrGrad = pooled.dot(outputError)\n    BrGrad = np.sum(outputError, 0)\n\n    WcGrad = np.zeros((filterSize, filterSize, numFilters))\n    BcGrad = np.empty(numFilters)\n\n    for i in range(numFilters):\n        BcGrad[i] = np.sum(convError[:, :, i, :])\n        for j in range(numImages): \n            filterLayer = np.rot90(convError[:, :, i, j], 2)\n            WcGrad[:, :, i] += convolve2d(features[:, :, j], filterLayer, 'valid')\n\n    WrGrad /= numImages\n    WcGrad /= numImages\n    BrGrad /= numImages\n    BcGrad /= numImages\n\n    WrGrad += reg * Wr / numImages\n    WcGrad += reg * Wc / numImages\n\n    global costCache\n    costCache = cost\n    return (cost, np.concatenate((WcGrad.flatten(), BcGrad.flatten(), WrGrad.flatten(), BrGrad.flatten()), axis=0))\n</code></pre>\n\n<p>I implemented a numerical gradient to verify if it was returning the right values, and it was. However, my softmax regression seems to be predicting the same value across the entire batch when I do SGD.</p>\n\n<p>However, when I use scipy.minimize function, it gives me different values for softmax regression</p>\n\n<p>Any help is greatly appreciated.</p>\n <machine-learning><neural-network>",
                "codes": [],
                "question_id:": "10564",
                "question_votes:": "1",
                "question_text:": "<p>I'm implementing a CNN with Numpy and Scipy to solidify my understanding, but I'm encountering a rather strange problem.</p>\n\n<p>My layers are: input -> conv -> pool -> FC</p>\n\n<p>Here are the relevant functions:</p>\n\n<pre><code>def unpackTheta (theta, filterSize, numFilters, pooledDim, outputSize):\n    a = filterSize ** 2 * numFilters\n    b = a + numFilters\n    c = b + pooledDim ** 2 * numFilters * outputSize\n    d = c + outputSize\n    return (np.reshape(theta[0 : a], (filterSize, filterSize, numFilters)),\n            np.reshape(theta[a : b], (numFilters)),\n            np.reshape(theta[b : c], (pooledDim ** 2 * numFilters, outputSize)),\n            np.reshape(theta[c : d], (outputSize)))\n\ndef getConvolution (features, Wc, Bc, numFilters, numImages, filteredSize):\n    conv = np.zeros((filteredSize, filteredSize, numFilters, numImages))\n    for imageNum in range(numImages):\n        image = features[:, :, imageNum]\n        for filterNum in range(numFilters):\n            filterLayer = np.rot90(Wc[:, :, filterNum], 2)\n            conv[:, :, filterNum, imageNum] = sigmoid(convolve2d(image, filterLayer, 'valid') + Bc[filterNum])\n    return conv\n\ndef getPooled (features, poolSize, pooledSize, filteredSize, numFilters, numImages):\n    ret = np.empty((pooledSize, pooledSize, numFilters, numImages))\n    poolFilter = np.ones((poolSize, poolSize)) / poolSize ** 2\n    for i in range(numFilters): \n        for j in range(numImages):\n            pooledLayer = convolve2d(features[:, :, i, j], poolFilter, 'valid')\n            for x in range(0, filteredSize, poolSize):\n                for y in range(0, filteredSize, poolSize):\n                    ret[x / poolSize, y / poolSize, i, j] = pooledLayer[x, y]\n    return ret\n\ndef getCost (theta, *args) :\n    ## Initializing variables\n    features, inputSize, filterSize, numFilters, poolSize, outputSize, reg = args\n    filteredSize = inputSize - filterSize + 1\n    pooledSize = filteredSize / poolSize\n    (Wc, Bc, Wr, Br) = unpackTheta(theta, filterSize, numFilters, pooledSize, outputSize)\n    numImages = np.size(features, 0)\n\n    actualValues = np.eye(outputSize)[features[:, 0]]\n    features = np.reshape(features[:, 1:] / 255.0, (inputSize, inputSize, numImages))\n\n    ## Forward propagation\n    # Convolution\n    conv = getConvolution(features, Wc, Bc, numFilters, numImages, filteredSize)\n\n    # Mean pooling\n    pooled = np.reshape(getPooled(conv, poolSize, pooledSize, filteredSize, numFilters, numImages), (-1, numImages))\n\n    # Logistic regression\n    calcValues = sigmoid(pooled.transpose().dot(Wr) + Br)\n\n    ## Calculating cost\n    cost = -np.sum(actualValues * np.log(calcValues) + (1 - actualValues) * np.log(1 - calcValues)) / numImages\n    cost += reg * (np.sum(Wc ** 2) + np.sum(Wr ** 2)) / (2 * numImages)\n\n    ## Back propagation\n\n    #print Wr\n    #print Br\n    outputError = (calcValues - actualValues) \n\n    pooledError = Wr.dot(outputError.transpose())\n    pooledError = np.reshape(pooledError, (pooledSize, pooledSize, numFilters, numImages))\n\n    convError = np.empty((filteredSize, filteredSize, numFilters, numImages))\n    convErrorFilter = np.ones((poolSize, poolSize)) / (poolSize ** 2)\n    for i in range(numFilters):\n        for j in range(numImages):\n            convError[:, :, i, j] = np.kron(pooledError[:, :, i, j], convErrorFilter)\n\n    convError *= conv * (1 - conv)\n\n    ## Gradient\n\n    WrGrad = pooled.dot(outputError)\n    BrGrad = np.sum(outputError, 0)\n\n    WcGrad = np.zeros((filterSize, filterSize, numFilters))\n    BcGrad = np.empty(numFilters)\n\n    for i in range(numFilters):\n        BcGrad[i] = np.sum(convError[:, :, i, :])\n        for j in range(numImages): \n            filterLayer = np.rot90(convError[:, :, i, j], 2)\n            WcGrad[:, :, i] += convolve2d(features[:, :, j], filterLayer, 'valid')\n\n    WrGrad /= numImages\n    WcGrad /= numImages\n    BrGrad /= numImages\n    BcGrad /= numImages\n\n    WrGrad += reg * Wr / numImages\n    WcGrad += reg * Wc / numImages\n\n    global costCache\n    costCache = cost\n    return (cost, np.concatenate((WcGrad.flatten(), BcGrad.flatten(), WrGrad.flatten(), BrGrad.flatten()), axis=0))\n</code></pre>\n\n<p>I implemented a numerical gradient to verify if it was returning the right values, and it was. However, my softmax regression seems to be predicting the same value across the entire batch when I do SGD.</p>\n\n<p>However, when I use scipy.minimize function, it gives me different values for softmax regression</p>\n\n<p>Any help is greatly appreciated.</p>\n",
                "tags": "<machine-learning><neural-network>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15226",
            "_score": 8.376503,
            "_source": {
                "title": "conv2d function in pytorch",
                "content": "conv2d function in pytorch <p>I'm trying to use the function <a href=\"https://pytorch.org/docs/stable/nn.html#id22\" rel=\"nofollow noreferrer\">torch.conv2d</a> from Pytorch but can't get a result I understand...</p>\n\n<p>Here is a simple example where the kernel (<code>filt</code>) is the same size as the input (<code>im</code>) to explain what I'm looking for.</p>\n\n<pre><code>import pytorch\n\nfilt = torch.rand(3, 3)\nim = torch.rand(3, 3)\n</code></pre>\n\n<p><em>I want to compute a simple convolution with no padding</em>, so the result should be a scalar (i.e. a 1x1 tensor).</p>\n\n<p>I tried this with <code>conv2d</code>:</p>\n\n<pre><code># I have to convert image and kernel to 4 dimensions tensors to use conv2d\nim_torch = im.reshape((im_height, filt_height, 1, 1))\nfilt_torch = filt.reshape((filt_height, im_height, 1, 1))\nout = torch.nn.functional.conv2d(im_torch, filt_torch, stride=1, padding=0)\nprint(out)\n</code></pre>\n\n<p>But the result is not what I expected:</p>\n\n<pre><code>tensor([[[[0.6067]], [[0.3564]], [[0.5397]]],\n    [[[0.2557]], [[0.0493]], [[0.2562]]],\n    [[[0.6067]], [[0.3564]], [[0.5397]]]])\n</code></pre>\n\n<p>To give an idea of what I'd like, I want to reproduce scipy <code>convolve2d</code> behavior:</p>\n\n<pre><code>import scipy.signal\nout_scipy = scipy.signal.convolve2d(im.detach().numpy(), filt.detach().numpy(), 'valid')\nprint(out_scipy)\n</code></pre>\n\n<p>which prints:</p>\n\n<pre><code>array([[1.195723]], dtype=float32)\n</code></pre>\n <python><convolution><pytorch><p>Ok, I didn't find the exact answer to my question (i.e. how to use conv2d) but I found another way to do it.</p>\n\n<p>First of all, I learned that I'm looking for is called a <em>valid</em> cross-correlation and it is actually the operation implemented by the <code>[Conv2d][1]</code> class.</p>\n\n<p>Hence my solution uses the <code>Conv2d</code> class instead of the <code>conv2d</code> function.</p>\n\n<pre><code>import pytorch\n\nimg = torch.rand(3, 3)\n\nmodel = torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 3), stride=1, padding=0, bias=False)\n\nres = conv_mdl(img)\nprint(res.shape)\n</code></pre>\n\n<p>Which prints the scalar I wanted:</p>\n\n<pre><code>torch.Size([1, 1, 1, 1])\n</code></pre>\n\n<p>PS: I also checked that the result is the right one, not just the dimension.</p>\n",
                "codes": [
                    [
                        "import pytorch\n\nimg = torch.rand(3, 3)\n\nmodel = torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 3), stride=1, padding=0, bias=False)\n\nres = conv_mdl(img)\nprint(res.shape)\n",
                        "torch.Size([1, 1, 1, 1])\n"
                    ]
                ],
                "question_id:": "51452",
                "question_votes:": "1",
                "question_text:": "<p>I'm trying to use the function <a href=\"https://pytorch.org/docs/stable/nn.html#id22\" rel=\"nofollow noreferrer\">torch.conv2d</a> from Pytorch but can't get a result I understand...</p>\n\n<p>Here is a simple example where the kernel (<code>filt</code>) is the same size as the input (<code>im</code>) to explain what I'm looking for.</p>\n\n<pre><code>import pytorch\n\nfilt = torch.rand(3, 3)\nim = torch.rand(3, 3)\n</code></pre>\n\n<p><em>I want to compute a simple convolution with no padding</em>, so the result should be a scalar (i.e. a 1x1 tensor).</p>\n\n<p>I tried this with <code>conv2d</code>:</p>\n\n<pre><code># I have to convert image and kernel to 4 dimensions tensors to use conv2d\nim_torch = im.reshape((im_height, filt_height, 1, 1))\nfilt_torch = filt.reshape((filt_height, im_height, 1, 1))\nout = torch.nn.functional.conv2d(im_torch, filt_torch, stride=1, padding=0)\nprint(out)\n</code></pre>\n\n<p>But the result is not what I expected:</p>\n\n<pre><code>tensor([[[[0.6067]], [[0.3564]], [[0.5397]]],\n    [[[0.2557]], [[0.0493]], [[0.2562]]],\n    [[[0.6067]], [[0.3564]], [[0.5397]]]])\n</code></pre>\n\n<p>To give an idea of what I'd like, I want to reproduce scipy <code>convolve2d</code> behavior:</p>\n\n<pre><code>import scipy.signal\nout_scipy = scipy.signal.convolve2d(im.detach().numpy(), filt.detach().numpy(), 'valid')\nprint(out_scipy)\n</code></pre>\n\n<p>which prints:</p>\n\n<pre><code>array([[1.195723]], dtype=float32)\n</code></pre>\n",
                "tags": "<python><convolution><pytorch>",
                "answers": [
                    [
                        "51881",
                        "2",
                        "51452",
                        "",
                        "",
                        "<p>Ok, I didn't find the exact answer to my question (i.e. how to use conv2d) but I found another way to do it.</p>\n\n<p>First of all, I learned that I'm looking for is called a <em>valid</em> cross-correlation and it is actually the operation implemented by the <code>[Conv2d][1]</code> class.</p>\n\n<p>Hence my solution uses the <code>Conv2d</code> class instead of the <code>conv2d</code> function.</p>\n\n<pre><code>import pytorch\n\nimg = torch.rand(3, 3)\n\nmodel = torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 3), stride=1, padding=0, bias=False)\n\nres = conv_mdl(img)\nprint(res.shape)\n</code></pre>\n\n<p>Which prints the scalar I wanted:</p>\n\n<pre><code>torch.Size([1, 1, 1, 1])\n</code></pre>\n\n<p>PS: I also checked that the result is the right one, not just the dimension.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4585",
            "_score": 8.332417,
            "_source": {
                "title": "Incorrect output dimension?",
                "content": "Incorrect output dimension? <p>I am trying to start the learning of a cnn network which has 72 input and one output being a vector of length 24 stating the a class for each third input 72/24 = 3. There are 145 classes. </p>\n\n<p>this is how i've designed the network currently passed my data:</p>\n\n<pre><code>print \"After test_output/input\"\n\nprint \"Length:\"\nprint len(data_train_input)\nprint len(data_train_output)\n\nprint len(data_test_input)\nprint len(data_test_output)\n\nprint \"Type;\"\nprint type(data_train_input[0])\nprint type(data_train_output[0])\n\nprint \"Size [0]\"\nprint data_train_input[0].shape\nprint data_train_output[0].shape\n\nlist_of_input = [Input(shape = (78,3)) for i in range(72)]\nlist_of_conv_output = []\nlist_of_max_out = []\nfor i in range(72):\n    list_of_conv_output.append(Conv1D(filters = 32 , kernel_size = 6 , padding = \"same\", activation = 'relu')(list_of_input[i]))\n    list_of_max_out.append(MaxPooling1D(pool_size=3)(list_of_conv_output[i]))\n\nmerge = keras.layers.concatenate(list_of_max_out)\nreshape = Reshape((-1,))(merge)\n\ndense1 = Dense(500, activation = 'relu')(reshape)\ndense2 = Dense(250,activation = 'relu')(dense1)\ndense3 = Dense(1 ,activation = 'softmax')(dense2)\n\nmodel = Model(inputs = list_of_input , outputs = dense3)\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\" , metrics = [metrics.sparse_categorical_accuracy])\n\nreduce_lr=ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, mode='auto', epsilon=0.01, cooldown=0, min_lr=0.000000000000000000001)\nstop  = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n\nprint \"Train!\"\nlist_train_input = []\nlist_test_input = []\n\nfor i in range(len(data_train_input)):\n    list_train_input.append(data_train_input[i])\n\nfor i in range(len(data_test_input)):\n    list_test_input.append(data_test_input[i])\n\nhist_current = model.fit(x = [np.array(list_train_input[i]) for i in range(72)],\n                    y = np.array(data_train_output),\n                    shuffle=False,\n                    validation_data=([np.array(list_test_input[i]) for i in range(72)], np.array(data_test_output)),\n                    validation_split=0.1,\n                    epochs=150000,\n                    verbose=1,\n                    callbacks=[reduce_lr,stop])\n</code></pre>\n\n<p>Which generates this output: </p>\n\n<pre><code>After test_output/input\nLength:\n9436\n9417\n1017\n1035\nType;\n&lt;type 'numpy.ndarray'&gt;\n&lt;type 'numpy.ndarray'&gt;\nSize [0]\n(72, 78, 3)\n(24,)\nTrain!\nTraceback (most recent call last):\n  File \"keras_cnn_phoneme_classification.py\", line 382, in &lt;module&gt;\n    model(train_input_data_interweawed_normalized, output_train, test_input_data_interweawed_normalized, output_test, test_name_interweawed_normalized)\n  File \"keras_cnn_phoneme_classification.py\", line 361, in model\n    callbacks=[reduce_lr,stop])\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 1405, in fit\n    batch_size=batch_size)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 1299, in _standardize_user_data\n    exception_prefix='model target')\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 133, in _standardize_input_data\n    str(array.shape))\nValueError: Error when checking model target: expected dense_3 to have shape (None, 1) but got array with shape (9417, 24)\n</code></pre>\n\n<p>Why am i getting this error? \nI tried changing the output size of the dense3 to many  different?  but is is it expecting?</p>\n <python><keras><convnet><p>The error message is pretty clear... you feed a vector of length 24 to your model, but your model is outputting a vector of length 1.</p>\n\n<p>Change :</p>\n\n<pre><code>dense3 = Dense(1 ,activation = 'softmax')(dense2)\n</code></pre>\n\n<p>to :</p>\n\n<pre><code>dense3 = Dense(24 ,activation = 'softmax')(dense2)\n</code></pre>\n",
                "codes": [
                    [
                        "dense3 = Dense(1 ,activation = 'softmax')(dense2)\n",
                        "dense3 = Dense(24 ,activation = 'softmax')(dense2)\n"
                    ]
                ],
                "question_id:": "18080",
                "question_votes:": "",
                "question_text:": "<p>I am trying to start the learning of a cnn network which has 72 input and one output being a vector of length 24 stating the a class for each third input 72/24 = 3. There are 145 classes. </p>\n\n<p>this is how i've designed the network currently passed my data:</p>\n\n<pre><code>print \"After test_output/input\"\n\nprint \"Length:\"\nprint len(data_train_input)\nprint len(data_train_output)\n\nprint len(data_test_input)\nprint len(data_test_output)\n\nprint \"Type;\"\nprint type(data_train_input[0])\nprint type(data_train_output[0])\n\nprint \"Size [0]\"\nprint data_train_input[0].shape\nprint data_train_output[0].shape\n\nlist_of_input = [Input(shape = (78,3)) for i in range(72)]\nlist_of_conv_output = []\nlist_of_max_out = []\nfor i in range(72):\n    list_of_conv_output.append(Conv1D(filters = 32 , kernel_size = 6 , padding = \"same\", activation = 'relu')(list_of_input[i]))\n    list_of_max_out.append(MaxPooling1D(pool_size=3)(list_of_conv_output[i]))\n\nmerge = keras.layers.concatenate(list_of_max_out)\nreshape = Reshape((-1,))(merge)\n\ndense1 = Dense(500, activation = 'relu')(reshape)\ndense2 = Dense(250,activation = 'relu')(dense1)\ndense3 = Dense(1 ,activation = 'softmax')(dense2)\n\nmodel = Model(inputs = list_of_input , outputs = dense3)\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\" , metrics = [metrics.sparse_categorical_accuracy])\n\nreduce_lr=ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, mode='auto', epsilon=0.01, cooldown=0, min_lr=0.000000000000000000001)\nstop  = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n\nprint \"Train!\"\nlist_train_input = []\nlist_test_input = []\n\nfor i in range(len(data_train_input)):\n    list_train_input.append(data_train_input[i])\n\nfor i in range(len(data_test_input)):\n    list_test_input.append(data_test_input[i])\n\nhist_current = model.fit(x = [np.array(list_train_input[i]) for i in range(72)],\n                    y = np.array(data_train_output),\n                    shuffle=False,\n                    validation_data=([np.array(list_test_input[i]) for i in range(72)], np.array(data_test_output)),\n                    validation_split=0.1,\n                    epochs=150000,\n                    verbose=1,\n                    callbacks=[reduce_lr,stop])\n</code></pre>\n\n<p>Which generates this output: </p>\n\n<pre><code>After test_output/input\nLength:\n9436\n9417\n1017\n1035\nType;\n&lt;type 'numpy.ndarray'&gt;\n&lt;type 'numpy.ndarray'&gt;\nSize [0]\n(72, 78, 3)\n(24,)\nTrain!\nTraceback (most recent call last):\n  File \"keras_cnn_phoneme_classification.py\", line 382, in &lt;module&gt;\n    model(train_input_data_interweawed_normalized, output_train, test_input_data_interweawed_normalized, output_test, test_name_interweawed_normalized)\n  File \"keras_cnn_phoneme_classification.py\", line 361, in model\n    callbacks=[reduce_lr,stop])\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 1405, in fit\n    batch_size=batch_size)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 1299, in _standardize_user_data\n    exception_prefix='model target')\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 133, in _standardize_input_data\n    str(array.shape))\nValueError: Error when checking model target: expected dense_3 to have shape (None, 1) but got array with shape (9417, 24)\n</code></pre>\n\n<p>Why am i getting this error? \nI tried changing the output size of the dense3 to many  different?  but is is it expecting?</p>\n",
                "tags": "<python><keras><convnet>",
                "answers": [
                    [
                        "18092",
                        "2",
                        "18080",
                        "",
                        "",
                        "<p>The error message is pretty clear... you feed a vector of length 24 to your model, but your model is outputting a vector of length 1.</p>\n\n<p>Change :</p>\n\n<pre><code>dense3 = Dense(1 ,activation = 'softmax')(dense2)\n</code></pre>\n\n<p>to :</p>\n\n<pre><code>dense3 = Dense(24 ,activation = 'softmax')(dense2)\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4641",
            "_score": 8.275627,
            "_source": {
                "title": "Pass data to CNN with multiple outputs in eras",
                "content": "Pass data to CNN with multiple outputs in eras <p>For some reason am I getting an uexpected output dimension for my classification network. </p>\n\n<p>The network has 18 inputs of shape (45,5,3) - data formatted as (samples,45,5,3)</p>\n\n<p>And the output is a vector of length 15 - one class for each third of 45.  The extracted classes comes from a pool of 145 classes. - data formatted as (samples,15)</p>\n\n<p>My network looks like this: </p>\n\n<pre><code>#stride = 2\n#dim = 40\n#window_height = 5\n#splits = ((40-5)+1)/2 = 18\n\nkernel_number = int(math.ceil(splits))\nlist_of_input = [Input(shape = (45,5,3)) for i in range(splits)]\nlist_of_conv_output = []\nlist_of_max_out = []\nfor i in range(splits):\n    list_of_conv_output.append(Conv2D(filters = kernel_number , kernel_size = (int(splits-3),3))(list_of_input[i]))\n    list_of_max_out.append((MaxPooling2D(pool_size=((2,2)))(list_of_conv_output[i])))\n\nmerge = keras.layers.concatenate(list_of_max_out)\nprint merge.shape\nreshape = Reshape((15,324))(merge)\n\ndense1 = Dense(units = 1000, activation = 'relu',    name = \"dense_1\")(reshape)\ndense2 = Dense(units = 1000, activation = 'relu',    name = \"dense_2\")(dense1)\ndense3 = Dense(units = 145 , activation = 'softmax', name = \"dense_3\")(dense2)\nmodel = Model(inputs = list_of_input ,outputs = dense3)\n</code></pre>\n\n<p>But for some reason am I getting an error when I passing my output data. \nIt is currently stored as numpy.ndarray of shape (16828,15) and I get an value error stating: </p>\n\n<pre><code>Error when checking model target: expected dense_3 to have 3 dimensions, but got array with shape (16828, 15)\n</code></pre>\n\n<p>Why is it expecting 3 dim rather than 2 dim?</p>\n\n<p>The model summary clearly indicates that the output dim is (15,145) as I also would expect?  15 classes from a pool of 145 classes. right?</p>\n\n<p>Model summary: \n<a href=\"https://pastebin.com/27YTQW2m\" rel=\"nofollow noreferrer\">https://pastebin.com/27YTQW2m</a></p>\n <python><classification><keras><convnet><p>The first dimension is always the sample index. In the model summary this is written as None, so your last output (None, 15, 145) is 3D. </p>\n\n<p>The error message shows that your target data has dimension (:, 15), rather than the required (:, 15, 145) so you will have to reformat it.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "18283",
                "question_votes:": "1",
                "question_text:": "<p>For some reason am I getting an uexpected output dimension for my classification network. </p>\n\n<p>The network has 18 inputs of shape (45,5,3) - data formatted as (samples,45,5,3)</p>\n\n<p>And the output is a vector of length 15 - one class for each third of 45.  The extracted classes comes from a pool of 145 classes. - data formatted as (samples,15)</p>\n\n<p>My network looks like this: </p>\n\n<pre><code>#stride = 2\n#dim = 40\n#window_height = 5\n#splits = ((40-5)+1)/2 = 18\n\nkernel_number = int(math.ceil(splits))\nlist_of_input = [Input(shape = (45,5,3)) for i in range(splits)]\nlist_of_conv_output = []\nlist_of_max_out = []\nfor i in range(splits):\n    list_of_conv_output.append(Conv2D(filters = kernel_number , kernel_size = (int(splits-3),3))(list_of_input[i]))\n    list_of_max_out.append((MaxPooling2D(pool_size=((2,2)))(list_of_conv_output[i])))\n\nmerge = keras.layers.concatenate(list_of_max_out)\nprint merge.shape\nreshape = Reshape((15,324))(merge)\n\ndense1 = Dense(units = 1000, activation = 'relu',    name = \"dense_1\")(reshape)\ndense2 = Dense(units = 1000, activation = 'relu',    name = \"dense_2\")(dense1)\ndense3 = Dense(units = 145 , activation = 'softmax', name = \"dense_3\")(dense2)\nmodel = Model(inputs = list_of_input ,outputs = dense3)\n</code></pre>\n\n<p>But for some reason am I getting an error when I passing my output data. \nIt is currently stored as numpy.ndarray of shape (16828,15) and I get an value error stating: </p>\n\n<pre><code>Error when checking model target: expected dense_3 to have 3 dimensions, but got array with shape (16828, 15)\n</code></pre>\n\n<p>Why is it expecting 3 dim rather than 2 dim?</p>\n\n<p>The model summary clearly indicates that the output dim is (15,145) as I also would expect?  15 classes from a pool of 145 classes. right?</p>\n\n<p>Model summary: \n<a href=\"https://pastebin.com/27YTQW2m\" rel=\"nofollow noreferrer\">https://pastebin.com/27YTQW2m</a></p>\n",
                "tags": "<python><classification><keras><convnet>",
                "answers": [
                    [
                        "18435",
                        "2",
                        "18283",
                        "",
                        "",
                        "<p>The first dimension is always the sample index. In the model summary this is written as None, so your last output (None, 15, 145) is 3D. </p>\n\n<p>The error message shows that your target data has dimension (:, 15), rather than the required (:, 15, 145) so you will have to reformat it.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11195",
            "_score": 8.243099,
            "_source": {
                "title": "How to properly save and load an intermediate model in Keras?",
                "content": "How to properly save and load an intermediate model in Keras? <p>I'm working with a model that involves 3 stages of 'nesting' of models in Keras.</p>\n\n<p>Conceptually the first is a transfer learning CNN model, for example MobileNetV2. (Model 1) This is then wrapped by a model that consists of a small DNN. (Model 2) Finally during training these are all wrapped by a model that concatenates multiple outputs from model 2, calculates loss, and then backpropagates into model 2 and in the future model 1. (Model 3)</p>\n\n<p>For inference later I simply want to save the weights of models 1 and 2.  I have had multiple issues with this, due to what appear to be bugs in some versions of Keras (I'm using 2.2.2) and also loading the weights more explicitly is appearing to result in randomized weights and so isn't working correctly.  Instead of attempting to troubleshoot what is going wrong with whatever scenario I'm simply trying to determine what is the best practice for saving intermediate nested models.</p>\n\n<pre><code>def create_model_2(IN_DIM=(224, 224, 3), OUT_DIM=128):\n    # First define the transfer learning model\n    initial_img = Input(shape=(IN_DIM))\n\n    black_box = MobileNetV2(include_top=False, input_shape=IN_DIM, weights=\"imagenet\", pooling=\"avg\")(initial_img)\n\n    bb_model = Model(b_img, black_box)\n\n    # freeze layers for transfer learning model\n    for layer in bb_model.layers:\n        layer.trainable = False\n\n    #########################\n    ###### TOWER BLOCK ######\n    #########################\n\n    img = Input(shape=(IN_DIM))\n\n    x = bb_model(img)\n\n    # add some layers to try to learn\n    x = Dense(64, activation='relu', name='new_fc0')(x)\n\n    x = Dense(OUT_DIM, activation='relu', name='new_fc1')(x)\n\n    # L2 norm to project to unit sphere\n    out = Lambda(lambda x: K.l2_normalize(x, axis=1), name='final_l2_norm')(x)\n\n    _model_2 = Model(img, out)\n\n    return _model_2\n</code></pre>\n\n<p>Then the structure of Model 3:</p>\n\n<pre><code>IN_DIM = (224, 224, 3)  # mobilenetv2=(224, 224, 3) Iv3=(299, 299, 3)\nOUT_DIM = 32 \n\nmodel_2 = create_model_2(IN_DIM, OUT_DIM)\n\n# then define images for triplets\nanchor_img = Input(shape=IN_DIM)\npos_img = Input(shape=IN_DIM)\nneg_img = Input(shape=IN_DIM)\n\n# create three vectors representing the images\nanchor_in = model_2(anchor_img)\npositive_in = model_2(pos_img)\nnegative_in = model_2(neg_img)\n\n# concatenate the vectors into one large vector for input into the triplet loss \"processor\"\nmerged_vector = concatenate([anchor_in, positive_in, negative_in], axis=-1)\n\n# actually define the model:\nmodel_3 = Model(inputs=[anchor_img, pos_img, neg_img], outputs=merged_vector)\n</code></pre>\n\n<p>The model seems to run and train just fine:</p>\n\n<pre><code>OPTIMIZER = SGD(lr=learning_rate, momentum=0.9)\n\nfinal_model.compile(optimizer=OPTIMIZER, loss=triplet_loss, metrics=[avg_AP_dist, avg_AN_dist])\n\nhistory = final_model.fit_generator(generator=training_generator,\n                                    epochs=5,  # short for debugging\n                                    use_multiprocessing=True,\n                                    workers=4)\n</code></pre>\n\n<p>But saving the model after training is unclear:</p>\n\n<pre><code>out_file = \"../../models/{:}_epoch_{:}_weights.h5\".format(MODEL_DESC, 5)\nmodel_2.save_weights(out_file)  # save the actual Tower weights, discard the \"booster\" wrapper\nprint(\"Saved: {:}\".format(out_file))\n</code></pre>\n\n<p>Or:</p>\n\n<pre><code>out_file = \"../../models/{:}_epoch_{:}_weights.h5\".format(MODEL_DESC, 5)\nmodel_2.save(out_file)  # save the actual Tower weights, discard the \"booster\" wrapper\nprint(\"Saved: {:}\".format(out_file))\n</code></pre>\n\n<p>Or something else?</p>\n\n<p>The current failure modes seem to be if I try to load in just the weights into a newly instantiated model_2 instance I get:</p>\n\n<pre><code>ValueError: axes don't match array\n</code></pre>\n\n<p>Which from searching may be related to a bug in Keras.  If I save the model (.save() rather than .save_weights() then it loads without complaint but the inference is not stable and appears to be horrible/random.)</p>\n\n<p>Thank you.</p>\n\n<p>Still getting the following traceback:</p>\n\n<pre><code>&lt;snip&gt;/src/notebooks/vectorizer.py in load_model()\n     65 \n     66     # load the weights\n---&gt; 67     loaded_model.load_weights(weights_path)\n     68 \n     69     print(\"Model ready\")\n\n/opt/conda/lib/python3.6/site-packages/keras/engine/network.py in load_weights(self, filepath, by_name, skip_mismatch, reshape)\n   1164             else:\n   1165                 saving.load_weights_from_hdf5_group(\n-&gt; 1166                     f, self.layers, reshape=reshape)\n   1167 \n   1168     def _updated_config(self):\n\n/opt/conda/lib/python3.6/site-packages/keras/engine/saving.py in load_weights_from_hdf5_group(f, layers, reshape)\n   1043                                                        original_keras_version,\n   1044                                                        original_backend,\n-&gt; 1045                                                        reshape=reshape)\n   1046         if len(weight_values) != len(symbolic_weights):\n   1047             raise ValueError('Layer #' + str(k) +\n\n/opt/conda/lib/python3.6/site-packages/keras/engine/saving.py in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape)\n    680         weights = convert_nested_time_distributed(weights)\n    681     elif layer.__class__.__name__ in ['Model', 'Sequential']:\n--&gt; 682         weights = convert_nested_model(weights)\n    683 \n    684     if original_keras_version == '1':\n\n/opt/conda/lib/python3.6/site-packages/keras/engine/saving.py in convert_nested_model(weights)\n    668                     weights=weights[:num_weights],\n    669                     original_keras_version=original_keras_version,\n--&gt; 670                     original_backend=original_backend))\n    671                 weights = weights[num_weights:]\n    672         return new_weights\n\n/opt/conda/lib/python3.6/site-packages/keras/engine/saving.py in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape)\n    680         weights = convert_nested_time_distributed(weights)\n    681     elif layer.__class__.__name__ in ['Model', 'Sequential']:\n--&gt; 682         weights = convert_nested_model(weights)\n    683 \n    684     if original_keras_version == '1':\n\n/opt/conda/lib/python3.6/site-packages/keras/engine/saving.py in convert_nested_model(weights)\n    656                     weights=weights[:num_weights],\n    657                     original_keras_version=original_keras_version,\n--&gt; 658                     original_backend=original_backend))\n    659                 weights = weights[num_weights:]\n    660 \n\n/opt/conda/lib/python3.6/site-packages/keras/engine/saving.py in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape)\n    799             weights[0] = np.reshape(weights[0], layer_weights_shape)\n    800         elif layer_weights_shape != weights[0].shape:\n--&gt; 801             weights[0] = np.transpose(weights[0], (3, 2, 0, 1))\n    802             if layer.__class__.__name__ == 'ConvLSTM2D':\n    803                 weights[1] = np.transpose(weights[1], (3, 2, 0, 1))\n\n/opt/conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py in transpose(a, axes)\n    596 \n    597     \"\"\"\n--&gt; 598     return _wrapfunc(a, 'transpose', axes)\n    599 \n    600 \n\n/opt/conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds)\n     49 def _wrapfunc(obj, method, *args, **kwds):\n     50     try:\n---&gt; 51         return getattr(obj, method)(*args, **kwds)\n     52 \n     53     # An AttributeError occurs if the object does not have\n\nValueError: axes don't match array\n</code></pre>\n <neural-network><keras><convnet><computer-vision><image-recognition><p>Try to save the model to JSON, and the weights in HDF5 format with <code>save_weights()</code>.</p>\n\n<pre><code># save the model\nmodel_json = model_2.to_json()\nwith open(\"model_2.json\", \"w\") as j_file:\n    j_file.write(model_json)\n\n# save the weights\nmodel.save_weights(\"model_2.h5\")\n</code></pre>\n\n<p>Later to load the model:</p>\n\n<pre><code># load the model\nj_file = open('model_2.json', 'r')\nloaded_json_model = j_file.read()\nj_file.close()\nloaded_model = model_from_json(loaded_json_model)\n\n\n# load the weights\nloaded_model.load_weights(\"model_2.h5\")\n</code></pre>\n<p>After you've done training the model:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>final_model.save('model.h5')\n</code></pre>\n\n<p>To reload the model, simply use:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from keras import load_model\nmodel=load_model('model.h5')\n</code></pre>\n",
                "codes": [
                    [
                        "# save the model\nmodel_json = model_2.to_json()\nwith open(\"model_2.json\", \"w\") as j_file:\n    j_file.write(model_json)\n\n# save the weights\nmodel.save_weights(\"model_2.h5\")\n",
                        "# load the model\nj_file = open('model_2.json', 'r')\nloaded_json_model = j_file.read()\nj_file.close()\nloaded_model = model_from_json(loaded_json_model)\n\n\n# load the weights\nloaded_model.load_weights(\"model_2.h5\")\n"
                    ],
                    [
                        "final_model.save('model.h5')\n",
                        "from keras import load_model\nmodel=load_model('model.h5')\n"
                    ]
                ],
                "question_id:": "39483",
                "question_votes:": "1",
                "question_text:": "<p>I'm working with a model that involves 3 stages of 'nesting' of models in Keras.</p>\n\n<p>Conceptually the first is a transfer learning CNN model, for example MobileNetV2. (Model 1) This is then wrapped by a model that consists of a small DNN. (Model 2) Finally during training these are all wrapped by a model that concatenates multiple outputs from model 2, calculates loss, and then backpropagates into model 2 and in the future model 1. (Model 3)</p>\n\n<p>For inference later I simply want to save the weights of models 1 and 2.  I have had multiple issues with this, due to what appear to be bugs in some versions of Keras (I'm using 2.2.2) and also loading the weights more explicitly is appearing to result in randomized weights and so isn't working correctly.  Instead of attempting to troubleshoot what is going wrong with whatever scenario I'm simply trying to determine what is the best practice for saving intermediate nested models.</p>\n\n<pre><code>def create_model_2(IN_DIM=(224, 224, 3), OUT_DIM=128):\n    # First define the transfer learning model\n    initial_img = Input(shape=(IN_DIM))\n\n    black_box = MobileNetV2(include_top=False, input_shape=IN_DIM, weights=\"imagenet\", pooling=\"avg\")(initial_img)\n\n    bb_model = Model(b_img, black_box)\n\n    # freeze layers for transfer learning model\n    for layer in bb_model.layers:\n        layer.trainable = False\n\n    #########################\n    ###### TOWER BLOCK ######\n    #########################\n\n    img = Input(shape=(IN_DIM))\n\n    x = bb_model(img)\n\n    # add some layers to try to learn\n    x = Dense(64, activation='relu', name='new_fc0')(x)\n\n    x = Dense(OUT_DIM, activation='relu', name='new_fc1')(x)\n\n    # L2 norm to project to unit sphere\n    out = Lambda(lambda x: K.l2_normalize(x, axis=1), name='final_l2_norm')(x)\n\n    _model_2 = Model(img, out)\n\n    return _model_2\n</code></pre>\n\n<p>Then the structure of Model 3:</p>\n\n<pre><code>IN_DIM = (224, 224, 3)  # mobilenetv2=(224, 224, 3) Iv3=(299, 299, 3)\nOUT_DIM = 32 \n\nmodel_2 = create_model_2(IN_DIM, OUT_DIM)\n\n# then define images for triplets\nanchor_img = Input(shape=IN_DIM)\npos_img = Input(shape=IN_DIM)\nneg_img = Input(shape=IN_DIM)\n\n# create three vectors representing the images\nanchor_in = model_2(anchor_img)\npositive_in = model_2(pos_img)\nnegative_in = model_2(neg_img)\n\n# concatenate the vectors into one large vector for input into the triplet loss \"processor\"\nmerged_vector = concatenate([anchor_in, positive_in, negative_in], axis=-1)\n\n# actually define the model:\nmodel_3 = Model(inputs=[anchor_img, pos_img, neg_img], outputs=merged_vector)\n</code></pre>\n\n<p>The model seems to run and train just fine:</p>\n\n<pre><code>OPTIMIZER = SGD(lr=learning_rate, momentum=0.9)\n\nfinal_model.compile(optimizer=OPTIMIZER, loss=triplet_loss, metrics=[avg_AP_dist, avg_AN_dist])\n\nhistory = final_model.fit_generator(generator=training_generator,\n                                    epochs=5,  # short for debugging\n                                    use_multiprocessing=True,\n                                    workers=4)\n</code></pre>\n\n<p>But saving the model after training is unclear:</p>\n\n<pre><code>out_file = \"../../models/{:}_epoch_{:}_weights.h5\".format(MODEL_DESC, 5)\nmodel_2.save_weights(out_file)  # save the actual Tower weights, discard the \"booster\" wrapper\nprint(\"Saved: {:}\".format(out_file))\n</code></pre>\n\n<p>Or:</p>\n\n<pre><code>out_file = \"../../models/{:}_epoch_{:}_weights.h5\".format(MODEL_DESC, 5)\nmodel_2.save(out_file)  # save the actual Tower weights, discard the \"booster\" wrapper\nprint(\"Saved: {:}\".format(out_file))\n</code></pre>\n\n<p>Or something else?</p>\n\n<p>The current failure modes seem to be if I try to load in just the weights into a newly instantiated model_2 instance I get:</p>\n\n<pre><code>ValueError: axes don't match array\n</code></pre>\n\n<p>Which from searching may be related to a bug in Keras.  If I save the model (.save() rather than .save_weights() then it loads without complaint but the inference is not stable and appears to be horrible/random.)</p>\n\n<p>Thank you.</p>\n\n<p>Still getting the following traceback:</p>\n\n<pre><code>&lt;snip&gt;/src/notebooks/vectorizer.py in load_model()\n     65 \n     66     # load the weights\n---&gt; 67     loaded_model.load_weights(weights_path)\n     68 \n     69     print(\"Model ready\")\n\n/opt/conda/lib/python3.6/site-packages/keras/engine/network.py in load_weights(self, filepath, by_name, skip_mismatch, reshape)\n   1164             else:\n   1165                 saving.load_weights_from_hdf5_group(\n-&gt; 1166                     f, self.layers, reshape=reshape)\n   1167 \n   1168     def _updated_config(self):\n\n/opt/conda/lib/python3.6/site-packages/keras/engine/saving.py in load_weights_from_hdf5_group(f, layers, reshape)\n   1043                                                        original_keras_version,\n   1044                                                        original_backend,\n-&gt; 1045                                                        reshape=reshape)\n   1046         if len(weight_values) != len(symbolic_weights):\n   1047             raise ValueError('Layer #' + str(k) +\n\n/opt/conda/lib/python3.6/site-packages/keras/engine/saving.py in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape)\n    680         weights = convert_nested_time_distributed(weights)\n    681     elif layer.__class__.__name__ in ['Model', 'Sequential']:\n--&gt; 682         weights = convert_nested_model(weights)\n    683 \n    684     if original_keras_version == '1':\n\n/opt/conda/lib/python3.6/site-packages/keras/engine/saving.py in convert_nested_model(weights)\n    668                     weights=weights[:num_weights],\n    669                     original_keras_version=original_keras_version,\n--&gt; 670                     original_backend=original_backend))\n    671                 weights = weights[num_weights:]\n    672         return new_weights\n\n/opt/conda/lib/python3.6/site-packages/keras/engine/saving.py in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape)\n    680         weights = convert_nested_time_distributed(weights)\n    681     elif layer.__class__.__name__ in ['Model', 'Sequential']:\n--&gt; 682         weights = convert_nested_model(weights)\n    683 \n    684     if original_keras_version == '1':\n\n/opt/conda/lib/python3.6/site-packages/keras/engine/saving.py in convert_nested_model(weights)\n    656                     weights=weights[:num_weights],\n    657                     original_keras_version=original_keras_version,\n--&gt; 658                     original_backend=original_backend))\n    659                 weights = weights[num_weights:]\n    660 \n\n/opt/conda/lib/python3.6/site-packages/keras/engine/saving.py in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape)\n    799             weights[0] = np.reshape(weights[0], layer_weights_shape)\n    800         elif layer_weights_shape != weights[0].shape:\n--&gt; 801             weights[0] = np.transpose(weights[0], (3, 2, 0, 1))\n    802             if layer.__class__.__name__ == 'ConvLSTM2D':\n    803                 weights[1] = np.transpose(weights[1], (3, 2, 0, 1))\n\n/opt/conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py in transpose(a, axes)\n    596 \n    597     \"\"\"\n--&gt; 598     return _wrapfunc(a, 'transpose', axes)\n    599 \n    600 \n\n/opt/conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds)\n     49 def _wrapfunc(obj, method, *args, **kwds):\n     50     try:\n---&gt; 51         return getattr(obj, method)(*args, **kwds)\n     52 \n     53     # An AttributeError occurs if the object does not have\n\nValueError: axes don't match array\n</code></pre>\n",
                "tags": "<neural-network><keras><convnet><computer-vision><image-recognition>",
                "answers": [
                    [
                        "39489",
                        "2",
                        "39483",
                        "",
                        "",
                        "<p>Try to save the model to JSON, and the weights in HDF5 format with <code>save_weights()</code>.</p>\n\n<pre><code># save the model\nmodel_json = model_2.to_json()\nwith open(\"model_2.json\", \"w\") as j_file:\n    j_file.write(model_json)\n\n# save the weights\nmodel.save_weights(\"model_2.h5\")\n</code></pre>\n\n<p>Later to load the model:</p>\n\n<pre><code># load the model\nj_file = open('model_2.json', 'r')\nloaded_json_model = j_file.read()\nj_file.close()\nloaded_model = model_from_json(loaded_json_model)\n\n\n# load the weights\nloaded_model.load_weights(\"model_2.h5\")\n</code></pre>\n",
                        "",
                        ""
                    ],
                    [
                        "49063",
                        "2",
                        "39483",
                        "",
                        "",
                        "<p>After you've done training the model:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>final_model.save('model.h5')\n</code></pre>\n\n<p>To reload the model, simply use:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from keras import load_model\nmodel=load_model('model.h5')\n</code></pre>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7341",
            "_score": 8.242166,
            "_source": {
                "title": "Tips & Tricks on training DCGAN on small dataset",
                "content": "Tips & Tricks on training DCGAN on small dataset <p>I have made a DCGAN which I am trying to train on custom dataset of only 1200 images. I have tried to gather more, but even gathering these 1200 was hard enough. If you are wondering I used Google Chromes extension \"Fakun Batch Download Image\" to gather my dataset.</p>\n\n<p><strong>TRAINING DETAILS:</strong>\nIn training procedure I am simultaneously updating parameters of both, Generator, and Discriminator network. I've read that it works much better then training only one player ( Discriminator ) for K steps and then other ( Generator ) for one.</p>\n\n<p><strong>QUESTION:</strong> Should I perform maybe some kind of transformation on all of those images and then merge transformed images with the initial ones, or something similar? </p>\n <deep-learning><convolution><cnn><gan><h1>Extending a small dataset comprised of images</h1>\n\n<p>A deep learning algorithm will learn a mapping function from your input space to your outputs. The variations in your input images will be learned within this function. Thus, you will want to consider this fact when you augment your dataset. The distribution of your input features should be concise as to what you plan to model. </p>\n\n<p>You are thus left balancing between adding data and adding variability to your input space. For example, it might not be worth it to rotate by 180 degrees when trying to generate Dragon Ball characters. Their heads should not be where their feet are. You would want your network to understand that the bottom of the image should contain some strange space boots, and the top exotic haircuts or bald heads. </p>\n\n<h2>Augmenting images</h2>\n\n<p>Here are some useful transformations that you can use to get more data</p>\n\n<ul>\n<li>Apply transformations (rotations, translations)</li>\n<li>Mirror the image</li>\n<li>Add distortions </li>\n<li>Change zoom factor</li>\n<li>Add blurring thus to better generalize the input data</li>\n<li>Invert colors (skew, add brightness, etc.)</li>\n</ul>\n\n<h2>In Keras</h2>\n\n<p>In Keras you can use the <code>ImageDataGenerator</code> functions. </p>\n\n<pre><code>import numpy as np\nfrom keras.datasets import mnist\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# load data\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nX_train = X_train.astype('float32')\n\n# set up your data generator\ndatagen = ImageDataGenerator(\n   featurewise_center=True,\n   featurewise_std_normalization=True,\n   rotation_range=60,\n   width_shift_range=0.2,\n   height_shift_range=0.2,\n   shear_range=0.2,\n   zoom_range=0.2,\n   horizontal_flip=True,\n   vertical_flip = True)\n\n# Fit the generator using your data\ndatagen.fit(X_train.reshape((len(X_train), 28, 28, 1)))\n\n# let's look at some generated images\nimage = X_train[5]\n\nplt.figure(figsize=(12,12))\nplt.subplot(4, 4, 1)\nplt.imshow(image.reshape((28,28)),  cmap='gray')\nfor j in range(15):\n   augmented = datagen.random_transform(image.reshape((28,28,1)))\n    plt.subplot(4, 4, j+2)\n    plt.imshow(augmented.reshape((28,28)),  cmap='gray')\nplt.tight_layout()\nplt.show()\n</code></pre>\n",
                "codes": [
                    [
                        "import numpy as np\nfrom keras.datasets import mnist\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# load data\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nX_train = X_train.astype('float32')\n\n# set up your data generator\ndatagen = ImageDataGenerator(\n   featurewise_center=True,\n   featurewise_std_normalization=True,\n   rotation_range=60,\n   width_shift_range=0.2,\n   height_shift_range=0.2,\n   shear_range=0.2,\n   zoom_range=0.2,\n   horizontal_flip=True,\n   vertical_flip = True)\n\n# Fit the generator using your data\ndatagen.fit(X_train.reshape((len(X_train), 28, 28, 1)))\n\n# let's look at some generated images\nimage = X_train[5]\n\nplt.figure(figsize=(12,12))\nplt.subplot(4, 4, 1)\nplt.imshow(image.reshape((28,28)),  cmap='gray')\nfor j in range(15):\n   augmented = datagen.random_transform(image.reshape((28,28,1)))\n    plt.subplot(4, 4, j+2)\n    plt.imshow(augmented.reshape((28,28)),  cmap='gray')\nplt.tight_layout()\nplt.show()\n"
                    ]
                ],
                "question_id:": "27574",
                "question_votes:": "1",
                "question_text:": "<p>I have made a DCGAN which I am trying to train on custom dataset of only 1200 images. I have tried to gather more, but even gathering these 1200 was hard enough. If you are wondering I used Google Chromes extension \"Fakun Batch Download Image\" to gather my dataset.</p>\n\n<p><strong>TRAINING DETAILS:</strong>\nIn training procedure I am simultaneously updating parameters of both, Generator, and Discriminator network. I've read that it works much better then training only one player ( Discriminator ) for K steps and then other ( Generator ) for one.</p>\n\n<p><strong>QUESTION:</strong> Should I perform maybe some kind of transformation on all of those images and then merge transformed images with the initial ones, or something similar? </p>\n",
                "tags": "<deep-learning><convolution><cnn><gan>",
                "answers": [
                    [
                        "27600",
                        "2",
                        "27574",
                        "",
                        "",
                        "<h1>Extending a small dataset comprised of images</h1>\n\n<p>A deep learning algorithm will learn a mapping function from your input space to your outputs. The variations in your input images will be learned within this function. Thus, you will want to consider this fact when you augment your dataset. The distribution of your input features should be concise as to what you plan to model. </p>\n\n<p>You are thus left balancing between adding data and adding variability to your input space. For example, it might not be worth it to rotate by 180 degrees when trying to generate Dragon Ball characters. Their heads should not be where their feet are. You would want your network to understand that the bottom of the image should contain some strange space boots, and the top exotic haircuts or bald heads. </p>\n\n<h2>Augmenting images</h2>\n\n<p>Here are some useful transformations that you can use to get more data</p>\n\n<ul>\n<li>Apply transformations (rotations, translations)</li>\n<li>Mirror the image</li>\n<li>Add distortions </li>\n<li>Change zoom factor</li>\n<li>Add blurring thus to better generalize the input data</li>\n<li>Invert colors (skew, add brightness, etc.)</li>\n</ul>\n\n<h2>In Keras</h2>\n\n<p>In Keras you can use the <code>ImageDataGenerator</code> functions. </p>\n\n<pre><code>import numpy as np\nfrom keras.datasets import mnist\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# load data\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nX_train = X_train.astype('float32')\n\n# set up your data generator\ndatagen = ImageDataGenerator(\n   featurewise_center=True,\n   featurewise_std_normalization=True,\n   rotation_range=60,\n   width_shift_range=0.2,\n   height_shift_range=0.2,\n   shear_range=0.2,\n   zoom_range=0.2,\n   horizontal_flip=True,\n   vertical_flip = True)\n\n# Fit the generator using your data\ndatagen.fit(X_train.reshape((len(X_train), 28, 28, 1)))\n\n# let's look at some generated images\nimage = X_train[5]\n\nplt.figure(figsize=(12,12))\nplt.subplot(4, 4, 1)\nplt.imshow(image.reshape((28,28)),  cmap='gray')\nfor j in range(15):\n   augmented = datagen.random_transform(image.reshape((28,28,1)))\n    plt.subplot(4, 4, j+2)\n    plt.imshow(augmented.reshape((28,28)),  cmap='gray')\nplt.tight_layout()\nplt.show()\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11165",
            "_score": 8.214668,
            "_source": {
                "title": "Question Related Numpy",
                "content": "Question Related Numpy <p>With Numpy, what\u2019s the best way to compute the inner product of a vector of size 10 with each row in a matrix of size (5, 10)?</p>\n <python><deep-learning><numpy><p>Here are a few ways, using some dummy data:</p>\n\n<pre><code>In [1]: import numpy as np\n\nIn [2]: a = np.random.randint(0, 10, (10,))\n\nIn [3]: b = np.random.randint(0, 10, (5, 10))\n\nIn [4]: a\nOut[4]: array([4, 1, 0, 6, 3, 3, 6, 6, 1, 8])\n\nIn [5]: b\nOut[5]: \narray([[9, 0, 6, 1, 1, 1, 4, 7, 4, 7],\n       [5, 8, 8, 3, 4, 8, 7, 3, 0, 4],\n       [2, 2, 5, 3, 9, 6, 1, 5, 8, 3],\n       [2, 0, 4, 3, 5, 3, 3, 4, 3, 3],\n       [3, 3, 6, 4, 7, 5, 8, 6, 7, 3]])\n</code></pre>\n\n<p>Because of the dimensions you asked for, in order to compute inner products (a.k.a. scalar products and dot products), we need to transpose the matrix <code>b</code> so that the dimensions work out.\nWith a vector of length 10, numpy gives it shape <code>(10,)</code>. So it seems 10 rows and no columns, however it is kind of ambiguous. Numpy will essentially do what it has to in order to make dimensions work. We could force it into a <code>(10, 1)</code> vector by using <code>a.reshape((10, 1))</code>, but it isn't necessary. The matrix has a defined second dimensions, so we have a shape <code>(5, 10)</code>. In order to multiply these two shapes together, we need to make the same dimensions match in the middle. This means making <code>(10,) * (10, 5)</code>. Performing the transpose on matrix reverses the dimensions to give us that <code>(10, 5)</code>. Those inner <code>10</code>s will then disappear and leave us with a <code>(1, 5)</code> vector.</p>\n\n<hr>\n\n<p>That all being said, we can use any of the following to get equivalent answers:</p>\n\n<ol>\n<li><p>The standard good ol' dot-product:</p>\n\n<pre><code>In [7]: a.dot(b.T)\nOut[7]: array([174, 174, 141, 119, 190])\n</code></pre></li>\n<li><p>The convenient numpy notation:</p>\n\n<pre><code>In [6]: a @ b.T\nOut[6]: array([174, 174, 141, 119, 190])\n</code></pre></li>\n<li><p>Some crazy looking <strong>Einstein notation</strong>, a subset of Ricci calculus (I leave the interested reader to google that shizzle!):</p>\n\n<pre><code>In [8]: np.einsum('i,ij-&gt;j', a, b.T)\nOut[8]: array([174, 174, 141, 119, 190])\n</code></pre></li>\n<li><p>Here as in the comments from <em>shadowstalker</em>:</p>\n\n<pre><code>In [9]: np.array([np.dot(a, r) for r in b])\nOut[9]: array([174, 174, 141, 119, 190])\n</code></pre></li>\n</ol>\n\n<hr>\n\n<p>If your matrices are of dimensions <code>(100, 100)</code> or smaller, then the <code>@</code> method is probably the fastest and most elegant. However, once you start getting into matrices that make you wonder if you laptop will handle it (e.g. with shape <code>(10000, 10000)</code>) - then it is time to <a href=\"https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.einsum.html\" rel=\"nofollow noreferrer\">read the documentation</a> and <strong><a href=\"http://ajcr.net/Basic-guide-to-einsum/\" rel=\"nofollow noreferrer\">this blog</a></strong> about Einstein notation and the awesomely baffling <code>einsum</code> module within numpy!</p>\n",
                "codes": [
                    [
                        "In [1]: import numpy as np\n\nIn [2]: a = np.random.randint(0, 10, (10,))\n\nIn [3]: b = np.random.randint(0, 10, (5, 10))\n\nIn [4]: a\nOut[4]: array([4, 1, 0, 6, 3, 3, 6, 6, 1, 8])\n\nIn [5]: b\nOut[5]: \narray([[9, 0, 6, 1, 1, 1, 4, 7, 4, 7],\n       [5, 8, 8, 3, 4, 8, 7, 3, 0, 4],\n       [2, 2, 5, 3, 9, 6, 1, 5, 8, 3],\n       [2, 0, 4, 3, 5, 3, 3, 4, 3, 3],\n       [3, 3, 6, 4, 7, 5, 8, 6, 7, 3]])\n",
                        "In [7]: a.dot(b.T)\nOut[7]: array([174, 174, 141, 119, 190])\n",
                        "In [6]: a @ b.T\nOut[6]: array([174, 174, 141, 119, 190])\n",
                        "In [8]: np.einsum('i,ij->j', a, b.T)\nOut[8]: array([174, 174, 141, 119, 190])\n",
                        "In [9]: np.array([np.dot(a, r) for r in b])\nOut[9]: array([174, 174, 141, 119, 190])\n"
                    ]
                ],
                "question_id:": "39364",
                "question_votes:": "2",
                "question_text:": "<p>With Numpy, what\u2019s the best way to compute the inner product of a vector of size 10 with each row in a matrix of size (5, 10)?</p>\n",
                "tags": "<python><deep-learning><numpy>",
                "answers": [
                    [
                        "39385",
                        "2",
                        "39364",
                        "",
                        "",
                        "<p>Here are a few ways, using some dummy data:</p>\n\n<pre><code>In [1]: import numpy as np\n\nIn [2]: a = np.random.randint(0, 10, (10,))\n\nIn [3]: b = np.random.randint(0, 10, (5, 10))\n\nIn [4]: a\nOut[4]: array([4, 1, 0, 6, 3, 3, 6, 6, 1, 8])\n\nIn [5]: b\nOut[5]: \narray([[9, 0, 6, 1, 1, 1, 4, 7, 4, 7],\n       [5, 8, 8, 3, 4, 8, 7, 3, 0, 4],\n       [2, 2, 5, 3, 9, 6, 1, 5, 8, 3],\n       [2, 0, 4, 3, 5, 3, 3, 4, 3, 3],\n       [3, 3, 6, 4, 7, 5, 8, 6, 7, 3]])\n</code></pre>\n\n<p>Because of the dimensions you asked for, in order to compute inner products (a.k.a. scalar products and dot products), we need to transpose the matrix <code>b</code> so that the dimensions work out.\nWith a vector of length 10, numpy gives it shape <code>(10,)</code>. So it seems 10 rows and no columns, however it is kind of ambiguous. Numpy will essentially do what it has to in order to make dimensions work. We could force it into a <code>(10, 1)</code> vector by using <code>a.reshape((10, 1))</code>, but it isn't necessary. The matrix has a defined second dimensions, so we have a shape <code>(5, 10)</code>. In order to multiply these two shapes together, we need to make the same dimensions match in the middle. This means making <code>(10,) * (10, 5)</code>. Performing the transpose on matrix reverses the dimensions to give us that <code>(10, 5)</code>. Those inner <code>10</code>s will then disappear and leave us with a <code>(1, 5)</code> vector.</p>\n\n<hr>\n\n<p>That all being said, we can use any of the following to get equivalent answers:</p>\n\n<ol>\n<li><p>The standard good ol' dot-product:</p>\n\n<pre><code>In [7]: a.dot(b.T)\nOut[7]: array([174, 174, 141, 119, 190])\n</code></pre></li>\n<li><p>The convenient numpy notation:</p>\n\n<pre><code>In [6]: a @ b.T\nOut[6]: array([174, 174, 141, 119, 190])\n</code></pre></li>\n<li><p>Some crazy looking <strong>Einstein notation</strong>, a subset of Ricci calculus (I leave the interested reader to google that shizzle!):</p>\n\n<pre><code>In [8]: np.einsum('i,ij-&gt;j', a, b.T)\nOut[8]: array([174, 174, 141, 119, 190])\n</code></pre></li>\n<li><p>Here as in the comments from <em>shadowstalker</em>:</p>\n\n<pre><code>In [9]: np.array([np.dot(a, r) for r in b])\nOut[9]: array([174, 174, 141, 119, 190])\n</code></pre></li>\n</ol>\n\n<hr>\n\n<p>If your matrices are of dimensions <code>(100, 100)</code> or smaller, then the <code>@</code> method is probably the fastest and most elegant. However, once you start getting into matrices that make you wonder if you laptop will handle it (e.g. with shape <code>(10000, 10000)</code>) - then it is time to <a href=\"https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.einsum.html\" rel=\"nofollow noreferrer\">read the documentation</a> and <strong><a href=\"http://ajcr.net/Basic-guide-to-einsum/\" rel=\"nofollow noreferrer\">this blog</a></strong> about Einstein notation and the awesomely baffling <code>einsum</code> module within numpy!</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8787",
            "_score": 8.203409,
            "_source": {
                "title": "Query data dimension",
                "content": "Query data dimension <pre><code>import numpy as np\nfrom sklearn import preprocessing, cross_validation, neighbors\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndf = pd.read_csv('Downloads/breast-cancer-wisconsin.data.txt',skiprows=1)\ndf.replace('?', -99999, inplace=True)\ndf.drop('id', 1, inplace=True )\n\nX= np.array(df.drop(['class'],1))\ny= np.array(df['class'])\n\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.2)\n\n#clf = neighbors.KNeighborsClassifier()\nclf = LinearRegression(normalize=True)\nclf.fit(X_train, y_train)\n\naccuracy= clf.score(X_test, y_test)\nprint(accuracy)\n\nexample_measures = np.array([[4,2,1,1,1,2,3,2,1],[4,2,1,2,2,2,3,2,1]])\nexample_measures = example_measures.reshape(1,-1)\n\nprediction = clf.predict(example_measures)     ##(example_measures)\n\nprint(prediction)\n</code></pre>\n\n<p>Problem arises when  I run the above command line at Ubuntu or Anaconda:</p>\n\n<blockquote>\n  <p>ValueError: query data dimension must match training data dimension</p>\n</blockquote>\n\n<p>How to solve that problem ? I am sure that by method of isolating individual commandline-- and find it appears Error at :</p>\n\n<pre><code>prediction = clf.predict(example_measures)\n</code></pre>\n\n<p>I try to use : </p>\n\n<pre><code>prediction = clf.predict(X_test).\n</code></pre>\n\n<p>It is ok.\nI really want to predict the example I create. How can I change the code?</p>\n <machine-learning-model><p>How many columns do <code>X_train</code> and <code>X_test</code> have? </p>\n\n<p>I'd imagine (though can't confirm, as I don't have access to your data) that they have fewer (or more) than 18 columns.</p>\n\n<p>This is because your code </p>\n\n<pre><code>example_measures = np.array([[4,2,1,1,1,2,3,2,1],[4,2,1,2,2,2,3,2,1]])\nexample_measures = example_measures.reshape(1,-1)\n</code></pre>\n\n<p>produces an array of shape <code>(1, 18)</code>.</p>\n\n<p>EDIT: I've tried matching your dataset, and got the following:</p>\n\n<pre><code>import numpy as np\nfrom sklearn import preprocessing, cross_validation, neighbors\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.datasets import load_breast_cancer\n\nX= load_breast_cancer().data\ny= load_breast_cancer().target\n\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.2)\n\nclf = LinearRegression(normalize=True)\nclf.fit(X_train, y_train)\n\naccuracy= clf.score(X_test, y_test)\nprint(accuracy)\n</code></pre>\n\n<p>If I call <code>X.shape</code>, I get <code>(569, 30)</code>. So, if you want to make your own array to pass to <code>clf</code>, it needs to have 30 columns (one for each feature).</p>\n",
                "codes": [
                    [
                        "example_measures = np.array([[4,2,1,1,1,2,3,2,1],[4,2,1,2,2,2,3,2,1]])\nexample_measures = example_measures.reshape(1,-1)\n",
                        "import numpy as np\nfrom sklearn import preprocessing, cross_validation, neighbors\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.datasets import load_breast_cancer\n\nX= load_breast_cancer().data\ny= load_breast_cancer().target\n\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.2)\n\nclf = LinearRegression(normalize=True)\nclf.fit(X_train, y_train)\n\naccuracy= clf.score(X_test, y_test)\nprint(accuracy)\n"
                    ]
                ],
                "question_id:": "31795",
                "question_votes:": "3",
                "question_text:": "<pre><code>import numpy as np\nfrom sklearn import preprocessing, cross_validation, neighbors\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndf = pd.read_csv('Downloads/breast-cancer-wisconsin.data.txt',skiprows=1)\ndf.replace('?', -99999, inplace=True)\ndf.drop('id', 1, inplace=True )\n\nX= np.array(df.drop(['class'],1))\ny= np.array(df['class'])\n\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.2)\n\n#clf = neighbors.KNeighborsClassifier()\nclf = LinearRegression(normalize=True)\nclf.fit(X_train, y_train)\n\naccuracy= clf.score(X_test, y_test)\nprint(accuracy)\n\nexample_measures = np.array([[4,2,1,1,1,2,3,2,1],[4,2,1,2,2,2,3,2,1]])\nexample_measures = example_measures.reshape(1,-1)\n\nprediction = clf.predict(example_measures)     ##(example_measures)\n\nprint(prediction)\n</code></pre>\n\n<p>Problem arises when  I run the above command line at Ubuntu or Anaconda:</p>\n\n<blockquote>\n  <p>ValueError: query data dimension must match training data dimension</p>\n</blockquote>\n\n<p>How to solve that problem ? I am sure that by method of isolating individual commandline-- and find it appears Error at :</p>\n\n<pre><code>prediction = clf.predict(example_measures)\n</code></pre>\n\n<p>I try to use : </p>\n\n<pre><code>prediction = clf.predict(X_test).\n</code></pre>\n\n<p>It is ok.\nI really want to predict the example I create. How can I change the code?</p>\n",
                "tags": "<machine-learning-model>",
                "answers": [
                    [
                        "31805",
                        "2",
                        "31795",
                        "",
                        "",
                        "<p>How many columns do <code>X_train</code> and <code>X_test</code> have? </p>\n\n<p>I'd imagine (though can't confirm, as I don't have access to your data) that they have fewer (or more) than 18 columns.</p>\n\n<p>This is because your code </p>\n\n<pre><code>example_measures = np.array([[4,2,1,1,1,2,3,2,1],[4,2,1,2,2,2,3,2,1]])\nexample_measures = example_measures.reshape(1,-1)\n</code></pre>\n\n<p>produces an array of shape <code>(1, 18)</code>.</p>\n\n<p>EDIT: I've tried matching your dataset, and got the following:</p>\n\n<pre><code>import numpy as np\nfrom sklearn import preprocessing, cross_validation, neighbors\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.datasets import load_breast_cancer\n\nX= load_breast_cancer().data\ny= load_breast_cancer().target\n\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.2)\n\nclf = LinearRegression(normalize=True)\nclf.fit(X_train, y_train)\n\naccuracy= clf.score(X_test, y_test)\nprint(accuracy)\n</code></pre>\n\n<p>If I call <code>X.shape</code>, I get <code>(569, 30)</code>. So, if you want to make your own array to pass to <code>clf</code>, it needs to have 30 columns (one for each feature).</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13850",
            "_score": 8.200575,
            "_source": {
                "title": "Architecture for multivariate multi-time-series model where some features are TS specific and some features are global",
                "content": "Architecture for multivariate multi-time-series model where some features are TS specific and some features are global <p>I'm looking to build a time series model (using a TCN or a LSTM)  with <span class=\"math-container\">$N$</span> different series, each of which has <span class=\"math-container\">$P$</span> series-specific features <span class=\"math-container\">$\\mathbf{X}$</span>.  My input array is of dimension <span class=\"math-container\">$N \\times t \\times P$</span>, where <span class=\"math-container\">$t$</span> is the number of time steps.  </p>\n\n<p>I've also got features <span class=\"math-container\">$G$</span>, which are constant across all time series.  For concreteness, imagine I'm predicting city-level ice cream sales with weather data, and I also want to use GDP growth as a predictor.  GDP growth is national.  A simple approach could be to augment <span class=\"math-container\">$\\mathbf{X}$</span> with <span class=\"math-container\">$G$</span>, adding 1 to the dimension of <span class=\"math-container\">$P$</span>.  Then my forecast output for the next period would be <span class=\"math-container\">$N \\times 1 \\times P+1$</span>, which is no good because there is a GDP forecast for each city, when in reality GDP growth is common across cities (when measured nationally).  I suppose that I want two outputs -- one of shape <span class=\"math-container\">$N \\times 1 \\times P$</span>, and the other of shape <span class=\"math-container\">$1 \\times 1 \\times 1$</span>, a scalar (if <span class=\"math-container\">$G$</span> is of dimension <span class=\"math-container\">$t \\times 1$</span>).  </p>\n\n<p>Here's a dummy example in which time is a global variable, but it is constant across all series.  (Let's just assume for the moment that time isn't exogenous, but rather something to include in a multivariate forecast).</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.models import Model\nfrom keras.layers import Input, Conv1D, Dense\nfrom keras.optimizers import Adam\n\ntime = np.array(range(100))\nbrk = np.array((time&gt;40) &amp; (time &lt; 60)).reshape(100,1)\nB = np.array([5, -5]).reshape(1,2)\nnp.dot(brk, B)\ny = np.c_[np.sin(time), np.sin(time)] + np.random.normal(scale = .2, size=(100,2))+ np.dot(brk, B)\n\nplt.plot(time, y[:,0])\nplt.plot(time, y[:,1])\n\n# Temporal convolutional network\nn_filters = 2\nfilter_width = 3\ndilation_rates = [2**i for i in range(5)] \ninp = Input(shape=(None, 2))\nx = inp\nfor dilation_rate in dilation_rates:\n    x = Conv1D(filters=n_filters,\n               kernel_size=filter_width, \n               padding='causal',\n               activation = \"relu\",\n               dilation_rate=dilation_rate)(x)\nx = Dense(2)(x)\n\n\nmodel = Model(inputs = inp, outputs = x)\nmodel.compile(optimizer = Adam(), loss='mean_squared_error')\nmodel.summary()\n\ndef shift5(arr, num, fill_value=np.nan):\n    result = np.empty_like(arr)\n    if num &gt; 0:\n        result[:num] = fill_value\n        result[num:] = arr[:-num]\n    elif num &lt; 0:\n        result[num:] = fill_value\n        result[:num] = arr[-num:]\n    else:\n        result = arr\n    return result\n\n\n\nX = y.reshape(2,100,1)\nX = np.concatenate([X, np.concatenate([time.reshape(100,1),time.reshape(100,1)], axis = 1).reshape(2,100, 1)],\n                    axis = 2)\nX_tr = X[:,:95,:]\nX_te = X[:,5:,:]\n\nhistory = model.fit(X_tr, X_te,\n                batch_size=2,\n                epochs=10,\n                verbose = 1)\n</code></pre>\n\n<p>How would I modify this architecture to have two inputs and two outputs, with both input and output having local and global components?</p>\n <neural-network><deep-learning><keras><time-series><multitask-learning><p>Stacked LSTM is one option in this scenario</p>\n\n<p><a href=\"https://i.stack.imgur.com/2YkSE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/2YkSE.png\" alt=\"enter image description here\"></a></p>\n\n<p>This assumes that First two LSTMs have different frequencies and City has static features (Like lat/long, one-hot-encoded value etc). If City is also time-series like series of population , mean income; it will be an LSTM as well. </p>\n\n<p>Code example for stacked LSTM : <a href=\"https://machinelearningmastery.com/stacked-long-short-term-memory-networks/\" rel=\"nofollow noreferrer\">https://machinelearningmastery.com/stacked-long-short-term-memory-networks/</a></p>\n",
                "codes": [
                    []
                ],
                "question_id:": "47000",
                "question_votes:": "",
                "question_text:": "<p>I'm looking to build a time series model (using a TCN or a LSTM)  with <span class=\"math-container\">$N$</span> different series, each of which has <span class=\"math-container\">$P$</span> series-specific features <span class=\"math-container\">$\\mathbf{X}$</span>.  My input array is of dimension <span class=\"math-container\">$N \\times t \\times P$</span>, where <span class=\"math-container\">$t$</span> is the number of time steps.  </p>\n\n<p>I've also got features <span class=\"math-container\">$G$</span>, which are constant across all time series.  For concreteness, imagine I'm predicting city-level ice cream sales with weather data, and I also want to use GDP growth as a predictor.  GDP growth is national.  A simple approach could be to augment <span class=\"math-container\">$\\mathbf{X}$</span> with <span class=\"math-container\">$G$</span>, adding 1 to the dimension of <span class=\"math-container\">$P$</span>.  Then my forecast output for the next period would be <span class=\"math-container\">$N \\times 1 \\times P+1$</span>, which is no good because there is a GDP forecast for each city, when in reality GDP growth is common across cities (when measured nationally).  I suppose that I want two outputs -- one of shape <span class=\"math-container\">$N \\times 1 \\times P$</span>, and the other of shape <span class=\"math-container\">$1 \\times 1 \\times 1$</span>, a scalar (if <span class=\"math-container\">$G$</span> is of dimension <span class=\"math-container\">$t \\times 1$</span>).  </p>\n\n<p>Here's a dummy example in which time is a global variable, but it is constant across all series.  (Let's just assume for the moment that time isn't exogenous, but rather something to include in a multivariate forecast).</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.models import Model\nfrom keras.layers import Input, Conv1D, Dense\nfrom keras.optimizers import Adam\n\ntime = np.array(range(100))\nbrk = np.array((time&gt;40) &amp; (time &lt; 60)).reshape(100,1)\nB = np.array([5, -5]).reshape(1,2)\nnp.dot(brk, B)\ny = np.c_[np.sin(time), np.sin(time)] + np.random.normal(scale = .2, size=(100,2))+ np.dot(brk, B)\n\nplt.plot(time, y[:,0])\nplt.plot(time, y[:,1])\n\n# Temporal convolutional network\nn_filters = 2\nfilter_width = 3\ndilation_rates = [2**i for i in range(5)] \ninp = Input(shape=(None, 2))\nx = inp\nfor dilation_rate in dilation_rates:\n    x = Conv1D(filters=n_filters,\n               kernel_size=filter_width, \n               padding='causal',\n               activation = \"relu\",\n               dilation_rate=dilation_rate)(x)\nx = Dense(2)(x)\n\n\nmodel = Model(inputs = inp, outputs = x)\nmodel.compile(optimizer = Adam(), loss='mean_squared_error')\nmodel.summary()\n\ndef shift5(arr, num, fill_value=np.nan):\n    result = np.empty_like(arr)\n    if num &gt; 0:\n        result[:num] = fill_value\n        result[num:] = arr[:-num]\n    elif num &lt; 0:\n        result[num:] = fill_value\n        result[:num] = arr[-num:]\n    else:\n        result = arr\n    return result\n\n\n\nX = y.reshape(2,100,1)\nX = np.concatenate([X, np.concatenate([time.reshape(100,1),time.reshape(100,1)], axis = 1).reshape(2,100, 1)],\n                    axis = 2)\nX_tr = X[:,:95,:]\nX_te = X[:,5:,:]\n\nhistory = model.fit(X_tr, X_te,\n                batch_size=2,\n                epochs=10,\n                verbose = 1)\n</code></pre>\n\n<p>How would I modify this architecture to have two inputs and two outputs, with both input and output having local and global components?</p>\n",
                "tags": "<neural-network><deep-learning><keras><time-series><multitask-learning>",
                "answers": [
                    [
                        "47016",
                        "2",
                        "47000",
                        "",
                        "",
                        "<p>Stacked LSTM is one option in this scenario</p>\n\n<p><a href=\"https://i.stack.imgur.com/2YkSE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/2YkSE.png\" alt=\"enter image description here\"></a></p>\n\n<p>This assumes that First two LSTMs have different frequencies and City has static features (Like lat/long, one-hot-encoded value etc). If City is also time-series like series of population , mean income; it will be an LSTM as well. </p>\n\n<p>Code example for stacked LSTM : <a href=\"https://machinelearningmastery.com/stacked-long-short-term-memory-networks/\" rel=\"nofollow noreferrer\">https://machinelearningmastery.com/stacked-long-short-term-memory-networks/</a></p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6736",
            "_score": 8.180054,
            "_source": {
                "title": "TypeError: Cannot cast array data from dtype('float64') to dtype('S32') according to the rule 'safe'",
                "content": "TypeError: Cannot cast array data from dtype('float64') to dtype('S32') according to the rule 'safe' <p><a href=\"https://i.stack.imgur.com/aWlvb.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/aWlvb.png\" alt=\"\"></a></p>\n\n<p>I'm getting the above error while I'm extracting the sensor data from serial port and giving it for prediction.Tried reshape and string functions but every trial throws back me same error.i'm using mlp neuralnetwork in my model.Thanks in advance</p>\n <classification><scikit-learn><numpy><p>Spent some time with error and found that serial data consists a newline character\"\\n\" in it and it caused error pitch data is a float and due added character roll value is a string.So, changed code as below a little and it worked </p>\n\n<p><a href=\"https://i.stack.imgur.com/j71YH.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/j71YH.png\" alt=\"\"></a></p>\n",
                "codes": [
                    []
                ],
                "question_id:": "25933",
                "question_votes:": "1",
                "question_text:": "<p><a href=\"https://i.stack.imgur.com/aWlvb.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/aWlvb.png\" alt=\"\"></a></p>\n\n<p>I'm getting the above error while I'm extracting the sensor data from serial port and giving it for prediction.Tried reshape and string functions but every trial throws back me same error.i'm using mlp neuralnetwork in my model.Thanks in advance</p>\n",
                "tags": "<classification><scikit-learn><numpy>",
                "answers": [
                    [
                        "26010",
                        "2",
                        "25933",
                        "",
                        "",
                        "<p>Spent some time with error and found that serial data consists a newline character\"\\n\" in it and it caused error pitch data is a float and due added character roll value is a string.So, changed code as below a little and it worked </p>\n\n<p><a href=\"https://i.stack.imgur.com/j71YH.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/j71YH.png\" alt=\"\"></a></p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16209",
            "_score": 8.173724,
            "_source": {
                "title": "Deep learning: How to write pseudo algorithm for network architecture",
                "content": "Deep learning: How to write pseudo algorithm for network architecture <p>How do I write pseudo algorithm for any deep learning model?</p>\n\n<p>I was going through few deep learning papers on graph and there is pseudo algorithm for network architecture, Example :</p>\n\n<p><a href=\"https://i.stack.imgur.com/oWsXq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/oWsXq.png\" alt=\"enter image description here\"></a></p>\n\n<p>That is overall architecture described in paper.</p>\n\n<p>I want to write one pseudo algorithm for one custom network, Network structure is very simple, It's sentence classification using dynamic rnn.</p>\n\n<pre><code>Input is sentence [ batch_size x max_sentence_length x embedding_dim ]\n\nlabels are [ batch_size ]\n</code></pre>\n\n<p>network is send sentences to rnn and get the feature vectors after send this feature vector to one other nano network for attention part and get attention vector, after getting attention vector add one dense layer to reshape the feature vectors and get the probability values shape [ batch_size ] </p>\n\n<p>So nano network is:</p>\n\n<pre><code>import numpy as np\n#simple soft attention\n\ndef nano_network( logits, lstm_units ):\n\n    # just for example \n    logits_ = tf.reshape(logits,[-1, lstm_units])\n    attention_size = tf.get_variable(name='attention_size',\n                                         shape=[lstm_units,1],\n                                         dtype=tf.float32,\n                                         initializer=tf.random_uniform_initializer(-0.01,0.01))\n\n    attention_matmul =  tf.matmul(logits_,attention_size)\n    output_reshape = tf.reshape(attention_matmul,[tf.shape(logits)[0],tf.shape(logits)[1],-1])\n    return tf.squeeze(output_reshape)\n</code></pre>\n\n<p>Simple rnn network :</p>\n\n<pre><code>import tensorflow as tf\n\n#simple network\n\nclass Base_model(object):\n\n    def __init__(self):\n\n        tf.reset_default_graph()\n\n        # define placeholders\n        self.sentences        = tf.placeholder(tf.float32, [12, 50, 10], name='sentences') # batch_size x max_sentence_length x dim\n        self.targets          = tf.placeholder(tf.int32, [12], name='labels'  )\n\n\n        with tf.variable_scope('dynamic_rnn') as scope:\n            cell = tf.nn.rnn_cell.LSTMCell(num_units=5, state_is_tuple=True)\n            outputs, _states = tf.nn.dynamic_rnn(cell, self.sentences, dtype=tf.float32)\n\n\n        #attention function\n        self.output_s = nano_network(outputs,5)\n\n\n        # simple linear projection\n        self.output = tf.layers.dense(self.output_s,2)\n\n        cross_entropy  = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.targets,logits=self.output)\n\n        #loss calculation\n        loss = tf.reduce_mean(cross_entropy)\n\n        #train / network weights update\n        self.train = tf.train.AdamOptimizer().minimize(loss)\n\n\n        self.out = { 'loss':loss, 'train':self.train } \n</code></pre>\n\n<p>If someone want to run this code, here is random values for testing the code:</p>\n\n<pre><code># #model train\n\n# def rand_exec(model):\n#     with tf.Session() as sess:\n#         sess.run(tf.global_variables_initializer())\n\n#         for i in range(100):\n#             loss_ = sess.run(model.out,\n#                      feed_dict = {\n#                          model.sentences  : np.random.randint(0, 10, [12,50,10]),\n#                          model.targets  : np.random.randint(0, 2, [12] )})\n\n#             print(loss_['loss'])\n\n# # wdim, hdim, vocab_size, num_labels,threshold,relation_embeddings,relation_dim,t,adj_file\n# if __name__ == '__main__':\n\n#     model = Base_model()\n#     out = rand_exec(model)\n</code></pre>\n\n<p>Now, I want to write pseudo algorithm for this simple network.</p>\n\n<p>I tried to convert this network architecture into pseudo algorithm, Here is my pseudo code:</p>\n\n<p><a href=\"https://i.stack.imgur.com/YyPar.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/YyPar.png\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://docs.google.com/document/d/1PkAlJbLh5U3nTYZiKgmdf2bkKa0gFwFA62TpGfnpo_s/edit?usp=sharing\" rel=\"nofollow noreferrer\">Here is textual format of this algorithm</a> </p>\n\n<p>But I am confuse if it is correct or not like the parameters update rule and other things in algorithm.</p>\n\n<p>Thank you !</p>\n <machine-learning><python><deep-learning><tensorflow><algorithms>",
                "codes": [],
                "question_id:": "53591",
                "question_votes:": "",
                "question_text:": "<p>How do I write pseudo algorithm for any deep learning model?</p>\n\n<p>I was going through few deep learning papers on graph and there is pseudo algorithm for network architecture, Example :</p>\n\n<p><a href=\"https://i.stack.imgur.com/oWsXq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/oWsXq.png\" alt=\"enter image description here\"></a></p>\n\n<p>That is overall architecture described in paper.</p>\n\n<p>I want to write one pseudo algorithm for one custom network, Network structure is very simple, It's sentence classification using dynamic rnn.</p>\n\n<pre><code>Input is sentence [ batch_size x max_sentence_length x embedding_dim ]\n\nlabels are [ batch_size ]\n</code></pre>\n\n<p>network is send sentences to rnn and get the feature vectors after send this feature vector to one other nano network for attention part and get attention vector, after getting attention vector add one dense layer to reshape the feature vectors and get the probability values shape [ batch_size ] </p>\n\n<p>So nano network is:</p>\n\n<pre><code>import numpy as np\n#simple soft attention\n\ndef nano_network( logits, lstm_units ):\n\n    # just for example \n    logits_ = tf.reshape(logits,[-1, lstm_units])\n    attention_size = tf.get_variable(name='attention_size',\n                                         shape=[lstm_units,1],\n                                         dtype=tf.float32,\n                                         initializer=tf.random_uniform_initializer(-0.01,0.01))\n\n    attention_matmul =  tf.matmul(logits_,attention_size)\n    output_reshape = tf.reshape(attention_matmul,[tf.shape(logits)[0],tf.shape(logits)[1],-1])\n    return tf.squeeze(output_reshape)\n</code></pre>\n\n<p>Simple rnn network :</p>\n\n<pre><code>import tensorflow as tf\n\n#simple network\n\nclass Base_model(object):\n\n    def __init__(self):\n\n        tf.reset_default_graph()\n\n        # define placeholders\n        self.sentences        = tf.placeholder(tf.float32, [12, 50, 10], name='sentences') # batch_size x max_sentence_length x dim\n        self.targets          = tf.placeholder(tf.int32, [12], name='labels'  )\n\n\n        with tf.variable_scope('dynamic_rnn') as scope:\n            cell = tf.nn.rnn_cell.LSTMCell(num_units=5, state_is_tuple=True)\n            outputs, _states = tf.nn.dynamic_rnn(cell, self.sentences, dtype=tf.float32)\n\n\n        #attention function\n        self.output_s = nano_network(outputs,5)\n\n\n        # simple linear projection\n        self.output = tf.layers.dense(self.output_s,2)\n\n        cross_entropy  = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.targets,logits=self.output)\n\n        #loss calculation\n        loss = tf.reduce_mean(cross_entropy)\n\n        #train / network weights update\n        self.train = tf.train.AdamOptimizer().minimize(loss)\n\n\n        self.out = { 'loss':loss, 'train':self.train } \n</code></pre>\n\n<p>If someone want to run this code, here is random values for testing the code:</p>\n\n<pre><code># #model train\n\n# def rand_exec(model):\n#     with tf.Session() as sess:\n#         sess.run(tf.global_variables_initializer())\n\n#         for i in range(100):\n#             loss_ = sess.run(model.out,\n#                      feed_dict = {\n#                          model.sentences  : np.random.randint(0, 10, [12,50,10]),\n#                          model.targets  : np.random.randint(0, 2, [12] )})\n\n#             print(loss_['loss'])\n\n# # wdim, hdim, vocab_size, num_labels,threshold,relation_embeddings,relation_dim,t,adj_file\n# if __name__ == '__main__':\n\n#     model = Base_model()\n#     out = rand_exec(model)\n</code></pre>\n\n<p>Now, I want to write pseudo algorithm for this simple network.</p>\n\n<p>I tried to convert this network architecture into pseudo algorithm, Here is my pseudo code:</p>\n\n<p><a href=\"https://i.stack.imgur.com/YyPar.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/YyPar.png\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://docs.google.com/document/d/1PkAlJbLh5U3nTYZiKgmdf2bkKa0gFwFA62TpGfnpo_s/edit?usp=sharing\" rel=\"nofollow noreferrer\">Here is textual format of this algorithm</a> </p>\n\n<p>But I am confuse if it is correct or not like the parameters update rule and other things in algorithm.</p>\n\n<p>Thank you !</p>\n",
                "tags": "<machine-learning><python><deep-learning><tensorflow><algorithms>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14583",
            "_score": 8.113991,
            "_source": {
                "title": "ValueError: Tensor Tensor(\"activation_5/Softmax:0\", shape=(?, 2), dtype=float32) is not an element of this graph",
                "content": "ValueError: Tensor Tensor(\"activation_5/Softmax:0\", shape=(?, 2), dtype=float32) is not an element of this graph <p>There seem to be an issue with predicting using my keras model. I had trained it using the following keras code: </p>\n\n<pre><code>model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(150, 150,3),padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n\nmodel.add(Conv2D(32, (3, 3),padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n\nmodel.add(Conv2D(64, (3, 3),padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n\nmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='binary_crossentropy',\n          optimizer='rmsprop',\n          metrics=['accuracy'])\n</code></pre>\n\n<p>However when i predict it on my local system after training with the shape (1,150,150,3) . It predicts accurately with an accuracy over 90%. however when i load my model on my raspberry pi and input the image of the same shape (1,150,150,3) it returns an error. Below is the code loaded on the raspberry pi to predict from the keras model.</p>\n\n<pre><code>    data = numpy.fromstring(stream.getvalue() , dtype = numpy.uint8)\n    image5 = cv.imdecode(data , 1)\n    print(image5.shape)\n    #cv.imwrite('uhhu.png',image5)\n    img = cv.resize(image5,(150,150))\n    x = img_to_array(img)\n    x = x.reshape((1,) + x.shape)\n    x = x/255\n    x = numpy.float32(x)\n    print(x.shape)\n    score = loaded_model.predict(x)\n    print(score)\n</code></pre>\n <neural-network><deep-learning><keras><p>The solution to this issue is predict from the keras model when running a tensorflow graph as default. </p>\n\n<pre><code>import tensorflow as tf\ngraph = tf.get_default_graph()\n\nglobal graph\nwith graph.as_default():\n    result = loaded_model.predict(x)\n</code></pre>\n",
                "codes": [
                    [
                        "import tensorflow as tf\ngraph = tf.get_default_graph()\n\nglobal graph\nwith graph.as_default():\n    result = loaded_model.predict(x)\n"
                    ]
                ],
                "question_id:": "48984",
                "question_votes:": "",
                "question_text:": "<p>There seem to be an issue with predicting using my keras model. I had trained it using the following keras code: </p>\n\n<pre><code>model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(150, 150,3),padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n\nmodel.add(Conv2D(32, (3, 3),padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n\nmodel.add(Conv2D(64, (3, 3),padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n\nmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='binary_crossentropy',\n          optimizer='rmsprop',\n          metrics=['accuracy'])\n</code></pre>\n\n<p>However when i predict it on my local system after training with the shape (1,150,150,3) . It predicts accurately with an accuracy over 90%. however when i load my model on my raspberry pi and input the image of the same shape (1,150,150,3) it returns an error. Below is the code loaded on the raspberry pi to predict from the keras model.</p>\n\n<pre><code>    data = numpy.fromstring(stream.getvalue() , dtype = numpy.uint8)\n    image5 = cv.imdecode(data , 1)\n    print(image5.shape)\n    #cv.imwrite('uhhu.png',image5)\n    img = cv.resize(image5,(150,150))\n    x = img_to_array(img)\n    x = x.reshape((1,) + x.shape)\n    x = x/255\n    x = numpy.float32(x)\n    print(x.shape)\n    score = loaded_model.predict(x)\n    print(score)\n</code></pre>\n",
                "tags": "<neural-network><deep-learning><keras>",
                "answers": [
                    [
                        "49025",
                        "2",
                        "48984",
                        "",
                        "",
                        "<p>The solution to this issue is predict from the keras model when running a tensorflow graph as default. </p>\n\n<pre><code>import tensorflow as tf\ngraph = tf.get_default_graph()\n\nglobal graph\nwith graph.as_default():\n    result = loaded_model.predict(x)\n</code></pre>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3821",
            "_score": 8.085057,
            "_source": {
                "title": "shape of theano tensor variable out of keras Conv2D",
                "content": "shape of theano tensor variable out of keras Conv2D <p>Being new to theano, pls bear with me. I thought the shape of the tensor variable is already well defined out of the Conv2D layer since the input is specified, as follow,</p>\n\n<pre><code>from keras.layers import Input, Convolution2D\nimport theano\ninput_img = Input(shape=(1, 28, 28))\nx = Convolution2D(16, 3, 3, activation='relu', border_mode='same')   (input_img)\nprint type(x)\nprint theano.tensor.shape(x)\n</code></pre>\n\n<p>But the output is,</p>\n\n<pre><code>&lt;class 'theano.tensor.var.TensorVariable'&gt;\nShape.0\n</code></pre>\n\n<p>Since I'm taking the default stride of 1, and <code>same</code> border mode here means that padding is added so the output is the same as input. Using this information I could calculate by hand what the output shape should be.  </p>\n\n<p>Did I miss something here? The question is how to get the shape of the output of a convolution layer?</p>\n <convnet><keras><theano><p>You can't get the shape of a theano tensor, because it is not fixed. The output of the convolutional layer is just a symbolic variable and its shape depends on whatever you put into the layer as input.</p>\n\n<p>You can get the shape of the output for a specific input by making a theano function for the output of the layer, and feeding a numpy array through the function:</p>\n\n<pre><code>import numpy as np\ninput = np.ones(28*28).reshape(1, 1, 28, 28).astype('float32')\nfn = theano.function([input_img], x)\n\nprint fn(input).shape\n&gt;&gt;&gt; (1, 16, 28, 28)\n</code></pre>\n",
                "codes": [
                    [
                        "import numpy as np\ninput = np.ones(28*28).reshape(1, 1, 28, 28).astype('float32')\nfn = theano.function([input_img], x)\n\nprint fn(input).shape\n>>> (1, 16, 28, 28)\n"
                    ]
                ],
                "question_id:": "15841",
                "question_votes:": "1",
                "question_text:": "<p>Being new to theano, pls bear with me. I thought the shape of the tensor variable is already well defined out of the Conv2D layer since the input is specified, as follow,</p>\n\n<pre><code>from keras.layers import Input, Convolution2D\nimport theano\ninput_img = Input(shape=(1, 28, 28))\nx = Convolution2D(16, 3, 3, activation='relu', border_mode='same')   (input_img)\nprint type(x)\nprint theano.tensor.shape(x)\n</code></pre>\n\n<p>But the output is,</p>\n\n<pre><code>&lt;class 'theano.tensor.var.TensorVariable'&gt;\nShape.0\n</code></pre>\n\n<p>Since I'm taking the default stride of 1, and <code>same</code> border mode here means that padding is added so the output is the same as input. Using this information I could calculate by hand what the output shape should be.  </p>\n\n<p>Did I miss something here? The question is how to get the shape of the output of a convolution layer?</p>\n",
                "tags": "<convnet><keras><theano>",
                "answers": [
                    [
                        "15843",
                        "2",
                        "15841",
                        "",
                        "",
                        "<p>You can't get the shape of a theano tensor, because it is not fixed. The output of the convolutional layer is just a symbolic variable and its shape depends on whatever you put into the layer as input.</p>\n\n<p>You can get the shape of the output for a specific input by making a theano function for the output of the layer, and feeding a numpy array through the function:</p>\n\n<pre><code>import numpy as np\ninput = np.ones(28*28).reshape(1, 1, 28, 28).astype('float32')\nfn = theano.function([input_img], x)\n\nprint fn(input).shape\n&gt;&gt;&gt; (1, 16, 28, 28)\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10461",
            "_score": 8.085057,
            "_source": {
                "title": "After one hot encoding, instead of columns, my number of rows are increasing",
                "content": "After one hot encoding, instead of columns, my number of rows are increasing <p>This is the code: </p>\n\n<pre><code>housing_cat1 = X_train[:,[2,7,8,10,11,13,14,15,16,21,22,23,24,25,27,28,29,30,31,32,33,35,39,40,41,42,53,55,57,58,60,63,64,65,73,74,78,79]].reshape(1,-1)\n\nfrom future_encoders import OneHotEncoder\n\ncat_encoder = OneHotEncoder(sparse=False)                  # Set to True if sparse matrix is needed\nhousing_cat_1_1hot = cat_encoder.fit_transform(housing_cat)\nhousing_cat_1_1hot\n</code></pre>\n <machine-learning><python><scikit-learn><categorical-data><p><a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html\" rel=\"nofollow noreferrer\">get_dummies</a> function of pandas can also be used for this. Just create a pandas dataframe with your data and subject it to this function. There is no need to list categorical variables: </p>\n\n<pre><code>X_train_df = pandas.DataFrame(data=X_train)\nX_train_df_1hot = pandas.get_dummies(X_train_df)\n</code></pre>\n\n<p>You can specify prefix etc also for new columns is required: </p>\n\n<pre><code>pandas.get_dummies(data, prefix=None, prefix_sep='_', \n     dummy_na=False, columns=None, \n     sparse=False, drop_first=False, \n     dtype=None)\n</code></pre>\n\n<p>Data as a list of lists is available with <code>.values</code> attribute which can be converted to a numpy array: </p>\n\n<pre><code>housing_cat_1hot = numpy.array(X_train_df_1hot.values)\n</code></pre>\n<p>What is the shape of housing_cat1, and what is the shape of housing_cat_1hot?</p>\n\n<p>You shouldn't be reshaping to (1, -1). This takes all the data and puts it in one long row.</p>\n",
                "codes": [
                    [
                        "X_train_df = pandas.DataFrame(data=X_train)\nX_train_df_1hot = pandas.get_dummies(X_train_df)\n",
                        "pandas.get_dummies(data, prefix=None, prefix_sep='_', \n     dummy_na=False, columns=None, \n     sparse=False, drop_first=False, \n     dtype=None)\n",
                        "housing_cat_1hot = numpy.array(X_train_df_1hot.values)\n"
                    ],
                    []
                ],
                "question_id:": "37529",
                "question_votes:": "3",
                "question_text:": "<p>This is the code: </p>\n\n<pre><code>housing_cat1 = X_train[:,[2,7,8,10,11,13,14,15,16,21,22,23,24,25,27,28,29,30,31,32,33,35,39,40,41,42,53,55,57,58,60,63,64,65,73,74,78,79]].reshape(1,-1)\n\nfrom future_encoders import OneHotEncoder\n\ncat_encoder = OneHotEncoder(sparse=False)                  # Set to True if sparse matrix is needed\nhousing_cat_1_1hot = cat_encoder.fit_transform(housing_cat)\nhousing_cat_1_1hot\n</code></pre>\n",
                "tags": "<machine-learning><python><scikit-learn><categorical-data>",
                "answers": [
                    [
                        "41830",
                        "2",
                        "37529",
                        "",
                        "",
                        "<p><a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html\" rel=\"nofollow noreferrer\">get_dummies</a> function of pandas can also be used for this. Just create a pandas dataframe with your data and subject it to this function. There is no need to list categorical variables: </p>\n\n<pre><code>X_train_df = pandas.DataFrame(data=X_train)\nX_train_df_1hot = pandas.get_dummies(X_train_df)\n</code></pre>\n\n<p>You can specify prefix etc also for new columns is required: </p>\n\n<pre><code>pandas.get_dummies(data, prefix=None, prefix_sep='_', \n     dummy_na=False, columns=None, \n     sparse=False, drop_first=False, \n     dtype=None)\n</code></pre>\n\n<p>Data as a list of lists is available with <code>.values</code> attribute which can be converted to a numpy array: </p>\n\n<pre><code>housing_cat_1hot = numpy.array(X_train_df_1hot.values)\n</code></pre>\n",
                        "",
                        "1"
                    ],
                    [
                        "37531",
                        "2",
                        "37529",
                        "",
                        "",
                        "<p>What is the shape of housing_cat1, and what is the shape of housing_cat_1hot?</p>\n\n<p>You shouldn't be reshaping to (1, -1). This takes all the data and puts it in one long row.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14178",
            "_score": 8.038725,
            "_source": {
                "title": "Why is my generator loss function increasing with iterations?",
                "content": "Why is my generator loss function increasing with iterations? <p>I'm trying to train a DC-GAN on CIFAR-10 Dataset. I'm using Binary Cross Entropy as my loss function for both discriminator and generator (appended with non-trainable discriminator). If I train using Adam optimizer, the GAN is training fine. But if I replace the optimizer by SGD, the training is going haywire. The generator accuracy starts at some higher point and with iterations, it goes to 0 and stays there. The discriminator accuracy starts at some lower point and reaches somewhere around 0.5 (expected, right?). The peculiar thing is the generator loss function is increasing with iterations. I though may be the step is too high. I tried changing the step size. I tried using momentum with SGD. In all these cases, the generator may or may not decrease in the beginning, but then increases for sure. So, I think there is something inherently wrong in my model. I know training Deep Models is difficult and GANs still more, but there has to be some reason/heuristic as to why this is happening. Any inputs in appreciated. I'm new to Neural Networks, Deep Learning and hence new to GANs as well.</p>\n\n<p>Here is my code:\nCifar10Models.py</p>\n\n<pre><code>from keras import Sequential\nfrom keras.initializers import TruncatedNormal\nfrom keras.layers import Activation, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Flatten, LeakyReLU, Reshape\nfrom keras.optimizers import SGD\n\n\nclass DcGan:\n    def __init__(self, print_model_summary: bool = False):\n        self.generator_model = None\n        self.discriminator_model = None\n        self.concatenated_model = None\n        self.print_model_summary = print_model_summary\n\n    def build_generator_model(self):\n        if self.generator_model:\n            return self.generator_model\n\n        self.generator_model = Sequential()\n        self.generator_model.add(Dense(4 * 4 * 512, input_dim=100,\n                                       kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(BatchNormalization(momentum=0.5))\n        self.generator_model.add(Activation('relu'))\n        self.generator_model.add(Reshape((4, 4, 512)))\n\n        self.generator_model.add(Conv2DTranspose(256, 3, strides=2, padding='same',\n                                                 kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(BatchNormalization(momentum=0.5))\n        self.generator_model.add(Activation('relu'))\n\n        self.generator_model.add(Conv2DTranspose(128, 3, strides=2, padding='same',\n                                                 kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(BatchNormalization(momentum=0.5))\n        self.generator_model.add(Activation('relu'))\n\n        self.generator_model.add(Conv2DTranspose(64, 3, strides=2, padding='same',\n                                                 kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(BatchNormalization(momentum=0.5))\n        self.generator_model.add(Activation('relu'))\n\n        self.generator_model.add(Conv2D(3, 3, padding='same',\n                                        kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(Activation('tanh'))\n\n        if self.print_model_summary:\n            self.generator_model.summary()\n\n        return self.generator_model\n\n    def build_discriminator_model(self):\n        if self.discriminator_model:\n            return self.discriminator_model\n\n        self.discriminator_model = Sequential()\n        self.discriminator_model.add(Conv2D(128, 3, strides=2, input_shape=(32, 32, 3), padding='same',\n                                            kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.discriminator_model.add(LeakyReLU(alpha=0.2))\n\n        self.discriminator_model.add(Conv2D(256, 3, strides=2, padding='same',\n                                            kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(BatchNormalization(momentum=0.5))\n        self.discriminator_model.add(LeakyReLU(alpha=0.2))\n\n        self.discriminator_model.add(Conv2D(512, 3, strides=2, padding='same',\n                                            kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(BatchNormalization(momentum=0.5))\n        self.discriminator_model.add(LeakyReLU(alpha=0.2))\n\n        self.discriminator_model.add(Conv2D(1024, 3, strides=2, padding='same',\n                                            kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(BatchNormalization(momentum=0.5))\n        self.discriminator_model.add(LeakyReLU(alpha=0.2))\n\n        self.discriminator_model.add(Flatten())\n        self.discriminator_model.add(Dense(1, kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(BatchNormalization(momentum=0.5))\n        self.discriminator_model.add(Activation('sigmoid'))\n\n        if self.print_model_summary:\n            self.discriminator_model.summary()\n\n        return self.discriminator_model\n\n    def build_concatenated_model(self):\n        if self.concatenated_model:\n            return self.concatenated_model\n\n        self.concatenated_model = Sequential()\n        self.concatenated_model.add(self.generator_model)\n        self.concatenated_model.add(self.discriminator_model)\n\n        if self.print_model_summary:\n            self.concatenated_model.summary()\n\n        return self.concatenated_model\n\n    def build_dc_gan(self):\n        self.build_generator_model()\n        self.build_discriminator_model()\n        self.build_concatenated_model()\n\n        self.discriminator_model.trainable = True\n        optimizer = SGD(lr=0.0002)\n        self.discriminator_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n        self.discriminator_model.trainable = False\n        optimizer = SGD(lr=0.0001)\n        self.concatenated_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n        self.discriminator_model.trainable = True\n</code></pre>\n\n<p>Cifar10Trainer.py:</p>\n\n<pre><code># Based on https://towardsdatascience.com/gan-by-example-using-keras-on-tensorflow-backend-1a6d515a60d0\n\nimport os\n\nimport datetime\nimport numpy\nimport time\nfrom keras.datasets import cifar10\nfrom keras.utils import np_utils\nfrom matplotlib import pyplot as plt\n\nimport Cifar10Models\n\nlog_file_name = 'logs.csv'\n\n\nclass Cifar10Trainer:\n    def __init__(self):\n        self.x_train, self.y_train = self.get_train_and_test_data()\n        self.dc_gan = Cifar10Models.DcGan()\n        self.dc_gan.build_dc_gan()\n\n    @staticmethod\n    def get_train_and_test_data():\n        (x_train, y_train), _ = cifar10.load_data()\n        x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 3)\n        # Generator output has tanh activation whose range is [-1,1]\n        x_train = (x_train.astype('float32') * 2 / 255) - 1\n        y_train = np_utils.to_categorical(y_train, 10)\n        return x_train, y_train\n\n    def train(self, train_steps=10000, batch_size=128, log_interval=10, save_interval=100,\n              output_folder_path='./Trained_Models/'):\n        self.initialize_log(output_folder_path)\n        self.sample_real_images(output_folder_path)\n        for i in range(train_steps):\n            # Get real (Database) Images\n            images_real = self.x_train[numpy.random.randint(0, self.x_train.shape[0], size=batch_size), :, :, :]\n\n            # Generate Fake Images\n            noise = numpy.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n            images_fake = self.dc_gan.generator_model.predict(noise)\n\n            # Train discriminator on both real and fake images\n            x = numpy.concatenate((images_real, images_fake), axis=0)\n            y = numpy.ones([2 * batch_size, 1])\n            y[batch_size:, :] = 0\n            d_loss = self.dc_gan.discriminator_model.train_on_batch(x, y)\n\n            # Train generator i.e. concatenated model\n            noise = numpy.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n            y = numpy.ones([batch_size, 1])\n            g_loss = self.dc_gan.concatenated_model.train_on_batch(noise, y)\n\n            # Print Logs, Save Models, generate sample images\n            if (i + 1) % log_interval == 0:\n                self.log_progress(output_folder_path, i + 1, g_loss, d_loss)\n            if (i + 1) % save_interval == 0:\n                self.save_models(output_folder_path, i + 1)\n                self.generate_images(output_folder_path, i + 1)\n\n    @staticmethod\n    def initialize_log(output_folder_path):\n        log_line = 'Iteration No, Generator Loss, Generator Accuracy, Discriminator Loss, Discriminator Accuracy, ' \\\n                   'Time\\n'\n        with open(os.path.join(output_folder_path, log_file_name), 'w') as log_file:\n            log_file.write(log_line)\n\n    @staticmethod\n    def log_progress(output_folder_path, iteration_no, g_loss, d_loss):\n        log_line = '{0:05},{1:2.4f},{2:0.4f},{3:2.4f},{4:0.4f},{5}\\n' \\\n            .format(iteration_no, g_loss[0], g_loss[1], d_loss[0], d_loss[1],\n                    datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n        with open(os.path.join(output_folder_path, log_file_name), 'a') as log_file:\n            log_file.write(log_line)\n        print(log_line)\n\n    def save_models(self, output_folder_path, iteration_no):\n        self.dc_gan.generator_model.save(\n            os.path.join(output_folder_path, 'generator_model_{0}.h5'.format(iteration_no)))\n        self.dc_gan.discriminator_model.save(\n            os.path.join(output_folder_path, 'discriminator_model_{0}.h5'.format(iteration_no)))\n        self.dc_gan.concatenated_model.save(\n            os.path.join(output_folder_path, 'concatenated_model_{0}.h5'.format(iteration_no)))\n\n    def sample_real_images(self, output_folder_path):\n        filepath = os.path.join(output_folder_path, 'CIFAR10_Sample_Real_Images.png')\n        i = numpy.random.randint(0, self.x_train.shape[0], 16)\n        images = self.x_train[i, :, :, :]\n        plt.figure(figsize=(10, 10))\n        for i in range(16):\n            plt.subplot(4, 4, i + 1)\n            image = images[i, :, :, :]\n            image = numpy.reshape(image, [32, 32, 3])\n            plt.imshow(image)\n            plt.axis('off')\n        plt.tight_layout()\n        plt.savefig(filepath)\n        plt.close('all')\n\n    def generate_images(self, output_folder_path, iteration_no, noise=None):\n        filepath = os.path.join(output_folder_path, 'CIFAR10_Gen_Image{0}.png'.format(iteration_no))\n        if noise is None:\n            noise = numpy.random.uniform(-1, 1, size=[16, 100])\n        # Generator output has tanh activation whose range is [-1,1]\n        images = (self.dc_gan.generator_model.predict(noise) + 1) / 2\n        plt.figure(figsize=(10, 10))\n        for i in range(16):\n            plt.subplot(4, 4, i + 1)\n            image = images[i, :, :, :]\n            image = numpy.reshape(image, [32, 32, 3])\n            plt.imshow(image)\n            plt.axis('off')\n        plt.tight_layout()\n        plt.savefig(filepath)\n        plt.close('all')\n\n\ndef main():\n    cifar10_trainer = Cifar10Trainer()\n    cifar10_trainer.train(train_steps=10000, log_interval=10, save_interval=100)\n    del cifar10_trainer.dc_gan\n    return\n\n\nif __name__ == '__main__':\n    start_time = time.time()\n    print('Program Started at {0}'.format(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))))\n    main()\n    end_time = time.time()\n    print('Program Ended at {0}'.format(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))))\n    print('Total Execution Time: {0}s'.format(datetime.timedelta(seconds=end_time - start_time)))\n</code></pre>\n\n<p>Some of the graphs are as below:</p>\n\n<ol>\n<li><p>Discriminator Optimizer: Adam(lr=0.0001, beta1=0.5)<br>\nGenerator Optimizer: Adam(lr=0.0001, beta1=0.5)\n<a href=\"https://i.stack.imgur.com/u04Yz.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/u04Yz.png\" alt=\"enter image description here\"></a></p></li>\n<li><p>Discriminator Optimizer: SGD(lr=0.0001)<br>\nGenerator Optimizer: SGD(lr=0.0001)\n<a href=\"https://i.stack.imgur.com/QQ0NZ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/QQ0NZ.png\" alt=\"enter image description here\"></a></p></li>\n<li><p>Discriminator Optimizer: SGD(lr=0.0001)<br>\nGenerator Optimizer: SGD(lr=0.001)\n<a href=\"https://i.stack.imgur.com/DX2q3.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/DX2q3.png\" alt=\"enter image description here\"></a></p></li>\n<li><p>Discriminator Optimizer: SGD(lr=0.0001)<br>\nGenerator Optimizer: SGD(lr=0.0005)\n<a href=\"https://i.stack.imgur.com/a8gQg.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/a8gQg.png\" alt=\"enter image description here\"></a></p></li>\n</ol>\n\n<p><strong>Note:</strong><br>\nThis question was originally asked in StackOverflow and then re-asked here as per suggestions in SO</p>\n\n<p><strong>Edit1:</strong><br>\nAdding some generated images for reference</p>\n\n<ol>\n<li><p>Images generated by Adam Optimizer\n<a href=\"https://i.stack.imgur.com/WNnOk.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WNnOk.png\" alt=\"enter image description here\"></a></p></li>\n<li><p>Images generated by SGD Optimizer\n<a href=\"https://i.stack.imgur.com/A7WvZ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/A7WvZ.png\" alt=\"enter image description here\"></a></p></li>\n</ol>\n <python><deep-learning><keras><optimization><gan><p>I think that there are several issues with your model:</p>\n\n<p>First of all - Your generator's loss is not the generator's loss. You have on binary cross-entropy loss function for the discriminator, and you have another binary cross-entropy loss function for the concatenated model whose output is again the discriminator's output (on generated images). \nThe \"generator loss\" you are showing is the discriminator's loss when dealing with generated images. <strong>You want this loss to go up</strong>, it means that your model successfully generates images that you discriminator fails to catch (as can be seen in the overall discriminator's accuracy which is at 0.5).</p>\n\n<p>Another issue, is that you should add some generator regularization in the form of an actual generator loss (\"generator objective function\"). You can read about the different options in <a href=\"https://towardsdatascience.com/gan-objective-functions-gans-and-their-variations-ad77340bce3c\" rel=\"nofollow noreferrer\">GAN Objective Functions: GANs and Their Variations</a>.</p>\n\n<p>A final issue that I see is that you are passing the generated images thru a final hyperbolic tangent activation function, and I don't really understand why? The generator in your case is supposed to generate a \"believable\" CIFAR10 image, which is a 32x32x3 tensor with values in the range [0,255] or [0,1]. Your generator's output has a potential range of [-1,1] (as you state in your code). </p>\n",
                "codes": [
                    []
                ],
                "question_id:": "47875",
                "question_votes:": "1",
                "question_text:": "<p>I'm trying to train a DC-GAN on CIFAR-10 Dataset. I'm using Binary Cross Entropy as my loss function for both discriminator and generator (appended with non-trainable discriminator). If I train using Adam optimizer, the GAN is training fine. But if I replace the optimizer by SGD, the training is going haywire. The generator accuracy starts at some higher point and with iterations, it goes to 0 and stays there. The discriminator accuracy starts at some lower point and reaches somewhere around 0.5 (expected, right?). The peculiar thing is the generator loss function is increasing with iterations. I though may be the step is too high. I tried changing the step size. I tried using momentum with SGD. In all these cases, the generator may or may not decrease in the beginning, but then increases for sure. So, I think there is something inherently wrong in my model. I know training Deep Models is difficult and GANs still more, but there has to be some reason/heuristic as to why this is happening. Any inputs in appreciated. I'm new to Neural Networks, Deep Learning and hence new to GANs as well.</p>\n\n<p>Here is my code:\nCifar10Models.py</p>\n\n<pre><code>from keras import Sequential\nfrom keras.initializers import TruncatedNormal\nfrom keras.layers import Activation, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Flatten, LeakyReLU, Reshape\nfrom keras.optimizers import SGD\n\n\nclass DcGan:\n    def __init__(self, print_model_summary: bool = False):\n        self.generator_model = None\n        self.discriminator_model = None\n        self.concatenated_model = None\n        self.print_model_summary = print_model_summary\n\n    def build_generator_model(self):\n        if self.generator_model:\n            return self.generator_model\n\n        self.generator_model = Sequential()\n        self.generator_model.add(Dense(4 * 4 * 512, input_dim=100,\n                                       kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(BatchNormalization(momentum=0.5))\n        self.generator_model.add(Activation('relu'))\n        self.generator_model.add(Reshape((4, 4, 512)))\n\n        self.generator_model.add(Conv2DTranspose(256, 3, strides=2, padding='same',\n                                                 kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(BatchNormalization(momentum=0.5))\n        self.generator_model.add(Activation('relu'))\n\n        self.generator_model.add(Conv2DTranspose(128, 3, strides=2, padding='same',\n                                                 kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(BatchNormalization(momentum=0.5))\n        self.generator_model.add(Activation('relu'))\n\n        self.generator_model.add(Conv2DTranspose(64, 3, strides=2, padding='same',\n                                                 kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(BatchNormalization(momentum=0.5))\n        self.generator_model.add(Activation('relu'))\n\n        self.generator_model.add(Conv2D(3, 3, padding='same',\n                                        kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(Activation('tanh'))\n\n        if self.print_model_summary:\n            self.generator_model.summary()\n\n        return self.generator_model\n\n    def build_discriminator_model(self):\n        if self.discriminator_model:\n            return self.discriminator_model\n\n        self.discriminator_model = Sequential()\n        self.discriminator_model.add(Conv2D(128, 3, strides=2, input_shape=(32, 32, 3), padding='same',\n                                            kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.discriminator_model.add(LeakyReLU(alpha=0.2))\n\n        self.discriminator_model.add(Conv2D(256, 3, strides=2, padding='same',\n                                            kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(BatchNormalization(momentum=0.5))\n        self.discriminator_model.add(LeakyReLU(alpha=0.2))\n\n        self.discriminator_model.add(Conv2D(512, 3, strides=2, padding='same',\n                                            kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(BatchNormalization(momentum=0.5))\n        self.discriminator_model.add(LeakyReLU(alpha=0.2))\n\n        self.discriminator_model.add(Conv2D(1024, 3, strides=2, padding='same',\n                                            kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(BatchNormalization(momentum=0.5))\n        self.discriminator_model.add(LeakyReLU(alpha=0.2))\n\n        self.discriminator_model.add(Flatten())\n        self.discriminator_model.add(Dense(1, kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        self.generator_model.add(BatchNormalization(momentum=0.5))\n        self.discriminator_model.add(Activation('sigmoid'))\n\n        if self.print_model_summary:\n            self.discriminator_model.summary()\n\n        return self.discriminator_model\n\n    def build_concatenated_model(self):\n        if self.concatenated_model:\n            return self.concatenated_model\n\n        self.concatenated_model = Sequential()\n        self.concatenated_model.add(self.generator_model)\n        self.concatenated_model.add(self.discriminator_model)\n\n        if self.print_model_summary:\n            self.concatenated_model.summary()\n\n        return self.concatenated_model\n\n    def build_dc_gan(self):\n        self.build_generator_model()\n        self.build_discriminator_model()\n        self.build_concatenated_model()\n\n        self.discriminator_model.trainable = True\n        optimizer = SGD(lr=0.0002)\n        self.discriminator_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n        self.discriminator_model.trainable = False\n        optimizer = SGD(lr=0.0001)\n        self.concatenated_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n        self.discriminator_model.trainable = True\n</code></pre>\n\n<p>Cifar10Trainer.py:</p>\n\n<pre><code># Based on https://towardsdatascience.com/gan-by-example-using-keras-on-tensorflow-backend-1a6d515a60d0\n\nimport os\n\nimport datetime\nimport numpy\nimport time\nfrom keras.datasets import cifar10\nfrom keras.utils import np_utils\nfrom matplotlib import pyplot as plt\n\nimport Cifar10Models\n\nlog_file_name = 'logs.csv'\n\n\nclass Cifar10Trainer:\n    def __init__(self):\n        self.x_train, self.y_train = self.get_train_and_test_data()\n        self.dc_gan = Cifar10Models.DcGan()\n        self.dc_gan.build_dc_gan()\n\n    @staticmethod\n    def get_train_and_test_data():\n        (x_train, y_train), _ = cifar10.load_data()\n        x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 3)\n        # Generator output has tanh activation whose range is [-1,1]\n        x_train = (x_train.astype('float32') * 2 / 255) - 1\n        y_train = np_utils.to_categorical(y_train, 10)\n        return x_train, y_train\n\n    def train(self, train_steps=10000, batch_size=128, log_interval=10, save_interval=100,\n              output_folder_path='./Trained_Models/'):\n        self.initialize_log(output_folder_path)\n        self.sample_real_images(output_folder_path)\n        for i in range(train_steps):\n            # Get real (Database) Images\n            images_real = self.x_train[numpy.random.randint(0, self.x_train.shape[0], size=batch_size), :, :, :]\n\n            # Generate Fake Images\n            noise = numpy.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n            images_fake = self.dc_gan.generator_model.predict(noise)\n\n            # Train discriminator on both real and fake images\n            x = numpy.concatenate((images_real, images_fake), axis=0)\n            y = numpy.ones([2 * batch_size, 1])\n            y[batch_size:, :] = 0\n            d_loss = self.dc_gan.discriminator_model.train_on_batch(x, y)\n\n            # Train generator i.e. concatenated model\n            noise = numpy.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n            y = numpy.ones([batch_size, 1])\n            g_loss = self.dc_gan.concatenated_model.train_on_batch(noise, y)\n\n            # Print Logs, Save Models, generate sample images\n            if (i + 1) % log_interval == 0:\n                self.log_progress(output_folder_path, i + 1, g_loss, d_loss)\n            if (i + 1) % save_interval == 0:\n                self.save_models(output_folder_path, i + 1)\n                self.generate_images(output_folder_path, i + 1)\n\n    @staticmethod\n    def initialize_log(output_folder_path):\n        log_line = 'Iteration No, Generator Loss, Generator Accuracy, Discriminator Loss, Discriminator Accuracy, ' \\\n                   'Time\\n'\n        with open(os.path.join(output_folder_path, log_file_name), 'w') as log_file:\n            log_file.write(log_line)\n\n    @staticmethod\n    def log_progress(output_folder_path, iteration_no, g_loss, d_loss):\n        log_line = '{0:05},{1:2.4f},{2:0.4f},{3:2.4f},{4:0.4f},{5}\\n' \\\n            .format(iteration_no, g_loss[0], g_loss[1], d_loss[0], d_loss[1],\n                    datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n        with open(os.path.join(output_folder_path, log_file_name), 'a') as log_file:\n            log_file.write(log_line)\n        print(log_line)\n\n    def save_models(self, output_folder_path, iteration_no):\n        self.dc_gan.generator_model.save(\n            os.path.join(output_folder_path, 'generator_model_{0}.h5'.format(iteration_no)))\n        self.dc_gan.discriminator_model.save(\n            os.path.join(output_folder_path, 'discriminator_model_{0}.h5'.format(iteration_no)))\n        self.dc_gan.concatenated_model.save(\n            os.path.join(output_folder_path, 'concatenated_model_{0}.h5'.format(iteration_no)))\n\n    def sample_real_images(self, output_folder_path):\n        filepath = os.path.join(output_folder_path, 'CIFAR10_Sample_Real_Images.png')\n        i = numpy.random.randint(0, self.x_train.shape[0], 16)\n        images = self.x_train[i, :, :, :]\n        plt.figure(figsize=(10, 10))\n        for i in range(16):\n            plt.subplot(4, 4, i + 1)\n            image = images[i, :, :, :]\n            image = numpy.reshape(image, [32, 32, 3])\n            plt.imshow(image)\n            plt.axis('off')\n        plt.tight_layout()\n        plt.savefig(filepath)\n        plt.close('all')\n\n    def generate_images(self, output_folder_path, iteration_no, noise=None):\n        filepath = os.path.join(output_folder_path, 'CIFAR10_Gen_Image{0}.png'.format(iteration_no))\n        if noise is None:\n            noise = numpy.random.uniform(-1, 1, size=[16, 100])\n        # Generator output has tanh activation whose range is [-1,1]\n        images = (self.dc_gan.generator_model.predict(noise) + 1) / 2\n        plt.figure(figsize=(10, 10))\n        for i in range(16):\n            plt.subplot(4, 4, i + 1)\n            image = images[i, :, :, :]\n            image = numpy.reshape(image, [32, 32, 3])\n            plt.imshow(image)\n            plt.axis('off')\n        plt.tight_layout()\n        plt.savefig(filepath)\n        plt.close('all')\n\n\ndef main():\n    cifar10_trainer = Cifar10Trainer()\n    cifar10_trainer.train(train_steps=10000, log_interval=10, save_interval=100)\n    del cifar10_trainer.dc_gan\n    return\n\n\nif __name__ == '__main__':\n    start_time = time.time()\n    print('Program Started at {0}'.format(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))))\n    main()\n    end_time = time.time()\n    print('Program Ended at {0}'.format(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))))\n    print('Total Execution Time: {0}s'.format(datetime.timedelta(seconds=end_time - start_time)))\n</code></pre>\n\n<p>Some of the graphs are as below:</p>\n\n<ol>\n<li><p>Discriminator Optimizer: Adam(lr=0.0001, beta1=0.5)<br>\nGenerator Optimizer: Adam(lr=0.0001, beta1=0.5)\n<a href=\"https://i.stack.imgur.com/u04Yz.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/u04Yz.png\" alt=\"enter image description here\"></a></p></li>\n<li><p>Discriminator Optimizer: SGD(lr=0.0001)<br>\nGenerator Optimizer: SGD(lr=0.0001)\n<a href=\"https://i.stack.imgur.com/QQ0NZ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/QQ0NZ.png\" alt=\"enter image description here\"></a></p></li>\n<li><p>Discriminator Optimizer: SGD(lr=0.0001)<br>\nGenerator Optimizer: SGD(lr=0.001)\n<a href=\"https://i.stack.imgur.com/DX2q3.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/DX2q3.png\" alt=\"enter image description here\"></a></p></li>\n<li><p>Discriminator Optimizer: SGD(lr=0.0001)<br>\nGenerator Optimizer: SGD(lr=0.0005)\n<a href=\"https://i.stack.imgur.com/a8gQg.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/a8gQg.png\" alt=\"enter image description here\"></a></p></li>\n</ol>\n\n<p><strong>Note:</strong><br>\nThis question was originally asked in StackOverflow and then re-asked here as per suggestions in SO</p>\n\n<p><strong>Edit1:</strong><br>\nAdding some generated images for reference</p>\n\n<ol>\n<li><p>Images generated by Adam Optimizer\n<a href=\"https://i.stack.imgur.com/WNnOk.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WNnOk.png\" alt=\"enter image description here\"></a></p></li>\n<li><p>Images generated by SGD Optimizer\n<a href=\"https://i.stack.imgur.com/A7WvZ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/A7WvZ.png\" alt=\"enter image description here\"></a></p></li>\n</ol>\n",
                "tags": "<python><deep-learning><keras><optimization><gan>",
                "answers": [
                    [
                        "47883",
                        "2",
                        "47875",
                        "",
                        "",
                        "<p>I think that there are several issues with your model:</p>\n\n<p>First of all - Your generator's loss is not the generator's loss. You have on binary cross-entropy loss function for the discriminator, and you have another binary cross-entropy loss function for the concatenated model whose output is again the discriminator's output (on generated images). \nThe \"generator loss\" you are showing is the discriminator's loss when dealing with generated images. <strong>You want this loss to go up</strong>, it means that your model successfully generates images that you discriminator fails to catch (as can be seen in the overall discriminator's accuracy which is at 0.5).</p>\n\n<p>Another issue, is that you should add some generator regularization in the form of an actual generator loss (\"generator objective function\"). You can read about the different options in <a href=\"https://towardsdatascience.com/gan-objective-functions-gans-and-their-variations-ad77340bce3c\" rel=\"nofollow noreferrer\">GAN Objective Functions: GANs and Their Variations</a>.</p>\n\n<p>A final issue that I see is that you are passing the generated images thru a final hyperbolic tangent activation function, and I don't really understand why? The generator in your case is supposed to generate a \"believable\" CIFAR10 image, which is a 32x32x3 tensor with values in the range [0,255] or [0,1]. Your generator's output has a potential range of [-1,1] (as you state in your code). </p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3752",
            "_score": 8.014904,
            "_source": {
                "title": "How to find the filename associated with a prediction in Keras?",
                "content": "How to find the filename associated with a prediction in Keras? <p>My question is really simple, how to find the filename associated with a prediction in Keras? That is, if I have a set of 100 test samples named  and I get a numpy array which contains the estimated class probabilities, how do I map the filenames to the probabilities?</p>\n\n<pre><code>import cv2\nimport os\nimport glob \n\ndef load_test():\n    X_test = []\n    y_test = []\n    os.chdir(testing_path)\n    file_list = glob.glob('*.png')\n    for test_image in file_list:\n        img = cv2.imread(test_image,1)\n        X_test.append(img)\n        y_test.append(1)\n   return X_test,y_test\n\nif __name__ == '__main__':\n   X_test = np.array(X_test, dtype = np.uint8)\n   X_test = X_test.reshape(X_test.shape[0],3,100,100)\n   X_test = X_test.astype('float32')\n   X_test /= 255\n</code></pre>\n <python><keras><p>The order of the files that populate file_list, is the same order X_test appears in, by row. </p>\n\n<p>So just match the indices to correlate filename with prediction.</p>\n\n<p>X_test[0] ~ prediction[0] ~ file_list[0]</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "15598",
                "question_votes:": "1",
                "question_text:": "<p>My question is really simple, how to find the filename associated with a prediction in Keras? That is, if I have a set of 100 test samples named  and I get a numpy array which contains the estimated class probabilities, how do I map the filenames to the probabilities?</p>\n\n<pre><code>import cv2\nimport os\nimport glob \n\ndef load_test():\n    X_test = []\n    y_test = []\n    os.chdir(testing_path)\n    file_list = glob.glob('*.png')\n    for test_image in file_list:\n        img = cv2.imread(test_image,1)\n        X_test.append(img)\n        y_test.append(1)\n   return X_test,y_test\n\nif __name__ == '__main__':\n   X_test = np.array(X_test, dtype = np.uint8)\n   X_test = X_test.reshape(X_test.shape[0],3,100,100)\n   X_test = X_test.astype('float32')\n   X_test /= 255\n</code></pre>\n",
                "tags": "<python><keras>",
                "answers": [
                    [
                        "15621",
                        "2",
                        "15598",
                        "",
                        "",
                        "<p>The order of the files that populate file_list, is the same order X_test appears in, by row. </p>\n\n<p>So just match the indices to correlate filename with prediction.</p>\n\n<p>X_test[0] ~ prediction[0] ~ file_list[0]</p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4182",
            "_score": 8.014904,
            "_source": {
                "title": "printing theano.tensor without having any idea about the shape and type of the tensor",
                "content": "printing theano.tensor without having any idea about the shape and type of the tensor <p>I am debugging a code which I haven't written. I want to print out <code>state_below_</code> variable which is calculated as following:</p>\n\n<pre><code>state_below_ = tensor.dot(state_below*emb_dropout[1], tparams[pp(prefix, 'W')]) +\\\n        tparams[pp(prefix, 'b')]\n</code></pre>\n\n<p>When I use <code>state_below_.eval()</code>, I get </p>\n\n<blockquote>\n  <p>MissingInputError: (\"An input of the graph, used to compute\n  Reshape{1}(y_sampler, TensorConstant{(1,) of -1}), was not provided\n  and not given a value.Use the Theano flag\n  exception_verbosity='high',for more information on this error.\",\n  y_sampler)</p>\n</blockquote>\n\n<p>error. How can I print this damn \"state_below_\" value?</p>\n\n<p>Thanks,</p>\n <python><tensorflow><theano><p>For evaluating and tensor, you have to pass the value of the input tensors as shown in the below code snippet.</p>\n\n<pre><code>import numpy\nimport theano.tensor as T\nx = T.dscalar('x')\ny = T.dscalar('y')\nz = x + y\nprint(z.eval({x : 16.3, y : 12.1}))\n</code></pre>\n",
                "codes": [
                    [
                        "import numpy\nimport theano.tensor as T\nx = T.dscalar('x')\ny = T.dscalar('y')\nz = x + y\nprint(z.eval({x : 16.3, y : 12.1}))\n"
                    ]
                ],
                "question_id:": "16999",
                "question_votes:": "1",
                "question_text:": "<p>I am debugging a code which I haven't written. I want to print out <code>state_below_</code> variable which is calculated as following:</p>\n\n<pre><code>state_below_ = tensor.dot(state_below*emb_dropout[1], tparams[pp(prefix, 'W')]) +\\\n        tparams[pp(prefix, 'b')]\n</code></pre>\n\n<p>When I use <code>state_below_.eval()</code>, I get </p>\n\n<blockquote>\n  <p>MissingInputError: (\"An input of the graph, used to compute\n  Reshape{1}(y_sampler, TensorConstant{(1,) of -1}), was not provided\n  and not given a value.Use the Theano flag\n  exception_verbosity='high',for more information on this error.\",\n  y_sampler)</p>\n</blockquote>\n\n<p>error. How can I print this damn \"state_below_\" value?</p>\n\n<p>Thanks,</p>\n",
                "tags": "<python><tensorflow><theano>",
                "answers": [
                    [
                        "17005",
                        "2",
                        "16999",
                        "",
                        "",
                        "<p>For evaluating and tensor, you have to pass the value of the input tensors as shown in the below code snippet.</p>\n\n<pre><code>import numpy\nimport theano.tensor as T\nx = T.dscalar('x')\ny = T.dscalar('y')\nz = x + y\nprint(z.eval({x : 16.3, y : 12.1}))\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "18345",
            "_score": 7.9935474,
            "_source": {
                "title": "CNN Combinined with LSTM",
                "content": "CNN Combinined with LSTM <p>I tried to combine CNN with LSTM for depression detection using the following code</p>\n\n<pre><code>from __future__ import print_function\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers import Embedding\nfrom keras.layers import LSTM\nfrom keras.layers import Conv1D, MaxPooling1D\nimport numpy as np\nfrom keras.utils import np_utils\nfrom keras import backend as K\n\ndef preprocess(X_train, X_test):\n    \"\"\"\n    Convert from float64 to float32 and normalize normalize to decibels\n    relative to full scale (dBFS) for the 4 sec clip.\n    \"\"\"\n    X_train = X_train.astype('float32')\n    X_test = X_test.astype('float32')\n\n    X_train = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_train])\n    X_test = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_test])\n    return X_train, X_test\n\n\ndef prep_train_test(X_train, y_train, X_test, y_test, nb_classes):\n    \"\"\"\n    Prep samples ands labels for Keras input by noramalzing and converting\n    labels to a categorical representation.\n    \"\"\"\n    print('Train on {} samples, validate on {}'.format(X_train.shape[0],\n                                                       X_test.shape[0]))\n\n    # normalize to dBfS\n    X_train, X_test = preprocess(X_train, X_test)\n\n    # Convert class vectors to binary class matrices\n    Y_train = np_utils.to_categorical(y_train, nb_classes)\n    Y_test = np_utils.to_categorical(y_test, nb_classes)\n\n    return X_train, X_test, Y_train, Y_test\n\n\ndef keras_img_prep(X_train, X_test, img_dep, img_rows, img_cols):\n    \"\"\"\n    Reshape feature matrices for Keras' expexcted input dimensions.\n    For 'th' (Theano) dim_order, the model expects dimensions:\n    (# channels, # images, # rows, # cols).\n    \"\"\"\n    if K.image_dim_ordering() == 'th':\n        X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n        X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n        input_shape = (1, img_rows, img_cols)\n    else:\n        X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n        X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n        input_shape = (img_rows, img_cols, 1)\n    return X_train, X_test, input_shape\n\n\n\n\nif __name__ == '__main__':\n\n\n\n    print('Retrieving locally')\n    X_train = np.load('E:/depression detection/data/processed/train_samples.npz')\n    y_train = np.load('E:/depression detection/data/processed/train_labels.npz')\n    X_test = np.load('E:/depression detection/data/processed/test_samples.npz')\n    y_test = np.load('E:/depression detection/data/processed/test_labels.npz')\n\n    X_train, y_train, X_test, y_test = \\\n        X_train['arr_0'], y_train['arr_0'], X_test['arr_0'], y_test['arr_0']\n\n\n\n#     Embedding\n    max_features = 20000\n    maxlen = 100\n    embedding_size = 128\n    nb_classes = 2\n\n# Convolution\n    kernel_size = 5\n    filters = 64\n    pool_size = 4\n\n# LSTM\n    lstm_output_size = 70\n\n# Training\n    batch_size = 30\n    epochs = 2\n\n\n\n\n    # normalalize data and prep for Keras\n    print('Processing images for Keras...')\n    X_train, X_test, y_train, y_test = prep_train_test(X_train, y_train,\n                                                       X_test, y_test,\n                                                       nb_classes=nb_classes)\n\n    # 513x125x1 for spectrogram with crop size of 125 pixels\n    img_rows, img_cols, img_depth = X_train.shape[1], X_train.shape[2], 1\n\n    # reshape image input for Keras\n    # used Theano dim_ordering (th), (# chans, # images, # rows, # cols)\n    X_train, X_test, input_shape = keras_img_prep(X_train, X_test, img_depth,\n                                                  img_rows, img_cols)\n\n\n\n    print(len(X_train), 'train sequences')\n    print(len(X_test), 'test sequences')\n\n    print('Pad sequences (samples x time)')\n    X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n    X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n    print('X_train shape:', X_train.shape)\n    print('X_test shape:', X_test.shape)\n\n    print('Build model...')\n\n    model = Sequential()\n    model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n    model.add(Dropout(0.25))\n    model.add(Conv1D(filters,\n                 kernel_size,\n                 padding='valid',\n                 activation='relu',\n                 strides=1))\n    model.add(MaxPooling1D(pool_size=pool_size))\n    model.add(LSTM(lstm_output_size))\n    model.add(Dense(1))\n    model.add(Activation('sigmoid'))\n\n    model.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n    print('Train...')\n    model.fit(X_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_data=(X_test, y_test))\n    score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n    print('Test score:', score)\n    print('Test accuracy:', acc)\n</code></pre>\n\n<p>But I got this error message </p>\n\n<p><strong>Error when checking input: expected embedding_5_input to have 2 dimensions, but got array with shape (2480, 100, 125, 1)</strong></p>\n\n<p>I don't know where the problem is??</p>\n <keras><cnn><lstm>",
                "codes": [],
                "question_id:": "58172",
                "question_votes:": "",
                "question_text:": "<p>I tried to combine CNN with LSTM for depression detection using the following code</p>\n\n<pre><code>from __future__ import print_function\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers import Embedding\nfrom keras.layers import LSTM\nfrom keras.layers import Conv1D, MaxPooling1D\nimport numpy as np\nfrom keras.utils import np_utils\nfrom keras import backend as K\n\ndef preprocess(X_train, X_test):\n    \"\"\"\n    Convert from float64 to float32 and normalize normalize to decibels\n    relative to full scale (dBFS) for the 4 sec clip.\n    \"\"\"\n    X_train = X_train.astype('float32')\n    X_test = X_test.astype('float32')\n\n    X_train = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_train])\n    X_test = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_test])\n    return X_train, X_test\n\n\ndef prep_train_test(X_train, y_train, X_test, y_test, nb_classes):\n    \"\"\"\n    Prep samples ands labels for Keras input by noramalzing and converting\n    labels to a categorical representation.\n    \"\"\"\n    print('Train on {} samples, validate on {}'.format(X_train.shape[0],\n                                                       X_test.shape[0]))\n\n    # normalize to dBfS\n    X_train, X_test = preprocess(X_train, X_test)\n\n    # Convert class vectors to binary class matrices\n    Y_train = np_utils.to_categorical(y_train, nb_classes)\n    Y_test = np_utils.to_categorical(y_test, nb_classes)\n\n    return X_train, X_test, Y_train, Y_test\n\n\ndef keras_img_prep(X_train, X_test, img_dep, img_rows, img_cols):\n    \"\"\"\n    Reshape feature matrices for Keras' expexcted input dimensions.\n    For 'th' (Theano) dim_order, the model expects dimensions:\n    (# channels, # images, # rows, # cols).\n    \"\"\"\n    if K.image_dim_ordering() == 'th':\n        X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n        X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n        input_shape = (1, img_rows, img_cols)\n    else:\n        X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n        X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n        input_shape = (img_rows, img_cols, 1)\n    return X_train, X_test, input_shape\n\n\n\n\nif __name__ == '__main__':\n\n\n\n    print('Retrieving locally')\n    X_train = np.load('E:/depression detection/data/processed/train_samples.npz')\n    y_train = np.load('E:/depression detection/data/processed/train_labels.npz')\n    X_test = np.load('E:/depression detection/data/processed/test_samples.npz')\n    y_test = np.load('E:/depression detection/data/processed/test_labels.npz')\n\n    X_train, y_train, X_test, y_test = \\\n        X_train['arr_0'], y_train['arr_0'], X_test['arr_0'], y_test['arr_0']\n\n\n\n#     Embedding\n    max_features = 20000\n    maxlen = 100\n    embedding_size = 128\n    nb_classes = 2\n\n# Convolution\n    kernel_size = 5\n    filters = 64\n    pool_size = 4\n\n# LSTM\n    lstm_output_size = 70\n\n# Training\n    batch_size = 30\n    epochs = 2\n\n\n\n\n    # normalalize data and prep for Keras\n    print('Processing images for Keras...')\n    X_train, X_test, y_train, y_test = prep_train_test(X_train, y_train,\n                                                       X_test, y_test,\n                                                       nb_classes=nb_classes)\n\n    # 513x125x1 for spectrogram with crop size of 125 pixels\n    img_rows, img_cols, img_depth = X_train.shape[1], X_train.shape[2], 1\n\n    # reshape image input for Keras\n    # used Theano dim_ordering (th), (# chans, # images, # rows, # cols)\n    X_train, X_test, input_shape = keras_img_prep(X_train, X_test, img_depth,\n                                                  img_rows, img_cols)\n\n\n\n    print(len(X_train), 'train sequences')\n    print(len(X_test), 'test sequences')\n\n    print('Pad sequences (samples x time)')\n    X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n    X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n    print('X_train shape:', X_train.shape)\n    print('X_test shape:', X_test.shape)\n\n    print('Build model...')\n\n    model = Sequential()\n    model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n    model.add(Dropout(0.25))\n    model.add(Conv1D(filters,\n                 kernel_size,\n                 padding='valid',\n                 activation='relu',\n                 strides=1))\n    model.add(MaxPooling1D(pool_size=pool_size))\n    model.add(LSTM(lstm_output_size))\n    model.add(Dense(1))\n    model.add(Activation('sigmoid'))\n\n    model.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n    print('Train...')\n    model.fit(X_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_data=(X_test, y_test))\n    score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n    print('Test score:', score)\n    print('Test accuracy:', acc)\n</code></pre>\n\n<p>But I got this error message </p>\n\n<p><strong>Error when checking input: expected embedding_5_input to have 2 dimensions, but got array with shape (2480, 100, 125, 1)</strong></p>\n\n<p>I don't know where the problem is??</p>\n",
                "tags": "<keras><cnn><lstm>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7891",
            "_score": 7.9817276,
            "_source": {
                "title": "Isolation forest results every value -1",
                "content": "Isolation forest results every value -1 <p>I am trying out isolation forest to detect outliers in a specific target column of my dataset. The dataset contains 188 rows of data with 178 rows with the same value for that target column and the isolation forest gives out every single value -1. Is that a bug or should I take it as that the values are fine? Here is a piece of the code. (I know I need to stop using <code>ix</code>).</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import IsolationForest\n\ndf1 = pd.read_csv('C:/Users/smotapar/Desktop/ase/source/data.csv')\nclf = IsolationForest(n_estimators=200, random_state=10, bootstrap=False)\nclf.fit(df1.ix[:,\"target\"].values.reshape(-1, 1))\nclf.predict(df1.ix[:,\"target\"].values.reshape(-1, 1))\n</code></pre>\n\n<p>Which gives out an output:</p>\n\n<blockquote>\n  <p>array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])</p>\n</blockquote>\n\n<p>So, what did I do wrong? If I didn't, why is the output like this?</p>\n <python><scikit-learn><pandas><outlier>",
                "codes": [],
                "question_id:": "29239",
                "question_votes:": "1",
                "question_text:": "<p>I am trying out isolation forest to detect outliers in a specific target column of my dataset. The dataset contains 188 rows of data with 178 rows with the same value for that target column and the isolation forest gives out every single value -1. Is that a bug or should I take it as that the values are fine? Here is a piece of the code. (I know I need to stop using <code>ix</code>).</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import IsolationForest\n\ndf1 = pd.read_csv('C:/Users/smotapar/Desktop/ase/source/data.csv')\nclf = IsolationForest(n_estimators=200, random_state=10, bootstrap=False)\nclf.fit(df1.ix[:,\"target\"].values.reshape(-1, 1))\nclf.predict(df1.ix[:,\"target\"].values.reshape(-1, 1))\n</code></pre>\n\n<p>Which gives out an output:</p>\n\n<blockquote>\n  <p>array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])</p>\n</blockquote>\n\n<p>So, what did I do wrong? If I didn't, why is the output like this?</p>\n",
                "tags": "<python><scikit-learn><pandas><outlier>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16781",
            "_score": 7.940393,
            "_source": {
                "title": "Error when checking input while running the LSTM model using panda python",
                "content": "Error when checking input while running the LSTM model using panda python <p>I have a data set include with temperature, humidity and wind. Here I want to predict future temperature value in next hour. </p>\n\n<p>I used LSTM to predict future temperature value.\nBut when I run the model it showed up this error</p>\n\n<p>Can anyone help me to solve this problem?</p>\n\n<p>Here is my code:</p>\n\n<pre><code>\n    import datetime\n    import time\n    from sklearn.metrics import mean_squared_error\n    import matplotlib.pyplot as plt \n    from matplotlib.dates import DateFormatter\n    import numpy as np\n    import pandas as pd \n    from sklearn.preprocessing import MinMaxScaler\n\n    from sklearn import preprocessing\n    from keras.layers.core import Dense, Dropout, Activation\n    from keras.activations import linear\n    from keras.layers.recurrent import LSTM\n    from keras.models import Sequential\n    from sklearn.preprocessing import MinMaxScaler\n\n\n    data = pd.read_csv('data6.csv' , sep=',')\n    data['date'] = pd.to_datetime(data['date'] + \" \" + data['time'], format='%m/%d/%Y %H:%M:%S')\n    data.set_index('time', inplace=True)\n    data = data.values\n    data = data.astype('float32')\n    # normalize the dataset\n    def create_data(train,X,n_out=1):\n    #data = np.reshape(train, (train.shape[0], train_shape[1], train_shape[2]))\n    x,y=list(),list()\n    start =0\n    for _ in range(len(data)):\n        in_end = start+X\n        out_end= in_end + n_out\n        if out_end &lt; len(data):\n            x_input = data[start:in_end]\n            x.append(x_input)\n            y.append(data[in_end:out_end,0])\n        start +=1\n    return np.array(x),np.array(y)\n    scaler = MinMaxScaler()\n    data = scaler.fit_transform(data)\n    # split into train and test sets\n    train = int(len(data) * 0.6)\n    test = len(data) - train\n    train, test = data[0:train,:], data[train:len(data),:]\n    X=1\n    x_train, y_train = create_data(train,X)\n    x_test, y_test = create_data(test,X)\n    x_train=x_train.reshape(x_train.shape +(1,))\n    x_test=x_test.reshape(x_test.shape + (1,))\n\n\n    n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], x_train.shape[1]\n\n\n    model = Sequential()\n    model.add(LSTM(8, activation='relu', input_shape=(n_timesteps, n_features)))\n    model.add(Dense(8,activation='relu'))\n    model.add(Dense(n_outputs))\n    model.compile(loss='mse', optimizer='adam')\n    # fit network\n    model.fit(x_train,y_train, epochs=10,batch_size=1, verbose=0)\n</code></pre>\n\n<p>My csv file:</p>\n\n<p><a href=\"https://docs.google.com/spreadsheets/d/1KsAtm0vSsBfOL8z42UAPAwljaO1-DSKfdD9lSu3lv80/edit#gid=35707506\" rel=\"nofollow noreferrer\">My csv file.</a></p>\n\n<p>My error:</p>\n\n<p><a href=\"https://i.stack.imgur.com/q1sLe.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/q1sLe.png\" alt=\"enter image description here\"></a></p>\n <python><pandas><lstm>",
                "codes": [],
                "question_id:": "54834",
                "question_votes:": "",
                "question_text:": "<p>I have a data set include with temperature, humidity and wind. Here I want to predict future temperature value in next hour. </p>\n\n<p>I used LSTM to predict future temperature value.\nBut when I run the model it showed up this error</p>\n\n<p>Can anyone help me to solve this problem?</p>\n\n<p>Here is my code:</p>\n\n<pre><code>\n    import datetime\n    import time\n    from sklearn.metrics import mean_squared_error\n    import matplotlib.pyplot as plt \n    from matplotlib.dates import DateFormatter\n    import numpy as np\n    import pandas as pd \n    from sklearn.preprocessing import MinMaxScaler\n\n    from sklearn import preprocessing\n    from keras.layers.core import Dense, Dropout, Activation\n    from keras.activations import linear\n    from keras.layers.recurrent import LSTM\n    from keras.models import Sequential\n    from sklearn.preprocessing import MinMaxScaler\n\n\n    data = pd.read_csv('data6.csv' , sep=',')\n    data['date'] = pd.to_datetime(data['date'] + \" \" + data['time'], format='%m/%d/%Y %H:%M:%S')\n    data.set_index('time', inplace=True)\n    data = data.values\n    data = data.astype('float32')\n    # normalize the dataset\n    def create_data(train,X,n_out=1):\n    #data = np.reshape(train, (train.shape[0], train_shape[1], train_shape[2]))\n    x,y=list(),list()\n    start =0\n    for _ in range(len(data)):\n        in_end = start+X\n        out_end= in_end + n_out\n        if out_end &lt; len(data):\n            x_input = data[start:in_end]\n            x.append(x_input)\n            y.append(data[in_end:out_end,0])\n        start +=1\n    return np.array(x),np.array(y)\n    scaler = MinMaxScaler()\n    data = scaler.fit_transform(data)\n    # split into train and test sets\n    train = int(len(data) * 0.6)\n    test = len(data) - train\n    train, test = data[0:train,:], data[train:len(data),:]\n    X=1\n    x_train, y_train = create_data(train,X)\n    x_test, y_test = create_data(test,X)\n    x_train=x_train.reshape(x_train.shape +(1,))\n    x_test=x_test.reshape(x_test.shape + (1,))\n\n\n    n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], x_train.shape[1]\n\n\n    model = Sequential()\n    model.add(LSTM(8, activation='relu', input_shape=(n_timesteps, n_features)))\n    model.add(Dense(8,activation='relu'))\n    model.add(Dense(n_outputs))\n    model.compile(loss='mse', optimizer='adam')\n    # fit network\n    model.fit(x_train,y_train, epochs=10,batch_size=1, verbose=0)\n</code></pre>\n\n<p>My csv file:</p>\n\n<p><a href=\"https://docs.google.com/spreadsheets/d/1KsAtm0vSsBfOL8z42UAPAwljaO1-DSKfdD9lSu3lv80/edit#gid=35707506\" rel=\"nofollow noreferrer\">My csv file.</a></p>\n\n<p>My error:</p>\n\n<p><a href=\"https://i.stack.imgur.com/q1sLe.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/q1sLe.png\" alt=\"enter image description here\"></a></p>\n",
                "tags": "<python><pandas><lstm>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17735",
            "_score": 7.8923693,
            "_source": {
                "title": "DC GAN with Batch Normalization not working",
                "content": "DC GAN with Batch Normalization not working <p>I'm trying to implement DC GAN as they have described in the paper. Specifically, they mention the below points</p>\n\n<ol>\n<li>Use strided convolutions instead of pooling or upsampling layers.</li>\n<li>Use only one fully connected layer</li>\n<li><strong>Use Batch Normalization: Directly applying batchnorm to all layers resulted in sample oscillation and model instability. This was avoided by not applying batchnorm to the generator output layer and the discriminator input layer.</strong></li>\n<li>use ReLU for generator and Leaky ReLU for discriminator</li>\n</ol>\n\n<p>I tried to implement a GAN for MNIST dataset. It is outputting garbage. I tried </p>\n\n<ol>\n<li>changing learning rate from 0.01 to 0.00001</li>\n<li>optimizer momentum as 0.5, 0.9</li>\n<li>Using BatchNormalization before and after activation layer</li>\n<li>BatchNormalization momentum as 0.5, 0.9, 0.99</li>\n<li>Training for upto 3,00,000 iterations</li>\n</ol>\n\n<p>But nothing is working. I'm just getting garbage output. But I noticed two strange things</p>\n\n<ol>\n<li>Both generator and discriminator loss are going to 0, accuracy going to 1. How is this possible?</li>\n<li><strong>If I remove all Batch Normalization layers from discriminator, the model starts working. Why?</strong> The paper suggests to use BatchNormalization, but it is working otherwise.</li>\n</ol>\n\n<p>Any help, tips or suggestions is highly appreciated. Thanks!</p>\n\n<p>Here is my full code:<br>\n<em>MnistModel07.py</em></p>\n\n<pre><code>import numpy\nfrom keras import Sequential\nfrom keras.engine.saving import load_model\nfrom keras.initializers import TruncatedNormal\nfrom keras.layers import Activation, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Flatten, LeakyReLU, Reshape\nfrom keras.optimizers import Adam\n\nfrom DcGanBaseModel import DcGanBaseModel\n\n\nclass MnistModel07(DcGanBaseModel):\n    def __init__(self, verbose: bool = False):\n        super().__init__(verbose)\n        self.generator_model = None\n        self.discriminator_model = None\n        self.concatenated_model = None\n        self.verbose = verbose\n\n    def build_models(self):\n        self.generator_model = self.build_generator_model()\n        self.discriminator_model = self.build_discriminator_model()\n        self.concatenated_model = self.build_concatenated_model()\n        self.print_model_summary()\n\n    def build_generator_model(self):\n        if self.generator_model:\n            return self.generator_model\n\n        generator_model = Sequential()\n        generator_model.add(Dense(7 * 7 * 512, input_dim=100,\n                                  kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        generator_model.add(Activation('relu'))\n        generator_model.add(BatchNormalization(momentum=0.9))\n        generator_model.add(Reshape((7, 7, 512)))\n\n        generator_model.add(Conv2DTranspose(256, 3, strides=2, padding='same',\n                                            kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        generator_model.add(Activation('relu'))\n        generator_model.add(BatchNormalization(momentum=0.9))\n\n        generator_model.add(Conv2DTranspose(128, 3, strides=2, padding='same',\n                                            kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        generator_model.add(Activation('relu'))\n        generator_model.add(BatchNormalization(momentum=0.9))\n\n        generator_model.add(Conv2D(1, 3, padding='same',\n                                   kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        generator_model.add(Activation('tanh'))\n\n        return generator_model\n\n    def build_discriminator_model(self):\n        if self.discriminator_model:\n            return self.discriminator_model\n\n        discriminator_model = Sequential()\n        discriminator_model.add(Conv2D(128, 3, strides=2, input_shape=(28, 28, 1), padding='same',\n                                       kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        discriminator_model.add(LeakyReLU(alpha=0.2))\n\n        discriminator_model.add(Conv2D(256, 3, strides=2, padding='same',\n                                       kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        discriminator_model.add(LeakyReLU(alpha=0.2))\n        discriminator_model.add(BatchNormalization(momentum=0.9))\n\n        discriminator_model.add(Flatten())\n        discriminator_model.add(Dense(1, kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        discriminator_model.add(Activation('sigmoid'))\n\n        return discriminator_model\n\n    def build_concatenated_model(self):\n        if self.concatenated_model:\n            return self.concatenated_model\n\n        concatenated_model = Sequential()\n        concatenated_model.add(self.generator_model)\n        concatenated_model.add(self.discriminator_model)\n\n        return concatenated_model\n\n    def print_model_summary(self):\n        self.verbose_log(self.generator_model.summary())\n        self.verbose_log(self.discriminator_model.summary())\n        self.verbose_log(self.concatenated_model.summary())\n\n    def build_dc_gan(self):\n        \"\"\"\n        Binary Cross-Entropy Loss is used for both Generator and Discriminator\n        Discriminator: loss = -log(D(x)) when x is real image and loss=-log(1-D(x)) when x is fake image\n        Optimizer minimizes this loss. This is equivalent to maximize over D(x) as specified in original GAN paper\n        Generator: loss = -log(D(G(z))\n        Optimizer minimizes this loss. This is the second loss function defined in paper, not the one in min-max\n                definition\n        Since while training Generator we are not minimizing log(1-D(G(z))), the analytical results we derived won't\n                hold for generator part.\n        Ideally, Discriminator loss = -ln(0.5); Generator loss = -ln(0.5) = 0.693\n\n        metrics = accuracy: binary_accuracy is used\n        https://github.com/keras-team/keras/blob/d8b226f26b35348d934edb1213061993e7e5a1fa/keras/engine/training.py#L651\n        https://github.com/keras-team/keras/blob/c2e36f369b411ad1d0a40ac096fe35f73b9dffd3/keras/metrics.py#L6\n        Binary_accuracy: Average of correct predictions\n        Discriminator: Ideally, discriminator should be completely confused i.e. accuracy=0.5\n        Generator: Ideally, Generator should be able to fool discriminator. So, accuracy=1. But, since Discriminator\n                    is confused, it randomly flags some images as fake. So, accuracy=0.5\n        \"\"\"\n        self.build_models()\n\n        self.discriminator_model.trainable = True\n        optimizer = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, decay=0)\n        self.discriminator_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n        self.discriminator_model.trainable = False\n        optimizer = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, decay=0)\n        self.concatenated_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\n    def train_on_batch(self, images_real: numpy.ndarray):\n        # Generator output has tanh activation whose range is [-1,1]\n        images_real = (images_real.astype('float32') * 2 / 255) - 1\n\n        # Generate Fake Images\n        batch_size = images_real.shape[0]\n        noise = numpy.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n        images_fake = self.generator_model.predict(noise)\n\n        # Train discriminator on both real and fake images\n        x = numpy.concatenate((images_real, images_fake), axis=0)\n        y = numpy.ones([2 * batch_size, 1])\n        y[batch_size:, :] = 0\n        d_loss = self.discriminator_model.train_on_batch(x, y)\n\n        # Train generator i.e. concatenated model\n        # Note that in concatenated model, training of discriminator weights is disabled\n        noise = numpy.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n        y = numpy.ones([batch_size, 1])\n        g_loss = self.concatenated_model.train_on_batch(noise, y)\n\n        return g_loss, d_loss\n\n    def generate_images(self, num_images=1, noise=None) -&gt; numpy.ndarray:\n        if noise is None:\n            noise = numpy.random.uniform(-1, 1, size=[num_images, 100])\n        # Generator output has tanh activation whose range is [-1,1]\n        images = (self.generator_model.predict(noise) + 1) * 255 / 2\n        images = numpy.round(images).astype('uint8')\n        return images\n\n    def save_generator_model(self, save_path):\n        self.generator_model.save(save_path)\n\n    def save_generator_model_data(self, json_path, weights_path):\n        with open(json_path, 'w') as json_file:\n            json_file.write(self.generator_model.to_json())\n        self.generator_model.save_weights(weights_path)\n\n    def load_generator_model(self, model_path):\n        self.generator_model = load_model(model_path)\n\n    def load_generator_model_weights(self, weights_path):\n        self.generator_model.load_weights(weights_path)\n\n    def save_discriminator_model(self, save_path):\n        self.discriminator_model.save(save_path)\n\n    def save_discriminator_model_data(self, json_path, weights_path):\n        with open(json_path, 'w') as json_file:\n            json_file.write(self.discriminator_model.to_json())\n        self.discriminator_model.save_weights(weights_path)\n\n    def load_discriminator_model(self, model_path):\n        self.discriminator_model = load_model(model_path)\n\n    def load_discriminator_model_weights(self, weights_path):\n        self.discriminator_model.load_weights(weights_path)\n\n    def save_concatenated_model(self, save_path):\n        self.concatenated_model.save(save_path)\n\n    def save_concatenated_model_data(self, json_path, weights_path):\n        with open(json_path, 'w') as json_file:\n            json_file.write(self.concatenated_model.to_json())\n        self.concatenated_model.save_weights(weights_path)\n\n    def load_concatenated_model(self, model_path):\n        self.concatenated_model = load_model(model_path)\n\n    def load_concatenated_model_weights(self, weights_path):\n        self.concatenated_model.load_weights(weights_path)\n</code></pre>\n\n<p><em>MnistTrainer.py</em></p>\n\n<pre><code>import datetime\nimport os\nimport time\n\nimport numpy\nfrom keras.datasets import mnist\nfrom matplotlib import pyplot as plt\n\nfrom evaluation.EvaluationMetricsWrapper import ClassifierData, Evaluator\nfrom utils import CommonUtils, GraphPlotter\nfrom utils.CommonUtils import check_output_dir\n\n\nclass MnistTrainer:\n    def __init__(self, model, classifier_data: ClassifierData, verbose=False):\n        self.x_train = self.get_train_data()\n        self.dc_gan = model(verbose=verbose)\n        self.dc_gan.build_dc_gan()\n        self.evaluator = Evaluator(classifier_data, num_classes=10) if classifier_data is not None else None\n        self.verbose = verbose\n\n    @staticmethod\n    def get_train_data():\n        (x_train, y_train), _ = mnist.load_data()\n        x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n        return x_train\n\n    def train(self, train_steps, batch_size, loss_log_interval, save_interval, output_folder_path=None):\n        self.verbose_log('Training begins: ' + datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n        if output_folder_path is not None:\n            CommonUtils.check_output_dir(output_folder_path)\n            loss_file_path = os.path.join(output_folder_path, 'TrainLosses.csv')\n            self.initialize_loss_file(loss_file_path)\n            self.sample_real_images(output_folder_path)\n            if self.evaluator is not None:\n                metrics_filepath = os.path.join(output_folder_path, 'Evaluation/EvaluationMetrics.csv')\n                self.initialize_metrics_file(metrics_filepath)\n\n        for i in range(train_steps):\n            # Get real (Dataset) Images\n            images_real = self.x_train[numpy.random.randint(0, self.x_train.shape[0], size=batch_size), :, :, :]\n            g_loss, d_loss = self.dc_gan.train_on_batch(images_real)\n\n            if output_folder_path is not None:\n                # Save train losses,  models, generate sample images\n                if (i + 1) % loss_log_interval == 0:\n                    # noinspection PyUnboundLocalVariable\n                    self.append_losses(loss_file_path, i + 1, g_loss, d_loss)\n                if (i + 1) % save_interval == 0:\n                    self.save_models(output_folder_path, i + 1)\n                    self.generate_images(output_folder_path, i + 1)\n                    if self.evaluator is not None:\n                        # noinspection PyUnboundLocalVariable\n                        self.append_metrics(metrics_filepath, i + 1)\n\n        if output_folder_path is not None:\n            # Plot the loss functions and accuracy\n            graph_file_path = os.path.join(output_folder_path, 'LossAccuracyPlot.png')\n            GraphPlotter.plot_loss_and_accuracy(loss_file_path, graph_file_path)\n            if self.evaluator is not None:\n                metrics_graph_path = os.path.join(output_folder_path, 'Evaluation/EvaluationMetrics.png')\n                GraphPlotter.plot_evaluation_metrics(metrics_filepath, metrics_graph_path)\n\n        self.verbose_log('Training ends: ' + datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n\n    @staticmethod\n    def initialize_loss_file(loss_file_path):\n        line = 'Iteration No, Generator Loss, Generator Accuracy, Discriminator Loss, Discriminator Accuracy, Time\\n'\n        with open(loss_file_path, 'w') as loss_file:\n            loss_file.write(line)\n\n    def append_losses(self, loss_file_path, iteration_no, g_loss, d_loss):\n        line = '{0:05},{1:2.4f},{2:0.4f},{3:2.4f},{4:0.4f},{5}\\n' \\\n            .format(iteration_no, g_loss[0], g_loss[1], d_loss[0], d_loss[1],\n                    datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n        with open(loss_file_path, 'a') as loss_file:\n            loss_file.write(line)\n        self.verbose_log(line)\n\n    def save_models(self, output_folder_path, iteration_no):\n        models_save_dir = os.path.join(output_folder_path, 'TrainedModels')\n        if not os.path.exists(models_save_dir):\n            os.makedirs(models_save_dir)\n\n        self.dc_gan.save_generator_model(\n            os.path.join(models_save_dir, 'generator_model_{0}.h5'.format(iteration_no)))\n        self.dc_gan.save_generator_model_data(\n            os.path.join(models_save_dir, 'generator_model_arch_{0}.json'.format(iteration_no)),\n            os.path.join(models_save_dir, 'generator_model_weights_{0}.h5'.format(iteration_no))\n        )\n\n        self.dc_gan.save_discriminator_model(\n            os.path.join(models_save_dir, 'discriminator_model_{0}.h5'.format(iteration_no)))\n        self.dc_gan.save_discriminator_model_data(\n            os.path.join(models_save_dir, 'discriminator_model_arch_{0}.json'.format(iteration_no)),\n            os.path.join(models_save_dir, 'discriminator_model_weights_{0}.h5'.format(iteration_no))\n        )\n\n        self.dc_gan.save_concatenated_model(\n            os.path.join(models_save_dir, 'concatenated_model_{0}.h5'.format(iteration_no)))\n        self.dc_gan.save_concatenated_model_data(\n            os.path.join(models_save_dir, 'concatenated_model_arch_{0}.json'.format(iteration_no)),\n            os.path.join(models_save_dir, 'concatenated_model_weights_{0}.h5'.format(iteration_no))\n        )\n\n    def sample_real_images(self, output_folder_path):\n        filepath = os.path.join(output_folder_path, 'MNIST_Sample_Real_Images.png')\n        i = numpy.random.randint(0, self.x_train.shape[0], 16)\n        images = self.x_train[i, :, :, :]\n        plt.figure(figsize=(10, 10))\n        for i in range(16):\n            plt.subplot(4, 4, i + 1)\n            image = images[i, :, :, :]\n            image = numpy.reshape(image, [28, 28])\n            plt.imshow(image, cmap='gray')\n            plt.axis('off')\n        plt.tight_layout()\n        plt.savefig(filepath)\n        plt.close('all')\n\n    def generate_images(self, output_folder_path, iteration_no, noise=None):\n        gen_images_dir = os.path.join(output_folder_path, 'Generated_Images')\n        if not os.path.exists(gen_images_dir):\n            os.makedirs(gen_images_dir)\n        filepath = os.path.join(gen_images_dir, 'MNIST_Gen_Image{0}.png'.format(iteration_no))\n        images = self.dc_gan.generate_images(16, noise)\n        plt.figure(figsize=(10, 10))\n        for i in range(16):\n            plt.subplot(4, 4, i + 1)\n            image = images[i, :, :, :]\n            image = numpy.reshape(image, [28, 28])\n            plt.imshow(image, cmap='gray')\n            plt.axis('off')\n        plt.tight_layout()\n        plt.savefig(filepath)\n        plt.close('all')\n\n    def initialize_metrics_file(self, filepath: str):\n        check_output_dir(os.path.split(filepath)[0])\n        with open(filepath, 'w') as metrics_file:\n            metrics_file.write('Iteration No,' + ','.join(self.evaluator.get_metrics_names()) + '\\n')\n\n    def append_metrics(self, filepath: str, iteration_no):\n        metrics = self.evaluator.evaluate(self.dc_gan)\n        with open(filepath, 'a') as metrics_file:\n            metrics_file.write(str(iteration_no) + ',' + ','.join(map(str, metrics)) + '\\n')\n\n    def verbose_log(self, log_line):\n        if self.verbose:\n            print(log_line)\n\n\ndef main():\n    \"\"\"\n    Execute in src directory\n    \"\"\"\n    from mnist.MnistModel05 import MnistModel05\n\n    train_steps = 10000\n    batch_size = 128\n    loss_log_interval = 10\n    save_interval = 100\n    output_folder_path = '../Runs/Run01'\n\n    classifier_name = 'MnistClassifier06'\n    classifier_filepath = '../../../../DiscriminativeModels/01_MNIST_Classification/src/MnistClassifierModel06.py'\n    classifier_json_path = \\\n        '../../../../DiscriminativeModels/01_MNIST_Classification/Runs/MnistClassifier06/Run01/TrainedModels' \\\n        '/MNIST_Model_Arch_30.json'\n    classifier_weights_path = \\\n        '../../../../DiscriminativeModels/01_MNIST_Classification/Runs/MnistClassifier06/Run01/TrainedModels' \\\n        '/MNIST_Model_Weights_30.h5'\n    classifier_data = ClassifierData(classifier_name, classifier_filepath, classifier_json_path,\n                                     classifier_weights_path)\n\n    mnist_trainer = MnistTrainer(model=MnistModel05, classifier_data=classifier_data, verbose=True)\n    mnist_trainer.train(train_steps, batch_size, loss_log_interval, save_interval, output_folder_path)\n    del mnist_trainer.dc_gan\n    return\n\n\nif __name__ == '__main__':\n    start_time = time.time()\n    print('Program Started at {0}'.format(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))))\n    try:\n        main()\n    except Exception as e:\n        print(e)\n    end_time = time.time()\n    print('Program Ended at {0}'.format(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))))\n    print('Total Execution Time: {0}s'.format(datetime.timedelta(seconds=end_time - start_time)))\n</code></pre>\n <training><gan><mnist><p><strong>Golden Rule:</strong> In Keras, if using Batch Normalization layer, train the discriminator on real and fake images separately. Don't combine them.</p>\n\n<hr>\n\n<p>I was able to solve it by changing the discriminator training code as follows:</p>\n\n<pre><code>d_loss = self.discriminator_model.train_on_batch(images_real, numpy.ones((batch_size, 1)))\nd_loss = self.discriminator_model.train_on_batch(images_fake, numpy.zeros((batch_size, 1)))\n</code></pre>\n\n<p>With this change, the issue of generator and discriminator accuracy being at 1 was also solved. I guess combining real and fake images in a single batch causes some problem with the Batch Normalization in Keras. That was the problem. Why that causing the problem, I have no idea.</p>\n",
                "codes": [
                    [
                        "d_loss = self.discriminator_model.train_on_batch(images_real, numpy.ones((batch_size, 1)))\nd_loss = self.discriminator_model.train_on_batch(images_fake, numpy.zeros((batch_size, 1)))\n"
                    ]
                ],
                "question_id:": "56860",
                "question_votes:": "",
                "question_text:": "<p>I'm trying to implement DC GAN as they have described in the paper. Specifically, they mention the below points</p>\n\n<ol>\n<li>Use strided convolutions instead of pooling or upsampling layers.</li>\n<li>Use only one fully connected layer</li>\n<li><strong>Use Batch Normalization: Directly applying batchnorm to all layers resulted in sample oscillation and model instability. This was avoided by not applying batchnorm to the generator output layer and the discriminator input layer.</strong></li>\n<li>use ReLU for generator and Leaky ReLU for discriminator</li>\n</ol>\n\n<p>I tried to implement a GAN for MNIST dataset. It is outputting garbage. I tried </p>\n\n<ol>\n<li>changing learning rate from 0.01 to 0.00001</li>\n<li>optimizer momentum as 0.5, 0.9</li>\n<li>Using BatchNormalization before and after activation layer</li>\n<li>BatchNormalization momentum as 0.5, 0.9, 0.99</li>\n<li>Training for upto 3,00,000 iterations</li>\n</ol>\n\n<p>But nothing is working. I'm just getting garbage output. But I noticed two strange things</p>\n\n<ol>\n<li>Both generator and discriminator loss are going to 0, accuracy going to 1. How is this possible?</li>\n<li><strong>If I remove all Batch Normalization layers from discriminator, the model starts working. Why?</strong> The paper suggests to use BatchNormalization, but it is working otherwise.</li>\n</ol>\n\n<p>Any help, tips or suggestions is highly appreciated. Thanks!</p>\n\n<p>Here is my full code:<br>\n<em>MnistModel07.py</em></p>\n\n<pre><code>import numpy\nfrom keras import Sequential\nfrom keras.engine.saving import load_model\nfrom keras.initializers import TruncatedNormal\nfrom keras.layers import Activation, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Flatten, LeakyReLU, Reshape\nfrom keras.optimizers import Adam\n\nfrom DcGanBaseModel import DcGanBaseModel\n\n\nclass MnistModel07(DcGanBaseModel):\n    def __init__(self, verbose: bool = False):\n        super().__init__(verbose)\n        self.generator_model = None\n        self.discriminator_model = None\n        self.concatenated_model = None\n        self.verbose = verbose\n\n    def build_models(self):\n        self.generator_model = self.build_generator_model()\n        self.discriminator_model = self.build_discriminator_model()\n        self.concatenated_model = self.build_concatenated_model()\n        self.print_model_summary()\n\n    def build_generator_model(self):\n        if self.generator_model:\n            return self.generator_model\n\n        generator_model = Sequential()\n        generator_model.add(Dense(7 * 7 * 512, input_dim=100,\n                                  kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        generator_model.add(Activation('relu'))\n        generator_model.add(BatchNormalization(momentum=0.9))\n        generator_model.add(Reshape((7, 7, 512)))\n\n        generator_model.add(Conv2DTranspose(256, 3, strides=2, padding='same',\n                                            kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        generator_model.add(Activation('relu'))\n        generator_model.add(BatchNormalization(momentum=0.9))\n\n        generator_model.add(Conv2DTranspose(128, 3, strides=2, padding='same',\n                                            kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        generator_model.add(Activation('relu'))\n        generator_model.add(BatchNormalization(momentum=0.9))\n\n        generator_model.add(Conv2D(1, 3, padding='same',\n                                   kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        generator_model.add(Activation('tanh'))\n\n        return generator_model\n\n    def build_discriminator_model(self):\n        if self.discriminator_model:\n            return self.discriminator_model\n\n        discriminator_model = Sequential()\n        discriminator_model.add(Conv2D(128, 3, strides=2, input_shape=(28, 28, 1), padding='same',\n                                       kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        discriminator_model.add(LeakyReLU(alpha=0.2))\n\n        discriminator_model.add(Conv2D(256, 3, strides=2, padding='same',\n                                       kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        discriminator_model.add(LeakyReLU(alpha=0.2))\n        discriminator_model.add(BatchNormalization(momentum=0.9))\n\n        discriminator_model.add(Flatten())\n        discriminator_model.add(Dense(1, kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.02)))\n        discriminator_model.add(Activation('sigmoid'))\n\n        return discriminator_model\n\n    def build_concatenated_model(self):\n        if self.concatenated_model:\n            return self.concatenated_model\n\n        concatenated_model = Sequential()\n        concatenated_model.add(self.generator_model)\n        concatenated_model.add(self.discriminator_model)\n\n        return concatenated_model\n\n    def print_model_summary(self):\n        self.verbose_log(self.generator_model.summary())\n        self.verbose_log(self.discriminator_model.summary())\n        self.verbose_log(self.concatenated_model.summary())\n\n    def build_dc_gan(self):\n        \"\"\"\n        Binary Cross-Entropy Loss is used for both Generator and Discriminator\n        Discriminator: loss = -log(D(x)) when x is real image and loss=-log(1-D(x)) when x is fake image\n        Optimizer minimizes this loss. This is equivalent to maximize over D(x) as specified in original GAN paper\n        Generator: loss = -log(D(G(z))\n        Optimizer minimizes this loss. This is the second loss function defined in paper, not the one in min-max\n                definition\n        Since while training Generator we are not minimizing log(1-D(G(z))), the analytical results we derived won't\n                hold for generator part.\n        Ideally, Discriminator loss = -ln(0.5); Generator loss = -ln(0.5) = 0.693\n\n        metrics = accuracy: binary_accuracy is used\n        https://github.com/keras-team/keras/blob/d8b226f26b35348d934edb1213061993e7e5a1fa/keras/engine/training.py#L651\n        https://github.com/keras-team/keras/blob/c2e36f369b411ad1d0a40ac096fe35f73b9dffd3/keras/metrics.py#L6\n        Binary_accuracy: Average of correct predictions\n        Discriminator: Ideally, discriminator should be completely confused i.e. accuracy=0.5\n        Generator: Ideally, Generator should be able to fool discriminator. So, accuracy=1. But, since Discriminator\n                    is confused, it randomly flags some images as fake. So, accuracy=0.5\n        \"\"\"\n        self.build_models()\n\n        self.discriminator_model.trainable = True\n        optimizer = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, decay=0)\n        self.discriminator_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n        self.discriminator_model.trainable = False\n        optimizer = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, decay=0)\n        self.concatenated_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\n    def train_on_batch(self, images_real: numpy.ndarray):\n        # Generator output has tanh activation whose range is [-1,1]\n        images_real = (images_real.astype('float32') * 2 / 255) - 1\n\n        # Generate Fake Images\n        batch_size = images_real.shape[0]\n        noise = numpy.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n        images_fake = self.generator_model.predict(noise)\n\n        # Train discriminator on both real and fake images\n        x = numpy.concatenate((images_real, images_fake), axis=0)\n        y = numpy.ones([2 * batch_size, 1])\n        y[batch_size:, :] = 0\n        d_loss = self.discriminator_model.train_on_batch(x, y)\n\n        # Train generator i.e. concatenated model\n        # Note that in concatenated model, training of discriminator weights is disabled\n        noise = numpy.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n        y = numpy.ones([batch_size, 1])\n        g_loss = self.concatenated_model.train_on_batch(noise, y)\n\n        return g_loss, d_loss\n\n    def generate_images(self, num_images=1, noise=None) -&gt; numpy.ndarray:\n        if noise is None:\n            noise = numpy.random.uniform(-1, 1, size=[num_images, 100])\n        # Generator output has tanh activation whose range is [-1,1]\n        images = (self.generator_model.predict(noise) + 1) * 255 / 2\n        images = numpy.round(images).astype('uint8')\n        return images\n\n    def save_generator_model(self, save_path):\n        self.generator_model.save(save_path)\n\n    def save_generator_model_data(self, json_path, weights_path):\n        with open(json_path, 'w') as json_file:\n            json_file.write(self.generator_model.to_json())\n        self.generator_model.save_weights(weights_path)\n\n    def load_generator_model(self, model_path):\n        self.generator_model = load_model(model_path)\n\n    def load_generator_model_weights(self, weights_path):\n        self.generator_model.load_weights(weights_path)\n\n    def save_discriminator_model(self, save_path):\n        self.discriminator_model.save(save_path)\n\n    def save_discriminator_model_data(self, json_path, weights_path):\n        with open(json_path, 'w') as json_file:\n            json_file.write(self.discriminator_model.to_json())\n        self.discriminator_model.save_weights(weights_path)\n\n    def load_discriminator_model(self, model_path):\n        self.discriminator_model = load_model(model_path)\n\n    def load_discriminator_model_weights(self, weights_path):\n        self.discriminator_model.load_weights(weights_path)\n\n    def save_concatenated_model(self, save_path):\n        self.concatenated_model.save(save_path)\n\n    def save_concatenated_model_data(self, json_path, weights_path):\n        with open(json_path, 'w') as json_file:\n            json_file.write(self.concatenated_model.to_json())\n        self.concatenated_model.save_weights(weights_path)\n\n    def load_concatenated_model(self, model_path):\n        self.concatenated_model = load_model(model_path)\n\n    def load_concatenated_model_weights(self, weights_path):\n        self.concatenated_model.load_weights(weights_path)\n</code></pre>\n\n<p><em>MnistTrainer.py</em></p>\n\n<pre><code>import datetime\nimport os\nimport time\n\nimport numpy\nfrom keras.datasets import mnist\nfrom matplotlib import pyplot as plt\n\nfrom evaluation.EvaluationMetricsWrapper import ClassifierData, Evaluator\nfrom utils import CommonUtils, GraphPlotter\nfrom utils.CommonUtils import check_output_dir\n\n\nclass MnistTrainer:\n    def __init__(self, model, classifier_data: ClassifierData, verbose=False):\n        self.x_train = self.get_train_data()\n        self.dc_gan = model(verbose=verbose)\n        self.dc_gan.build_dc_gan()\n        self.evaluator = Evaluator(classifier_data, num_classes=10) if classifier_data is not None else None\n        self.verbose = verbose\n\n    @staticmethod\n    def get_train_data():\n        (x_train, y_train), _ = mnist.load_data()\n        x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n        return x_train\n\n    def train(self, train_steps, batch_size, loss_log_interval, save_interval, output_folder_path=None):\n        self.verbose_log('Training begins: ' + datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n        if output_folder_path is not None:\n            CommonUtils.check_output_dir(output_folder_path)\n            loss_file_path = os.path.join(output_folder_path, 'TrainLosses.csv')\n            self.initialize_loss_file(loss_file_path)\n            self.sample_real_images(output_folder_path)\n            if self.evaluator is not None:\n                metrics_filepath = os.path.join(output_folder_path, 'Evaluation/EvaluationMetrics.csv')\n                self.initialize_metrics_file(metrics_filepath)\n\n        for i in range(train_steps):\n            # Get real (Dataset) Images\n            images_real = self.x_train[numpy.random.randint(0, self.x_train.shape[0], size=batch_size), :, :, :]\n            g_loss, d_loss = self.dc_gan.train_on_batch(images_real)\n\n            if output_folder_path is not None:\n                # Save train losses,  models, generate sample images\n                if (i + 1) % loss_log_interval == 0:\n                    # noinspection PyUnboundLocalVariable\n                    self.append_losses(loss_file_path, i + 1, g_loss, d_loss)\n                if (i + 1) % save_interval == 0:\n                    self.save_models(output_folder_path, i + 1)\n                    self.generate_images(output_folder_path, i + 1)\n                    if self.evaluator is not None:\n                        # noinspection PyUnboundLocalVariable\n                        self.append_metrics(metrics_filepath, i + 1)\n\n        if output_folder_path is not None:\n            # Plot the loss functions and accuracy\n            graph_file_path = os.path.join(output_folder_path, 'LossAccuracyPlot.png')\n            GraphPlotter.plot_loss_and_accuracy(loss_file_path, graph_file_path)\n            if self.evaluator is not None:\n                metrics_graph_path = os.path.join(output_folder_path, 'Evaluation/EvaluationMetrics.png')\n                GraphPlotter.plot_evaluation_metrics(metrics_filepath, metrics_graph_path)\n\n        self.verbose_log('Training ends: ' + datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n\n    @staticmethod\n    def initialize_loss_file(loss_file_path):\n        line = 'Iteration No, Generator Loss, Generator Accuracy, Discriminator Loss, Discriminator Accuracy, Time\\n'\n        with open(loss_file_path, 'w') as loss_file:\n            loss_file.write(line)\n\n    def append_losses(self, loss_file_path, iteration_no, g_loss, d_loss):\n        line = '{0:05},{1:2.4f},{2:0.4f},{3:2.4f},{4:0.4f},{5}\\n' \\\n            .format(iteration_no, g_loss[0], g_loss[1], d_loss[0], d_loss[1],\n                    datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n        with open(loss_file_path, 'a') as loss_file:\n            loss_file.write(line)\n        self.verbose_log(line)\n\n    def save_models(self, output_folder_path, iteration_no):\n        models_save_dir = os.path.join(output_folder_path, 'TrainedModels')\n        if not os.path.exists(models_save_dir):\n            os.makedirs(models_save_dir)\n\n        self.dc_gan.save_generator_model(\n            os.path.join(models_save_dir, 'generator_model_{0}.h5'.format(iteration_no)))\n        self.dc_gan.save_generator_model_data(\n            os.path.join(models_save_dir, 'generator_model_arch_{0}.json'.format(iteration_no)),\n            os.path.join(models_save_dir, 'generator_model_weights_{0}.h5'.format(iteration_no))\n        )\n\n        self.dc_gan.save_discriminator_model(\n            os.path.join(models_save_dir, 'discriminator_model_{0}.h5'.format(iteration_no)))\n        self.dc_gan.save_discriminator_model_data(\n            os.path.join(models_save_dir, 'discriminator_model_arch_{0}.json'.format(iteration_no)),\n            os.path.join(models_save_dir, 'discriminator_model_weights_{0}.h5'.format(iteration_no))\n        )\n\n        self.dc_gan.save_concatenated_model(\n            os.path.join(models_save_dir, 'concatenated_model_{0}.h5'.format(iteration_no)))\n        self.dc_gan.save_concatenated_model_data(\n            os.path.join(models_save_dir, 'concatenated_model_arch_{0}.json'.format(iteration_no)),\n            os.path.join(models_save_dir, 'concatenated_model_weights_{0}.h5'.format(iteration_no))\n        )\n\n    def sample_real_images(self, output_folder_path):\n        filepath = os.path.join(output_folder_path, 'MNIST_Sample_Real_Images.png')\n        i = numpy.random.randint(0, self.x_train.shape[0], 16)\n        images = self.x_train[i, :, :, :]\n        plt.figure(figsize=(10, 10))\n        for i in range(16):\n            plt.subplot(4, 4, i + 1)\n            image = images[i, :, :, :]\n            image = numpy.reshape(image, [28, 28])\n            plt.imshow(image, cmap='gray')\n            plt.axis('off')\n        plt.tight_layout()\n        plt.savefig(filepath)\n        plt.close('all')\n\n    def generate_images(self, output_folder_path, iteration_no, noise=None):\n        gen_images_dir = os.path.join(output_folder_path, 'Generated_Images')\n        if not os.path.exists(gen_images_dir):\n            os.makedirs(gen_images_dir)\n        filepath = os.path.join(gen_images_dir, 'MNIST_Gen_Image{0}.png'.format(iteration_no))\n        images = self.dc_gan.generate_images(16, noise)\n        plt.figure(figsize=(10, 10))\n        for i in range(16):\n            plt.subplot(4, 4, i + 1)\n            image = images[i, :, :, :]\n            image = numpy.reshape(image, [28, 28])\n            plt.imshow(image, cmap='gray')\n            plt.axis('off')\n        plt.tight_layout()\n        plt.savefig(filepath)\n        plt.close('all')\n\n    def initialize_metrics_file(self, filepath: str):\n        check_output_dir(os.path.split(filepath)[0])\n        with open(filepath, 'w') as metrics_file:\n            metrics_file.write('Iteration No,' + ','.join(self.evaluator.get_metrics_names()) + '\\n')\n\n    def append_metrics(self, filepath: str, iteration_no):\n        metrics = self.evaluator.evaluate(self.dc_gan)\n        with open(filepath, 'a') as metrics_file:\n            metrics_file.write(str(iteration_no) + ',' + ','.join(map(str, metrics)) + '\\n')\n\n    def verbose_log(self, log_line):\n        if self.verbose:\n            print(log_line)\n\n\ndef main():\n    \"\"\"\n    Execute in src directory\n    \"\"\"\n    from mnist.MnistModel05 import MnistModel05\n\n    train_steps = 10000\n    batch_size = 128\n    loss_log_interval = 10\n    save_interval = 100\n    output_folder_path = '../Runs/Run01'\n\n    classifier_name = 'MnistClassifier06'\n    classifier_filepath = '../../../../DiscriminativeModels/01_MNIST_Classification/src/MnistClassifierModel06.py'\n    classifier_json_path = \\\n        '../../../../DiscriminativeModels/01_MNIST_Classification/Runs/MnistClassifier06/Run01/TrainedModels' \\\n        '/MNIST_Model_Arch_30.json'\n    classifier_weights_path = \\\n        '../../../../DiscriminativeModels/01_MNIST_Classification/Runs/MnistClassifier06/Run01/TrainedModels' \\\n        '/MNIST_Model_Weights_30.h5'\n    classifier_data = ClassifierData(classifier_name, classifier_filepath, classifier_json_path,\n                                     classifier_weights_path)\n\n    mnist_trainer = MnistTrainer(model=MnistModel05, classifier_data=classifier_data, verbose=True)\n    mnist_trainer.train(train_steps, batch_size, loss_log_interval, save_interval, output_folder_path)\n    del mnist_trainer.dc_gan\n    return\n\n\nif __name__ == '__main__':\n    start_time = time.time()\n    print('Program Started at {0}'.format(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))))\n    try:\n        main()\n    except Exception as e:\n        print(e)\n    end_time = time.time()\n    print('Program Ended at {0}'.format(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))))\n    print('Total Execution Time: {0}s'.format(datetime.timedelta(seconds=end_time - start_time)))\n</code></pre>\n",
                "tags": "<training><gan><mnist>",
                "answers": [
                    [
                        "56891",
                        "2",
                        "56860",
                        "",
                        "",
                        "<p><strong>Golden Rule:</strong> In Keras, if using Batch Normalization layer, train the discriminator on real and fake images separately. Don't combine them.</p>\n\n<hr>\n\n<p>I was able to solve it by changing the discriminator training code as follows:</p>\n\n<pre><code>d_loss = self.discriminator_model.train_on_batch(images_real, numpy.ones((batch_size, 1)))\nd_loss = self.discriminator_model.train_on_batch(images_fake, numpy.zeros((batch_size, 1)))\n</code></pre>\n\n<p>With this change, the issue of generator and discriminator accuracy being at 1 was also solved. I guess combining real and fake images in a single batch causes some problem with the Batch Normalization in Keras. That was the problem. Why that causing the problem, I have no idea.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4442",
            "_score": 7.8778286,
            "_source": {
                "title": "Reproducing randomForest Proximity Matrix from R package in Python",
                "content": "Reproducing randomForest Proximity Matrix from R package in Python <p>I am trying to port this little piece of R code to python:</p>\n\n<pre><code>rf &lt;- randomForest(features, proximity = T, oob.prox = T, ntree = 2000)\ndists &lt;- as.dist(1 - rf$proximity)\n</code></pre>\n\n<p>with parameters<br>\noob.prox: Should proximity be calculated only on \u201cout-of-bag\u201d data?<br>\nproximity: if proximity=TRUE when randomForest is called, a matrix of proximity measures among the input (based on the frequency that pairs of data points are in the same terminal nodes).  </p>\n\n<p>I am currently trying using sklearn.ensemble.RandomTreesEmbedding for this task, however there is no functionality for the proximity matrix. I found the following developer comment though:</p>\n\n<blockquote>\n  <p>We don't implement proximity matrix in Scikit-Learn (yet).\n   However, this could be done by relying on the apply function provided\n   in our implementation of decision trees. That is, for all pairs of \n   samples in your dataset, iterate over the decision trees in the forest\n   (through forest.estimators_) and count the number of times they fall \n   in the same leaf, i.e., the number of times apply give the same node \n   id for both samples in the pair.  </p>\n</blockquote>\n\n<p>And so I tried, utilizing numpy's pdist() function along with my custom distance (or in this case, proximity) measure. I still have several problems:  </p>\n\n<ol>\n<li>The proximity function is outstandingly slow  </li>\n<li>How to handle the out-of-bag behaviour  </li>\n<li>How to recreate the exact behaviour of as.dist(1- rf$proximity): I think I need to normalize my count matrix, then subtract it from 1 and then afterwards compute the euclidean distances between its rows!?  </li>\n</ol>\n\n<p>My code as of now looks like this:</p>\n\n<pre><code># grow a random forest from points\nrf = ensemble.RandomTreesEmbedding(n_estimators=200, \n    random_state=0,\n    max_depth=5\n)\nrfdata = rf.fit_transform(xdata);\n\n\n# define an affinity measure function to use with numpy's pdist\ndef treeprox(u, v):\n    leafcount = 0\n    # needs reshaping for single samples\n    u = u.reshape(1,-1)\n    v = v.reshape(1,-1)\n    a = rf.apply(u)\n    b = rf.apply(v)\n    # count number of times they fall in the same leaf \n    # (use of np forces element-wise)\n    c = np.sum(np.array(a)==np.array(b))\n    return c\n\ndistm = pdist(xdata, proxfun)\ndistm = squareform(distm)\n</code></pre>\n\n<p>There must be a better way I guess, since this functionality is readily provided by the R package randomForest.<br>\nAny suggestions?<br>\ntia</p>\n <python><r><scikit-learn><random-forest><p>I have written some code for this. It can be found <a href=\"https://stats.stackexchange.com/questions/270201/pooling-levels-of-categorical-variables-for-regression-trees/\">here</a>. In answer to your specific questions:</p>\n\n<ol>\n<li>I have tried to optimize for speed. What I did should be a little faster than the code above.</li>\n<li>I do not use out of bag records. In fact the original documentation does not suggest this. I created another <a href=\"https://stats.stackexchange.com/questions/274857/proximity-matrix-should-i-include-in-bag-records\">post</a> to see if the consequences are understood.</li>\n<li>This is handled in my code by normalizing by the total possible leaves that could be matched.</li>\n</ol>\n",
                "codes": [
                    []
                ],
                "question_id:": "17641",
                "question_votes:": "4",
                "question_text:": "<p>I am trying to port this little piece of R code to python:</p>\n\n<pre><code>rf &lt;- randomForest(features, proximity = T, oob.prox = T, ntree = 2000)\ndists &lt;- as.dist(1 - rf$proximity)\n</code></pre>\n\n<p>with parameters<br>\noob.prox: Should proximity be calculated only on \u201cout-of-bag\u201d data?<br>\nproximity: if proximity=TRUE when randomForest is called, a matrix of proximity measures among the input (based on the frequency that pairs of data points are in the same terminal nodes).  </p>\n\n<p>I am currently trying using sklearn.ensemble.RandomTreesEmbedding for this task, however there is no functionality for the proximity matrix. I found the following developer comment though:</p>\n\n<blockquote>\n  <p>We don't implement proximity matrix in Scikit-Learn (yet).\n   However, this could be done by relying on the apply function provided\n   in our implementation of decision trees. That is, for all pairs of \n   samples in your dataset, iterate over the decision trees in the forest\n   (through forest.estimators_) and count the number of times they fall \n   in the same leaf, i.e., the number of times apply give the same node \n   id for both samples in the pair.  </p>\n</blockquote>\n\n<p>And so I tried, utilizing numpy's pdist() function along with my custom distance (or in this case, proximity) measure. I still have several problems:  </p>\n\n<ol>\n<li>The proximity function is outstandingly slow  </li>\n<li>How to handle the out-of-bag behaviour  </li>\n<li>How to recreate the exact behaviour of as.dist(1- rf$proximity): I think I need to normalize my count matrix, then subtract it from 1 and then afterwards compute the euclidean distances between its rows!?  </li>\n</ol>\n\n<p>My code as of now looks like this:</p>\n\n<pre><code># grow a random forest from points\nrf = ensemble.RandomTreesEmbedding(n_estimators=200, \n    random_state=0,\n    max_depth=5\n)\nrfdata = rf.fit_transform(xdata);\n\n\n# define an affinity measure function to use with numpy's pdist\ndef treeprox(u, v):\n    leafcount = 0\n    # needs reshaping for single samples\n    u = u.reshape(1,-1)\n    v = v.reshape(1,-1)\n    a = rf.apply(u)\n    b = rf.apply(v)\n    # count number of times they fall in the same leaf \n    # (use of np forces element-wise)\n    c = np.sum(np.array(a)==np.array(b))\n    return c\n\ndistm = pdist(xdata, proxfun)\ndistm = squareform(distm)\n</code></pre>\n\n<p>There must be a better way I guess, since this functionality is readily provided by the R package randomForest.<br>\nAny suggestions?<br>\ntia</p>\n",
                "tags": "<python><r><scikit-learn><random-forest>",
                "answers": [
                    [
                        "18596",
                        "2",
                        "17641",
                        "",
                        "",
                        "<p>I have written some code for this. It can be found <a href=\"https://stats.stackexchange.com/questions/270201/pooling-levels-of-categorical-variables-for-regression-trees/\">here</a>. In answer to your specific questions:</p>\n\n<ol>\n<li>I have tried to optimize for speed. What I did should be a little faster than the code above.</li>\n<li>I do not use out of bag records. In fact the original documentation does not suggest this. I created another <a href=\"https://stats.stackexchange.com/questions/274857/proximity-matrix-should-i-include-in-bag-records\">post</a> to see if the consequences are understood.</li>\n<li>This is handled in my code by normalizing by the total possible leaves that could be matched.</li>\n</ol>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10936",
            "_score": 7.8778286,
            "_source": {
                "title": "Always getting value one for a binary classifier",
                "content": "Always getting value one for a binary classifier <p>I'm using keras. I have one classification problem. The output should be either 0 or 1. I trained my model and I'm getting 86.59 accuracy. But when i check the predicted output what I'm seeing is all ones. I tried creating a categorical classifier with two nodes and tried the same. The test accuracy is 86.59% but when I check the output the prediction contains only one node with value one for the entire dataset. </p>\n\n<p>This is the code</p>\n\n<pre><code>from keras.models import Sequential\n\nmodel = Sequential()\nfrom keras.utils import to_categorical\ny_traine = to_categorical(y_train)\ny_teste = to_categorical(y_test)\n\nfrom keras.layers import Dense\nx_train = x_train.reshape(1300,64)\nmodel.add(Dense(units=64, activation='relu', input_dim=64))\nmodel.add(Dense(units=2, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='sgd',\n              metrics=['accuracy'])\n# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\nmodel.fit(x_train, y_traine, epochs=50, batch_size=32)\nx_test = x_test.reshape(len(x_test),64)\nloss_and_metrics = model.evaluate(x_test, y_teste, batch_size=128)\nclasses = model.predict(x_test, batch_size=128)\nprint (loss_and_metrics)\nprint (classes)\n</code></pre>\n\n<p>output</p>\n\n<pre><code>[0.32096896952051834, 0.875968992248062]\n\n[[0.84422934 0.1557707 ]\n [0.8332991  0.16670085]\n [0.86778754 0.13221247]\n [0.9261704  0.07382962]\n [0.85143256 0.14856751]\n .\n .\n</code></pre>\n\n<p>What I'm doing wrong here? Why I'm getting training accuracy as 86% if my predictions are wrong?</p>\n <keras><classifier><p>As with most problems like this, it is always best to see the dataset upfront to gain a full understanding.</p>\n\n<p>That said, if your categorical dependent variable is between 0 and 1, have you ensured that the independent variables in your dataset have also been scaled in this way? From looking at your code, it doesn't look like this is the case.</p>\n\n<p>If your data has not been transformed to a common scale, then the neural network won't necessarily give you accurate results.</p>\n\n<p>In this regard, you might try scaling your x data with <strong>MinMaxScaler</strong> if you haven't done so already and see what you com up with.</p>\n\n<p>For instance, suppose you have variables <strong>x1</strong>, <strong>x2</strong>, and <strong>x3</strong>.</p>\n\n<pre><code>import numpy as np    \nfrom sklearn.preprocessing import MinMaxScaler\n\nx=np.column_stack((x1,x2,x3))\nx=sm.add_constant(x,prepend=True)\n\nx_scaled=MinMaxScaler().fit_transform(x)\nx_train,x_test,y_train,y_test = train_test_split(x_scaled,y,test_size=0.2)\n</code></pre>\n\n<p>Essentially, you are scaling the x variables between 0 and 1, so that the x variables now have the same scale as the y variable. It might be an idea to try this if you haven't already and see what you come up with.</p>\n<p>Did you check how many samples are there for each class. I suspect imbalance class problem here. If you have majority of images with class=1. Classifier will be biased towards predicting everything as class 1. Try to balance your classes by either duplicating minor class images or deleting major class images.</p>\n",
                "codes": [
                    [
                        "import numpy as np    \nfrom sklearn.preprocessing import MinMaxScaler\n\nx=np.column_stack((x1,x2,x3))\nx=sm.add_constant(x,prepend=True)\n\nx_scaled=MinMaxScaler().fit_transform(x)\nx_train,x_test,y_train,y_test = train_test_split(x_scaled,y,test_size=0.2)\n"
                    ],
                    []
                ],
                "question_id:": "38760",
                "question_votes:": "",
                "question_text:": "<p>I'm using keras. I have one classification problem. The output should be either 0 or 1. I trained my model and I'm getting 86.59 accuracy. But when i check the predicted output what I'm seeing is all ones. I tried creating a categorical classifier with two nodes and tried the same. The test accuracy is 86.59% but when I check the output the prediction contains only one node with value one for the entire dataset. </p>\n\n<p>This is the code</p>\n\n<pre><code>from keras.models import Sequential\n\nmodel = Sequential()\nfrom keras.utils import to_categorical\ny_traine = to_categorical(y_train)\ny_teste = to_categorical(y_test)\n\nfrom keras.layers import Dense\nx_train = x_train.reshape(1300,64)\nmodel.add(Dense(units=64, activation='relu', input_dim=64))\nmodel.add(Dense(units=2, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='sgd',\n              metrics=['accuracy'])\n# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\nmodel.fit(x_train, y_traine, epochs=50, batch_size=32)\nx_test = x_test.reshape(len(x_test),64)\nloss_and_metrics = model.evaluate(x_test, y_teste, batch_size=128)\nclasses = model.predict(x_test, batch_size=128)\nprint (loss_and_metrics)\nprint (classes)\n</code></pre>\n\n<p>output</p>\n\n<pre><code>[0.32096896952051834, 0.875968992248062]\n\n[[0.84422934 0.1557707 ]\n [0.8332991  0.16670085]\n [0.86778754 0.13221247]\n [0.9261704  0.07382962]\n [0.85143256 0.14856751]\n .\n .\n</code></pre>\n\n<p>What I'm doing wrong here? Why I'm getting training accuracy as 86% if my predictions are wrong?</p>\n",
                "tags": "<keras><classifier>",
                "answers": [
                    [
                        "38778",
                        "2",
                        "38760",
                        "",
                        "",
                        "<p>As with most problems like this, it is always best to see the dataset upfront to gain a full understanding.</p>\n\n<p>That said, if your categorical dependent variable is between 0 and 1, have you ensured that the independent variables in your dataset have also been scaled in this way? From looking at your code, it doesn't look like this is the case.</p>\n\n<p>If your data has not been transformed to a common scale, then the neural network won't necessarily give you accurate results.</p>\n\n<p>In this regard, you might try scaling your x data with <strong>MinMaxScaler</strong> if you haven't done so already and see what you com up with.</p>\n\n<p>For instance, suppose you have variables <strong>x1</strong>, <strong>x2</strong>, and <strong>x3</strong>.</p>\n\n<pre><code>import numpy as np    \nfrom sklearn.preprocessing import MinMaxScaler\n\nx=np.column_stack((x1,x2,x3))\nx=sm.add_constant(x,prepend=True)\n\nx_scaled=MinMaxScaler().fit_transform(x)\nx_train,x_test,y_train,y_test = train_test_split(x_scaled,y,test_size=0.2)\n</code></pre>\n\n<p>Essentially, you are scaling the x variables between 0 and 1, so that the x variables now have the same scale as the y variable. It might be an idea to try this if you haven't already and see what you come up with.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "38761",
                        "2",
                        "38760",
                        "",
                        "",
                        "<p>Did you check how many samples are there for each class. I suspect imbalance class problem here. If you have majority of images with class=1. Classifier will be biased towards predicting everything as class 1. Try to balance your classes by either duplicating minor class images or deleting major class images.</p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "201",
            "_score": 7.860095,
            "_source": {
                "title": "Data visualization for pattern analysis (language-independent, but R preferred)",
                "content": "Data visualization for pattern analysis (language-independent, but R preferred) <p>I want to plot the bytes from a disk image in order to understand a pattern in them. This is mainly an academic task, since I'm almost sure this pattern was created by a disk testing program, but I'd like to reverse-engineer it anyway.</p>\n\n<p>I already know that the pattern is aligned, with a periodicity of 256 characters.</p>\n\n<p>I can envision two ways of visualizing this information: either a 16x16 plane viewed through time (3 dimensions), where each pixel's color is the ASCII code for the character, or a 256 pixel line for each period (2 dimensions).</p>\n\n<p>This is a snapshot of the pattern (you can see more than one), seen through <code>xxd</code> (32x16):</p>\n\n<p><img src=\"https://i.stack.imgur.com/zOFSK.gif\" alt=\"Pattern to analyze\"></p>\n\n<p>Either way, I am trying to find a way of visualizing this information. This probably isn't hard for anyone into signal analysis, but I can't seem to find a way using open-source software.</p>\n\n<p>I'd like to avoid Matlab or Mathematica and I'd prefer an answer in R, since I have been learning it recently, but nonetheless, any language is welcome.</p>\n\n<hr>\n\n<p>Update, 2014-07-25: given Emre's answer below, this is what the pattern looks like, given the first 30MB of the pattern, aligned at 512 instead of 256 (this alignment looks better):</p>\n\n<p><img src=\"https://i.stack.imgur.com/4tDIA.png\" alt=\"Graphical pattern\"></p>\n\n<p>Any further ideas are welcome!</p>\n <r><visualization><p>I would use a visual analysis. Since you know there is a repetition every 256 bytes, create an image 256 pixels wide by however many deep, and encode the data using brightness. In (i)python it would look like this:</p>\n\n<pre><code>import os, numpy, matplotlib.pyplot as plt\n\n%matplotlib inline\n\ndef read_in_chunks(infile, chunk_size=256):\n    while True:\n        chunk = infile.read(chunk_size)\n        if chunk:\n            yield chunk\n        else:\n            # The chunk was empty, which means we're at the end\n            # of the file\n            return\n\nfname = 'enter something here'\nsrcfile = open(fname, 'rb')\nheight = 1 + os.path.getsize(fname)/256\ndata = numpy.zeros((height, 256), dtype=numpy.uint8)    \n\nfor i, line in enumerate(read_in_chunks(srcfile)):\n    vals = list(map(int, line))\n    data[i,:len(vals)] = vals\n\nplt.imshow(data, aspect=1e-2);\n</code></pre>\n\n<p>This is what a PDF looks like:</p>\n\n<p><img src=\"https://i.stack.imgur.com/bicgF.png\" alt=\"A PDF file visualized\"></p>\n\n<p>A 256 byte periodic pattern would have manifested itself as vertical lines. Except for the header and tail it looks pretty noisy.</p>\n<p>I would look at the <code>raster</code> package for this, which can read in raw binary data and present it as NxM grids. It can even extract subsets of large binary grids without having to read in the whole file (the R raster object itself is just a proxy to the data, not the data itself).</p>\n<p>I know almost nothing about signal analysis, but 2-dimensional visualization could be easily done using R. Particularly you will need <code>reshape2</code> and <code>ggplot2</code> packages. Assuming your data is <strong>wide</strong> (e.g. [n X 256] size), first you need to transform it to <a href=\"http://www.cookbook-r.com/Manipulating_data/Converting_data_between_wide_and_long_format/\" rel=\"nofollow\"><strong>long</strong></a> format using <code>melt()</code> function from <code>reshape2</code> package. Then use <a href=\"http://docs.ggplot2.org/current/geom_tile.html\" rel=\"nofollow\"><code>geom_tile</code></a> geometry from <code>ggplot2</code>. Here is a nice <a href=\"http://www.r-bloggers.com/simplest-possible-heatmap-with-ggplot2/\" rel=\"nofollow\">recipe</a> with <a href=\"https://gist.github.com/dsparks/3710171\" rel=\"nofollow\">gist</a>.</p>\n",
                "codes": [
                    [
                        "import os, numpy, matplotlib.pyplot as plt\n\n%matplotlib inline\n\ndef read_in_chunks(infile, chunk_size=256):\n    while True:\n        chunk = infile.read(chunk_size)\n        if chunk:\n            yield chunk\n        else:\n            # The chunk was empty, which means we're at the end\n            # of the file\n            return\n\nfname = 'enter something here'\nsrcfile = open(fname, 'rb')\nheight = 1 + os.path.getsize(fname)/256\ndata = numpy.zeros((height, 256), dtype=numpy.uint8)    \n\nfor i, line in enumerate(read_in_chunks(srcfile)):\n    vals = list(map(int, line))\n    data[i,:len(vals)] = vals\n\nplt.imshow(data, aspect=1e-2);\n"
                    ],
                    [],
                    []
                ],
                "question_id:": "783",
                "question_votes:": "10",
                "question_text:": "<p>I want to plot the bytes from a disk image in order to understand a pattern in them. This is mainly an academic task, since I'm almost sure this pattern was created by a disk testing program, but I'd like to reverse-engineer it anyway.</p>\n\n<p>I already know that the pattern is aligned, with a periodicity of 256 characters.</p>\n\n<p>I can envision two ways of visualizing this information: either a 16x16 plane viewed through time (3 dimensions), where each pixel's color is the ASCII code for the character, or a 256 pixel line for each period (2 dimensions).</p>\n\n<p>This is a snapshot of the pattern (you can see more than one), seen through <code>xxd</code> (32x16):</p>\n\n<p><img src=\"https://i.stack.imgur.com/zOFSK.gif\" alt=\"Pattern to analyze\"></p>\n\n<p>Either way, I am trying to find a way of visualizing this information. This probably isn't hard for anyone into signal analysis, but I can't seem to find a way using open-source software.</p>\n\n<p>I'd like to avoid Matlab or Mathematica and I'd prefer an answer in R, since I have been learning it recently, but nonetheless, any language is welcome.</p>\n\n<hr>\n\n<p>Update, 2014-07-25: given Emre's answer below, this is what the pattern looks like, given the first 30MB of the pattern, aligned at 512 instead of 256 (this alignment looks better):</p>\n\n<p><img src=\"https://i.stack.imgur.com/4tDIA.png\" alt=\"Graphical pattern\"></p>\n\n<p>Any further ideas are welcome!</p>\n",
                "tags": "<r><visualization>",
                "answers": [
                    [
                        "799",
                        "2",
                        "783",
                        "",
                        "",
                        "<p>I would use a visual analysis. Since you know there is a repetition every 256 bytes, create an image 256 pixels wide by however many deep, and encode the data using brightness. In (i)python it would look like this:</p>\n\n<pre><code>import os, numpy, matplotlib.pyplot as plt\n\n%matplotlib inline\n\ndef read_in_chunks(infile, chunk_size=256):\n    while True:\n        chunk = infile.read(chunk_size)\n        if chunk:\n            yield chunk\n        else:\n            # The chunk was empty, which means we're at the end\n            # of the file\n            return\n\nfname = 'enter something here'\nsrcfile = open(fname, 'rb')\nheight = 1 + os.path.getsize(fname)/256\ndata = numpy.zeros((height, 256), dtype=numpy.uint8)    \n\nfor i, line in enumerate(read_in_chunks(srcfile)):\n    vals = list(map(int, line))\n    data[i,:len(vals)] = vals\n\nplt.imshow(data, aspect=1e-2);\n</code></pre>\n\n<p>This is what a PDF looks like:</p>\n\n<p><img src=\"https://i.stack.imgur.com/bicgF.png\" alt=\"A PDF file visualized\"></p>\n\n<p>A 256 byte periodic pattern would have manifested itself as vertical lines. Except for the header and tail it looks pretty noisy.</p>\n",
                        "",
                        "6"
                    ],
                    [
                        "837",
                        "2",
                        "783",
                        "",
                        "",
                        "<p>I would look at the <code>raster</code> package for this, which can read in raw binary data and present it as NxM grids. It can even extract subsets of large binary grids without having to read in the whole file (the R raster object itself is just a proxy to the data, not the data itself).</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "785",
                        "2",
                        "783",
                        "",
                        "",
                        "<p>I know almost nothing about signal analysis, but 2-dimensional visualization could be easily done using R. Particularly you will need <code>reshape2</code> and <code>ggplot2</code> packages. Assuming your data is <strong>wide</strong> (e.g. [n X 256] size), first you need to transform it to <a href=\"http://www.cookbook-r.com/Manipulating_data/Converting_data_between_wide_and_long_format/\" rel=\"nofollow\"><strong>long</strong></a> format using <code>melt()</code> function from <code>reshape2</code> package. Then use <a href=\"http://docs.ggplot2.org/current/geom_tile.html\" rel=\"nofollow\"><code>geom_tile</code></a> geometry from <code>ggplot2</code>. Here is a nice <a href=\"http://www.r-bloggers.com/simplest-possible-heatmap-with-ggplot2/\" rel=\"nofollow\">recipe</a> with <a href=\"https://gist.github.com/dsparks/3710171\" rel=\"nofollow\">gist</a>.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16005",
            "_score": 7.860095,
            "_source": {
                "title": "How to find prediction probability in given CNN in tensor flow?",
                "content": "How to find prediction probability in given CNN in tensor flow? <p>I am very new in tenser flow. Lets assume I already have a trained convolution neutral network, now I give one new data to this CNN, and I want to see whats the prediction probability in each class. (e.g, the CNN is for handwriting 0-2, now I give a new data 2 to this trained CNN, the prediction probability should give me something like, 0.01 for class 0, 0.02 for class 1, and 0.97 for class 2)</p>\n\n<p>May I ask someone advise me, whats the right code to do that in tenser flow (1.13.1) for python ? Sorry about the elementary level question.</p>\n\n<p>I am using the example code.  </p>\n\n<pre><code>\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\nprint(\"heeeeeeeeeeeeeeeeeeeeere:\", tf.VERSION)\n\ntf.logging.set_verbosity(tf.logging.DEBUG)\n\n\ndef cnn_model_fn(features, labels, mode):\n  \"\"\"Model function for CNN.\"\"\"\n\n  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n\n  conv1 = tf.layers.conv2d(inputs=input_layer, filters=30, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu)\n\n  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n\n  pool2_flat = tf.reshape(pool1, [-1, 14 * 14 * 30])\n\n  dense = tf.layers.dense(inputs=pool2_flat, units=1000, activation=tf.nn.relu)\n\n  # Add dropout operation; 0.6 probability that element will be kept\n  dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n\n  logits = tf.layers.dense(inputs=dropout, units=10)\n\n  predictions = {\n      # Generate predictions (for PREDICT and EVAL mode)\n      \"classes\": tf.argmax(input=logits, axis=1),\n      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n      # `logging_hook`.\n      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n  }\n\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n  # Calculate Loss (for both TRAIN and EVAL modes)\n  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\n  # Configure the Training Op (for TRAIN mode)\n  if mode == tf.estimator.ModeKeys.TRAIN:\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n    train_op = optimizer.minimize(\n        loss=loss,\n        global_step=tf.train.get_global_step())\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n  # Add evaluation metrics (for EVAL mode)\n  eval_metric_ops = {\n      \"accuracy after all\": tf.metrics.accuracy(\n          labels=labels, predictions=predictions[\"classes\"])}\n  return tf.estimator.EstimatorSpec(\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n\n\ndef main(unused_argv):\n  model_path = \"/tmp/mnist_convnet_model\"\n\n  # Load training and eval data\n  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n  train_data = mnist.train.images  # Returns np.array\n  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n  eval_data = mnist.test.images  # Returns np.array\n  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n\n  # delete old checkpoint if needed\n  delete_checkpoint = True\n  import os\n  if (delete_checkpoint and os.path.isfile(model_path + '/checkpoint')):\n      os.remove(model_path + '/checkpoint')\n\n  # Create the Estimator\n  mnist_classifier = tf.estimator.Estimator(\n      model_fn=cnn_model_fn, model_dir=model_path)\n\n  # Set up logging for predictions\n  # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n  logging_hook = tf.train.LoggingTensorHook(\n      tensors=tensors_to_log, every_n_iter=50)\n\n  # Train the model\n  train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n      x={\"x\": train_data},\n      y=train_labels,\n      batch_size=100,\n      num_epochs=None,\n      shuffle=True)\n  mnist_classifier.train(\n      input_fn=train_input_fn,\n      steps=5000,\n      hooks=[logging_hook])\n\n  # Evaluate the model and print results\n  eval_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n      x={\"x\": eval_data}, y=eval_labels, num_epochs=1, shuffle=False)\n  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n  print(eval_results)\n\n\nif __name__ == \"__main__\":\n  tf.app.run()\n\n</code></pre>\n <python><tensorflow><cnn><prediction>",
                "codes": [],
                "question_id:": "53142",
                "question_votes:": "",
                "question_text:": "<p>I am very new in tenser flow. Lets assume I already have a trained convolution neutral network, now I give one new data to this CNN, and I want to see whats the prediction probability in each class. (e.g, the CNN is for handwriting 0-2, now I give a new data 2 to this trained CNN, the prediction probability should give me something like, 0.01 for class 0, 0.02 for class 1, and 0.97 for class 2)</p>\n\n<p>May I ask someone advise me, whats the right code to do that in tenser flow (1.13.1) for python ? Sorry about the elementary level question.</p>\n\n<p>I am using the example code.  </p>\n\n<pre><code>\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\nprint(\"heeeeeeeeeeeeeeeeeeeeere:\", tf.VERSION)\n\ntf.logging.set_verbosity(tf.logging.DEBUG)\n\n\ndef cnn_model_fn(features, labels, mode):\n  \"\"\"Model function for CNN.\"\"\"\n\n  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n\n  conv1 = tf.layers.conv2d(inputs=input_layer, filters=30, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu)\n\n  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n\n  pool2_flat = tf.reshape(pool1, [-1, 14 * 14 * 30])\n\n  dense = tf.layers.dense(inputs=pool2_flat, units=1000, activation=tf.nn.relu)\n\n  # Add dropout operation; 0.6 probability that element will be kept\n  dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n\n  logits = tf.layers.dense(inputs=dropout, units=10)\n\n  predictions = {\n      # Generate predictions (for PREDICT and EVAL mode)\n      \"classes\": tf.argmax(input=logits, axis=1),\n      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n      # `logging_hook`.\n      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n  }\n\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n  # Calculate Loss (for both TRAIN and EVAL modes)\n  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\n  # Configure the Training Op (for TRAIN mode)\n  if mode == tf.estimator.ModeKeys.TRAIN:\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n    train_op = optimizer.minimize(\n        loss=loss,\n        global_step=tf.train.get_global_step())\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n  # Add evaluation metrics (for EVAL mode)\n  eval_metric_ops = {\n      \"accuracy after all\": tf.metrics.accuracy(\n          labels=labels, predictions=predictions[\"classes\"])}\n  return tf.estimator.EstimatorSpec(\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n\n\ndef main(unused_argv):\n  model_path = \"/tmp/mnist_convnet_model\"\n\n  # Load training and eval data\n  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n  train_data = mnist.train.images  # Returns np.array\n  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n  eval_data = mnist.test.images  # Returns np.array\n  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n\n  # delete old checkpoint if needed\n  delete_checkpoint = True\n  import os\n  if (delete_checkpoint and os.path.isfile(model_path + '/checkpoint')):\n      os.remove(model_path + '/checkpoint')\n\n  # Create the Estimator\n  mnist_classifier = tf.estimator.Estimator(\n      model_fn=cnn_model_fn, model_dir=model_path)\n\n  # Set up logging for predictions\n  # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n  logging_hook = tf.train.LoggingTensorHook(\n      tensors=tensors_to_log, every_n_iter=50)\n\n  # Train the model\n  train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n      x={\"x\": train_data},\n      y=train_labels,\n      batch_size=100,\n      num_epochs=None,\n      shuffle=True)\n  mnist_classifier.train(\n      input_fn=train_input_fn,\n      steps=5000,\n      hooks=[logging_hook])\n\n  # Evaluate the model and print results\n  eval_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n      x={\"x\": eval_data}, y=eval_labels, num_epochs=1, shuffle=False)\n  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n  print(eval_results)\n\n\nif __name__ == \"__main__\":\n  tf.app.run()\n\n</code></pre>\n",
                "tags": "<python><tensorflow><cnn><prediction>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6242",
            "_score": 7.836322,
            "_source": {
                "title": "Low accuracy using Multi Layer perceptron network on CIFAR10 dataset?",
                "content": "Low accuracy using Multi Layer perceptron network on CIFAR10 dataset? <p>I  trained Muti layer perceptrons using keras to classify cifar-10 dataset the results I got shows that there is something wrong in the code ,because all the epoch are identical here is the code :\nIn this I flatten the data from 32x32x3 to 3072 array.</p>\n\n<pre><code>   #nn layers \nimport numpy\nfrom keras.datasets import cifar10\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom matplotlib import pyplot\nfrom scipy.misc import toimage\n\n#load data\n(Xt,Yt),(Xts,Yts)=cifar10.load_data()\n\nnum_pix=Xt.shape[1]*Xt.shape[2]*Xt.shape[3]\nX_tr=Xt.reshape(-1,3072).astype('float32')\nX_ts=Xts.reshape(-1,3072).astype('float32')\n#feature scaling\nX_tr= X_tr / 255\nX_ts = X_ts / 255\n#one hot encoding\nfrom keras.utils import np_utils\nYtr=Yt.reshape(-1,50000)\nYt=np_utils.to_categorical(Ytr)\nYts=Yts.reshape(-1,10000)\nYts=np_utils.to_categorical(Yts)\nnum_class=Yts.shape[1]\n\n\ndef base_model():\n    model=Sequential()\n    #build layers Dense(10, init=\"normal\", activation=\"relu\"\n    model.add(Dense(num_pix,input_dim=num_pix,activation='relu'))#input layer\n    model.add(Dense(num_class,activation='softmax'))#output layer\n    #compile model\n    model.compile(loss='squared_hinge',optimizer='adam',metrics=['accuracy'])\n    return model\n    #build the model\nmodel=base_model()\n#Fit model\nmodel.fit(X_tr,Yt,validation_data=(X_ts,Yts),epochs=10,batch_size=200,verbose=2)\n#Final assesment\nscore=model.evaluate(X_ts,Yts,verbose=0)\nprint(\"Baseline Error: %.2f%%\" % (100-score[1]*100))\n\n  Results :\n\n Train on 50000 samples, validate on 10000 samples\n    Epoch 1/10\n    134s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 2/10\n    97s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 3/10\n    99s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 4/10\n    96s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 5/10\n    96s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 6/10\n    96s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 7/10\n    96s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 8/10\n    95s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 9/10\n    95s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 10/10\n    95s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Baseline Error: 90.00%\n</code></pre>\n\n<p>Any help will be appreciated.can my model be overfitted?</p>\n <machine-learning><neural-network><keras><image-classification><overfitting><p>CIFAR10 has 10 class label. So by random guessing, you should achieve an accuracy of 10%. And this is what you are getting. This means your algorithm is not learning at all. The most common problem causes this is your learning rate. Reduce your learning rate by replacing your line,</p>\n\n<pre><code>model.fit(X_tr,Yt,validation_data=(X_ts,Yts),epochs=10,batch_size=200,verbose=2)\n</code></pre>\n\n<p>with </p>\n\n<pre><code>optimizer = keras.optimizers.Adam(lr=1e-4)\nmodel.compile(loss='squared_hinge',optimizer=optimizer,metrics=['accuracy'])\n</code></pre>\n\n<p>I just did a test run, it is learning slowly. </p>\n",
                "codes": [
                    [
                        "model.fit(X_tr,Yt,validation_data=(X_ts,Yts),epochs=10,batch_size=200,verbose=2)\n",
                        "optimizer = keras.optimizers.Adam(lr=1e-4)\nmodel.compile(loss='squared_hinge',optimizer=optimizer,metrics=['accuracy'])\n"
                    ]
                ],
                "question_id:": "24474",
                "question_votes:": "2",
                "question_text:": "<p>I  trained Muti layer perceptrons using keras to classify cifar-10 dataset the results I got shows that there is something wrong in the code ,because all the epoch are identical here is the code :\nIn this I flatten the data from 32x32x3 to 3072 array.</p>\n\n<pre><code>   #nn layers \nimport numpy\nfrom keras.datasets import cifar10\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom matplotlib import pyplot\nfrom scipy.misc import toimage\n\n#load data\n(Xt,Yt),(Xts,Yts)=cifar10.load_data()\n\nnum_pix=Xt.shape[1]*Xt.shape[2]*Xt.shape[3]\nX_tr=Xt.reshape(-1,3072).astype('float32')\nX_ts=Xts.reshape(-1,3072).astype('float32')\n#feature scaling\nX_tr= X_tr / 255\nX_ts = X_ts / 255\n#one hot encoding\nfrom keras.utils import np_utils\nYtr=Yt.reshape(-1,50000)\nYt=np_utils.to_categorical(Ytr)\nYts=Yts.reshape(-1,10000)\nYts=np_utils.to_categorical(Yts)\nnum_class=Yts.shape[1]\n\n\ndef base_model():\n    model=Sequential()\n    #build layers Dense(10, init=\"normal\", activation=\"relu\"\n    model.add(Dense(num_pix,input_dim=num_pix,activation='relu'))#input layer\n    model.add(Dense(num_class,activation='softmax'))#output layer\n    #compile model\n    model.compile(loss='squared_hinge',optimizer='adam',metrics=['accuracy'])\n    return model\n    #build the model\nmodel=base_model()\n#Fit model\nmodel.fit(X_tr,Yt,validation_data=(X_ts,Yts),epochs=10,batch_size=200,verbose=2)\n#Final assesment\nscore=model.evaluate(X_ts,Yts,verbose=0)\nprint(\"Baseline Error: %.2f%%\" % (100-score[1]*100))\n\n  Results :\n\n Train on 50000 samples, validate on 10000 samples\n    Epoch 1/10\n    134s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 2/10\n    97s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 3/10\n    99s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 4/10\n    96s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 5/10\n    96s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 6/10\n    96s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 7/10\n    96s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 8/10\n    95s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 9/10\n    95s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Epoch 10/10\n    95s - loss: 0.9900 - acc: 0.1000 - val_loss: 0.9900 - val_acc: 0.1000\n    Baseline Error: 90.00%\n</code></pre>\n\n<p>Any help will be appreciated.can my model be overfitted?</p>\n",
                "tags": "<machine-learning><neural-network><keras><image-classification><overfitting>",
                "answers": [
                    [
                        "24547",
                        "2",
                        "24474",
                        "",
                        "",
                        "<p>CIFAR10 has 10 class label. So by random guessing, you should achieve an accuracy of 10%. And this is what you are getting. This means your algorithm is not learning at all. The most common problem causes this is your learning rate. Reduce your learning rate by replacing your line,</p>\n\n<pre><code>model.fit(X_tr,Yt,validation_data=(X_ts,Yts),epochs=10,batch_size=200,verbose=2)\n</code></pre>\n\n<p>with </p>\n\n<pre><code>optimizer = keras.optimizers.Adam(lr=1e-4)\nmodel.compile(loss='squared_hinge',optimizer=optimizer,metrics=['accuracy'])\n</code></pre>\n\n<p>I just did a test run, it is learning slowly. </p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7042",
            "_score": 7.8053265,
            "_source": {
                "title": "Keras LSTM: use weights from Keras model to replicate predictions using numpy",
                "content": "Keras LSTM: use weights from Keras model to replicate predictions using numpy <p>I'm trying to understand what's going on under the hood in Keras' LSTM using the approach taken by <a href=\"https://github.com/greydanus/mr_london/blob/master/app/model/textgen.py\" rel=\"nofollow noreferrer\">https://github.com/greydanus/mr_london/blob/master/app/model/textgen.py</a>.   </p>\n\n<p>I have a sequential model with two layers of LSTM followed by a dense layer and the output layer. I can access weights for each layer from Keras model and am trying to use those weights to replicate the same model prediction using numpy. However, whenever I set \"units\" value in the code greater than 1, I get very different output compared to Keras' \"model.predict()\". Also, the shape of outputs from Keras' \"model.summary()\" is different than what I am getting. My code is as below.  </p>\n\n<h1>Import libraries</h1>\n\n<pre><code>from keras.models import Model   \nfrom keras.layers import Input, Dense, LSTM  \nimport numpy as np  \nimport keras.backend as K  \nfrom __future__ import division  \nfrom numpy import array  \nfrom keras.models import Sequential  \nnp.random.seed(42)  \n</code></pre>\n\n<h1>Bunch of basic functions</h1>\n\n<pre><code>def tanh(x):\n    return np.tanh(x)  \n\ndef sigmoid(x):  \n    return 1 / (1 + np.exp(-x))\n\ndef hard_sigmoid(x):\n    slope = 0.2\n    shift = 0.5\n    x = (x * slope) + shift\n    x = np.clip(x, 0, 1)\n    return x\n\ndef softmax_2D(X):\n    maxes = np.amax(w, axis=1)\n    maxes = maxes.reshape(maxes.shape[0], 1)\n    e = np.exp(w - maxes)\n    dist = e / np.sum(e, axis=1, keepdims=True)\n    dist = np.float64(dist)\n    return dist\n</code></pre>\n\n<h1>Helper function for LSTM layer</h1>\n\n<pre><code>def nsteps(xi, xf, xo, xc, hprev, Cprev, U_i, U_f, U_o, U_c):\n    nsteps = xi.shape[0] # should be n long\n    output = np.zeros_like(xi) # [n,1,m]\n    memory = np.zeros_like(xi) # [n,1,m]\n\n    for t in range(nsteps):\n        xi_t = xi[:,t,:] ; xf_t = xf[:,t,:] ; xc_t = xc[:,t,:] ; xo_t = xo[:,t,:] # [1,m] for all\n\n        i_t = hard_sigmoid(xi_t + np.dot(hprev, U_i)) #[1,m] + [m]*[m,m] -&gt; [1,m]\n        f_t = hard_sigmoid(xf_t + np.dot(hprev, U_f)) #[1,m] + [m]*[m,m] -&gt; [1,m]\n        o_t = hard_sigmoid(xo_t + np.dot(hprev, U_o)) #[1,m] + [m]*[m,m] -&gt; [1,m]\n        c_t = f_t*Cprev + i_t * np.tanh(xc_t + np.dot(hprev, U_c)) #[1,m]*[m] + [1,m] * [1,m] -&gt; [1,m]\n        h_t = o_t * np.tanh(c_t) #[1,m]*[1,m] (elementwise)\n\n        output[t,:,:] = h_t ; memory[t,:,:] = c_t\n        hprev = h_t # [1,m]\n        Cprev = c_t # [1,m]\n    return [output, memory]\n</code></pre>\n\n<h1>Main LSTM layer</h1>\n\n<pre><code>def lstm_layer(X, units, i=0, seq=False):\n    kernel_weights = model.layers[i].get_weights()[0]\n    recurrent_kernel_weights = model.layers[i].get_weights()[1]\n    bias = model.layers[i].get_weights()[2]\n\n    #Get the weights\n\n    # kernels\n    kernel_i = kernel_weights[:, :units]\n    kernel_f = kernel_weights[:, units: units * 2]\n    kernel_c = kernel_weights[:, units * 2: units * 3]\n    kernel_o = kernel_weights[:, units * 3:]\n\n    # recurrent kernel\n    h_i = recurrent_kernel_weights[:, :units]\n    h_f = recurrent_kernel_weights[:, units: units * 2]\n    h_c = recurrent_kernel_weights[:, units * 2: units* 3]\n    h_o = recurrent_kernel_weights[:, units * 3:]\n\n    # bias\n    bias_i = bias[:units]\n    bias_f = bias[units: units * 2]\n    bias_c = bias[units * 2: units * 3]\n    bias_o = bias[units * 3:]\n\n    x_i = np.dot(X,kernel_i) + bias_i\n    x_f = np.dot(X,kernel_f) + bias_f\n    x_c = np.dot(X,kernel_c) + bias_c\n    x_o = np.dot(X,kernel_o) + bias_o\n\n    # Set cell &amp; memory states to zeros\n    h_tm1 = np.zeros((1, len(bias_i)))\n    c_tm1 = np.zeros((1, len(bias_i)))\n\n    h_tm1_i = h_tm1\n    h_tm1_f = h_tm1\n    h_tm1_c = h_tm1\n    h_tm1_o = h_tm1\n\n    [output, memory] = nsteps(x_i, x_f, x_o, x_c, h_tm1, c_tm1, h_i, h_f, h_o, h_c)\n\n    if seq:\n        return output\n    else:\n         output = output[:,timesteps-1,:]\n         output = output.reshape(1,units)\n    return output\n</code></pre>\n\n<h1>Now a dense layer</h1>\n\n<pre><code>def dense(X, i=0):\n    W = model.layers[i].get_weights()[0]\n    b = model.layers[i].get_weights()[1]\n    output = np.dot(X, W) + b\n    return output\n</code></pre>\n\n<h1>Create the model now</h1>\n\n<pre><code>data_dim = 28  \ntimesteps = 32  \nnum_classes = 2  \nunits = 5  \n</code></pre>\n\n<h1>Expected input data shape: (batch_size, timesteps, data_dim)</h1>\n\n<pre><code>model = Sequential()  \nmodel.add(LSTM(units, return_sequences=True, input_shape=(timesteps, \ndata_dim)))  \nmodel.add(LSTM(units))  \nmodel.add(Dense(2, activation='softmax'))  \nmodel.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])  \n</code></pre>\n\n<h1>Generate dummy training data</h1>\n\n<pre><code>x_train = np.random.random((1, timesteps, data_dim))  \nx_train = np.where(x_train &gt; 0.5, 1.0, 0.0)  \ny_train = np.random.random((1, num_classes))  \ny_train = np.where(y_train &gt; 0.5, 1.0, 0.0)  \n</code></pre>\n\n<h1>Generate dummy validation data</h1>\n\n<pre><code>x_val = np.random.random((1, timesteps, data_dim))  \nx_val = np.where(x_val &gt; 0.5, 1.0, 0.0)  \ny_val = np.random.random((1, num_classes))  \ny_val = np.where(y_val &gt; 0.5, 1.0, 0.0)  \n</code></pre>\n\n<h1>Fit the model</h1>\n\n<pre><code>model.fit(x_train, y_train,batch_size=1, epochs=1,validation_data=(x_val, y_val))  \n</code></pre>\n\n<h1>Print model summary</h1>\n\n<pre><code>print(model.summary())  \n</code></pre>\n\n<h1>Numpy prediction model</h1>\n\n<pre><code>def predict_i(X, units):\n    print ('Shape of input to LSTM layer 1:', X.shape)\n    h = lstm_layer(X, units=units, i=0, seq=True) ; X = h\n    print('Shape of output from LSTM layer 1:', X.shape)\n    h = lstm_layer(X, units = units, i = 1, seq=False) ; X = h\n    print ('Shape of output from LSTM layer 2:', X.shape)\n    h = dense(X, i = 2) ; X = h\n    print ('Shape of output from dense layer:', X.shape)\n    h = softmax_2D(X) ; X = h[0] \n    return h\n</code></pre>\n\n<h1>Get prediction from numpy model</h1>\n\n<pre><code>predict_i(x_train,units)    \n</code></pre>\n\n<h1>Get prediction from Keras model</h1>\n\n<pre><code>model.predict(x_train)  \n</code></pre>\n\n<p>Prediction from Keras' model does not match with numpy model. Any help/feedback is much appreciated. </p>\n <keras><rnn><lstm><numpy>",
                "codes": [],
                "question_id:": "26715",
                "question_votes:": "2",
                "question_text:": "<p>I'm trying to understand what's going on under the hood in Keras' LSTM using the approach taken by <a href=\"https://github.com/greydanus/mr_london/blob/master/app/model/textgen.py\" rel=\"nofollow noreferrer\">https://github.com/greydanus/mr_london/blob/master/app/model/textgen.py</a>.   </p>\n\n<p>I have a sequential model with two layers of LSTM followed by a dense layer and the output layer. I can access weights for each layer from Keras model and am trying to use those weights to replicate the same model prediction using numpy. However, whenever I set \"units\" value in the code greater than 1, I get very different output compared to Keras' \"model.predict()\". Also, the shape of outputs from Keras' \"model.summary()\" is different than what I am getting. My code is as below.  </p>\n\n<h1>Import libraries</h1>\n\n<pre><code>from keras.models import Model   \nfrom keras.layers import Input, Dense, LSTM  \nimport numpy as np  \nimport keras.backend as K  \nfrom __future__ import division  \nfrom numpy import array  \nfrom keras.models import Sequential  \nnp.random.seed(42)  \n</code></pre>\n\n<h1>Bunch of basic functions</h1>\n\n<pre><code>def tanh(x):\n    return np.tanh(x)  \n\ndef sigmoid(x):  \n    return 1 / (1 + np.exp(-x))\n\ndef hard_sigmoid(x):\n    slope = 0.2\n    shift = 0.5\n    x = (x * slope) + shift\n    x = np.clip(x, 0, 1)\n    return x\n\ndef softmax_2D(X):\n    maxes = np.amax(w, axis=1)\n    maxes = maxes.reshape(maxes.shape[0], 1)\n    e = np.exp(w - maxes)\n    dist = e / np.sum(e, axis=1, keepdims=True)\n    dist = np.float64(dist)\n    return dist\n</code></pre>\n\n<h1>Helper function for LSTM layer</h1>\n\n<pre><code>def nsteps(xi, xf, xo, xc, hprev, Cprev, U_i, U_f, U_o, U_c):\n    nsteps = xi.shape[0] # should be n long\n    output = np.zeros_like(xi) # [n,1,m]\n    memory = np.zeros_like(xi) # [n,1,m]\n\n    for t in range(nsteps):\n        xi_t = xi[:,t,:] ; xf_t = xf[:,t,:] ; xc_t = xc[:,t,:] ; xo_t = xo[:,t,:] # [1,m] for all\n\n        i_t = hard_sigmoid(xi_t + np.dot(hprev, U_i)) #[1,m] + [m]*[m,m] -&gt; [1,m]\n        f_t = hard_sigmoid(xf_t + np.dot(hprev, U_f)) #[1,m] + [m]*[m,m] -&gt; [1,m]\n        o_t = hard_sigmoid(xo_t + np.dot(hprev, U_o)) #[1,m] + [m]*[m,m] -&gt; [1,m]\n        c_t = f_t*Cprev + i_t * np.tanh(xc_t + np.dot(hprev, U_c)) #[1,m]*[m] + [1,m] * [1,m] -&gt; [1,m]\n        h_t = o_t * np.tanh(c_t) #[1,m]*[1,m] (elementwise)\n\n        output[t,:,:] = h_t ; memory[t,:,:] = c_t\n        hprev = h_t # [1,m]\n        Cprev = c_t # [1,m]\n    return [output, memory]\n</code></pre>\n\n<h1>Main LSTM layer</h1>\n\n<pre><code>def lstm_layer(X, units, i=0, seq=False):\n    kernel_weights = model.layers[i].get_weights()[0]\n    recurrent_kernel_weights = model.layers[i].get_weights()[1]\n    bias = model.layers[i].get_weights()[2]\n\n    #Get the weights\n\n    # kernels\n    kernel_i = kernel_weights[:, :units]\n    kernel_f = kernel_weights[:, units: units * 2]\n    kernel_c = kernel_weights[:, units * 2: units * 3]\n    kernel_o = kernel_weights[:, units * 3:]\n\n    # recurrent kernel\n    h_i = recurrent_kernel_weights[:, :units]\n    h_f = recurrent_kernel_weights[:, units: units * 2]\n    h_c = recurrent_kernel_weights[:, units * 2: units* 3]\n    h_o = recurrent_kernel_weights[:, units * 3:]\n\n    # bias\n    bias_i = bias[:units]\n    bias_f = bias[units: units * 2]\n    bias_c = bias[units * 2: units * 3]\n    bias_o = bias[units * 3:]\n\n    x_i = np.dot(X,kernel_i) + bias_i\n    x_f = np.dot(X,kernel_f) + bias_f\n    x_c = np.dot(X,kernel_c) + bias_c\n    x_o = np.dot(X,kernel_o) + bias_o\n\n    # Set cell &amp; memory states to zeros\n    h_tm1 = np.zeros((1, len(bias_i)))\n    c_tm1 = np.zeros((1, len(bias_i)))\n\n    h_tm1_i = h_tm1\n    h_tm1_f = h_tm1\n    h_tm1_c = h_tm1\n    h_tm1_o = h_tm1\n\n    [output, memory] = nsteps(x_i, x_f, x_o, x_c, h_tm1, c_tm1, h_i, h_f, h_o, h_c)\n\n    if seq:\n        return output\n    else:\n         output = output[:,timesteps-1,:]\n         output = output.reshape(1,units)\n    return output\n</code></pre>\n\n<h1>Now a dense layer</h1>\n\n<pre><code>def dense(X, i=0):\n    W = model.layers[i].get_weights()[0]\n    b = model.layers[i].get_weights()[1]\n    output = np.dot(X, W) + b\n    return output\n</code></pre>\n\n<h1>Create the model now</h1>\n\n<pre><code>data_dim = 28  \ntimesteps = 32  \nnum_classes = 2  \nunits = 5  \n</code></pre>\n\n<h1>Expected input data shape: (batch_size, timesteps, data_dim)</h1>\n\n<pre><code>model = Sequential()  \nmodel.add(LSTM(units, return_sequences=True, input_shape=(timesteps, \ndata_dim)))  \nmodel.add(LSTM(units))  \nmodel.add(Dense(2, activation='softmax'))  \nmodel.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])  \n</code></pre>\n\n<h1>Generate dummy training data</h1>\n\n<pre><code>x_train = np.random.random((1, timesteps, data_dim))  \nx_train = np.where(x_train &gt; 0.5, 1.0, 0.0)  \ny_train = np.random.random((1, num_classes))  \ny_train = np.where(y_train &gt; 0.5, 1.0, 0.0)  \n</code></pre>\n\n<h1>Generate dummy validation data</h1>\n\n<pre><code>x_val = np.random.random((1, timesteps, data_dim))  \nx_val = np.where(x_val &gt; 0.5, 1.0, 0.0)  \ny_val = np.random.random((1, num_classes))  \ny_val = np.where(y_val &gt; 0.5, 1.0, 0.0)  \n</code></pre>\n\n<h1>Fit the model</h1>\n\n<pre><code>model.fit(x_train, y_train,batch_size=1, epochs=1,validation_data=(x_val, y_val))  \n</code></pre>\n\n<h1>Print model summary</h1>\n\n<pre><code>print(model.summary())  \n</code></pre>\n\n<h1>Numpy prediction model</h1>\n\n<pre><code>def predict_i(X, units):\n    print ('Shape of input to LSTM layer 1:', X.shape)\n    h = lstm_layer(X, units=units, i=0, seq=True) ; X = h\n    print('Shape of output from LSTM layer 1:', X.shape)\n    h = lstm_layer(X, units = units, i = 1, seq=False) ; X = h\n    print ('Shape of output from LSTM layer 2:', X.shape)\n    h = dense(X, i = 2) ; X = h\n    print ('Shape of output from dense layer:', X.shape)\n    h = softmax_2D(X) ; X = h[0] \n    return h\n</code></pre>\n\n<h1>Get prediction from numpy model</h1>\n\n<pre><code>predict_i(x_train,units)    \n</code></pre>\n\n<h1>Get prediction from Keras model</h1>\n\n<pre><code>model.predict(x_train)  \n</code></pre>\n\n<p>Prediction from Keras' model does not match with numpy model. Any help/feedback is much appreciated. </p>\n",
                "tags": "<keras><rnn><lstm><numpy>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6547",
            "_score": 7.7837143,
            "_source": {
                "title": "Calculate similarity on boolean data",
                "content": "Calculate similarity on boolean data <p>I am trying to implement simple recommender system and I am trying to understand different approaches to achieve my goal.</p>\n\n<p>My dataset consists of users and items that they bought. I have information about what items user bought and descriptions of these items in form of titles.</p>\n\n<p>At first I though I could use user based collaborative filtering approach but I am stuck at this. I am not quite sure how to calculate similarity for boolean data.</p>\n\n<p>When I have data like this for example</p>\n\n<pre><code>   1  2  3  4\nA  0  1  0  1\nB  0  1  0  1\nC  1  0  1  1\nD  0  1  0  0\nE  0  0  1  1\n</code></pre>\n\n<p>And I want to recommend items for user <strong>E</strong>, so how should I calculate similarity in this case? I chosen for example cosine similarity from scikit learn module in python. But I am not quite sure what should be considered as input. From what I read it should be only vectors of items that two users for which similarity is calculated have in common.</p>\n\n<p>So for example if I wanted to compute similarity between user <strong>E</strong> and <strong>C</strong> what should be my input? Because if I input only values that they have in common it does not make sense right? Beacuse input will be [1, 1] and [1, 1] and for that similarity is 1.</p>\n\n<p>Then I tried to input the whole vector like this:</p>\n\n<pre><code>from sklearn.metrics.pairwise import cosine_similarity\nfrom numpy import array, reshape\n\nc = array([1, 0, 1, 1])\ne = array([0, 0, 1, 1])\n\nresult = cosine_similarity(c.reshape(1, -1), e.reshape(1, -1))\n\n&gt;&gt;&gt; result is 0.81649658\n</code></pre>\n\n<p>And this approach I think makes more sense but I am not sure if it is acceptable based on what I learned about this type of recommendation.</p>\n <recommender-system><similarity><p>You should look at the <a href=\"https://en.wikipedia.org/wiki/Jaccard_index\" rel=\"nofollow noreferrer\">Jaccard Index</a>, is the de facto similarity between set of items, where the sets are represented using a boolean vector. In this boolean vector each coordinate represents an item, 1 means the item is present, 0 otherwise. For example: for an universe of items banana, orange and apple. the set banana, orange will be represented by (1, 1, 0). The Jaccard Index is the intersection of the sets over union the sets so for a set (1, 1) it's value is 1. </p>\n\n<p>Cosine similarity is for real-valued vectors, but whether cosine similarity is better than the Jaccard index and vice versa depends on the application. You should do a test on your data and verify which is better, for a discussion see this <a href=\"https://datascience.stackexchange.com/questions/5121/applications-and-differences-for-jaccard-similarity-and-cosine-similarity\">question</a></p>\n",
                "codes": [
                    []
                ],
                "question_id:": "25377",
                "question_votes:": "1",
                "question_text:": "<p>I am trying to implement simple recommender system and I am trying to understand different approaches to achieve my goal.</p>\n\n<p>My dataset consists of users and items that they bought. I have information about what items user bought and descriptions of these items in form of titles.</p>\n\n<p>At first I though I could use user based collaborative filtering approach but I am stuck at this. I am not quite sure how to calculate similarity for boolean data.</p>\n\n<p>When I have data like this for example</p>\n\n<pre><code>   1  2  3  4\nA  0  1  0  1\nB  0  1  0  1\nC  1  0  1  1\nD  0  1  0  0\nE  0  0  1  1\n</code></pre>\n\n<p>And I want to recommend items for user <strong>E</strong>, so how should I calculate similarity in this case? I chosen for example cosine similarity from scikit learn module in python. But I am not quite sure what should be considered as input. From what I read it should be only vectors of items that two users for which similarity is calculated have in common.</p>\n\n<p>So for example if I wanted to compute similarity between user <strong>E</strong> and <strong>C</strong> what should be my input? Because if I input only values that they have in common it does not make sense right? Beacuse input will be [1, 1] and [1, 1] and for that similarity is 1.</p>\n\n<p>Then I tried to input the whole vector like this:</p>\n\n<pre><code>from sklearn.metrics.pairwise import cosine_similarity\nfrom numpy import array, reshape\n\nc = array([1, 0, 1, 1])\ne = array([0, 0, 1, 1])\n\nresult = cosine_similarity(c.reshape(1, -1), e.reshape(1, -1))\n\n&gt;&gt;&gt; result is 0.81649658\n</code></pre>\n\n<p>And this approach I think makes more sense but I am not sure if it is acceptable based on what I learned about this type of recommendation.</p>\n",
                "tags": "<recommender-system><similarity>",
                "answers": [
                    [
                        "25378",
                        "2",
                        "25377",
                        "",
                        "",
                        "<p>You should look at the <a href=\"https://en.wikipedia.org/wiki/Jaccard_index\" rel=\"nofollow noreferrer\">Jaccard Index</a>, is the de facto similarity between set of items, where the sets are represented using a boolean vector. In this boolean vector each coordinate represents an item, 1 means the item is present, 0 otherwise. For example: for an universe of items banana, orange and apple. the set banana, orange will be represented by (1, 1, 0). The Jaccard Index is the intersection of the sets over union the sets so for a set (1, 1) it's value is 1. </p>\n\n<p>Cosine similarity is for real-valued vectors, but whether cosine similarity is better than the Jaccard index and vice versa depends on the application. You should do a test on your data and verify which is better, for a discussion see this <a href=\"https://datascience.stackexchange.com/questions/5121/applications-and-differences-for-jaccard-similarity-and-cosine-similarity\">question</a></p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4980",
            "_score": 7.7763777,
            "_source": {
                "title": "Implementation of Gaussian Mixture Model for clustering when dealing with multidimensional hyperspectral data in python",
                "content": "Implementation of Gaussian Mixture Model for clustering when dealing with multidimensional hyperspectral data in python <p>I have a python numpy array of size (800,800,4) which is my hyperspectral camera data.</p>\n\n<p>When I try standard GMM methods from scikit-learn I get an error saying that the expected dimension of the data should be less than or equal to 2.</p>\n\n<p>Current method:</p>\n\n<p>gmm=GaussianMixture(covariance_type=\"full\")</p>\n\n<p>gmm=gmm.fit(data)</p>\n\n<p>Are there any python packages or functions available to process higher dimensional data using gmm?</p>\n <python><clustering><image-classification><image-recognition><p>If I understand your type of data correctly, what you have is essentially an image with $800\\times800 =640000$ pixels and each pixel has a vector of 4 values.</p>\n\n<p>If this stands, I suppose you could then transform your data to a $640000\\times4$ matrix, so as to conform with scikit-learn's data representation schema of inputting matrices of shape ($\\#samples\\times\\#features$) and then you could use the GMM class implemented by the package.</p>\n\n<p>And you could transform the data back if needed.</p>\n\n<p>P.S.: On a second thought, I don't know if the spatial distribution of pixels plays a role on the generation of the GMM components. Maybe try it out and let us know?</p>\n\n<p>Ok, after you have trained your model you can ask for it to predict the mixture model from which each pixel in your dataset has been generated.</p>\n\n<p>That is if you run again:\n$clusters=gmm.predict(newdata)$ you will get an array with values $0-2$, denoting the cluster that each pixel belongs to. You can, then map these values in the image at hand, applying a mask of different color for each pixel in order to see if your model correctly identifies the three classes.</p>\n\n<p>Here is an example of what I mean:</p>\n\n<pre><code>from scipy.misc import imread, imshow\nfrom sklearn.datasets import load_sample_image\n\nX = load_sample_image('china.jpg')\nold_shape = X.shape\nX = X.reshape(-1,3)\ngmm = mixture.GMM(covariance_type='full', n_components=5)\ngmm.fit(X)\nclusters = gmm.predict(X)\nclusters = clusters.reshape(old_shape[0], old_shape[1])\nimshow(clusters)\n</code></pre>\n",
                "codes": [
                    [
                        "from scipy.misc import imread, imshow\nfrom sklearn.datasets import load_sample_image\n\nX = load_sample_image('china.jpg')\nold_shape = X.shape\nX = X.reshape(-1,3)\ngmm = mixture.GMM(covariance_type='full', n_components=5)\ngmm.fit(X)\nclusters = gmm.predict(X)\nclusters = clusters.reshape(old_shape[0], old_shape[1])\nimshow(clusters)\n"
                    ]
                ],
                "question_id:": "19405",
                "question_votes:": "2",
                "question_text:": "<p>I have a python numpy array of size (800,800,4) which is my hyperspectral camera data.</p>\n\n<p>When I try standard GMM methods from scikit-learn I get an error saying that the expected dimension of the data should be less than or equal to 2.</p>\n\n<p>Current method:</p>\n\n<p>gmm=GaussianMixture(covariance_type=\"full\")</p>\n\n<p>gmm=gmm.fit(data)</p>\n\n<p>Are there any python packages or functions available to process higher dimensional data using gmm?</p>\n",
                "tags": "<python><clustering><image-classification><image-recognition>",
                "answers": [
                    [
                        "19426",
                        "2",
                        "19405",
                        "",
                        "",
                        "<p>If I understand your type of data correctly, what you have is essentially an image with $800\\times800 =640000$ pixels and each pixel has a vector of 4 values.</p>\n\n<p>If this stands, I suppose you could then transform your data to a $640000\\times4$ matrix, so as to conform with scikit-learn's data representation schema of inputting matrices of shape ($\\#samples\\times\\#features$) and then you could use the GMM class implemented by the package.</p>\n\n<p>And you could transform the data back if needed.</p>\n\n<p>P.S.: On a second thought, I don't know if the spatial distribution of pixels plays a role on the generation of the GMM components. Maybe try it out and let us know?</p>\n\n<p>Ok, after you have trained your model you can ask for it to predict the mixture model from which each pixel in your dataset has been generated.</p>\n\n<p>That is if you run again:\n$clusters=gmm.predict(newdata)$ you will get an array with values $0-2$, denoting the cluster that each pixel belongs to. You can, then map these values in the image at hand, applying a mask of different color for each pixel in order to see if your model correctly identifies the three classes.</p>\n\n<p>Here is an example of what I mean:</p>\n\n<pre><code>from scipy.misc import imread, imshow\nfrom sklearn.datasets import load_sample_image\n\nX = load_sample_image('china.jpg')\nold_shape = X.shape\nX = X.reshape(-1,3)\ngmm = mixture.GMM(covariance_type='full', n_components=5)\ngmm.fit(X)\nclusters = gmm.predict(X)\nclusters = clusters.reshape(old_shape[0], old_shape[1])\nimshow(clusters)\n</code></pre>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14239",
            "_score": 7.723565,
            "_source": {
                "title": "CNN reshape problem",
                "content": "CNN reshape problem <p>I am new to CNN and i want to use it for Modulation classification\nI found this <a href=\"https://github.com/RobinChenRichmond/RF-Signal-Model/blob/master/2x128_CNN.py\" rel=\"nofollow noreferrer\">code</a> and I want to replicate it as it is exept that i only used the digital modulations and some SNR (signal-Noise Ratio) levels</p>\n\n<pre><code>import os\nimport theano as th\nimport theano.tensor as T\nos.environ[\"KERAS_BACKEND\"] = \"theano\"\n#os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\nos.environ[\"THEANO_FLAGS\"]  = \"device=gpu%d\"%(1)\nimport numpy as np\nimport keras.models as models\nfrom keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten\nfrom keras.layers.convolutional import Convolution2D, ZeroPadding2D, Conv2D\nimport pickle, keras\n\nfull_dataset = pickle.load(open(\"RML2016.10a.pkl\",'rb'),encoding='latin1')\nsnrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], full_dataset.keys())))), [1,0])\n\ndigital_mods    = ['8PSK', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16', 'QAM64', 'QPSK']\nsnr_levels      = [-16, -12, -8, -4, 0, 4, 8, 12, 16]\n\nX = []\nlbl = []\nfor mod in digital_mods:\n    for snr in snr_levels:\n        X.append(full_dataset[(mod,snr)])\n        for i in range(full_dataset[(mod,snr)].shape[0]):  lbl.append((mod,snr))\nX = np.vstack(X)\n\nnp.random.seed(2016)\nn_examples = X.shape[0]\nn_train = int(n_examples * 0.5)\ntrain_idx = np.random.choice(range(0,n_examples), size=n_train, replace=False)\ntest_idx = list(set(range(0,n_examples))-set(train_idx))\nX_train = X[train_idx]\nX_test =  X[test_idx]\ndef to_onehot(yy):\n    yy1 = np.zeros([len(yy), max(yy)+1])\n    yy1[np.arange(len(yy)),yy] = 1\n    return yy1\nY_train = to_onehot(list(map(lambda x: mods.index(lbl[x][0]), train_idx)))\nY_test = to_onehot(list(map(lambda x: mods.index(lbl[x][0]), test_idx)))\n\nin_shp = list(X_train.shape[1:])\nclasses = digital_mods\n\nnb_epoch = 100     # number of epochs to train on\nbatch_size = 1024\ndr = 0.5\nmodel = models.Sequential()\nmodel.add(Reshape(in_shp+[1], input_shape=in_shp))\nmodel.add(ZeroPadding2D((0,2)))\nmodel.add(Conv2D(64, (1,4), activation=\"relu\"))\nmodel.add(Dropout(dr))\nmodel.add(ZeroPadding2D((0,2)))\nmodel.add(Conv2D(64, (2,4), activation=\"relu\"))\nmodel.add(Dropout(dr))\nmodel.add(Conv2D(128, (1,8), activation=\"relu\"))\nmodel.add(Dropout(dr))\nmodel.add(Conv2D(128, (1,8), activation=\"relu\"))\nmodel.add(Dropout(dr))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(dr))\nmodel.add(Dense(len(classes), activation='softmax'))\nmodel.add(Reshape([len(classes)]))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\n\n\nfilepath = 'weight_4layers.wts.h5'\nhistory = model.fit(X_train,\n    Y_train,\n    batch_size=batch_size,\n    nb_epoch=nb_epoch,\n    verbose=1,\n    validation_data=(X_test, Y_test),\n    callbacks = [\n        keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),\n        keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n]) \n</code></pre>\n\n<p>please note the following:</p>\n\n<p>I have 8 modulation types and 9 SNR levels = 72 pairs [mod,snr]\neach paire is composed of 1000 array of [2, 128] (complex values of radio signal)</p>\n\n<p><strong>X train</strong> has the shape (36000, 2, 128)\n <strong>in_shape</strong> has the shape (2, 128)</p>\n\n<p>So when i run my program I get the following error:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"/home/nechi/PycharmProjects/AMC/cnn.py\", line 88, in &lt;module&gt;\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 952, in fit\n    batch_size=batch_size)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 789, in _standardize_user_data\n    exception_prefix='target')\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\", line 138, in standardize_input_data\n    str(data_shape))\nValueError: Error when checking target: expected reshape_2 to have shape (8,) but got array with shape (10,)\n</code></pre>\n <python><cnn>",
                "codes": [],
                "question_id:": "48037",
                "question_votes:": "1",
                "question_text:": "<p>I am new to CNN and i want to use it for Modulation classification\nI found this <a href=\"https://github.com/RobinChenRichmond/RF-Signal-Model/blob/master/2x128_CNN.py\" rel=\"nofollow noreferrer\">code</a> and I want to replicate it as it is exept that i only used the digital modulations and some SNR (signal-Noise Ratio) levels</p>\n\n<pre><code>import os\nimport theano as th\nimport theano.tensor as T\nos.environ[\"KERAS_BACKEND\"] = \"theano\"\n#os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\nos.environ[\"THEANO_FLAGS\"]  = \"device=gpu%d\"%(1)\nimport numpy as np\nimport keras.models as models\nfrom keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten\nfrom keras.layers.convolutional import Convolution2D, ZeroPadding2D, Conv2D\nimport pickle, keras\n\nfull_dataset = pickle.load(open(\"RML2016.10a.pkl\",'rb'),encoding='latin1')\nsnrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], full_dataset.keys())))), [1,0])\n\ndigital_mods    = ['8PSK', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16', 'QAM64', 'QPSK']\nsnr_levels      = [-16, -12, -8, -4, 0, 4, 8, 12, 16]\n\nX = []\nlbl = []\nfor mod in digital_mods:\n    for snr in snr_levels:\n        X.append(full_dataset[(mod,snr)])\n        for i in range(full_dataset[(mod,snr)].shape[0]):  lbl.append((mod,snr))\nX = np.vstack(X)\n\nnp.random.seed(2016)\nn_examples = X.shape[0]\nn_train = int(n_examples * 0.5)\ntrain_idx = np.random.choice(range(0,n_examples), size=n_train, replace=False)\ntest_idx = list(set(range(0,n_examples))-set(train_idx))\nX_train = X[train_idx]\nX_test =  X[test_idx]\ndef to_onehot(yy):\n    yy1 = np.zeros([len(yy), max(yy)+1])\n    yy1[np.arange(len(yy)),yy] = 1\n    return yy1\nY_train = to_onehot(list(map(lambda x: mods.index(lbl[x][0]), train_idx)))\nY_test = to_onehot(list(map(lambda x: mods.index(lbl[x][0]), test_idx)))\n\nin_shp = list(X_train.shape[1:])\nclasses = digital_mods\n\nnb_epoch = 100     # number of epochs to train on\nbatch_size = 1024\ndr = 0.5\nmodel = models.Sequential()\nmodel.add(Reshape(in_shp+[1], input_shape=in_shp))\nmodel.add(ZeroPadding2D((0,2)))\nmodel.add(Conv2D(64, (1,4), activation=\"relu\"))\nmodel.add(Dropout(dr))\nmodel.add(ZeroPadding2D((0,2)))\nmodel.add(Conv2D(64, (2,4), activation=\"relu\"))\nmodel.add(Dropout(dr))\nmodel.add(Conv2D(128, (1,8), activation=\"relu\"))\nmodel.add(Dropout(dr))\nmodel.add(Conv2D(128, (1,8), activation=\"relu\"))\nmodel.add(Dropout(dr))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(dr))\nmodel.add(Dense(len(classes), activation='softmax'))\nmodel.add(Reshape([len(classes)]))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\n\n\nfilepath = 'weight_4layers.wts.h5'\nhistory = model.fit(X_train,\n    Y_train,\n    batch_size=batch_size,\n    nb_epoch=nb_epoch,\n    verbose=1,\n    validation_data=(X_test, Y_test),\n    callbacks = [\n        keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),\n        keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n]) \n</code></pre>\n\n<p>please note the following:</p>\n\n<p>I have 8 modulation types and 9 SNR levels = 72 pairs [mod,snr]\neach paire is composed of 1000 array of [2, 128] (complex values of radio signal)</p>\n\n<p><strong>X train</strong> has the shape (36000, 2, 128)\n <strong>in_shape</strong> has the shape (2, 128)</p>\n\n<p>So when i run my program I get the following error:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"/home/nechi/PycharmProjects/AMC/cnn.py\", line 88, in &lt;module&gt;\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 952, in fit\n    batch_size=batch_size)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 789, in _standardize_user_data\n    exception_prefix='target')\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\", line 138, in standardize_input_data\n    str(data_shape))\nValueError: Error when checking target: expected reshape_2 to have shape (8,) but got array with shape (10,)\n</code></pre>\n",
                "tags": "<python><cnn>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "18316",
            "_score": 7.7038307,
            "_source": {
                "title": "Softmax activation predictions not summing to 1",
                "content": "Softmax activation predictions not summing to 1 <p>I am a beginner with rnns, consider this sample code </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from tensorflow import keras\nimport numpy as np\n\nif __name__ == '__main__':\n    model = keras.Sequential((\n        keras.layers.SimpleRNN(5, activation=\"softmax\", input_shape=(1, 3)),\n    ))\n    X = [\n        [1, 2, 3],\n        [4, 5, 6]\n    ]\n    y = [\n        [1, 0, 0, 0, 0],\n        [0, 1, 0, 0, 0]\n    ]\n    X = np.array(X)\n    X = np.reshape(X, (2, 1, 3))\n    y = np.array(y)\n    # print(X)\n    # print(y)\n    print(model.summary())\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),\n                 loss=\"categorical_crossentropy\")\n    model.fit(X, y, epochs=100)\n    p = model.predict(X)\n    print(p)\n    p = list(np.squeeze(p))\n    print(p)\n    print(np.sum(p,axis=1))\n</code></pre>\n\n<p>I am using a simple rnn with batch size=2, 3 input features and 1 timestep,as the activation is softmax the last line prints [1,1] as the sum of predictions of a softmax is 1.\nBut when when I change the layer from a SimpleRNN to </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>keras.layers.LSTM(5, activation=\"softmax\", input_shape= \n                 (1,3),recurrent_activation=\"softmax\")\n</code></pre>\n\n<p>The sum of predictions is no longer 1, why is that?</p>\n <keras><tensorflow><rnn><softmax>",
                "codes": [],
                "question_id:": "58114",
                "question_votes:": "3",
                "question_text:": "<p>I am a beginner with rnns, consider this sample code </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from tensorflow import keras\nimport numpy as np\n\nif __name__ == '__main__':\n    model = keras.Sequential((\n        keras.layers.SimpleRNN(5, activation=\"softmax\", input_shape=(1, 3)),\n    ))\n    X = [\n        [1, 2, 3],\n        [4, 5, 6]\n    ]\n    y = [\n        [1, 0, 0, 0, 0],\n        [0, 1, 0, 0, 0]\n    ]\n    X = np.array(X)\n    X = np.reshape(X, (2, 1, 3))\n    y = np.array(y)\n    # print(X)\n    # print(y)\n    print(model.summary())\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),\n                 loss=\"categorical_crossentropy\")\n    model.fit(X, y, epochs=100)\n    p = model.predict(X)\n    print(p)\n    p = list(np.squeeze(p))\n    print(p)\n    print(np.sum(p,axis=1))\n</code></pre>\n\n<p>I am using a simple rnn with batch size=2, 3 input features and 1 timestep,as the activation is softmax the last line prints [1,1] as the sum of predictions of a softmax is 1.\nBut when when I change the layer from a SimpleRNN to </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>keras.layers.LSTM(5, activation=\"softmax\", input_shape= \n                 (1,3),recurrent_activation=\"softmax\")\n</code></pre>\n\n<p>The sum of predictions is no longer 1, why is that?</p>\n",
                "tags": "<keras><tensorflow><rnn><softmax>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7254",
            "_score": 7.6336527,
            "_source": {
                "title": "Python : Feature Matching + Homography to find Multiple Objects",
                "content": "Python : Feature Matching + Homography to find Multiple Objects <p>I'm trying to use opencv via python to find multiple objects in a train image and match it with the key points detected from query image.For my case, i'm trying to detect the tennis courts in the image provided below. I I looked at the online tutorials,and only figured that it can only detect 1 object. I thought of inserting a loop in for it to find multiple objects but i failed to do so. Any idea on how to do it ? </p>\n\n<p>*I Used SIFT as ORB does not work that well for my case</p>\n\n<p>Here's the code and a sample set of images</p>\n\n<pre><code>import numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\n\nMIN_MATCH_COUNT = 10\nimg1 = cv2.imread('Image 11.jpg',0)          # queryImage\nimg2 = cv2.imread('Image 5.jpg',0) # trainImage\n\n# Initiate SIFT detector\nsift = cv2.xfeatures2d.SIFT_create()\n\n# find the keypoints and descriptors with SIFT\nkp1, des1 = sift.detectAndCompute(img1,None)\nkp2, des2 = sift.detectAndCompute(img2,None)\nFLANN_INDEX_KDTREE = 1\nindex_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\nsearch_params = dict(checks = 50)\nflann = cv2.FlannBasedMatcher(index_params, search_params)\nmatches = flann.knnMatch(des1,des2,k=2)\n\n# store all the good matches as per Lowe's ratio test.\ngood = []\nfor m,n in matches:\n    if m.distance &lt; 0.7*n.distance:\n        good.append(m)\nif len(good)&gt;MIN_MATCH_COUNT:\n    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n    matchesMask = mask.ravel().tolist()\n    h,w = img1.shape\n    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n    dst = cv2.perspectiveTransform(pts,M)\n    img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\nelse:\n    print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n    matchesMask = None\ndraw_params = dict(matchColor = (0,255,0), # draw matches in green color\n                   singlePointColor = None,\n                   matchesMask = matchesMask, # draw only inliers\n                   flags = 2)\nimg3 = cv2.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\nplt.imshow(img3, 'gray'),plt.show()\n</code></pre>\n\n<p><strong>Train Image :</strong> \n<a href=\"https://i.stack.imgur.com/noqE8.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/noqE8.jpg\" alt=\"Train Image\"></a></p>\n\n<p><strong>Query Image :</strong>\n<a href=\"https://i.stack.imgur.com/0OYpz.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/0OYpz.jpg\" alt=\"Query Image\"></a></p>\n\n<ul>\n<li>Have already posted this question in stackoverflow but was recommended by @sophros to try posting it here</li>\n</ul>\n <python><computer-vision><object-recognition>",
                "codes": [],
                "question_id:": "27330",
                "question_votes:": "2",
                "question_text:": "<p>I'm trying to use opencv via python to find multiple objects in a train image and match it with the key points detected from query image.For my case, i'm trying to detect the tennis courts in the image provided below. I I looked at the online tutorials,and only figured that it can only detect 1 object. I thought of inserting a loop in for it to find multiple objects but i failed to do so. Any idea on how to do it ? </p>\n\n<p>*I Used SIFT as ORB does not work that well for my case</p>\n\n<p>Here's the code and a sample set of images</p>\n\n<pre><code>import numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\n\nMIN_MATCH_COUNT = 10\nimg1 = cv2.imread('Image 11.jpg',0)          # queryImage\nimg2 = cv2.imread('Image 5.jpg',0) # trainImage\n\n# Initiate SIFT detector\nsift = cv2.xfeatures2d.SIFT_create()\n\n# find the keypoints and descriptors with SIFT\nkp1, des1 = sift.detectAndCompute(img1,None)\nkp2, des2 = sift.detectAndCompute(img2,None)\nFLANN_INDEX_KDTREE = 1\nindex_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\nsearch_params = dict(checks = 50)\nflann = cv2.FlannBasedMatcher(index_params, search_params)\nmatches = flann.knnMatch(des1,des2,k=2)\n\n# store all the good matches as per Lowe's ratio test.\ngood = []\nfor m,n in matches:\n    if m.distance &lt; 0.7*n.distance:\n        good.append(m)\nif len(good)&gt;MIN_MATCH_COUNT:\n    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n    matchesMask = mask.ravel().tolist()\n    h,w = img1.shape\n    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n    dst = cv2.perspectiveTransform(pts,M)\n    img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\nelse:\n    print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n    matchesMask = None\ndraw_params = dict(matchColor = (0,255,0), # draw matches in green color\n                   singlePointColor = None,\n                   matchesMask = matchesMask, # draw only inliers\n                   flags = 2)\nimg3 = cv2.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\nplt.imshow(img3, 'gray'),plt.show()\n</code></pre>\n\n<p><strong>Train Image :</strong> \n<a href=\"https://i.stack.imgur.com/noqE8.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/noqE8.jpg\" alt=\"Train Image\"></a></p>\n\n<p><strong>Query Image :</strong>\n<a href=\"https://i.stack.imgur.com/0OYpz.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/0OYpz.jpg\" alt=\"Query Image\"></a></p>\n\n<ul>\n<li>Have already posted this question in stackoverflow but was recommended by @sophros to try posting it here</li>\n</ul>\n",
                "tags": "<python><computer-vision><object-recognition>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10992",
            "_score": 7.6336527,
            "_source": {
                "title": "normalizing data and avoiding dividing by zero",
                "content": "normalizing data and avoiding dividing by zero <p>I have data that I'm compressing with AutoEncoders (3-layer neural network) and I would like to normalize my data first. I would like to try to use the coded latent vector and feed it into an anomaly detection algorithm and see what happens.</p>\n\n<p>I would like to normalize the data for the autoencoder so my values are either between 0,1 or -1,-1 because my output activation function will either be a sigmoid or tanh. This way my algorithm can train and the input will be in the same range as the output values of the NN.</p>\n\n<p>However, when I normalized with </p>\n\n<pre><code>x(i)-xmean/(xmax-xmin) \n</code></pre>\n\n<p>I ended up dividing by 0 in several features of the data which gave NaN. Is is possible to normalize my data so it is between -1,1 or 0,1 while avoiding dividing by 0 for my data?</p>\n <neural-network><normalization><p>As others pointed out, you can normalize or standardize your data using the following steps. I'm sure other libraries have similar functions but I think this is efficient. </p>\n\n<p>Since you requested normalization, I'll cover that topic in this post. As others alluded, data normalization is the process in which researchers or data science practitioners make all the values in a given dataset be proportionally spread between 0 and 1. </p>\n\n<p>To implement normalization, follow the steps below:</p>\n\n<pre><code>from sklearn.datasets import load_iris\nfrom sklearn import preprocessing\n\niris = load_iris()\nprint(iris.data.shape)\n\nX_data = iris.data\ny_labels = iris.target\n\nnormalized_X_data = preprocessing.normalize(X_data)\n</code></pre>\n<p>You should subtract the <code>xmin</code> from x, not <code>xmean</code>.</p>\n\n<p>Here is a normalization function generalized to rescale any new minimum and maximum as parameters (e.g., 0,1 or -1,-1):</p>\n\n<pre><code>def rescale(nums, new_min=0, new_max=1):\n      \"Rescale values to be between new min and max\"\n      return [(new_max - new_min) / (max(nums)-min(nums)) * (value-max(nums)) + new_max for value in nums]\n</code></pre>\n<p>While you could do this manually, Python also has a handy little function called <strong>MinMaxScaler</strong>, which will automatically apply max-min normalization to scale data between <strong>0</strong> and <strong>1</strong>.</p>\n\n<p>Assume we have an array of 200 values for variables <strong>s</strong> and <strong>t</strong>:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\nmu, sigma = 20, 10 # mean and standard deviation\ns = np.random.normal(mu, sigma, 200)\nt = np.random.normal(mu, sigma, 200)\n</code></pre>\n\n<p>Reshape your variables if necessary:</p>\n\n<pre><code>s=np.reshape(s,(-1,1))\nt=np.reshape(t,(-1,1))\n</code></pre>\n\n<p>Now, you can see that we are forming two new variables, <strong>snew</strong> and <strong>tnew</strong>, which we are scaling using <strong>MinMaxScaler</strong>.</p>\n\n<pre><code>scaler = MinMaxScaler()\nprint(scaler.fit(s))\nprint(scaler.fit(s))\nsnew=scaler.transform(s)\ntnew=scaler.transform(t)\n</code></pre>\n\n<p>Here is a sample of our new variables:</p>\n\n<pre><code>&gt;&gt;&gt; snew\narray([[0.24896606],\n       [0.63121206],\n       [0.60448469],\n       .......\n       [0.49044733],\n       [0.28131596],\n       [0.32909155]\n\n&gt;&gt;&gt; tnew\narray([[0.91224005],\n       [0.74540598],\n       [0.3938718 ],\n       .......\n       [0.75749275],\n       [0.80709325],\n       [0.19440844]\n</code></pre>\n",
                "codes": [
                    [
                        "from sklearn.datasets import load_iris\nfrom sklearn import preprocessing\n\niris = load_iris()\nprint(iris.data.shape)\n\nX_data = iris.data\ny_labels = iris.target\n\nnormalized_X_data = preprocessing.normalize(X_data)\n"
                    ],
                    [
                        "def rescale(nums, new_min=0, new_max=1):\n      \"Rescale values to be between new min and max\"\n      return [(new_max - new_min) / (max(nums)-min(nums)) * (value-max(nums)) + new_max for value in nums]\n"
                    ],
                    [
                        "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\nmu, sigma = 20, 10 # mean and standard deviation\ns = np.random.normal(mu, sigma, 200)\nt = np.random.normal(mu, sigma, 200)\n",
                        "s=np.reshape(s,(-1,1))\nt=np.reshape(t,(-1,1))\n",
                        "scaler = MinMaxScaler()\nprint(scaler.fit(s))\nprint(scaler.fit(s))\nsnew=scaler.transform(s)\ntnew=scaler.transform(t)\n",
                        ">>> snew\narray([[0.24896606],\n       [0.63121206],\n       [0.60448469],\n       .......\n       [0.49044733],\n       [0.28131596],\n       [0.32909155]\n\n>>> tnew\narray([[0.91224005],\n       [0.74540598],\n       [0.3938718 ],\n       .......\n       [0.75749275],\n       [0.80709325],\n       [0.19440844]\n"
                    ]
                ],
                "question_id:": "38913",
                "question_votes:": "3",
                "question_text:": "<p>I have data that I'm compressing with AutoEncoders (3-layer neural network) and I would like to normalize my data first. I would like to try to use the coded latent vector and feed it into an anomaly detection algorithm and see what happens.</p>\n\n<p>I would like to normalize the data for the autoencoder so my values are either between 0,1 or -1,-1 because my output activation function will either be a sigmoid or tanh. This way my algorithm can train and the input will be in the same range as the output values of the NN.</p>\n\n<p>However, when I normalized with </p>\n\n<pre><code>x(i)-xmean/(xmax-xmin) \n</code></pre>\n\n<p>I ended up dividing by 0 in several features of the data which gave NaN. Is is possible to normalize my data so it is between -1,1 or 0,1 while avoiding dividing by 0 for my data?</p>\n",
                "tags": "<neural-network><normalization>",
                "answers": [
                    [
                        "45474",
                        "2",
                        "38913",
                        "",
                        "",
                        "<p>As others pointed out, you can normalize or standardize your data using the following steps. I'm sure other libraries have similar functions but I think this is efficient. </p>\n\n<p>Since you requested normalization, I'll cover that topic in this post. As others alluded, data normalization is the process in which researchers or data science practitioners make all the values in a given dataset be proportionally spread between 0 and 1. </p>\n\n<p>To implement normalization, follow the steps below:</p>\n\n<pre><code>from sklearn.datasets import load_iris\nfrom sklearn import preprocessing\n\niris = load_iris()\nprint(iris.data.shape)\n\nX_data = iris.data\ny_labels = iris.target\n\nnormalized_X_data = preprocessing.normalize(X_data)\n</code></pre>\n",
                        "",
                        ""
                    ],
                    [
                        "38915",
                        "2",
                        "38913",
                        "",
                        "",
                        "<p>You should subtract the <code>xmin</code> from x, not <code>xmean</code>.</p>\n\n<p>Here is a normalization function generalized to rescale any new minimum and maximum as parameters (e.g., 0,1 or -1,-1):</p>\n\n<pre><code>def rescale(nums, new_min=0, new_max=1):\n      \"Rescale values to be between new min and max\"\n      return [(new_max - new_min) / (max(nums)-min(nums)) * (value-max(nums)) + new_max for value in nums]\n</code></pre>\n",
                        "",
                        ""
                    ],
                    [
                        "38942",
                        "2",
                        "38913",
                        "",
                        "",
                        "<p>While you could do this manually, Python also has a handy little function called <strong>MinMaxScaler</strong>, which will automatically apply max-min normalization to scale data between <strong>0</strong> and <strong>1</strong>.</p>\n\n<p>Assume we have an array of 200 values for variables <strong>s</strong> and <strong>t</strong>:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\nmu, sigma = 20, 10 # mean and standard deviation\ns = np.random.normal(mu, sigma, 200)\nt = np.random.normal(mu, sigma, 200)\n</code></pre>\n\n<p>Reshape your variables if necessary:</p>\n\n<pre><code>s=np.reshape(s,(-1,1))\nt=np.reshape(t,(-1,1))\n</code></pre>\n\n<p>Now, you can see that we are forming two new variables, <strong>snew</strong> and <strong>tnew</strong>, which we are scaling using <strong>MinMaxScaler</strong>.</p>\n\n<pre><code>scaler = MinMaxScaler()\nprint(scaler.fit(s))\nprint(scaler.fit(s))\nsnew=scaler.transform(s)\ntnew=scaler.transform(t)\n</code></pre>\n\n<p>Here is a sample of our new variables:</p>\n\n<pre><code>&gt;&gt;&gt; snew\narray([[0.24896606],\n       [0.63121206],\n       [0.60448469],\n       .......\n       [0.49044733],\n       [0.28131596],\n       [0.32909155]\n\n&gt;&gt;&gt; tnew\narray([[0.91224005],\n       [0.74540598],\n       [0.3938718 ],\n       .......\n       [0.75749275],\n       [0.80709325],\n       [0.19440844]\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4819",
            "_score": 7.629407,
            "_source": {
                "title": "Convert exponential to normal distribution",
                "content": "Convert exponential to normal distribution <p>For the distribution shown below, I want to convert the exponential distribution to a normal distribution. I want to do this is as part of data pre-processing so that the classifier can better interpret the feature (named <code>ipc</code> here).</p>\n\n<p><a href=\"https://i.stack.imgur.com/GpQbK.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/GpQbK.png\" alt=\"Distribution of ipc feature\"></a></p>\n\n<p>The regular log transformation does not work here because of the (x-axis) spread.</p>\n\n<p>How can I transform this data to a normal distribution?</p>\n\n<p>A related answer has been pointed out in the comment but I am looking for some Python code excerpt as well.</p>\n\n<p>Thanks</p>\n <machine-learning><preprocessing><normalization><p>The following code works:</p>\n\n<pre><code>import scipy\nimport numpy as np\n\ney = np.random.exponential(size=100)\ncdfy = scipy.stats.expon.cdf(np.sort(ey))\ninvcdf = scipy.stats.norm.ppf(cdfy) # a normal distribution\n</code></pre>\n\n<p>Hope this helps</p>\n<p>You can use <code>sklearn.preprocessing.QuantileTransformer</code> (or <code>sklearn.preprocessing.PowerTransformer</code>) which does exactly what you want:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from sklearn.preprocessing import QuantileTransformer\nimport numpy as np\n\ney = np.random.exponential(size=100)\nqt = QuantileTransformer(output_distribution='normal')\nno = qt.fit_transform(ey.reshape(-1, 1))\n</code></pre>\n\n<p>You can plot histograms to compare \"before\" vs \"after\":</p>\n\n<pre class=\"lang-py prettyprint-override\"><code># Plot histograms to see before vs after.\nimport matplotlib.pyplot as plt\n%matplotlib inline \nplt.subplot(2, 2, 1)\nplt.hist(ey, bins='auto')\nplt.subplot(2, 2, 2)\nplt.hist(no, bins='auto')\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/rY0cR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/rY0cR.png\" alt=\"enter image description here\"></a></p>\n\n<p>The advantage of this approach is that it will also work for other input distributions, not only exponential.</p>\n",
                "codes": [
                    [
                        "import scipy\nimport numpy as np\n\ney = np.random.exponential(size=100)\ncdfy = scipy.stats.expon.cdf(np.sort(ey))\ninvcdf = scipy.stats.norm.ppf(cdfy) # a normal distribution\n"
                    ],
                    [
                        "from sklearn.preprocessing import QuantileTransformer\nimport numpy as np\n\ney = np.random.exponential(size=100)\nqt = QuantileTransformer(output_distribution='normal')\nno = qt.fit_transform(ey.reshape(-1, 1))\n",
                        "# Plot histograms to see before vs after.\nimport matplotlib.pyplot as plt\n%matplotlib inline \nplt.subplot(2, 2, 1)\nplt.hist(ey, bins='auto')\nplt.subplot(2, 2, 2)\nplt.hist(no, bins='auto')\nplt.show()\n"
                    ]
                ],
                "question_id:": "18933",
                "question_votes:": "2",
                "question_text:": "<p>For the distribution shown below, I want to convert the exponential distribution to a normal distribution. I want to do this is as part of data pre-processing so that the classifier can better interpret the feature (named <code>ipc</code> here).</p>\n\n<p><a href=\"https://i.stack.imgur.com/GpQbK.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/GpQbK.png\" alt=\"Distribution of ipc feature\"></a></p>\n\n<p>The regular log transformation does not work here because of the (x-axis) spread.</p>\n\n<p>How can I transform this data to a normal distribution?</p>\n\n<p>A related answer has been pointed out in the comment but I am looking for some Python code excerpt as well.</p>\n\n<p>Thanks</p>\n",
                "tags": "<machine-learning><preprocessing><normalization>",
                "answers": [
                    [
                        "19067",
                        "2",
                        "18933",
                        "",
                        "",
                        "<p>The following code works:</p>\n\n<pre><code>import scipy\nimport numpy as np\n\ney = np.random.exponential(size=100)\ncdfy = scipy.stats.expon.cdf(np.sort(ey))\ninvcdf = scipy.stats.norm.ppf(cdfy) # a normal distribution\n</code></pre>\n\n<p>Hope this helps</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "53866",
                        "2",
                        "18933",
                        "",
                        "",
                        "<p>You can use <code>sklearn.preprocessing.QuantileTransformer</code> (or <code>sklearn.preprocessing.PowerTransformer</code>) which does exactly what you want:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from sklearn.preprocessing import QuantileTransformer\nimport numpy as np\n\ney = np.random.exponential(size=100)\nqt = QuantileTransformer(output_distribution='normal')\nno = qt.fit_transform(ey.reshape(-1, 1))\n</code></pre>\n\n<p>You can plot histograms to compare \"before\" vs \"after\":</p>\n\n<pre class=\"lang-py prettyprint-override\"><code># Plot histograms to see before vs after.\nimport matplotlib.pyplot as plt\n%matplotlib inline \nplt.subplot(2, 2, 1)\nplt.hist(ey, bins='auto')\nplt.subplot(2, 2, 2)\nplt.hist(no, bins='auto')\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/rY0cR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/rY0cR.png\" alt=\"enter image description here\"></a></p>\n\n<p>The advantage of this approach is that it will also work for other input distributions, not only exponential.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13075",
            "_score": 7.629407,
            "_source": {
                "title": "Guys I am trying to create a application to create training data",
                "content": "Guys I am trying to create a application to create training data <pre><code>import os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom colorama import Fore\nimport random\nimport numpy as np\nimport pickle\n\ntraining_data = []\ndef create_training_data():\npath = os.getcwd()\npath_dataset = os.path.join(path,'dataset')\ncategories = ['a','b']\nfor category in categories:\n    path_categories = os.path.join(path_dataset,category)\n    index = categories.index(category)\n    for img in os.listdir(path_categories):\n        try:\n            path = os.path.join(path_categories,img)\n            img_array = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n            training_data.append([img_array,index])\n        except Exception as e:\n            print(Fore.RED+path)\n    print(Fore.GREEN+f\"imported all data from cateogry {category}\")\n\n\n\n#For every object in the training dataset\n#training_data[element][data type*]\n#0 - Stores the values of all images\n#1 -  stores the values of all category\n\ncreate_training_data()\n\nprint(training_data[1201][1])\nplt.imshow(training_data[1201][0],cmap=\"gray\")\nrows,columns = training_data[0][0].shape\nprint(f\"rows-{rows} cols-{columns}\")\nplt.show()\nrandom.shuffle(training_data)\nX = []\nY = []\n\nfor feature,label in training_data:\nX.append(feature)\nY.append(label)\n\nX = np.array(X).reshape(-1,rows,columns,1)\n\n\npickle_out = open(X.pickle,'wb')\npickle.dump(X,pickle_out)\npickle_out.close()\n\npickle_out = open(Y.pickle,'wb')\npickle.dump(Y,pickle_out)\npickle_out.close()\n</code></pre>\n\n<p>After I run this script I am getting an error:</p>\n\n<p>Traceback (most recent call last):\n  File \"trainingdata.py\", line 55, in \n    pickle_out = open(X.pickle,'wb')\nAttributeError: 'numpy.ndarray' object has no attribute 'pickle'</p>\n <dataset><training><p>The error in the line <code>pickle_out = open(X.pickle,'wb')</code> is that the name of file must be in quotes. So the correct code would be:</p>\n\n<pre><code>pickle_out = open('X.pickle','wb')\npickle.dump(X,pickle_out)\npickle_out.close()\n</code></pre>\n\n<p>Do the same for Y also. Also you can do it more concisely in the following way:</p>\n\n<pre><code>with open('X.pickle', 'wb') as f:\n    pickle.dump(X, f)\n</code></pre>\n",
                "codes": [
                    [
                        "pickle_out = open('X.pickle','wb')\npickle.dump(X,pickle_out)\npickle_out.close()\n",
                        "with open('X.pickle', 'wb') as f:\n    pickle.dump(X, f)\n"
                    ]
                ],
                "question_id:": "45214",
                "question_votes:": "2",
                "question_text:": "<pre><code>import os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom colorama import Fore\nimport random\nimport numpy as np\nimport pickle\n\ntraining_data = []\ndef create_training_data():\npath = os.getcwd()\npath_dataset = os.path.join(path,'dataset')\ncategories = ['a','b']\nfor category in categories:\n    path_categories = os.path.join(path_dataset,category)\n    index = categories.index(category)\n    for img in os.listdir(path_categories):\n        try:\n            path = os.path.join(path_categories,img)\n            img_array = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n            training_data.append([img_array,index])\n        except Exception as e:\n            print(Fore.RED+path)\n    print(Fore.GREEN+f\"imported all data from cateogry {category}\")\n\n\n\n#For every object in the training dataset\n#training_data[element][data type*]\n#0 - Stores the values of all images\n#1 -  stores the values of all category\n\ncreate_training_data()\n\nprint(training_data[1201][1])\nplt.imshow(training_data[1201][0],cmap=\"gray\")\nrows,columns = training_data[0][0].shape\nprint(f\"rows-{rows} cols-{columns}\")\nplt.show()\nrandom.shuffle(training_data)\nX = []\nY = []\n\nfor feature,label in training_data:\nX.append(feature)\nY.append(label)\n\nX = np.array(X).reshape(-1,rows,columns,1)\n\n\npickle_out = open(X.pickle,'wb')\npickle.dump(X,pickle_out)\npickle_out.close()\n\npickle_out = open(Y.pickle,'wb')\npickle.dump(Y,pickle_out)\npickle_out.close()\n</code></pre>\n\n<p>After I run this script I am getting an error:</p>\n\n<p>Traceback (most recent call last):\n  File \"trainingdata.py\", line 55, in \n    pickle_out = open(X.pickle,'wb')\nAttributeError: 'numpy.ndarray' object has no attribute 'pickle'</p>\n",
                "tags": "<dataset><training>",
                "answers": [
                    [
                        "45215",
                        "2",
                        "45214",
                        "",
                        "",
                        "<p>The error in the line <code>pickle_out = open(X.pickle,'wb')</code> is that the name of file must be in quotes. So the correct code would be:</p>\n\n<pre><code>pickle_out = open('X.pickle','wb')\npickle.dump(X,pickle_out)\npickle_out.close()\n</code></pre>\n\n<p>Do the same for Y also. Also you can do it more concisely in the following way:</p>\n\n<pre><code>with open('X.pickle', 'wb') as f:\n    pickle.dump(X, f)\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11501",
            "_score": 7.581847,
            "_source": {
                "title": "Does a matrix factorization recommendation engine use user/item related features?",
                "content": "Does a matrix factorization recommendation engine use user/item related features? <p>All the tutorials I can find about matrix factorization recommendation systems start with importing users, items, and user-item-ratings, but then only use the rating matrix to train the recommender (not features of the users or items themselves like \"age\").</p>\n\n<p><strong>Example</strong></p>\n\n<p><strong>Tutorial</strong>: Matrix Factorization for Movie Recommendations in Python</p>\n\n<p><strong>URL</strong>: <a href=\"https://beckernick.github.io/matrix-factorization-recommender/\" rel=\"nofollow noreferrer\">https://beckernick.github.io/matrix-factorization-recommender/</a></p>\n\n<p>Users (userID, gender, ageGroup, occupationGroup, zipCode) \n<a href=\"https://i.stack.imgur.com/PYruE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PYruE.png\" alt=\"enter image description here\"></a></p>\n\n<p>Items (movieID, title, genres)\n<a href=\"https://i.stack.imgur.com/ZsLhR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ZsLhR.png\" alt=\"enter image description here\"></a></p>\n\n<p>Ratings  (userID, movieID, rating, timestamp)\n<a href=\"https://i.stack.imgur.com/Z3Hg3.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Z3Hg3.png\" alt=\"enter image description here\"></a></p>\n\n<p>Then we do some cleaning and build a matrix of users-to-items with ratings as the values.\n<a href=\"https://i.stack.imgur.com/axjdt.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/axjdt.png\" alt=\"enter image description here\"></a></p>\n\n<p>Then we proceed to to only use the matrix built from ratings (not other features of the user like age which I might guess has some predictive value).</p>\n\n<pre><code># normalize data\nimport numpy as np\nR = R_df.as_matrix()\nuser_ratings_mean = np.mean(R, axis=1)\nR_demeaned = R - user_ratings_mean.reshape(-1,1)\n\n# import numpy as np\nR = R_df.as_matrix()\nuser_ratings_mean = np.mean(R, axis=1)\nR_demeaned = R - user_ratings_mean.reshape(-1,1)\n\n# SVD\nimport scipy\nfrom scipy.sparse.linalg import svds\nU, sigma, Vt = svds(R_demeaned, k=2)\n\n# convert to diagonal matrix\nsigma2 = np.diag(sigma)\n\n# build predication matrix\nall_user_predicted_ratings = np.dot(np.dot(U, sigma2), Vt) + user_ratings_mean.reshape(-1, 1)\npreds_df = pd.DataFrame(all_user_predicted_ratings, columns = R_df.columns, dtype='float')\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/GCP5y.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/GCP5y.png\" alt=\"enter image description here\"></a></p>\n\n<p>Theres more in the tutorial but at this point our predication matrix is already set.</p>\n\n<ol>\n<li><p>I wondered if this is just how matrix factorization recommenders work (aka. not use user/item features) or if online tutorials are just too simple?</p></li>\n<li><p>If I wanted to incorporate a user feature like age, would it be possible with matrix factorization?</p></li>\n</ol>\n <machine-learning><python><recommender-system><matrix-factorisation><blockquote>\n  <blockquote>\n    <blockquote>\n      <p>If I wanted to incorporate a user feature like age, would it be possible with matrix factorization?</p>\n    </blockquote>\n  </blockquote>\n</blockquote>\n\n<p>Yes, it's possible. It's commonly called a hybrid recommendation system.</p>\n<blockquote>\n  <ol>\n  <li>I wondered if this is just how matrix factorization recommenders work (aka. not use user/item features) or if online tutorials are just too simple?</li>\n  </ol>\n</blockquote>\n\n<p>In most of the cases, ALS or any other Matrix Factorization techniques are used for interaction data. Like: visits, clicks, skips, etc.  We can have a hybrid matrix factorization, just in case you need to decide what to include in the User/Item matrix[Also termed as hybrid Recommendations]</p>\n\n<blockquote>\n  <ol start=\"2\">\n  <li>If I wanted to incorporate a user feature like age, would it be possible with matrix factorization?</li>\n  </ol>\n</blockquote>\n\n<p>Yes, you can, In can be complex to thought process to incorporate it into FMs. But it is surely possible.</p>\n\n<h3>Example</h3>\n\n<p>Counts: </p>\n\n<ul>\n<li>user 1:30-50yrs old, </li>\n<li>user2: 18-30yrs old,</li>\n<li>user 3: &lt;18.</li>\n</ul>\n\n<p>Matrix can be made of the counts of the purchased products[i1,i2,i3] as below </p>\n\n<p><a href=\"https://i.stack.imgur.com/xNLRR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/xNLRR.png\" alt=\"enter image description here\"></a></p>\n\n<p>This can be given as input to ALS to find out feature matrices for users and items. </p>\n\n<p><strong>Similary you can incorporate other features to create your recommendation engine</strong></p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "40590",
                "question_votes:": "1",
                "question_text:": "<p>All the tutorials I can find about matrix factorization recommendation systems start with importing users, items, and user-item-ratings, but then only use the rating matrix to train the recommender (not features of the users or items themselves like \"age\").</p>\n\n<p><strong>Example</strong></p>\n\n<p><strong>Tutorial</strong>: Matrix Factorization for Movie Recommendations in Python</p>\n\n<p><strong>URL</strong>: <a href=\"https://beckernick.github.io/matrix-factorization-recommender/\" rel=\"nofollow noreferrer\">https://beckernick.github.io/matrix-factorization-recommender/</a></p>\n\n<p>Users (userID, gender, ageGroup, occupationGroup, zipCode) \n<a href=\"https://i.stack.imgur.com/PYruE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PYruE.png\" alt=\"enter image description here\"></a></p>\n\n<p>Items (movieID, title, genres)\n<a href=\"https://i.stack.imgur.com/ZsLhR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ZsLhR.png\" alt=\"enter image description here\"></a></p>\n\n<p>Ratings  (userID, movieID, rating, timestamp)\n<a href=\"https://i.stack.imgur.com/Z3Hg3.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Z3Hg3.png\" alt=\"enter image description here\"></a></p>\n\n<p>Then we do some cleaning and build a matrix of users-to-items with ratings as the values.\n<a href=\"https://i.stack.imgur.com/axjdt.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/axjdt.png\" alt=\"enter image description here\"></a></p>\n\n<p>Then we proceed to to only use the matrix built from ratings (not other features of the user like age which I might guess has some predictive value).</p>\n\n<pre><code># normalize data\nimport numpy as np\nR = R_df.as_matrix()\nuser_ratings_mean = np.mean(R, axis=1)\nR_demeaned = R - user_ratings_mean.reshape(-1,1)\n\n# import numpy as np\nR = R_df.as_matrix()\nuser_ratings_mean = np.mean(R, axis=1)\nR_demeaned = R - user_ratings_mean.reshape(-1,1)\n\n# SVD\nimport scipy\nfrom scipy.sparse.linalg import svds\nU, sigma, Vt = svds(R_demeaned, k=2)\n\n# convert to diagonal matrix\nsigma2 = np.diag(sigma)\n\n# build predication matrix\nall_user_predicted_ratings = np.dot(np.dot(U, sigma2), Vt) + user_ratings_mean.reshape(-1, 1)\npreds_df = pd.DataFrame(all_user_predicted_ratings, columns = R_df.columns, dtype='float')\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/GCP5y.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/GCP5y.png\" alt=\"enter image description here\"></a></p>\n\n<p>Theres more in the tutorial but at this point our predication matrix is already set.</p>\n\n<ol>\n<li><p>I wondered if this is just how matrix factorization recommenders work (aka. not use user/item features) or if online tutorials are just too simple?</p></li>\n<li><p>If I wanted to incorporate a user feature like age, would it be possible with matrix factorization?</p></li>\n</ol>\n",
                "tags": "<machine-learning><python><recommender-system><matrix-factorisation>",
                "answers": [
                    [
                        "40614",
                        "2",
                        "40590",
                        "",
                        "",
                        "<blockquote>\n  <blockquote>\n    <blockquote>\n      <p>If I wanted to incorporate a user feature like age, would it be possible with matrix factorization?</p>\n    </blockquote>\n  </blockquote>\n</blockquote>\n\n<p>Yes, it's possible. It's commonly called a hybrid recommendation system.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "52117",
                        "2",
                        "40590",
                        "",
                        "",
                        "<blockquote>\n  <ol>\n  <li>I wondered if this is just how matrix factorization recommenders work (aka. not use user/item features) or if online tutorials are just too simple?</li>\n  </ol>\n</blockquote>\n\n<p>In most of the cases, ALS or any other Matrix Factorization techniques are used for interaction data. Like: visits, clicks, skips, etc.  We can have a hybrid matrix factorization, just in case you need to decide what to include in the User/Item matrix[Also termed as hybrid Recommendations]</p>\n\n<blockquote>\n  <ol start=\"2\">\n  <li>If I wanted to incorporate a user feature like age, would it be possible with matrix factorization?</li>\n  </ol>\n</blockquote>\n\n<p>Yes, you can, In can be complex to thought process to incorporate it into FMs. But it is surely possible.</p>\n\n<h3>Example</h3>\n\n<p>Counts: </p>\n\n<ul>\n<li>user 1:30-50yrs old, </li>\n<li>user2: 18-30yrs old,</li>\n<li>user 3: &lt;18.</li>\n</ul>\n\n<p>Matrix can be made of the counts of the purchased products[i1,i2,i3] as below </p>\n\n<p><a href=\"https://i.stack.imgur.com/xNLRR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/xNLRR.png\" alt=\"enter image description here\"></a></p>\n\n<p>This can be given as input to ALS to find out feature matrices for users and items. </p>\n\n<p><strong>Similary you can incorporate other features to create your recommendation engine</strong></p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17203",
            "_score": 7.581847,
            "_source": {
                "title": "RuntimeError: Assertion `cur_target >= 0 && cur_target < n_classes' failed",
                "content": "RuntimeError: Assertion `cur_target >= 0 && cur_target < n_classes' failed <p>I am referring this previously asked <a href=\"https://stackoverflow.com/questions/55981101/runtimeerror-assertion-cur-target-0-cur-target-n-classes-failed\">question</a> in stack-overflow which remains unsolved till now. </p>\n\n<p>I am facing same problem with <code>pytorch</code> when I am solving multiclass classification. </p>\n\n<p>Here is my exception </p>\n\n<blockquote>\n  <p>RuntimeError: Assertion `cur_target >= 0 &amp;&amp; cur_target &lt; n_classes' failed.  at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1532501501514\\work\\aten\\src\\thnn\\generic/ClassNLLCriterion.c:93</p>\n</blockquote>\n\n<p>I have added whole code of mine with the dataset I am trying with but still get stuck on that </p>\n\n<pre><code># -*- coding: utf-8 -*-\n\"\"\"\nCreated on Thu Jul 11 22:41:07 2019\n\n@author: Ananda Mohon Ghosh\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport torch\nfrom torch import nn\nfrom torch.autograd import Variable\nimport torch.utils.data as utils\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nimport torch.optim as optim\n\n\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.classificaion =nn.Sequential(\n            nn.Linear(16, 12),\n            nn.LogSoftmax(dim=1)            \n        )\n\n    def forward(self, x):\n        clsf = self.classificaion(x)\n        return clsf\n\ndef oneHotCode(y):\n    y = y-min(y)\n    nOfClasses = len(set(y)) \n    labels = y.reshape(len(y), 1)\n    return (labels == torch.arange(nOfClasses).reshape(1, nOfClasses)).long()\n\ndef batchData(xBatch, yBatch):\n    return np.concat((xBatch, yBatch),axis=1)\n\ndef findMinMax(df):\n    #find max-min\n    minimum = 999999\n    maximum =  -999999\n\n    for di in  df:\n        tMin = min(di)\n        tMax = max(di)\n        if(tMin&lt;minimum):\n            minimum = tMin\n        if(tMax&gt;maximum):\n            maximum = tMax\n    return maximum, minimum\n\n\ndataFrame = pd.read_csv('data/features_test_encoded16_ds1_batch_sig.csv')\ndataFrameValues = dataFrame.values\n\navailabelCuda = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\nprint('Availabel CUDA ', availabelCuda)\n\n#variables\nnum_epochs = 10\nbatch_size = 128\nlearning_rate = 1e-3\nweight_decay = 1e-5\nmomentum = 0.9\n\n\nclsf = Net()\nmodel = clsf.to(availabelCuda)\n\nlossFunc= nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate,  weight_decay=weight_decay)\n\n\nobservations =  dataFrameValues.shape[0]\nfeatureSetLength = dataFrameValues.shape[1]\nfeatureSet = dataFrameValues[0:len(dataFrameValues), 0:featureSetLength-1 ]\nmaximum, minimum =findMinMax(featureSet)\n\nfeatureSet = (featureSet-minimum)/(maximum-minimum)\n\nlabelSet = dataFrameValues[0:len(dataFrameValues), featureSetLength-1 ]\n\nXtrain = featureSet[0:int(observations*0.7), :]\nXtest = featureSet[int(observations*0.7):observations, :]\nYtrain = labelSet[0:int(observations*0.7)]\nYtest = labelSet[int(observations*0.7):observations]\n\nX = torch.Tensor(Xtrain)\nY = torch.Tensor(Ytrain.reshape(-1,1))\ntrainDataset = utils.TensorDataset(X, Y)\n\n\ndataloaderTrain = utils.DataLoader(trainDataset, batch_size=batch_size, shuffle=False)\n\nprint('Model running on ', availabelCuda)\n\n\nfor epoch in range(num_epochs):\n    for xX, yY in dataloaderTrain:\n        optimizer.zero_grad()\n        dataX = Variable(xX).to(availabelCuda)\n        dataY = Variable(yY.long()).to(availabelCuda)\n\n        outclass = clsf(dataX)\n        print(outclass.type(), dataY.view(-1).type())\n\n        loss = lossFunc(outclass, dataY.view(-1))\n        optimizer.zero_grad()               # clear gradients for this training step\n        loss.backward()                     # backpropagation, compute gradients\n        optimizer.step()\n    print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy()) #CPU\n</code></pre>\n\n<p>and here is the <a href=\"https://www.dropbox.com/s/tstwfbx94w4l327/features_test_encoded16_ds1_batch_sig.csv?dl=0\" rel=\"nofollow noreferrer\">link</a> of my dataset. Actually, I was hoping that I have problem with data normalization but eventually I couldn't solve it and still have this issue. Any kind of help is appreciated. Thanks. </p>\n <deep-learning><multiclass-classification><pytorch><p>Okay after 4 days I got my solution eventually. I figured it out that my classes are started from 1 to 12, so, in total I had 12 classes. </p>\n\n<p>The problem was appearing when I was about to calculate the predicted class vs actual class loss with the loss function. Instead of having start from 1 that function always from class 0 instead of 1 and continuously look for 0 to 12 which indicated it do have 13 classes in total which generates an exception. </p>\n\n<p>So how do I solved that? I just docked 1 form each labels and shifted it from 0 to 11 and it went fine. That's how I solved the issue. Mention, I got couple of solution at PyTorch forum regarding the same issue and those wasn't helpful at all, literally!</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "55745",
                "question_votes:": "",
                "question_text:": "<p>I am referring this previously asked <a href=\"https://stackoverflow.com/questions/55981101/runtimeerror-assertion-cur-target-0-cur-target-n-classes-failed\">question</a> in stack-overflow which remains unsolved till now. </p>\n\n<p>I am facing same problem with <code>pytorch</code> when I am solving multiclass classification. </p>\n\n<p>Here is my exception </p>\n\n<blockquote>\n  <p>RuntimeError: Assertion `cur_target >= 0 &amp;&amp; cur_target &lt; n_classes' failed.  at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1532501501514\\work\\aten\\src\\thnn\\generic/ClassNLLCriterion.c:93</p>\n</blockquote>\n\n<p>I have added whole code of mine with the dataset I am trying with but still get stuck on that </p>\n\n<pre><code># -*- coding: utf-8 -*-\n\"\"\"\nCreated on Thu Jul 11 22:41:07 2019\n\n@author: Ananda Mohon Ghosh\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport torch\nfrom torch import nn\nfrom torch.autograd import Variable\nimport torch.utils.data as utils\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nimport torch.optim as optim\n\n\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.classificaion =nn.Sequential(\n            nn.Linear(16, 12),\n            nn.LogSoftmax(dim=1)            \n        )\n\n    def forward(self, x):\n        clsf = self.classificaion(x)\n        return clsf\n\ndef oneHotCode(y):\n    y = y-min(y)\n    nOfClasses = len(set(y)) \n    labels = y.reshape(len(y), 1)\n    return (labels == torch.arange(nOfClasses).reshape(1, nOfClasses)).long()\n\ndef batchData(xBatch, yBatch):\n    return np.concat((xBatch, yBatch),axis=1)\n\ndef findMinMax(df):\n    #find max-min\n    minimum = 999999\n    maximum =  -999999\n\n    for di in  df:\n        tMin = min(di)\n        tMax = max(di)\n        if(tMin&lt;minimum):\n            minimum = tMin\n        if(tMax&gt;maximum):\n            maximum = tMax\n    return maximum, minimum\n\n\ndataFrame = pd.read_csv('data/features_test_encoded16_ds1_batch_sig.csv')\ndataFrameValues = dataFrame.values\n\navailabelCuda = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\nprint('Availabel CUDA ', availabelCuda)\n\n#variables\nnum_epochs = 10\nbatch_size = 128\nlearning_rate = 1e-3\nweight_decay = 1e-5\nmomentum = 0.9\n\n\nclsf = Net()\nmodel = clsf.to(availabelCuda)\n\nlossFunc= nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate,  weight_decay=weight_decay)\n\n\nobservations =  dataFrameValues.shape[0]\nfeatureSetLength = dataFrameValues.shape[1]\nfeatureSet = dataFrameValues[0:len(dataFrameValues), 0:featureSetLength-1 ]\nmaximum, minimum =findMinMax(featureSet)\n\nfeatureSet = (featureSet-minimum)/(maximum-minimum)\n\nlabelSet = dataFrameValues[0:len(dataFrameValues), featureSetLength-1 ]\n\nXtrain = featureSet[0:int(observations*0.7), :]\nXtest = featureSet[int(observations*0.7):observations, :]\nYtrain = labelSet[0:int(observations*0.7)]\nYtest = labelSet[int(observations*0.7):observations]\n\nX = torch.Tensor(Xtrain)\nY = torch.Tensor(Ytrain.reshape(-1,1))\ntrainDataset = utils.TensorDataset(X, Y)\n\n\ndataloaderTrain = utils.DataLoader(trainDataset, batch_size=batch_size, shuffle=False)\n\nprint('Model running on ', availabelCuda)\n\n\nfor epoch in range(num_epochs):\n    for xX, yY in dataloaderTrain:\n        optimizer.zero_grad()\n        dataX = Variable(xX).to(availabelCuda)\n        dataY = Variable(yY.long()).to(availabelCuda)\n\n        outclass = clsf(dataX)\n        print(outclass.type(), dataY.view(-1).type())\n\n        loss = lossFunc(outclass, dataY.view(-1))\n        optimizer.zero_grad()               # clear gradients for this training step\n        loss.backward()                     # backpropagation, compute gradients\n        optimizer.step()\n    print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy()) #CPU\n</code></pre>\n\n<p>and here is the <a href=\"https://www.dropbox.com/s/tstwfbx94w4l327/features_test_encoded16_ds1_batch_sig.csv?dl=0\" rel=\"nofollow noreferrer\">link</a> of my dataset. Actually, I was hoping that I have problem with data normalization but eventually I couldn't solve it and still have this issue. Any kind of help is appreciated. Thanks. </p>\n",
                "tags": "<deep-learning><multiclass-classification><pytorch>",
                "answers": [
                    [
                        "56027",
                        "2",
                        "55745",
                        "",
                        "",
                        "<p>Okay after 4 days I got my solution eventually. I figured it out that my classes are started from 1 to 12, so, in total I had 12 classes. </p>\n\n<p>The problem was appearing when I was about to calculate the predicted class vs actual class loss with the loss function. Instead of having start from 1 that function always from class 0 instead of 1 and continuously look for 0 to 12 which indicated it do have 13 classes in total which generates an exception. </p>\n\n<p>So how do I solved that? I just docked 1 form each labels and shifted it from 0 to 11 and it went fine. That's how I solved the issue. Mention, I got couple of solution at PyTorch forum regarding the same issue and those wasn't helpful at all, literally!</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15496",
            "_score": 7.568583,
            "_source": {
                "title": "Using the Iris Flower dataset, why does my classifier classify any data inputted as \"Iris - Virginica\"?",
                "content": "Using the Iris Flower dataset, why does my classifier classify any data inputted as \"Iris - Virginica\"? <p>I'm a high school senior who is very new to making neural networks. I've been using the Iris Flower dataset (<a href=\"https://www.kaggle.com/arshid/iris-flower-dataset\" rel=\"nofollow noreferrer\">https://www.kaggle.com/arshid/iris-flower-dataset</a>) to build my neural network. My model gets above 90% accuracy for both the training and the testing data, however when I made my classifier using the weights and biased terms from the model, the classifier always classifies the data as \"Iris - Virginica\". I am not sure what the problem is, and any help would be appreciated. It should be noted that I want to make the neural network myself using feed forward, backpropagation, gradient descent, etc. I do not want to use an existing classifier from a well-known library (e,g KNeighbors from SKLearn). My code is below.</p>\n\n<pre><code>#Full Code\n\n#importing necessary libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv(\"Iris.csv\") #loading the data into Python\ndf.head()#checking the contents to manipulate\n\n#Preprocessing the data (making the features and the targets)\n\nX = np.asmatrix(np.copy(df))[:,:5] #getting all the columns of the feature data\nX = np.delete(X, 0, axis = 1) #dropping column of index 0 because it is \"id\".\n\nnameOfTargets = df.Species.unique() #Getting the unique values of the target column for one hot encoding\n\nY_data = [] #Empty list that will eventually become target data\nfor i in df.iloc[:,5]:\n    for j in range(nameOfTargets.shape[0]): #for j from 0 to N, where N is the number of items in nameOfTargets\n        if i == nameOfTargets[j]:       \n            Y_data.append(j)\n    #The index number of the item in nameOfTargets is how they will be represented \n        #in the target data. I.E if the value of the target is equal to the FIRST \n        #item of nameOfTargets, the value is represented by the item's INDEX (0).\n\nN = len(Y_data) #Getting the number of items in the dataset\nY = np.zeros(N*nameOfTargets.shape[0]).reshape(N,nameOfTargets.shape[0]) \n#Making the target matrix. The number of rows = number of subjects, number of columns = number of unique targets\n\n\nfor i in range(N): #One Hot Encoding. After the loop finishes, Y will be the final target matrix.\n    t = Y_data[i]\n    Y[i,t] = 1\n\n\n#Standardizing values in the feature matrix X\nfor i in range(X.shape[1]):\n    X[:,i] = (X[:,i].astype(float) - np.mean(X[:,i].astype(float)))/np.std(X[:,i].astype(float))\n\n\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 42) #Splitting the data into testing data and training data\n\n\n#Deep Learning\n\nnp.random.seed(1) #making sure the weights are the same every time the cell is rerun (still random)\nN,D = X_train.shape #N = num subjects, D = num features\nM = 100 #num hidden nodes of the first hidden layer\nK = nameOfTargets.shape[0] #number of outputs\n\niteration_num = 1000 #Number of times gradient descent will be performed\na = 0.02 #learning rate\n\n#creating the weights\nW = np.random.randn(D*M).reshape(D,M)\nV = np.random.randn(M*K).reshape(M,K)\n\n\n#creating the biased terms\nb = np.random.randn(M).reshape(1,M)\nb_ones = np.ones(N).reshape(N,1)\nb = np.dot(b_ones,b)\n\nc = np.random.randn(K).reshape(1,K)\nc_ones = np.ones(N).reshape(N,1)\nc = np.dot(c_ones, c)\n\nfor j in range(iteration_num): #Back Propagation\n\n    #feed forward\n    z = np.dot(X_train,W) + b\n    z = 1/(1 + np.exp(-z.astype(float)))\n    predictions = np.exp(np.dot(z,V) + c)\n\n    #softmax\n    for i in range(predictions.shape[0]):\n        predictions[i,:] = predictions[i,:]/np.sum(predictions[i,:])\n\n\n    #gradient descent\n    dV = np.dot(z.T,(y_train - predictions)) \n    dZ = np.dot(np.dot(np.dot((y_train - predictions), V.T).T, z),(1-z.T)) #m x n matrix\n    dW = np.dot(X_train.T,dZ.T) \n    db = np.dot(np.dot(np.dot((y_train - predictions), V.T).T, z), (1-z.T)).T.sum(axis = 0)\n    dc = (y_train - predictions).sum(axis = 0)\n\n\n    W += a*dW.astype(float) \n    V += a*dV.astype(float) \n    b += a*db.astype(float)\n    c += a*dc.astype(float)\n\n    if j%100 == 0: #Every 100 iterations, print out the cost and accuracy\n        total = -np.dot(y_train.T, np.log(predictions))\n        cost = total.sum()\n        Accuracy = np.mean(np.round(predictions) == y_train)\n        print(cost, Accuracy)\n\n\nprint(\" \")\nprint(\"Final Cost and Accuracy of training data: \")\nprint(cost, Accuracy)\n\n#Applying the model to the test data. The X_test data must be put through the softmax function and compared to y_test\n\n#feed forward\nz = np.dot(X_test,W) + b[0]\nz = 1/(1 + np.exp(-z.astype(float)))\ntest_predictions = np.exp(np.dot(z,V) + c[0])\n\n#softmax\nfor i in range(test_predictions.shape[0]):\n    test_predictions[i,:] = test_predictions[i,:]/np.sum(test_predictions[i,:])\n\ntest_Acc = np.mean(np.round(test_predictions) == y_test)\ntest_total = -np.dot(y_test.T, np.log(test_predictions))\ntest_cost = total.sum()\n\nprint(\" \")\nprint(\"Cost and Accuracy of testing data: \")\nprint(test_cost, test_Acc)\n\ndef classify(SLen, SWid, PLen, PWid):\n    X = np.array([SLen, SWid, PLen, PWid]).reshape(1,-1) #Converting to 2D matrix for calculations\n    z = np.dot(X,W) + b[0]\n    z = 1/(1 + np.exp(-z.astype(float)))\n    test_predictions = np.exp(np.dot(z,V) + c[0])\n\n    #softmax\n    for i in range(test_predictions.shape[0]):\n        test_predictions[i,:] = test_predictions[i,:]/np.sum(test_predictions[i,:])\n\n    test_predictions = np.round(test_predictions)[0] #reshaping back to 1D matrix\n    j = np.where(test_predictions == 1)[0][0]\n\n    return nameOfTargets[j]\n\nprint(classify(4.7, 3.2, 1.3, 0.2)\n</code></pre>\n <machine-learning><classification><python><p>The function for the classifier does not standardize the data, which is required for the model to make predictions because standardized data was used to train it. Standardizing the input data solves the problem.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "52025",
                "question_votes:": "1",
                "question_text:": "<p>I'm a high school senior who is very new to making neural networks. I've been using the Iris Flower dataset (<a href=\"https://www.kaggle.com/arshid/iris-flower-dataset\" rel=\"nofollow noreferrer\">https://www.kaggle.com/arshid/iris-flower-dataset</a>) to build my neural network. My model gets above 90% accuracy for both the training and the testing data, however when I made my classifier using the weights and biased terms from the model, the classifier always classifies the data as \"Iris - Virginica\". I am not sure what the problem is, and any help would be appreciated. It should be noted that I want to make the neural network myself using feed forward, backpropagation, gradient descent, etc. I do not want to use an existing classifier from a well-known library (e,g KNeighbors from SKLearn). My code is below.</p>\n\n<pre><code>#Full Code\n\n#importing necessary libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv(\"Iris.csv\") #loading the data into Python\ndf.head()#checking the contents to manipulate\n\n#Preprocessing the data (making the features and the targets)\n\nX = np.asmatrix(np.copy(df))[:,:5] #getting all the columns of the feature data\nX = np.delete(X, 0, axis = 1) #dropping column of index 0 because it is \"id\".\n\nnameOfTargets = df.Species.unique() #Getting the unique values of the target column for one hot encoding\n\nY_data = [] #Empty list that will eventually become target data\nfor i in df.iloc[:,5]:\n    for j in range(nameOfTargets.shape[0]): #for j from 0 to N, where N is the number of items in nameOfTargets\n        if i == nameOfTargets[j]:       \n            Y_data.append(j)\n    #The index number of the item in nameOfTargets is how they will be represented \n        #in the target data. I.E if the value of the target is equal to the FIRST \n        #item of nameOfTargets, the value is represented by the item's INDEX (0).\n\nN = len(Y_data) #Getting the number of items in the dataset\nY = np.zeros(N*nameOfTargets.shape[0]).reshape(N,nameOfTargets.shape[0]) \n#Making the target matrix. The number of rows = number of subjects, number of columns = number of unique targets\n\n\nfor i in range(N): #One Hot Encoding. After the loop finishes, Y will be the final target matrix.\n    t = Y_data[i]\n    Y[i,t] = 1\n\n\n#Standardizing values in the feature matrix X\nfor i in range(X.shape[1]):\n    X[:,i] = (X[:,i].astype(float) - np.mean(X[:,i].astype(float)))/np.std(X[:,i].astype(float))\n\n\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 42) #Splitting the data into testing data and training data\n\n\n#Deep Learning\n\nnp.random.seed(1) #making sure the weights are the same every time the cell is rerun (still random)\nN,D = X_train.shape #N = num subjects, D = num features\nM = 100 #num hidden nodes of the first hidden layer\nK = nameOfTargets.shape[0] #number of outputs\n\niteration_num = 1000 #Number of times gradient descent will be performed\na = 0.02 #learning rate\n\n#creating the weights\nW = np.random.randn(D*M).reshape(D,M)\nV = np.random.randn(M*K).reshape(M,K)\n\n\n#creating the biased terms\nb = np.random.randn(M).reshape(1,M)\nb_ones = np.ones(N).reshape(N,1)\nb = np.dot(b_ones,b)\n\nc = np.random.randn(K).reshape(1,K)\nc_ones = np.ones(N).reshape(N,1)\nc = np.dot(c_ones, c)\n\nfor j in range(iteration_num): #Back Propagation\n\n    #feed forward\n    z = np.dot(X_train,W) + b\n    z = 1/(1 + np.exp(-z.astype(float)))\n    predictions = np.exp(np.dot(z,V) + c)\n\n    #softmax\n    for i in range(predictions.shape[0]):\n        predictions[i,:] = predictions[i,:]/np.sum(predictions[i,:])\n\n\n    #gradient descent\n    dV = np.dot(z.T,(y_train - predictions)) \n    dZ = np.dot(np.dot(np.dot((y_train - predictions), V.T).T, z),(1-z.T)) #m x n matrix\n    dW = np.dot(X_train.T,dZ.T) \n    db = np.dot(np.dot(np.dot((y_train - predictions), V.T).T, z), (1-z.T)).T.sum(axis = 0)\n    dc = (y_train - predictions).sum(axis = 0)\n\n\n    W += a*dW.astype(float) \n    V += a*dV.astype(float) \n    b += a*db.astype(float)\n    c += a*dc.astype(float)\n\n    if j%100 == 0: #Every 100 iterations, print out the cost and accuracy\n        total = -np.dot(y_train.T, np.log(predictions))\n        cost = total.sum()\n        Accuracy = np.mean(np.round(predictions) == y_train)\n        print(cost, Accuracy)\n\n\nprint(\" \")\nprint(\"Final Cost and Accuracy of training data: \")\nprint(cost, Accuracy)\n\n#Applying the model to the test data. The X_test data must be put through the softmax function and compared to y_test\n\n#feed forward\nz = np.dot(X_test,W) + b[0]\nz = 1/(1 + np.exp(-z.astype(float)))\ntest_predictions = np.exp(np.dot(z,V) + c[0])\n\n#softmax\nfor i in range(test_predictions.shape[0]):\n    test_predictions[i,:] = test_predictions[i,:]/np.sum(test_predictions[i,:])\n\ntest_Acc = np.mean(np.round(test_predictions) == y_test)\ntest_total = -np.dot(y_test.T, np.log(test_predictions))\ntest_cost = total.sum()\n\nprint(\" \")\nprint(\"Cost and Accuracy of testing data: \")\nprint(test_cost, test_Acc)\n\ndef classify(SLen, SWid, PLen, PWid):\n    X = np.array([SLen, SWid, PLen, PWid]).reshape(1,-1) #Converting to 2D matrix for calculations\n    z = np.dot(X,W) + b[0]\n    z = 1/(1 + np.exp(-z.astype(float)))\n    test_predictions = np.exp(np.dot(z,V) + c[0])\n\n    #softmax\n    for i in range(test_predictions.shape[0]):\n        test_predictions[i,:] = test_predictions[i,:]/np.sum(test_predictions[i,:])\n\n    test_predictions = np.round(test_predictions)[0] #reshaping back to 1D matrix\n    j = np.where(test_predictions == 1)[0][0]\n\n    return nameOfTargets[j]\n\nprint(classify(4.7, 3.2, 1.3, 0.2)\n</code></pre>\n",
                "tags": "<machine-learning><classification><python>",
                "answers": [
                    [
                        "52365",
                        "2",
                        "52025",
                        "",
                        "",
                        "<p>The function for the classifier does not standardize the data, which is required for the model to make predictions because standardized data was used to train it. Standardizing the input data solves the problem.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11337",
            "_score": 7.557177,
            "_source": {
                "title": "cannot use sklearn.naive_bayes MultinomialNB to predict from one attribute",
                "content": "cannot use sklearn.naive_bayes MultinomialNB to predict from one attribute <p>I tried to create a simple example for Naive Bayes by learning from one attribute.  It seems like I cannot use <code>sklearn.naive_bayes.MultinomialNB</code> to predict from one attribute.  This is because the <code>predict_proba</code> is the same for every input.</p>\n\n<p>Here is the code:</p>\n\n<pre><code>import numpy as np\nX = np.array([1, 1, 1, 0, 0, 1, 1])\nX = X.reshape(-1,1)\ny = np.array([0, 0, 0, 0, 1, 1, 1])\n\nfrom sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB()\nclf.fit(X, y)\n\nprint(clf.predict(X))\nprint(clf.predict_proba(X))\n</code></pre>\n\n<p>and its result.</p>\n\n<pre><code>[0 0 0 0 0 0 0]\n[[0.57142857 0.42857143]\n [0.57142857 0.42857143]\n [0.57142857 0.42857143]\n [0.57142857 0.42857143]\n [0.57142857 0.42857143]\n [0.57142857 0.42857143]\n [0.57142857 0.42857143]]\n</code></pre>\n <scikit-learn><p>If your problem is shaped as you stated, you might need to reconsider your Naive Bayes model. MultinomialNB does not seem to be appropriate for your case. You can rather use the Naive Bayes classifier that uses the gaussian distribution.</p>\n\n<pre><code>from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X, y)\nprint(gnb.predict(X))\nprint(gnb.predict_proba(X))\n</code></pre>\n",
                "codes": [
                    [
                        "from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X, y)\nprint(gnb.predict(X))\nprint(gnb.predict_proba(X))\n"
                    ]
                ],
                "question_id:": "40018",
                "question_votes:": "1",
                "question_text:": "<p>I tried to create a simple example for Naive Bayes by learning from one attribute.  It seems like I cannot use <code>sklearn.naive_bayes.MultinomialNB</code> to predict from one attribute.  This is because the <code>predict_proba</code> is the same for every input.</p>\n\n<p>Here is the code:</p>\n\n<pre><code>import numpy as np\nX = np.array([1, 1, 1, 0, 0, 1, 1])\nX = X.reshape(-1,1)\ny = np.array([0, 0, 0, 0, 1, 1, 1])\n\nfrom sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB()\nclf.fit(X, y)\n\nprint(clf.predict(X))\nprint(clf.predict_proba(X))\n</code></pre>\n\n<p>and its result.</p>\n\n<pre><code>[0 0 0 0 0 0 0]\n[[0.57142857 0.42857143]\n [0.57142857 0.42857143]\n [0.57142857 0.42857143]\n [0.57142857 0.42857143]\n [0.57142857 0.42857143]\n [0.57142857 0.42857143]\n [0.57142857 0.42857143]]\n</code></pre>\n",
                "tags": "<scikit-learn>",
                "answers": [
                    [
                        "40023",
                        "2",
                        "40018",
                        "",
                        "",
                        "<p>If your problem is shaped as you stated, you might need to reconsider your Naive Bayes model. MultinomialNB does not seem to be appropriate for your case. You can rather use the Naive Bayes classifier that uses the gaussian distribution.</p>\n\n<pre><code>from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X, y)\nprint(gnb.predict(X))\nprint(gnb.predict_proba(X))\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16242",
            "_score": 7.4295588,
            "_source": {
                "title": "TensorFlow: how to restore pre-trained meta model and pass it's weights and biases to the optimizer?",
                "content": "TensorFlow: how to restore pre-trained meta model and pass it's weights and biases to the optimizer? <p>I trained a model on a specific dataset and saved it as a meta, I want to restore the model and use its weights and biases on another dataset the code isn't mine but I'm trying to restore the architecture after it was saved to metafile, the TGCN was designed by the lehaifeng to predict speeds on edges of a graph.<br>\nYou can find the source code belongs to <a href=\"https://github.com/lehaifeng\" rel=\"nofollow noreferrer\">lehaifeng</a> and his teammates through the following link:</p>\n\n<p><a href=\"https://github.com/lehaifeng/T-GCN\" rel=\"nofollow noreferrer\">https://github.com/lehaifeng/T-GCN</a></p>\n\n<p>I tried many workarounds and ran into numerous errors I can't post all of them here, is it possible to do transfer learning using the model I post above because I can't use this architecture on a new dataset  </p>\n\n<p>I have tried using to <code>tf.get_collection(tf.GraphKeys.GLOBAL/TRAINABLE_VARIABLES)</code> to set the global variable to the restored model global variables and then pass it to the optimizer it's telling me there are no variables in the restored graph.</p>\n\n<p>one other problem is the model can't iterate over a tensor unless I'm using eager execution and that I have to use tf.map_fn, you can't use eager execution when calling placeholders from the trained model as tensor using <code>graph.get_tensor_by_name()</code></p>\n\n<pre><code>import pickle as pkl\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport math\nimport os\nimport numpy.linalg as la\nfrom input_data import preprocess_data,load_doha_data,load_los_data\nfrom tgcn import tgcnCell\n###from gru import GRUCell \n\nfrom visualization import plot_result,plot_error\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nimport matplotlib.pyplot as plt\nimport time\n\ntime_start = time.time()\n####Settings####\nflags = tf.app.flags\nFLAGS = flags.FLAGS\nflags.DEFINE_float('learning_rate', 0.003, 'Initial learning rate.')\nflags.DEFINE_integer('training_epoch', 10, 'Number of epochs to train.')\nflags.DEFINE_integer('gru_units', 100, 'hidden units of gru.')\nflags.DEFINE_integer('seq_len',4  , '  time length of inputs.')\nflags.DEFINE_integer('pre_len', 1, 'time length of prediction.')\nflags.DEFINE_float('train_rate', 0.8, 'rate of training set.')\nflags.DEFINE_integer('batch_size', 64, 'batch size.')\nflags.DEFINE_string('dataset', 'los', 'doha or los.')\nflags.DEFINE_string('model_name', 'tgcn', 'tgcn')\nmodel_name = FLAGS.model_name\ndata_name = FLAGS.dataset\ntrain_rate =  FLAGS.train_rate\nseq_len = FLAGS.seq_len\noutput_dim = pre_len = FLAGS.pre_len\nbatch_size = FLAGS.batch_size\nlr = FLAGS.learning_rate\ntraining_epoch = FLAGS.training_epoch\ngru_units = FLAGS.gru_units\n\n###### load data ######\nif data_name == 'los':\ndata, adj = load_los_data('los')\n\ntime_len = data.shape[0]\nprint(time_len)\nnum_nodes = data.shape[1]\nprint(num_nodes)\ndata1 =np.mat(data,dtype=np.float32)\n\n#### normalization\nmax_value = np.max(data1)\ndata1  = data1/max_value\ntrainX, trainY, testX, testY = preprocess_data(data1, time_len, train_rate, seq_len, pre_len)\n\ntotalbatch = int(trainX.shape[0]/batch_size)\ntraining_data_count = len(trainX)\n\ndef TGCN(_X, _weights, _biases):\n###\ncell_1 = tgcnCell(gru_units, adj, num_nodes=num_nodes)\ncell = tf.nn.rnn_cell.MultiRNNCell([cell_1], state_is_tuple=True)\n_X = tf.unstack(_X, axis=1)\noutputs, states = tf.nn.static_rnn(cell, _X, dtype=tf.float32)\nm = []\nfor i in outputs:\n    o = tf.reshape(i,shape=[-1,num_nodes,gru_units])\n    o = tf.reshape(o,shape=[-1,gru_units])\n    m.append(o)\nlast_output = m[-1]\noutput = tf.matmul(last_output, _weights['out2']) + _biases['out2']\noutput = tf.reshape(output,shape=[-1,num_nodes,pre_len])\noutput = tf.transpose(output, perm=[0,2,1])\noutput = tf.reshape(output, shape=[-1,num_nodes])\nreturn output, m, states\n\n###### placeholders ######\ninputs = tf.placeholder(tf.float32, shape=[None, seq_len, num_nodes],name=\"inputs1\")\nlabels = tf.placeholder(tf.float32, shape=[None, pre_len, num_nodes],name=\"lables1\")\n\n# Graph weights \nweights = {\n'out2': tf.Variable(tf.random_normal([gru_units, pre_len], mean=1.0), name='weight_o')}\nbiases = {\n'out2': tf.Variable(tf.random_normal([pre_len]),name='bias_o')}\n\nif model_name == 'tgcn':\npred,ttts,ttto = TGCN(inputs, weights, biases)\n\ny_pred = pred\n\n\n###### optimizer ######\nlambda_loss = 0.0010\nLreg = lambda_loss * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\nlabel = tf.reshape(labels, [-1,num_nodes])\n##loss\nloss = tf.reduce_mean(tf.nn.l2_loss(y_pred-label) + Lreg)\n##rmse\nerror = tf.sqrt(tf.reduce_mean(tf.square(y_pred-label)))\noptimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n\n###### Initialize session ######\nvariables = tf.global_variables()\n\n#Create a saver object which will save all the variables\nsaver = tf.train.Saver(tf.global_variables())\ninit = tf.global_variables_initializer()\nsess = tf.Session()\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\nsess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\nsess.run(init)\n\n\nout = 'out2/%s'%(model_name)\n#out = 'out/%s_%s'%(model_name,'perturbation')\npath1 = '%s_%s_lr%r_batch%r_unit%r_seq%r_pre%r_epoch%r'%(model_name,data_name,lr,batch_size,gru_units,seq_len,pre_len,training_epoch)\npath = os.path.join(out,path1)\nif not os.path.exists(path):\nos.makedirs(path)\n\n###### evaluation ######\ndef evaluation(a,b):\nrmse = math.sqrt(mean_squared_error(a,b))\nmae = mean_absolute_error(a, b)\nF_norm = la.norm(a-b,'fro')/la.norm(a,'fro')\nr2 = 1-((a-b)**2).sum()/((a-a.mean())**2).sum()\nvar = 1-(np.var(a-b))/np.var(a)\nreturn rmse, mae, 1-F_norm, r2, var\n\n\nx_axe,batch_loss,batch_rmse,batch_pred = [], [], [], []\ntest_loss,test_rmse,test_mae,test_acc,test_r2,test_var,test_pred = [],[],[],[],[],[],[]\n\nfor epoch in range(training_epoch):\nfor m in range(totalbatch):\n    mini_batch = trainX[m * batch_size : (m+1) * batch_size]\n    mini_label = trainY[m * batch_size : (m+1) * batch_size]\n    _, loss1, rmse1, train_output = sess.run([optimizer, loss, error, y_pred],\n                                             feed_dict = {inputs:mini_batch, labels:mini_label})\n    batch_loss.append(loss1)\n    batch_rmse.append(rmse1 * max_value)\n\n # Test completely at every epoch\n loss2, rmse2, test_output = sess.run([loss, error, y_pred],\n                                     feed_dict = {inputs:testX, labels:testY})\ntest_label = np.reshape(testY,[-1,num_nodes])\nrmse, mae, acc, r2_score, var_score = evaluation(test_label, test_output)\ntest_label1 = test_label * max_value\ntest_output1 = test_output * max_value\ntest_loss.append(loss2)\ntest_rmse.append(rmse * max_value)\ntest_mae.append(mae * max_value)\ntest_acc.append(acc)\ntest_r2.append(r2_score)\ntest_var.append(var_score)\ntest_pred.append(test_output1)\n\nprint('Iter:{}'.format(epoch),\n      'train_rmse:{:.4}'.format(batch_rmse[-1]),\n     'test_loss:{:.4}'.format(loss2),\n    'test_rmse:{:.4}'.format(rmse),\n     'test_acc:{:.4}'.format(acc))\n\nsaver.save(sess, './TGCNpretrain.model')\nprint (tf.contrib.framework.list_variables('./TGCNpretrain.model'))\ntime_end = time.time()\nprint(time_end-time_start,'s')\n</code></pre>\n\n<p>So to sum my problem how do I restore and load this model on another data set, you can download all other code callback functions and data sets from the source code link make sure you change paths so that the main.py can import its input matrices. thanks in advance</p>\n\n<p>p.s I'm an extreme beginner to Tesnorflow in particular and a beginner in Python in general. so pardon my inexperience in expressing the problem.</p>\n <tensorflow><convnet><recurrent-neural-net><transfer-learning>",
                "codes": [],
                "question_id:": "53664",
                "question_votes:": "1",
                "question_text:": "<p>I trained a model on a specific dataset and saved it as a meta, I want to restore the model and use its weights and biases on another dataset the code isn't mine but I'm trying to restore the architecture after it was saved to metafile, the TGCN was designed by the lehaifeng to predict speeds on edges of a graph.<br>\nYou can find the source code belongs to <a href=\"https://github.com/lehaifeng\" rel=\"nofollow noreferrer\">lehaifeng</a> and his teammates through the following link:</p>\n\n<p><a href=\"https://github.com/lehaifeng/T-GCN\" rel=\"nofollow noreferrer\">https://github.com/lehaifeng/T-GCN</a></p>\n\n<p>I tried many workarounds and ran into numerous errors I can't post all of them here, is it possible to do transfer learning using the model I post above because I can't use this architecture on a new dataset  </p>\n\n<p>I have tried using to <code>tf.get_collection(tf.GraphKeys.GLOBAL/TRAINABLE_VARIABLES)</code> to set the global variable to the restored model global variables and then pass it to the optimizer it's telling me there are no variables in the restored graph.</p>\n\n<p>one other problem is the model can't iterate over a tensor unless I'm using eager execution and that I have to use tf.map_fn, you can't use eager execution when calling placeholders from the trained model as tensor using <code>graph.get_tensor_by_name()</code></p>\n\n<pre><code>import pickle as pkl\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport math\nimport os\nimport numpy.linalg as la\nfrom input_data import preprocess_data,load_doha_data,load_los_data\nfrom tgcn import tgcnCell\n###from gru import GRUCell \n\nfrom visualization import plot_result,plot_error\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nimport matplotlib.pyplot as plt\nimport time\n\ntime_start = time.time()\n####Settings####\nflags = tf.app.flags\nFLAGS = flags.FLAGS\nflags.DEFINE_float('learning_rate', 0.003, 'Initial learning rate.')\nflags.DEFINE_integer('training_epoch', 10, 'Number of epochs to train.')\nflags.DEFINE_integer('gru_units', 100, 'hidden units of gru.')\nflags.DEFINE_integer('seq_len',4  , '  time length of inputs.')\nflags.DEFINE_integer('pre_len', 1, 'time length of prediction.')\nflags.DEFINE_float('train_rate', 0.8, 'rate of training set.')\nflags.DEFINE_integer('batch_size', 64, 'batch size.')\nflags.DEFINE_string('dataset', 'los', 'doha or los.')\nflags.DEFINE_string('model_name', 'tgcn', 'tgcn')\nmodel_name = FLAGS.model_name\ndata_name = FLAGS.dataset\ntrain_rate =  FLAGS.train_rate\nseq_len = FLAGS.seq_len\noutput_dim = pre_len = FLAGS.pre_len\nbatch_size = FLAGS.batch_size\nlr = FLAGS.learning_rate\ntraining_epoch = FLAGS.training_epoch\ngru_units = FLAGS.gru_units\n\n###### load data ######\nif data_name == 'los':\ndata, adj = load_los_data('los')\n\ntime_len = data.shape[0]\nprint(time_len)\nnum_nodes = data.shape[1]\nprint(num_nodes)\ndata1 =np.mat(data,dtype=np.float32)\n\n#### normalization\nmax_value = np.max(data1)\ndata1  = data1/max_value\ntrainX, trainY, testX, testY = preprocess_data(data1, time_len, train_rate, seq_len, pre_len)\n\ntotalbatch = int(trainX.shape[0]/batch_size)\ntraining_data_count = len(trainX)\n\ndef TGCN(_X, _weights, _biases):\n###\ncell_1 = tgcnCell(gru_units, adj, num_nodes=num_nodes)\ncell = tf.nn.rnn_cell.MultiRNNCell([cell_1], state_is_tuple=True)\n_X = tf.unstack(_X, axis=1)\noutputs, states = tf.nn.static_rnn(cell, _X, dtype=tf.float32)\nm = []\nfor i in outputs:\n    o = tf.reshape(i,shape=[-1,num_nodes,gru_units])\n    o = tf.reshape(o,shape=[-1,gru_units])\n    m.append(o)\nlast_output = m[-1]\noutput = tf.matmul(last_output, _weights['out2']) + _biases['out2']\noutput = tf.reshape(output,shape=[-1,num_nodes,pre_len])\noutput = tf.transpose(output, perm=[0,2,1])\noutput = tf.reshape(output, shape=[-1,num_nodes])\nreturn output, m, states\n\n###### placeholders ######\ninputs = tf.placeholder(tf.float32, shape=[None, seq_len, num_nodes],name=\"inputs1\")\nlabels = tf.placeholder(tf.float32, shape=[None, pre_len, num_nodes],name=\"lables1\")\n\n# Graph weights \nweights = {\n'out2': tf.Variable(tf.random_normal([gru_units, pre_len], mean=1.0), name='weight_o')}\nbiases = {\n'out2': tf.Variable(tf.random_normal([pre_len]),name='bias_o')}\n\nif model_name == 'tgcn':\npred,ttts,ttto = TGCN(inputs, weights, biases)\n\ny_pred = pred\n\n\n###### optimizer ######\nlambda_loss = 0.0010\nLreg = lambda_loss * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\nlabel = tf.reshape(labels, [-1,num_nodes])\n##loss\nloss = tf.reduce_mean(tf.nn.l2_loss(y_pred-label) + Lreg)\n##rmse\nerror = tf.sqrt(tf.reduce_mean(tf.square(y_pred-label)))\noptimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n\n###### Initialize session ######\nvariables = tf.global_variables()\n\n#Create a saver object which will save all the variables\nsaver = tf.train.Saver(tf.global_variables())\ninit = tf.global_variables_initializer()\nsess = tf.Session()\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\nsess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\nsess.run(init)\n\n\nout = 'out2/%s'%(model_name)\n#out = 'out/%s_%s'%(model_name,'perturbation')\npath1 = '%s_%s_lr%r_batch%r_unit%r_seq%r_pre%r_epoch%r'%(model_name,data_name,lr,batch_size,gru_units,seq_len,pre_len,training_epoch)\npath = os.path.join(out,path1)\nif not os.path.exists(path):\nos.makedirs(path)\n\n###### evaluation ######\ndef evaluation(a,b):\nrmse = math.sqrt(mean_squared_error(a,b))\nmae = mean_absolute_error(a, b)\nF_norm = la.norm(a-b,'fro')/la.norm(a,'fro')\nr2 = 1-((a-b)**2).sum()/((a-a.mean())**2).sum()\nvar = 1-(np.var(a-b))/np.var(a)\nreturn rmse, mae, 1-F_norm, r2, var\n\n\nx_axe,batch_loss,batch_rmse,batch_pred = [], [], [], []\ntest_loss,test_rmse,test_mae,test_acc,test_r2,test_var,test_pred = [],[],[],[],[],[],[]\n\nfor epoch in range(training_epoch):\nfor m in range(totalbatch):\n    mini_batch = trainX[m * batch_size : (m+1) * batch_size]\n    mini_label = trainY[m * batch_size : (m+1) * batch_size]\n    _, loss1, rmse1, train_output = sess.run([optimizer, loss, error, y_pred],\n                                             feed_dict = {inputs:mini_batch, labels:mini_label})\n    batch_loss.append(loss1)\n    batch_rmse.append(rmse1 * max_value)\n\n # Test completely at every epoch\n loss2, rmse2, test_output = sess.run([loss, error, y_pred],\n                                     feed_dict = {inputs:testX, labels:testY})\ntest_label = np.reshape(testY,[-1,num_nodes])\nrmse, mae, acc, r2_score, var_score = evaluation(test_label, test_output)\ntest_label1 = test_label * max_value\ntest_output1 = test_output * max_value\ntest_loss.append(loss2)\ntest_rmse.append(rmse * max_value)\ntest_mae.append(mae * max_value)\ntest_acc.append(acc)\ntest_r2.append(r2_score)\ntest_var.append(var_score)\ntest_pred.append(test_output1)\n\nprint('Iter:{}'.format(epoch),\n      'train_rmse:{:.4}'.format(batch_rmse[-1]),\n     'test_loss:{:.4}'.format(loss2),\n    'test_rmse:{:.4}'.format(rmse),\n     'test_acc:{:.4}'.format(acc))\n\nsaver.save(sess, './TGCNpretrain.model')\nprint (tf.contrib.framework.list_variables('./TGCNpretrain.model'))\ntime_end = time.time()\nprint(time_end-time_start,'s')\n</code></pre>\n\n<p>So to sum my problem how do I restore and load this model on another data set, you can download all other code callback functions and data sets from the source code link make sure you change paths so that the main.py can import its input matrices. thanks in advance</p>\n\n<p>p.s I'm an extreme beginner to Tesnorflow in particular and a beginner in Python in general. so pardon my inexperience in expressing the problem.</p>\n",
                "tags": "<tensorflow><convnet><recurrent-neural-net><transfer-learning>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14382",
            "_score": 7.4083767,
            "_source": {
                "title": "How to build an image dataset for CNN?",
                "content": "How to build an image dataset for CNN? <p>I don't understand how images are actually fed into a CNN? If I have a directory containing a few thousand images, what steps do I need to take in order to feed them to a neural network (for instance resizing, grey scale, labeling, etc) I don't understand how even the labeling of an image works. What would this dataset actually look like? Or can you not look at it at all (in a summarized form, I'm thinking something like a table)?</p>\n <machine-learning><python><neural-network><keras><cnn><p>This is a very packed question. Let's try to go through it and I will try to provide some example for image processing using a CNN. </p>\n\n<h1>Pre-processing the data</h1>\n\n<p>Pre-processing the data such as resizing, and grey scale is the first step of your machine learning pipeline. Most deep learning frameworks will require your training data to all have the same shape. So it is best to resize your images to some standard. </p>\n\n<p>Whenever training any kind of machine learning model it is important to remember the bias variance trade-off. The more complex the model the harder it will be to train it. That means it is best to limit the number of model parameters in your model. You can lower the number of inputs to your model by downsampling the images. Greyscaling is often used for the same reason. If the colors in the images do not contain any distinguishing information then you can reduce the number of inputs by a third by greyscaling. </p>\n\n<p>There are a number of other pre-processing methods which can be used depending on your data. It is also a good idea to do some data augmentation, this is altering your input data slightly without changing the resulting label to increase the number of instances you have to train your model.</p>\n\n<h1>How to structure the data?</h1>\n\n<p>The shape of the variable which you will use as the input for your CNN will depend on the package you choose. I prefer using tensorflow, which is developed by Google. If you are planning on using a pretty standard architecture, then there is a very useful wrapper library named Keras which will help make designing and training a CNN very easy.</p>\n\n<p>When using tensorflow you will want to get your set of images into a numpy matrix. The first dimension is your instances, then your image dimensions and finally the last dimension is for <code>channels</code>.</p>\n\n<p>So for example if you are using MNIST data as shown below, then you are working with greyscale images which each have dimensions 28 by 28. Then the numpy matrix shape that you would feed into your deep learning model would be (n, 28, 28, 1), where <span class=\"math-container\">$n$</span> is the number of images you have in your dataset.</p>\n\n<p><a href=\"https://i.stack.imgur.com/4V7iv.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/4V7iv.png\" alt=\"enter image description here\"></a></p>\n\n<h1>How to label images?</h1>\n\n<p>For most data the labeling would need to be done manually. This is often named data collection and is the hardest and most expensive part of any machine learning solution. It is often best to either use readily available data, or to use less complex models and more pre-processing if the data is just unavailable.</p>\n\n<hr>\n\n<p>Here is an example of the use of a CNN for the MNIST dataset</p>\n\n<p>First we load the data </p>\n\n<pre><code>from keras.datasets import mnist\nimport numpy as np\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\nprint('Training data shape: ', x_train.shape)\nprint('Testing data shape : ', x_test.shape)\n</code></pre>\n\n<blockquote>\n  <p>Training data shape:  (60000, 28, 28) <br>Testing data shape :  (10000,\n  28, 28)</p>\n</blockquote>\n\n<pre><code>from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n</code></pre>\n\n<p>Then we need to reshape our data to add the channel dimension at the end of our numpy matrix. Furthermore, we will one-hot encode the labels. So you will have 10 output neurons, where each represent a different class.</p>\n\n<pre><code># The known number of output classes.\nnum_classes = 10\n\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test_reshaped = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n</code></pre>\n\n<p>Now we design our model</p>\n\n<pre><code>model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<p>Finally we can train the model</p>\n\n<pre><code>epochs = 4\nbatch_size = 128\n# Fit the model weights.\nmodel.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n</code></pre>\n<p>Dataset just consists of Features and Labels. Here features are your images and labels are the classes.</p>\n\n<p>There is a fit() method for every CNN model, which will take in Features and Labels, and performs training.</p>\n\n<p>for the first layer, you need to mention the input dimension of image, and the output layer should be a softmax (if you're doing classification) with dimension as the number of classes you have.</p>\n\n<pre><code>model = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same', input_shape=(64, 64, 3)))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=10)\n</code></pre>\n\n<p>The above is the code for training a Keras sequenctioal model.</p>\n\n<p>General Points:</p>\n\n<ol>\n<li>input_shape should be the dimension of X_train.</li>\n<li>You need to get this shape when you do X_train.shape (numpy)</li>\n<li>Convolutions are then applied with respective Activations</li>\n<li>Dropout and Pooling layers are optional.</li>\n<li>After the convolution layers, the data is flattened. using Flatten()</li>\n<li>Then it is sent to few Fully Connected layers</li>\n<li>The last but one layer should have the dimensions of number of classes</li>\n<li>Last layer will be softmax.</li>\n<li>Now, compile the model with the loss, optimizer and metric</li>\n<li>Then fit()</li>\n</ol>\n\n<p>Vote up ;) if you like it.</p>\n",
                "codes": [
                    [
                        "from keras.datasets import mnist\nimport numpy as np\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\nprint('Training data shape: ', x_train.shape)\nprint('Testing data shape : ', x_test.shape)\n",
                        "from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n",
                        "# The known number of output classes.\nnum_classes = 10\n\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test_reshaped = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n",
                        "model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n",
                        "epochs = 4\nbatch_size = 128\n# Fit the model weights.\nmodel.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n"
                    ],
                    [
                        "model = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same', input_shape=(64, 64, 3)))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=10)\n"
                    ]
                ],
                "question_id:": "48390",
                "question_votes:": "1",
                "question_text:": "<p>I don't understand how images are actually fed into a CNN? If I have a directory containing a few thousand images, what steps do I need to take in order to feed them to a neural network (for instance resizing, grey scale, labeling, etc) I don't understand how even the labeling of an image works. What would this dataset actually look like? Or can you not look at it at all (in a summarized form, I'm thinking something like a table)?</p>\n",
                "tags": "<machine-learning><python><neural-network><keras><cnn>",
                "answers": [
                    [
                        "48392",
                        "2",
                        "48390",
                        "",
                        "",
                        "<p>This is a very packed question. Let's try to go through it and I will try to provide some example for image processing using a CNN. </p>\n\n<h1>Pre-processing the data</h1>\n\n<p>Pre-processing the data such as resizing, and grey scale is the first step of your machine learning pipeline. Most deep learning frameworks will require your training data to all have the same shape. So it is best to resize your images to some standard. </p>\n\n<p>Whenever training any kind of machine learning model it is important to remember the bias variance trade-off. The more complex the model the harder it will be to train it. That means it is best to limit the number of model parameters in your model. You can lower the number of inputs to your model by downsampling the images. Greyscaling is often used for the same reason. If the colors in the images do not contain any distinguishing information then you can reduce the number of inputs by a third by greyscaling. </p>\n\n<p>There are a number of other pre-processing methods which can be used depending on your data. It is also a good idea to do some data augmentation, this is altering your input data slightly without changing the resulting label to increase the number of instances you have to train your model.</p>\n\n<h1>How to structure the data?</h1>\n\n<p>The shape of the variable which you will use as the input for your CNN will depend on the package you choose. I prefer using tensorflow, which is developed by Google. If you are planning on using a pretty standard architecture, then there is a very useful wrapper library named Keras which will help make designing and training a CNN very easy.</p>\n\n<p>When using tensorflow you will want to get your set of images into a numpy matrix. The first dimension is your instances, then your image dimensions and finally the last dimension is for <code>channels</code>.</p>\n\n<p>So for example if you are using MNIST data as shown below, then you are working with greyscale images which each have dimensions 28 by 28. Then the numpy matrix shape that you would feed into your deep learning model would be (n, 28, 28, 1), where <span class=\"math-container\">$n$</span> is the number of images you have in your dataset.</p>\n\n<p><a href=\"https://i.stack.imgur.com/4V7iv.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/4V7iv.png\" alt=\"enter image description here\"></a></p>\n\n<h1>How to label images?</h1>\n\n<p>For most data the labeling would need to be done manually. This is often named data collection and is the hardest and most expensive part of any machine learning solution. It is often best to either use readily available data, or to use less complex models and more pre-processing if the data is just unavailable.</p>\n\n<hr>\n\n<p>Here is an example of the use of a CNN for the MNIST dataset</p>\n\n<p>First we load the data </p>\n\n<pre><code>from keras.datasets import mnist\nimport numpy as np\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\nprint('Training data shape: ', x_train.shape)\nprint('Testing data shape : ', x_test.shape)\n</code></pre>\n\n<blockquote>\n  <p>Training data shape:  (60000, 28, 28) <br>Testing data shape :  (10000,\n  28, 28)</p>\n</blockquote>\n\n<pre><code>from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n</code></pre>\n\n<p>Then we need to reshape our data to add the channel dimension at the end of our numpy matrix. Furthermore, we will one-hot encode the labels. So you will have 10 output neurons, where each represent a different class.</p>\n\n<pre><code># The known number of output classes.\nnum_classes = 10\n\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test_reshaped = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n</code></pre>\n\n<p>Now we design our model</p>\n\n<pre><code>model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<p>Finally we can train the model</p>\n\n<pre><code>epochs = 4\nbatch_size = 128\n# Fit the model weights.\nmodel.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n</code></pre>\n",
                        "",
                        "2"
                    ],
                    [
                        "48391",
                        "2",
                        "48390",
                        "",
                        "",
                        "<p>Dataset just consists of Features and Labels. Here features are your images and labels are the classes.</p>\n\n<p>There is a fit() method for every CNN model, which will take in Features and Labels, and performs training.</p>\n\n<p>for the first layer, you need to mention the input dimension of image, and the output layer should be a softmax (if you're doing classification) with dimension as the number of classes you have.</p>\n\n<pre><code>model = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same', input_shape=(64, 64, 3)))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=10)\n</code></pre>\n\n<p>The above is the code for training a Keras sequenctioal model.</p>\n\n<p>General Points:</p>\n\n<ol>\n<li>input_shape should be the dimension of X_train.</li>\n<li>You need to get this shape when you do X_train.shape (numpy)</li>\n<li>Convolutions are then applied with respective Activations</li>\n<li>Dropout and Pooling layers are optional.</li>\n<li>After the convolution layers, the data is flattened. using Flatten()</li>\n<li>Then it is sent to few Fully Connected layers</li>\n<li>The last but one layer should have the dimensions of number of classes</li>\n<li>Last layer will be softmax.</li>\n<li>Now, compile the model with the loss, optimizer and metric</li>\n<li>Then fit()</li>\n</ol>\n\n<p>Vote up ;) if you like it.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9641",
            "_score": 7.396851,
            "_source": {
                "title": "why always predict same class for all input",
                "content": "why always predict same class for all input <pre><code>import numpy as np\nfrom sklearn import datasets as ds\n\niris = ds.load_iris()\nx = iris.data\ny1 = iris.target\n\nx = x / x.max()\ny1 = np.matrix(y1)\nnp.random.seed(1)\ny = np.zeros((y1.size, y1.max() + 1))\ny[np.arange(y1.size), y1] = 1\n\nclass NeuralNetwork(object):\n\n    def __init__(self):\n        self.inputSize = 4\n        self.outputSize = 3\n        self.hiddenSize = 5\n\n        self.W1 = np.random.randn(self.inputSize, self.hiddenSize) * 0.01\n        self.W2 = np.random.randn(self.hiddenSize, self.outputSize) * 0.01\n        self.b1 = np.random.randn(1, self.hiddenSize)\n        self.b2 = np.random.randn(1, self.outputSize)\n\n    def forward(self, x):\n        self.z = np.dot(x, self.W1) + self.b1\n        self.z2 = self.sigmoid(self.z)\n        self.z3 = np.dot(self.z2, self.W2) + self.b2\n        o = self.sigmoid(self.z3)\n        return o\n\n    def sigmoid(self, s):\n\n        return 1 / (1 + np.exp(-s))\n\n    def sigmoidPrime(self, s):\n\n        return s * (1 - s)\n\n    def backward(self, x, y, o):\n        l = 0.2\n        self.dz2 = y - o\n        self.dw2 = (1 / 150 * self.dz2.T.dot(self.z)).T\n\n        self.db2 = 1 / 150 * np.sum(self.dz2, axis=0).reshape(1, 3)\n\n        self.dz1 = 1 / 150 * self.W2.dot(self.dz2.T).T * self.sigmoidPrime(self.z)\n\n        self.dw1 = (1 / 150 * self.dz1.T.dot(x)).T\n\n        self.db1 = 1 / 150 * np.sum(self.dz1, axis=0).reshape(1, 5)\n\n        self.W1 = self.W1 - l * self.dw1\n\n        self.W2 = self.W2 - l * self.dw2\n\n        self.b1 = self.b1 - l * self.db1\n\n        self.b2 = self.b2 - l * self.db2\n\n    def train(self, x, y):\n        o = self.forward(x)\n        self.backward(x, y, o)\n</code></pre>\n\n<p>when I run this code it predicts always same class\nbut when I change backward function to this one:</p>\n\n<pre><code>def backward(self, x, y, o):\n    self.o_error = y - o\n    self.o_delta = self.o_error * self.sigmoidPrime(o)\n    self.z2_error = self.o_delta.dot(self.W2.T)\n    self.z2_delta = self.z2_error * self.sigmoidPrime(self.z2)\n    self.W1 += x.T.dot(self.z2_delta)\n    self.W2 += self.z2.T.dot(self.o_delta)\n</code></pre>\n\n<p>It predicts correctly. Why first function doesn't work correctly (backward)?</p>\n <machine-learning><python><neural-network><p>I solve this problem with adjusting learning rate and adding regularization and some optimization</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "34214",
                "question_votes:": "2",
                "question_text:": "<pre><code>import numpy as np\nfrom sklearn import datasets as ds\n\niris = ds.load_iris()\nx = iris.data\ny1 = iris.target\n\nx = x / x.max()\ny1 = np.matrix(y1)\nnp.random.seed(1)\ny = np.zeros((y1.size, y1.max() + 1))\ny[np.arange(y1.size), y1] = 1\n\nclass NeuralNetwork(object):\n\n    def __init__(self):\n        self.inputSize = 4\n        self.outputSize = 3\n        self.hiddenSize = 5\n\n        self.W1 = np.random.randn(self.inputSize, self.hiddenSize) * 0.01\n        self.W2 = np.random.randn(self.hiddenSize, self.outputSize) * 0.01\n        self.b1 = np.random.randn(1, self.hiddenSize)\n        self.b2 = np.random.randn(1, self.outputSize)\n\n    def forward(self, x):\n        self.z = np.dot(x, self.W1) + self.b1\n        self.z2 = self.sigmoid(self.z)\n        self.z3 = np.dot(self.z2, self.W2) + self.b2\n        o = self.sigmoid(self.z3)\n        return o\n\n    def sigmoid(self, s):\n\n        return 1 / (1 + np.exp(-s))\n\n    def sigmoidPrime(self, s):\n\n        return s * (1 - s)\n\n    def backward(self, x, y, o):\n        l = 0.2\n        self.dz2 = y - o\n        self.dw2 = (1 / 150 * self.dz2.T.dot(self.z)).T\n\n        self.db2 = 1 / 150 * np.sum(self.dz2, axis=0).reshape(1, 3)\n\n        self.dz1 = 1 / 150 * self.W2.dot(self.dz2.T).T * self.sigmoidPrime(self.z)\n\n        self.dw1 = (1 / 150 * self.dz1.T.dot(x)).T\n\n        self.db1 = 1 / 150 * np.sum(self.dz1, axis=0).reshape(1, 5)\n\n        self.W1 = self.W1 - l * self.dw1\n\n        self.W2 = self.W2 - l * self.dw2\n\n        self.b1 = self.b1 - l * self.db1\n\n        self.b2 = self.b2 - l * self.db2\n\n    def train(self, x, y):\n        o = self.forward(x)\n        self.backward(x, y, o)\n</code></pre>\n\n<p>when I run this code it predicts always same class\nbut when I change backward function to this one:</p>\n\n<pre><code>def backward(self, x, y, o):\n    self.o_error = y - o\n    self.o_delta = self.o_error * self.sigmoidPrime(o)\n    self.z2_error = self.o_delta.dot(self.W2.T)\n    self.z2_delta = self.z2_error * self.sigmoidPrime(self.z2)\n    self.W1 += x.T.dot(self.z2_delta)\n    self.W2 += self.z2.T.dot(self.o_delta)\n</code></pre>\n\n<p>It predicts correctly. Why first function doesn't work correctly (backward)?</p>\n",
                "tags": "<machine-learning><python><neural-network>",
                "answers": [
                    [
                        "34286",
                        "2",
                        "34214",
                        "",
                        "",
                        "<p>I solve this problem with adjusting learning rate and adding regularization and some optimization</p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17455",
            "_score": 7.361365,
            "_source": {
                "title": "How to modify display loss function for the Vectorised Feedforward network?",
                "content": "How to modify display loss function for the Vectorised Feedforward network? <p>I was practicing vectorising the baackprop for a basic NN and I tried modifying a code for binary classification which was originally written for multi class classification. Code:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.colors\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, mean_squared_error, log_loss\nfrom tqdm import tqdm_notebook \nimport seaborn as sns\nimport imageio\nimport time\nfrom IPython.display import HTML\n\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.datasets import make_blobs\n\ndata, labels = make_blobs(n_samples=1000, centers=4, n_features=2, random_state=0)\nlabels = np.mod(labels_orig, 2)\nX_train, X_val, Y_train, Y_val = train_test_split(data, labels, stratify=labels, random_state=0)\nY_train = Y_train.reshape(-1,1)\nW1 = np.random.randn(2,2)\nW2 = np.random.randn(2,1)\nclass FF_MultiClass_InputWeightVectorisedEx:\n\n  def __init__(self, W1, W2):\n    self.W1 = W1.copy() #(2,2)\n    self.W2 = W2.copy() #(2,1)\n    self.B1 = np.zeros((1,2))\n    self.B2 = np.zeros((1,1))\n\n  def sigmoid(self, X):\n    return 1.0/(1.0 + np.exp(-X))\n\n  def softmax(self, X):\n    exps = np.exp(X)\n    return exps / np.sum(exps, axis=1).reshape(-1,1)\n\n  def forward_pass(self, X):\n    self.A1 = np.matmul(X,self.W1) + self.B1 # (N, 2) * (2, 2) -&gt; (N, 2)\n    self.H1 = self.sigmoid(self.A1) # (N, 2)\n    self.A2 = np.matmul(self.H1, self.W2) + self.B2 # (N, 2) * (2, 1) -&gt; (N, 1)\n    self.H2 = self.softmax(self.A2) # (N, 1)\n    return self.H2\n\n  def grad_sigmoid(self, X):\n    return X*(1-X) \n\n  def grad(self, X, Y):\n    self.forward_pass(X)\n    m = X.shape[0]\n\n    self.dA2 = self.H2 - Y # (N, 1) - (N, 1) -&gt; (N, 1)\n    self.dW2 = np.matmul(self.H1.T, self.dA2) # (2, N) * (N, 1) -&gt; (2, 1)\n    self.dB2 = np.sum(self.dA2, axis=0).reshape(1, -1) # (N, 1) -&gt; (1, 1)\n    self.dH1 = np.matmul(self.dA2, self.W2.T) # (N, 1) * (1, 2) -&gt; (N, 2)\n    self.dA1 = np.multiply(self.dH1, self.grad_sigmoid(self.H1)) # (N, 2) .* (N, 2) -&gt; (N, 2)\n\n    self.dW1 = np.matmul(X.T, self.dA1) # (2, N) * (N, 2) -&gt; (2, 2)\n    self.dB1 = np.sum(self.dA1, axis=0).reshape(1, -1) # (N, 2) -&gt; (1, 2)\n\n\n  def fit(self, X, Y, epochs=1, learning_rate=1, display_loss=False):\n\n    if display_loss:\n      loss = {}\n\n    for i in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n      self.grad(X, Y) # X -&gt; (N, 2), Y -&gt; (N, 4)\n\n      m = X.shape[0]\n      self.W2 -= learning_rate * (self.dW2/m)\n      self.B2 -= learning_rate * (self.dB2/m)\n      self.W1 -= learning_rate * (self.dW1/m)\n      self.B1 -= learning_rate * (self.dB1/m)\n\n      if display_loss:\n        Y_pred = self.predict(X)\n        loss[i] = log_loss(Y, Y_pred)\n\n\n    if display_loss:\n      plt.plot(loss.values())\n      plt.xlabel('Epochs')\n      plt.ylabel('Log Loss')\n      plt.show()\n\n\n  def predict(self, X):\n    Y_pred = self.forward_pass(X)\n    return np.array(Y_pred).squeeze()\nmodels_init = [FF_MultiClass_InputWeightVectorisedEx(W1, W2)]\nmodels = []\nfor idx, model in enumerate(models_init, start=1):\n  tic = time.time()\n  ffsn_multi_specific = FF_MultiClass_InputWeightVectorisedEx(W1, W2)\n  ffsn_multi_specific.fit(X_train,Y_train,epochs=2000,learning_rate=.5,display_loss=True)\n  models.append(ffsn_multi_specific)\n  toc = time.time()\n  print(\"Time taken by model {}: {}\".format(idx, toc-tic))\n</code></pre>\n\n<p>The error I'm getting is for the <code>display loss</code> function in the above class which is </p>\n\n<pre><code>ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n</code></pre>\n\n<p>The original multi class classification display loss function was:</p>\n\n<pre><code>if display_loss:\n        Y_pred = self.predict(X)\n        loss[i] = log_loss(np.argmax(Y, axis=1), Y_pred)\n</code></pre>\n\n<p>As I am new to NN in general, can anyone tell what was the cause of this error and how can it be modififed?</p>\n <neural-network><classification>",
                "codes": [],
                "question_id:": "56254",
                "question_votes:": "",
                "question_text:": "<p>I was practicing vectorising the baackprop for a basic NN and I tried modifying a code for binary classification which was originally written for multi class classification. Code:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.colors\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, mean_squared_error, log_loss\nfrom tqdm import tqdm_notebook \nimport seaborn as sns\nimport imageio\nimport time\nfrom IPython.display import HTML\n\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.datasets import make_blobs\n\ndata, labels = make_blobs(n_samples=1000, centers=4, n_features=2, random_state=0)\nlabels = np.mod(labels_orig, 2)\nX_train, X_val, Y_train, Y_val = train_test_split(data, labels, stratify=labels, random_state=0)\nY_train = Y_train.reshape(-1,1)\nW1 = np.random.randn(2,2)\nW2 = np.random.randn(2,1)\nclass FF_MultiClass_InputWeightVectorisedEx:\n\n  def __init__(self, W1, W2):\n    self.W1 = W1.copy() #(2,2)\n    self.W2 = W2.copy() #(2,1)\n    self.B1 = np.zeros((1,2))\n    self.B2 = np.zeros((1,1))\n\n  def sigmoid(self, X):\n    return 1.0/(1.0 + np.exp(-X))\n\n  def softmax(self, X):\n    exps = np.exp(X)\n    return exps / np.sum(exps, axis=1).reshape(-1,1)\n\n  def forward_pass(self, X):\n    self.A1 = np.matmul(X,self.W1) + self.B1 # (N, 2) * (2, 2) -&gt; (N, 2)\n    self.H1 = self.sigmoid(self.A1) # (N, 2)\n    self.A2 = np.matmul(self.H1, self.W2) + self.B2 # (N, 2) * (2, 1) -&gt; (N, 1)\n    self.H2 = self.softmax(self.A2) # (N, 1)\n    return self.H2\n\n  def grad_sigmoid(self, X):\n    return X*(1-X) \n\n  def grad(self, X, Y):\n    self.forward_pass(X)\n    m = X.shape[0]\n\n    self.dA2 = self.H2 - Y # (N, 1) - (N, 1) -&gt; (N, 1)\n    self.dW2 = np.matmul(self.H1.T, self.dA2) # (2, N) * (N, 1) -&gt; (2, 1)\n    self.dB2 = np.sum(self.dA2, axis=0).reshape(1, -1) # (N, 1) -&gt; (1, 1)\n    self.dH1 = np.matmul(self.dA2, self.W2.T) # (N, 1) * (1, 2) -&gt; (N, 2)\n    self.dA1 = np.multiply(self.dH1, self.grad_sigmoid(self.H1)) # (N, 2) .* (N, 2) -&gt; (N, 2)\n\n    self.dW1 = np.matmul(X.T, self.dA1) # (2, N) * (N, 2) -&gt; (2, 2)\n    self.dB1 = np.sum(self.dA1, axis=0).reshape(1, -1) # (N, 2) -&gt; (1, 2)\n\n\n  def fit(self, X, Y, epochs=1, learning_rate=1, display_loss=False):\n\n    if display_loss:\n      loss = {}\n\n    for i in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n      self.grad(X, Y) # X -&gt; (N, 2), Y -&gt; (N, 4)\n\n      m = X.shape[0]\n      self.W2 -= learning_rate * (self.dW2/m)\n      self.B2 -= learning_rate * (self.dB2/m)\n      self.W1 -= learning_rate * (self.dW1/m)\n      self.B1 -= learning_rate * (self.dB1/m)\n\n      if display_loss:\n        Y_pred = self.predict(X)\n        loss[i] = log_loss(Y, Y_pred)\n\n\n    if display_loss:\n      plt.plot(loss.values())\n      plt.xlabel('Epochs')\n      plt.ylabel('Log Loss')\n      plt.show()\n\n\n  def predict(self, X):\n    Y_pred = self.forward_pass(X)\n    return np.array(Y_pred).squeeze()\nmodels_init = [FF_MultiClass_InputWeightVectorisedEx(W1, W2)]\nmodels = []\nfor idx, model in enumerate(models_init, start=1):\n  tic = time.time()\n  ffsn_multi_specific = FF_MultiClass_InputWeightVectorisedEx(W1, W2)\n  ffsn_multi_specific.fit(X_train,Y_train,epochs=2000,learning_rate=.5,display_loss=True)\n  models.append(ffsn_multi_specific)\n  toc = time.time()\n  print(\"Time taken by model {}: {}\".format(idx, toc-tic))\n</code></pre>\n\n<p>The error I'm getting is for the <code>display loss</code> function in the above class which is </p>\n\n<pre><code>ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n</code></pre>\n\n<p>The original multi class classification display loss function was:</p>\n\n<pre><code>if display_loss:\n        Y_pred = self.predict(X)\n        loss[i] = log_loss(np.argmax(Y, axis=1), Y_pred)\n</code></pre>\n\n<p>As I am new to NN in general, can anyone tell what was the cause of this error and how can it be modififed?</p>\n",
                "tags": "<neural-network><classification>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8322",
            "_score": 7.36117,
            "_source": {
                "title": "Recommending college degrees based on high school subjects",
                "content": "Recommending college degrees based on high school subjects <p>I have a list of our college students' high school courses.</p>\n\n<p>I want to recommend college degrees to current high school students based on their courses - that is, predict a class based on a vector. For instance someone who studied algebra, calculus and statistics could be recommended software engineering, accountancy or mathematics.</p>\n\n<p>There seem to be a few approaches I could take: market basket analysis, collaborative filtering, clustering or even neural networks. </p>\n\n<p>I can structure my data in a sparse matrix of courses, with each row having a class representing the student's eventual degree, e.g.:</p>\n\n<pre><code>DEGREE       English    Calc    Algebra    Geography    History ... etc\nSoft.Eng.    0          1       1          0            0\nComms        1          0       0          1            1\nMech.Eng.    1          1       1          0            0\n</code></pre>\n\n<p>How should I approach this?</p>\n <classification><clustering><recommender-system><p>This problem is perfectly suited for a neural network. Your model will have 40 input nodes (this is fine), then you will have some arbitrary hidden layers, you need to tune this, and 20 outputs. After the training process you can even get a probability for each of them. This can be used to rank suggestions for potential students!</p>\n\n<hr>\n\n<h1>How to do this</h1>\n\n<h2>Load the data to memory</h2>\n\n<p>Depending on the means by which your data is stored this step will be different. However, the goal is to go from the raw file source to either Python Numpy array or a Pandas DataFrame. I will assume your data is structured as follows</p>\n\n<p><a href=\"https://i.stack.imgur.com/Px0mH.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Px0mH.png\" alt=\"enter image description here\"></a></p>\n\n<p>and is saved as a .csv file.</p>\n\n<p>Let's load our data into an X and Y matrix. We will be encoding the labels for 'degree' as values. Make sure these are all well spelled otherwise a new label will be created for the mispelled ones. </p>\n\n<pre><code>import pandas as pd\nimport numpy as np\n\ndf = pd.read_csv('test1.csv')\ndf['Degree'] = df['Degree'].astype('category')\ndf[\"Degree_encoding\"] = df[\"Degree\"].cat.codes\n\nX = np.asarray(df.loc[:, df.columns != 'Degree'])\nY = df['Degree_encoding']\n\nprint(X.shape)\nprint(Y.shape)\n</code></pre>\n\n<blockquote>\n  <p>(39, 7) <br/>(39,)</p>\n</blockquote>\n\n<h2>Applying a neural network to this dataset</h2>\n\n<p>First we will split the data randomly into a training and testing set. This is used to evaluate our model while maintaining that we are not overfitting. Then we identify the number of output classes. Then we reshape the input matrices such that they have a channel in their last dimension, this is how data flows through the model. Then we will categorize our outputs as one-hot encoded vectors.</p>\n\n<pre><code>from sklearn.model_selection import train_test_split\nimport keras\n\n# Split the data\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n\n# The known number of output classes.\nnum_classes = len(set(df[\"Degree_encoding\"]))\n# Input dimensions\nshape = X.shape[1::]\n\n# We need to add a channels dimension to our data\n# Channels go last for TensorFlow backend in Keras\nx_train_reshaped = x_train.reshape((x_train.shape[0],) + shape)\nx_test_reshaped = x_test.reshape((x_test.shape[0],) + shape)\ninput_shape = shape\nprint(input_shape)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n</code></pre>\n\n<p>We then design our model</p>\n\n<pre><code>model = Sequential()\nmodel.add(Dense(32,\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<p>You can use <code>model.summary()</code> to get a description of these layers. Then we are ready to train our model!</p>\n\n<pre><code>epochs = 100\nbatch_size = 128\nmodel.fit(x_train_reshaped, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test))\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/PORhj.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PORhj.png\" alt=\"enter image description here\"></a></p>\n<p>On such data, naive bayes (and maybe non-naive Bayes variants) should perform extremely well. Because all your inputs are binary.</p>\n\n<p>It's also incredibly cheap to train, evaluate, and explain.</p>\n\n<p>You can combine it with frequent itemset to make it less naive, but I wouldn't be surprised if that does not improve the accuracy much. You would use FIM to find dependencies worth modeling, and build an optimal Bayes for non-overlapping frequent subsets (e.g. engineering subjects vs. languages). Then combine these partitions assuming independence.</p>\n",
                "codes": [
                    [
                        "import pandas as pd\nimport numpy as np\n\ndf = pd.read_csv('test1.csv')\ndf['Degree'] = df['Degree'].astype('category')\ndf[\"Degree_encoding\"] = df[\"Degree\"].cat.codes\n\nX = np.asarray(df.loc[:, df.columns != 'Degree'])\nY = df['Degree_encoding']\n\nprint(X.shape)\nprint(Y.shape)\n",
                        "from sklearn.model_selection import train_test_split\nimport keras\n\n# Split the data\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n\n# The known number of output classes.\nnum_classes = len(set(df[\"Degree_encoding\"]))\n# Input dimensions\nshape = X.shape[1::]\n\n# We need to add a channels dimension to our data\n# Channels go last for TensorFlow backend in Keras\nx_train_reshaped = x_train.reshape((x_train.shape[0],) + shape)\nx_test_reshaped = x_test.reshape((x_test.shape[0],) + shape)\ninput_shape = shape\nprint(input_shape)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n",
                        "model = Sequential()\nmodel.add(Dense(32,\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n",
                        "epochs = 100\nbatch_size = 128\nmodel.fit(x_train_reshaped, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test))\n"
                    ],
                    []
                ],
                "question_id:": "30560",
                "question_votes:": "1",
                "question_text:": "<p>I have a list of our college students' high school courses.</p>\n\n<p>I want to recommend college degrees to current high school students based on their courses - that is, predict a class based on a vector. For instance someone who studied algebra, calculus and statistics could be recommended software engineering, accountancy or mathematics.</p>\n\n<p>There seem to be a few approaches I could take: market basket analysis, collaborative filtering, clustering or even neural networks. </p>\n\n<p>I can structure my data in a sparse matrix of courses, with each row having a class representing the student's eventual degree, e.g.:</p>\n\n<pre><code>DEGREE       English    Calc    Algebra    Geography    History ... etc\nSoft.Eng.    0          1       1          0            0\nComms        1          0       0          1            1\nMech.Eng.    1          1       1          0            0\n</code></pre>\n\n<p>How should I approach this?</p>\n",
                "tags": "<classification><clustering><recommender-system>",
                "answers": [
                    [
                        "30633",
                        "2",
                        "30560",
                        "",
                        "",
                        "<p>This problem is perfectly suited for a neural network. Your model will have 40 input nodes (this is fine), then you will have some arbitrary hidden layers, you need to tune this, and 20 outputs. After the training process you can even get a probability for each of them. This can be used to rank suggestions for potential students!</p>\n\n<hr>\n\n<h1>How to do this</h1>\n\n<h2>Load the data to memory</h2>\n\n<p>Depending on the means by which your data is stored this step will be different. However, the goal is to go from the raw file source to either Python Numpy array or a Pandas DataFrame. I will assume your data is structured as follows</p>\n\n<p><a href=\"https://i.stack.imgur.com/Px0mH.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Px0mH.png\" alt=\"enter image description here\"></a></p>\n\n<p>and is saved as a .csv file.</p>\n\n<p>Let's load our data into an X and Y matrix. We will be encoding the labels for 'degree' as values. Make sure these are all well spelled otherwise a new label will be created for the mispelled ones. </p>\n\n<pre><code>import pandas as pd\nimport numpy as np\n\ndf = pd.read_csv('test1.csv')\ndf['Degree'] = df['Degree'].astype('category')\ndf[\"Degree_encoding\"] = df[\"Degree\"].cat.codes\n\nX = np.asarray(df.loc[:, df.columns != 'Degree'])\nY = df['Degree_encoding']\n\nprint(X.shape)\nprint(Y.shape)\n</code></pre>\n\n<blockquote>\n  <p>(39, 7) <br/>(39,)</p>\n</blockquote>\n\n<h2>Applying a neural network to this dataset</h2>\n\n<p>First we will split the data randomly into a training and testing set. This is used to evaluate our model while maintaining that we are not overfitting. Then we identify the number of output classes. Then we reshape the input matrices such that they have a channel in their last dimension, this is how data flows through the model. Then we will categorize our outputs as one-hot encoded vectors.</p>\n\n<pre><code>from sklearn.model_selection import train_test_split\nimport keras\n\n# Split the data\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n\n# The known number of output classes.\nnum_classes = len(set(df[\"Degree_encoding\"]))\n# Input dimensions\nshape = X.shape[1::]\n\n# We need to add a channels dimension to our data\n# Channels go last for TensorFlow backend in Keras\nx_train_reshaped = x_train.reshape((x_train.shape[0],) + shape)\nx_test_reshaped = x_test.reshape((x_test.shape[0],) + shape)\ninput_shape = shape\nprint(input_shape)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n</code></pre>\n\n<p>We then design our model</p>\n\n<pre><code>model = Sequential()\nmodel.add(Dense(32,\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<p>You can use <code>model.summary()</code> to get a description of these layers. Then we are ready to train our model!</p>\n\n<pre><code>epochs = 100\nbatch_size = 128\nmodel.fit(x_train_reshaped, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test))\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/PORhj.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PORhj.png\" alt=\"enter image description here\"></a></p>\n",
                        "",
                        ""
                    ],
                    [
                        "30844",
                        "2",
                        "30560",
                        "",
                        "",
                        "<p>On such data, naive bayes (and maybe non-naive Bayes variants) should perform extremely well. Because all your inputs are binary.</p>\n\n<p>It's also incredibly cheap to train, evaluate, and explain.</p>\n\n<p>You can combine it with frequent itemset to make it less naive, but I wouldn't be surprised if that does not improve the accuracy much. You would use FIM to find dependencies worth modeling, and build an optimal Bayes for non-overlapping frequent subsets (e.g. engineering subjects vs. languages). Then combine these partitions assuming independence.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11453",
            "_score": 7.3200383,
            "_source": {
                "title": "Approximation of function with neural networks",
                "content": "Approximation of function with neural networks <p>I am looking for the relevant techniques to approximate a function on <span class=\"math-container\">$[0,1]$</span> with a neural network when the function has a huge amplitude?</p>\n\n<p>Here is an example with a simple neural network. For test = 1 everything works well. For test = 2 then the algo \"converges\" towards a constant. Why?</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib\n\nsample_size = 5000000\n\ntest = 1\n\nif test == 1:\n    learning_rate = 1e-2\n    alpha = 2.\nelif test == 2:\n    learning_rate = 5e-10\n    alpha = 2000000.\n\nxs = np.random.normal(0.,1.,sample_size).reshape(-1,1)\nys = alpha * xs * xs\n\nxs_test = np.arange(-3.,3.,0.01).reshape(-1,1)\nys_test = alpha * xs_test * xs_test\n\nmatplotlib.interactive(True)\nfig = plt.figure()\nax = fig.gca()\nax.plot(xs_test, ys_test, 'r')\nfig.canvas.draw()\nfig.canvas.flush_events()\n\nx = tf.placeholder(tf.float32, shape=(None,1))\ny = tf.placeholder(tf.float32, shape=(None,1))\n\nbatch_size = 50\nnb_batches = int(np.ceil(sample_size/batch_size))\n\nwith tf.name_scope('nn'):\n    hidden = tf.layers.dense(x, 50, name=\"hidden\", activation=tf.nn.elu)\n    outcome = tf.layers.dense(hidden, 1, name=\"output\")    \nwith tf.name_scope('loss'):\n    loss = tf.reduce_mean(tf.square(outcome - y))    \nwith tf.name_scope('train'):\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n    training_op = optimizer.minimize(loss)\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for i in range(nb_batches):\n        indices = slice(i*batch_size, (i+1)*batch_size)\n        mini_batch_x = xs[indices]\n        mini_batch_y = ys[indices]\n        if i % 100 == 0:\n            print('loop: ', i, 'loss:', loss.eval(feed_dict = {x: xs_test, y: ys_test}))\n            ax.clear()\n            ax.plot(xs_test, ys_test, 'r')\n            ax.plot(xs_test, outcome.eval(feed_dict = {x: xs_test}), 'b.')\n            fig.canvas.draw()\n            fig.canvas.flush_events()\n        sess.run(training_op, feed_dict={x: mini_batch_x, y: mini_batch_y})\n</code></pre>\n <neural-network><p>Neural networks are function approximators, thus the answer is yes. Neural networks go from a set of inputs and map them to a set of outputs. That is precisely what a function does as well. In theory a sufficiently deep enough network and sufficient data coverage can approximate any function within a finite range. </p>\n\n<hr>\n\n<p>Let's look at an example</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n</code></pre>\n\n<p>We will approximate some arbitrary function </p>\n\n<p><span class=\"math-container\">$y = x_1^2 + x_2^2 + x_1x_2^2 + \\text{tan}(x_1)$</span></p>\n\n<pre><code>def func(x1, x2):\n    return x1**2 + x2**2 + x1*x2**2 + np.tan(x1)\n</code></pre>\n\n<p>We will bound our inputs from <span class=\"math-container\">$[-1, 1]$</span>.</p>\n\n<pre><code>n = 10000\nx_train =  (np.random.rand(n,2) - 0.5) * 2\ny_train = np.zeros((n,))\n\nfor i in range(n):\n    y_train[i] = func(x_train[i,0], x_train[i,1])\n\nn = 1000\nx_test =  (np.random.rand(n,2) - 0.5) * 2\ny_test = np.zeros((n,))\n\nfor i in range(n):\n    y_test[i] = func(x_test[i,0], x_test[i,1])\n\nplt.scatter(x_train[:,0], x_train[:,1], c=y_train)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/ouPSt.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ouPSt.png\" alt=\"enter image description here\"></a></p>\n\n<p>Let's now build a model.</p>\n\n<pre><code>from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv1D, MaxPooling1D, Reshape\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\nfrom keras import optimizers\n\ninput_shape = (2,)\n\nmodel = Sequential()\nmodel.add(Dense(32, activation='linear',\n                 input_shape=input_shape))\nmodel.add(Dense(64, activation='tanh'))\nmodel.add(Dense(32, activation='tanh'))\nmodel.add(Dense(1, activation='linear'))\n\nsgd = keras.optimizers.RMSprop(lr=0.001)\nmodel.compile(loss=keras.losses.mean_squared_error,\n              optimizer=sgd,\n              metrics=['mae'])\n</code></pre>\n\n<p>We will train the model</p>\n\n<pre><code>epochs = 50\nbatch_size = 128\n# Fit the model weights.\nhistory = model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\n</code></pre>\n\n<p>Let's see how well we did. We will compare the test set that we have to the predicted values.</p>\n\n<pre><code>plt.scatter(x_test[:,0], x_test[:,1], c=y_test)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/jRbV5.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/jRbV5.png\" alt=\"enter image description here\"></a></p>\n\n<pre><code>plt.scatter(x_test[:,0], x_test[:,1], \n            c=model.predict(x_test).reshape(x_test.shape[0],))\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/s3Y8v.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/s3Y8v.png\" alt=\"enter image description here\"></a></p>\n\n<hr>\n\n<h2>Other functions</h2>\n\n<pre><code>def func(x1, x2):\n    if x1 &gt;= 0 and x2 &gt;= 0:\n        return x1**2 + x2**2\n    else:\n        return x1*2 + x2*2\n</code></pre>\n\n<p>Test set</p>\n\n<p><a href=\"https://i.stack.imgur.com/IiizC.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/IiizC.png\" alt=\"enter image description here\"></a></p>\n\n<p>Prediction</p>\n\n<p><a href=\"https://i.stack.imgur.com/j3z4b.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/j3z4b.png\" alt=\"enter image description here\"></a></p>\n\n<pre><code>def func(x1, x2):\n    return np.sinc(x1 + x2)\n</code></pre>\n\n<p>Test set</p>\n\n<p><a href=\"https://i.stack.imgur.com/KNkoP.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/KNkoP.png\" alt=\"enter image description here\"></a></p>\n\n<p>Prediction</p>\n\n<p><a href=\"https://i.stack.imgur.com/1MR43.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/1MR43.png\" alt=\"enter image description here\"></a></p>\n\n<p>Try your own function with this network.</p>\n",
                "codes": [
                    [
                        "import numpy as np\nimport matplotlib.pyplot as plt\n",
                        "def func(x1, x2):\n    return x1**2 + x2**2 + x1*x2**2 + np.tan(x1)\n",
                        "n = 10000\nx_train =  (np.random.rand(n,2) - 0.5) * 2\ny_train = np.zeros((n,))\n\nfor i in range(n):\n    y_train[i] = func(x_train[i,0], x_train[i,1])\n\nn = 1000\nx_test =  (np.random.rand(n,2) - 0.5) * 2\ny_test = np.zeros((n,))\n\nfor i in range(n):\n    y_test[i] = func(x_test[i,0], x_test[i,1])\n\nplt.scatter(x_train[:,0], x_train[:,1], c=y_train)\nplt.show()\n",
                        "from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv1D, MaxPooling1D, Reshape\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\nfrom keras import optimizers\n\ninput_shape = (2,)\n\nmodel = Sequential()\nmodel.add(Dense(32, activation='linear',\n                 input_shape=input_shape))\nmodel.add(Dense(64, activation='tanh'))\nmodel.add(Dense(32, activation='tanh'))\nmodel.add(Dense(1, activation='linear'))\n\nsgd = keras.optimizers.RMSprop(lr=0.001)\nmodel.compile(loss=keras.losses.mean_squared_error,\n              optimizer=sgd,\n              metrics=['mae'])\n",
                        "epochs = 50\nbatch_size = 128\n# Fit the model weights.\nhistory = model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\n",
                        "plt.scatter(x_test[:,0], x_test[:,1], c=y_test)\nplt.show()\n",
                        "plt.scatter(x_test[:,0], x_test[:,1], \n            c=model.predict(x_test).reshape(x_test.shape[0],))\nplt.show()\n",
                        "def func(x1, x2):\n    if x1 >= 0 and x2 >= 0:\n        return x1**2 + x2**2\n    else:\n        return x1*2 + x2*2\n",
                        "def func(x1, x2):\n    return np.sinc(x1 + x2)\n"
                    ]
                ],
                "question_id:": "40451",
                "question_votes:": "1",
                "question_text:": "<p>I am looking for the relevant techniques to approximate a function on <span class=\"math-container\">$[0,1]$</span> with a neural network when the function has a huge amplitude?</p>\n\n<p>Here is an example with a simple neural network. For test = 1 everything works well. For test = 2 then the algo \"converges\" towards a constant. Why?</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib\n\nsample_size = 5000000\n\ntest = 1\n\nif test == 1:\n    learning_rate = 1e-2\n    alpha = 2.\nelif test == 2:\n    learning_rate = 5e-10\n    alpha = 2000000.\n\nxs = np.random.normal(0.,1.,sample_size).reshape(-1,1)\nys = alpha * xs * xs\n\nxs_test = np.arange(-3.,3.,0.01).reshape(-1,1)\nys_test = alpha * xs_test * xs_test\n\nmatplotlib.interactive(True)\nfig = plt.figure()\nax = fig.gca()\nax.plot(xs_test, ys_test, 'r')\nfig.canvas.draw()\nfig.canvas.flush_events()\n\nx = tf.placeholder(tf.float32, shape=(None,1))\ny = tf.placeholder(tf.float32, shape=(None,1))\n\nbatch_size = 50\nnb_batches = int(np.ceil(sample_size/batch_size))\n\nwith tf.name_scope('nn'):\n    hidden = tf.layers.dense(x, 50, name=\"hidden\", activation=tf.nn.elu)\n    outcome = tf.layers.dense(hidden, 1, name=\"output\")    \nwith tf.name_scope('loss'):\n    loss = tf.reduce_mean(tf.square(outcome - y))    \nwith tf.name_scope('train'):\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n    training_op = optimizer.minimize(loss)\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for i in range(nb_batches):\n        indices = slice(i*batch_size, (i+1)*batch_size)\n        mini_batch_x = xs[indices]\n        mini_batch_y = ys[indices]\n        if i % 100 == 0:\n            print('loop: ', i, 'loss:', loss.eval(feed_dict = {x: xs_test, y: ys_test}))\n            ax.clear()\n            ax.plot(xs_test, ys_test, 'r')\n            ax.plot(xs_test, outcome.eval(feed_dict = {x: xs_test}), 'b.')\n            fig.canvas.draw()\n            fig.canvas.flush_events()\n        sess.run(training_op, feed_dict={x: mini_batch_x, y: mini_batch_y})\n</code></pre>\n",
                "tags": "<neural-network>",
                "answers": [
                    [
                        "40547",
                        "2",
                        "40451",
                        "",
                        "",
                        "<p>Neural networks are function approximators, thus the answer is yes. Neural networks go from a set of inputs and map them to a set of outputs. That is precisely what a function does as well. In theory a sufficiently deep enough network and sufficient data coverage can approximate any function within a finite range. </p>\n\n<hr>\n\n<p>Let's look at an example</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n</code></pre>\n\n<p>We will approximate some arbitrary function </p>\n\n<p><span class=\"math-container\">$y = x_1^2 + x_2^2 + x_1x_2^2 + \\text{tan}(x_1)$</span></p>\n\n<pre><code>def func(x1, x2):\n    return x1**2 + x2**2 + x1*x2**2 + np.tan(x1)\n</code></pre>\n\n<p>We will bound our inputs from <span class=\"math-container\">$[-1, 1]$</span>.</p>\n\n<pre><code>n = 10000\nx_train =  (np.random.rand(n,2) - 0.5) * 2\ny_train = np.zeros((n,))\n\nfor i in range(n):\n    y_train[i] = func(x_train[i,0], x_train[i,1])\n\nn = 1000\nx_test =  (np.random.rand(n,2) - 0.5) * 2\ny_test = np.zeros((n,))\n\nfor i in range(n):\n    y_test[i] = func(x_test[i,0], x_test[i,1])\n\nplt.scatter(x_train[:,0], x_train[:,1], c=y_train)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/ouPSt.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ouPSt.png\" alt=\"enter image description here\"></a></p>\n\n<p>Let's now build a model.</p>\n\n<pre><code>from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv1D, MaxPooling1D, Reshape\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\nfrom keras import optimizers\n\ninput_shape = (2,)\n\nmodel = Sequential()\nmodel.add(Dense(32, activation='linear',\n                 input_shape=input_shape))\nmodel.add(Dense(64, activation='tanh'))\nmodel.add(Dense(32, activation='tanh'))\nmodel.add(Dense(1, activation='linear'))\n\nsgd = keras.optimizers.RMSprop(lr=0.001)\nmodel.compile(loss=keras.losses.mean_squared_error,\n              optimizer=sgd,\n              metrics=['mae'])\n</code></pre>\n\n<p>We will train the model</p>\n\n<pre><code>epochs = 50\nbatch_size = 128\n# Fit the model weights.\nhistory = model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\n</code></pre>\n\n<p>Let's see how well we did. We will compare the test set that we have to the predicted values.</p>\n\n<pre><code>plt.scatter(x_test[:,0], x_test[:,1], c=y_test)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/jRbV5.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/jRbV5.png\" alt=\"enter image description here\"></a></p>\n\n<pre><code>plt.scatter(x_test[:,0], x_test[:,1], \n            c=model.predict(x_test).reshape(x_test.shape[0],))\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/s3Y8v.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/s3Y8v.png\" alt=\"enter image description here\"></a></p>\n\n<hr>\n\n<h2>Other functions</h2>\n\n<pre><code>def func(x1, x2):\n    if x1 &gt;= 0 and x2 &gt;= 0:\n        return x1**2 + x2**2\n    else:\n        return x1*2 + x2*2\n</code></pre>\n\n<p>Test set</p>\n\n<p><a href=\"https://i.stack.imgur.com/IiizC.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/IiizC.png\" alt=\"enter image description here\"></a></p>\n\n<p>Prediction</p>\n\n<p><a href=\"https://i.stack.imgur.com/j3z4b.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/j3z4b.png\" alt=\"enter image description here\"></a></p>\n\n<pre><code>def func(x1, x2):\n    return np.sinc(x1 + x2)\n</code></pre>\n\n<p>Test set</p>\n\n<p><a href=\"https://i.stack.imgur.com/KNkoP.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/KNkoP.png\" alt=\"enter image description here\"></a></p>\n\n<p>Prediction</p>\n\n<p><a href=\"https://i.stack.imgur.com/1MR43.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/1MR43.png\" alt=\"enter image description here\"></a></p>\n\n<p>Try your own function with this network.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17887",
            "_score": 7.2811265,
            "_source": {
                "title": "Adding machine learning classifier at the end of CNN layer",
                "content": "Adding machine learning classifier at the end of CNN layer <p>I wanted to use the CNN as feature extractor for my images and then fed these features to some machine learning classifiers such as SVM, decision tree and KNN.\nHowever when I was trying with SVM I got this error message:</p>\n\n<p><strong>File \"C:\\Users\\Afef-\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\", line 521, in _validate_targets\n    \" class\" % len(cls))\nValueError: The number of classes has to be greater than one; got 1 class</strong></p>\n\n<p>This is my code :</p>\n\n<pre><code>import os\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nfrom plot_metrics import plot_accuracy, plot_loss, plot_roc_curve\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\nK.set_image_dim_ordering('th')\nnp.random.seed(15)  \n\n\n\"\"\"\nUsing Theano backend and Theano image_dim_ordering:\n(# channels, # images, # rows, # cols)\n(1, 3040, 513, 125)\n\"\"\"\n\ndef preprocess(X_train, X_test):\n    \"\"\"\n    Convert from float64 to float32 and normalize normalize to decibels\n    relative to full scale (dBFS) for the 4 sec clip.\n    \"\"\"\n    X_train = X_train.astype('float32')\n    X_test = X_test.astype('float32')\n\n    X_train = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_train])\n    X_test = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_test])\n    return X_train, X_test\n\n\ndef prep_train_test(X_train, y_train1, X_test, y_test1, nb_classes):\n    \"\"\"\n    Prep samples ands labels for Keras input by noramalzing and converting\n    labels to a categorical representation.\n    \"\"\"\n    print('Train on {} samples, validate on {}'.format(X_train.shape[0],\n                                                       X_test.shape[0]))\n\n    # normalize to dBfS\n    X_train, X_test = preprocess(X_train, X_test)\n\n    # Convert class vectors to binary class matrices\n    Y_train1 = np_utils.to_categorical(y_train, nb_classes)\n    Y_test1 = np_utils.to_categorical(y_test, nb_classes)\n\n    return X_train, X_test, Y_train1, Y_test1\n\n\ndef keras_img_prep(X_train, X_test, img_dep, img_rows, img_cols):\n    \"\"\"\n    Reshape feature matrices for Keras' expexcted input dimensions.\n    For 'th' (Theano) dim_order, the model expects dimensions:\n    (# channels, # images, # rows, # cols).\n    \"\"\"\n    if K.image_dim_ordering() == 'th':\n        X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n        X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n        input_shape = (1, img_rows, img_cols)\n    else:\n        X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n        X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n        input_shape = (img_rows, img_cols, 1)\n    return X_train, X_test, input_shape\n\n\ndef cnn(X_train, y_train1, X_test, y_test1, batch_size,\n        nb_classes, epochs, input_shape):\n    \"\"\"\n    The Convolutional Neural Net architecture for classifying the audio clips\n    as normal (0) or depressed (1).\n    \"\"\"\n    model = Sequential()\n\n    model.add(Conv2D(32, (3, 3), padding='valid', strides=1,\n                     input_shape=input_shape, activation='relu'))\n\n    model.add(MaxPooling2D(pool_size=(4, 3), strides=(1, 3)))\n\n    model.add(Conv2D(32, (1, 3), padding='valid', strides=1,\n              input_shape=input_shape, activation='relu'))\n\n    model.add(MaxPooling2D(pool_size=(1, 3), strides=(1, 3)))\n\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(nb_classes))\n    model.add(Activation('softmax'))\n\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='adadelta',\n                  metrics=['accuracy'])\n\n    history = model.fit(X_train, y_train1, batch_size=batch_size, epochs=epochs,\n                        verbose=1, validation_data=(X_test, y_test1))\n\n\n    # Evaluate accuracy on test and train sets\n    score_train = model.evaluate(X_train, y_train1, verbose=0)\n    print('Train accuracy:', score_train[1])\n    score_test = model.evaluate(X_test, y_test1, verbose=0)\n    print('Test accuracy:', score_test[1])\n#    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n    return model, history\n\n\n\nif __name__ == '__main__':\n\n\n    print('Retrieving locally')\n    X_train = np.load('E:/depression detection/data/processed/train_samples.npz')\n    y_train = np.load('E:/depression detection/data/processed/train_labels.npz')\n    X_test = np.load('E:/depression detection/data/processed/test_samples.npz')\n    y_test = np.load('E:/depression detection/data/processed/test_labels.npz')\n\n    X_train, y_train, X_test, y_test = \\\n        X_train['arr_0'], y_train['arr_0'], X_test['arr_0'], y_test['arr_0']\n\n    # CNN parameters\n    batch_size = 32\n    nb_classes = 2\n    epochs = 7\n\n    # normalalize data and prep for Keras\n    print('Processing images for Keras...')\n    X_train, X_test, y_train1, y_test1 = prep_train_test(X_train, y_train,\n                                                       X_test, y_test,\n                                                       nb_classes=nb_classes)\n\n    # 513x125x1 for spectrogram with crop size of 125 pixels\n    img_rows, img_cols, img_depth = X_train.shape[1], X_train.shape[2], 1\n\n    # reshape image input for Keras\n    # used Theano dim_ordering (th), (# chans, # images, # rows, # cols)\n    X_train, X_test, input_shape = keras_img_prep(X_train, X_test, img_depth,\n                                                  img_rows, img_cols)\n\n\n    # run CNN\n    print('Fitting model...')\n    model, history = cnn(X_train, y_train1, X_test, y_test1, batch_size,\n                         nb_classes, epochs, input_shape)\n\n\n\n    for l in range(len(model.layers)):\n      print(l, model.layers[l])\n\n     # feature extraction layer\n    getFeature = K.function([model.layers[0].input, K.learning_phase()],\n                       [model.layers[7].output])\n# classification layer\n    getPrediction = K.function([model.layers[8].input, K.learning_phase()],\n                           [model.layers[9].output])\n\n    exTrain = getFeature([X_train[:30], 0])[0]\n    exTest = getFeature([X_test[:30], 0])[0]\n    y_train00 = y_train[:30]\n    y_test00 = y_test[:30]\n    from sklearn.svm import SVC\n    clf = SVC(gamma='auto')\n    clf.fit(exTrain, y_train00)\n</code></pre>\n <machine-learning><python><classification><keras><scikit-learn><p>Check y_test[:30] contains more than one class.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "57200",
                "question_votes:": "",
                "question_text:": "<p>I wanted to use the CNN as feature extractor for my images and then fed these features to some machine learning classifiers such as SVM, decision tree and KNN.\nHowever when I was trying with SVM I got this error message:</p>\n\n<p><strong>File \"C:\\Users\\Afef-\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\", line 521, in _validate_targets\n    \" class\" % len(cls))\nValueError: The number of classes has to be greater than one; got 1 class</strong></p>\n\n<p>This is my code :</p>\n\n<pre><code>import os\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nfrom plot_metrics import plot_accuracy, plot_loss, plot_roc_curve\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\nK.set_image_dim_ordering('th')\nnp.random.seed(15)  \n\n\n\"\"\"\nUsing Theano backend and Theano image_dim_ordering:\n(# channels, # images, # rows, # cols)\n(1, 3040, 513, 125)\n\"\"\"\n\ndef preprocess(X_train, X_test):\n    \"\"\"\n    Convert from float64 to float32 and normalize normalize to decibels\n    relative to full scale (dBFS) for the 4 sec clip.\n    \"\"\"\n    X_train = X_train.astype('float32')\n    X_test = X_test.astype('float32')\n\n    X_train = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_train])\n    X_test = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_test])\n    return X_train, X_test\n\n\ndef prep_train_test(X_train, y_train1, X_test, y_test1, nb_classes):\n    \"\"\"\n    Prep samples ands labels for Keras input by noramalzing and converting\n    labels to a categorical representation.\n    \"\"\"\n    print('Train on {} samples, validate on {}'.format(X_train.shape[0],\n                                                       X_test.shape[0]))\n\n    # normalize to dBfS\n    X_train, X_test = preprocess(X_train, X_test)\n\n    # Convert class vectors to binary class matrices\n    Y_train1 = np_utils.to_categorical(y_train, nb_classes)\n    Y_test1 = np_utils.to_categorical(y_test, nb_classes)\n\n    return X_train, X_test, Y_train1, Y_test1\n\n\ndef keras_img_prep(X_train, X_test, img_dep, img_rows, img_cols):\n    \"\"\"\n    Reshape feature matrices for Keras' expexcted input dimensions.\n    For 'th' (Theano) dim_order, the model expects dimensions:\n    (# channels, # images, # rows, # cols).\n    \"\"\"\n    if K.image_dim_ordering() == 'th':\n        X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n        X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n        input_shape = (1, img_rows, img_cols)\n    else:\n        X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n        X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n        input_shape = (img_rows, img_cols, 1)\n    return X_train, X_test, input_shape\n\n\ndef cnn(X_train, y_train1, X_test, y_test1, batch_size,\n        nb_classes, epochs, input_shape):\n    \"\"\"\n    The Convolutional Neural Net architecture for classifying the audio clips\n    as normal (0) or depressed (1).\n    \"\"\"\n    model = Sequential()\n\n    model.add(Conv2D(32, (3, 3), padding='valid', strides=1,\n                     input_shape=input_shape, activation='relu'))\n\n    model.add(MaxPooling2D(pool_size=(4, 3), strides=(1, 3)))\n\n    model.add(Conv2D(32, (1, 3), padding='valid', strides=1,\n              input_shape=input_shape, activation='relu'))\n\n    model.add(MaxPooling2D(pool_size=(1, 3), strides=(1, 3)))\n\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(nb_classes))\n    model.add(Activation('softmax'))\n\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='adadelta',\n                  metrics=['accuracy'])\n\n    history = model.fit(X_train, y_train1, batch_size=batch_size, epochs=epochs,\n                        verbose=1, validation_data=(X_test, y_test1))\n\n\n    # Evaluate accuracy on test and train sets\n    score_train = model.evaluate(X_train, y_train1, verbose=0)\n    print('Train accuracy:', score_train[1])\n    score_test = model.evaluate(X_test, y_test1, verbose=0)\n    print('Test accuracy:', score_test[1])\n#    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n    return model, history\n\n\n\nif __name__ == '__main__':\n\n\n    print('Retrieving locally')\n    X_train = np.load('E:/depression detection/data/processed/train_samples.npz')\n    y_train = np.load('E:/depression detection/data/processed/train_labels.npz')\n    X_test = np.load('E:/depression detection/data/processed/test_samples.npz')\n    y_test = np.load('E:/depression detection/data/processed/test_labels.npz')\n\n    X_train, y_train, X_test, y_test = \\\n        X_train['arr_0'], y_train['arr_0'], X_test['arr_0'], y_test['arr_0']\n\n    # CNN parameters\n    batch_size = 32\n    nb_classes = 2\n    epochs = 7\n\n    # normalalize data and prep for Keras\n    print('Processing images for Keras...')\n    X_train, X_test, y_train1, y_test1 = prep_train_test(X_train, y_train,\n                                                       X_test, y_test,\n                                                       nb_classes=nb_classes)\n\n    # 513x125x1 for spectrogram with crop size of 125 pixels\n    img_rows, img_cols, img_depth = X_train.shape[1], X_train.shape[2], 1\n\n    # reshape image input for Keras\n    # used Theano dim_ordering (th), (# chans, # images, # rows, # cols)\n    X_train, X_test, input_shape = keras_img_prep(X_train, X_test, img_depth,\n                                                  img_rows, img_cols)\n\n\n    # run CNN\n    print('Fitting model...')\n    model, history = cnn(X_train, y_train1, X_test, y_test1, batch_size,\n                         nb_classes, epochs, input_shape)\n\n\n\n    for l in range(len(model.layers)):\n      print(l, model.layers[l])\n\n     # feature extraction layer\n    getFeature = K.function([model.layers[0].input, K.learning_phase()],\n                       [model.layers[7].output])\n# classification layer\n    getPrediction = K.function([model.layers[8].input, K.learning_phase()],\n                           [model.layers[9].output])\n\n    exTrain = getFeature([X_train[:30], 0])[0]\n    exTest = getFeature([X_test[:30], 0])[0]\n    y_train00 = y_train[:30]\n    y_test00 = y_test[:30]\n    from sklearn.svm import SVC\n    clf = SVC(gamma='auto')\n    clf.fit(exTrain, y_train00)\n</code></pre>\n",
                "tags": "<machine-learning><python><classification><keras><scikit-learn>",
                "answers": [
                    [
                        "57201",
                        "2",
                        "57200",
                        "",
                        "",
                        "<p>Check y_test[:30] contains more than one class.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10419",
            "_score": 7.221086,
            "_source": {
                "title": "adding summary to tensorflow model error",
                "content": "adding summary to tensorflow model error <p>I have a CNN model for classifying lung CT images, the code is written in tensorflow, I added some tensorflow summaries to my code to show graph, scalar, histogram, ... of my tensorflow model in tensorboard, in last step when I want to add_summary to the file writer it gives me an error, here is my code:</p>\n\n<pre><code>def train_CNN(input):\n    train_predict = CNN_Model(x_img)\n    with tf.name_scope(\"cross_entropy\"):\n        cost = tf.nn.softmax_cross_entropy_with_logits_v2(logits=train_predict, labels=y_label, name='cross_entropy')\n        cost = tf.reduce_mean(cost, name='reduce_mean')\n        tf.summary.scalar(\"cost\", cost)\n    with tf.name_scope(\"optimization\"):\n        optimizer = tf.train.AdamOptimizer(learning_rate, name='AdamOptimizer').minimize(cost)\n\n    with tf.name_scope(\"accuracy\"):\n        correct_predict = tf.equal(tf.argmax(train_predict, 1), tf.argmax(y_label, 1))\n        accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n        tf.summary.scalar(\"accuracy\", accuracy)\n\n    #tf.summary.image(\"input\", x_img, 5)\n\n    sess.run(tf.global_variables_initializer())\n    log_train_path = 'C:/temp/tensorflow_logs' + '/train_{}'.format(datetime.now().strftime(\"%Y-%m-%d-%H%M%S\"))   \n    summary_writer = tf.summary.FileWriter(log_train_path)\n    summary_writer.add_graph(sess.graph)\n    merged_summary = tf.summary.merge_all()\n\n    all_time = 0\n\n    for epoch in range(num_epochs):\n        start_time = time.time()\n        ep_loss = 0\n        for data in train_data:\n            X = data[0]\n            Y = data[1]\n            summary, _, c = sess.run([merged_summary, optimizer, cost], feed_dict={x_img: X, y_label: Y})\n            ep_loss += c\n            summary_writer.add_summary(summary, epoch)\n        end_time = time.time()\n        all_time += int(end_time-start_time)\n        print('Epoch', epoch+1, 'completed out of',num_epochs,'loss:',ep_loss, 'time usage: '+str(int(end_time-start_time))+' seconds')\n\n        print('Accuracy of this epoch:',accuracy.eval({x_img:[i[0] for i in val_data], y_label:[i[1] for i in val_data]}))\n\n    print('Finall Accuracy:',accuracy.eval({x_img:[i[0] for i in val_data], y_label:[i[1] for i in val_data]}), 'time usage: '+str(all_time)+' seconds')\n</code></pre>\n\n<p>after running the model it give me error, can anyone tell me how to solve it?</p>\n\n<p>here is the error:</p>\n\n<pre><code>InvalidArgumentError: Expected dimension in the range [-1, 1), but got 1\n     [[Node: accuracy/ArgMax_1 = ArgMax[T=DT_FLOAT, Tidx=DT_INT32, output_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_y_label_0_1, accuracy/ArgMax_1/dimension)]]\n</code></pre>\n <python><tensorflow><cnn><p>Check out dimension</p>\n\n<pre><code> X = data[0]\n Y = data[1]\n</code></pre>\n\n<p>Its likely that have dimensions like (1, ) what means that's 1 dim vector.</p>\n\n<p>That should be work</p>\n\n<pre><code>import numpy as np\nX = np.array(X).reshape(-1,1)\nY = np.array(Y).reshape(-1,1)\n</code></pre>\n",
                "codes": [
                    [
                        " X = data[0]\n Y = data[1]\n",
                        "import numpy as np\nX = np.array(X).reshape(-1,1)\nY = np.array(Y).reshape(-1,1)\n"
                    ]
                ],
                "question_id:": "37417",
                "question_votes:": "1",
                "question_text:": "<p>I have a CNN model for classifying lung CT images, the code is written in tensorflow, I added some tensorflow summaries to my code to show graph, scalar, histogram, ... of my tensorflow model in tensorboard, in last step when I want to add_summary to the file writer it gives me an error, here is my code:</p>\n\n<pre><code>def train_CNN(input):\n    train_predict = CNN_Model(x_img)\n    with tf.name_scope(\"cross_entropy\"):\n        cost = tf.nn.softmax_cross_entropy_with_logits_v2(logits=train_predict, labels=y_label, name='cross_entropy')\n        cost = tf.reduce_mean(cost, name='reduce_mean')\n        tf.summary.scalar(\"cost\", cost)\n    with tf.name_scope(\"optimization\"):\n        optimizer = tf.train.AdamOptimizer(learning_rate, name='AdamOptimizer').minimize(cost)\n\n    with tf.name_scope(\"accuracy\"):\n        correct_predict = tf.equal(tf.argmax(train_predict, 1), tf.argmax(y_label, 1))\n        accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n        tf.summary.scalar(\"accuracy\", accuracy)\n\n    #tf.summary.image(\"input\", x_img, 5)\n\n    sess.run(tf.global_variables_initializer())\n    log_train_path = 'C:/temp/tensorflow_logs' + '/train_{}'.format(datetime.now().strftime(\"%Y-%m-%d-%H%M%S\"))   \n    summary_writer = tf.summary.FileWriter(log_train_path)\n    summary_writer.add_graph(sess.graph)\n    merged_summary = tf.summary.merge_all()\n\n    all_time = 0\n\n    for epoch in range(num_epochs):\n        start_time = time.time()\n        ep_loss = 0\n        for data in train_data:\n            X = data[0]\n            Y = data[1]\n            summary, _, c = sess.run([merged_summary, optimizer, cost], feed_dict={x_img: X, y_label: Y})\n            ep_loss += c\n            summary_writer.add_summary(summary, epoch)\n        end_time = time.time()\n        all_time += int(end_time-start_time)\n        print('Epoch', epoch+1, 'completed out of',num_epochs,'loss:',ep_loss, 'time usage: '+str(int(end_time-start_time))+' seconds')\n\n        print('Accuracy of this epoch:',accuracy.eval({x_img:[i[0] for i in val_data], y_label:[i[1] for i in val_data]}))\n\n    print('Finall Accuracy:',accuracy.eval({x_img:[i[0] for i in val_data], y_label:[i[1] for i in val_data]}), 'time usage: '+str(all_time)+' seconds')\n</code></pre>\n\n<p>after running the model it give me error, can anyone tell me how to solve it?</p>\n\n<p>here is the error:</p>\n\n<pre><code>InvalidArgumentError: Expected dimension in the range [-1, 1), but got 1\n     [[Node: accuracy/ArgMax_1 = ArgMax[T=DT_FLOAT, Tidx=DT_INT32, output_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_y_label_0_1, accuracy/ArgMax_1/dimension)]]\n</code></pre>\n",
                "tags": "<python><tensorflow><cnn>",
                "answers": [
                    [
                        "37437",
                        "2",
                        "37417",
                        "",
                        "",
                        "<p>Check out dimension</p>\n\n<pre><code> X = data[0]\n Y = data[1]\n</code></pre>\n\n<p>Its likely that have dimensions like (1, ) what means that's 1 dim vector.</p>\n\n<p>That should be work</p>\n\n<pre><code>import numpy as np\nX = np.array(X).reshape(-1,1)\nY = np.array(Y).reshape(-1,1)\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15282",
            "_score": 7.221086,
            "_source": {
                "title": "Plotting Polynomial Regression?",
                "content": "Plotting Polynomial Regression? <p>I'm reading through <em>Hands-On Machine Learning with Scikit-learn and Tensorflow</em> by Geron. I am creating a simple polynomial regression using sklearn's <code>PolynomialFeatures</code>.</p>\n\n<p>First, I create an X and y set using numpy random numbers with quadratic shape:</p>\n\n<pre><code>m = 100\nX = 6 * np.random.rand(m, 1) - 3\ny = 0.5 * X**2 + X + 2 + np.random.randn(m, 1)\n</code></pre>\n\n<p>Then I plot the scatterplot distribution:</p>\n\n<pre><code>plt.plot(X, y, \"b.\")\nplt.xlabel(\"<span class=\"math-container\">$x_1$</span>\", fontsize=18)\nplt.ylabel(\"<span class=\"math-container\">$y$</span>\", rotation=0, fontsize=18)\nplt.axis([-3, 3, 0, 10])\nplt.show()\n</code></pre>\n\n<p>Then I use PolynomialFeatures to add the 2nd degree:</p>\n\n<pre><code>poly_features = PolynomialFeatures(degree=2, include_bias=False)\nX_poly = poly_features.fit_transform(X)\n</code></pre>\n\n<p>Then I fit the LinearRegression:</p>\n\n<pre><code>lin_reg = LinearRegression()\nlin_reg.fit(X_poly, y)\nlin_reg.intercept_, lin_reg.coef_\n</code></pre>\n\n<p>Then I plot the same distribution with the quadratic regression line. My question is with the following code:</p>\n\n<pre><code>X_new=np.linspace(-3, 3, 100).reshape(100, 1)\nX_new_poly = poly_features.transform(X_new)\ny_new = lin_reg.predict(X_new_poly)\nplt.plot(X, y, \"b.\")\nplt.plot(X_new, y_new, \"r-\", linewidth=2, label=\"Predictions\")\nplt.xlabel(\"<span class=\"math-container\">$x_1$</span>\", fontsize=18)\nplt.ylabel(\"<span class=\"math-container\">$y$</span>\", rotation=0, fontsize=18)\nplt.legend(loc=\"upper left\", fontsize=14)\nplt.axis([-3, 3, 0, 10])\nplt.show()\n</code></pre>\n\n<p>Why do we create X_new <code>(np.linspace(-3,3,100).reshape(100,1)</code> and X_new_poly? Why does this not work with the X_poly that I've already created? (I tried plotting it with the original X_poly and it definitely does not work. It's just oscillating lines up and down over and over. I'm just not sure why this is the case.)</p>\n <machine-learning><python><scikit-learn><p>You could use <code>X</code> and <code>lin_reg.predict(X_poly)</code>, but</p>\n\n<ol>\n<li>The plot will put those points in the order they appear in <code>X</code>, and since you're using a line connector it will appear to jump all over the place.  You could fix this by using a scatterplot instead.</li>\n<li>It's vaguely disingenuous to use the training set's x-values for plotting the fitted curve; using <code>np.linspace</code> to get equally-spaced x-values is preferable (even if your original <code>X</code> was randomly generated and should fill the space reasonably well).</li>\n</ol>\n",
                "codes": [
                    []
                ],
                "question_id:": "51569",
                "question_votes:": "",
                "question_text:": "<p>I'm reading through <em>Hands-On Machine Learning with Scikit-learn and Tensorflow</em> by Geron. I am creating a simple polynomial regression using sklearn's <code>PolynomialFeatures</code>.</p>\n\n<p>First, I create an X and y set using numpy random numbers with quadratic shape:</p>\n\n<pre><code>m = 100\nX = 6 * np.random.rand(m, 1) - 3\ny = 0.5 * X**2 + X + 2 + np.random.randn(m, 1)\n</code></pre>\n\n<p>Then I plot the scatterplot distribution:</p>\n\n<pre><code>plt.plot(X, y, \"b.\")\nplt.xlabel(\"<span class=\"math-container\">$x_1$</span>\", fontsize=18)\nplt.ylabel(\"<span class=\"math-container\">$y$</span>\", rotation=0, fontsize=18)\nplt.axis([-3, 3, 0, 10])\nplt.show()\n</code></pre>\n\n<p>Then I use PolynomialFeatures to add the 2nd degree:</p>\n\n<pre><code>poly_features = PolynomialFeatures(degree=2, include_bias=False)\nX_poly = poly_features.fit_transform(X)\n</code></pre>\n\n<p>Then I fit the LinearRegression:</p>\n\n<pre><code>lin_reg = LinearRegression()\nlin_reg.fit(X_poly, y)\nlin_reg.intercept_, lin_reg.coef_\n</code></pre>\n\n<p>Then I plot the same distribution with the quadratic regression line. My question is with the following code:</p>\n\n<pre><code>X_new=np.linspace(-3, 3, 100).reshape(100, 1)\nX_new_poly = poly_features.transform(X_new)\ny_new = lin_reg.predict(X_new_poly)\nplt.plot(X, y, \"b.\")\nplt.plot(X_new, y_new, \"r-\", linewidth=2, label=\"Predictions\")\nplt.xlabel(\"<span class=\"math-container\">$x_1$</span>\", fontsize=18)\nplt.ylabel(\"<span class=\"math-container\">$y$</span>\", rotation=0, fontsize=18)\nplt.legend(loc=\"upper left\", fontsize=14)\nplt.axis([-3, 3, 0, 10])\nplt.show()\n</code></pre>\n\n<p>Why do we create X_new <code>(np.linspace(-3,3,100).reshape(100,1)</code> and X_new_poly? Why does this not work with the X_poly that I've already created? (I tried plotting it with the original X_poly and it definitely does not work. It's just oscillating lines up and down over and over. I'm just not sure why this is the case.)</p>\n",
                "tags": "<machine-learning><python><scikit-learn>",
                "answers": [
                    [
                        "51582",
                        "2",
                        "51569",
                        "",
                        "",
                        "<p>You could use <code>X</code> and <code>lin_reg.predict(X_poly)</code>, but</p>\n\n<ol>\n<li>The plot will put those points in the order they appear in <code>X</code>, and since you're using a line connector it will appear to jump all over the place.  You could fix this by using a scatterplot instead.</li>\n<li>It's vaguely disingenuous to use the training set's x-values for plotting the fitted curve; using <code>np.linspace</code> to get equally-spaced x-values is preferable (even if your original <code>X</code> was randomly generated and should fill the space reasonably well).</li>\n</ol>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17093",
            "_score": 7.221086,
            "_source": {
                "title": "Neural Network for regression with one dependent and one independent variable",
                "content": "Neural Network for regression with one dependent and one independent variable <p>I am trying to make a simple neural network with one dependent and one independent variable. Could you maybe give me a tutorial or help me with the implementation of a neural network with one dependent and one independent variable. So far I have the following code, however my predictions are not good although the error is minimized. Should I scale X and Y or do I have some mistake?</p>\n\n<p>Thank you in advance </p>\n\n<pre><code>import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx=[(i*i)+0.2 for i in range(1000)]\ny=[i for i in range(1000)]\n\nx_train=np.reshape(x,(-1,1))\ny_train=np.reshape(y,(-1,1))\nx_test=x_train[:,-10:]\ny_test=y_train[:,-10:]\nplt.scatter(x_train,y_train)\nplt.show()\n\n\nX=tf.placeholder(tf.float32,[None,1])\nY=tf.placeholder(tf.float32,[None,1])\n\nn_inputs=1\nn_hidden_1=20\nn_hidden_2=20\nn_outputs=1\n\nweights={\n    \"h1\": tf.Variable(tf.random_normal([n_inputs,n_hidden_1])),\n    \"h2\": tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n    \"out\": tf.Variable(tf.random_normal([n_hidden_2,n_outputs]))\n}\n\nbiases={\n    \"b1\": tf.Variable(tf.random_normal([n_hidden_1])),\n    \"b2\": tf.Variable(tf.random_normal([n_hidden_2])),\n    \"out\": tf.Variable(tf.random_normal([n_outputs]))\n}\n\ndef neural_net(x):\n    layer_1=tf.add(tf.matmul(x,weights[\"h1\"]),biases[\"b1\"])\n    layer_1=tf.nn.relu(layer_1)\n    layer_2=tf.add(tf.matmul(layer_1,weights[\"h2\"]),biases[\"b2\"])\n    layer_2=tf.nn.relu(layer_2)\n    layer_3=tf.matmul(layer_2,weights[\"out\"])+biases[\"out\"]\n    return layer_3\n\nY_pred=neural_net(X)\n\nloss=tf.losses.mean_squared_error(X,Y_pred)\noptimizer=tf.train.AdamOptimizer(learning_rate=0.01)\ntrain_op=optimizer.minimize(loss)\n\nepochs=1000\ninit=tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    for i in range(epochs):\n        sess.run(train_op,feed_dict={X:x_train,Y:y_train})\n        loss_op=sess.run(loss,feed_dict={X:x_train,Y:y_train})\n        if i%10==0:\n            print(\"Epoch \"+str(i)+\" loss \"+str(loss_op))\n    pred=sess.run(Y_pred,feed_dict={X:x_test})\n    plt.plot(pred,color=\"red\")\n    plt.plot(y_test,color=\"blue\")\n    plt.show()\n    plt.scatter(pred,y_test)\n    plt.show()\n    for i in range(len(pred)):\n        print(str(pred[i])+\" \"+str(y_test[i]))\n</code></pre>\n <neural-network><tensorflow><regression><p>Your predictions are not actually that bad. At the very last line of your code, print the expected value too at each line (that is x_test[i]= y_test[i]^2+0.2).</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "55494",
                "question_votes:": "",
                "question_text:": "<p>I am trying to make a simple neural network with one dependent and one independent variable. Could you maybe give me a tutorial or help me with the implementation of a neural network with one dependent and one independent variable. So far I have the following code, however my predictions are not good although the error is minimized. Should I scale X and Y or do I have some mistake?</p>\n\n<p>Thank you in advance </p>\n\n<pre><code>import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx=[(i*i)+0.2 for i in range(1000)]\ny=[i for i in range(1000)]\n\nx_train=np.reshape(x,(-1,1))\ny_train=np.reshape(y,(-1,1))\nx_test=x_train[:,-10:]\ny_test=y_train[:,-10:]\nplt.scatter(x_train,y_train)\nplt.show()\n\n\nX=tf.placeholder(tf.float32,[None,1])\nY=tf.placeholder(tf.float32,[None,1])\n\nn_inputs=1\nn_hidden_1=20\nn_hidden_2=20\nn_outputs=1\n\nweights={\n    \"h1\": tf.Variable(tf.random_normal([n_inputs,n_hidden_1])),\n    \"h2\": tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n    \"out\": tf.Variable(tf.random_normal([n_hidden_2,n_outputs]))\n}\n\nbiases={\n    \"b1\": tf.Variable(tf.random_normal([n_hidden_1])),\n    \"b2\": tf.Variable(tf.random_normal([n_hidden_2])),\n    \"out\": tf.Variable(tf.random_normal([n_outputs]))\n}\n\ndef neural_net(x):\n    layer_1=tf.add(tf.matmul(x,weights[\"h1\"]),biases[\"b1\"])\n    layer_1=tf.nn.relu(layer_1)\n    layer_2=tf.add(tf.matmul(layer_1,weights[\"h2\"]),biases[\"b2\"])\n    layer_2=tf.nn.relu(layer_2)\n    layer_3=tf.matmul(layer_2,weights[\"out\"])+biases[\"out\"]\n    return layer_3\n\nY_pred=neural_net(X)\n\nloss=tf.losses.mean_squared_error(X,Y_pred)\noptimizer=tf.train.AdamOptimizer(learning_rate=0.01)\ntrain_op=optimizer.minimize(loss)\n\nepochs=1000\ninit=tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    for i in range(epochs):\n        sess.run(train_op,feed_dict={X:x_train,Y:y_train})\n        loss_op=sess.run(loss,feed_dict={X:x_train,Y:y_train})\n        if i%10==0:\n            print(\"Epoch \"+str(i)+\" loss \"+str(loss_op))\n    pred=sess.run(Y_pred,feed_dict={X:x_test})\n    plt.plot(pred,color=\"red\")\n    plt.plot(y_test,color=\"blue\")\n    plt.show()\n    plt.scatter(pred,y_test)\n    plt.show()\n    for i in range(len(pred)):\n        print(str(pred[i])+\" \"+str(y_test[i]))\n</code></pre>\n",
                "tags": "<neural-network><tensorflow><regression>",
                "answers": [
                    [
                        "55497",
                        "2",
                        "55494",
                        "",
                        "",
                        "<p>Your predictions are not actually that bad. At the very last line of your code, print the expected value too at each line (that is x_test[i]= y_test[i]^2+0.2).</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5454",
            "_score": 7.1489067,
            "_source": {
                "title": "Keras input dimension bug?",
                "content": "Keras input dimension bug? <p>Keras has a problem with the input dimension. My first layer looks like this:</p>\n\n<pre><code>model.add(Dense(128, batch_size=1, input_shape=(150,), kernel_initializer=\"he_uniform\", kernel_regularizer=regularizers.l2(0.01), activation=\"elu\"))\n</code></pre>\n\n<p>As you can see the input dimension should be (150,) and with the fixed batch_size it is (1, 150)</p>\n\n<p>My data has dimension (150,) and could be for example a numpy array with 150 zeros.</p>\n\n<pre><code>old_qval = model.predict(old_state_m)\n</code></pre>\n\n<p>Here I call the model to make a prediction. Normally Keras should automatically add the batch size as an extra dimension so I should end up with (1, 150) which would work. But Keras adds the dimension for the batch size at the wrong place and I end up with (150, 1). I tried tensorflow and theano backend. </p>\n\n<p>Do I have a bug in my code or is it a problem with Keras?</p>\n\n<p>How can I fix the problem? I could reshape my input data but it already has the needed shape of (150,) and should be fine. What else could I do?</p>\n\n<p>If I should provide more data or code feel free to ask.</p>\n <python><neural-network><deep-learning><keras><q-learning><p>When you do <code>model.predict(X)</code> the first axis in <code>X</code> is always an index in a batch. So if you want to predict on one sample, do something like <code>X = np.expand_dims(X, axis=0)</code></p>\n\n<p>In your case, this should work:</p>\n\n<pre><code>old_qval = model.predict( np.expand_dims(old_state_m, axis=0) )\n</code></pre>\n",
                "codes": [
                    [
                        "old_qval = model.predict( np.expand_dims(old_state_m, axis=0) )\n"
                    ]
                ],
                "question_id:": "21887",
                "question_votes:": "5",
                "question_text:": "<p>Keras has a problem with the input dimension. My first layer looks like this:</p>\n\n<pre><code>model.add(Dense(128, batch_size=1, input_shape=(150,), kernel_initializer=\"he_uniform\", kernel_regularizer=regularizers.l2(0.01), activation=\"elu\"))\n</code></pre>\n\n<p>As you can see the input dimension should be (150,) and with the fixed batch_size it is (1, 150)</p>\n\n<p>My data has dimension (150,) and could be for example a numpy array with 150 zeros.</p>\n\n<pre><code>old_qval = model.predict(old_state_m)\n</code></pre>\n\n<p>Here I call the model to make a prediction. Normally Keras should automatically add the batch size as an extra dimension so I should end up with (1, 150) which would work. But Keras adds the dimension for the batch size at the wrong place and I end up with (150, 1). I tried tensorflow and theano backend. </p>\n\n<p>Do I have a bug in my code or is it a problem with Keras?</p>\n\n<p>How can I fix the problem? I could reshape my input data but it already has the needed shape of (150,) and should be fine. What else could I do?</p>\n\n<p>If I should provide more data or code feel free to ask.</p>\n",
                "tags": "<python><neural-network><deep-learning><keras><q-learning>",
                "answers": [
                    [
                        "21899",
                        "2",
                        "21887",
                        "",
                        "",
                        "<p>When you do <code>model.predict(X)</code> the first axis in <code>X</code> is always an index in a batch. So if you want to predict on one sample, do something like <code>X = np.expand_dims(X, axis=0)</code></p>\n\n<p>In your case, this should work:</p>\n\n<pre><code>old_qval = model.predict( np.expand_dims(old_state_m, axis=0) )\n</code></pre>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17794",
            "_score": 7.148637,
            "_source": {
                "title": "converting .hf to caffe",
                "content": "converting .hf to caffe <p>I am converting .hf model to caffe model.\nI have created .prototxt of my model and also extracted the weights. The problem I am facing is to create .caffemodel from my existing model because my model have a flatten layer and in create_caffemodel.py when I assign weights to the fully connected layer , the error says that shape of weights and layer does not match.\nI am unable to reshape my model kindly help me.</p>\n\n<p><strong>LeNet.prototxt</strong></p>\n\n<pre><code>name: 'LeNet'\ninput: 'data'\ninput_shape{\ndim: 1  #no of images\ndim: 3   #no of channels\ndim :224    #width\ndim :224\n}\nlayer {\n  name: \"conv2d_1\"\n  type: \"Convolution\"\n  bottom: \"data\"\n  top: \"conv2d_1\"\n  convolution_param{\n    num_output: 64\n    kernel_size: 5\n    stride: 2\n    pad: 0\n  }\n}\nlayer {\n  name: \"activation_1\"\n  type: \"ReLU\"\n  bottom: \"conv2d_1\"\n  top: \"conv2d_1\"\n}\n\nlayer {\n  name: \"max_pooling2d_1\"\n  type: \"Pooling\"\n  bottom: \"conv2d_1\"\n  top: \"max_pooling2d_1\"\n  pooling_param{\n    pool :MAX\n    kernel_size: 5\n    stride: 2\n    pad: 0\n  }\n}\nlayer {\n  name: \"conv2d_2\"\n      type: \"Convolution\"\n  bottom: \"max_pooling2d_1\"\n  top: \"conv2d_2\"\n  convolution_param{\n    num_output: 16\n    kernel_size: 5\n    stride: 2\n    pad: 0\n  }\n}\nlayer {\n  name: \"activation_2\"\n  type: \"ReLU\"\n  bottom: \"conv2d_2\"\n  top: \"conv2d_2\"\n}\nlayer {\n  name: \"max_pooling2d_2\"\n  type: \"Pooling\"\n  bottom: \"conv2d_2\"\n  top: \"max_pooling2d_2\"\n  pooling_param{\n    pool :MAX\n    kernel_size: 5\n    stride: 2\n    pad: 0\n  }\n}\nlayer {\n  name: \"conv2d_3\"\n  type: \"Convolution\"\n  bottom: \"max_pooling2d_2\"\n  top: \"conv2d_3\"\n  convolution_param{\n    num_output: 64\n    kernel_size: 5\n    stride: 2\n    pad: 0\n  }\n}\nlayer {\n  name: \"activation_3\"\n  type: \"ReLU\"\n  bottom: \"conv2d_3\"\n  top: \"conv2d_3\"\n}\nlayer {\n  name: \"max_pooling2d_3\"\n  type: \"Pooling\"\n  bottom: \"conv2d_3\"\n  top: \"max_pooling2d_3\"\n  pooling_param{\n    pool :MAX\n    kernel_size: 5\n    stride: 2\n    pad: 0\n  }\n}\nlayer{\n  name: \"flatten_1\"\n  type: \"Reshape\"\n  bottom: \"max_pooling2d_3\"\n  top: \"flatten_1\"\n    reshape_param{shape:{dim:0 dim:1 dim:-1 dim:1}}\n}\nlayer {\n  name: \"dense_1\"\n  type: \"InnerProduct\"\n  bottom:\"flatten_1\"\n  top:\"dense_1\"\n  inner_product_param {\n    num_output: 120\n  }\n  param {\n        lr_mult: 1\n    }\n    param {\n        lr_mult: 2\n    }\n}\nlayer {\n  name: \"activation_4\"\n  type: \"ReLU\"\n      bottom: \"dense_1\"\n  top: \"dense_1\"\n    }\n    layer {\n  name: \"dense_2\"\n  type: \"InnerProduct\"\n  bottom:\"dense_1\"\n  top:\"dense_2\"\n  inner_product_param {\n    num_output: 64\n  }\n    }\n    layer {\n  name: \"activation_5\"\n  type: \"ReLU\"\n      bottom: \"dense_2\"\n  top: \"dense_2\"\n    }\nlayer {\n  name: \"dense_3\"\n  type: \"InnerProduct\"\n  bottom:\"dense_2\"\n  top:\"dense_3\"\n  inner_product_param {\n num_output: 10\n  }\n }\n layer {\n   name: \"activation_6\"\n   type: \"Softmax\"\n   bottom: \"dense_3\"\n   top: \"dense_3\"\n }\n</code></pre>\n\n<p><strong>Model</strong>\n<a href=\"https://i.stack.imgur.com/uiLWy.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/uiLWy.png\" alt=\"LeNet Model Description\"></a></p>\n\n<p><strong>Create_caffemodel.py</strong></p>\n\n<pre><code>        # -*- coding: utf-8 -*-\n    \"\"\"\n    Created on Mon Jul 29 11:59:15 2019\n\n    @author: hrehman\n    \"\"\"\n    from __future__ import print_function, division\n    caffe_root = '/TUB/robo/caffe-master/'\n\n    import sys\n    sys.path.insert(0, caffe_root+'python')\n    import caffe\n    import numpy as np\n\n    #load the data file\n    data_file = np.load('./LeNet.npy',allow_pickle=True)\n    caffe.set_mode_cpu()\n\n    #get the weights and biases out of the array\n    #the weights have to be transposed because of differences between Caffe and Tensorflow\n    #format filter weights:\n    #Tensorflow: [height (0), width (1), depth (2), number of filters (3)]\n    #Caffe:      [number of filters (3), depth (2), height (0), width (1)]\n\n\n    weights1 = data_file[0][0].transpose((3,2,0,1))\n    bias1 = data_file[0][1]\n\n    weights2 = data_file[1][0].transpose((3,2,0,1))\n    bias2 = data_file[1][1]\n\n    weights3 = data_file[2][0].transpose((3,2,0,1))\n    bias3 = data_file[2][1]\n\n    #connecting the tensor after last pooling layer with the first fully-connected layer\n    #here is the link to the video where this part is explained (https://youtu.be/kvXHOIn3-8s?t=3m38s)\n    fc1_w = data_file[3][0].reshape((28,28,64,120))\n    fc1_w = fc1_w.transpose((3,2,0,1))\n    fc1_w = fc1_w.reshape((120,50176))\n    fc1_b = data_file[3][1]\n\n    #fully connected layer format:\n    #Tensorflow: [number of inputs (0), number of outputs (1)]\n    #Caffe:      [number of outputs (1), number of inputs (0)]\n    fc2_w = data_file[4][0].transpose((1,0))\n    fc2_b = data_file[4][1]\n\n    fc3_w = data_file[5][0].transpose((1,0))\n    fc3_b = data_file[5][1]\n\n    #define architecture\n    print('Start creating caffe model')\n    net = caffe.Net('./LeNet.prototxt', caffe.TEST)\n    #load parameters\n\n    net.params['conv2d_1'][0].data[...] = weights1\n    net.params['conv2d_1'][1].data[...] = bias1\n\n    net.params['conv2d_2'][0].data[...] = weights2\n    net.params['conv2d_2'][1].data[...] = bias2\n\n    net.params['conv2d_3'][0].data[...] = weights3\n    net.params['conv2d_3'][1].data[...] = bias3\n\n\n    net.params['dense_1'][0].data[...]= fc1_w\n    net.params['dense_1'][1].data[...] = fc1_b\n\n    net.params['dense_2'][0].data[...] = fc2_w\n    net.params['dense_2'][1].data[...] = fc2_b\n\n    net.params['dense_3'][0].data[...] = fc3_w\n    net.params['dense_3'][1].data[...] = fc3_b\n    print('End')\n    #save caffemodel\n    net.save('LeNet.caffemodel')\n</code></pre>\n <machine-learning-model>",
                "codes": [],
                "question_id:": "56988",
                "question_votes:": "",
                "question_text:": "<p>I am converting .hf model to caffe model.\nI have created .prototxt of my model and also extracted the weights. The problem I am facing is to create .caffemodel from my existing model because my model have a flatten layer and in create_caffemodel.py when I assign weights to the fully connected layer , the error says that shape of weights and layer does not match.\nI am unable to reshape my model kindly help me.</p>\n\n<p><strong>LeNet.prototxt</strong></p>\n\n<pre><code>name: 'LeNet'\ninput: 'data'\ninput_shape{\ndim: 1  #no of images\ndim: 3   #no of channels\ndim :224    #width\ndim :224\n}\nlayer {\n  name: \"conv2d_1\"\n  type: \"Convolution\"\n  bottom: \"data\"\n  top: \"conv2d_1\"\n  convolution_param{\n    num_output: 64\n    kernel_size: 5\n    stride: 2\n    pad: 0\n  }\n}\nlayer {\n  name: \"activation_1\"\n  type: \"ReLU\"\n  bottom: \"conv2d_1\"\n  top: \"conv2d_1\"\n}\n\nlayer {\n  name: \"max_pooling2d_1\"\n  type: \"Pooling\"\n  bottom: \"conv2d_1\"\n  top: \"max_pooling2d_1\"\n  pooling_param{\n    pool :MAX\n    kernel_size: 5\n    stride: 2\n    pad: 0\n  }\n}\nlayer {\n  name: \"conv2d_2\"\n      type: \"Convolution\"\n  bottom: \"max_pooling2d_1\"\n  top: \"conv2d_2\"\n  convolution_param{\n    num_output: 16\n    kernel_size: 5\n    stride: 2\n    pad: 0\n  }\n}\nlayer {\n  name: \"activation_2\"\n  type: \"ReLU\"\n  bottom: \"conv2d_2\"\n  top: \"conv2d_2\"\n}\nlayer {\n  name: \"max_pooling2d_2\"\n  type: \"Pooling\"\n  bottom: \"conv2d_2\"\n  top: \"max_pooling2d_2\"\n  pooling_param{\n    pool :MAX\n    kernel_size: 5\n    stride: 2\n    pad: 0\n  }\n}\nlayer {\n  name: \"conv2d_3\"\n  type: \"Convolution\"\n  bottom: \"max_pooling2d_2\"\n  top: \"conv2d_3\"\n  convolution_param{\n    num_output: 64\n    kernel_size: 5\n    stride: 2\n    pad: 0\n  }\n}\nlayer {\n  name: \"activation_3\"\n  type: \"ReLU\"\n  bottom: \"conv2d_3\"\n  top: \"conv2d_3\"\n}\nlayer {\n  name: \"max_pooling2d_3\"\n  type: \"Pooling\"\n  bottom: \"conv2d_3\"\n  top: \"max_pooling2d_3\"\n  pooling_param{\n    pool :MAX\n    kernel_size: 5\n    stride: 2\n    pad: 0\n  }\n}\nlayer{\n  name: \"flatten_1\"\n  type: \"Reshape\"\n  bottom: \"max_pooling2d_3\"\n  top: \"flatten_1\"\n    reshape_param{shape:{dim:0 dim:1 dim:-1 dim:1}}\n}\nlayer {\n  name: \"dense_1\"\n  type: \"InnerProduct\"\n  bottom:\"flatten_1\"\n  top:\"dense_1\"\n  inner_product_param {\n    num_output: 120\n  }\n  param {\n        lr_mult: 1\n    }\n    param {\n        lr_mult: 2\n    }\n}\nlayer {\n  name: \"activation_4\"\n  type: \"ReLU\"\n      bottom: \"dense_1\"\n  top: \"dense_1\"\n    }\n    layer {\n  name: \"dense_2\"\n  type: \"InnerProduct\"\n  bottom:\"dense_1\"\n  top:\"dense_2\"\n  inner_product_param {\n    num_output: 64\n  }\n    }\n    layer {\n  name: \"activation_5\"\n  type: \"ReLU\"\n      bottom: \"dense_2\"\n  top: \"dense_2\"\n    }\nlayer {\n  name: \"dense_3\"\n  type: \"InnerProduct\"\n  bottom:\"dense_2\"\n  top:\"dense_3\"\n  inner_product_param {\n num_output: 10\n  }\n }\n layer {\n   name: \"activation_6\"\n   type: \"Softmax\"\n   bottom: \"dense_3\"\n   top: \"dense_3\"\n }\n</code></pre>\n\n<p><strong>Model</strong>\n<a href=\"https://i.stack.imgur.com/uiLWy.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/uiLWy.png\" alt=\"LeNet Model Description\"></a></p>\n\n<p><strong>Create_caffemodel.py</strong></p>\n\n<pre><code>        # -*- coding: utf-8 -*-\n    \"\"\"\n    Created on Mon Jul 29 11:59:15 2019\n\n    @author: hrehman\n    \"\"\"\n    from __future__ import print_function, division\n    caffe_root = '/TUB/robo/caffe-master/'\n\n    import sys\n    sys.path.insert(0, caffe_root+'python')\n    import caffe\n    import numpy as np\n\n    #load the data file\n    data_file = np.load('./LeNet.npy',allow_pickle=True)\n    caffe.set_mode_cpu()\n\n    #get the weights and biases out of the array\n    #the weights have to be transposed because of differences between Caffe and Tensorflow\n    #format filter weights:\n    #Tensorflow: [height (0), width (1), depth (2), number of filters (3)]\n    #Caffe:      [number of filters (3), depth (2), height (0), width (1)]\n\n\n    weights1 = data_file[0][0].transpose((3,2,0,1))\n    bias1 = data_file[0][1]\n\n    weights2 = data_file[1][0].transpose((3,2,0,1))\n    bias2 = data_file[1][1]\n\n    weights3 = data_file[2][0].transpose((3,2,0,1))\n    bias3 = data_file[2][1]\n\n    #connecting the tensor after last pooling layer with the first fully-connected layer\n    #here is the link to the video where this part is explained (https://youtu.be/kvXHOIn3-8s?t=3m38s)\n    fc1_w = data_file[3][0].reshape((28,28,64,120))\n    fc1_w = fc1_w.transpose((3,2,0,1))\n    fc1_w = fc1_w.reshape((120,50176))\n    fc1_b = data_file[3][1]\n\n    #fully connected layer format:\n    #Tensorflow: [number of inputs (0), number of outputs (1)]\n    #Caffe:      [number of outputs (1), number of inputs (0)]\n    fc2_w = data_file[4][0].transpose((1,0))\n    fc2_b = data_file[4][1]\n\n    fc3_w = data_file[5][0].transpose((1,0))\n    fc3_b = data_file[5][1]\n\n    #define architecture\n    print('Start creating caffe model')\n    net = caffe.Net('./LeNet.prototxt', caffe.TEST)\n    #load parameters\n\n    net.params['conv2d_1'][0].data[...] = weights1\n    net.params['conv2d_1'][1].data[...] = bias1\n\n    net.params['conv2d_2'][0].data[...] = weights2\n    net.params['conv2d_2'][1].data[...] = bias2\n\n    net.params['conv2d_3'][0].data[...] = weights3\n    net.params['conv2d_3'][1].data[...] = bias3\n\n\n    net.params['dense_1'][0].data[...]= fc1_w\n    net.params['dense_1'][1].data[...] = fc1_b\n\n    net.params['dense_2'][0].data[...] = fc2_w\n    net.params['dense_2'][1].data[...] = fc2_b\n\n    net.params['dense_3'][0].data[...] = fc3_w\n    net.params['dense_3'][1].data[...] = fc3_b\n    print('End')\n    #save caffemodel\n    net.save('LeNet.caffemodel')\n</code></pre>\n",
                "tags": "<machine-learning-model>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6275",
            "_score": 7.1004086,
            "_source": {
                "title": "ReLU activation function outputs HUGE numbers",
                "content": "ReLU activation function outputs HUGE numbers <p>I have FINALLY been able to implement backpropagation, but there are still some bugs I need to fix.  The main is issue the following: <strong>My ReLU activation function produces really big dJdW values (derivative of error function wrt weights).</strong>  When this gets subtracted from the weights, my output becomes a matrix of -int or inf.  How do I stop this?  As of now, the only solution I have is to make my learning rate <em>scalar</em> variable REALLY small.</p>\n\n<pre><code>import numpy as np\n\n\nclass Neural_Network(object):\n    def __init__(self, input_, hidden_, output_, numHiddenLayer_, numExamples_):\n        # Define Hyperparameters\n        self.inputLayerSize = input_\n        self.outputLayerSize = output_\n        self.hiddenLayerSize = hidden_\n        self.numHiddenLayer = numHiddenLayer_\n        self.numExamples = numExamples_\n        self.scalar = 0.0000000001 # LEARNING RATE: Why does ReLU produce such large dJdW values?\n        # in -&gt; out\n        self.weights = [] # stores matrices of each layer of weights\n        self.z = [] # stores matrices of each layer of weighted sums\n        self.a = [] # stores matrices of each layer of activity \n        self.biases = [] # stores all biases\n\n        # Biases are matrices that are added to activity matrix\n        # Dimensions -&gt; numExamples_*hiddenLayerSize or numExamples_*outputLayerSize\n        for i in range(self.numHiddenLayer):\n            # Biases for hidden layer\n            b = [np.random.random() for x in range(self.hiddenLayerSize)];\n            B = [b for x in range(self.numExamples)];\n            self.biases.append(np.mat(B))\n        # Biases for output layer\n        b = [np.random.random() for x in range(self.outputLayerSize)]\n        B = [b for x in range(self.numExamples)];\n        self.biases.append(np.mat(B))\n\n\n        # Weights (Parameters)\n        # Weight matrix between input and first layer\n        W = np.random.rand(self.inputLayerSize, self.hiddenLayerSize)\n        self.weights.append(W)\n\n        for i in range(self.numHiddenLayer-1):\n            # Weight matrices between hidden layers\n            W = np.random.rand(self.hiddenLayerSize, self.hiddenLayerSize)\n            self.weights.append(W)\n        # Weight matric between hiddenlayer and outputlayer\n        self.weights.append(np.random.rand(self.hiddenLayerSize, self.outputLayerSize))\n\n    def setBatchSize(self, numExamples):\n        # Changes the number of rows (examples) for biases\n        if (self.numExamples &gt; numExamples):\n            self.biases = [b[:numExamples] for b in self.biases]\n\n    def sigmoid(self, z):\n        # Apply sigmoid activation function\n        return 1/(1+np.exp(-z))\n\n    def sigmoidPrime(self, z):\n        # Derivative of sigmoid function\n        return 1-self.sigmoid(z)\n\n    def ReLU(self, z):\n        # Apply activation function\n        for (i, j), item in np.ndenumerate(z):\n            if (item &lt; 0):\n                item *= 0.01\n            else:\n                item = item\n        return z        \n\n\n    def ReLUPrime(self, z):\n        # Derivative of ReLU activation function\n        for (i, j), item in np.ndenumerate(z):\n            if (item &lt; 0):\n                item = 0.01\n            else:\n                item = 1\n\n        return z\n\n    def forward(self, X):\n        # Propagate outputs through network\n\n        self.z.append(np.dot(X, self.weights[0]) + self.biases[0])\n        self.a.append(self.ReLU(self.z[0]))\n\n        for i in range(1, self.numHiddenLayer):\n            self.z.append(np.dot(self.a[-1], self.weights[i]) + self.biases[i])\n            self.a.append(self.ReLU(self.z[-1]))\n\n        self.z.append(np.dot(self.z[-1], self.weights[-1]) + self.biases[-1])\n        self.a.append(self.ReLU(self.z[-1]))\n        yHat = self.ReLU(self.z[-1])\n        return yHat\n\n    def backProp(self, X, y):\n        # Compute derivative wrt W\n        # out -&gt; in\n        dJdW = [] # stores matrices of each dJdW (equal in size to self.weights[])\n        delta = [] # stores matrices of each backpropagating error\n\n        self.yHat = self.forward(X)\n        delta.insert(0,np.multiply(-(y-self.yHat), self.ReLUPrime(self.z[-1]))) # delta = (y-yHat)(sigmoidPrime(final layer unactivated))\n        dJdW.insert(0, np.dot(self.a[-2].T, delta[0])) # dJdW\n        for i in range(len(self.weights)-1, 1, -1):\n            # Iterate from self.weights[-1] -&gt; self.weights[1]\n            delta.insert(0, np.multiply(np.dot(delta[0], self.weights[i].T), self.ReLUPrime(self.z[i-1])))\n            dJdW.insert(0, np.dot(self.a[i-2].T, delta[0]))\n\n        delta.insert(0, np.multiply(np.dot(delta[0], self.weights[1].T), self.ReLUPrime(self.z[0])))\n        dJdW.insert(0, np.dot(X.T, delta[0]))\n\n\n        return dJdW\n\n    def train(self, X, y):\n        for t in range(60000):\n            dJdW = self.backProp(X, y)\n            for i in range(len(dJdW)):\n                self.weights[i] -= self.scalar*dJdW[i]\n\n# Instantiating Neural Network\ninputs = [int(np.random.randint(0,100)) for x in range(100)]\nx = np.mat([x for x in inputs]).reshape(100,1)\ny = np.mat([x+1 for x in inputs]).reshape(100,1)\nNN = Neural_Network(1,3,1,1,100)\n\n\n# Training\nprint(\"INPUT: \", end = '\\n')\nprint(x, end = '\\n\\n')\n\nprint(\"BEFORE TRAINING\", NN.forward(x), sep = '\\n', end = '\\n\\n')\nNN.train(x,y)\nprint(\"AFTER TRAINING\", NN.forward(x), sep = '\\n', end = '\\n\\n')\n\n# Testing\ntest = np.mat([int(np.random.randint(0,100)) for x in range(100)]).reshape(100,1)\nprint(\"TEST INPUT:\", test, sep = '\\n', end = '\\n\\n')\nprint(NN.forward(test), end = '\\n\\n')\n\n\nNN.setBatchSize(1) # changing settings to receive one input at a time\n\nwhile True:\n    # Give numbers between 0-100 (I need to fix overfitting) and it will get next value\n    inputs = input()\n    x = np.mat([int(i) for i in inputs.split(\" \")])\n    print(NN.forward(x))\n</code></pre>\n\n<p>I first made the ANN using sigmoid but Leaky ReLU is faster.\nThe code is a bit much so here is a summary:</p>\n\n<ol>\n<li>Neural Network Class\n\n<ul>\n<li>define hyperparameter and stuff (include really small learning rate scalar)</li>\n<li>activation functions and their derivatives (<em>ReLU</em> and sigmoid)</li>\n<li>Member functions: forward propagation, backpropagation, setBatchSize etc.</li>\n</ul></li>\n<li>Instantiating ANN\n\n<ul>\n<li>setting hyperparameters (topology of ANN)</li>\n<li>creating data (one array has values x and the output array has values x+1)</li>\n</ul></li>\n<li>Training\n\n<ul>\n<li>using inputs generated in step 2 to train ANN</li>\n</ul></li>\n<li>Testing\n\n<ul>\n<li>Testing using randomly generated inputs</li>\n<li>User can give inputs</li>\n</ul></li>\n</ol>\n\n<p>Hope that helps you help me.  Thanks!</p>\n <machine-learning><backpropagation><p>I suspect the problem is the fact that your input data values are very high. You're trying to map the input variable $x \\in (0,100)$ to $y = x+1$ in your code, but neural networks work best when the data has much lower values. A good strategy is to normalise the data before training so that each feature has zero mean and unit variance. Try scaling your data down like so (I've also changed the code that originally generates the inputs to make it more efficient in numpy):</p>\n\n<pre><code># Instantiating Neural Network\nx = np.random.randint(0, 100, size=100).reshape(100,1)\ny = x + 1\n\n# normalize data to have zero mean and unit variance\nx_normalized = (x - x.mean()) / x.std()\ny_normalized = (y - y.mean()) / y.std()\n</code></pre>\n\n<p>Train your network with <code>x_normalized</code> and <code>y_normalized</code> instead of <code>x</code> and <code>y</code>. Then, during testing, you normalize your input data like above, and you can scale your predictions back up to the original scale by rearranging the above formula.</p>\n\n<pre><code># generate test data &amp; normalize using train data mean&amp;std\ntest = np.random.randint(0, 100, size=100).reshape(100,1)\ntest_x_normalized = (test - x.mean()) / x.std()\n\n# input to network to get normalized outputs\ntest_y_normalized = NN.forward(test_x_normalized)\n\n# rescale normalized outputs to original 0-100 scale\ntest_y = (test_y_normalized * y.std()) + y.mean()\n\nprint(\"TEST INPUT:\", test, sep = '\\n', end = '\\n\\n')\nprint(test_y, end = '\\n\\n')\n</code></pre>\n",
                "codes": [
                    [
                        "# Instantiating Neural Network\nx = np.random.randint(0, 100, size=100).reshape(100,1)\ny = x + 1\n\n# normalize data to have zero mean and unit variance\nx_normalized = (x - x.mean()) / x.std()\ny_normalized = (y - y.mean()) / y.std()\n",
                        "# generate test data & normalize using train data mean&std\ntest = np.random.randint(0, 100, size=100).reshape(100,1)\ntest_x_normalized = (test - x.mean()) / x.std()\n\n# input to network to get normalized outputs\ntest_y_normalized = NN.forward(test_x_normalized)\n\n# rescale normalized outputs to original 0-100 scale\ntest_y = (test_y_normalized * y.std()) + y.mean()\n\nprint(\"TEST INPUT:\", test, sep = '\\n', end = '\\n\\n')\nprint(test_y, end = '\\n\\n')\n"
                    ]
                ],
                "question_id:": "24579",
                "question_votes:": "2",
                "question_text:": "<p>I have FINALLY been able to implement backpropagation, but there are still some bugs I need to fix.  The main is issue the following: <strong>My ReLU activation function produces really big dJdW values (derivative of error function wrt weights).</strong>  When this gets subtracted from the weights, my output becomes a matrix of -int or inf.  How do I stop this?  As of now, the only solution I have is to make my learning rate <em>scalar</em> variable REALLY small.</p>\n\n<pre><code>import numpy as np\n\n\nclass Neural_Network(object):\n    def __init__(self, input_, hidden_, output_, numHiddenLayer_, numExamples_):\n        # Define Hyperparameters\n        self.inputLayerSize = input_\n        self.outputLayerSize = output_\n        self.hiddenLayerSize = hidden_\n        self.numHiddenLayer = numHiddenLayer_\n        self.numExamples = numExamples_\n        self.scalar = 0.0000000001 # LEARNING RATE: Why does ReLU produce such large dJdW values?\n        # in -&gt; out\n        self.weights = [] # stores matrices of each layer of weights\n        self.z = [] # stores matrices of each layer of weighted sums\n        self.a = [] # stores matrices of each layer of activity \n        self.biases = [] # stores all biases\n\n        # Biases are matrices that are added to activity matrix\n        # Dimensions -&gt; numExamples_*hiddenLayerSize or numExamples_*outputLayerSize\n        for i in range(self.numHiddenLayer):\n            # Biases for hidden layer\n            b = [np.random.random() for x in range(self.hiddenLayerSize)];\n            B = [b for x in range(self.numExamples)];\n            self.biases.append(np.mat(B))\n        # Biases for output layer\n        b = [np.random.random() for x in range(self.outputLayerSize)]\n        B = [b for x in range(self.numExamples)];\n        self.biases.append(np.mat(B))\n\n\n        # Weights (Parameters)\n        # Weight matrix between input and first layer\n        W = np.random.rand(self.inputLayerSize, self.hiddenLayerSize)\n        self.weights.append(W)\n\n        for i in range(self.numHiddenLayer-1):\n            # Weight matrices between hidden layers\n            W = np.random.rand(self.hiddenLayerSize, self.hiddenLayerSize)\n            self.weights.append(W)\n        # Weight matric between hiddenlayer and outputlayer\n        self.weights.append(np.random.rand(self.hiddenLayerSize, self.outputLayerSize))\n\n    def setBatchSize(self, numExamples):\n        # Changes the number of rows (examples) for biases\n        if (self.numExamples &gt; numExamples):\n            self.biases = [b[:numExamples] for b in self.biases]\n\n    def sigmoid(self, z):\n        # Apply sigmoid activation function\n        return 1/(1+np.exp(-z))\n\n    def sigmoidPrime(self, z):\n        # Derivative of sigmoid function\n        return 1-self.sigmoid(z)\n\n    def ReLU(self, z):\n        # Apply activation function\n        for (i, j), item in np.ndenumerate(z):\n            if (item &lt; 0):\n                item *= 0.01\n            else:\n                item = item\n        return z        \n\n\n    def ReLUPrime(self, z):\n        # Derivative of ReLU activation function\n        for (i, j), item in np.ndenumerate(z):\n            if (item &lt; 0):\n                item = 0.01\n            else:\n                item = 1\n\n        return z\n\n    def forward(self, X):\n        # Propagate outputs through network\n\n        self.z.append(np.dot(X, self.weights[0]) + self.biases[0])\n        self.a.append(self.ReLU(self.z[0]))\n\n        for i in range(1, self.numHiddenLayer):\n            self.z.append(np.dot(self.a[-1], self.weights[i]) + self.biases[i])\n            self.a.append(self.ReLU(self.z[-1]))\n\n        self.z.append(np.dot(self.z[-1], self.weights[-1]) + self.biases[-1])\n        self.a.append(self.ReLU(self.z[-1]))\n        yHat = self.ReLU(self.z[-1])\n        return yHat\n\n    def backProp(self, X, y):\n        # Compute derivative wrt W\n        # out -&gt; in\n        dJdW = [] # stores matrices of each dJdW (equal in size to self.weights[])\n        delta = [] # stores matrices of each backpropagating error\n\n        self.yHat = self.forward(X)\n        delta.insert(0,np.multiply(-(y-self.yHat), self.ReLUPrime(self.z[-1]))) # delta = (y-yHat)(sigmoidPrime(final layer unactivated))\n        dJdW.insert(0, np.dot(self.a[-2].T, delta[0])) # dJdW\n        for i in range(len(self.weights)-1, 1, -1):\n            # Iterate from self.weights[-1] -&gt; self.weights[1]\n            delta.insert(0, np.multiply(np.dot(delta[0], self.weights[i].T), self.ReLUPrime(self.z[i-1])))\n            dJdW.insert(0, np.dot(self.a[i-2].T, delta[0]))\n\n        delta.insert(0, np.multiply(np.dot(delta[0], self.weights[1].T), self.ReLUPrime(self.z[0])))\n        dJdW.insert(0, np.dot(X.T, delta[0]))\n\n\n        return dJdW\n\n    def train(self, X, y):\n        for t in range(60000):\n            dJdW = self.backProp(X, y)\n            for i in range(len(dJdW)):\n                self.weights[i] -= self.scalar*dJdW[i]\n\n# Instantiating Neural Network\ninputs = [int(np.random.randint(0,100)) for x in range(100)]\nx = np.mat([x for x in inputs]).reshape(100,1)\ny = np.mat([x+1 for x in inputs]).reshape(100,1)\nNN = Neural_Network(1,3,1,1,100)\n\n\n# Training\nprint(\"INPUT: \", end = '\\n')\nprint(x, end = '\\n\\n')\n\nprint(\"BEFORE TRAINING\", NN.forward(x), sep = '\\n', end = '\\n\\n')\nNN.train(x,y)\nprint(\"AFTER TRAINING\", NN.forward(x), sep = '\\n', end = '\\n\\n')\n\n# Testing\ntest = np.mat([int(np.random.randint(0,100)) for x in range(100)]).reshape(100,1)\nprint(\"TEST INPUT:\", test, sep = '\\n', end = '\\n\\n')\nprint(NN.forward(test), end = '\\n\\n')\n\n\nNN.setBatchSize(1) # changing settings to receive one input at a time\n\nwhile True:\n    # Give numbers between 0-100 (I need to fix overfitting) and it will get next value\n    inputs = input()\n    x = np.mat([int(i) for i in inputs.split(\" \")])\n    print(NN.forward(x))\n</code></pre>\n\n<p>I first made the ANN using sigmoid but Leaky ReLU is faster.\nThe code is a bit much so here is a summary:</p>\n\n<ol>\n<li>Neural Network Class\n\n<ul>\n<li>define hyperparameter and stuff (include really small learning rate scalar)</li>\n<li>activation functions and their derivatives (<em>ReLU</em> and sigmoid)</li>\n<li>Member functions: forward propagation, backpropagation, setBatchSize etc.</li>\n</ul></li>\n<li>Instantiating ANN\n\n<ul>\n<li>setting hyperparameters (topology of ANN)</li>\n<li>creating data (one array has values x and the output array has values x+1)</li>\n</ul></li>\n<li>Training\n\n<ul>\n<li>using inputs generated in step 2 to train ANN</li>\n</ul></li>\n<li>Testing\n\n<ul>\n<li>Testing using randomly generated inputs</li>\n<li>User can give inputs</li>\n</ul></li>\n</ol>\n\n<p>Hope that helps you help me.  Thanks!</p>\n",
                "tags": "<machine-learning><backpropagation>",
                "answers": [
                    [
                        "24584",
                        "2",
                        "24579",
                        "",
                        "",
                        "<p>I suspect the problem is the fact that your input data values are very high. You're trying to map the input variable $x \\in (0,100)$ to $y = x+1$ in your code, but neural networks work best when the data has much lower values. A good strategy is to normalise the data before training so that each feature has zero mean and unit variance. Try scaling your data down like so (I've also changed the code that originally generates the inputs to make it more efficient in numpy):</p>\n\n<pre><code># Instantiating Neural Network\nx = np.random.randint(0, 100, size=100).reshape(100,1)\ny = x + 1\n\n# normalize data to have zero mean and unit variance\nx_normalized = (x - x.mean()) / x.std()\ny_normalized = (y - y.mean()) / y.std()\n</code></pre>\n\n<p>Train your network with <code>x_normalized</code> and <code>y_normalized</code> instead of <code>x</code> and <code>y</code>. Then, during testing, you normalize your input data like above, and you can scale your predictions back up to the original scale by rearranging the above formula.</p>\n\n<pre><code># generate test data &amp; normalize using train data mean&amp;std\ntest = np.random.randint(0, 100, size=100).reshape(100,1)\ntest_x_normalized = (test - x.mean()) / x.std()\n\n# input to network to get normalized outputs\ntest_y_normalized = NN.forward(test_x_normalized)\n\n# rescale normalized outputs to original 0-100 scale\ntest_y = (test_y_normalized * y.std()) + y.mean()\n\nprint(\"TEST INPUT:\", test, sep = '\\n', end = '\\n\\n')\nprint(test_y, end = '\\n\\n')\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6600",
            "_score": 7.1004086,
            "_source": {
                "title": "Tensorflow regression predicting 1 for all inputs",
                "content": "Tensorflow regression predicting 1 for all inputs <p>I'm trying to predict a UPDRS score (regression) from the <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/telemonitoring/\" rel=\"nofollow noreferrer\">parkinsons dataset</a>. I wanted to start with a fairly basic structure and the add in more layers/techniques to improve performance but no matter what I do the network constantly predicts 1 for every input. </p>\n\n<p>I've been banging my head against this problem for a couple of days now with no success. Originally I was using RELU and thought it was a case of dead neurons but using leaky RELU and monitoring the outputs I can see them firing.</p>\n\n<p>Changing the network structure or training steps always results with the same horrible MSE of 896.39105. This leads me to believe the mistake is somewhere in the normalization but when I check the intermediate values they all seem fine.</p>\n\n<p>Can anyone tell me where I've messed up?</p>\n\n<pre>\n\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.preprocessing import normalize\nfrom sklearn.preprocessing import StandardScaler\n\n\ndef leaky_relu(x, alpha):\n  return tf.nn.relu(x) - alpha * tf.nn.relu(-x)\n\nraw = pd.read_csv('parkinsons_updrs.data')\nprint(\"CSV loaded successfully\")\n\n#Split into features and targets\nfeatures = raw.drop(['subject#','test_time','motor_UPDRS','total_UPDRS'], axis = 1).as_matrix()\ntargets = raw['total_UPDRS'].get_values()\n\nscale = StandardScaler(with_mean=0, with_std=1)\nscale.fit(features, targets)\nscaled_feats = scale.transform(features)\n\nprint(\"pre-processing complete\")\n\n#Split data into test/train\ndata_train, data_test, targets_train, targets_test = train_test_split(scaled_feats,targets,test_size = 0.2,random_state=123)\n\nprint(\"Train/Test split complete\")\n\n\n#Need to reshape to match placeholder shape\ntargets_train = targets_train.reshape(targets_train.shape[0],-1)\ntargets_test = targets_test.reshape(targets_test.shape[0],-1)\n\n\n\n#Network Structure\nX = tf.placeholder(tf.float32, [None,features.shape[1]])\ny = tf.placeholder(tf.float32, [None,1])\nprob = tf.placeholder(tf.float32)\n\nw1 = tf.Variable(tf.random_normal([features.shape[1],100]))\nw2 = tf.Variable(tf.random_normal([100,1]))\n\nb1 = tf.Variable(tf.random_normal([100]))\nb2 = tf.Variable(tf.random_normal([1]))\n\n\nlayer1 = tf.nn.dropout(leaky_relu(tf.add(tf.matmul(X,w1),b1),0.2),prob)\nout = tf.nn.dropout(tf.nn.tanh(tf.add(tf.matmul(layer1,w2),b2)),prob)\n\nloss = tf.reduce_mean(tf.square(out - y))\ntrain_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\nprint(\"Training...\")\n\n\nminibatch = False\nbatchsize = 512\n\n\nfor i in range(1000):\n    if minibatch:\n        for x in range(0,targets_train.shape[0],batchsize):\n            sess.run(train_step, feed_dict={X:data_train[x:x+batchsize],y:targets_train[x:x+batchsize],prob:0.5})\n    else:\n        sess.run(train_step, feed_dict={X:data_train,y:targets_train,prob:0.5})\n    if i%25==0:\n        acc = sess.run(loss, feed_dict={X: data_train, y: targets_train,prob:1})\n        print (\"Training accuracy: %.5f\" % (acc))\n        #print(sess.run(layer1,feed_dict={X: data_train, y: targets_train,prob:1})[0])\n\n\n\ntest_acc = sess.run(loss, feed_dict={X: data_test, y: targets_test,prob:1})\nprint (\"Test accuracy: %.5f\" % (test_acc))\n\n#Check if still predicting 1\noutput = sess.run(out,feed_dict={X: data_test, y: targets_test,prob:1})\nprint(sum(output)==len(output))\n\n\n\n</pre>\n <machine-learning><neural-network><deep-learning><regression><tensorflow><p>The range of tanh is (-1, 1), but the target is at least 7.<br>\nSo I think you should rescale the range of target to be [-1, 1].</p>\n\n<p>And when I tested, </p>\n\n<pre><code>w1 = tf.Variable(tf.random_normal([features.shape[1],100], stddev=0.1))\nw2 = tf.Variable(tf.random_normal([100,1], stddev=0.1))\n</code></pre>\n\n<p>works better than</p>\n\n<pre><code>w1 = tf.Variable(tf.random_normal([features.shape[1],100]))\nw2 = tf.Variable(tf.random_normal([100,1]))\n</code></pre>\n\n<p>.</p>\n<p>Ok, I've managed to get a decent improvement. Currently producing an MSE of 20 for training and 30 for test. This is after converting all layers to relu and increasing their size. </p>\n\n<p>The problem appeared the activation function on the output. I was under the impression that a sigmoid output layer was common practice.</p>\n\n<p>I was also normalizing before the test/train split and leaking information into the test set! (though this likely wasn't the cause of my problem)</p>\n\n<p>Here is my 'improved' code:</p>\n\n<pre>\n\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn import preprocessing\n\n\nraw = pd.read_csv('parkinsons_updrs.data')\nprint(\"CSV loaded successfully\")\n\nevents = raw.shape[0]\n#drop events where any feature has a zscore > 3 for that feature\nraw = raw[(np.abs(stats.zscore(raw)) &lt 3).all(axis=1)]\nprint(\"Removed \" + str(events-raw.shape[0]) + \" outlier events\")\n\nfeatures = raw.drop(['subject#','test_time','motor_UPDRS','total_UPDRS'], axis = 1)\ntargets = raw['total_UPDRS'].get_values()\nprint(\"pre-processing complete\")\n\n#Split data into test/train\ndata_train, data_test, targets_train, targets_test = train_test_split(features,targets,test_size = 0.33,random_state=123)\nprint(\"Train/Test split complete\")\n\n\n#Normalize data to mean 0 and std 1\n#We normalize after the split to avoid leaking information to the training set\ndata_train = (data_train-data_train.mean())/data_train.std()\ndata_test = (data_test-data_test.mean())/data_test.std()\n\ntargets_train = targets_train.reshape(targets_train.shape[0],-1)\ntargets_test = targets_test.reshape(targets_test.shape[0],-1)\n\n\n\n#Network Structure\nX = tf.placeholder(tf.float32, [None,18])\ny = tf.placeholder(tf.float32, [None,1])\nprob = tf.placeholder_with_default(1.0, shape=())\n\nw1 = tf.Variable(tf.random_normal([18,72]))\nw2 = tf.Variable(tf.random_normal([72,36]))\nw3 = tf.Variable(tf.random_normal([36,1]))\n\nb1 = tf.Variable(tf.random_normal([72]))\nb2 = tf.Variable(tf.random_normal([36]))\nb3 = tf.Variable(tf.random_normal([1]))\n\n\n\nlayer1 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(X,w1),b1)),prob)\nlayer2 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(layer1,w2),b2)),prob)\nout = tf.nn.relu(tf.add(tf.matmul(layer2,w3),b3))\n\nloss = tf.losses.mean_squared_error(y, out)\n\ntrain_step = tf.train.AdamOptimizer(0.005).minimize(loss)\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\nprint(\"Training...\")\n\n\nminibatch = True\nbatchsize = 512\n\n\nfor i in range(10000):\n    if minibatch:\n        for x in range(0,targets_train.shape[0],batchsize):\n            sess.run(train_step, feed_dict={X:data_train[x:x+batchsize],y:targets_train[x:x+batchsize],prob:0.5})\n    else:\n        sess.run(train_step, feed_dict={X:data_train,y:targets_train,prob:0.5})\n    if i%25==0:\n        acc = sess.run(loss, feed_dict={X: data_train, y: targets_train})\n        print (\"Training accuracy: %.5f\" % (acc))\n\n\n\ntest_acc = sess.run(loss, feed_dict={X: data_test, y: targets_test})\nprint (\"Test accuracy: %.5f\" % (test_acc))\n\noutput = sess.run(out,feed_dict={X: data_test, y: targets_test})\n\nerror = abs(output-targets_test)\n\nprint(max(error))\nprint(sum(error)/len(error))\nprint(min(error))\n </pre>\n\n<p>I'd be very interested to know why this happened. Both tanh and sigmoid get 'stuck' in the 900s whereas relu sorts itself out and carries on.</p>\n",
                "codes": [
                    [
                        "w1 = tf.Variable(tf.random_normal([features.shape[1],100], stddev=0.1))\nw2 = tf.Variable(tf.random_normal([100,1], stddev=0.1))\n",
                        "w1 = tf.Variable(tf.random_normal([features.shape[1],100]))\nw2 = tf.Variable(tf.random_normal([100,1]))\n"
                    ],
                    []
                ],
                "question_id:": "25542",
                "question_votes:": "1",
                "question_text:": "<p>I'm trying to predict a UPDRS score (regression) from the <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/telemonitoring/\" rel=\"nofollow noreferrer\">parkinsons dataset</a>. I wanted to start with a fairly basic structure and the add in more layers/techniques to improve performance but no matter what I do the network constantly predicts 1 for every input. </p>\n\n<p>I've been banging my head against this problem for a couple of days now with no success. Originally I was using RELU and thought it was a case of dead neurons but using leaky RELU and monitoring the outputs I can see them firing.</p>\n\n<p>Changing the network structure or training steps always results with the same horrible MSE of 896.39105. This leads me to believe the mistake is somewhere in the normalization but when I check the intermediate values they all seem fine.</p>\n\n<p>Can anyone tell me where I've messed up?</p>\n\n<pre>\n\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.preprocessing import normalize\nfrom sklearn.preprocessing import StandardScaler\n\n\ndef leaky_relu(x, alpha):\n  return tf.nn.relu(x) - alpha * tf.nn.relu(-x)\n\nraw = pd.read_csv('parkinsons_updrs.data')\nprint(\"CSV loaded successfully\")\n\n#Split into features and targets\nfeatures = raw.drop(['subject#','test_time','motor_UPDRS','total_UPDRS'], axis = 1).as_matrix()\ntargets = raw['total_UPDRS'].get_values()\n\nscale = StandardScaler(with_mean=0, with_std=1)\nscale.fit(features, targets)\nscaled_feats = scale.transform(features)\n\nprint(\"pre-processing complete\")\n\n#Split data into test/train\ndata_train, data_test, targets_train, targets_test = train_test_split(scaled_feats,targets,test_size = 0.2,random_state=123)\n\nprint(\"Train/Test split complete\")\n\n\n#Need to reshape to match placeholder shape\ntargets_train = targets_train.reshape(targets_train.shape[0],-1)\ntargets_test = targets_test.reshape(targets_test.shape[0],-1)\n\n\n\n#Network Structure\nX = tf.placeholder(tf.float32, [None,features.shape[1]])\ny = tf.placeholder(tf.float32, [None,1])\nprob = tf.placeholder(tf.float32)\n\nw1 = tf.Variable(tf.random_normal([features.shape[1],100]))\nw2 = tf.Variable(tf.random_normal([100,1]))\n\nb1 = tf.Variable(tf.random_normal([100]))\nb2 = tf.Variable(tf.random_normal([1]))\n\n\nlayer1 = tf.nn.dropout(leaky_relu(tf.add(tf.matmul(X,w1),b1),0.2),prob)\nout = tf.nn.dropout(tf.nn.tanh(tf.add(tf.matmul(layer1,w2),b2)),prob)\n\nloss = tf.reduce_mean(tf.square(out - y))\ntrain_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\nprint(\"Training...\")\n\n\nminibatch = False\nbatchsize = 512\n\n\nfor i in range(1000):\n    if minibatch:\n        for x in range(0,targets_train.shape[0],batchsize):\n            sess.run(train_step, feed_dict={X:data_train[x:x+batchsize],y:targets_train[x:x+batchsize],prob:0.5})\n    else:\n        sess.run(train_step, feed_dict={X:data_train,y:targets_train,prob:0.5})\n    if i%25==0:\n        acc = sess.run(loss, feed_dict={X: data_train, y: targets_train,prob:1})\n        print (\"Training accuracy: %.5f\" % (acc))\n        #print(sess.run(layer1,feed_dict={X: data_train, y: targets_train,prob:1})[0])\n\n\n\ntest_acc = sess.run(loss, feed_dict={X: data_test, y: targets_test,prob:1})\nprint (\"Test accuracy: %.5f\" % (test_acc))\n\n#Check if still predicting 1\noutput = sess.run(out,feed_dict={X: data_test, y: targets_test,prob:1})\nprint(sum(output)==len(output))\n\n\n\n</pre>\n",
                "tags": "<machine-learning><neural-network><deep-learning><regression><tensorflow>",
                "answers": [
                    [
                        "39366",
                        "2",
                        "25542",
                        "",
                        "",
                        "<p>The range of tanh is (-1, 1), but the target is at least 7.<br>\nSo I think you should rescale the range of target to be [-1, 1].</p>\n\n<p>And when I tested, </p>\n\n<pre><code>w1 = tf.Variable(tf.random_normal([features.shape[1],100], stddev=0.1))\nw2 = tf.Variable(tf.random_normal([100,1], stddev=0.1))\n</code></pre>\n\n<p>works better than</p>\n\n<pre><code>w1 = tf.Variable(tf.random_normal([features.shape[1],100]))\nw2 = tf.Variable(tf.random_normal([100,1]))\n</code></pre>\n\n<p>.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "25547",
                        "2",
                        "25542",
                        "",
                        "",
                        "<p>Ok, I've managed to get a decent improvement. Currently producing an MSE of 20 for training and 30 for test. This is after converting all layers to relu and increasing their size. </p>\n\n<p>The problem appeared the activation function on the output. I was under the impression that a sigmoid output layer was common practice.</p>\n\n<p>I was also normalizing before the test/train split and leaking information into the test set! (though this likely wasn't the cause of my problem)</p>\n\n<p>Here is my 'improved' code:</p>\n\n<pre>\n\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn import preprocessing\n\n\nraw = pd.read_csv('parkinsons_updrs.data')\nprint(\"CSV loaded successfully\")\n\nevents = raw.shape[0]\n#drop events where any feature has a zscore > 3 for that feature\nraw = raw[(np.abs(stats.zscore(raw)) &lt 3).all(axis=1)]\nprint(\"Removed \" + str(events-raw.shape[0]) + \" outlier events\")\n\nfeatures = raw.drop(['subject#','test_time','motor_UPDRS','total_UPDRS'], axis = 1)\ntargets = raw['total_UPDRS'].get_values()\nprint(\"pre-processing complete\")\n\n#Split data into test/train\ndata_train, data_test, targets_train, targets_test = train_test_split(features,targets,test_size = 0.33,random_state=123)\nprint(\"Train/Test split complete\")\n\n\n#Normalize data to mean 0 and std 1\n#We normalize after the split to avoid leaking information to the training set\ndata_train = (data_train-data_train.mean())/data_train.std()\ndata_test = (data_test-data_test.mean())/data_test.std()\n\ntargets_train = targets_train.reshape(targets_train.shape[0],-1)\ntargets_test = targets_test.reshape(targets_test.shape[0],-1)\n\n\n\n#Network Structure\nX = tf.placeholder(tf.float32, [None,18])\ny = tf.placeholder(tf.float32, [None,1])\nprob = tf.placeholder_with_default(1.0, shape=())\n\nw1 = tf.Variable(tf.random_normal([18,72]))\nw2 = tf.Variable(tf.random_normal([72,36]))\nw3 = tf.Variable(tf.random_normal([36,1]))\n\nb1 = tf.Variable(tf.random_normal([72]))\nb2 = tf.Variable(tf.random_normal([36]))\nb3 = tf.Variable(tf.random_normal([1]))\n\n\n\nlayer1 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(X,w1),b1)),prob)\nlayer2 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(layer1,w2),b2)),prob)\nout = tf.nn.relu(tf.add(tf.matmul(layer2,w3),b3))\n\nloss = tf.losses.mean_squared_error(y, out)\n\ntrain_step = tf.train.AdamOptimizer(0.005).minimize(loss)\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\nprint(\"Training...\")\n\n\nminibatch = True\nbatchsize = 512\n\n\nfor i in range(10000):\n    if minibatch:\n        for x in range(0,targets_train.shape[0],batchsize):\n            sess.run(train_step, feed_dict={X:data_train[x:x+batchsize],y:targets_train[x:x+batchsize],prob:0.5})\n    else:\n        sess.run(train_step, feed_dict={X:data_train,y:targets_train,prob:0.5})\n    if i%25==0:\n        acc = sess.run(loss, feed_dict={X: data_train, y: targets_train})\n        print (\"Training accuracy: %.5f\" % (acc))\n\n\n\ntest_acc = sess.run(loss, feed_dict={X: data_test, y: targets_test})\nprint (\"Test accuracy: %.5f\" % (test_acc))\n\noutput = sess.run(out,feed_dict={X: data_test, y: targets_test})\n\nerror = abs(output-targets_test)\n\nprint(max(error))\nprint(sum(error)/len(error))\nprint(min(error))\n </pre>\n\n<p>I'd be very interested to know why this happened. Both tanh and sigmoid get 'stuck' in the 900s whereas relu sorts itself out and carries on.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8000",
            "_score": 7.1004086,
            "_source": {
                "title": "Neural network accuracy for simple classification",
                "content": "Neural network accuracy for simple classification <p>I am trying to develop a NN for a very simple classification model with keras/tensorflow:</p>\n\n<p>Ex:</p>\n\n<ul>\n<li>input: \"Do\" => class output: \"Dog\"</li>\n<li>input: \"Ca\" => class output: \"Cat\"</li>\n<li>input: \"Mo\" => class output: \"Mouse\"</li>\n</ul>\n\n<p>I train the model with many \"Do\", \"Ca\", etc. (as dictionary), indexing the input to categorical arrays (<code>[0,1,0]</code> for example is \"Cat\", <code>[1,0,0]</code> is \"Dog\", <code>[0,0,1]</code> is \"Mouse\" in case of three classes).</p>\n\n<p>I know that for this type of problem every other traditional classification algorithm should be used, and not DL, but I'm doing it with a purpose (I need to merge it with an image classifier).</p>\n\n<p>My question is: since the classification is easy (\"Do\" is always \"Dog\", \"Ca\" is always \"Cat\") a Decision tree would have an accuracy of 100% always. Why do Neural Networks need tons of data and epochs to get an acceptable accuracy? With 10 classes, it takes 10 epochs and 8 thousand entries in order to get an accuracy higher than 90%. I'm using sparse categorical crossentropy as loss, and SGD as the optimizer. (2 Dense layer, relu - softmax). Also, I am a bit lost on how to choose the number of neurons, I guess trial and error is the way.</p>\n <machine-learning><python><neural-network><keras><tensorflow><p>I will add my 2 cents at the end of this answer. However, this is how it can be done using a neural network. Firstly, yes, you should expect to need more data to train even a simple neural network because their are more parameters that need tuning. Think of them like little faucets that you need to tune in order to get the right output volume based on an input. If you have millions of these faucets you an imagine that this is an arduous process. </p>\n\n<p>You will need some of the following imports</p>\n\n<pre><code>from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n</code></pre>\n\n<p>But, in your case you know what your data should be so you can simulate it. I do this as follows and make a training and testing set. </p>\n\n<pre><code>import numpy as np\n\nn = 10\nm = 2\n\nx_train = np.zeros((n, m))\ny_train = np.zeros((n,))\nfor i in range(n):\n    label = np.random.randint(0,m)\n    y_train[i] = label\n    x_train[i, label] = 1\n\nx_test = np.zeros((n//3, m))\ny_test = np.zeros((n//3,))\nfor i in range(n//3):\n    label = np.random.randint(0,m)\n    y_test[i] = label\n    x_test[i, label] = 1\n</code></pre>\n\n<p>Now we will have a training set which contains $n$ instances and a testing set with a third as many. $m$ is the number of possible inputs. For cat vs. dog this would be $m=2$. You will be using your more general case where $m=10$. Each entry in the matrix $x$ has the vector with one-hot encoded vector where the index in accordance with the label is 1.</p>\n\n<p>We need to reshape the data for it to fit with the Keras structure.</p>\n\n<pre><code># The known number of output classes.\nnum_classes = m\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], m,)\nx_test_reshaped = x_test.reshape(x_test.shape[0], m,)\ninput_shape = (m,)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n</code></pre>\n\n<p>We then build our model</p>\n\n<pre><code>model = Sequential()\nmodel.add(Dense(64, activation='relu', input_shape = input_shape))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<p>We then train our model</p>\n\n<pre><code>epochs = 4\nbatch_size = 128\n# Fit the model weights.\nhistory = model.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n</code></pre>\n\n<blockquote>\n  <p>Epoch 4/4 <br/>10/10 [==============================] - 0s 251us/step -\n  loss: 0.6247 - acc: 0.6000 - val_loss: 0.5311 - val_acc: 1.0000</p>\n</blockquote>\n\n<p>Voila, now you have perfect classification with this network. You can play around with the model and see a summary of the model using.</p>\n\n<pre><code>model.summary()\n</code></pre>\n\n<hr>\n\n<h1>For $m = 10$</h1>\n\n<p>Due to the higher complexity that this set has you will need to increase the number of instances in your training set. I will also 2 layers to our model and make them less wide. Furthermore, we will add more epochs so we will train longer.</p>\n\n<pre><code>import numpy as np\n\nn = 1000\nm = 10\n\nx_train = np.zeros((n, m))\ny_train = np.zeros((n,))\nfor i in range(n):\n    label = np.random.randint(0,m)\n    y_train[i] = label\n    x_train[i, label] = 1\n\nx_test = np.zeros((n//3, m))\ny_test = np.zeros((n//3,))\nfor i in range(n//3):\n    label = np.random.randint(0,m)\n    y_test[i] = label\n    x_test[i, label] = 1\n\n# The known number of output classes.\nnum_classes = m\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], m,)\nx_test_reshaped = x_test.reshape(x_test.shape[0], m,)\n\ninput_shape = (m,)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Dense(32, activation='relu', input_shape = input_shape))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nepochs = 10\nbatch_size = 128\n# Fit the model weights.\nhistory = model.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n</code></pre>\n\n<blockquote>\n  <p>Epoch 10/10 <br/>1000/1000 [==============================] - 0s 49us/step\n  - loss: 1.5977 - acc: 1.0000 - val_loss: 1.5235 - val_acc: 1.0000</p>\n</blockquote>\n\n<hr>\n\n<h1>My suggestions</h1>\n\n<p>I would not use a NN for such a case. Most of the frameworks allow you to add information throughout your model. Such that if you have images you can run a CNN over them, then when you are ready to convert your layers to a densely connected layer you can in additional information, such as vectorized text. </p>\n\n<p>You can thus use a random forests approach or something even simpler to get your 100% classification even faster. Then you can feed the output of this model to your deep learning framework which has already \"extracted the features\" from the images and concatenate these additional features to that tensor. Then you will pass this larger tensor through the subsequent Dense layers to get your final output.</p>\n<p>For every problem there is proportional solution. </p>\n\n<p>I understand that you want to build your classifier inside an image recognition algorithm. </p>\n\n<p>You may need a NN for the image (lots of inputs + lots of possibilities) but not for the whole system. </p>\n\n<p>What is usually done for this kind of problematic is to build a \"pipe\". A sequence of ML algorithms taking as input the output of the previous one:</p>\n\n<ul>\n<li>First block is a text zone detection within the image </li>\n<li>Second block read the zones into text</li>\n<li>Third block do the actual classification.</li>\n</ul>\n\n<p>This method also make the debugging process easier, as you can evaluate your prediction rate at every step making easy to know which part can be optimized/fixed if a problem is encountered.</p>\n\n<p>Hope this helps.</p>\n",
                "codes": [
                    [
                        "from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n",
                        "import numpy as np\n\nn = 10\nm = 2\n\nx_train = np.zeros((n, m))\ny_train = np.zeros((n,))\nfor i in range(n):\n    label = np.random.randint(0,m)\n    y_train[i] = label\n    x_train[i, label] = 1\n\nx_test = np.zeros((n//3, m))\ny_test = np.zeros((n//3,))\nfor i in range(n//3):\n    label = np.random.randint(0,m)\n    y_test[i] = label\n    x_test[i, label] = 1\n",
                        "# The known number of output classes.\nnum_classes = m\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], m,)\nx_test_reshaped = x_test.reshape(x_test.shape[0], m,)\ninput_shape = (m,)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n",
                        "model = Sequential()\nmodel.add(Dense(64, activation='relu', input_shape = input_shape))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n",
                        "epochs = 4\nbatch_size = 128\n# Fit the model weights.\nhistory = model.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n",
                        "model.summary()\n",
                        "import numpy as np\n\nn = 1000\nm = 10\n\nx_train = np.zeros((n, m))\ny_train = np.zeros((n,))\nfor i in range(n):\n    label = np.random.randint(0,m)\n    y_train[i] = label\n    x_train[i, label] = 1\n\nx_test = np.zeros((n//3, m))\ny_test = np.zeros((n//3,))\nfor i in range(n//3):\n    label = np.random.randint(0,m)\n    y_test[i] = label\n    x_test[i, label] = 1\n\n# The known number of output classes.\nnum_classes = m\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], m,)\nx_test_reshaped = x_test.reshape(x_test.shape[0], m,)\n\ninput_shape = (m,)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Dense(32, activation='relu', input_shape = input_shape))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nepochs = 10\nbatch_size = 128\n# Fit the model weights.\nhistory = model.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n"
                    ],
                    []
                ],
                "question_id:": "29570",
                "question_votes:": "",
                "question_text:": "<p>I am trying to develop a NN for a very simple classification model with keras/tensorflow:</p>\n\n<p>Ex:</p>\n\n<ul>\n<li>input: \"Do\" => class output: \"Dog\"</li>\n<li>input: \"Ca\" => class output: \"Cat\"</li>\n<li>input: \"Mo\" => class output: \"Mouse\"</li>\n</ul>\n\n<p>I train the model with many \"Do\", \"Ca\", etc. (as dictionary), indexing the input to categorical arrays (<code>[0,1,0]</code> for example is \"Cat\", <code>[1,0,0]</code> is \"Dog\", <code>[0,0,1]</code> is \"Mouse\" in case of three classes).</p>\n\n<p>I know that for this type of problem every other traditional classification algorithm should be used, and not DL, but I'm doing it with a purpose (I need to merge it with an image classifier).</p>\n\n<p>My question is: since the classification is easy (\"Do\" is always \"Dog\", \"Ca\" is always \"Cat\") a Decision tree would have an accuracy of 100% always. Why do Neural Networks need tons of data and epochs to get an acceptable accuracy? With 10 classes, it takes 10 epochs and 8 thousand entries in order to get an accuracy higher than 90%. I'm using sparse categorical crossentropy as loss, and SGD as the optimizer. (2 Dense layer, relu - softmax). Also, I am a bit lost on how to choose the number of neurons, I guess trial and error is the way.</p>\n",
                "tags": "<machine-learning><python><neural-network><keras><tensorflow>",
                "answers": [
                    [
                        "29573",
                        "2",
                        "29570",
                        "",
                        "",
                        "<p>I will add my 2 cents at the end of this answer. However, this is how it can be done using a neural network. Firstly, yes, you should expect to need more data to train even a simple neural network because their are more parameters that need tuning. Think of them like little faucets that you need to tune in order to get the right output volume based on an input. If you have millions of these faucets you an imagine that this is an arduous process. </p>\n\n<p>You will need some of the following imports</p>\n\n<pre><code>from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n</code></pre>\n\n<p>But, in your case you know what your data should be so you can simulate it. I do this as follows and make a training and testing set. </p>\n\n<pre><code>import numpy as np\n\nn = 10\nm = 2\n\nx_train = np.zeros((n, m))\ny_train = np.zeros((n,))\nfor i in range(n):\n    label = np.random.randint(0,m)\n    y_train[i] = label\n    x_train[i, label] = 1\n\nx_test = np.zeros((n//3, m))\ny_test = np.zeros((n//3,))\nfor i in range(n//3):\n    label = np.random.randint(0,m)\n    y_test[i] = label\n    x_test[i, label] = 1\n</code></pre>\n\n<p>Now we will have a training set which contains $n$ instances and a testing set with a third as many. $m$ is the number of possible inputs. For cat vs. dog this would be $m=2$. You will be using your more general case where $m=10$. Each entry in the matrix $x$ has the vector with one-hot encoded vector where the index in accordance with the label is 1.</p>\n\n<p>We need to reshape the data for it to fit with the Keras structure.</p>\n\n<pre><code># The known number of output classes.\nnum_classes = m\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], m,)\nx_test_reshaped = x_test.reshape(x_test.shape[0], m,)\ninput_shape = (m,)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n</code></pre>\n\n<p>We then build our model</p>\n\n<pre><code>model = Sequential()\nmodel.add(Dense(64, activation='relu', input_shape = input_shape))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<p>We then train our model</p>\n\n<pre><code>epochs = 4\nbatch_size = 128\n# Fit the model weights.\nhistory = model.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n</code></pre>\n\n<blockquote>\n  <p>Epoch 4/4 <br/>10/10 [==============================] - 0s 251us/step -\n  loss: 0.6247 - acc: 0.6000 - val_loss: 0.5311 - val_acc: 1.0000</p>\n</blockquote>\n\n<p>Voila, now you have perfect classification with this network. You can play around with the model and see a summary of the model using.</p>\n\n<pre><code>model.summary()\n</code></pre>\n\n<hr>\n\n<h1>For $m = 10$</h1>\n\n<p>Due to the higher complexity that this set has you will need to increase the number of instances in your training set. I will also 2 layers to our model and make them less wide. Furthermore, we will add more epochs so we will train longer.</p>\n\n<pre><code>import numpy as np\n\nn = 1000\nm = 10\n\nx_train = np.zeros((n, m))\ny_train = np.zeros((n,))\nfor i in range(n):\n    label = np.random.randint(0,m)\n    y_train[i] = label\n    x_train[i, label] = 1\n\nx_test = np.zeros((n//3, m))\ny_test = np.zeros((n//3,))\nfor i in range(n//3):\n    label = np.random.randint(0,m)\n    y_test[i] = label\n    x_test[i, label] = 1\n\n# The known number of output classes.\nnum_classes = m\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], m,)\nx_test_reshaped = x_test.reshape(x_test.shape[0], m,)\n\ninput_shape = (m,)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Dense(32, activation='relu', input_shape = input_shape))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nepochs = 10\nbatch_size = 128\n# Fit the model weights.\nhistory = model.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n</code></pre>\n\n<blockquote>\n  <p>Epoch 10/10 <br/>1000/1000 [==============================] - 0s 49us/step\n  - loss: 1.5977 - acc: 1.0000 - val_loss: 1.5235 - val_acc: 1.0000</p>\n</blockquote>\n\n<hr>\n\n<h1>My suggestions</h1>\n\n<p>I would not use a NN for such a case. Most of the frameworks allow you to add information throughout your model. Such that if you have images you can run a CNN over them, then when you are ready to convert your layers to a densely connected layer you can in additional information, such as vectorized text. </p>\n\n<p>You can thus use a random forests approach or something even simpler to get your 100% classification even faster. Then you can feed the output of this model to your deep learning framework which has already \"extracted the features\" from the images and concatenate these additional features to that tensor. Then you will pass this larger tensor through the subsequent Dense layers to get your final output.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "29576",
                        "2",
                        "29570",
                        "",
                        "",
                        "<p>For every problem there is proportional solution. </p>\n\n<p>I understand that you want to build your classifier inside an image recognition algorithm. </p>\n\n<p>You may need a NN for the image (lots of inputs + lots of possibilities) but not for the whole system. </p>\n\n<p>What is usually done for this kind of problematic is to build a \"pipe\". A sequence of ML algorithms taking as input the output of the previous one:</p>\n\n<ul>\n<li>First block is a text zone detection within the image </li>\n<li>Second block read the zones into text</li>\n<li>Third block do the actual classification.</li>\n</ul>\n\n<p>This method also make the debugging process easier, as you can evaluate your prediction rate at every step making easy to know which part can be optimized/fixed if a problem is encountered.</p>\n\n<p>Hope this helps.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16494",
            "_score": 7.0912685,
            "_source": {
                "title": "Keras model giving error when fields of unseen test data and train data are not same",
                "content": "Keras model giving error when fields of unseen test data and train data are not same <p>I have created a simple Keras deep learning model in python. Total no of variables in training are 195 while in unseen test data are 181.All input fields are categorical(converted by one hot encoding). Since unseen test data has some different categories thats why after one hot encoding fields are not matching with train.</p>\n\n<p>So during predict step on unseen test data, model gives the following error. Is there any way out?</p>\n\n<pre><code>ValueError: Error when checking input: expected dense_30_input to have shape (195,)\nbut got array with shape (181,)\n</code></pre>\n <machine-learning><deep-learning><keras><image-classification><machine-learning-model><p>The model will only be able to predict when you have all the variables as training data. That's how model learnt and the weights of NNs got updated. You cannot predict with different categories when you didn't use them while training.</p>\n<p>Use any publicly available data set which is good and clean and test your model output. You will get to know how the model predicts, if the model predicts well then you will get to know if there is an issue in your data or issue with your model.</p>\n<p>As others before me pointed out you should have exactly the same variables in your test data as in your training data.</p>\n\n<p>In case of one-hot encoding if you have unseen categories in your test data your model doesn't know how to handle them it was not trained on those variables. In that case during data preparation you shall create all the variables that you had during training with the value of 0 and you don't create new variable for the unseen category.</p>\n\n<p>I think your confusion and the differing number of variables come from the function that you use to do the one-hot encoding for you. Probably you run them on the two datasets separately and it will only create the variables that it founds in the specific datasets.\nYou can overcome on it by using label encoder or onehotencoder transformer from scikit-learn that will save inside its obeject the original state and in every transformation it will recreate exactly the same structure.</p>\n\n<p>UPDATE to use sklearn onehotencoder:</p>\n\n<pre><code>from sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder(handle_unknown='ignore')\nencoder.fit(train_categorical_data)\nencoded_train=encoder.transform(train_categorical_data)\nencoded_test=encoder.transform(test_categorical_data)\n</code></pre>\n\n<p>You can save the encoder to use it later. See more about it in the official <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" rel=\"nofollow noreferrer\">documentation</a>.</p>\n<p>As pointed out by others, test data should have the same variables as in your training data for the ML to work.</p>\n\n<p>Here are my thoughts, if your training and test data categorical classes are not matching. </p>\n\n<ol>\n<li><p>can use <code>sklearn onehotencoding</code> and specify to ignore any unknown classes in test data. </p>\n\n<p><code>from numpy import array\nfrom sklearn.preprocessing import OneHotEncoder\ndata = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm']\nvalues = array(data)\nprint(values)\nonehot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\ndata2 = ['cold', 'warm', 'hot', 'colder']\nvalues = values.reshape(-1, 1)\ntrain_encoded = onehot_encoder.fit_transform(values)\nvalues2 = array(data2).reshape(-1, 1)\nprint(train_encoded)\nprint(data2)\nprint(onehot_encoder.transform(values2))\ndata3 = ['cold']\nprint(data3)\nvalues3 = array(data3).reshape(-1, 1)\nprint(onehot_encoder.transform(values3))</code></p></li>\n</ol>\n\n<p>output</p>\n\n<pre><code>`['cold' 'cold' 'warm' 'cold' 'hot' 'hot' 'warm']\n[[1. 0. 0.]\n [1. 0. 0.]\n [0. 0. 1.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 0. 1.]]\n['cold', 'warm', 'hot', 'colder']\n[[1. 0. 0.]\n [0. 0. 1.]\n [0. 1. 0.]\n [0. 0. 0.]]\n['cold']\n[[1. 0. 0.]]`\n</code></pre>\n\n<p>2. or combine training and test data and perform one hot encoding to get all the class labels.               </p>\n",
                "codes": [
                    [],
                    [],
                    [
                        "from sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder(handle_unknown='ignore')\nencoder.fit(train_categorical_data)\nencoded_train=encoder.transform(train_categorical_data)\nencoded_test=encoder.transform(test_categorical_data)\n"
                    ],
                    [
                        "from numpy import array\nfrom sklearn.preprocessing import OneHotEncoder\ndata = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm']\nvalues = array(data)\nprint(values)\nonehot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\ndata2 = ['cold', 'warm', 'hot', 'colder']\nvalues = values.reshape(-1, 1)\ntrain_encoded = onehot_encoder.fit_transform(values)\nvalues2 = array(data2).reshape(-1, 1)\nprint(train_encoded)\nprint(data2)\nprint(onehot_encoder.transform(values2))\ndata3 = ['cold']\nprint(data3)\nvalues3 = array(data3).reshape(-1, 1)\nprint(onehot_encoder.transform(values3))",
                        "`['cold' 'cold' 'warm' 'cold' 'hot' 'hot' 'warm']\n[[1. 0. 0.]\n [1. 0. 0.]\n [0. 0. 1.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 0. 1.]]\n['cold', 'warm', 'hot', 'colder']\n[[1. 0. 0.]\n [0. 0. 1.]\n [0. 1. 0.]\n [0. 0. 0.]]\n['cold']\n[[1. 0. 0.]]`\n"
                    ]
                ],
                "question_id:": "54208",
                "question_votes:": "1",
                "question_text:": "<p>I have created a simple Keras deep learning model in python. Total no of variables in training are 195 while in unseen test data are 181.All input fields are categorical(converted by one hot encoding). Since unseen test data has some different categories thats why after one hot encoding fields are not matching with train.</p>\n\n<p>So during predict step on unseen test data, model gives the following error. Is there any way out?</p>\n\n<pre><code>ValueError: Error when checking input: expected dense_30_input to have shape (195,)\nbut got array with shape (181,)\n</code></pre>\n",
                "tags": "<machine-learning><deep-learning><keras><image-classification><machine-learning-model>",
                "answers": [
                    [
                        "54209",
                        "2",
                        "54208",
                        "",
                        "",
                        "<p>The model will only be able to predict when you have all the variables as training data. That's how model learnt and the weights of NNs got updated. You cannot predict with different categories when you didn't use them while training.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "54211",
                        "2",
                        "54208",
                        "",
                        "",
                        "<p>Use any publicly available data set which is good and clean and test your model output. You will get to know how the model predicts, if the model predicts well then you will get to know if there is an issue in your data or issue with your model.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "54235",
                        "2",
                        "54208",
                        "",
                        "",
                        "<p>As others before me pointed out you should have exactly the same variables in your test data as in your training data.</p>\n\n<p>In case of one-hot encoding if you have unseen categories in your test data your model doesn't know how to handle them it was not trained on those variables. In that case during data preparation you shall create all the variables that you had during training with the value of 0 and you don't create new variable for the unseen category.</p>\n\n<p>I think your confusion and the differing number of variables come from the function that you use to do the one-hot encoding for you. Probably you run them on the two datasets separately and it will only create the variables that it founds in the specific datasets.\nYou can overcome on it by using label encoder or onehotencoder transformer from scikit-learn that will save inside its obeject the original state and in every transformation it will recreate exactly the same structure.</p>\n\n<p>UPDATE to use sklearn onehotencoder:</p>\n\n<pre><code>from sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder(handle_unknown='ignore')\nencoder.fit(train_categorical_data)\nencoded_train=encoder.transform(train_categorical_data)\nencoded_test=encoder.transform(test_categorical_data)\n</code></pre>\n\n<p>You can save the encoder to use it later. See more about it in the official <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" rel=\"nofollow noreferrer\">documentation</a>.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "54241",
                        "2",
                        "54208",
                        "",
                        "",
                        "<p>As pointed out by others, test data should have the same variables as in your training data for the ML to work.</p>\n\n<p>Here are my thoughts, if your training and test data categorical classes are not matching. </p>\n\n<ol>\n<li><p>can use <code>sklearn onehotencoding</code> and specify to ignore any unknown classes in test data. </p>\n\n<p><code>from numpy import array\nfrom sklearn.preprocessing import OneHotEncoder\ndata = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm']\nvalues = array(data)\nprint(values)\nonehot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\ndata2 = ['cold', 'warm', 'hot', 'colder']\nvalues = values.reshape(-1, 1)\ntrain_encoded = onehot_encoder.fit_transform(values)\nvalues2 = array(data2).reshape(-1, 1)\nprint(train_encoded)\nprint(data2)\nprint(onehot_encoder.transform(values2))\ndata3 = ['cold']\nprint(data3)\nvalues3 = array(data3).reshape(-1, 1)\nprint(onehot_encoder.transform(values3))</code></p></li>\n</ol>\n\n<p>output</p>\n\n<pre><code>`['cold' 'cold' 'warm' 'cold' 'hot' 'hot' 'warm']\n[[1. 0. 0.]\n [1. 0. 0.]\n [0. 0. 1.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 0. 1.]]\n['cold', 'warm', 'hot', 'colder']\n[[1. 0. 0.]\n [0. 0. 1.]\n [0. 1. 0.]\n [0. 0. 0.]]\n['cold']\n[[1. 0. 0.]]`\n</code></pre>\n\n<p>2. or combine training and test data and perform one hot encoding to get all the class labels.               </p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15240",
            "_score": 7.0537295,
            "_source": {
                "title": "How to transform predicted time series data to real values in time series?",
                "content": "How to transform predicted time series data to real values in time series? <p>I am implementing an LSTM model for time series prediction and I would like to return predicted values to its real value to calculate and plot model performance.</p>\n\n<p>Here is my code:</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nnp.random.seed(2018)\ndataset= pd.read_csv(\"CAC40 .csv\")\nprint(dataset.head(4))\n      # Apply log neperien\ndataset.Close=np.log (dataset.Close)\ndataset.Close=dataset.Close.diff()\nfrom matplotlib import pyplot\npyplot.plot(diff)\npyplot.show()\ndataset.iloc[0,4:5]=dataset.iloc[1,4:5]\n# Part 2 - Building the RNN\n\n# Importing the Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\n\n# Initialising the RNN\nregressor = Sequential()\n# Importing the Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\n\n# Initialising the RNN\nregressor = Sequential()\n\n# Adding the first LSTM layer and some Dropout regularisation\nregressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\nregressor.add(Dropout(0.2))\n\n# Adding a second LSTM layer and some Dropout regularisation\nregressor.add(LSTM(units = 50, return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a third LSTM layer and some Dropout regularisation\nregressor.add(LSTM(units = 50, return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a fourth LSTM layer and some Dropout regularisation\nregressor.add(LSTM(units = 50))\nregressor.add(Dropout(0.2))\n\n# Adding the output layer\nregressor.add(Dense(units = 1))\n\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics=['accuracy'])\n\n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, epochs = 100, batch_size = 32)\n# Part 3 - Making the predictions and visualising the results\n\n# Getting the real stock price of 2017\n#dataset_test = pd.read_csv(\"CAC40Test.csv\")\ndataset_test =dataset.iloc[1486:2123]\nreal_stock_price=dataset_test.iloc[:,4:5].values\n#real_stock_price = dataset_test\n\n# Getting the predicted stock price of 2017\ndataset_total = pd.concat((dataset_train['Close'], dataset_test['Close']), axis = 0)\ninputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\ninputs = inputs.reshape(-1,1)\ninputs =np.nan_to_num(inputs )\ninputs = sc.transform(inputs)\nX_test = []\nfor i in range(60, 60+len(real_stock_price)):\n    X_test.append(inputs[i-60:i, 0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\npredicted_stock_price = regressor.predict(X_test)\npredicted_stock_price = sc.inverse_transform(predicted_stock_price)\nlen(predicted_stock_price)\n#len(X_test)\nlen(real_stock_price)\npredicted_stock_price\n# Visualising the results\nplt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\nplt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\nplt.title('Google Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Google Stock Price')\nplt.legend()\nplt.show()\n</code></pre>\n <python><time-series>",
                "codes": [],
                "question_id:": "51485",
                "question_votes:": "",
                "question_text:": "<p>I am implementing an LSTM model for time series prediction and I would like to return predicted values to its real value to calculate and plot model performance.</p>\n\n<p>Here is my code:</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nnp.random.seed(2018)\ndataset= pd.read_csv(\"CAC40 .csv\")\nprint(dataset.head(4))\n      # Apply log neperien\ndataset.Close=np.log (dataset.Close)\ndataset.Close=dataset.Close.diff()\nfrom matplotlib import pyplot\npyplot.plot(diff)\npyplot.show()\ndataset.iloc[0,4:5]=dataset.iloc[1,4:5]\n# Part 2 - Building the RNN\n\n# Importing the Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\n\n# Initialising the RNN\nregressor = Sequential()\n# Importing the Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\n\n# Initialising the RNN\nregressor = Sequential()\n\n# Adding the first LSTM layer and some Dropout regularisation\nregressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\nregressor.add(Dropout(0.2))\n\n# Adding a second LSTM layer and some Dropout regularisation\nregressor.add(LSTM(units = 50, return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a third LSTM layer and some Dropout regularisation\nregressor.add(LSTM(units = 50, return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a fourth LSTM layer and some Dropout regularisation\nregressor.add(LSTM(units = 50))\nregressor.add(Dropout(0.2))\n\n# Adding the output layer\nregressor.add(Dense(units = 1))\n\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics=['accuracy'])\n\n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, epochs = 100, batch_size = 32)\n# Part 3 - Making the predictions and visualising the results\n\n# Getting the real stock price of 2017\n#dataset_test = pd.read_csv(\"CAC40Test.csv\")\ndataset_test =dataset.iloc[1486:2123]\nreal_stock_price=dataset_test.iloc[:,4:5].values\n#real_stock_price = dataset_test\n\n# Getting the predicted stock price of 2017\ndataset_total = pd.concat((dataset_train['Close'], dataset_test['Close']), axis = 0)\ninputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\ninputs = inputs.reshape(-1,1)\ninputs =np.nan_to_num(inputs )\ninputs = sc.transform(inputs)\nX_test = []\nfor i in range(60, 60+len(real_stock_price)):\n    X_test.append(inputs[i-60:i, 0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\npredicted_stock_price = regressor.predict(X_test)\npredicted_stock_price = sc.inverse_transform(predicted_stock_price)\nlen(predicted_stock_price)\n#len(X_test)\nlen(real_stock_price)\npredicted_stock_price\n# Visualising the results\nplt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\nplt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\nplt.title('Google Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Google Stock Price')\nplt.legend()\nplt.show()\n</code></pre>\n",
                "tags": "<python><time-series>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "18173",
            "_score": 7.0537295,
            "_source": {
                "title": "Which algorithm to use to classify plots based on graphical features?",
                "content": "Which algorithm to use to classify plots based on graphical features? <p>I have plots which I need to classify based on some features. For example, I need to differentiate between the following plots having smooth features or 'valleys' at certain x values. Which machine learning algorithm would be most appropriate to do so? I was thinking a combination of anomaly detection, clustering and classification. Any help is appreciated. Thank you!</p>\n\n<p><a href=\"https://i.stack.imgur.com/EJXYp.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/EJXYp.png\" alt=\"enter image description here\"></a> </p>\n\n<p><a href=\"https://i.stack.imgur.com/CxuK6.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/CxuK6.png\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/PwF4d.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PwF4d.png\" alt=\"enter image description here\"></a></p>\n <machine-learning><p>Your question is unclear. Please provide more information about the dataset, the dataset size, the target, the motivation. \nUntil then I can only assume and try to help nontheless.</p>\n\n<p><strong>Assumptions</strong></p>\n\n<p>Since you speak of classification I assume that you have labels.\nI further assume that you have access to the underlying data used to produce the plot. \nIn that exact case, the following will be useful:</p>\n\n<p><strong>Solution</strong></p>\n\n<p>Instead of classifying the plots, you could classify the underlying two-dimensional datasets treating them as time-series. </p>\n\n<p>For your specific case, Dynamic Time Warping distance could be useful. You could therefore use <a href=\"https://gist.github.com/nikolasrieble/8bd3a83e14c0b2fa66bfa2ddd8828717\" rel=\"nofollow noreferrer\">this</a> code:</p>\n\n<pre><code>import numpy as np\nfrom scipy.spatial import distance\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\n\n#toy dataset \nX = np.random.random((100,10))\ny = np.random.randint(0,2, (100))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n#custom metric\ndef DTW(a, b):   \n    an = a.size\n    bn = b.size\n    pointwise_distance = distance.cdist(a.reshape(-1,1),b.reshape(-1,1))\n    cumdist = np.matrix(np.ones((an+1,bn+1)) * np.inf)\n    cumdist[0,0] = 0\n\n    for ai in range(an):\n        for bi in range(bn):\n            minimum_cost = np.min([cumdist[ai, bi+1],\n                                   cumdist[ai+1, bi],\n                                   cumdist[ai, bi]])\n            cumdist[ai+1, bi+1] = pointwise_distance[ai,bi] + minimum_cost\n\n    return cumdist[an, bn]\n\n#train\nparameters = {'n_neighbors':[2, 4, 8]}\nclf = GridSearchCV(KNeighborsClassifier(metric =DTW), parameters, cv=5)\nclf.fit(X_train, y_train)\n\n#evaluate\ny_pred = clf.predict(X_test)\nprint(classification_report(y_test, y_pred))\n</code></pre>\n",
                "codes": [
                    [
                        "import numpy as np\nfrom scipy.spatial import distance\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\n\n#toy dataset \nX = np.random.random((100,10))\ny = np.random.randint(0,2, (100))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n#custom metric\ndef DTW(a, b):   \n    an = a.size\n    bn = b.size\n    pointwise_distance = distance.cdist(a.reshape(-1,1),b.reshape(-1,1))\n    cumdist = np.matrix(np.ones((an+1,bn+1)) * np.inf)\n    cumdist[0,0] = 0\n\n    for ai in range(an):\n        for bi in range(bn):\n            minimum_cost = np.min([cumdist[ai, bi+1],\n                                   cumdist[ai+1, bi],\n                                   cumdist[ai, bi]])\n            cumdist[ai+1, bi+1] = pointwise_distance[ai,bi] + minimum_cost\n\n    return cumdist[an, bn]\n\n#train\nparameters = {'n_neighbors':[2, 4, 8]}\nclf = GridSearchCV(KNeighborsClassifier(metric =DTW), parameters, cv=5)\nclf.fit(X_train, y_train)\n\n#evaluate\ny_pred = clf.predict(X_test)\nprint(classification_report(y_test, y_pred))\n"
                    ]
                ],
                "question_id:": "57815",
                "question_votes:": "",
                "question_text:": "<p>I have plots which I need to classify based on some features. For example, I need to differentiate between the following plots having smooth features or 'valleys' at certain x values. Which machine learning algorithm would be most appropriate to do so? I was thinking a combination of anomaly detection, clustering and classification. Any help is appreciated. Thank you!</p>\n\n<p><a href=\"https://i.stack.imgur.com/EJXYp.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/EJXYp.png\" alt=\"enter image description here\"></a> </p>\n\n<p><a href=\"https://i.stack.imgur.com/CxuK6.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/CxuK6.png\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/PwF4d.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PwF4d.png\" alt=\"enter image description here\"></a></p>\n",
                "tags": "<machine-learning>",
                "answers": [
                    [
                        "57847",
                        "2",
                        "57815",
                        "",
                        "",
                        "<p>Your question is unclear. Please provide more information about the dataset, the dataset size, the target, the motivation. \nUntil then I can only assume and try to help nontheless.</p>\n\n<p><strong>Assumptions</strong></p>\n\n<p>Since you speak of classification I assume that you have labels.\nI further assume that you have access to the underlying data used to produce the plot. \nIn that exact case, the following will be useful:</p>\n\n<p><strong>Solution</strong></p>\n\n<p>Instead of classifying the plots, you could classify the underlying two-dimensional datasets treating them as time-series. </p>\n\n<p>For your specific case, Dynamic Time Warping distance could be useful. You could therefore use <a href=\"https://gist.github.com/nikolasrieble/8bd3a83e14c0b2fa66bfa2ddd8828717\" rel=\"nofollow noreferrer\">this</a> code:</p>\n\n<pre><code>import numpy as np\nfrom scipy.spatial import distance\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\n\n#toy dataset \nX = np.random.random((100,10))\ny = np.random.randint(0,2, (100))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n#custom metric\ndef DTW(a, b):   \n    an = a.size\n    bn = b.size\n    pointwise_distance = distance.cdist(a.reshape(-1,1),b.reshape(-1,1))\n    cumdist = np.matrix(np.ones((an+1,bn+1)) * np.inf)\n    cumdist[0,0] = 0\n\n    for ai in range(an):\n        for bi in range(bn):\n            minimum_cost = np.min([cumdist[ai, bi+1],\n                                   cumdist[ai+1, bi],\n                                   cumdist[ai, bi]])\n            cumdist[ai+1, bi+1] = pointwise_distance[ai,bi] + minimum_cost\n\n    return cumdist[an, bn]\n\n#train\nparameters = {'n_neighbors':[2, 4, 8]}\nclf = GridSearchCV(KNeighborsClassifier(metric =DTW), parameters, cv=5)\nclf.fit(X_train, y_train)\n\n#evaluate\ny_pred = clf.predict(X_test)\nprint(classification_report(y_test, y_pred))\n</code></pre>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17426",
            "_score": 7.0433445,
            "_source": {
                "title": "How to compute Frechet Inception Score for MNIST GAN?",
                "content": "How to compute Frechet Inception Score for MNIST GAN? <p>I'm starting out with GANs and I am training a DC-GAN on MNIST dataset. The two metrics that are used to evaluate GANs are Inception Score (IS) and Frechet Inception Distance (FID). Since Inception network is not trained to classify MNIST digits, I built a simple MNIST classifier and I'm using that. Inception score, I'm getting pretty decent values. For FID, I'm using the output of last Fully Connected Layer as feature vector. But, I'm getting values in the order of <span class=\"math-container\">$10^6$</span>, which doesn't look right. So, I have a few questions</p>\n\n<ol>\n<li>Does it make sense to compute FID for MNIST GAN?</li>\n<li>Is the value in the order of <span class=\"math-container\">$10^6$</span> correct?</li>\n<li>How many images from real dataset should be used while computing FID</li>\n<li>Is my code below correct? I used the <a href=\"https://github.com/bioinf-jku/TTUR/blob/master/FIDvsINC/fid.py\" rel=\"nofollow noreferrer\">code</a> provided by original authors and modified it according to my requirements.</li>\n</ol>\n\n<p>If you can answer any of these questions, even partially, that would be of immense help to me. Thanks!</p>\n\n<p><strong>Code</strong>:\n<em>FidScore.py</em></p>\n\n<pre><code>import warnings\n\nimport numpy\nfrom keras.datasets import mnist\nfrom keras.models import Model\nfrom scipy import linalg\n\nfrom DcGanBaseModel import DcGanBaseModel\nfrom MnistClassifierModel06 import MnistClassifier06\nfrom mnist.MnistModel02 import MnistModel02\n\n\nclass FrechetInceptionDistance:\n\n    def __init__(self, real_activations: numpy.ndarray, verbose=False) -&gt; None:\n        self.real_activations = real_activations\n        self.verbose = verbose\n\n        self.real_mu = numpy.mean(real_activations, axis=0)\n        self.real_sigma = numpy.cov(real_activations, rowvar=False)\n\n    def compute_fid(self, fake_activations: numpy.ndarray):\n        fake_mu = numpy.mean(fake_activations, axis=0)\n        fake_sigma = numpy.cov(fake_activations, rowvar=False)\n        fid = self.calculate_frechet_distance(fake_mu, fake_sigma, self.real_mu, self.real_sigma)\n        return fid\n\n    @staticmethod\n    def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n        \"\"\"\n        https://github.com/bioinf-jku/TTUR/blob/master/FIDvsINC/fid.py#L99-L148\n        Numpy implementation of the Frechet Distance.\n        The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n        and X_2 ~ N(mu_2, C_2) is\n                d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n        Stable version by Dougal J. Sutherland.\n        Params:\n        -- mu1 : Numpy array containing the activations of the pool_3 layer of the\n                 inception net ( like returned by the function 'get_predictions')\n                 for generated samples.\n        -- mu2   : The sample mean over activations of the pool_3 layer, precalcualted\n                   on an representive data set.\n        -- sigma1: The covariance matrix over activations of the pool_3 layer for\n                   generated samples.\n        -- sigma2: The covariance matrix over activations of the pool_3 layer,\n                   precalcualted on an representive data set.\n        Returns:\n        --   : The Frechet Distance.\n        \"\"\"\n\n        mu1 = numpy.atleast_1d(mu1)\n        mu2 = numpy.atleast_1d(mu2)\n\n        sigma1 = numpy.atleast_2d(sigma1)\n        sigma2 = numpy.atleast_2d(sigma2)\n\n        assert mu1.shape == mu2.shape, \"Training and test mean vectors have different lengths\"\n        assert sigma1.shape == sigma2.shape, \"Training and test covariances have different dimensions\"\n\n        diff = mu1 - mu2\n\n        # product might be almost singular\n        covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n        if not numpy.isfinite(covmean).all():\n            msg = \"fid calculation produces singular product; adding %s to diagonal of cov estimates\" % eps\n            warnings.warn(msg)\n            offset = numpy.eye(sigma1.shape[0]) * eps\n            covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n\n        # numerical error might give slight imaginary component\n        if numpy.iscomplexobj(covmean):\n            if not numpy.allclose(numpy.diagonal(covmean).imag, 0, atol=1e-3):\n                m = numpy.max(numpy.abs(covmean.imag))\n                raise ValueError(\"Imaginary component {}\".format(m))\n            covmean = covmean.real\n\n        tr_covmean = numpy.trace(covmean)\n\n        return diff.dot(diff) + numpy.trace(sigma1) + numpy.trace(sigma2) - 2 * tr_covmean\n\n\ndef compute_fid_score_for_gan(gan_model: DcGanBaseModel, classifier_model, layer_name, num_classes):\n    # Define Feature Extracter\n    feature_layer = Model(inputs=classifier_model.model.input,\n                          outputs=classifier_model.model.get_layer(layer_name).output)\n\n    # Compute Features for MNIST Dataset Images\n    (x_train, _), _ = mnist.load_data()\n    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n    real_features = feature_layer.predict(x_train)\n    fid = FrechetInceptionDistance(real_features, verbose=True)\n\n    num_images = num_classes * 1000\n    gen_images = gan_model.generate_images(num_images)\n    fake_features = feature_layer.predict(gen_images)\n\n    fid_score = fid.compute_fid(fake_features)\n    return fid_score\n\n\ndef demo1():\n    gan_model = MnistModel02(print_model_summary=False)\n    gan_model.load_generator_model('../../Runs/01_MNIST/Model02/Run01/TrainedModels/generator_model_10000.h5')\n    classifier_model = MnistClassifier06().load_model(\n        '../../../../../DiscriminativeModels/01_MNIST_Classification/Runs/Run01/Trained_Models/MNIST_Model_10.h5')\n    fid_score = compute_fid_score_for_gan(gan_model, classifier_model, 'dense_1', 10)\n    print(fid_score)\n\n\nif __name__ == '__main__':\n    demo1()\n</code></pre>\n\n<p><em>MnistClassifierModel06.py</em></p>\n\n<pre><code>import math\nimport numpy\nfrom keras import Sequential\nfrom keras.engine.saving import load_model, model_from_json\nfrom keras.layers import Convolution2D, Dense, Dropout, Flatten, MaxPooling2D\n\nfrom MnistClassifierModelBase import MnistClassifier\n\n\nclass MnistClassifier06(MnistClassifier):\n    def __init__(self, verbose: bool = False):\n        super().__init__(verbose)\n        self.model = None\n        self.verbose = verbose\n\n    def build_model(self):\n        self.model = Sequential()\n        self.model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n        self.model.add(Convolution2D(32, (3, 3), activation='relu'))\n        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n        self.model.add(Dropout(0.25))\n\n        self.model.add(Flatten())\n        self.model.add(Dense(128, activation='relu'))\n        self.model.add(Dropout(0.5))\n        self.model.add(Dense(10, activation='softmax'))\n\n        self.verbose_log(self.model.summary())\n        self.compile_model()\n\n    def compile_model(self):\n        self.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n    def fit(self, x, y, batch_size=32, epochs=30):\n        history = self.model.fit(x, y, batch_size, epochs)\n        return history.history['loss'], history.history['acc']\n\n    def train_on_batch(self, x: numpy.ndarray, y: numpy.ndarray, batch_size=32):\n        num_samples = x.shape[0]\n        if num_samples % batch_size != 0:\n            raise RuntimeWarning('Batch size does not divide number of samples exactly. '\n                                 'Last set of samples will not be used for training')\n        loss, accuracy = [], []\n        self.verbose_log('iteration, loss, accuracy')\n        for i in range(int(math.floor(num_samples / batch_size))):\n            data = x[i * batch_size:(i + 1) * batch_size, :, :]\n            labels = y[i * batch_size:(i + 1) * batch_size]\n            batch_loss, batch_accuracy = self.model.train_on_batch(data, labels)\n            loss.append(batch_loss)\n            accuracy.append(batch_accuracy)\n            self.verbose_log('{0:04},{1:2.4f},{2:0.4f}\\n'.format(i + 1, batch_loss, batch_accuracy))\n        return loss, accuracy\n\n    def evaluate(self, x, y):\n        score = self.model.evaluate(x, y)\n        return score[0], score[1]\n\n    def classify(self, x):\n        y = self.model.predict(x)\n        return y\n\n    def save_model(self, save_path):\n        self.model.save(save_path)\n\n    def save_model_data(self, json_path, weights_path):\n        with open(json_path, 'w') as json_file:\n            json_file.write(self.model.to_json())\n        self.model.save_weights(weights_path)\n\n    @staticmethod\n    def load_model(model_path) -&gt; MnistClassifier:\n        model = load_model(model_path)\n        classifier = MnistClassifier06()\n        classifier.model = model\n        return classifier\n\n    @staticmethod\n    def load_model_from_data(json_path, weights_path) -&gt; MnistClassifier:\n        with open(json_path, 'r') as json_file:\n            model = model_from_json(json_file.read())\n        model.load_weights(weights_path)\n        classifier = MnistClassifier06()\n        classifier.model = model\n        classifier.compile_model()\n        return classifier\n</code></pre>\n <keras><evaluation><gan><inception>",
                "codes": [],
                "question_id:": "56196",
                "question_votes:": "",
                "question_text:": "<p>I'm starting out with GANs and I am training a DC-GAN on MNIST dataset. The two metrics that are used to evaluate GANs are Inception Score (IS) and Frechet Inception Distance (FID). Since Inception network is not trained to classify MNIST digits, I built a simple MNIST classifier and I'm using that. Inception score, I'm getting pretty decent values. For FID, I'm using the output of last Fully Connected Layer as feature vector. But, I'm getting values in the order of <span class=\"math-container\">$10^6$</span>, which doesn't look right. So, I have a few questions</p>\n\n<ol>\n<li>Does it make sense to compute FID for MNIST GAN?</li>\n<li>Is the value in the order of <span class=\"math-container\">$10^6$</span> correct?</li>\n<li>How many images from real dataset should be used while computing FID</li>\n<li>Is my code below correct? I used the <a href=\"https://github.com/bioinf-jku/TTUR/blob/master/FIDvsINC/fid.py\" rel=\"nofollow noreferrer\">code</a> provided by original authors and modified it according to my requirements.</li>\n</ol>\n\n<p>If you can answer any of these questions, even partially, that would be of immense help to me. Thanks!</p>\n\n<p><strong>Code</strong>:\n<em>FidScore.py</em></p>\n\n<pre><code>import warnings\n\nimport numpy\nfrom keras.datasets import mnist\nfrom keras.models import Model\nfrom scipy import linalg\n\nfrom DcGanBaseModel import DcGanBaseModel\nfrom MnistClassifierModel06 import MnistClassifier06\nfrom mnist.MnistModel02 import MnistModel02\n\n\nclass FrechetInceptionDistance:\n\n    def __init__(self, real_activations: numpy.ndarray, verbose=False) -&gt; None:\n        self.real_activations = real_activations\n        self.verbose = verbose\n\n        self.real_mu = numpy.mean(real_activations, axis=0)\n        self.real_sigma = numpy.cov(real_activations, rowvar=False)\n\n    def compute_fid(self, fake_activations: numpy.ndarray):\n        fake_mu = numpy.mean(fake_activations, axis=0)\n        fake_sigma = numpy.cov(fake_activations, rowvar=False)\n        fid = self.calculate_frechet_distance(fake_mu, fake_sigma, self.real_mu, self.real_sigma)\n        return fid\n\n    @staticmethod\n    def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n        \"\"\"\n        https://github.com/bioinf-jku/TTUR/blob/master/FIDvsINC/fid.py#L99-L148\n        Numpy implementation of the Frechet Distance.\n        The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n        and X_2 ~ N(mu_2, C_2) is\n                d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n        Stable version by Dougal J. Sutherland.\n        Params:\n        -- mu1 : Numpy array containing the activations of the pool_3 layer of the\n                 inception net ( like returned by the function 'get_predictions')\n                 for generated samples.\n        -- mu2   : The sample mean over activations of the pool_3 layer, precalcualted\n                   on an representive data set.\n        -- sigma1: The covariance matrix over activations of the pool_3 layer for\n                   generated samples.\n        -- sigma2: The covariance matrix over activations of the pool_3 layer,\n                   precalcualted on an representive data set.\n        Returns:\n        --   : The Frechet Distance.\n        \"\"\"\n\n        mu1 = numpy.atleast_1d(mu1)\n        mu2 = numpy.atleast_1d(mu2)\n\n        sigma1 = numpy.atleast_2d(sigma1)\n        sigma2 = numpy.atleast_2d(sigma2)\n\n        assert mu1.shape == mu2.shape, \"Training and test mean vectors have different lengths\"\n        assert sigma1.shape == sigma2.shape, \"Training and test covariances have different dimensions\"\n\n        diff = mu1 - mu2\n\n        # product might be almost singular\n        covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n        if not numpy.isfinite(covmean).all():\n            msg = \"fid calculation produces singular product; adding %s to diagonal of cov estimates\" % eps\n            warnings.warn(msg)\n            offset = numpy.eye(sigma1.shape[0]) * eps\n            covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n\n        # numerical error might give slight imaginary component\n        if numpy.iscomplexobj(covmean):\n            if not numpy.allclose(numpy.diagonal(covmean).imag, 0, atol=1e-3):\n                m = numpy.max(numpy.abs(covmean.imag))\n                raise ValueError(\"Imaginary component {}\".format(m))\n            covmean = covmean.real\n\n        tr_covmean = numpy.trace(covmean)\n\n        return diff.dot(diff) + numpy.trace(sigma1) + numpy.trace(sigma2) - 2 * tr_covmean\n\n\ndef compute_fid_score_for_gan(gan_model: DcGanBaseModel, classifier_model, layer_name, num_classes):\n    # Define Feature Extracter\n    feature_layer = Model(inputs=classifier_model.model.input,\n                          outputs=classifier_model.model.get_layer(layer_name).output)\n\n    # Compute Features for MNIST Dataset Images\n    (x_train, _), _ = mnist.load_data()\n    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n    real_features = feature_layer.predict(x_train)\n    fid = FrechetInceptionDistance(real_features, verbose=True)\n\n    num_images = num_classes * 1000\n    gen_images = gan_model.generate_images(num_images)\n    fake_features = feature_layer.predict(gen_images)\n\n    fid_score = fid.compute_fid(fake_features)\n    return fid_score\n\n\ndef demo1():\n    gan_model = MnistModel02(print_model_summary=False)\n    gan_model.load_generator_model('../../Runs/01_MNIST/Model02/Run01/TrainedModels/generator_model_10000.h5')\n    classifier_model = MnistClassifier06().load_model(\n        '../../../../../DiscriminativeModels/01_MNIST_Classification/Runs/Run01/Trained_Models/MNIST_Model_10.h5')\n    fid_score = compute_fid_score_for_gan(gan_model, classifier_model, 'dense_1', 10)\n    print(fid_score)\n\n\nif __name__ == '__main__':\n    demo1()\n</code></pre>\n\n<p><em>MnistClassifierModel06.py</em></p>\n\n<pre><code>import math\nimport numpy\nfrom keras import Sequential\nfrom keras.engine.saving import load_model, model_from_json\nfrom keras.layers import Convolution2D, Dense, Dropout, Flatten, MaxPooling2D\n\nfrom MnistClassifierModelBase import MnistClassifier\n\n\nclass MnistClassifier06(MnistClassifier):\n    def __init__(self, verbose: bool = False):\n        super().__init__(verbose)\n        self.model = None\n        self.verbose = verbose\n\n    def build_model(self):\n        self.model = Sequential()\n        self.model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n        self.model.add(Convolution2D(32, (3, 3), activation='relu'))\n        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n        self.model.add(Dropout(0.25))\n\n        self.model.add(Flatten())\n        self.model.add(Dense(128, activation='relu'))\n        self.model.add(Dropout(0.5))\n        self.model.add(Dense(10, activation='softmax'))\n\n        self.verbose_log(self.model.summary())\n        self.compile_model()\n\n    def compile_model(self):\n        self.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n    def fit(self, x, y, batch_size=32, epochs=30):\n        history = self.model.fit(x, y, batch_size, epochs)\n        return history.history['loss'], history.history['acc']\n\n    def train_on_batch(self, x: numpy.ndarray, y: numpy.ndarray, batch_size=32):\n        num_samples = x.shape[0]\n        if num_samples % batch_size != 0:\n            raise RuntimeWarning('Batch size does not divide number of samples exactly. '\n                                 'Last set of samples will not be used for training')\n        loss, accuracy = [], []\n        self.verbose_log('iteration, loss, accuracy')\n        for i in range(int(math.floor(num_samples / batch_size))):\n            data = x[i * batch_size:(i + 1) * batch_size, :, :]\n            labels = y[i * batch_size:(i + 1) * batch_size]\n            batch_loss, batch_accuracy = self.model.train_on_batch(data, labels)\n            loss.append(batch_loss)\n            accuracy.append(batch_accuracy)\n            self.verbose_log('{0:04},{1:2.4f},{2:0.4f}\\n'.format(i + 1, batch_loss, batch_accuracy))\n        return loss, accuracy\n\n    def evaluate(self, x, y):\n        score = self.model.evaluate(x, y)\n        return score[0], score[1]\n\n    def classify(self, x):\n        y = self.model.predict(x)\n        return y\n\n    def save_model(self, save_path):\n        self.model.save(save_path)\n\n    def save_model_data(self, json_path, weights_path):\n        with open(json_path, 'w') as json_file:\n            json_file.write(self.model.to_json())\n        self.model.save_weights(weights_path)\n\n    @staticmethod\n    def load_model(model_path) -&gt; MnistClassifier:\n        model = load_model(model_path)\n        classifier = MnistClassifier06()\n        classifier.model = model\n        return classifier\n\n    @staticmethod\n    def load_model_from_data(json_path, weights_path) -&gt; MnistClassifier:\n        with open(json_path, 'r') as json_file:\n            model = model_from_json(json_file.read())\n        model.load_weights(weights_path)\n        classifier = MnistClassifier06()\n        classifier.model = model\n        classifier.compile_model()\n        return classifier\n</code></pre>\n",
                "tags": "<keras><evaluation><gan><inception>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5384",
            "_score": 7.039652,
            "_source": {
                "title": "Prepending Input layer to pre-trained model",
                "content": "Prepending Input layer to pre-trained model <p>I'm trying to input numpy arrays of shape (1036800,) - originally images of shape (480, 720, 3) - into a pre-trained VGG16 model to predict continuous values.</p>\n\n<p>I've tried several variations of the code below:</p>\n\n<pre><code>input = Input(shape=(1036800,), name='image_input')\ninitial_model = VGG16(weights='imagenet', include_top=False)\nx = Flatten()(initial_model(input).output)\nx = Dense(200, activation='relu')(x)\nx = Dense(1)(x)\nmodel = Model(inputs=input, outputs=x)\n</code></pre>\n\n<p>Previous variations of the above code yielded errors related to the input being the wrong dimensions, <code>input_shape</code> needing to have 3 channels (when using (1036800,) for that parameter in the initialization of VGG16), and the most recent error that results from running the above code is this:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"model_alex.py\", line 57, in &lt;module&gt;\n    model = initialize_model()\n  File \"model_alex.py\", line 20, in initialize_model\n    x = Flatten()(initial_model(input).output)\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/engine/topology.py\", line 596, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/engine/topology.py\", line 2061, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/engine/topology.py\", line 2212, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/layers/convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 3156, in conv2d\n    data_format='NHWC')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 639, in convolution\n    input_channels_dim = input.get_shape()[num_spatial_dims + 1]\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py\", line 500, in __getitem__\n    return self._dims[key]\nIndexError: list index out of range\n</code></pre>\n\n<p>Here is the <a href=\"https://pastebin.com/9EwQy5tV\" rel=\"noreferrer\">full code</a>. Here is the <a href=\"https://drive.google.com/open?id=0B-i1XzvYHh2ZaHVSVmhNSlNLc0E\" rel=\"noreferrer\">sample data file</a> used in the script.</p>\n\n<p>One of the possible approach towards fixing this might be to resize the raw image files to 224x224 and turn them into numpy arrays of shape (224, 224, 3) so they can be plugged into the pre-trained model's first layer. However, I don't want to warp the images or waste another night pre-processing data when I should already be training.</p>\n\n<p>Besides that, I all I can think to do is Google my problem and try to adapt the found solutions or aimlessly tweak various shape related parameters and functions -- neither of which has gotten me very far over the past 4 hours.</p>\n <python><keras><p>The issue is that you shouldn't flatten the images into 1-dimensional vector because the VGG16 contains 2D convolution layers (e.g. spatial convolution over images), which require the input to have the shape of <code>(number_of_images, image_height, image_width, image_channels)</code>, given that <code>keras.backend.image_data_format()</code> returns <code>'channels_last'</code>. If your <code>image_data_format</code> is <code>'channels_first'</code>, change the input data shape to <code>(number_of_images, image_channels, image_height, image_width)</code>.</p>\n\n<p>Here is your fixed code (tested with Keras 2.0.4):</p>\n\n<pre><code>x_train = x_train.reshape((x_train.shape[0], 480, 720, 3))\nx_test = x_test.reshape((x_test.shape[0], 480, 720, 3))\n\ninitial_model = VGG16(weights='imagenet', include_top=False)\ninput = Input(shape=(480, 720, 3), name='image_input')\nx = Flatten()(initial_model(input))\nx = Dense(200, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Dense(1)(x)\nmodel = Model(inputs=input, outputs=x)\nmodel.compile(loss='mse', optimizer='adam')\n\nmodel.fit(x_train, y_train, epochs=20, batch_size=16)\nscore = model.evaluate(x_test, y_test, batch_size=16)\n</code></pre>\n",
                "codes": [
                    [
                        "x_train = x_train.reshape((x_train.shape[0], 480, 720, 3))\nx_test = x_test.reshape((x_test.shape[0], 480, 720, 3))\n\ninitial_model = VGG16(weights='imagenet', include_top=False)\ninput = Input(shape=(480, 720, 3), name='image_input')\nx = Flatten()(initial_model(input))\nx = Dense(200, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Dense(1)(x)\nmodel = Model(inputs=input, outputs=x)\nmodel.compile(loss='mse', optimizer='adam')\n\nmodel.fit(x_train, y_train, epochs=20, batch_size=16)\nscore = model.evaluate(x_test, y_test, batch_size=16)\n"
                    ]
                ],
                "question_id:": "21610",
                "question_votes:": "6",
                "question_text:": "<p>I'm trying to input numpy arrays of shape (1036800,) - originally images of shape (480, 720, 3) - into a pre-trained VGG16 model to predict continuous values.</p>\n\n<p>I've tried several variations of the code below:</p>\n\n<pre><code>input = Input(shape=(1036800,), name='image_input')\ninitial_model = VGG16(weights='imagenet', include_top=False)\nx = Flatten()(initial_model(input).output)\nx = Dense(200, activation='relu')(x)\nx = Dense(1)(x)\nmodel = Model(inputs=input, outputs=x)\n</code></pre>\n\n<p>Previous variations of the above code yielded errors related to the input being the wrong dimensions, <code>input_shape</code> needing to have 3 channels (when using (1036800,) for that parameter in the initialization of VGG16), and the most recent error that results from running the above code is this:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"model_alex.py\", line 57, in &lt;module&gt;\n    model = initialize_model()\n  File \"model_alex.py\", line 20, in initialize_model\n    x = Flatten()(initial_model(input).output)\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/engine/topology.py\", line 596, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/engine/topology.py\", line 2061, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/engine/topology.py\", line 2212, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/layers/convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 3156, in conv2d\n    data_format='NHWC')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 639, in convolution\n    input_channels_dim = input.get_shape()[num_spatial_dims + 1]\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py\", line 500, in __getitem__\n    return self._dims[key]\nIndexError: list index out of range\n</code></pre>\n\n<p>Here is the <a href=\"https://pastebin.com/9EwQy5tV\" rel=\"noreferrer\">full code</a>. Here is the <a href=\"https://drive.google.com/open?id=0B-i1XzvYHh2ZaHVSVmhNSlNLc0E\" rel=\"noreferrer\">sample data file</a> used in the script.</p>\n\n<p>One of the possible approach towards fixing this might be to resize the raw image files to 224x224 and turn them into numpy arrays of shape (224, 224, 3) so they can be plugged into the pre-trained model's first layer. However, I don't want to warp the images or waste another night pre-processing data when I should already be training.</p>\n\n<p>Besides that, I all I can think to do is Google my problem and try to adapt the found solutions or aimlessly tweak various shape related parameters and functions -- neither of which has gotten me very far over the past 4 hours.</p>\n",
                "tags": "<python><keras>",
                "answers": [
                    [
                        "21620",
                        "2",
                        "21610",
                        "",
                        "",
                        "<p>The issue is that you shouldn't flatten the images into 1-dimensional vector because the VGG16 contains 2D convolution layers (e.g. spatial convolution over images), which require the input to have the shape of <code>(number_of_images, image_height, image_width, image_channels)</code>, given that <code>keras.backend.image_data_format()</code> returns <code>'channels_last'</code>. If your <code>image_data_format</code> is <code>'channels_first'</code>, change the input data shape to <code>(number_of_images, image_channels, image_height, image_width)</code>.</p>\n\n<p>Here is your fixed code (tested with Keras 2.0.4):</p>\n\n<pre><code>x_train = x_train.reshape((x_train.shape[0], 480, 720, 3))\nx_test = x_test.reshape((x_test.shape[0], 480, 720, 3))\n\ninitial_model = VGG16(weights='imagenet', include_top=False)\ninput = Input(shape=(480, 720, 3), name='image_input')\nx = Flatten()(initial_model(input))\nx = Dense(200, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Dense(1)(x)\nmodel = Model(inputs=input, outputs=x)\nmodel.compile(loss='mse', optimizer='adam')\n\nmodel.fit(x_train, y_train, epochs=20, batch_size=16)\nscore = model.evaluate(x_test, y_test, batch_size=16)\n</code></pre>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12415",
            "_score": 7.039652,
            "_source": {
                "title": "Sobel Operator || Pixel Constraint",
                "content": "Sobel Operator || Pixel Constraint <p>I am trying out the Sobel vertical operator to identify vertical edges in a picture. In each image there is one rectangle but the difference is that in 1 image the 2 vertical lines in the rectangle is 1 pixel apart whereas in the other it is more than 1 pixel apart as shown below.</p>\n\n<h2><a href=\"https://i.stack.imgur.com/AJpvT.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/AJpvT.png\" alt=\"enter image description here\"></a> <a href=\"https://i.stack.imgur.com/VX5uE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/VX5uE.png\" alt=\"enter image description here\"></a></h2>\n\n<p>Now when i run the sobel vertical filter my expectation is that in both cases i should get 2 edges. But to my surprise it returns 2 edges for the bigger rectangle but only one edge for the smaller rectangle as shown below.</p>\n\n<p><a href=\"https://i.stack.imgur.com/6FWjW.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/6FWjW.png\" alt=\"enter image description here\"></a>   <a href=\"https://i.stack.imgur.com/1PTwI.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/1PTwI.png\" alt=\"enter image description here\"></a></p>\n\n<hr>\n\n<p>My Python code is as follows.</p>\n\n<pre><code>from PIL import Image\nimport numpy as np\nim = Image.open('Test.png').convert('L')\nim.save('greyscale.png')\npix_val = np.array(list(im.getdata())).reshape(81,91)\nfor i in range(12,14):\n    for j in range(12,78):\n        pix_val[i,j]=255      \nfor i in range(63,65):\n    for j in range(12,78):\n        pix_val[i,j]=255\nfor i in range(14,63):\n    for j in range(12,14):\n        pix_val[i,j]=255\nfor i in range(14,63):\n    for j in range(76,78):\n        pix_val[i,j]=255\nOim1=Image.fromarray(pix_val.astype(np.uint8))\nOim1.save('out1.bmp')\npix_val2=np.delete(pix_val,range(16,75), 1)\nOim2=Image.fromarray(pix_val2.astype(np.uint8))\nOim2.save('out2.bmp')\nfrom scipy import ndimage\ndy1 = ndimage.sobel(Oim1, 1)\nOim3=Image.fromarray(dy1.astype(np.uint8))\nOim3.save('Sobel1.bmp')\ndy2 = ndimage.sobel(Oim2, 1)\nOim4=Image.fromarray(dy2.astype(np.uint8))\nOim4.save('Sobel2.bmp')\n</code></pre>\n\n<p>Is this a limitation of sobel operator that it cant detect edges that are very near to each other?</p>\n <image-recognition><p>This is <strong>not a limitation</strong> of the Sobel operator, if the boundaries are clear, even a single pixel wide rectangle should be detectable.</p>\n\n<p>I ran your code, but just used an empty image as the \"im\" image and it worked fine for me.</p>\n\n<p>Here is my code (similar to yours, just without 'Test.png' and without saving the images):</p>\n\n<pre><code>from PIL import Image\nimport numpy as np\nfrom scipy import ndimage\n\nim = Image.fromarray(np.zeros((81,91)).astype(np.uint8))\npix_val = np.array(list(im.getdata())).reshape(81,91)\nfor i in range(12,14):\n    for j in range(12,78):\n        pix_val[i,j]=255      \nfor i in range(63,65):\n    for j in range(12,78):\n        pix_val[i,j]=255\nfor i in range(14,63):\n    for j in range(12,14):\n        pix_val[i,j]=255\nfor i in range(14,63):\n    for j in range(76,78):\n        pix_val[i,j]=255\n\nOim1 = Image.fromarray(pix_val.astype(np.uint8))\npix_val2 = np.delete(pix_val,range(16,75), 1)\nOim1.show()\n\nOim2 = Image.fromarray(pix_val2.astype(np.uint8))\nOim2.show()\n\ndy1 = ndimage.sobel(Oim1, 1)\nOim3 = Image.fromarray(dy1.astype(np.uint8))\nOim3.show()\n\ndy2 = ndimage.sobel(Oim2, 1)\nOim4 = Image.fromarray(dy2.astype(np.uint8))\nOim4.show()\n</code></pre>\n\n<p>This is what I get:</p>\n\n<p><a href=\"https://i.stack.imgur.com/AKHjm.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/AKHjm.png\" alt=\"enter image description here\"></a>\n<a href=\"https://i.stack.imgur.com/Cyem3.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Cyem3.png\" alt=\"enter image description here\"></a></p>\n",
                "codes": [
                    [
                        "from PIL import Image\nimport numpy as np\nfrom scipy import ndimage\n\nim = Image.fromarray(np.zeros((81,91)).astype(np.uint8))\npix_val = np.array(list(im.getdata())).reshape(81,91)\nfor i in range(12,14):\n    for j in range(12,78):\n        pix_val[i,j]=255      \nfor i in range(63,65):\n    for j in range(12,78):\n        pix_val[i,j]=255\nfor i in range(14,63):\n    for j in range(12,14):\n        pix_val[i,j]=255\nfor i in range(14,63):\n    for j in range(76,78):\n        pix_val[i,j]=255\n\nOim1 = Image.fromarray(pix_val.astype(np.uint8))\npix_val2 = np.delete(pix_val,range(16,75), 1)\nOim1.show()\n\nOim2 = Image.fromarray(pix_val2.astype(np.uint8))\nOim2.show()\n\ndy1 = ndimage.sobel(Oim1, 1)\nOim3 = Image.fromarray(dy1.astype(np.uint8))\nOim3.show()\n\ndy2 = ndimage.sobel(Oim2, 1)\nOim4 = Image.fromarray(dy2.astype(np.uint8))\nOim4.show()\n"
                    ]
                ],
                "question_id:": "43570",
                "question_votes:": "",
                "question_text:": "<p>I am trying out the Sobel vertical operator to identify vertical edges in a picture. In each image there is one rectangle but the difference is that in 1 image the 2 vertical lines in the rectangle is 1 pixel apart whereas in the other it is more than 1 pixel apart as shown below.</p>\n\n<h2><a href=\"https://i.stack.imgur.com/AJpvT.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/AJpvT.png\" alt=\"enter image description here\"></a> <a href=\"https://i.stack.imgur.com/VX5uE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/VX5uE.png\" alt=\"enter image description here\"></a></h2>\n\n<p>Now when i run the sobel vertical filter my expectation is that in both cases i should get 2 edges. But to my surprise it returns 2 edges for the bigger rectangle but only one edge for the smaller rectangle as shown below.</p>\n\n<p><a href=\"https://i.stack.imgur.com/6FWjW.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/6FWjW.png\" alt=\"enter image description here\"></a>   <a href=\"https://i.stack.imgur.com/1PTwI.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/1PTwI.png\" alt=\"enter image description here\"></a></p>\n\n<hr>\n\n<p>My Python code is as follows.</p>\n\n<pre><code>from PIL import Image\nimport numpy as np\nim = Image.open('Test.png').convert('L')\nim.save('greyscale.png')\npix_val = np.array(list(im.getdata())).reshape(81,91)\nfor i in range(12,14):\n    for j in range(12,78):\n        pix_val[i,j]=255      \nfor i in range(63,65):\n    for j in range(12,78):\n        pix_val[i,j]=255\nfor i in range(14,63):\n    for j in range(12,14):\n        pix_val[i,j]=255\nfor i in range(14,63):\n    for j in range(76,78):\n        pix_val[i,j]=255\nOim1=Image.fromarray(pix_val.astype(np.uint8))\nOim1.save('out1.bmp')\npix_val2=np.delete(pix_val,range(16,75), 1)\nOim2=Image.fromarray(pix_val2.astype(np.uint8))\nOim2.save('out2.bmp')\nfrom scipy import ndimage\ndy1 = ndimage.sobel(Oim1, 1)\nOim3=Image.fromarray(dy1.astype(np.uint8))\nOim3.save('Sobel1.bmp')\ndy2 = ndimage.sobel(Oim2, 1)\nOim4=Image.fromarray(dy2.astype(np.uint8))\nOim4.save('Sobel2.bmp')\n</code></pre>\n\n<p>Is this a limitation of sobel operator that it cant detect edges that are very near to each other?</p>\n",
                "tags": "<image-recognition>",
                "answers": [
                    [
                        "43571",
                        "2",
                        "43570",
                        "",
                        "",
                        "<p>This is <strong>not a limitation</strong> of the Sobel operator, if the boundaries are clear, even a single pixel wide rectangle should be detectable.</p>\n\n<p>I ran your code, but just used an empty image as the \"im\" image and it worked fine for me.</p>\n\n<p>Here is my code (similar to yours, just without 'Test.png' and without saving the images):</p>\n\n<pre><code>from PIL import Image\nimport numpy as np\nfrom scipy import ndimage\n\nim = Image.fromarray(np.zeros((81,91)).astype(np.uint8))\npix_val = np.array(list(im.getdata())).reshape(81,91)\nfor i in range(12,14):\n    for j in range(12,78):\n        pix_val[i,j]=255      \nfor i in range(63,65):\n    for j in range(12,78):\n        pix_val[i,j]=255\nfor i in range(14,63):\n    for j in range(12,14):\n        pix_val[i,j]=255\nfor i in range(14,63):\n    for j in range(76,78):\n        pix_val[i,j]=255\n\nOim1 = Image.fromarray(pix_val.astype(np.uint8))\npix_val2 = np.delete(pix_val,range(16,75), 1)\nOim1.show()\n\nOim2 = Image.fromarray(pix_val2.astype(np.uint8))\nOim2.show()\n\ndy1 = ndimage.sobel(Oim1, 1)\nOim3 = Image.fromarray(dy1.astype(np.uint8))\nOim3.show()\n\ndy2 = ndimage.sobel(Oim2, 1)\nOim4 = Image.fromarray(dy2.astype(np.uint8))\nOim4.show()\n</code></pre>\n\n<p>This is what I get:</p>\n\n<p><a href=\"https://i.stack.imgur.com/AKHjm.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/AKHjm.png\" alt=\"enter image description here\"></a>\n<a href=\"https://i.stack.imgur.com/Cyem3.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Cyem3.png\" alt=\"enter image description here\"></a></p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14484",
            "_score": 7.039652,
            "_source": {
                "title": "Implementation of actor-critic model for MountainCar",
                "content": "Implementation of actor-critic model for MountainCar <p>I'm trying to build a model for the Mountain Car game, following this Actor-Critic code: <a href=\"https://github.com/nikhilbarhate99/Actor-Critic\" rel=\"nofollow noreferrer\">https://github.com/nikhilbarhate99/Actor-Critic</a>\n(However, in this case, it's discrete action space, while it's continuous for my problem. Also, it's not the MountainCar game in this github code.</p>\n\n<p>So, I want to use the actor critic model in order to makes a player of the famous Mountain Car game. All the environment code is here: <a href=\"https://github.com/nbrosson/Actor-critic-MountainCar/\" rel=\"nofollow noreferrer\">https://github.com/nbrosson/Actor-critic-MountainCar/</a> Everything about the environment works fine. The only file that I have to worry about is agent.py</p>\n\n<pre><code>import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.distributions import Normal\n\n\"\"\"\nContains the definition of the agent that will run in an\nenvironment.\n\"\"\"\n\nclass ActorCritic(nn.Module):\n    def __init__(self):\n        super(ActorCritic, self).__init__()\n        self.affine = nn.Linear(2, 32)\n\n        self.action_layer = nn.Linear(32, 2)\n        self.value_layer = nn.Linear(32, 1)\n\n        self.logprobs = []\n        self.state_values = []\n        self.rewards = []\n        self.actions = []\n\n\n    def forward(self, observation):\n        # Convert tuple into tensor\n        observation_as_list = []\n        observation_as_list.append(observation[0])\n        observation_as_list.append(observation[1])\n        observation_as_list = np.asarray(observation_as_list)\n        observation_as_list = observation_as_list.reshape(1,2)\n        observation = observation_as_list\n\n        state = torch.from_numpy(observation).float()\n        state = F.relu(self.affine(state))\n\n        state_value = self.value_layer(state)\n        action_parameters = F.tanh(self.action_layer(state))\n        action_distribution = Normal(action_parameters[0][0], action_parameters[0][1])\n\n        action = action_distribution.sample() # Torch.tensor; action\n\n        self.logprobs.append(action_distribution.log_prob(action)+ 1e-6)\n        self.state_values.append(state_value)\n        return action.item() # Float element\n\n\n\n    def calculateLoss(self, gamma=0.99):\n\n        # calculating discounted rewards:\n        rewards = []\n        dis_reward = 0\n        for reward in self.rewards[::-1]:\n            dis_reward = reward + gamma * dis_reward\n            rewards.insert(0, dis_reward)\n\n        # normalizing the rewards:\n        rewards = torch.tensor(rewards)\n        rewards = (rewards - rewards.mean()) / (rewards.std())\n\n        loss = 0\n        for logprob, value, reward in zip(self.logprobs, self.state_values, rewards):\n            advantage = reward  - value.item()\n            action_loss = -logprob * advantage\n            value_loss = F.smooth_l1_loss(value, reward)\n            loss += (action_loss + value_loss)  \n\n        return loss\n\n    def clearMemory(self):\n        del self.logprobs[:]\n        del self.state_values[:]\n        del self.rewards[:]\n\n\n\n\nclass RandomAgent():\n    def __init__(self):\n        \"\"\"Init a new agent.\n        \"\"\"\n        #self.theta = np.zeros((3, 2))\n        #self.state = RandomAgent.reset(self,[-20,20])\n\n        self.count_episodes = -1\n        self.max_position = -0.4\n        self.epsilon = 0.9\n        self.gamma = 0.99\n        self.running_rewards = 0\n        self.policy = ActorCritic()\n        self.optimizer = optim.Adam(self.policy.parameters(), lr=0.01, betas=(0.9, 0.999))\n        self.check_new_episode = 1\n        self.count_iter = 0\n\n    def reset(self, x_range):\n        \"\"\"Reset the state of the agent for the start of new game.\n\n        Parameters of the environment do not change, but your initial\n        location is randomized.\n\n        x_range = [xmin, xmax] contains the range of possible values for x\n\n        range for vx is always [-20, 20]\n        \"\"\"\n        self.epsilon = (self.epsilon * 0.99)\n        self.count_episodes += 1\n        return (np.random.uniform(x_range[0],x_range[1]), np.random.uniform(-20,20))\n\n    def act(self, observation):\n        \"\"\"Acts given an observation of the environment.\n\n        Takes as argument an observation of the current state, and\n        returns the chosen action.\n\n        observation = (x, vx)\n        \"\"\"\n\n#        observation_as_list = []\n#        observation_as_list.append(observation[0])\n#        observation_as_list.append(observation[1])\n#        observation_as_list = np.asarray(observation_as_list)\n#        observation_as_list = observation_as_list.reshape(1,2)\n#        observation = observation_as_list\n\n\n        if np.random.rand(1) &lt; self.epsilon:\n            return np.random.uniform(-1,1)\n        else:\n            action = self.policy(observation)\n            return action\n\n    def reward(self, observation, action, reward):\n        \"\"\"Receive a reward for performing given action on\n        given observation.\n\n        This is where your agent can learn.\n        \"\"\"\n        self.count_iter +=1\n        self.policy.rewards.append(reward)\n        self.running_rewards += reward\n        if self.count_iter == 100:\n            # We want first to update the critic agent:\n            self.optimizer.zero_grad()\n            self.loss = self.policy.calculateLoss(self.gamma)\n            self.loss.backward()\n            self.optimizer.step()        \n            self.policy.clearMemory()\n\n            self.count_iter = 0\n\n\nAgent = RandomAgent\n</code></pre>\n\n<p>However, my model does not provide good results. It doesn't even improve with 200 episodes. </p>\n\n<p>Any ideas what is wrong on my code?? Any suggestions?? </p>\n\n<p>Thanks a lot !! </p>\n <python><reinforcement-learning><pytorch><actor-critic>",
                "codes": [],
                "question_id:": "48713",
                "question_votes:": "",
                "question_text:": "<p>I'm trying to build a model for the Mountain Car game, following this Actor-Critic code: <a href=\"https://github.com/nikhilbarhate99/Actor-Critic\" rel=\"nofollow noreferrer\">https://github.com/nikhilbarhate99/Actor-Critic</a>\n(However, in this case, it's discrete action space, while it's continuous for my problem. Also, it's not the MountainCar game in this github code.</p>\n\n<p>So, I want to use the actor critic model in order to makes a player of the famous Mountain Car game. All the environment code is here: <a href=\"https://github.com/nbrosson/Actor-critic-MountainCar/\" rel=\"nofollow noreferrer\">https://github.com/nbrosson/Actor-critic-MountainCar/</a> Everything about the environment works fine. The only file that I have to worry about is agent.py</p>\n\n<pre><code>import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.distributions import Normal\n\n\"\"\"\nContains the definition of the agent that will run in an\nenvironment.\n\"\"\"\n\nclass ActorCritic(nn.Module):\n    def __init__(self):\n        super(ActorCritic, self).__init__()\n        self.affine = nn.Linear(2, 32)\n\n        self.action_layer = nn.Linear(32, 2)\n        self.value_layer = nn.Linear(32, 1)\n\n        self.logprobs = []\n        self.state_values = []\n        self.rewards = []\n        self.actions = []\n\n\n    def forward(self, observation):\n        # Convert tuple into tensor\n        observation_as_list = []\n        observation_as_list.append(observation[0])\n        observation_as_list.append(observation[1])\n        observation_as_list = np.asarray(observation_as_list)\n        observation_as_list = observation_as_list.reshape(1,2)\n        observation = observation_as_list\n\n        state = torch.from_numpy(observation).float()\n        state = F.relu(self.affine(state))\n\n        state_value = self.value_layer(state)\n        action_parameters = F.tanh(self.action_layer(state))\n        action_distribution = Normal(action_parameters[0][0], action_parameters[0][1])\n\n        action = action_distribution.sample() # Torch.tensor; action\n\n        self.logprobs.append(action_distribution.log_prob(action)+ 1e-6)\n        self.state_values.append(state_value)\n        return action.item() # Float element\n\n\n\n    def calculateLoss(self, gamma=0.99):\n\n        # calculating discounted rewards:\n        rewards = []\n        dis_reward = 0\n        for reward in self.rewards[::-1]:\n            dis_reward = reward + gamma * dis_reward\n            rewards.insert(0, dis_reward)\n\n        # normalizing the rewards:\n        rewards = torch.tensor(rewards)\n        rewards = (rewards - rewards.mean()) / (rewards.std())\n\n        loss = 0\n        for logprob, value, reward in zip(self.logprobs, self.state_values, rewards):\n            advantage = reward  - value.item()\n            action_loss = -logprob * advantage\n            value_loss = F.smooth_l1_loss(value, reward)\n            loss += (action_loss + value_loss)  \n\n        return loss\n\n    def clearMemory(self):\n        del self.logprobs[:]\n        del self.state_values[:]\n        del self.rewards[:]\n\n\n\n\nclass RandomAgent():\n    def __init__(self):\n        \"\"\"Init a new agent.\n        \"\"\"\n        #self.theta = np.zeros((3, 2))\n        #self.state = RandomAgent.reset(self,[-20,20])\n\n        self.count_episodes = -1\n        self.max_position = -0.4\n        self.epsilon = 0.9\n        self.gamma = 0.99\n        self.running_rewards = 0\n        self.policy = ActorCritic()\n        self.optimizer = optim.Adam(self.policy.parameters(), lr=0.01, betas=(0.9, 0.999))\n        self.check_new_episode = 1\n        self.count_iter = 0\n\n    def reset(self, x_range):\n        \"\"\"Reset the state of the agent for the start of new game.\n\n        Parameters of the environment do not change, but your initial\n        location is randomized.\n\n        x_range = [xmin, xmax] contains the range of possible values for x\n\n        range for vx is always [-20, 20]\n        \"\"\"\n        self.epsilon = (self.epsilon * 0.99)\n        self.count_episodes += 1\n        return (np.random.uniform(x_range[0],x_range[1]), np.random.uniform(-20,20))\n\n    def act(self, observation):\n        \"\"\"Acts given an observation of the environment.\n\n        Takes as argument an observation of the current state, and\n        returns the chosen action.\n\n        observation = (x, vx)\n        \"\"\"\n\n#        observation_as_list = []\n#        observation_as_list.append(observation[0])\n#        observation_as_list.append(observation[1])\n#        observation_as_list = np.asarray(observation_as_list)\n#        observation_as_list = observation_as_list.reshape(1,2)\n#        observation = observation_as_list\n\n\n        if np.random.rand(1) &lt; self.epsilon:\n            return np.random.uniform(-1,1)\n        else:\n            action = self.policy(observation)\n            return action\n\n    def reward(self, observation, action, reward):\n        \"\"\"Receive a reward for performing given action on\n        given observation.\n\n        This is where your agent can learn.\n        \"\"\"\n        self.count_iter +=1\n        self.policy.rewards.append(reward)\n        self.running_rewards += reward\n        if self.count_iter == 100:\n            # We want first to update the critic agent:\n            self.optimizer.zero_grad()\n            self.loss = self.policy.calculateLoss(self.gamma)\n            self.loss.backward()\n            self.optimizer.step()        \n            self.policy.clearMemory()\n\n            self.count_iter = 0\n\n\nAgent = RandomAgent\n</code></pre>\n\n<p>However, my model does not provide good results. It doesn't even improve with 200 episodes. </p>\n\n<p>Any ideas what is wrong on my code?? Any suggestions?? </p>\n\n<p>Thanks a lot !! </p>\n",
                "tags": "<python><reinforcement-learning><pytorch><actor-critic>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11232",
            "_score": 6.960334,
            "_source": {
                "title": "Keras - Error when using HDF5Matrix to fit the model",
                "content": "Keras - Error when using HDF5Matrix to fit the model <p>So I define my data like this:</p>\n\n<pre><code>x_train = keras.utils.io_utils.HDF5Matrix('dataset.h5', 'x_train')\ny_train = keras.utils.io_utils.HDF5Matrix('dataset.h5', 'y_train')\nx_test = keras.utils.io_utils.HDF5Matrix('dataset.h5', 'x_test')\ny_test = keras.utils.io_utils.HDF5Matrix('dataset.h5', 'y_test')\n</code></pre>\n\n<p>But then when I try to fit the model like this:</p>\n\n<pre><code>model.fit(x_train, y_train, epochs=epochs, \n          validation_data=(x_test, y_test), \n          callbacks=[tensorboard, modelcheckpoint], \n          batch_size=batch_size, shuffle=False)\n</code></pre>\n\n<p>I get this error:  </p>\n\n<pre><code>File \"G:\\CryptoForecast\\cryptomodel.py\", line 34, in train_model\n    model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test), callbacks=[tensorboard, modelcheckpoint], batch_size=batch_size, shuffle=False)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\TradingBot\\lib\\site-packages\\keras\\engine\\training.py\", line 952, in fit\n    batch_size=batch_size)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\TradingBot\\lib\\site-packages\\keras\\engine\\training.py\", line 670, in _standardize_user_data\n    'You passed: x=' + str(x))\nValueError: Please provide as model inputs either a single array or a list of arrays. You passed: x=&lt;keras.utils.io_utils.HDF5Matrix object at 0x000002342575E4E0&gt;\n</code></pre>\n\n<p>But it should be working, no?</p>\n <keras><p>You can see in the <code>fit()</code> method on your <code>Model</code> instance, that the input is first sent through a method called <a href=\"https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L643\" rel=\"nofollow noreferrer\"><code>_standardize_user_data</code> at line 643</a>.</p>\n\n<h3>Source of error</h3>\n\n<p>Your error message comes from the checks that happen across <a href=\"https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L650\" rel=\"nofollow noreferrer\">lines 650</a> to 671 in that file:</p>\n\n<pre><code>if not self.built:\n    # We need to use `x` to set the model inputs.\n    # We type-check that `x` and `y` are either single arrays\n    # or lists of arrays.\n    if isinstance(x, (list, tuple)):\n        if not all(isinstance(v, np.ndarray) or\n                   K.is_tensor(v) for v in x):\n            raise ValueError('Please provide as model inputs '\n                             'either a single '\n                             'array or a list of arrays. '\n                             'You passed: x=' + str(x))\n        all_inputs += list(x)\n    elif isinstance(x, dict):\n        raise ValueError('Please do not pass a dictionary '\n                         'as model inputs.')\n    else:\n        if not isinstance(x, np.ndarray) and not K.is_tensor(x):\n            raise ValueError('Please provide as model inputs '\n                             'either a single '\n                             'array or a list of arrays. '\n                             'You passed: x=' + str(x))\n        all_inputs.append(x)\n</code></pre>\n\n<p>They use <code>isinstance()</code> to check the type, and your HDF5 type is not covered anywhere.</p>\n\n<h2>Possible hack</h2>\n\n<p>I linked you GitHub issue as a comment on your post. Hpowever...</p>\n\n<p>You could alter the code above in your local version of Keras to cover your case, essentially converting the received input into a NumPy array, which would then pass then checks and be used.</p>\n\n<p>I would probably just enter a second <code>elif</code> to the conditions above, like this:</p>\n\n<pre><code>elif isinstance(x, dict):\n    raise ValueError('Please do not pass a dictionary '\n                     'as model inputs.')                   # original code\n\n#### add this snippet #############    \nelif isinstance(x, h5py._hl.dataset.Dataset):\n    x = np.array(x)      # you might need to find a more elegant way of converting the HDF5 block to a numpy array\n###################################\n\nelse:\n    if not isinstance(x, np.ndarray) and not K.is_tensor(x):   # original code\n</code></pre>\n\n<p>You can confirm that the correct type of data for you is that <code>h5py._hl.dataset.Dataset</code> by checking the output of <code>type(keras.utils.io_utils.HDF5Matrix('dataset.h5', 'x_train'))</code>.</p>\n\n<p>This should get things working, although it might cost you some of the other benefits of the HDF5 loading system, such as specifying <code>start</code> and <code>end</code> indices.</p>\n\n<h2>Testing</h2>\n\n<p>Just an example to show how the above transformation should really end up with your data being fed to the model as a numpy array:</p>\n\n<pre><code>import numpy as np\nimport keras\n\na = np.arange(0, 75).reshape((5, 5, 3))    # like a 5x5 RGB image\nf = h5py.File('tester.h5', 'w') \nf.create_dataset(name='a', data=a)                                     \n  # output:  &lt;HDF5 dataset \"a\": shape (5, 5), type \"&lt;i8\"&gt;\nf.close()\n\n# Later on ...\n\ndata = h5py.File('trial.h5', 'r')\ndata = np.array(data['a'])\n\nnp.array_equal(data, a)\n  # True\n</code></pre>\n\n<hr>\n\n<p>Given <a href=\"https://keras.io/utils/#hdf5matrix\" rel=\"nofollow noreferrer\">the documentation</a> on the the HDF5 utility:</p>\n\n<blockquote>\n  <p><code>keras.utils.HDF5Matrix(datapath, dataset, start=0, end=None, normalizer=None)</code>\n  Representation of HDF5 dataset to be used instead of a Numpy array.</p>\n</blockquote>\n\n<p>it does feel like there is a bug, or at least a discrepancy between the documentation and the code.</p>\n\n<h2>EDIT</h2>\n\n<p>You can fit via custom generator that would load blocks from your HDF5Matrix.</p>\n\n<pre><code>def generate_arrays_from_file(path):\n    while True:\n        with h5py.File(path) as f:\n\n            for batch in f:\n                # read the data and reshape as necessary\n                trainX, trainY, testX, testY = split_batch(batch)\n                yield (trainX, trainY)\n\nmodel.fit_generator(generate_arrays_from_file('dataset.h5'),\n                    steps_per_epoch=100, epochs=10)\n</code></pre>\n\n<p>You will have to obviously write a generator function yourself that matches you exact h5 format. Perhaps have a look at the <a href=\"http://docs.h5py.org/en/latest/high/dataset.html#fancy-indexing\" rel=\"nofollow noreferrer\"><em>fancy indexing</em></a> options of h5 files.</p>\n<p>This <a href=\"https://github.com/keras-team/keras/issues/628\" rel=\"nofollow noreferrer\">might be a bug</a> in Keras. However, you might have some luck if the \"validation_split\" parameter is set to 0.001 as mentioned on the corresponding Github page.</p>\n",
                "codes": [
                    [
                        "if not self.built:\n    # We need to use `x` to set the model inputs.\n    # We type-check that `x` and `y` are either single arrays\n    # or lists of arrays.\n    if isinstance(x, (list, tuple)):\n        if not all(isinstance(v, np.ndarray) or\n                   K.is_tensor(v) for v in x):\n            raise ValueError('Please provide as model inputs '\n                             'either a single '\n                             'array or a list of arrays. '\n                             'You passed: x=' + str(x))\n        all_inputs += list(x)\n    elif isinstance(x, dict):\n        raise ValueError('Please do not pass a dictionary '\n                         'as model inputs.')\n    else:\n        if not isinstance(x, np.ndarray) and not K.is_tensor(x):\n            raise ValueError('Please provide as model inputs '\n                             'either a single '\n                             'array or a list of arrays. '\n                             'You passed: x=' + str(x))\n        all_inputs.append(x)\n",
                        "elif isinstance(x, dict):\n    raise ValueError('Please do not pass a dictionary '\n                     'as model inputs.')                   # original code\n\n#### add this snippet #############    \nelif isinstance(x, h5py._hl.dataset.Dataset):\n    x = np.array(x)      # you might need to find a more elegant way of converting the HDF5 block to a numpy array\n###################################\n\nelse:\n    if not isinstance(x, np.ndarray) and not K.is_tensor(x):   # original code\n",
                        "import numpy as np\nimport keras\n\na = np.arange(0, 75).reshape((5, 5, 3))    # like a 5x5 RGB image\nf = h5py.File('tester.h5', 'w') \nf.create_dataset(name='a', data=a)                                     \n  # output:  <HDF5 dataset \"a\": shape (5, 5), type \"<i8\">\nf.close()\n\n# Later on ...\n\ndata = h5py.File('trial.h5', 'r')\ndata = np.array(data['a'])\n\nnp.array_equal(data, a)\n  # True\n",
                        "def generate_arrays_from_file(path):\n    while True:\n        with h5py.File(path) as f:\n\n            for batch in f:\n                # read the data and reshape as necessary\n                trainX, trainY, testX, testY = split_batch(batch)\n                yield (trainX, trainY)\n\nmodel.fit_generator(generate_arrays_from_file('dataset.h5'),\n                    steps_per_epoch=100, epochs=10)\n"
                    ],
                    []
                ],
                "question_id:": "39626",
                "question_votes:": "2",
                "question_text:": "<p>So I define my data like this:</p>\n\n<pre><code>x_train = keras.utils.io_utils.HDF5Matrix('dataset.h5', 'x_train')\ny_train = keras.utils.io_utils.HDF5Matrix('dataset.h5', 'y_train')\nx_test = keras.utils.io_utils.HDF5Matrix('dataset.h5', 'x_test')\ny_test = keras.utils.io_utils.HDF5Matrix('dataset.h5', 'y_test')\n</code></pre>\n\n<p>But then when I try to fit the model like this:</p>\n\n<pre><code>model.fit(x_train, y_train, epochs=epochs, \n          validation_data=(x_test, y_test), \n          callbacks=[tensorboard, modelcheckpoint], \n          batch_size=batch_size, shuffle=False)\n</code></pre>\n\n<p>I get this error:  </p>\n\n<pre><code>File \"G:\\CryptoForecast\\cryptomodel.py\", line 34, in train_model\n    model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test), callbacks=[tensorboard, modelcheckpoint], batch_size=batch_size, shuffle=False)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\TradingBot\\lib\\site-packages\\keras\\engine\\training.py\", line 952, in fit\n    batch_size=batch_size)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\TradingBot\\lib\\site-packages\\keras\\engine\\training.py\", line 670, in _standardize_user_data\n    'You passed: x=' + str(x))\nValueError: Please provide as model inputs either a single array or a list of arrays. You passed: x=&lt;keras.utils.io_utils.HDF5Matrix object at 0x000002342575E4E0&gt;\n</code></pre>\n\n<p>But it should be working, no?</p>\n",
                "tags": "<keras>",
                "answers": [
                    [
                        "39770",
                        "2",
                        "39626",
                        "",
                        "",
                        "<p>You can see in the <code>fit()</code> method on your <code>Model</code> instance, that the input is first sent through a method called <a href=\"https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L643\" rel=\"nofollow noreferrer\"><code>_standardize_user_data</code> at line 643</a>.</p>\n\n<h3>Source of error</h3>\n\n<p>Your error message comes from the checks that happen across <a href=\"https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L650\" rel=\"nofollow noreferrer\">lines 650</a> to 671 in that file:</p>\n\n<pre><code>if not self.built:\n    # We need to use `x` to set the model inputs.\n    # We type-check that `x` and `y` are either single arrays\n    # or lists of arrays.\n    if isinstance(x, (list, tuple)):\n        if not all(isinstance(v, np.ndarray) or\n                   K.is_tensor(v) for v in x):\n            raise ValueError('Please provide as model inputs '\n                             'either a single '\n                             'array or a list of arrays. '\n                             'You passed: x=' + str(x))\n        all_inputs += list(x)\n    elif isinstance(x, dict):\n        raise ValueError('Please do not pass a dictionary '\n                         'as model inputs.')\n    else:\n        if not isinstance(x, np.ndarray) and not K.is_tensor(x):\n            raise ValueError('Please provide as model inputs '\n                             'either a single '\n                             'array or a list of arrays. '\n                             'You passed: x=' + str(x))\n        all_inputs.append(x)\n</code></pre>\n\n<p>They use <code>isinstance()</code> to check the type, and your HDF5 type is not covered anywhere.</p>\n\n<h2>Possible hack</h2>\n\n<p>I linked you GitHub issue as a comment on your post. Hpowever...</p>\n\n<p>You could alter the code above in your local version of Keras to cover your case, essentially converting the received input into a NumPy array, which would then pass then checks and be used.</p>\n\n<p>I would probably just enter a second <code>elif</code> to the conditions above, like this:</p>\n\n<pre><code>elif isinstance(x, dict):\n    raise ValueError('Please do not pass a dictionary '\n                     'as model inputs.')                   # original code\n\n#### add this snippet #############    \nelif isinstance(x, h5py._hl.dataset.Dataset):\n    x = np.array(x)      # you might need to find a more elegant way of converting the HDF5 block to a numpy array\n###################################\n\nelse:\n    if not isinstance(x, np.ndarray) and not K.is_tensor(x):   # original code\n</code></pre>\n\n<p>You can confirm that the correct type of data for you is that <code>h5py._hl.dataset.Dataset</code> by checking the output of <code>type(keras.utils.io_utils.HDF5Matrix('dataset.h5', 'x_train'))</code>.</p>\n\n<p>This should get things working, although it might cost you some of the other benefits of the HDF5 loading system, such as specifying <code>start</code> and <code>end</code> indices.</p>\n\n<h2>Testing</h2>\n\n<p>Just an example to show how the above transformation should really end up with your data being fed to the model as a numpy array:</p>\n\n<pre><code>import numpy as np\nimport keras\n\na = np.arange(0, 75).reshape((5, 5, 3))    # like a 5x5 RGB image\nf = h5py.File('tester.h5', 'w') \nf.create_dataset(name='a', data=a)                                     \n  # output:  &lt;HDF5 dataset \"a\": shape (5, 5), type \"&lt;i8\"&gt;\nf.close()\n\n# Later on ...\n\ndata = h5py.File('trial.h5', 'r')\ndata = np.array(data['a'])\n\nnp.array_equal(data, a)\n  # True\n</code></pre>\n\n<hr>\n\n<p>Given <a href=\"https://keras.io/utils/#hdf5matrix\" rel=\"nofollow noreferrer\">the documentation</a> on the the HDF5 utility:</p>\n\n<blockquote>\n  <p><code>keras.utils.HDF5Matrix(datapath, dataset, start=0, end=None, normalizer=None)</code>\n  Representation of HDF5 dataset to be used instead of a Numpy array.</p>\n</blockquote>\n\n<p>it does feel like there is a bug, or at least a discrepancy between the documentation and the code.</p>\n\n<h2>EDIT</h2>\n\n<p>You can fit via custom generator that would load blocks from your HDF5Matrix.</p>\n\n<pre><code>def generate_arrays_from_file(path):\n    while True:\n        with h5py.File(path) as f:\n\n            for batch in f:\n                # read the data and reshape as necessary\n                trainX, trainY, testX, testY = split_batch(batch)\n                yield (trainX, trainY)\n\nmodel.fit_generator(generate_arrays_from_file('dataset.h5'),\n                    steps_per_epoch=100, epochs=10)\n</code></pre>\n\n<p>You will have to obviously write a generator function yourself that matches you exact h5 format. Perhaps have a look at the <a href=\"http://docs.h5py.org/en/latest/high/dataset.html#fancy-indexing\" rel=\"nofollow noreferrer\"><em>fancy indexing</em></a> options of h5 files.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "39757",
                        "2",
                        "39626",
                        "",
                        "",
                        "<p>This <a href=\"https://github.com/keras-team/keras/issues/628\" rel=\"nofollow noreferrer\">might be a bug</a> in Keras. However, you might have some luck if the \"validation_split\" parameter is set to 0.001 as mentioned on the corresponding Github page.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9504",
            "_score": 6.946992,
            "_source": {
                "title": "Tflearn \"nan\" weight matrices",
                "content": "Tflearn \"nan\" weight matrices <p>I wanted to build a DQN. So I followed this <a href=\"https://github.com/llSourcell/deep_q_learning/blob/master/03_PlayingAgent.ipynb\" rel=\"nofollow noreferrer\">code</a> and watched some videos about the idea of DQN. My Code is this (mine is written in tflearn and his in keras):</p>\n\n<pre><code>import tflearn as tfl\nimport numpy as np\nimport gym\nfrom collections import deque\nimport random\n\nclass DeepQ():\ndef __init__(self,game=\"SpaceInvaders-v0\"):\n    self.game=game\n    self.env=gym.make(game)\n    self.storage=deque()\n    self.filter_size=[4,4]\n    self.itertime=1000\n    self.random_move_prop=0.8\n    np.random.seed(1)\n    self.minibatch_size=250\n    self.discounted_future_reward=0.9\n\ndef Q_Network(self,learning_rate=0.0000001,load=False,model_path=None,checkpoint_path=\"X://xxx//xxx//Documents//GitHub//Deeplearning_for_starters//Atari_modells//checkpoint.ckpt\"):\n\n    if load==False:\n        net=tfl.layers.core.input_data(shape=[None,210,160,3])# rework this stuff\n        net=tfl.layers.conv.conv_2d(net,nb_filter=3,filter_size=self.filter_size,activation='relu')\n        net=tfl.layers.conv.conv_2d(net,nb_filter=3,filter_size=self.filter_size,activation=\"relu\")\n        #net=tfl.layers.fully_connected(net,20,activation=\"relu\")\n        net=tfl.layers.flatten(net)\n        #net=tfl.layers.fully_connected(net,18,activation=\"relu\")\n        net=tfl.layers.fully_connected(net,10,activation='relu')\n        net=tfl.layers.fully_connected(net,self.env.action_space.n,activation=\"linear\")\n        net=tfl.layers.estimator.regression(net,learning_rate=learning_rate)\n        self.modell=tfl.DNN(net,checkpoint_path=checkpoint_path)\n    else:\n        net=tfl.layers.core.input_data(shape=[None,210,160,3])\n        net=tfl.layers.conv.conv_2d(net,nb_filter=3,filter_size=self.filter_size,activation='relu')\n        net=tfl.layers.conv.conv_2d(net,nb_filter=3,filter_size=self.filter_size,activation=\"relu\")\n        #net=tfl.layers.fully_connected(net,20,activation=\"relu\")\n        net=tfl.layers.flatten(net)\n        #net=tfl.layers.fully_connected(net,18,activation=\"relu\")\n        net=tfl.layers.fully_connected(net,10,activation='relu')\n        net=tfl.layers.fully_connected(net,self.env.action_space.n,activation=\"linear\")\n        net=tfl.layers.estimator.regression(net,learning_rate=learning_rate)\n        self.modell=tfl.DNN(net)\n        self.modell.load(model_path,weights_only=True)\ndef Q_Learning(self):\n    observation=self.env.reset()\n    for i in range(self.itertime):\n        #self.env.render()\n        observation=observation.reshape(1,210,160,3) \n        if np.random.rand()&lt;=self.random_move_prop: \n            #print(\"Random step\")\n            action=np.random.randint(low=0,high=self.env.action_space.n) \n        else:\n            #print(\"Random prediction\") #for debugging usefull\n            action=self.modell.predict(observation)\n            action=np.argmax(action)\n        new_observation, reward, done, info=self.env.step(action)\n        self.storage.append((observation,action,reward,new_observation,done))\n        observation=new_observation\n        if done:\n            self.env.reset()\n    print(\"###############################################\")\n    print(\"Done with observing!\")\n    print(\"###############################################\")\n    minibatch=random.sample(self.storage,self.minibatch_size)# take random observations from our data\n    x=np.zeros((self.minibatch_size,)+observation.shape)\n    y=np.zeros((self.minibatch_size,self.env.action_space.n))\n    for i in range(0,self.minibatch_size):\n        Observation=minibatch[i][0]\n        Action=minibatch[i][1]\n        Reward=minibatch[i][2]\n        New_observation=minibatch[i][3]\n        done=minibatch[i][4]\n        print(\"Processing batch data... (step:\"+str(i)+\" from \"+str(self.minibatch_size)+\")\")\n        x[i:i+1]=Observation.reshape((1,)+observation.shape)\n        y[i]=self.modell.predict(Observation)\n        Q_sa=self.modell.predict(Observation)\n        if done:\n            y[i,action]=reward\n        else:\n            y[i,action]=reward+self.discounted_future_reward*np.max(Q_sa)\n        self.modell.fit_batch(x,y)\n    self.modell.save(\"X://xxx//xxx//xxx//SpaceInvaders1.tfl\")\n    print(\"\")\n    print(\"Modell fitting acomplished!\")\n    print(\"\")\ndef Q_predict(self,model_path=\"Your path here\"):\n    self.Q_Network(load=True,model_path=model_path)\n    observation=self.env.reset()\n    observation=observation.reshape((1,)+observation.shape)\n    done=False\n    total_reward=0.0\n    while not done:\n        self.env.render()\n        Q=self.modell.predict(observation)\n        print(Q)\n        action=np.argmax(Q)\n        print(action)\n        new_observation,reward,done,info=self.env.step(action)\n        observation=new_observation\n        observation=new_observation.reshape((1,)+observation.shape)\n        total_reward+=reward\n    print(\"Game ends with a score of: \"+str(total_reward))\n    print(\"\")\n</code></pre>\n\n<p>The problem is that, if I run the predict function the network does nothing.\nI figured out that <strong>all weights</strong> are filled with <code>nan</code>. What I have read is that it can depend on the learning rate, so I have lowered the rate from <code>1e-3</code> to the actual one, but this changed nothing.</p>\n <reinforcement-learning><python><q-learning><p>So, I figured it out. The problem was the loss function.\nI found a similar problem <a href=\"https://stackoverflow.com/questions/33712178/tensorflow-nan-bug#33713196\">here</a>. So because I am a noob in tflearn and I have no idea, if you can change the loss function to a custom one (I guess you can). I used <code>mean_squared</code> (Mean Squared Error) instead. This fixed my problem. I would appreciate if someone could explain the problem, so I can better understand it.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "33836",
                "question_votes:": "1",
                "question_text:": "<p>I wanted to build a DQN. So I followed this <a href=\"https://github.com/llSourcell/deep_q_learning/blob/master/03_PlayingAgent.ipynb\" rel=\"nofollow noreferrer\">code</a> and watched some videos about the idea of DQN. My Code is this (mine is written in tflearn and his in keras):</p>\n\n<pre><code>import tflearn as tfl\nimport numpy as np\nimport gym\nfrom collections import deque\nimport random\n\nclass DeepQ():\ndef __init__(self,game=\"SpaceInvaders-v0\"):\n    self.game=game\n    self.env=gym.make(game)\n    self.storage=deque()\n    self.filter_size=[4,4]\n    self.itertime=1000\n    self.random_move_prop=0.8\n    np.random.seed(1)\n    self.minibatch_size=250\n    self.discounted_future_reward=0.9\n\ndef Q_Network(self,learning_rate=0.0000001,load=False,model_path=None,checkpoint_path=\"X://xxx//xxx//Documents//GitHub//Deeplearning_for_starters//Atari_modells//checkpoint.ckpt\"):\n\n    if load==False:\n        net=tfl.layers.core.input_data(shape=[None,210,160,3])# rework this stuff\n        net=tfl.layers.conv.conv_2d(net,nb_filter=3,filter_size=self.filter_size,activation='relu')\n        net=tfl.layers.conv.conv_2d(net,nb_filter=3,filter_size=self.filter_size,activation=\"relu\")\n        #net=tfl.layers.fully_connected(net,20,activation=\"relu\")\n        net=tfl.layers.flatten(net)\n        #net=tfl.layers.fully_connected(net,18,activation=\"relu\")\n        net=tfl.layers.fully_connected(net,10,activation='relu')\n        net=tfl.layers.fully_connected(net,self.env.action_space.n,activation=\"linear\")\n        net=tfl.layers.estimator.regression(net,learning_rate=learning_rate)\n        self.modell=tfl.DNN(net,checkpoint_path=checkpoint_path)\n    else:\n        net=tfl.layers.core.input_data(shape=[None,210,160,3])\n        net=tfl.layers.conv.conv_2d(net,nb_filter=3,filter_size=self.filter_size,activation='relu')\n        net=tfl.layers.conv.conv_2d(net,nb_filter=3,filter_size=self.filter_size,activation=\"relu\")\n        #net=tfl.layers.fully_connected(net,20,activation=\"relu\")\n        net=tfl.layers.flatten(net)\n        #net=tfl.layers.fully_connected(net,18,activation=\"relu\")\n        net=tfl.layers.fully_connected(net,10,activation='relu')\n        net=tfl.layers.fully_connected(net,self.env.action_space.n,activation=\"linear\")\n        net=tfl.layers.estimator.regression(net,learning_rate=learning_rate)\n        self.modell=tfl.DNN(net)\n        self.modell.load(model_path,weights_only=True)\ndef Q_Learning(self):\n    observation=self.env.reset()\n    for i in range(self.itertime):\n        #self.env.render()\n        observation=observation.reshape(1,210,160,3) \n        if np.random.rand()&lt;=self.random_move_prop: \n            #print(\"Random step\")\n            action=np.random.randint(low=0,high=self.env.action_space.n) \n        else:\n            #print(\"Random prediction\") #for debugging usefull\n            action=self.modell.predict(observation)\n            action=np.argmax(action)\n        new_observation, reward, done, info=self.env.step(action)\n        self.storage.append((observation,action,reward,new_observation,done))\n        observation=new_observation\n        if done:\n            self.env.reset()\n    print(\"###############################################\")\n    print(\"Done with observing!\")\n    print(\"###############################################\")\n    minibatch=random.sample(self.storage,self.minibatch_size)# take random observations from our data\n    x=np.zeros((self.minibatch_size,)+observation.shape)\n    y=np.zeros((self.minibatch_size,self.env.action_space.n))\n    for i in range(0,self.minibatch_size):\n        Observation=minibatch[i][0]\n        Action=minibatch[i][1]\n        Reward=minibatch[i][2]\n        New_observation=minibatch[i][3]\n        done=minibatch[i][4]\n        print(\"Processing batch data... (step:\"+str(i)+\" from \"+str(self.minibatch_size)+\")\")\n        x[i:i+1]=Observation.reshape((1,)+observation.shape)\n        y[i]=self.modell.predict(Observation)\n        Q_sa=self.modell.predict(Observation)\n        if done:\n            y[i,action]=reward\n        else:\n            y[i,action]=reward+self.discounted_future_reward*np.max(Q_sa)\n        self.modell.fit_batch(x,y)\n    self.modell.save(\"X://xxx//xxx//xxx//SpaceInvaders1.tfl\")\n    print(\"\")\n    print(\"Modell fitting acomplished!\")\n    print(\"\")\ndef Q_predict(self,model_path=\"Your path here\"):\n    self.Q_Network(load=True,model_path=model_path)\n    observation=self.env.reset()\n    observation=observation.reshape((1,)+observation.shape)\n    done=False\n    total_reward=0.0\n    while not done:\n        self.env.render()\n        Q=self.modell.predict(observation)\n        print(Q)\n        action=np.argmax(Q)\n        print(action)\n        new_observation,reward,done,info=self.env.step(action)\n        observation=new_observation\n        observation=new_observation.reshape((1,)+observation.shape)\n        total_reward+=reward\n    print(\"Game ends with a score of: \"+str(total_reward))\n    print(\"\")\n</code></pre>\n\n<p>The problem is that, if I run the predict function the network does nothing.\nI figured out that <strong>all weights</strong> are filled with <code>nan</code>. What I have read is that it can depend on the learning rate, so I have lowered the rate from <code>1e-3</code> to the actual one, but this changed nothing.</p>\n",
                "tags": "<reinforcement-learning><python><q-learning>",
                "answers": [
                    [
                        "33852",
                        "2",
                        "33836",
                        "",
                        "",
                        "<p>So, I figured it out. The problem was the loss function.\nI found a similar problem <a href=\"https://stackoverflow.com/questions/33712178/tensorflow-nan-bug#33713196\">here</a>. So because I am a noob in tflearn and I have no idea, if you can change the loss function to a custom one (I guess you can). I used <code>mean_squared</code> (Mean Squared Error) instead. This fixed my problem. I would appreciate if someone could explain the problem, so I can better understand it.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10117",
            "_score": 6.9003825,
            "_source": {
                "title": "How to show progress of sklearn.multioutput.MultiOutputRegressor and XGBRegressor?",
                "content": "How to show progress of sklearn.multioutput.MultiOutputRegressor and XGBRegressor? <p>Is it possible to show the training progress of the MultiOutputRegressor in sklearn? When a huge dataset is processed, my program runs a long time and I have no clue how long it will take. I have shortened my program to a minimal working example below. </p>\n\n<pre><code>import numpy as np\nfrom sklearn.multioutput import MultiOutputRegressor\nimport xgboost as xgb\n\ndf = np.arange(50).reshape(10,5)\ntrain = df[:8]\ntest = df[8:]\nX_train = train[:,0:-2]\nX_test  = test[:,0:-2]\ny_train = train[:,-2:]\ny_test  = test[:,-2:] \n\neval_set = [(X_test, y_test)]\nmultioutputregressor = MultiOutputRegressor(xgb.XGBRegressor(eval_set=eval_set, verbose_eval=True))\nmultioutputregressor.fit(X_train, y_train)\npredictions = multioutputregressor.predict(X_test)\nprint(predictions)\n</code></pre>\n <scikit-learn><xgboost><p>You can consider modifying the code of <a href=\"https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/multioutput.py\" rel=\"nofollow noreferrer\">MultiOutputEstimator</a> or <a href=\"https://github.com/dmlc/xgboost/blob/master/python-package/xgboost/sklearn.py\" rel=\"nofollow noreferrer\">XGBModel</a> to introduce some debugging output. These seem to be the classes that implement the fitting logic of the two libraries. The corresponding source files should also be provided in the installations on your local hard drive.</p>\n\n<p>For example, you can print information of when the separate threads are starting and stopping in <code>MultiOutputEstimator.fit</code> (inherited and thus reused in <code>MultiOutputRegressor</code>), lines 167-169. Also, consider the tip in the documentation of the <code>n_jobs</code> parameter:</p>\n\n<pre><code>If 1 is given, no parallel computing code is used at all, which is useful for debugging.\n</code></pre>\n\n<p>You can use a similar approach to expand the debugging in <code>XGBModel.fit</code> (the basis of <code>XGBRegressor</code>).</p>\n",
                "codes": [
                    [
                        "If 1 is given, no parallel computing code is used at all, which is useful for debugging.\n"
                    ]
                ],
                "question_id:": "36652",
                "question_votes:": "",
                "question_text:": "<p>Is it possible to show the training progress of the MultiOutputRegressor in sklearn? When a huge dataset is processed, my program runs a long time and I have no clue how long it will take. I have shortened my program to a minimal working example below. </p>\n\n<pre><code>import numpy as np\nfrom sklearn.multioutput import MultiOutputRegressor\nimport xgboost as xgb\n\ndf = np.arange(50).reshape(10,5)\ntrain = df[:8]\ntest = df[8:]\nX_train = train[:,0:-2]\nX_test  = test[:,0:-2]\ny_train = train[:,-2:]\ny_test  = test[:,-2:] \n\neval_set = [(X_test, y_test)]\nmultioutputregressor = MultiOutputRegressor(xgb.XGBRegressor(eval_set=eval_set, verbose_eval=True))\nmultioutputregressor.fit(X_train, y_train)\npredictions = multioutputregressor.predict(X_test)\nprint(predictions)\n</code></pre>\n",
                "tags": "<scikit-learn><xgboost>",
                "answers": [
                    [
                        "36740",
                        "2",
                        "36652",
                        "",
                        "",
                        "<p>You can consider modifying the code of <a href=\"https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/multioutput.py\" rel=\"nofollow noreferrer\">MultiOutputEstimator</a> or <a href=\"https://github.com/dmlc/xgboost/blob/master/python-package/xgboost/sklearn.py\" rel=\"nofollow noreferrer\">XGBModel</a> to introduce some debugging output. These seem to be the classes that implement the fitting logic of the two libraries. The corresponding source files should also be provided in the installations on your local hard drive.</p>\n\n<p>For example, you can print information of when the separate threads are starting and stopping in <code>MultiOutputEstimator.fit</code> (inherited and thus reused in <code>MultiOutputRegressor</code>), lines 167-169. Also, consider the tip in the documentation of the <code>n_jobs</code> parameter:</p>\n\n<pre><code>If 1 is given, no parallel computing code is used at all, which is useful for debugging.\n</code></pre>\n\n<p>You can use a similar approach to expand the debugging in <code>XGBModel.fit</code> (the basis of <code>XGBRegressor</code>).</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13757",
            "_score": 6.9003825,
            "_source": {
                "title": "Why does not log transformation make the data normalized?",
                "content": "Why does not log transformation make the data normalized? <p>Having some skewed features as shown in the following figure. I am trying to imply log transformation to the feature called <code>vBMD(mgHA/cm3)</code>. I run the following codes</p>\n\n<p><a href=\"https://i.stack.imgur.com/PMFM0.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PMFM0.jpg\" alt=\"Distribution Plots\"></a></p>\n\n<blockquote>\n  <p>import numpy as np</p>\n  \n  <p>import pandas as pd</p>\n  \n  <p>from sklearn.preprocessing import MinMaxScaler</p>\n  \n  <p>df=pd.read_csv(\"Data.csv\")</p>\n  \n  <p>scaler=MinMaxScaler(feature_range=(0,1))</p>\n  \n  <p>df['vBMD (mgHA/cm3)']=scaler.fit_transform(np.array(df['vBMD\n  (mgHA/cm3)']).reshape(-1,1))</p>\n  \n  <p>df['vBMD (mgHA/cm3)']=np.log(np.array(df['vBMD (mgHA/cm3)']))</p>\n</blockquote>\n\n<p>After the transfromation, I have got the following result.\n<a href=\"https://i.stack.imgur.com/rTUG3.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/rTUG3.png\" alt=\"After transformation\"></a></p>\n\n<p>While I am waiting that the feature will be normalized, its skewness increased. Thus, what am I doing wrong?</p>\n <python><preprocessing><p>Log transformation leads to a normal distribution only for <a href=\"https://en.wikipedia.org/wiki/Log-normal_distribution\" rel=\"nofollow noreferrer\">log-normal distributions</a>. Not all distributions are log-normal, meaning they will not become normal after the log transformation.</p>\n\n<p><strong>EDIT:</strong></p>\n\n<p>As you have commented, if you are trying to convert an <em>arbitrary</em> distribution to normal, methods like <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html\" rel=\"nofollow noreferrer\">QuantileTransformer</a> can be used. But note that these transformations make a distribution normal by changing (destroying) some information from the original data.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "46763",
                "question_votes:": "2",
                "question_text:": "<p>Having some skewed features as shown in the following figure. I am trying to imply log transformation to the feature called <code>vBMD(mgHA/cm3)</code>. I run the following codes</p>\n\n<p><a href=\"https://i.stack.imgur.com/PMFM0.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PMFM0.jpg\" alt=\"Distribution Plots\"></a></p>\n\n<blockquote>\n  <p>import numpy as np</p>\n  \n  <p>import pandas as pd</p>\n  \n  <p>from sklearn.preprocessing import MinMaxScaler</p>\n  \n  <p>df=pd.read_csv(\"Data.csv\")</p>\n  \n  <p>scaler=MinMaxScaler(feature_range=(0,1))</p>\n  \n  <p>df['vBMD (mgHA/cm3)']=scaler.fit_transform(np.array(df['vBMD\n  (mgHA/cm3)']).reshape(-1,1))</p>\n  \n  <p>df['vBMD (mgHA/cm3)']=np.log(np.array(df['vBMD (mgHA/cm3)']))</p>\n</blockquote>\n\n<p>After the transfromation, I have got the following result.\n<a href=\"https://i.stack.imgur.com/rTUG3.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/rTUG3.png\" alt=\"After transformation\"></a></p>\n\n<p>While I am waiting that the feature will be normalized, its skewness increased. Thus, what am I doing wrong?</p>\n",
                "tags": "<python><preprocessing>",
                "answers": [
                    [
                        "46773",
                        "2",
                        "46763",
                        "",
                        "",
                        "<p>Log transformation leads to a normal distribution only for <a href=\"https://en.wikipedia.org/wiki/Log-normal_distribution\" rel=\"nofollow noreferrer\">log-normal distributions</a>. Not all distributions are log-normal, meaning they will not become normal after the log transformation.</p>\n\n<p><strong>EDIT:</strong></p>\n\n<p>As you have commented, if you are trying to convert an <em>arbitrary</em> distribution to normal, methods like <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html\" rel=\"nofollow noreferrer\">QuantileTransformer</a> can be used. But note that these transformations make a distribution normal by changing (destroying) some information from the original data.</p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14336",
            "_score": 6.9003825,
            "_source": {
                "title": "Why is the reported loss different from the mean squared error calculated on the train data?",
                "content": "Why is the reported loss different from the mean squared error calculated on the train data? <p>Why the loss in this code is not equal to the mean squared error in the training data?\nIt should be equal because I set alpha =0 , therefore there is no regularization. </p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import mean_squared_error\n\n\n#\ni = 1 #difficult index\n\nX_train = np.arange(-2,2,0.1/i).reshape(-1,1)\ny_train = 1+ np.sin(i*np.pi*X_train/4)\n\nfig = plt.figure(figsize=(8,8))\nax = fig.add_axes([0,0,1,1])\nax.plot(X_train,y_train,'b*-')\nax.set_xlabel('X_train')\nax.set_ylabel('y_train')\nax.set_title('Function')\nnn = MLPRegressor(\n    hidden_layer_sizes=(1,),  activation='tanh', solver='sgd', alpha=0.000, batch_size='auto',\n    learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n    random_state=0, tol=0.0001, verbose=True, warm_start=False, momentum=0.0, nesterovs_momentum=False,\n    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n\nnn = nn.fit(X_train, y_train)\n\npredict_train=nn.predict(X_train)\n\n\n\nprint('MSE training : {:.3f}'.format(mean_squared_error(y_train, predict_train)))\n\n</code></pre>\n\n<p>When I ran this code I found loss = 0.02061828 and the MSE in the training (MSE training) = 0.041</p>\n <keras><scikit-learn><mlp><p>That's because the square loss is defined as 0.5*MSE. </p>\n\n<p>See definition <a href=\"https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/neural_network/_base.py\" rel=\"nofollow noreferrer\">here</a>:</p>\n\n<p><a href=\"https://i.stack.imgur.com/QBy5S.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/QBy5S.png\" alt=\"enter image description here\"></a></p>\n",
                "codes": [
                    []
                ],
                "question_id:": "48279",
                "question_votes:": "",
                "question_text:": "<p>Why the loss in this code is not equal to the mean squared error in the training data?\nIt should be equal because I set alpha =0 , therefore there is no regularization. </p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import mean_squared_error\n\n\n#\ni = 1 #difficult index\n\nX_train = np.arange(-2,2,0.1/i).reshape(-1,1)\ny_train = 1+ np.sin(i*np.pi*X_train/4)\n\nfig = plt.figure(figsize=(8,8))\nax = fig.add_axes([0,0,1,1])\nax.plot(X_train,y_train,'b*-')\nax.set_xlabel('X_train')\nax.set_ylabel('y_train')\nax.set_title('Function')\nnn = MLPRegressor(\n    hidden_layer_sizes=(1,),  activation='tanh', solver='sgd', alpha=0.000, batch_size='auto',\n    learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n    random_state=0, tol=0.0001, verbose=True, warm_start=False, momentum=0.0, nesterovs_momentum=False,\n    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n\nnn = nn.fit(X_train, y_train)\n\npredict_train=nn.predict(X_train)\n\n\n\nprint('MSE training : {:.3f}'.format(mean_squared_error(y_train, predict_train)))\n\n</code></pre>\n\n<p>When I ran this code I found loss = 0.02061828 and the MSE in the training (MSE training) = 0.041</p>\n",
                "tags": "<keras><scikit-learn><mlp>",
                "answers": [
                    [
                        "48285",
                        "2",
                        "48279",
                        "",
                        "",
                        "<p>That's because the square loss is defined as 0.5*MSE. </p>\n\n<p>See definition <a href=\"https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/neural_network/_base.py\" rel=\"nofollow noreferrer\">here</a>:</p>\n\n<p><a href=\"https://i.stack.imgur.com/QBy5S.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/QBy5S.png\" alt=\"enter image description here\"></a></p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15064",
            "_score": 6.9003825,
            "_source": {
                "title": "How does SelectKBest order the best features?",
                "content": "How does SelectKBest order the best features? <p>I'm trying to run a quick univariate filtering on some data, using a t-test of independence, since my target is binary. However, when I run the filter using <code>sklearn</code>'s <code>SelectKBest</code>, I get the same top features returned doing  a manual filter, but in different order. The only information about <code>SelectKBest</code> I could find is <a href=\"https://datascience.stackexchange.com/questions/10773/how-does-selectkbest-work\">here</a> and the documentation, but both seem like they should work like my manual method. My code is </p>\n\n<pre><code>import numpy as np\nfrom sklearn.feature_selection import SelectKBest\nfrom scipy.stats import ttest_ind\n\nnp.random.seed(0)\n\ndata = np.random.random((100,50))\ntarget = np.random.randint(2, size = 100).reshape((100,1))\n\nX = data\ny = target.ravel()\n\nk = 10\np_values = []\nfor i in range(data.shape[1]):\n\n    t, p = ttest_ind(data[:,i], target)\n    p_values.append([i,p[0],t[0]])\n\np_values = sorted(p_values, key = lambda x: x[1])\np_values = p_values[:k]\n\n# Indices of the ranked p-values\nidx = [i[0] for i in p_values]\n\n# SelectKBest features\nmdl = SelectKBest(ttest_ind, k = k)\n\nX_new = mdl.fit_transform(X, y)\n# Manually selected k best features\nX_new2=X[:,idx]\n\n\n# Print first row of sklearn features\nprint(X_new[0])\narray([0.4236548 , 0.96366276, 0.38344152, 0.87001215, 0.63992102,\n   0.52184832, 0.41466194, 0.06022547, 0.67063787, 0.31542835])\n\n# Print first row of manually selected features\nprint(X_new2[0])\narray([0.67063787, 0.4236548 , 0.31542835, 0.87001215, 0.38344152,\n   0.63992102, 0.06022547, 0.52184832, 0.41466194, 0.96366276])\n</code></pre>\n\n<p>It seems <code>SelectKBest</code> is not ordering the features based solely on their p-values or their t-values. How does <code>SelectKBest</code> order the features then?</p>\n <python><scikit-learn><feature-selection>",
                "codes": [],
                "question_id:": "51118",
                "question_votes:": "",
                "question_text:": "<p>I'm trying to run a quick univariate filtering on some data, using a t-test of independence, since my target is binary. However, when I run the filter using <code>sklearn</code>'s <code>SelectKBest</code>, I get the same top features returned doing  a manual filter, but in different order. The only information about <code>SelectKBest</code> I could find is <a href=\"https://datascience.stackexchange.com/questions/10773/how-does-selectkbest-work\">here</a> and the documentation, but both seem like they should work like my manual method. My code is </p>\n\n<pre><code>import numpy as np\nfrom sklearn.feature_selection import SelectKBest\nfrom scipy.stats import ttest_ind\n\nnp.random.seed(0)\n\ndata = np.random.random((100,50))\ntarget = np.random.randint(2, size = 100).reshape((100,1))\n\nX = data\ny = target.ravel()\n\nk = 10\np_values = []\nfor i in range(data.shape[1]):\n\n    t, p = ttest_ind(data[:,i], target)\n    p_values.append([i,p[0],t[0]])\n\np_values = sorted(p_values, key = lambda x: x[1])\np_values = p_values[:k]\n\n# Indices of the ranked p-values\nidx = [i[0] for i in p_values]\n\n# SelectKBest features\nmdl = SelectKBest(ttest_ind, k = k)\n\nX_new = mdl.fit_transform(X, y)\n# Manually selected k best features\nX_new2=X[:,idx]\n\n\n# Print first row of sklearn features\nprint(X_new[0])\narray([0.4236548 , 0.96366276, 0.38344152, 0.87001215, 0.63992102,\n   0.52184832, 0.41466194, 0.06022547, 0.67063787, 0.31542835])\n\n# Print first row of manually selected features\nprint(X_new2[0])\narray([0.67063787, 0.4236548 , 0.31542835, 0.87001215, 0.38344152,\n   0.63992102, 0.06022547, 0.52184832, 0.41466194, 0.96366276])\n</code></pre>\n\n<p>It seems <code>SelectKBest</code> is not ordering the features based solely on their p-values or their t-values. How does <code>SelectKBest</code> order the features then?</p>\n",
                "tags": "<python><scikit-learn><feature-selection>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13433",
            "_score": 6.8608923,
            "_source": {
                "title": "Why doesn't loss go down during Neural Net training?",
                "content": "Why doesn't loss go down during Neural Net training? <p>I am working on a <a href=\"https://www.kaggle.com/c/tmdb-box-office-prediction\" rel=\"nofollow noreferrer\">Kaggle competition</a> and have tried 2 different code approaches and have the same issue: the loss is large (18247478709991652.0000) and does not go down or is nan.</p>\n\n<p>I'm not sure if there is something wrong with the code or with the data. I tried both scaled and non-scaled data and got the same results. I tried it with the full data set (3,000 examples) and an abbreviated data set.</p>\n\n<p>Here is the <a href=\"https://pastebin.com/NHsGYjBf\" rel=\"nofollow noreferrer\">abbreviated data</a>.</p>\n\n<pre><code>import numpy\nimport pandas\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\ndataframe = pandas.read_csv('data/tmdb/train_processed.csv')\ndataframe.drop('id', axis=1, inplace=True)\n\nY = dataframe['revenue'].values\ndataframe.drop(columns=['revenue'], inplace=True)\nX = dataframe.values\n\ndef baseline_model():\n  model = Sequential()\n  model.add(Dense(13, input_dim=3, kernel_initializer='normal', activation='relu'))\n  model.add(Dense(1, kernel_initializer='normal'))\n  model.compile(loss='mean_squared_error', optimizer='adam')\n  return model\n\nseed = 7\nnumpy.random.seed(seed)\n\nestimators = []\nestimators.append(('standardize', StandardScaler()))\nestimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=1)))\npipeline = Pipeline(estimators)\nkfold = KFold(n_splits=10, random_state=seed)\nresults = cross_val_score(pipeline, X, Y, cv=kfold)\nprint(\"Result: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n</code></pre>\n <neural-network><keras><tensorflow><p>Your loss does go down, but not significantly. This is because your target values are very large ~10e7 and the default learning rate is scaled for smaller values. The easiest way to fix this is to normalize Y.</p>\n\n<p>If your intention is for your code scale Y, then the problem is that Pipeline does not apply StandardScaler (or any transformations) to Y. You have to use sklearn.compose.TransformedTargetRegressor, or apply the transforms to Y outside of Pipeline.</p>\n\n<p>Pick 1:</p>\n\n<p>Outside the pipeline:<br/>\n<s>Y = dataframe['revenue'].values </s> <br/>\nY = StandardScaler().fit_transform(dataframe['revenue'].values.reshape(-1,1))</p>\n\n<p>Inside the pipeline:<br/>\n<s>estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=1)))\n</s> <br/>\nfrom sklearn.compose import TransformedTargetRegressor <br/>\nestimators.append(('mlp',TransformedTargetRegressor(<br/>\nregressor=KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=1),<br/>transformer=StandardScaler())))</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "45933",
                "question_votes:": "3",
                "question_text:": "<p>I am working on a <a href=\"https://www.kaggle.com/c/tmdb-box-office-prediction\" rel=\"nofollow noreferrer\">Kaggle competition</a> and have tried 2 different code approaches and have the same issue: the loss is large (18247478709991652.0000) and does not go down or is nan.</p>\n\n<p>I'm not sure if there is something wrong with the code or with the data. I tried both scaled and non-scaled data and got the same results. I tried it with the full data set (3,000 examples) and an abbreviated data set.</p>\n\n<p>Here is the <a href=\"https://pastebin.com/NHsGYjBf\" rel=\"nofollow noreferrer\">abbreviated data</a>.</p>\n\n<pre><code>import numpy\nimport pandas\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\ndataframe = pandas.read_csv('data/tmdb/train_processed.csv')\ndataframe.drop('id', axis=1, inplace=True)\n\nY = dataframe['revenue'].values\ndataframe.drop(columns=['revenue'], inplace=True)\nX = dataframe.values\n\ndef baseline_model():\n  model = Sequential()\n  model.add(Dense(13, input_dim=3, kernel_initializer='normal', activation='relu'))\n  model.add(Dense(1, kernel_initializer='normal'))\n  model.compile(loss='mean_squared_error', optimizer='adam')\n  return model\n\nseed = 7\nnumpy.random.seed(seed)\n\nestimators = []\nestimators.append(('standardize', StandardScaler()))\nestimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=1)))\npipeline = Pipeline(estimators)\nkfold = KFold(n_splits=10, random_state=seed)\nresults = cross_val_score(pipeline, X, Y, cv=kfold)\nprint(\"Result: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n</code></pre>\n",
                "tags": "<neural-network><keras><tensorflow>",
                "answers": [
                    [
                        "45935",
                        "2",
                        "45933",
                        "",
                        "",
                        "<p>Your loss does go down, but not significantly. This is because your target values are very large ~10e7 and the default learning rate is scaled for smaller values. The easiest way to fix this is to normalize Y.</p>\n\n<p>If your intention is for your code scale Y, then the problem is that Pipeline does not apply StandardScaler (or any transformations) to Y. You have to use sklearn.compose.TransformedTargetRegressor, or apply the transforms to Y outside of Pipeline.</p>\n\n<p>Pick 1:</p>\n\n<p>Outside the pipeline:<br/>\n<s>Y = dataframe['revenue'].values </s> <br/>\nY = StandardScaler().fit_transform(dataframe['revenue'].values.reshape(-1,1))</p>\n\n<p>Inside the pipeline:<br/>\n<s>estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=1)))\n</s> <br/>\nfrom sklearn.compose import TransformedTargetRegressor <br/>\nestimators.append(('mlp',TransformedTargetRegressor(<br/>\nregressor=KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=1),<br/>transformer=StandardScaler())))</p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15177",
            "_score": 6.8608923,
            "_source": {
                "title": "Simple linear regression in PyTorch",
                "content": "Simple linear regression in PyTorch <p>I am performing simple linear regression using PyTorch but my model is not able to properly fit over the training data. please look at the code to find the mistake.</p>\n\n<p><a href=\"https://raw.githubusercontent.com/emilmont/Artificial-Intelligence-and-Machine-Learning/master/ML/ex1/ex1data1.txt\" rel=\"nofollow noreferrer\">Dataset is here</a></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import torch\nfrom torch import nn\nfrom torch.optim import SGD, Adam\nfrom torch.autograd import Variable\n\nclass Linear_Reg(nn.Module):\n    def __init__(self):\n        super(Linear_Reg, self).__init__()\n        self.linear = nn.Linear(1,1)\n\n    def forward(self, x):\n        y_pred = self.linear(x)\n        return y_pred\n\nnet = Linear_Reg()\n\nXt = Variable(torch.Tensor(X[:,0]))\nyt = Variable(torch.Tensor(y))\nXt = Xt.view(-1,1)\n\ncriterion = nn.MSELoss()\noptimizer = Adam(net.parameters(), lr=0.001)\n\nEPOCHS = 500\nfor epoch in range(EPOCHS):\n    pred_y = net(Xt)\n    loss = criterion(pred_y, yt)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    print('Eopch: {}, \\t\\t loss: {}'.format(epoch, loss.data.item()))\n\n</code></pre>\n\n<p>The loss decreases from ~68.88 to ~30.26</p>\n\n<p>and the resulting fitting is this:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>xxt = torch.arange(5,23)\nwith torch.no_grad():\n    a = net(xxt.reshape(-1,1).float())\nplt.scatter(X[:,1], y, s=30, c='r', marker='x', linewidths=1)\nplt.plot(xxt.data.numpy(),a.data.numpy(), label='Linear regression (Gradient descent)')\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/KJCd9.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/KJCd9.png\" alt=\"enter image description here\"></a></p>\n\n<p>What is the problem here?</p>\n <linear-regression><pytorch><p>I know this doesn't answer you 100%, but maybe it helps. Feel free to disregard.</p>\n\n<p>I just implemented this in keras and didn't have any issues</p>\n\n<pre><code>model = Sequential([\n    Dense(1,activation='linear',input_shape=(1,))\n])\nsgd = optimizers.Adam(lr=0.001)\nmodel.compile(optimizer='adam',\n              loss='mean_squared_error',\n              metrics=['mae'])\nmodel.fit(test_df.x, test_df.y, validation_split = .2,epochs=500, batch_size=1)\n\nplt.scatter(test_df.x,test_df.y,s=30,c='r',marker='x')\nx = np.linspace(4,25,100)\ny = model.get_weights()[0][0][0]*x+model.get_weights()[1][0]\nplt.plot(x, y)\nplt.ylim([-5,50])\nplt.xlim([4.5,23])\n\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/INplV.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/INplV.png\" alt=\"enter image description here\"></a></p>\n\n<p>Is it possible you read your data in incorrectly maybe? Or maybe you are referencing it incorrectly when you set your Xt and yt?</p>\n",
                "codes": [
                    [
                        "model = Sequential([\n    Dense(1,activation='linear',input_shape=(1,))\n])\nsgd = optimizers.Adam(lr=0.001)\nmodel.compile(optimizer='adam',\n              loss='mean_squared_error',\n              metrics=['mae'])\nmodel.fit(test_df.x, test_df.y, validation_split = .2,epochs=500, batch_size=1)\n\nplt.scatter(test_df.x,test_df.y,s=30,c='r',marker='x')\nx = np.linspace(4,25,100)\ny = model.get_weights()[0][0][0]*x+model.get_weights()[1][0]\nplt.plot(x, y)\nplt.ylim([-5,50])\nplt.xlim([4.5,23])\n\n"
                    ]
                ],
                "question_id:": "51325",
                "question_votes:": "1",
                "question_text:": "<p>I am performing simple linear regression using PyTorch but my model is not able to properly fit over the training data. please look at the code to find the mistake.</p>\n\n<p><a href=\"https://raw.githubusercontent.com/emilmont/Artificial-Intelligence-and-Machine-Learning/master/ML/ex1/ex1data1.txt\" rel=\"nofollow noreferrer\">Dataset is here</a></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import torch\nfrom torch import nn\nfrom torch.optim import SGD, Adam\nfrom torch.autograd import Variable\n\nclass Linear_Reg(nn.Module):\n    def __init__(self):\n        super(Linear_Reg, self).__init__()\n        self.linear = nn.Linear(1,1)\n\n    def forward(self, x):\n        y_pred = self.linear(x)\n        return y_pred\n\nnet = Linear_Reg()\n\nXt = Variable(torch.Tensor(X[:,0]))\nyt = Variable(torch.Tensor(y))\nXt = Xt.view(-1,1)\n\ncriterion = nn.MSELoss()\noptimizer = Adam(net.parameters(), lr=0.001)\n\nEPOCHS = 500\nfor epoch in range(EPOCHS):\n    pred_y = net(Xt)\n    loss = criterion(pred_y, yt)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    print('Eopch: {}, \\t\\t loss: {}'.format(epoch, loss.data.item()))\n\n</code></pre>\n\n<p>The loss decreases from ~68.88 to ~30.26</p>\n\n<p>and the resulting fitting is this:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>xxt = torch.arange(5,23)\nwith torch.no_grad():\n    a = net(xxt.reshape(-1,1).float())\nplt.scatter(X[:,1], y, s=30, c='r', marker='x', linewidths=1)\nplt.plot(xxt.data.numpy(),a.data.numpy(), label='Linear regression (Gradient descent)')\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/KJCd9.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/KJCd9.png\" alt=\"enter image description here\"></a></p>\n\n<p>What is the problem here?</p>\n",
                "tags": "<linear-regression><pytorch>",
                "answers": [
                    [
                        "51344",
                        "2",
                        "51325",
                        "",
                        "",
                        "<p>I know this doesn't answer you 100%, but maybe it helps. Feel free to disregard.</p>\n\n<p>I just implemented this in keras and didn't have any issues</p>\n\n<pre><code>model = Sequential([\n    Dense(1,activation='linear',input_shape=(1,))\n])\nsgd = optimizers.Adam(lr=0.001)\nmodel.compile(optimizer='adam',\n              loss='mean_squared_error',\n              metrics=['mae'])\nmodel.fit(test_df.x, test_df.y, validation_split = .2,epochs=500, batch_size=1)\n\nplt.scatter(test_df.x,test_df.y,s=30,c='r',marker='x')\nx = np.linspace(4,25,100)\ny = model.get_weights()[0][0][0]*x+model.get_weights()[1][0]\nplt.plot(x, y)\nplt.ylim([-5,50])\nplt.xlim([4.5,23])\n\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/INplV.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/INplV.png\" alt=\"enter image description here\"></a></p>\n\n<p>Is it possible you read your data in incorrectly maybe? Or maybe you are referencing it incorrectly when you set your Xt and yt?</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9810",
            "_score": 6.8499675,
            "_source": {
                "title": "Testing independence of random variables in Python",
                "content": "Testing independence of random variables in Python <p>Are there any tools available in Python that allow for testing of independence of two random variables (data columns)? I have two columns of data $X$ and $Y$. They can be both discrete, with values $\\{0,1\\}$ or one of them can be continuous. I would like to perform some statistical test to be sure they are independent. I am using Python so it would nice to have some ready-to-use tool implemented. I my also use R if it is not something difficult to do.  </p>\n <python><statistics><feature-selection><p>As is <a href=\"https://stats.stackexchange.com/questions/73646/how-do-i-test-that-two-continuous-variables-are-independent\">discussed in the link to Cross-Validated SO</a> from Mephy, this is isn't an easy thing to do.</p>\n\n<p>If they are independent, you might expect a correlation between pairs of variables to be close to zero. That would mean that knowing anything about one of the two variables doesn't give you any insight as to the behaviour of the second. To this end, there is <a href=\"https://stackoverflow.com/questions/33997753/calculating-pairwise-correlation-among-all-columns\">a nice answer here</a>, which shows how to compute pairwise pearson correlation (with corresponding p-values) for all columns in a Pandas DataFrame.</p>\n\n<p>The Pearson correlation does assume your random variables to be normally distributed, so keep that in mind when interpreting results. Alternatively, you could swap out that <code>pearsonr</code> function for the Spearman Rank correlation function: <code>spearmanr</code>, which does not assume normality of your variables.</p>\n\n<p>Another (perhaps simpler) way using just a Pandas DataFrame is to use the built in method <code>corr</code>: This takes a keyword <code>method</code>, which allows you to specify one of three:</p>\n\n<blockquote>\n  <p>method : {\u2018pearson\u2019, \u2018kendall\u2019, \u2018spearman\u2019}</p>\n</blockquote>\n\n<hr>\n\n<p>If you random variables are time-series (you didn't mention it), another possible tool to look at would be <a href=\"https://en.wikipedia.org/wiki/Granger_causality\" rel=\"nofollow noreferrer\">Granger Causality</a>. This could also be performed pairwise (or batch-wise) across variables. It tests to see if a the future value of variable can be better predicted when historic values of the a different variable are included in the model. For example, if the price of <em>StockA</em> can be predicted with an accuracy of 52% using its own prices of the previous 5 days, the Granger test would have a null hypothesis that including some lags from <em>StockB</em> would not improve the accuracy. So if the accuracy does indeed jump up to 53% when including lagged prices of StockB, (and the test is significant), the null hypothesis is rejected and we say that StockB Granger-causes StockA.</p>\n\n<p>This is implemented in the <a href=\"https://www.rdocumentation.org/packages/vars/versions/1.5-2\" rel=\"nofollow noreferrer\"><code>vars</code> package in R</a> (there are others too). As a bonus, this version can also perform the Wald test for correlation in error processes of predictor and target variables.</p>\n<p><a href=\"https://stats.stackexchange.com/questions/73646/how-do-i-test-that-two-continuous-variables-are-independent\">This is a hard problem to solve and there are many tests that attempt to answer it.</a>. One way of testing it is using mutual information, available on scikit-learn for either <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html\" rel=\"nofollow noreferrer\">continuous variables</a> or <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html\" rel=\"nofollow noreferrer\">discrete variables</a>. It returns zero for independent variables and higher values the more dependence there is between the variables (makes it harder to call something \"independent/dependent\" but makes it easier to rank features by their independence).</p>\n\n<pre><code>from sklearn.feature_selection import mutual_info_regression\nimport numpy as np\n\nx = np.linspace(0, 10, 50)\ny = x + np.random.randn(50)\nz = np.random.randn(50)\n\n# reshape necessary because the function accepts many\n# features at once to be compared with the right-hand side\nprint(mutual_info_regression(x.reshape(-1, 1), y))\nprint(mutual_info_regression(x.reshape(-1, 1), z))\n\n&gt; 1.20832658\n&gt; 0\n</code></pre>\n",
                "codes": [
                    [],
                    [
                        "from sklearn.feature_selection import mutual_info_regression\nimport numpy as np\n\nx = np.linspace(0, 10, 50)\ny = x + np.random.randn(50)\nz = np.random.randn(50)\n\n# reshape necessary because the function accepts many\n# features at once to be compared with the right-hand side\nprint(mutual_info_regression(x.reshape(-1, 1), y))\nprint(mutual_info_regression(x.reshape(-1, 1), z))\n\n> 1.20832658\n> 0\n"
                    ]
                ],
                "question_id:": "35787",
                "question_votes:": "3",
                "question_text:": "<p>Are there any tools available in Python that allow for testing of independence of two random variables (data columns)? I have two columns of data $X$ and $Y$. They can be both discrete, with values $\\{0,1\\}$ or one of them can be continuous. I would like to perform some statistical test to be sure they are independent. I am using Python so it would nice to have some ready-to-use tool implemented. I my also use R if it is not something difficult to do.  </p>\n",
                "tags": "<python><statistics><feature-selection>",
                "answers": [
                    [
                        "35794",
                        "2",
                        "35787",
                        "",
                        "",
                        "<p>As is <a href=\"https://stats.stackexchange.com/questions/73646/how-do-i-test-that-two-continuous-variables-are-independent\">discussed in the link to Cross-Validated SO</a> from Mephy, this is isn't an easy thing to do.</p>\n\n<p>If they are independent, you might expect a correlation between pairs of variables to be close to zero. That would mean that knowing anything about one of the two variables doesn't give you any insight as to the behaviour of the second. To this end, there is <a href=\"https://stackoverflow.com/questions/33997753/calculating-pairwise-correlation-among-all-columns\">a nice answer here</a>, which shows how to compute pairwise pearson correlation (with corresponding p-values) for all columns in a Pandas DataFrame.</p>\n\n<p>The Pearson correlation does assume your random variables to be normally distributed, so keep that in mind when interpreting results. Alternatively, you could swap out that <code>pearsonr</code> function for the Spearman Rank correlation function: <code>spearmanr</code>, which does not assume normality of your variables.</p>\n\n<p>Another (perhaps simpler) way using just a Pandas DataFrame is to use the built in method <code>corr</code>: This takes a keyword <code>method</code>, which allows you to specify one of three:</p>\n\n<blockquote>\n  <p>method : {\u2018pearson\u2019, \u2018kendall\u2019, \u2018spearman\u2019}</p>\n</blockquote>\n\n<hr>\n\n<p>If you random variables are time-series (you didn't mention it), another possible tool to look at would be <a href=\"https://en.wikipedia.org/wiki/Granger_causality\" rel=\"nofollow noreferrer\">Granger Causality</a>. This could also be performed pairwise (or batch-wise) across variables. It tests to see if a the future value of variable can be better predicted when historic values of the a different variable are included in the model. For example, if the price of <em>StockA</em> can be predicted with an accuracy of 52% using its own prices of the previous 5 days, the Granger test would have a null hypothesis that including some lags from <em>StockB</em> would not improve the accuracy. So if the accuracy does indeed jump up to 53% when including lagged prices of StockB, (and the test is significant), the null hypothesis is rejected and we say that StockB Granger-causes StockA.</p>\n\n<p>This is implemented in the <a href=\"https://www.rdocumentation.org/packages/vars/versions/1.5-2\" rel=\"nofollow noreferrer\"><code>vars</code> package in R</a> (there are others too). As a bonus, this version can also perform the Wald test for correlation in error processes of predictor and target variables.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "35789",
                        "2",
                        "35787",
                        "",
                        "",
                        "<p><a href=\"https://stats.stackexchange.com/questions/73646/how-do-i-test-that-two-continuous-variables-are-independent\">This is a hard problem to solve and there are many tests that attempt to answer it.</a>. One way of testing it is using mutual information, available on scikit-learn for either <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html\" rel=\"nofollow noreferrer\">continuous variables</a> or <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html\" rel=\"nofollow noreferrer\">discrete variables</a>. It returns zero for independent variables and higher values the more dependence there is between the variables (makes it harder to call something \"independent/dependent\" but makes it easier to rank features by their independence).</p>\n\n<pre><code>from sklearn.feature_selection import mutual_info_regression\nimport numpy as np\n\nx = np.linspace(0, 10, 50)\ny = x + np.random.randn(50)\nz = np.random.randn(50)\n\n# reshape necessary because the function accepts many\n# features at once to be compared with the right-hand side\nprint(mutual_info_regression(x.reshape(-1, 1), y))\nprint(mutual_info_regression(x.reshape(-1, 1), z))\n\n&gt; 1.20832658\n&gt; 0\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14945",
            "_score": 6.7893667,
            "_source": {
                "title": "Keras Binary Classification val_acc won't go past ~67; Full data and code included",
                "content": "Keras Binary Classification val_acc won't go past ~67; Full data and code included <p>I'm working on a binary classification in Keras with a Tensorflow backend. No matter how much I tweak, I can't seem to get my model past a val_acc of 67%. Is there something I'm missing, or is this just simply as accurate as I can get with my data? </p>\n\n<p><a href=\"https://docs.google.com/spreadsheets/d/1VX-WsSfuHHxJxbWHR147bfArblUqY64-f4dJVZtgCr0/edit?usp=sharing\" rel=\"nofollow noreferrer\">Link to the data I am using</a></p>\n\n<p><strong>My Code</strong></p>\n\n<p>Load and Balance dataset to a 1:1, and create validation data.</p>\n\n<pre><code>from sklearn.utils import resample\n\nraw_data = pd.read_csv('Data.csv')\n\ndf_majority = raw_data[raw_data['RESULT']==0].iloc[1:-2,0:3].dropna()\ndf_minority = raw_data[raw_data['RESULT']==1].iloc[1:-2,0:3].dropna()\n\nprint(raw_data['RESULT'].value_counts())\n\n\ndf_majority_downsampled = resample(df_majority, \n                          replace=False,\n                 n_samples=raw_data['RESULT'].value_counts()[1],\n                             random_state=123)\n\n# Combine minority class with downsampled majority class\ndf_downsampled = pd.concat([df_majority_downsampled,df_minority])\n\n# Display new class counts\nprint(df_downsampled['RESULT'].value_counts())\nprint(numpy.unique(df_downsampled['RESULT']))\n\nX = df_downsampled.iloc[1:-2,0:2].dropna()\nY = df_downsampled.iloc[1:-2,2:3].dropna()\n\nX, XTest, Y, YTest = train_test_split(X, Y, test_size = 0.3, random_state = 0)\n\nprint(YTest['RESULT'].value_counts()) #Just a double check to make\n</code></pre>\n\n<p>Create Model</p>\n\n<pre><code>def create_model(activation):\n    model = Sequential()\n\n    model.add(Dense(128,activation=activation,input_dim=2))\n    model.add(BatchNormalization())\n\n    model.add(Dense(64,activation=activation))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    model.add(Dense(32,activation=activation))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    model.add(Dense(16,activation=activation))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    model.add(Dense(8,activation=activation))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    model.add(Dense(4,activation=activation))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    model.add(Dense(2,activation=activation))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    model.add(Dense(1,activation='sigmoid'))\n    # load weights\n    model.load_weights(\"weights.best.hdf5\")\n    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001),metrics=['accuracy'])  \n\nreturn model\nmodel = create_model('relu')\n\nfilepath       =\"weights.best.hdf5\"\ncheckpoint     = ModelCheckpoint(filepath,monitor='val_acc',verbose=1,save_best_only=True,mode='max')\ncallbacks_list = [checkpoint]\n\nhistory = model.fit(X,Y,epochs=2000,batch_size=32, shuffle = True,validation_data = (XTest,YTest), verbose = 0, \n     callbacks=callbacks_list)\n</code></pre>\n\n<p>Predict and get score</p>\n\n<pre><code>from sklearn.metrics import roc_auc_score\n\npredict = model.predict_classes(X)\nprint(numpy.unique(predict))\n\n#for index,val in enumerate(predict):\n#print(\"Predicted: %s, actual: %s, for val %s\"(val[0],Y.iloc[index].values,X.iloc[index].values))\n\npredict = [val[0] for val in predict]\nprint(\"ras score: \",roc_auc_score(Y,predict))\n\n\npredict = model.predict(numpy.array([0.0235,0.5]).reshape(-1,2))\nprint(predict[0][0])\n</code></pre>\n\n<p><strong>Result using current model</strong></p>\n\n<p><a href=\"https://i.stack.imgur.com/zCWBx.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zCWBx.png\" alt=\"result\"></a></p>\n\n<p><strong>Sok suggestion of placing Dropout before Dense: val_acc =0.65990</strong></p>\n\n<p><a href=\"https://i.stack.imgur.com/LH5hO.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/LH5hO.png\" alt=\"enter image description here\"></a></p>\n <machine-learning><deep-learning><keras><dataset><data-cleaning>",
                "codes": [],
                "question_id:": "50825",
                "question_votes:": "1",
                "question_text:": "<p>I'm working on a binary classification in Keras with a Tensorflow backend. No matter how much I tweak, I can't seem to get my model past a val_acc of 67%. Is there something I'm missing, or is this just simply as accurate as I can get with my data? </p>\n\n<p><a href=\"https://docs.google.com/spreadsheets/d/1VX-WsSfuHHxJxbWHR147bfArblUqY64-f4dJVZtgCr0/edit?usp=sharing\" rel=\"nofollow noreferrer\">Link to the data I am using</a></p>\n\n<p><strong>My Code</strong></p>\n\n<p>Load and Balance dataset to a 1:1, and create validation data.</p>\n\n<pre><code>from sklearn.utils import resample\n\nraw_data = pd.read_csv('Data.csv')\n\ndf_majority = raw_data[raw_data['RESULT']==0].iloc[1:-2,0:3].dropna()\ndf_minority = raw_data[raw_data['RESULT']==1].iloc[1:-2,0:3].dropna()\n\nprint(raw_data['RESULT'].value_counts())\n\n\ndf_majority_downsampled = resample(df_majority, \n                          replace=False,\n                 n_samples=raw_data['RESULT'].value_counts()[1],\n                             random_state=123)\n\n# Combine minority class with downsampled majority class\ndf_downsampled = pd.concat([df_majority_downsampled,df_minority])\n\n# Display new class counts\nprint(df_downsampled['RESULT'].value_counts())\nprint(numpy.unique(df_downsampled['RESULT']))\n\nX = df_downsampled.iloc[1:-2,0:2].dropna()\nY = df_downsampled.iloc[1:-2,2:3].dropna()\n\nX, XTest, Y, YTest = train_test_split(X, Y, test_size = 0.3, random_state = 0)\n\nprint(YTest['RESULT'].value_counts()) #Just a double check to make\n</code></pre>\n\n<p>Create Model</p>\n\n<pre><code>def create_model(activation):\n    model = Sequential()\n\n    model.add(Dense(128,activation=activation,input_dim=2))\n    model.add(BatchNormalization())\n\n    model.add(Dense(64,activation=activation))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    model.add(Dense(32,activation=activation))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    model.add(Dense(16,activation=activation))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    model.add(Dense(8,activation=activation))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    model.add(Dense(4,activation=activation))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    model.add(Dense(2,activation=activation))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    model.add(Dense(1,activation='sigmoid'))\n    # load weights\n    model.load_weights(\"weights.best.hdf5\")\n    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001),metrics=['accuracy'])  \n\nreturn model\nmodel = create_model('relu')\n\nfilepath       =\"weights.best.hdf5\"\ncheckpoint     = ModelCheckpoint(filepath,monitor='val_acc',verbose=1,save_best_only=True,mode='max')\ncallbacks_list = [checkpoint]\n\nhistory = model.fit(X,Y,epochs=2000,batch_size=32, shuffle = True,validation_data = (XTest,YTest), verbose = 0, \n     callbacks=callbacks_list)\n</code></pre>\n\n<p>Predict and get score</p>\n\n<pre><code>from sklearn.metrics import roc_auc_score\n\npredict = model.predict_classes(X)\nprint(numpy.unique(predict))\n\n#for index,val in enumerate(predict):\n#print(\"Predicted: %s, actual: %s, for val %s\"(val[0],Y.iloc[index].values,X.iloc[index].values))\n\npredict = [val[0] for val in predict]\nprint(\"ras score: \",roc_auc_score(Y,predict))\n\n\npredict = model.predict(numpy.array([0.0235,0.5]).reshape(-1,2))\nprint(predict[0][0])\n</code></pre>\n\n<p><strong>Result using current model</strong></p>\n\n<p><a href=\"https://i.stack.imgur.com/zCWBx.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zCWBx.png\" alt=\"result\"></a></p>\n\n<p><strong>Sok suggestion of placing Dropout before Dense: val_acc =0.65990</strong></p>\n\n<p><a href=\"https://i.stack.imgur.com/LH5hO.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/LH5hO.png\" alt=\"enter image description here\"></a></p>\n",
                "tags": "<machine-learning><deep-learning><keras><dataset><data-cleaning>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9036",
            "_score": 6.6878185,
            "_source": {
                "title": "Getting same result for all predictions in cnn",
                "content": "Getting same result for all predictions in cnn <p>This is my first time training a model in cnn and predicting results but I am getting same value for images I have input. Here is my code</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.optimizers import Adam\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.utils import np_utils\nfrom keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, \nGlobalAveragePooling2D\nfrom keras.layers.advanced_activations import LeakyReLU \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nclassifier=Sequential()\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_train/=255\nX_test/=255\nnumber_of_classes = 10\nY_train = np_utils.to_categorical(y_train, number_of_classes)\nY_test = np_utils.to_categorical(y_test, number_of_classes)\nclassifier.add(Convolution2D(32,3,3,input_shape= \n(28,28,1),activation='relu'))\nclassifier.add(BatchNormalization(axis=-1))\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\n\nclassifier.add(Convolution2D(32,3,3,activation='relu'))\nclassifier.add(BatchNormalization(axis=-1))\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\n\nclassifier.add(Flatten())\n\nclassifier.add(Dense(output_dim=256,activation='relu'))\nclassifier.add(BatchNormalization())\nclassifier.add(Dense(output_dim=10,activation='softmax'))\n\nclassifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=            \n['accuracy'])\ngen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08,         \nshear_range=0.3, height_shift_range=0.08, zoom_range=0.08)\n\ntest_gen = ImageDataGenerator()\ntrain_generator = gen.flow(X_train, Y_train, batch_size=64)\ntest_generator = test_gen.flow(X_test, Y_test, batch_size=64)\nclassifier.fit_generator(train_generator, steps_per_epoch=60000, epochs=1, \n                validation_data=test_generator, validation_steps=10000)\nimport cv2\nimage = cv2.imread(\"pitrain.png\")\ngray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY) # grayscale\nret,thresh = cv2.threshold(gray,150,255,cv2.THRESH_BINARY_INV) \n#threshold\nkernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\ndilated = cv2.dilate(thresh,kernel,iterations = 13) # dilate\nim2,contours, hierarchy =             \ncv2.findContours(dilated,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE) \n# get contours\n# for each contour found, draw a rectangle around it on original image\nfor contour in contours:\n\n# get rectangle bounding contour\n\n[x,y,w,h] = cv2.boundingRect(contour)\n# discard areas that are too large\n\nif h&gt;300 and w&gt;300:\n\n    continue\n# discard areas that are too small\n\nif h&lt;40 or w&lt;40:\n\n    continue\n# draw rectangle around contour on original image\n\ncv2.rectangle(image,(x,y),(x+w,y+h),(255,0,255),2)\nimage.shape\nimage=image[:,:,:1]\nnewimg = cv2.resize(image,(28,28))\nimg.shape\nimg = np.reshape(newimg,[1,28,28,1])\ncv2.imshow(\"screen\",img)\nclassifier.predict(img)\n</code></pre>\n\n<p>The output I am getting is array of zeros with 1 at third position.\nThis is where I copied the contour part from <a href=\"https://www.quora.com/How-do-I-extract-a-particular-object-from-images-using-OpenCV\" rel=\"nofollow noreferrer\">https://www.quora.com/How-do-I-extract-a-particular-object-from-images-using-OpenCV</a></p>\n\n<p>Epoch is equal to 1 because I only wanted to test my model and still I got <strong>accuracy of above 99%</strong></p>\n <python><image-classification><cnn><p>Ok so I changed your model to simplify the training for example's sake. I will go through the example in detail below. When you feed a value from a different distribution to your model you are always at risk of misclassification. For example, your model was trained using handwritten numbers, thus it is not surprising for the model to missclassify numbers that are typewritten. Of course a deeper more complex model could do this. </p>\n\n<hr>\n\n<h1>Getting the data</h1>\n\n<p>The MNIST data is of size 28 by 28. We will convert these values to floating point values and then normalize them to the range 0 to 1. We will also determine that we have 10 output classes.</p>\n\n<pre><code>from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\nfrom keras.datasets import mnist\nimport numpy as np\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\n# The known number of output classes.\nnum_classes = 10\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n</code></pre>\n\n<p>Next we need to reshape the data such that it matches with the Tensorflow framework which we will be using under the hood of Keras. This requires that the instances be the first dimension and it also requires a channels dimension as the last one. thus for the MNIST data we need to have $(6000, 28, 28, 1)$.</p>\n\n<pre><code># Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test_reshaped = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n</code></pre>\n\n<p>Then we will bin the outputs into one-hot-encoded vectors</p>\n\n<pre><code># Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n</code></pre>\n\n<p>Let's build our simple model, you can add more layers to this to make it more robust</p>\n\n<pre><code>model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<p>Let's train our model</p>\n\n<pre><code>epochs = 4\nbatch_size = 128\n# Fit the model weights.\nmodel.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n</code></pre>\n\n<p>This should yield about 98.75% on the validation set. This is pretty good and should be enough to test some new data using this set.</p>\n\n<hr>\n\n<h1>Validating results using MNIST</h1>\n\n<p>Let's pass through a few random values from the MNIST dataset to see if they get rightfully classified by our model. Note how I set the dimensionality of the data. The instance dimension must exist even if we only have a single instance to predict as well as the channel dimension</p>\n\n<pre><code>ix = 0\n\nplt.imshow(X_test[ix,:,:,0], 'gray')\nplt.show()\n\ntemp = np.zeros((1,28,28,1))\ntemp[0,:,:,0] = X_test[ix,:,:,0]\n\nmodel.predict_classes(temp)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/xrTp0.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/xrTp0.png\" alt=\"enter image description here\"></a></p>\n\n<blockquote>\n  <p>array([7], dtype=int64)</p>\n</blockquote>\n\n<p>Ok so that worked! Let's try another one <code>ix = 100</code>!</p>\n\n<p><a href=\"https://i.stack.imgur.com/WjZeD.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WjZeD.png\" alt=\"enter image description here\"></a></p>\n\n<blockquote>\n  <p>array([6], dtype=int64)</p>\n</blockquote>\n\n<p>That worked as well!</p>\n\n<hr>\n\n<h1>Validating the model on novel data</h1>\n\n<p>The image you sue has to match stylistically with the ones in the MNIST data set. Ideally they should be of the same distribution. The image you provided luckily gets correctly classified but it should be noted that this may not be the case for other numbers that are typewritten. If you want your algorithm to detect these then you should really train with typewritten numbers as well as handwritten numbers.</p>\n\n<pre><code>from skimage.transform import resize\n\ndef rgb2gray(rgb):\n    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n\nim = plt.imread(\"7 type.jpg\")\nim = rgb2gray(im)\nim = resize(im, (28, 28))\n\nplt.imshow(im[:,:], 'gray')\nplt.show()\n\ntemp = np.zeros((1,28,28,1))\ntemp[0,:,:,0] = im\n\nmodel.predict_classes(temp)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/kILus.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/kILus.png\" alt=\"enter image description here\"></a></p>\n\n<blockquote>\n  <p>array([7], dtype=int64)</p>\n</blockquote>\n\n<h1>Validating on hand drawn numbers</h1>\n\n<p>More realistically would be to use hand drawn numbers since that is what we used to train. I just drew this one using Paint.</p>\n\n<p><a href=\"https://i.stack.imgur.com/1Pnyl.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/1Pnyl.png\" alt=\"enter image description here\"></a></p>\n\n<blockquote>\n  <p>array([8], dtype=int64)</p>\n</blockquote>\n\n<p><a href=\"https://i.stack.imgur.com/t8gM3.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/t8gM3.png\" alt=\"enter image description here\"></a></p>\n\n<blockquote>\n  <p>array(<a href=\"https://i.stack.imgur.com/WjZeD.png\" rel=\"nofollow noreferrer\">2</a>, dtype=int64)</p>\n</blockquote>\n",
                "codes": [
                    [
                        "from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\nfrom keras.datasets import mnist\nimport numpy as np\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\n# The known number of output classes.\nnum_classes = 10\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n",
                        "# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test_reshaped = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n",
                        "# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n",
                        "model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n",
                        "epochs = 4\nbatch_size = 128\n# Fit the model weights.\nmodel.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n",
                        "ix = 0\n\nplt.imshow(X_test[ix,:,:,0], 'gray')\nplt.show()\n\ntemp = np.zeros((1,28,28,1))\ntemp[0,:,:,0] = X_test[ix,:,:,0]\n\nmodel.predict_classes(temp)\n",
                        "from skimage.transform import resize\n\ndef rgb2gray(rgb):\n    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n\nim = plt.imread(\"7 type.jpg\")\nim = rgb2gray(im)\nim = resize(im, (28, 28))\n\nplt.imshow(im[:,:], 'gray')\nplt.show()\n\ntemp = np.zeros((1,28,28,1))\ntemp[0,:,:,0] = im\n\nmodel.predict_classes(temp)\n"
                    ]
                ],
                "question_id:": "32353",
                "question_votes:": "2",
                "question_text:": "<p>This is my first time training a model in cnn and predicting results but I am getting same value for images I have input. Here is my code</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.optimizers import Adam\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.utils import np_utils\nfrom keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, \nGlobalAveragePooling2D\nfrom keras.layers.advanced_activations import LeakyReLU \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nclassifier=Sequential()\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_train/=255\nX_test/=255\nnumber_of_classes = 10\nY_train = np_utils.to_categorical(y_train, number_of_classes)\nY_test = np_utils.to_categorical(y_test, number_of_classes)\nclassifier.add(Convolution2D(32,3,3,input_shape= \n(28,28,1),activation='relu'))\nclassifier.add(BatchNormalization(axis=-1))\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\n\nclassifier.add(Convolution2D(32,3,3,activation='relu'))\nclassifier.add(BatchNormalization(axis=-1))\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\n\nclassifier.add(Flatten())\n\nclassifier.add(Dense(output_dim=256,activation='relu'))\nclassifier.add(BatchNormalization())\nclassifier.add(Dense(output_dim=10,activation='softmax'))\n\nclassifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=            \n['accuracy'])\ngen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08,         \nshear_range=0.3, height_shift_range=0.08, zoom_range=0.08)\n\ntest_gen = ImageDataGenerator()\ntrain_generator = gen.flow(X_train, Y_train, batch_size=64)\ntest_generator = test_gen.flow(X_test, Y_test, batch_size=64)\nclassifier.fit_generator(train_generator, steps_per_epoch=60000, epochs=1, \n                validation_data=test_generator, validation_steps=10000)\nimport cv2\nimage = cv2.imread(\"pitrain.png\")\ngray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY) # grayscale\nret,thresh = cv2.threshold(gray,150,255,cv2.THRESH_BINARY_INV) \n#threshold\nkernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\ndilated = cv2.dilate(thresh,kernel,iterations = 13) # dilate\nim2,contours, hierarchy =             \ncv2.findContours(dilated,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE) \n# get contours\n# for each contour found, draw a rectangle around it on original image\nfor contour in contours:\n\n# get rectangle bounding contour\n\n[x,y,w,h] = cv2.boundingRect(contour)\n# discard areas that are too large\n\nif h&gt;300 and w&gt;300:\n\n    continue\n# discard areas that are too small\n\nif h&lt;40 or w&lt;40:\n\n    continue\n# draw rectangle around contour on original image\n\ncv2.rectangle(image,(x,y),(x+w,y+h),(255,0,255),2)\nimage.shape\nimage=image[:,:,:1]\nnewimg = cv2.resize(image,(28,28))\nimg.shape\nimg = np.reshape(newimg,[1,28,28,1])\ncv2.imshow(\"screen\",img)\nclassifier.predict(img)\n</code></pre>\n\n<p>The output I am getting is array of zeros with 1 at third position.\nThis is where I copied the contour part from <a href=\"https://www.quora.com/How-do-I-extract-a-particular-object-from-images-using-OpenCV\" rel=\"nofollow noreferrer\">https://www.quora.com/How-do-I-extract-a-particular-object-from-images-using-OpenCV</a></p>\n\n<p>Epoch is equal to 1 because I only wanted to test my model and still I got <strong>accuracy of above 99%</strong></p>\n",
                "tags": "<python><image-classification><cnn>",
                "answers": [
                    [
                        "32363",
                        "2",
                        "32353",
                        "",
                        "",
                        "<p>Ok so I changed your model to simplify the training for example's sake. I will go through the example in detail below. When you feed a value from a different distribution to your model you are always at risk of misclassification. For example, your model was trained using handwritten numbers, thus it is not surprising for the model to missclassify numbers that are typewritten. Of course a deeper more complex model could do this. </p>\n\n<hr>\n\n<h1>Getting the data</h1>\n\n<p>The MNIST data is of size 28 by 28. We will convert these values to floating point values and then normalize them to the range 0 to 1. We will also determine that we have 10 output classes.</p>\n\n<pre><code>from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\nfrom keras.datasets import mnist\nimport numpy as np\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\n# The known number of output classes.\nnum_classes = 10\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n</code></pre>\n\n<p>Next we need to reshape the data such that it matches with the Tensorflow framework which we will be using under the hood of Keras. This requires that the instances be the first dimension and it also requires a channels dimension as the last one. thus for the MNIST data we need to have $(6000, 28, 28, 1)$.</p>\n\n<pre><code># Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test_reshaped = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n</code></pre>\n\n<p>Then we will bin the outputs into one-hot-encoded vectors</p>\n\n<pre><code># Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n</code></pre>\n\n<p>Let's build our simple model, you can add more layers to this to make it more robust</p>\n\n<pre><code>model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<p>Let's train our model</p>\n\n<pre><code>epochs = 4\nbatch_size = 128\n# Fit the model weights.\nmodel.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n</code></pre>\n\n<p>This should yield about 98.75% on the validation set. This is pretty good and should be enough to test some new data using this set.</p>\n\n<hr>\n\n<h1>Validating results using MNIST</h1>\n\n<p>Let's pass through a few random values from the MNIST dataset to see if they get rightfully classified by our model. Note how I set the dimensionality of the data. The instance dimension must exist even if we only have a single instance to predict as well as the channel dimension</p>\n\n<pre><code>ix = 0\n\nplt.imshow(X_test[ix,:,:,0], 'gray')\nplt.show()\n\ntemp = np.zeros((1,28,28,1))\ntemp[0,:,:,0] = X_test[ix,:,:,0]\n\nmodel.predict_classes(temp)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/xrTp0.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/xrTp0.png\" alt=\"enter image description here\"></a></p>\n\n<blockquote>\n  <p>array([7], dtype=int64)</p>\n</blockquote>\n\n<p>Ok so that worked! Let's try another one <code>ix = 100</code>!</p>\n\n<p><a href=\"https://i.stack.imgur.com/WjZeD.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WjZeD.png\" alt=\"enter image description here\"></a></p>\n\n<blockquote>\n  <p>array([6], dtype=int64)</p>\n</blockquote>\n\n<p>That worked as well!</p>\n\n<hr>\n\n<h1>Validating the model on novel data</h1>\n\n<p>The image you sue has to match stylistically with the ones in the MNIST data set. Ideally they should be of the same distribution. The image you provided luckily gets correctly classified but it should be noted that this may not be the case for other numbers that are typewritten. If you want your algorithm to detect these then you should really train with typewritten numbers as well as handwritten numbers.</p>\n\n<pre><code>from skimage.transform import resize\n\ndef rgb2gray(rgb):\n    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n\nim = plt.imread(\"7 type.jpg\")\nim = rgb2gray(im)\nim = resize(im, (28, 28))\n\nplt.imshow(im[:,:], 'gray')\nplt.show()\n\ntemp = np.zeros((1,28,28,1))\ntemp[0,:,:,0] = im\n\nmodel.predict_classes(temp)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/kILus.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/kILus.png\" alt=\"enter image description here\"></a></p>\n\n<blockquote>\n  <p>array([7], dtype=int64)</p>\n</blockquote>\n\n<h1>Validating on hand drawn numbers</h1>\n\n<p>More realistically would be to use hand drawn numbers since that is what we used to train. I just drew this one using Paint.</p>\n\n<p><a href=\"https://i.stack.imgur.com/1Pnyl.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/1Pnyl.png\" alt=\"enter image description here\"></a></p>\n\n<blockquote>\n  <p>array([8], dtype=int64)</p>\n</blockquote>\n\n<p><a href=\"https://i.stack.imgur.com/t8gM3.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/t8gM3.png\" alt=\"enter image description here\"></a></p>\n\n<blockquote>\n  <p>array(<a href=\"https://i.stack.imgur.com/WjZeD.png\" rel=\"nofollow noreferrer\">2</a>, dtype=int64)</p>\n</blockquote>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8338",
            "_score": 6.668556,
            "_source": {
                "title": "How to implement PCA color augmentation as discussed in AlexNet",
                "content": "How to implement PCA color augmentation as discussed in AlexNet <p>I read through \"ImageNet Classification with Deep Convolutional Neural Networks\" again specifically for details on how to implement PCA color augmentation. \nI am unsure if I have it right. Here is how I did this in numpy:</p>\n\n<pre><code># original image is 224x224x3 of dtype uint8 \n\nrenorm_image = np.reshape(original_image,(original_image.shape[0]*original_image.shape[1],3))\n\nrenorm_image = renorm_image.astype('float32')\nrenorm_image -= np.mean(renorm_image, axis=0)\nrenorm_image /= np.std(renorm_image, axis=0)\n\ncov = np.cov(renorm_image, rowvar=False)\n\nlambdas, p = np.linalg.eig(cov)\nalphas = np.random.normal(0, 0.1, 3)\n\ndelta = np.dot(p, alphas*lambdas)\n\ndelta = (delta*255.).astype('int8')\n\npca_color_image = np.maximum(np.minimum(original_image + delta, 255), 0).astype('uint8')\n</code></pre>\n\n<p>One serious doubt is the line \"delta = (delta*255.)\". I have to do this to rescale things such that the numbers make sense. I hope someone can give me feedback if this is right.</p>\n <convnet><pca><data-augmentation><p>You should not apply <code>*255</code>.</p>\n\n<p><code>delta</code> was supposed to be added to <code>renorm_image</code>, because you calculated this <code>delta</code> using <code>cov</code>, which was based on <code>renorm_image</code>. </p>\n\n<p>Then how would you restore <code>renorm_image</code> to your original image? <code>*std + mean</code> or <code>*255</code>?</p>\n\n<p>Obviously you should apply <code>*std + mean</code>.</p>\n\n<p>Therefore, </p>\n\n<pre><code>delta = (delta*255.).astype('int8')\npca_color_image = np.maximum(np.minimum(original_image + delta, 255), 0).astype('uint8')\n</code></pre>\n\n<p>should be changed to:</p>\n\n<pre><code>mean = np.mean(renorm_image, axis=0)\nstd = np.std(renorm_image, axis=0)\npca_augmentation_version_renorm_image = renorm_image + delta\npca_color_image = pca_augmentation_version_renorm_image * std + mean\npca_color_image = np.maximum(np.minimum(pca_color_image, 255), 0).astype('uint8')\n</code></pre>\n",
                "codes": [
                    [
                        "delta = (delta*255.).astype('int8')\npca_color_image = np.maximum(np.minimum(original_image + delta, 255), 0).astype('uint8')\n",
                        "mean = np.mean(renorm_image, axis=0)\nstd = np.std(renorm_image, axis=0)\npca_augmentation_version_renorm_image = renorm_image + delta\npca_color_image = pca_augmentation_version_renorm_image * std + mean\npca_color_image = np.maximum(np.minimum(pca_color_image, 255), 0).astype('uint8')\n"
                    ]
                ],
                "question_id:": "30602",
                "question_votes:": "1",
                "question_text:": "<p>I read through \"ImageNet Classification with Deep Convolutional Neural Networks\" again specifically for details on how to implement PCA color augmentation. \nI am unsure if I have it right. Here is how I did this in numpy:</p>\n\n<pre><code># original image is 224x224x3 of dtype uint8 \n\nrenorm_image = np.reshape(original_image,(original_image.shape[0]*original_image.shape[1],3))\n\nrenorm_image = renorm_image.astype('float32')\nrenorm_image -= np.mean(renorm_image, axis=0)\nrenorm_image /= np.std(renorm_image, axis=0)\n\ncov = np.cov(renorm_image, rowvar=False)\n\nlambdas, p = np.linalg.eig(cov)\nalphas = np.random.normal(0, 0.1, 3)\n\ndelta = np.dot(p, alphas*lambdas)\n\ndelta = (delta*255.).astype('int8')\n\npca_color_image = np.maximum(np.minimum(original_image + delta, 255), 0).astype('uint8')\n</code></pre>\n\n<p>One serious doubt is the line \"delta = (delta*255.)\". I have to do this to rescale things such that the numbers make sense. I hope someone can give me feedback if this is right.</p>\n",
                "tags": "<convnet><pca><data-augmentation>",
                "answers": [
                    [
                        "38757",
                        "2",
                        "30602",
                        "",
                        "",
                        "<p>You should not apply <code>*255</code>.</p>\n\n<p><code>delta</code> was supposed to be added to <code>renorm_image</code>, because you calculated this <code>delta</code> using <code>cov</code>, which was based on <code>renorm_image</code>. </p>\n\n<p>Then how would you restore <code>renorm_image</code> to your original image? <code>*std + mean</code> or <code>*255</code>?</p>\n\n<p>Obviously you should apply <code>*std + mean</code>.</p>\n\n<p>Therefore, </p>\n\n<pre><code>delta = (delta*255.).astype('int8')\npca_color_image = np.maximum(np.minimum(original_image + delta, 255), 0).astype('uint8')\n</code></pre>\n\n<p>should be changed to:</p>\n\n<pre><code>mean = np.mean(renorm_image, axis=0)\nstd = np.std(renorm_image, axis=0)\npca_augmentation_version_renorm_image = renorm_image + delta\npca_color_image = pca_augmentation_version_renorm_image * std + mean\npca_color_image = np.maximum(np.minimum(pca_color_image, 255), 0).astype('uint8')\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11268",
            "_score": 6.668556,
            "_source": {
                "title": "How to interpret the mean for output clusters for expected-maximization?",
                "content": "How to interpret the mean for output clusters for expected-maximization? <p>I am trying to cluster data using <a href=\"http://scikit-learn.org/stable/modules/mixture.html#expectation-maximization\" rel=\"nofollow noreferrer\">scikit's expectation-maximization</a>. So I created two different data sets from a normal distribution which is I have shown in the graph below.</p>\n\n<p><a href=\"https://i.stack.imgur.com/bzXVM.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/bzXVM.png\" alt=\"enter image description here\"></a></p>\n\n<p>The mean for each of the distribution is:</p>\n\n<pre><code>Mean of distr-1: 0.0037523503071361197\nMean of distr-2: -0.4384554574756237\n</code></pre>\n\n<p>But after I run the EM using scikit, I get the mean as follows:</p>\n\n<pre><code>Mean after EM: [[-0.12327634  0.39188704]\n[-1.31191255 -4.4292102 ]]\n</code></pre>\n\n<p>How am I supposed to interpret this mean? I am trying to create two clusters from the data. Here is my code:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.mixture import GaussianMixture\n\n\ndistr_1 = np.sin(2 * np.random.randn(100) + np.random.randn())\ndistr_2 = (3 * np.random.randn(100)) + np.random.randn()\n\nx = list(range(0,100))\n\nX_train = np.concatenate((distr_1, distr_2))\n\n\nplt.scatter(x,distr_1)\nplt.scatter(x,distr_2)\nplt.gca().legend(('sin', 'linear'))\nplt.savefig('cluster_data.png')\nplt.clf()\n\n\nprint(\"Mean of distr-1:\",np.mean(distr_1))\nprint(\"Mean of distr-2:\",np.mean(distr_2))\n\ngmm = GaussianMixture(n_components=2)\ngmm.fit(X_train.reshape(100,2))\n\nprint(\"Mean after EM:\",gmm.means_)\n</code></pre>\n\n<p>Am I doing this incorrectly? What does the output mean?</p>\n <python><scikit-learn><clustering><expectation-maximization><p>It seems like you are trying to create a mixture of 2 univariate distributions, but you happen to get a bivariate distribution (which is why you have a 2x2 array).</p>\n\n<p>This is because you reshaped the <code>X_train</code> array. You need to change your penultimate line to:</p>\n\n<pre><code>gmm.fit(X_train)\n</code></pre>\n",
                "codes": [
                    [
                        "gmm.fit(X_train)\n"
                    ]
                ],
                "question_id:": "39779",
                "question_votes:": "",
                "question_text:": "<p>I am trying to cluster data using <a href=\"http://scikit-learn.org/stable/modules/mixture.html#expectation-maximization\" rel=\"nofollow noreferrer\">scikit's expectation-maximization</a>. So I created two different data sets from a normal distribution which is I have shown in the graph below.</p>\n\n<p><a href=\"https://i.stack.imgur.com/bzXVM.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/bzXVM.png\" alt=\"enter image description here\"></a></p>\n\n<p>The mean for each of the distribution is:</p>\n\n<pre><code>Mean of distr-1: 0.0037523503071361197\nMean of distr-2: -0.4384554574756237\n</code></pre>\n\n<p>But after I run the EM using scikit, I get the mean as follows:</p>\n\n<pre><code>Mean after EM: [[-0.12327634  0.39188704]\n[-1.31191255 -4.4292102 ]]\n</code></pre>\n\n<p>How am I supposed to interpret this mean? I am trying to create two clusters from the data. Here is my code:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.mixture import GaussianMixture\n\n\ndistr_1 = np.sin(2 * np.random.randn(100) + np.random.randn())\ndistr_2 = (3 * np.random.randn(100)) + np.random.randn()\n\nx = list(range(0,100))\n\nX_train = np.concatenate((distr_1, distr_2))\n\n\nplt.scatter(x,distr_1)\nplt.scatter(x,distr_2)\nplt.gca().legend(('sin', 'linear'))\nplt.savefig('cluster_data.png')\nplt.clf()\n\n\nprint(\"Mean of distr-1:\",np.mean(distr_1))\nprint(\"Mean of distr-2:\",np.mean(distr_2))\n\ngmm = GaussianMixture(n_components=2)\ngmm.fit(X_train.reshape(100,2))\n\nprint(\"Mean after EM:\",gmm.means_)\n</code></pre>\n\n<p>Am I doing this incorrectly? What does the output mean?</p>\n",
                "tags": "<python><scikit-learn><clustering><expectation-maximization>",
                "answers": [
                    [
                        "39785",
                        "2",
                        "39779",
                        "",
                        "",
                        "<p>It seems like you are trying to create a mixture of 2 univariate distributions, but you happen to get a bivariate distribution (which is why you have a 2x2 array).</p>\n\n<p>This is because you reshaped the <code>X_train</code> array. You need to change your penultimate line to:</p>\n\n<pre><code>gmm.fit(X_train)\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12817",
            "_score": 6.668556,
            "_source": {
                "title": "Keras inconsistent training results",
                "content": "Keras inconsistent training results <p>I have a CNN network in keras. I do the training on a cloud GPU. I get completely different accuracy and loss graphs when I run the training twice. I set random seeds as below, still no luck. Anything missing? Or is this normal behaviour on external GPU? I read that sometimes that they induce randomness because of certain libraries they might be using? I see %2-4 difference in accuracy everytime I run. So makes it difficult to judge my hyperparameter tuning.  </p>\n\n<pre><code>import numpy as np\nnp.random.seed(3)\nimport tensorflow as tf\ntf.set_random_seed(4)\nimport keras\nkeras.backend.clear_session()\n\n\nfrom keras.layers import LeakyReLU\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers import Convolution2D, MaxPooling2D, Dropout, Reshape\nfrom keras.layers.pooling import GlobalAveragePooling2D\nfrom keras.optimizers import Adamax, Adadelta, Adagrad, Adam, RMSprop\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, \n ReduceLROnPlateau\nfrom keras.regularizers import l2,l1,l1_l2\nfrom sklearn.metrics import precision_recall_fscore_support, \n roc_auc_score\nfrom keras.models import model_from_json\nfrom keras.layers.normalization import BatchNormalization\nfrom sklearn.metrics import confusion_matrix, f1_score, \n precision_score, recall_score\nimport keras.backend as K\nfrom keras.layers import Dense, Dropout, Flatten\nfrom sklearn.preprocessing import Normalizer\n</code></pre>\n <machine-learning><neural-network><keras><tensorflow><p>The <code>Dropout</code> layer induces randomness (noise) in the training, because random neurons get disabled in every epoch. This leads to slightly different results per training, but the overall performance should be similar, especially for a large amount of epochs.</p>\n\n<p>In order to set the seed for the <code>Droupout</code> layer, you should modify the <code>seed=None</code> argument when you initialize the layer as <code>keras.layers.Dropout(rate, noise_shape=None, seed=None)</code>, as explained in the official <a href=\"https://keras.io/layers/core/#dropout\" rel=\"nofollow noreferrer\">webpage</a>.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "44645",
                "question_votes:": "1",
                "question_text:": "<p>I have a CNN network in keras. I do the training on a cloud GPU. I get completely different accuracy and loss graphs when I run the training twice. I set random seeds as below, still no luck. Anything missing? Or is this normal behaviour on external GPU? I read that sometimes that they induce randomness because of certain libraries they might be using? I see %2-4 difference in accuracy everytime I run. So makes it difficult to judge my hyperparameter tuning.  </p>\n\n<pre><code>import numpy as np\nnp.random.seed(3)\nimport tensorflow as tf\ntf.set_random_seed(4)\nimport keras\nkeras.backend.clear_session()\n\n\nfrom keras.layers import LeakyReLU\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers import Convolution2D, MaxPooling2D, Dropout, Reshape\nfrom keras.layers.pooling import GlobalAveragePooling2D\nfrom keras.optimizers import Adamax, Adadelta, Adagrad, Adam, RMSprop\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, \n ReduceLROnPlateau\nfrom keras.regularizers import l2,l1,l1_l2\nfrom sklearn.metrics import precision_recall_fscore_support, \n roc_auc_score\nfrom keras.models import model_from_json\nfrom keras.layers.normalization import BatchNormalization\nfrom sklearn.metrics import confusion_matrix, f1_score, \n precision_score, recall_score\nimport keras.backend as K\nfrom keras.layers import Dense, Dropout, Flatten\nfrom sklearn.preprocessing import Normalizer\n</code></pre>\n",
                "tags": "<machine-learning><neural-network><keras><tensorflow>",
                "answers": [
                    [
                        "44646",
                        "2",
                        "44645",
                        "",
                        "",
                        "<p>The <code>Dropout</code> layer induces randomness (noise) in the training, because random neurons get disabled in every epoch. This leads to slightly different results per training, but the overall performance should be similar, especially for a large amount of epochs.</p>\n\n<p>In order to set the seed for the <code>Droupout</code> layer, you should modify the <code>seed=None</code> argument when you initialize the layer as <code>keras.layers.Dropout(rate, noise_shape=None, seed=None)</code>, as explained in the official <a href=\"https://keras.io/layers/core/#dropout\" rel=\"nofollow noreferrer\">webpage</a>.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14392",
            "_score": 6.668556,
            "_source": {
                "title": "Reverse engineering on Xgboost model",
                "content": "Reverse engineering on Xgboost model <p>I am doing experiments on <a href=\"https://www.physionet.org/challenge/2017/sources/\" rel=\"nofollow noreferrer\">https://www.physionet.org/challenge/2017/sources/</a> submission. </p>\n\n<p>I like one of the submission code, which use <code>Xgboost</code> to train the classifier. Training data is in <code>.mat</code> file which I converted to CSV file for training.</p>\n\n<p>In the below code, I have a pre-trained model <code>xgb.bin</code>, with which I can test any input signal. But I want to train the model using different data and create my own training model.</p>\n\n<p>Here, is the code which predicts the class name for a given input ECG file:</p>\n\n<pre><code>def predict(data):\n    #data = io.loadmat(path)['val'][0]\n    from numpy import genfromtxt\n    data = genfromtxt('testdata/val.csv', delimiter=',')\n\n    features_noise = np.zeros((5, ))\n\n    snr, rr_num, var, fr, fr2 = find_noise_features(data)\n    features_noise[0] = snr\n    features_noise[1] = rr_num\n    features_noise[2] = var\n    features_noise[3] = fr\n    features_noise[4] = fr2\n    features = extract_basic_features(data, 30000)\n    features = np.hstack((features, features_noise.reshape(1, -1)))\n\n    mean_ = np.array([15.96300284066109753667, 0.00412371298595770857, 38811.34497233365254942328,\n                      0.48050717744965593115, 0.14397582347542958736])\n    scale_ = np.array([4.22917401559752281770, 0.00093664880988427878, 62350.76443798459513345733,\n                       0.15396567666240373873, 0.07085474966801086349])\n    features_noise -= mean_\n    features_noise /= scale_\n\n    prediction = 0\n    if features_noise[0] &lt; -2.9:\n        prediction = 3\n    if features_noise[2] &gt; 6.0:\n        prediction = 3\n    if features_noise[3] &gt; 3.0:\n        prediction = 3\n    if features_noise[4] &lt; -2.0:\n        prediction = 3\n\n    bst = xgb.Booster({'nthread': 4})\n    bst.load_model(\"xgb.bin\")\n\n    dfeatures = xgb.DMatrix(features)\n    prediction_prob = bst.predict(dfeatures)\n    prediction = np.argmax(prediction_prob)\n\n    return prediction\n\ndef run(data): \n    prediction = predict(data)\n    print(prediction)\n</code></pre>\n\n<p>I could create <code>dfeatures</code> for all training data which is in the CSV file. (I am reading each CSV individually and calculating feature. Is it correct?)</p>\n\n<p>Now once I have defaulters for all training ECG files, I want to create a xgboost model. But I don\u2019t have any clue for that. Any suggestion highly appreciated.</p>\n <machine-learning><python><classification><xgboost>",
                "codes": [],
                "question_id:": "48428",
                "question_votes:": "",
                "question_text:": "<p>I am doing experiments on <a href=\"https://www.physionet.org/challenge/2017/sources/\" rel=\"nofollow noreferrer\">https://www.physionet.org/challenge/2017/sources/</a> submission. </p>\n\n<p>I like one of the submission code, which use <code>Xgboost</code> to train the classifier. Training data is in <code>.mat</code> file which I converted to CSV file for training.</p>\n\n<p>In the below code, I have a pre-trained model <code>xgb.bin</code>, with which I can test any input signal. But I want to train the model using different data and create my own training model.</p>\n\n<p>Here, is the code which predicts the class name for a given input ECG file:</p>\n\n<pre><code>def predict(data):\n    #data = io.loadmat(path)['val'][0]\n    from numpy import genfromtxt\n    data = genfromtxt('testdata/val.csv', delimiter=',')\n\n    features_noise = np.zeros((5, ))\n\n    snr, rr_num, var, fr, fr2 = find_noise_features(data)\n    features_noise[0] = snr\n    features_noise[1] = rr_num\n    features_noise[2] = var\n    features_noise[3] = fr\n    features_noise[4] = fr2\n    features = extract_basic_features(data, 30000)\n    features = np.hstack((features, features_noise.reshape(1, -1)))\n\n    mean_ = np.array([15.96300284066109753667, 0.00412371298595770857, 38811.34497233365254942328,\n                      0.48050717744965593115, 0.14397582347542958736])\n    scale_ = np.array([4.22917401559752281770, 0.00093664880988427878, 62350.76443798459513345733,\n                       0.15396567666240373873, 0.07085474966801086349])\n    features_noise -= mean_\n    features_noise /= scale_\n\n    prediction = 0\n    if features_noise[0] &lt; -2.9:\n        prediction = 3\n    if features_noise[2] &gt; 6.0:\n        prediction = 3\n    if features_noise[3] &gt; 3.0:\n        prediction = 3\n    if features_noise[4] &lt; -2.0:\n        prediction = 3\n\n    bst = xgb.Booster({'nthread': 4})\n    bst.load_model(\"xgb.bin\")\n\n    dfeatures = xgb.DMatrix(features)\n    prediction_prob = bst.predict(dfeatures)\n    prediction = np.argmax(prediction_prob)\n\n    return prediction\n\ndef run(data): \n    prediction = predict(data)\n    print(prediction)\n</code></pre>\n\n<p>I could create <code>dfeatures</code> for all training data which is in the CSV file. (I am reading each CSV individually and calculating feature. Is it correct?)</p>\n\n<p>Now once I have defaulters for all training ECG files, I want to create a xgboost model. But I don\u2019t have any clue for that. Any suggestion highly appreciated.</p>\n",
                "tags": "<machine-learning><python><classification><xgboost>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14457",
            "_score": 6.6094656,
            "_source": {
                "title": "SVM with Tensorflow",
                "content": "SVM with Tensorflow <p>I have an array of Numpy with the following data, for example:</p>\n\n<pre><code>['13 .398249765480822 ''19 .324784598731966' '80 .98629514090669 '\n\u00a0 '-3.703122956721927e-06' '80 .98629884402965 ''24 .008452881790028'\n\u00a0 '679.6408224307851' '2498.8247399799975', 'fear']\n</code></pre>\n\n<p>And another array of Numpy with the same length and different numbers and another label that is 'neutral'.</p>\n\n<p>The fact is that I'm using the code (Setosa) of Github and other articles to make a binary classifier (fear or neutral) but I get the following error because I do not know how to do so that I take into account all the numbers in the array and not as the code of Setosa, which only takes into account two when performing the mesh.</p>\n\n<pre><code>## SVM con Tensorflow\nsess = tf.Session()\nx_vals = np.array([[x[0], x[1], x[2], x[3], x[4], x[5], x[6], x[7]] for x in matrix])\ny_vals = np.array([1 if y[8] == 'fear' else -1 for y in matrix])\n\n# Split the train data and testing data\ntrain_indices = np.random.choice(len(x_vals), int(round(len(x_vals)*0.8)), replace=False)\ntest_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\nx_vals_train = x_vals[train_indices]\nx_vals_test = x_vals[test_indices]\ny_vals_train = y_vals[train_indices]\ny_vals_test = y_vals[test_indices]\n\nclass1_x = [x[0] for i, x in enumerate(x_vals_train) if y_vals_train[i] == 1]\nclass1_y = [x[1] for i, x in enumerate(x_vals_train) if y_vals_train[i] == 1]\nclass2_x = [x[0] for i, x in enumerate(x_vals_train) if y_vals_train[i] == -1]\nclass2_y = [x[1] for i, x in enumerate(x_vals_train) if y_vals_train[i] == -1]\n\n# Declare batch size\nbatch_size = 150\n\n# Initialize placeholders\nx_data = tf.placeholder(shape=[None, 8], dtype=tf.float32)\ny_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\nprediction_grid = tf.placeholder(shape=[None, 8], dtype=tf.float32)\n\n# Create variables for svm\nb = tf.Variable(tf.random_normal(shape=[1, batch_size]))\n\n# Gaussian (RBF) kernel\ngamma = tf.constant(-10.0)\nsq_dists = tf.multiply(2., tf.matmul(x_data, tf.transpose(x_data)))\nmy_kernel = tf.exp(tf.multiply(gamma, tf.abs(sq_dists)))\n\n# Compute SVM Model\nfirst_term = tf.reduce_sum(b)\nb_vec_cross = tf.matmul(tf.transpose(b), b)\ny_target_cross = tf.matmul(y_target, tf.transpose(y_target))\nsecond_term = tf.reduce_sum(tf.multiply(my_kernel, tf.multiply(b_vec_cross, y_target_cross)))\nloss = tf.negative(tf.subtract(first_term, second_term))\n\n# Gaussian (RBF) prediction kernel\nrA = tf.reshape(tf.reduce_sum(tf.square(x_data), 1), [-1, 1])\nrB = tf.reshape(tf.reduce_sum(tf.square(prediction_grid), 1), [-1, 1])\npred_sq_dist = tf.add(tf.subtract(rA, tf.multiply(2., tf.matmul(x_data, tf.transpose(prediction_grid)))), tf.transpose(rB))\npred_kernel = tf.exp(tf.multiply(gamma, tf.abs(pred_sq_dist)))\n\nprediction_output = tf.matmul(tf.multiply(tf.transpose(y_target), b), pred_kernel)\nprediction = tf.sign(prediction_output - tf.reduce_mean(prediction_output))\naccuracy = tf.reduce_mean(tf.cast(tf.equal(tf.squeeze(prediction), tf.squeeze(y_target)), tf.float32))\n\n# Declare optimizer\nmy_opt = tf.train.GradientDescentOptimizer(0.01)\ntrain_step = my_opt.minimize(loss)\n\n# Initialize variables\ninit = tf.global_variables_initializer()\nsess.run(init)\n\n# Training loop\nloss_vec = []\nbatch_accuracy = []\nfor i in range(300):\n    rand_index = np.random.choice(len(x_vals), size=batch_size)\n    rand_x = x_vals[rand_index]\n    rand_y = np.transpose([y_vals[rand_index]])\n    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n\n    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n    loss_vec.append(temp_loss)\n\n    acc_temp = sess.run(accuracy, feed_dict={x_data: rand_x,\n                                             y_target: rand_y,\n                                             prediction_grid: rand_x})\n    batch_accuracy.append(acc_temp)\n\n    if (i + 1) % 75 == 0:\n        print('Step #' + str(i + 1))\n        print('Loss = ' + str(temp_loss))\n\n# Create a mesh to plot points in\nx_vals = x_vals.astype(np.float)\nx_min, x_max = x_vals[:, 0].min() - 1, x_vals[:, 0].max() + 1\ny_min, y_max = x_vals[:, 1].min() - 1, x_vals[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n                     np.arange(y_min, y_max, 0.02))\ngrid_points = np.c_[xx.ravel(), yy.ravel()]\n[grid_predictions] = sess.run(prediction, feed_dict={x_data: x_vals,\n                                                     y_target: np.transpose([y_vals]),\n                                                     prediction_grid: grid_points})\ngrid_predictions = grid_predictions.reshape(xx.shape)\n\n# Plot points and grid\nplt.contourf(xx, yy, grid_predictions, cmap=plt.cm.Paired, alpha=0.8)\nplt.plot(class1_x, class1_y, 'ro', label='I. setosa')\nplt.plot(class2_x, class2_y, 'kx', label='Non setosa')\nplt.title('Gaussian SVM Results on Iris Data')\nplt.xlabel('Petal Length')\nplt.ylabel('Sepal Width')\nplt.legend(loc='lower right')\nplt.ylim([-0.5, 3.0])\nplt.xlim([3.5, 8.5])\nplt.show()\n\n# Plot batch accuracy\nplt.plot(batch_accuracy, 'k-', label='Accuracy')\nplt.title('Batch Accuracy')\nplt.xlabel('Generation')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.show()\n\n# Plot loss over time\nplt.plot(loss_vec, 'k-')\nplt.title('Loss per Generation')\nplt.xlabel('Generation')\nplt.ylabel('Loss')\nplt.show()\n</code></pre>\n\n<p>The error obtained is:</p>\n\n<pre><code>File \"test.py\", line 154, in &lt;module&gt;\n    prediction_grid: grid_points})\nValueError: Cannot feed value of shape (30119320, 2) for Tensor u'Placeholder_2:0', which has shape '(?, 8)'\n</code></pre>\n\n<p>I know they do not have the same shape but I do not know how to change it or what to do because I need to make a classifier with the 8 features and with the two classes, 'neutral' and 'fear'.</p>\n\n<p>Original code is <a href=\"https://github.com/nfmcclure/tensorflow_cookbook/blob/master/04_Support_Vector_Machines/05_Implementing_Nonlinear_SVMs/05_nonlinear_svm.ipynb\" rel=\"nofollow noreferrer\">here</a>.</p>\n <classification><tensorflow><svm><p>This code is written only for 2D inputs, it cannot be used for 8D inputs.</p>\n\n<p>Here is <a href=\"https://stackoverflow.com/a/49497004/5341713\">an example</a> on stackoverflow for tensorflow's SVM <code>tf.contrib.learn.SVM</code>.</p>\n\n<p>Also, here is an easy to use <a href=\"https://scikit-learn.org/stable/modules/svm.html\" rel=\"nofollow noreferrer\">SVM example</a> in python (without tensorflow).</p>\n\n<p><strong>About the code</strong></p>\n\n<p>The 2D assumption is deeply integrated into the code for <code>prediction_grid</code> variable and the plots. </p>\n\n<p>An important section is when a grid needs to be created:</p>\n\n<pre><code>x_min, x_max = x_vals[:, 0].min() - 1, x_vals[:, 0].max() + 1\ny_min, y_max = x_vals[:, 1].min() - 1, x_vals[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n                     np.arange(y_min, y_max, 0.02))\ngrid_points = np.c_[xx.ravel(), yy.ravel()]\n</code></pre>\n\n<p>which creates a <span class=\"math-container\">$150^2 \\times 2$</span> <code>grid_points</code>. This grid is later used for 2D plots. Since <code>grid_points</code> size is <span class=\"math-container\">$150^d \\times d$</span>, it raises <code>MemoryError</code> for 8D (even for 4D).</p>\n\n<p>Here is an altered version of the code that I used to experiment with higher dimensions. It avoids <code>Memory Error</code> by changing the grid step from 0.02 to 1, thus decreasing <span class=\"math-container\">$150^d$</span> to <span class=\"math-container\">$3^d$</span> (increase the <code>grid_step</code> for wider ranges of inputs).</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndimension = 8\nN = 300\ngrid_step = 1  # default value was 0.02\n\nx_dummy = np.random.random((N, dimension))\ny_dummy = np.random.choice(['fear', 'abc'], (N, 1))\nmatrix = np.hstack((x_dummy, y_dummy))\n\n## SVM con Tensorflow\nsess = tf.Session()\nx_vals = np.array([x[0:dimension] for x in matrix])\ny_vals = np.array([1 if y[dimension] == 'fear' else -1 for y in matrix])\n\n# Split the train data and testing data\ntrain_indices = np.random.choice(len(x_vals), int(round(len(x_vals)*0.8)), replace=False)\ntest_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\nx_vals_train = x_vals[train_indices]\nx_vals_test = x_vals[test_indices]\ny_vals_train = y_vals[train_indices]\ny_vals_test = y_vals[test_indices]\n\nclass1_x = [x[0] for i, x in enumerate(x_vals_train) if y_vals_train[i] == 1]\nclass1_y = [x[1] for i, x in enumerate(x_vals_train) if y_vals_train[i] == 1]\nclass2_x = [x[0] for i, x in enumerate(x_vals_train) if y_vals_train[i] == -1]\nclass2_y = [x[1] for i, x in enumerate(x_vals_train) if y_vals_train[i] == -1]\n\n# Declare batch size\nbatch_size = N\n\n# Initialize placeholders\nx_data = tf.placeholder(shape=[None, dimension], dtype=tf.float32)\ny_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\nprediction_grid = tf.placeholder(shape=[None, dimension], dtype=tf.float32)\n\n# Create variables for svm\nb = tf.Variable(tf.random_normal(shape=[1, batch_size]))\n\n# Gaussian (RBF) kernel\ngamma = tf.constant(-10.0)\nsq_dists = tf.multiply(2., tf.matmul(x_data, tf.transpose(x_data)))\nmy_kernel = tf.exp(tf.multiply(gamma, tf.abs(sq_dists)))\n\n# Compute SVM Model\nfirst_term = tf.reduce_sum(b)\nb_vec_cross = tf.matmul(tf.transpose(b), b)\ny_target_cross = tf.matmul(y_target, tf.transpose(y_target))\nsecond_term = tf.reduce_sum(tf.multiply(my_kernel, tf.multiply(b_vec_cross, y_target_cross)))\nloss = tf.negative(tf.subtract(first_term, second_term))\n\n# Gaussian (RBF) prediction kernel\nrA = tf.reshape(tf.reduce_sum(tf.square(x_data), 1), [-1, 1])\nrB = tf.reshape(tf.reduce_sum(tf.square(prediction_grid), 1), [-1, 1])\npred_sq_dist = tf.add(tf.subtract(rA, tf.multiply(2., tf.matmul(x_data, tf.transpose(prediction_grid)))), tf.transpose(rB))\npred_kernel = tf.exp(tf.multiply(gamma, tf.abs(pred_sq_dist)))\n\nprediction_output = tf.matmul(tf.multiply(tf.transpose(y_target), b), pred_kernel)\nprediction = tf.sign(prediction_output - tf.reduce_mean(prediction_output))\naccuracy = tf.reduce_mean(tf.cast(tf.equal(tf.squeeze(prediction), tf.squeeze(y_target)), tf.float32))\n\n# Declare optimizer\nmy_opt = tf.train.GradientDescentOptimizer(0.01)\ntrain_step = my_opt.minimize(loss)\n\n# Initialize variables\ninit = tf.global_variables_initializer()\nsess.run(init)\n\n# Training loop\nloss_vec = []\nbatch_accuracy = []\nfor i in range(300):\n    rand_index = np.random.choice(len(x_vals), size=batch_size)\n    rand_x = x_vals[rand_index]\n    rand_y = np.transpose([y_vals[rand_index]])\n    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n\n    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n    loss_vec.append(temp_loss)\n\n    acc_temp = sess.run(accuracy, feed_dict={x_data: rand_x,\n                                             y_target: rand_y,\n                                             prediction_grid: rand_x})\n    batch_accuracy.append(acc_temp)\n\n    if (i + 1) % 75 == 0:\n        print('Step #' + str(i + 1))\n        print('Loss = ' + str(temp_loss))\n\n# Create a mesh to plot points in\nx_vals = x_vals.astype(np.float)\n# this code is used as a generalization to work with all dimensions\nx_ranges = np.vstack((x_vals.min(axis=0) - 1, x_vals.max(axis=0) + 1)).T\naranges = [np.arange(x_range[0], x_range[1], grid_step) for x_range in x_ranges]\nprint('grid size:', np.power(len(aranges[0]), dimension))\nmeshes = np.meshgrid(*aranges)\ngrid_points = np.vstack(tuple([mesh.ravel() for mesh in meshes])).T\nprint('grid size:', grid_points.shape)\n[grid_predictions] = sess.run(prediction, feed_dict={x_data: x_vals,\n                                                     y_target: np.transpose([y_vals]),\n                                                     prediction_grid: grid_points})\n\n# Plot points and grid\n# this is the old mesh generation code that is kept since it is used in the plots\nx_min, x_max = x_vals[:, 0].min() - 1, x_vals[:, 0].max() + 1\ny_min, y_max = x_vals[:, 1].min() - 1, x_vals[:, 1].max() + 1\nxx_arange = np.arange(x_min, x_max, grid_step)\nyy_arange = np.arange(y_min, y_max, grid_step)\nxx, yy = np.meshgrid(xx_arange,yy_arange)\nsize = np.power(len(xx), 2)\ngrid_predictions = grid_predictions[0:size].reshape(xx.shape)\n\nplt.contourf(xx, yy, grid_predictions, cmap=plt.cm.Paired, alpha=0.8)\nplt.plot(class1_x, class1_y, 'ro', label='I. setosa')\nplt.plot(class2_x, class2_y, 'kx', label='Non setosa')\nplt.title('Gaussian SVM Results on Iris Data')\nplt.xlabel('Petal Length')\nplt.ylabel('Sepal Width')\nplt.legend(loc='lower right')\nplt.ylim([-0.5, 3.0])\nplt.xlim([3.5, 8.5])\nplt.show()\n\n# Plot batch accuracy\nplt.plot(batch_accuracy, 'k-', label='Accuracy')\nplt.title('Batch Accuracy')\nplt.xlabel('Generation')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.show()\n\n# Plot loss over time\nplt.plot(loss_vec, 'k-')\nplt.title('Loss per Generation')\nplt.xlabel('Generation')\nplt.ylabel('Loss')\nplt.show()\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>Step #75\nLoss = -251.9497\nStep #150\nLoss = -476.96854\nStep #225\nLoss = -701.92444\nStep #300\nLoss = -927.2843\ngrid size: 6561\ngrid size: (6561, 8)\n</code></pre>\n",
                "codes": [
                    [
                        "x_min, x_max = x_vals[:, 0].min() - 1, x_vals[:, 0].max() + 1\ny_min, y_max = x_vals[:, 1].min() - 1, x_vals[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n                     np.arange(y_min, y_max, 0.02))\ngrid_points = np.c_[xx.ravel(), yy.ravel()]\n",
                        "import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndimension = 8\nN = 300\ngrid_step = 1  # default value was 0.02\n\nx_dummy = np.random.random((N, dimension))\ny_dummy = np.random.choice(['fear', 'abc'], (N, 1))\nmatrix = np.hstack((x_dummy, y_dummy))\n\n## SVM con Tensorflow\nsess = tf.Session()\nx_vals = np.array([x[0:dimension] for x in matrix])\ny_vals = np.array([1 if y[dimension] == 'fear' else -1 for y in matrix])\n\n# Split the train data and testing data\ntrain_indices = np.random.choice(len(x_vals), int(round(len(x_vals)*0.8)), replace=False)\ntest_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\nx_vals_train = x_vals[train_indices]\nx_vals_test = x_vals[test_indices]\ny_vals_train = y_vals[train_indices]\ny_vals_test = y_vals[test_indices]\n\nclass1_x = [x[0] for i, x in enumerate(x_vals_train) if y_vals_train[i] == 1]\nclass1_y = [x[1] for i, x in enumerate(x_vals_train) if y_vals_train[i] == 1]\nclass2_x = [x[0] for i, x in enumerate(x_vals_train) if y_vals_train[i] == -1]\nclass2_y = [x[1] for i, x in enumerate(x_vals_train) if y_vals_train[i] == -1]\n\n# Declare batch size\nbatch_size = N\n\n# Initialize placeholders\nx_data = tf.placeholder(shape=[None, dimension], dtype=tf.float32)\ny_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\nprediction_grid = tf.placeholder(shape=[None, dimension], dtype=tf.float32)\n\n# Create variables for svm\nb = tf.Variable(tf.random_normal(shape=[1, batch_size]))\n\n# Gaussian (RBF) kernel\ngamma = tf.constant(-10.0)\nsq_dists = tf.multiply(2., tf.matmul(x_data, tf.transpose(x_data)))\nmy_kernel = tf.exp(tf.multiply(gamma, tf.abs(sq_dists)))\n\n# Compute SVM Model\nfirst_term = tf.reduce_sum(b)\nb_vec_cross = tf.matmul(tf.transpose(b), b)\ny_target_cross = tf.matmul(y_target, tf.transpose(y_target))\nsecond_term = tf.reduce_sum(tf.multiply(my_kernel, tf.multiply(b_vec_cross, y_target_cross)))\nloss = tf.negative(tf.subtract(first_term, second_term))\n\n# Gaussian (RBF) prediction kernel\nrA = tf.reshape(tf.reduce_sum(tf.square(x_data), 1), [-1, 1])\nrB = tf.reshape(tf.reduce_sum(tf.square(prediction_grid), 1), [-1, 1])\npred_sq_dist = tf.add(tf.subtract(rA, tf.multiply(2., tf.matmul(x_data, tf.transpose(prediction_grid)))), tf.transpose(rB))\npred_kernel = tf.exp(tf.multiply(gamma, tf.abs(pred_sq_dist)))\n\nprediction_output = tf.matmul(tf.multiply(tf.transpose(y_target), b), pred_kernel)\nprediction = tf.sign(prediction_output - tf.reduce_mean(prediction_output))\naccuracy = tf.reduce_mean(tf.cast(tf.equal(tf.squeeze(prediction), tf.squeeze(y_target)), tf.float32))\n\n# Declare optimizer\nmy_opt = tf.train.GradientDescentOptimizer(0.01)\ntrain_step = my_opt.minimize(loss)\n\n# Initialize variables\ninit = tf.global_variables_initializer()\nsess.run(init)\n\n# Training loop\nloss_vec = []\nbatch_accuracy = []\nfor i in range(300):\n    rand_index = np.random.choice(len(x_vals), size=batch_size)\n    rand_x = x_vals[rand_index]\n    rand_y = np.transpose([y_vals[rand_index]])\n    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n\n    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n    loss_vec.append(temp_loss)\n\n    acc_temp = sess.run(accuracy, feed_dict={x_data: rand_x,\n                                             y_target: rand_y,\n                                             prediction_grid: rand_x})\n    batch_accuracy.append(acc_temp)\n\n    if (i + 1) % 75 == 0:\n        print('Step #' + str(i + 1))\n        print('Loss = ' + str(temp_loss))\n\n# Create a mesh to plot points in\nx_vals = x_vals.astype(np.float)\n# this code is used as a generalization to work with all dimensions\nx_ranges = np.vstack((x_vals.min(axis=0) - 1, x_vals.max(axis=0) + 1)).T\naranges = [np.arange(x_range[0], x_range[1], grid_step) for x_range in x_ranges]\nprint('grid size:', np.power(len(aranges[0]), dimension))\nmeshes = np.meshgrid(*aranges)\ngrid_points = np.vstack(tuple([mesh.ravel() for mesh in meshes])).T\nprint('grid size:', grid_points.shape)\n[grid_predictions] = sess.run(prediction, feed_dict={x_data: x_vals,\n                                                     y_target: np.transpose([y_vals]),\n                                                     prediction_grid: grid_points})\n\n# Plot points and grid\n# this is the old mesh generation code that is kept since it is used in the plots\nx_min, x_max = x_vals[:, 0].min() - 1, x_vals[:, 0].max() + 1\ny_min, y_max = x_vals[:, 1].min() - 1, x_vals[:, 1].max() + 1\nxx_arange = np.arange(x_min, x_max, grid_step)\nyy_arange = np.arange(y_min, y_max, grid_step)\nxx, yy = np.meshgrid(xx_arange,yy_arange)\nsize = np.power(len(xx), 2)\ngrid_predictions = grid_predictions[0:size].reshape(xx.shape)\n\nplt.contourf(xx, yy, grid_predictions, cmap=plt.cm.Paired, alpha=0.8)\nplt.plot(class1_x, class1_y, 'ro', label='I. setosa')\nplt.plot(class2_x, class2_y, 'kx', label='Non setosa')\nplt.title('Gaussian SVM Results on Iris Data')\nplt.xlabel('Petal Length')\nplt.ylabel('Sepal Width')\nplt.legend(loc='lower right')\nplt.ylim([-0.5, 3.0])\nplt.xlim([3.5, 8.5])\nplt.show()\n\n# Plot batch accuracy\nplt.plot(batch_accuracy, 'k-', label='Accuracy')\nplt.title('Batch Accuracy')\nplt.xlabel('Generation')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.show()\n\n# Plot loss over time\nplt.plot(loss_vec, 'k-')\nplt.title('Loss per Generation')\nplt.xlabel('Generation')\nplt.ylabel('Loss')\nplt.show()\n",
                        "Step #75\nLoss = -251.9497\nStep #150\nLoss = -476.96854\nStep #225\nLoss = -701.92444\nStep #300\nLoss = -927.2843\ngrid size: 6561\ngrid size: (6561, 8)\n"
                    ]
                ],
                "question_id:": "48624",
                "question_votes:": "1",
                "question_text:": "<p>I have an array of Numpy with the following data, for example:</p>\n\n<pre><code>['13 .398249765480822 ''19 .324784598731966' '80 .98629514090669 '\n\u00a0 '-3.703122956721927e-06' '80 .98629884402965 ''24 .008452881790028'\n\u00a0 '679.6408224307851' '2498.8247399799975', 'fear']\n</code></pre>\n\n<p>And another array of Numpy with the same length and different numbers and another label that is 'neutral'.</p>\n\n<p>The fact is that I'm using the code (Setosa) of Github and other articles to make a binary classifier (fear or neutral) but I get the following error because I do not know how to do so that I take into account all the numbers in the array and not as the code of Setosa, which only takes into account two when performing the mesh.</p>\n\n<pre><code>## SVM con Tensorflow\nsess = tf.Session()\nx_vals = np.array([[x[0], x[1], x[2], x[3], x[4], x[5], x[6], x[7]] for x in matrix])\ny_vals = np.array([1 if y[8] == 'fear' else -1 for y in matrix])\n\n# Split the train data and testing data\ntrain_indices = np.random.choice(len(x_vals), int(round(len(x_vals)*0.8)), replace=False)\ntest_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\nx_vals_train = x_vals[train_indices]\nx_vals_test = x_vals[test_indices]\ny_vals_train = y_vals[train_indices]\ny_vals_test = y_vals[test_indices]\n\nclass1_x = [x[0] for i, x in enumerate(x_vals_train) if y_vals_train[i] == 1]\nclass1_y = [x[1] for i, x in enumerate(x_vals_train) if y_vals_train[i] == 1]\nclass2_x = [x[0] for i, x in enumerate(x_vals_train) if y_vals_train[i] == -1]\nclass2_y = [x[1] for i, x in enumerate(x_vals_train) if y_vals_train[i] == -1]\n\n# Declare batch size\nbatch_size = 150\n\n# Initialize placeholders\nx_data = tf.placeholder(shape=[None, 8], dtype=tf.float32)\ny_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\nprediction_grid = tf.placeholder(shape=[None, 8], dtype=tf.float32)\n\n# Create variables for svm\nb = tf.Variable(tf.random_normal(shape=[1, batch_size]))\n\n# Gaussian (RBF) kernel\ngamma = tf.constant(-10.0)\nsq_dists = tf.multiply(2., tf.matmul(x_data, tf.transpose(x_data)))\nmy_kernel = tf.exp(tf.multiply(gamma, tf.abs(sq_dists)))\n\n# Compute SVM Model\nfirst_term = tf.reduce_sum(b)\nb_vec_cross = tf.matmul(tf.transpose(b), b)\ny_target_cross = tf.matmul(y_target, tf.transpose(y_target))\nsecond_term = tf.reduce_sum(tf.multiply(my_kernel, tf.multiply(b_vec_cross, y_target_cross)))\nloss = tf.negative(tf.subtract(first_term, second_term))\n\n# Gaussian (RBF) prediction kernel\nrA = tf.reshape(tf.reduce_sum(tf.square(x_data), 1), [-1, 1])\nrB = tf.reshape(tf.reduce_sum(tf.square(prediction_grid), 1), [-1, 1])\npred_sq_dist = tf.add(tf.subtract(rA, tf.multiply(2., tf.matmul(x_data, tf.transpose(prediction_grid)))), tf.transpose(rB))\npred_kernel = tf.exp(tf.multiply(gamma, tf.abs(pred_sq_dist)))\n\nprediction_output = tf.matmul(tf.multiply(tf.transpose(y_target), b), pred_kernel)\nprediction = tf.sign(prediction_output - tf.reduce_mean(prediction_output))\naccuracy = tf.reduce_mean(tf.cast(tf.equal(tf.squeeze(prediction), tf.squeeze(y_target)), tf.float32))\n\n# Declare optimizer\nmy_opt = tf.train.GradientDescentOptimizer(0.01)\ntrain_step = my_opt.minimize(loss)\n\n# Initialize variables\ninit = tf.global_variables_initializer()\nsess.run(init)\n\n# Training loop\nloss_vec = []\nbatch_accuracy = []\nfor i in range(300):\n    rand_index = np.random.choice(len(x_vals), size=batch_size)\n    rand_x = x_vals[rand_index]\n    rand_y = np.transpose([y_vals[rand_index]])\n    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n\n    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n    loss_vec.append(temp_loss)\n\n    acc_temp = sess.run(accuracy, feed_dict={x_data: rand_x,\n                                             y_target: rand_y,\n                                             prediction_grid: rand_x})\n    batch_accuracy.append(acc_temp)\n\n    if (i + 1) % 75 == 0:\n        print('Step #' + str(i + 1))\n        print('Loss = ' + str(temp_loss))\n\n# Create a mesh to plot points in\nx_vals = x_vals.astype(np.float)\nx_min, x_max = x_vals[:, 0].min() - 1, x_vals[:, 0].max() + 1\ny_min, y_max = x_vals[:, 1].min() - 1, x_vals[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n                     np.arange(y_min, y_max, 0.02))\ngrid_points = np.c_[xx.ravel(), yy.ravel()]\n[grid_predictions] = sess.run(prediction, feed_dict={x_data: x_vals,\n                                                     y_target: np.transpose([y_vals]),\n                                                     prediction_grid: grid_points})\ngrid_predictions = grid_predictions.reshape(xx.shape)\n\n# Plot points and grid\nplt.contourf(xx, yy, grid_predictions, cmap=plt.cm.Paired, alpha=0.8)\nplt.plot(class1_x, class1_y, 'ro', label='I. setosa')\nplt.plot(class2_x, class2_y, 'kx', label='Non setosa')\nplt.title('Gaussian SVM Results on Iris Data')\nplt.xlabel('Petal Length')\nplt.ylabel('Sepal Width')\nplt.legend(loc='lower right')\nplt.ylim([-0.5, 3.0])\nplt.xlim([3.5, 8.5])\nplt.show()\n\n# Plot batch accuracy\nplt.plot(batch_accuracy, 'k-', label='Accuracy')\nplt.title('Batch Accuracy')\nplt.xlabel('Generation')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.show()\n\n# Plot loss over time\nplt.plot(loss_vec, 'k-')\nplt.title('Loss per Generation')\nplt.xlabel('Generation')\nplt.ylabel('Loss')\nplt.show()\n</code></pre>\n\n<p>The error obtained is:</p>\n\n<pre><code>File \"test.py\", line 154, in &lt;module&gt;\n    prediction_grid: grid_points})\nValueError: Cannot feed value of shape (30119320, 2) for Tensor u'Placeholder_2:0', which has shape '(?, 8)'\n</code></pre>\n\n<p>I know they do not have the same shape but I do not know how to change it or what to do because I need to make a classifier with the 8 features and with the two classes, 'neutral' and 'fear'.</p>\n\n<p>Original code is <a href=\"https://github.com/nfmcclure/tensorflow_cookbook/blob/master/04_Support_Vector_Machines/05_Implementing_Nonlinear_SVMs/05_nonlinear_svm.ipynb\" rel=\"nofollow noreferrer\">here</a>.</p>\n",
                "tags": "<classification><tensorflow><svm>",
                "answers": [
                    [
                        "48628",
                        "2",
                        "48624",
                        "",
                        "",
                        "<p>This code is written only for 2D inputs, it cannot be used for 8D inputs.</p>\n\n<p>Here is <a href=\"https://stackoverflow.com/a/49497004/5341713\">an example</a> on stackoverflow for tensorflow's SVM <code>tf.contrib.learn.SVM</code>.</p>\n\n<p>Also, here is an easy to use <a href=\"https://scikit-learn.org/stable/modules/svm.html\" rel=\"nofollow noreferrer\">SVM example</a> in python (without tensorflow).</p>\n\n<p><strong>About the code</strong></p>\n\n<p>The 2D assumption is deeply integrated into the code for <code>prediction_grid</code> variable and the plots. </p>\n\n<p>An important section is when a grid needs to be created:</p>\n\n<pre><code>x_min, x_max = x_vals[:, 0].min() - 1, x_vals[:, 0].max() + 1\ny_min, y_max = x_vals[:, 1].min() - 1, x_vals[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n                     np.arange(y_min, y_max, 0.02))\ngrid_points = np.c_[xx.ravel(), yy.ravel()]\n</code></pre>\n\n<p>which creates a <span class=\"math-container\">$150^2 \\times 2$</span> <code>grid_points</code>. This grid is later used for 2D plots. Since <code>grid_points</code> size is <span class=\"math-container\">$150^d \\times d$</span>, it raises <code>MemoryError</code> for 8D (even for 4D).</p>\n\n<p>Here is an altered version of the code that I used to experiment with higher dimensions. It avoids <code>Memory Error</code> by changing the grid step from 0.02 to 1, thus decreasing <span class=\"math-container\">$150^d$</span> to <span class=\"math-container\">$3^d$</span> (increase the <code>grid_step</code> for wider ranges of inputs).</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndimension = 8\nN = 300\ngrid_step = 1  # default value was 0.02\n\nx_dummy = np.random.random((N, dimension))\ny_dummy = np.random.choice(['fear', 'abc'], (N, 1))\nmatrix = np.hstack((x_dummy, y_dummy))\n\n## SVM con Tensorflow\nsess = tf.Session()\nx_vals = np.array([x[0:dimension] for x in matrix])\ny_vals = np.array([1 if y[dimension] == 'fear' else -1 for y in matrix])\n\n# Split the train data and testing data\ntrain_indices = np.random.choice(len(x_vals), int(round(len(x_vals)*0.8)), replace=False)\ntest_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\nx_vals_train = x_vals[train_indices]\nx_vals_test = x_vals[test_indices]\ny_vals_train = y_vals[train_indices]\ny_vals_test = y_vals[test_indices]\n\nclass1_x = [x[0] for i, x in enumerate(x_vals_train) if y_vals_train[i] == 1]\nclass1_y = [x[1] for i, x in enumerate(x_vals_train) if y_vals_train[i] == 1]\nclass2_x = [x[0] for i, x in enumerate(x_vals_train) if y_vals_train[i] == -1]\nclass2_y = [x[1] for i, x in enumerate(x_vals_train) if y_vals_train[i] == -1]\n\n# Declare batch size\nbatch_size = N\n\n# Initialize placeholders\nx_data = tf.placeholder(shape=[None, dimension], dtype=tf.float32)\ny_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\nprediction_grid = tf.placeholder(shape=[None, dimension], dtype=tf.float32)\n\n# Create variables for svm\nb = tf.Variable(tf.random_normal(shape=[1, batch_size]))\n\n# Gaussian (RBF) kernel\ngamma = tf.constant(-10.0)\nsq_dists = tf.multiply(2., tf.matmul(x_data, tf.transpose(x_data)))\nmy_kernel = tf.exp(tf.multiply(gamma, tf.abs(sq_dists)))\n\n# Compute SVM Model\nfirst_term = tf.reduce_sum(b)\nb_vec_cross = tf.matmul(tf.transpose(b), b)\ny_target_cross = tf.matmul(y_target, tf.transpose(y_target))\nsecond_term = tf.reduce_sum(tf.multiply(my_kernel, tf.multiply(b_vec_cross, y_target_cross)))\nloss = tf.negative(tf.subtract(first_term, second_term))\n\n# Gaussian (RBF) prediction kernel\nrA = tf.reshape(tf.reduce_sum(tf.square(x_data), 1), [-1, 1])\nrB = tf.reshape(tf.reduce_sum(tf.square(prediction_grid), 1), [-1, 1])\npred_sq_dist = tf.add(tf.subtract(rA, tf.multiply(2., tf.matmul(x_data, tf.transpose(prediction_grid)))), tf.transpose(rB))\npred_kernel = tf.exp(tf.multiply(gamma, tf.abs(pred_sq_dist)))\n\nprediction_output = tf.matmul(tf.multiply(tf.transpose(y_target), b), pred_kernel)\nprediction = tf.sign(prediction_output - tf.reduce_mean(prediction_output))\naccuracy = tf.reduce_mean(tf.cast(tf.equal(tf.squeeze(prediction), tf.squeeze(y_target)), tf.float32))\n\n# Declare optimizer\nmy_opt = tf.train.GradientDescentOptimizer(0.01)\ntrain_step = my_opt.minimize(loss)\n\n# Initialize variables\ninit = tf.global_variables_initializer()\nsess.run(init)\n\n# Training loop\nloss_vec = []\nbatch_accuracy = []\nfor i in range(300):\n    rand_index = np.random.choice(len(x_vals), size=batch_size)\n    rand_x = x_vals[rand_index]\n    rand_y = np.transpose([y_vals[rand_index]])\n    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n\n    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n    loss_vec.append(temp_loss)\n\n    acc_temp = sess.run(accuracy, feed_dict={x_data: rand_x,\n                                             y_target: rand_y,\n                                             prediction_grid: rand_x})\n    batch_accuracy.append(acc_temp)\n\n    if (i + 1) % 75 == 0:\n        print('Step #' + str(i + 1))\n        print('Loss = ' + str(temp_loss))\n\n# Create a mesh to plot points in\nx_vals = x_vals.astype(np.float)\n# this code is used as a generalization to work with all dimensions\nx_ranges = np.vstack((x_vals.min(axis=0) - 1, x_vals.max(axis=0) + 1)).T\naranges = [np.arange(x_range[0], x_range[1], grid_step) for x_range in x_ranges]\nprint('grid size:', np.power(len(aranges[0]), dimension))\nmeshes = np.meshgrid(*aranges)\ngrid_points = np.vstack(tuple([mesh.ravel() for mesh in meshes])).T\nprint('grid size:', grid_points.shape)\n[grid_predictions] = sess.run(prediction, feed_dict={x_data: x_vals,\n                                                     y_target: np.transpose([y_vals]),\n                                                     prediction_grid: grid_points})\n\n# Plot points and grid\n# this is the old mesh generation code that is kept since it is used in the plots\nx_min, x_max = x_vals[:, 0].min() - 1, x_vals[:, 0].max() + 1\ny_min, y_max = x_vals[:, 1].min() - 1, x_vals[:, 1].max() + 1\nxx_arange = np.arange(x_min, x_max, grid_step)\nyy_arange = np.arange(y_min, y_max, grid_step)\nxx, yy = np.meshgrid(xx_arange,yy_arange)\nsize = np.power(len(xx), 2)\ngrid_predictions = grid_predictions[0:size].reshape(xx.shape)\n\nplt.contourf(xx, yy, grid_predictions, cmap=plt.cm.Paired, alpha=0.8)\nplt.plot(class1_x, class1_y, 'ro', label='I. setosa')\nplt.plot(class2_x, class2_y, 'kx', label='Non setosa')\nplt.title('Gaussian SVM Results on Iris Data')\nplt.xlabel('Petal Length')\nplt.ylabel('Sepal Width')\nplt.legend(loc='lower right')\nplt.ylim([-0.5, 3.0])\nplt.xlim([3.5, 8.5])\nplt.show()\n\n# Plot batch accuracy\nplt.plot(batch_accuracy, 'k-', label='Accuracy')\nplt.title('Batch Accuracy')\nplt.xlabel('Generation')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.show()\n\n# Plot loss over time\nplt.plot(loss_vec, 'k-')\nplt.title('Loss per Generation')\nplt.xlabel('Generation')\nplt.ylabel('Loss')\nplt.show()\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>Step #75\nLoss = -251.9497\nStep #150\nLoss = -476.96854\nStep #225\nLoss = -701.92444\nStep #300\nLoss = -927.2843\ngrid size: 6561\ngrid size: (6561, 8)\n</code></pre>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9357",
            "_score": 6.5963306,
            "_source": {
                "title": "How to resolve too many indices for array Index Error",
                "content": "How to resolve too many indices for array Index Error <p>I'm performing a binary classification in Keras and attempting to plot the ROC curves. When I tried to compute the fpr and tpr metrics, I get the \"too many indices for array\" error. Here is my code:</p>\n\n<pre><code>#declare the number of classes\nnum_classes=2\n#predicted labels\ny_pred = model.predict_generator(test_generator, nb_test_samples/batch_size, workers=1)\n#true labels\nY_test=test_generator.classes\n#print the predicted and true labels\nprint(y_pred)\nprint(Y_test)\n'''y_pred float32 (624,2) array([[9.99e-01  2.59e-04],\n                                 [9.97e-01  2.91e-03],...'''\n\n'''Y_test int32 (624,) array([0,0,0,...,1,1,1],dtype=int32)'''\n\n#reshape the predicted labels and convert type\ny_pred = y_pred.argmax(axis=-1)\ny_pred = y_pred.astype('int32')\n\n#plot ROC curve\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(Y_test[:,i], y_pred[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\nfig=plt.figure(figsize=(15,10), dpi=100)\nax = fig.add_subplot(1, 1, 1)\n# Major ticks every 0.05, minor ticks every 0.05\nmajor_ticks = np.arange(0.0, 1.0, 0.05)\nminor_ticks = np.arange(0.0, 1.0, 0.05)\nax.set_xticks(major_ticks)\nax.set_xticks(minor_ticks, minor=True)\nax.set_yticks(major_ticks)\nax.set_yticks(minor_ticks, minor=True)\nax.grid(which='both')\nlw = 1 \nplt.plot(fpr[1], tpr[1], color='red',\n         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\nplt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristics')\nplt.legend(loc=\"lower right\")\nplt.show()\n</code></pre>\n\n<p>The shape of y-pred and Y_test are:</p>\n\n<p>y_pred float32 (624,2) array([[9.99e-01 2.59e-04],\n                                 [9.97e-01  2.91e-03],...</p>\n\n<p>Y_test int32 (624,) array([0,0,0,...,1,1,1],dtype=int32)</p>\n <keras><image-classification><indexing><p>Your code is broken in two places.</p>\n\n<p>The first is because you took the argmax of your class probabilities from <code>y_pred</code>. The line</p>\n\n<p><code>y_pred = y_pred.argmax(axis=-1)</code> </p>\n\n<p>reshapes your prediction vector into <code>(624,)</code> to match your vector of classes. Thus, when you try to slice your array later with <code>y_pred[:,i]</code> it's going to bark since you no longer have a second dimension. This isn't really the behavior you want either, since the <code>roc_curve</code> function is interested in the exact class probabilities your model produces!</p>\n\n<p>The second is for the same reason, attempting to index the second dimension of  a one dimensional numpy array, but for the <code>Y_test</code> vector.</p>\n\n<p>So if you're interested in capturing TPR/FPR for both classes by treating each as the positive class, you need to drop these lines</p>\n\n<pre><code>#reshape the predicted labels and convert type\ny_pred = y_pred.argmax(axis=-1)\ny_pred = y_pred.astype('int32')\n</code></pre>\n\n<p>and you need to change the first line of your for loop to:</p>\n\n<p><code>fpr[i], tpr[i], _ = roc_curve(Y_test, y_pred[:, i])</code></p>\n\n<p>hope this helps</p>\n",
                "codes": [
                    [
                        "#reshape the predicted labels and convert type\ny_pred = y_pred.argmax(axis=-1)\ny_pred = y_pred.astype('int32')\n"
                    ]
                ],
                "question_id:": "33377",
                "question_votes:": "1",
                "question_text:": "<p>I'm performing a binary classification in Keras and attempting to plot the ROC curves. When I tried to compute the fpr and tpr metrics, I get the \"too many indices for array\" error. Here is my code:</p>\n\n<pre><code>#declare the number of classes\nnum_classes=2\n#predicted labels\ny_pred = model.predict_generator(test_generator, nb_test_samples/batch_size, workers=1)\n#true labels\nY_test=test_generator.classes\n#print the predicted and true labels\nprint(y_pred)\nprint(Y_test)\n'''y_pred float32 (624,2) array([[9.99e-01  2.59e-04],\n                                 [9.97e-01  2.91e-03],...'''\n\n'''Y_test int32 (624,) array([0,0,0,...,1,1,1],dtype=int32)'''\n\n#reshape the predicted labels and convert type\ny_pred = y_pred.argmax(axis=-1)\ny_pred = y_pred.astype('int32')\n\n#plot ROC curve\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(Y_test[:,i], y_pred[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\nfig=plt.figure(figsize=(15,10), dpi=100)\nax = fig.add_subplot(1, 1, 1)\n# Major ticks every 0.05, minor ticks every 0.05\nmajor_ticks = np.arange(0.0, 1.0, 0.05)\nminor_ticks = np.arange(0.0, 1.0, 0.05)\nax.set_xticks(major_ticks)\nax.set_xticks(minor_ticks, minor=True)\nax.set_yticks(major_ticks)\nax.set_yticks(minor_ticks, minor=True)\nax.grid(which='both')\nlw = 1 \nplt.plot(fpr[1], tpr[1], color='red',\n         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\nplt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristics')\nplt.legend(loc=\"lower right\")\nplt.show()\n</code></pre>\n\n<p>The shape of y-pred and Y_test are:</p>\n\n<p>y_pred float32 (624,2) array([[9.99e-01 2.59e-04],\n                                 [9.97e-01  2.91e-03],...</p>\n\n<p>Y_test int32 (624,) array([0,0,0,...,1,1,1],dtype=int32)</p>\n",
                "tags": "<keras><image-classification><indexing>",
                "answers": [
                    [
                        "33387",
                        "2",
                        "33377",
                        "",
                        "",
                        "<p>Your code is broken in two places.</p>\n\n<p>The first is because you took the argmax of your class probabilities from <code>y_pred</code>. The line</p>\n\n<p><code>y_pred = y_pred.argmax(axis=-1)</code> </p>\n\n<p>reshapes your prediction vector into <code>(624,)</code> to match your vector of classes. Thus, when you try to slice your array later with <code>y_pred[:,i]</code> it's going to bark since you no longer have a second dimension. This isn't really the behavior you want either, since the <code>roc_curve</code> function is interested in the exact class probabilities your model produces!</p>\n\n<p>The second is for the same reason, attempting to index the second dimension of  a one dimensional numpy array, but for the <code>Y_test</code> vector.</p>\n\n<p>So if you're interested in capturing TPR/FPR for both classes by treating each as the positive class, you need to drop these lines</p>\n\n<pre><code>#reshape the predicted labels and convert type\ny_pred = y_pred.argmax(axis=-1)\ny_pred = y_pred.astype('int32')\n</code></pre>\n\n<p>and you need to change the first line of your for loop to:</p>\n\n<p><code>fpr[i], tpr[i], _ = roc_curve(Y_test, y_pred[:, i])</code></p>\n\n<p>hope this helps</p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14767",
            "_score": 6.5963306,
            "_source": {
                "title": "Something is disastrously wrong with my neural network and what it's produced",
                "content": "Something is disastrously wrong with my neural network and what it's produced <p>I just got a neural network to run and although it doesn't raise any exceptions, I'm left with a horrible mess after 80 to 100 epochs: </p>\n\n<p>After 100 epochs with the adapted code: <img src=\"https://i.imgur.com/hQEuYGm.png\" alt=\"After 100 epochs\"></p>\n\n<p>After 100 epochs with the original code: <img src=\"https://i.imgur.com/ZeUgiYV.png\" alt=\"After 100 epochs\"></p>\n\n<p>I am trying to generate a grid of synthetic images of cats from my own database of cat photos that I compiled using a crawler. I am using an adapted code originally intended for the MNSIT handwritten digits database (hence the shape of the grid). </p>\n\n<p>The network doesn't appear to be training, generating or discriminating properly because the epochs aren't taking long at all and what is being produced is very poor.</p>\n\n<p>To be clear, I've tried to adapt another author's code that I found online and I've added other snippets of code to try to get it to work. It's evident that my 'FrankenNet' has fallen to bits and my 'bolt it together and see what happens' approach has its limitations. </p>\n\n<p>Maybe I haven't loaded in the data correctly or perhaps there are a few other issues such as converting the data to a numpy array?</p>\n\n<p>I'd love some advice because I really want to generate something and I've spent a long time trying to work it out through trial and error with no results. I'd especially appreciate some specific suggestions about what lines I need to change, add or remove to get this beast up to scratch. </p>\n\n<p>Firstly, I have removed keras.datasets because I am not working with their database. </p>\n\n<p>Original code:</p>\n\n<pre><code>from keras.layers.advanced_activations import LeakyReLU\nfrom keras.datasets import mnist\n</code></pre>\n\n<p>Adapted GAN:</p>\n\n<pre><code>from keras.layers.advanced_activations import LeakyReLU\nfrom keras.optimizers import Adam\n</code></pre>\n\n<p>This is how the data is loaded from MNIST in the original GAN: </p>\n\n<pre><code>def load_minst_data():\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    x_train = (x_train.astype(np.float32) - 127.5)/127.5\n    x_train = x_train.reshape(60000, 784)\n    return (x_train, y_train, x_test, y_test)\n</code></pre>\n\n<p>And this is what I have replaced it with to try to load and train my own JPGs: </p>\n\n<pre><code>from os import listdir\nfrom PIL import Image as PImage\n\ndef loadImages(path):\n    # return array of images\n    imagesList = listdir(path)\n    loadedImages = []\n    for image in imagesList:\n        img = PImage.open(path + image)\n        loadedImages.append(img)\n    return loadedImages\n\nDATASET_NAME = 'catscats'\nROOT_DIR = '/Users/Darren/desktop'\nDATASET_DIR = f'{ROOT_DIR}/{DATASET_NAME}'\n input_files = [os.path.join(dp, f) for dp, dn, fn in \n os.walk(os.path.expanduser(f'{DATASET_DIR}/processed')) for f in fn\n               if f != '.DS_Store']\nimgs = np.ndarray(shape=(len(input_files), 100, 100, 3),\n                  dtype=np.int)\nfor i, input_file in enumerate(input_files):\n    # print('processing file: {}'.format(input_file))\n    image = imread(input_file)\n    imgs[i] = image\n    # your images in an array\n    imgs = loadImages(path)\n\n def loadImages():\n    (x_train, y_train), (x_test, y_test) = input_file\n    x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n    x_train = x_train.reshape(60000, 784)\n    return (x_train, y_train, x_test, y_test)\n</code></pre>\n <python><keras><tensorflow><gan>",
                "codes": [],
                "question_id:": "49446",
                "question_votes:": "1",
                "question_text:": "<p>I just got a neural network to run and although it doesn't raise any exceptions, I'm left with a horrible mess after 80 to 100 epochs: </p>\n\n<p>After 100 epochs with the adapted code: <img src=\"https://i.imgur.com/hQEuYGm.png\" alt=\"After 100 epochs\"></p>\n\n<p>After 100 epochs with the original code: <img src=\"https://i.imgur.com/ZeUgiYV.png\" alt=\"After 100 epochs\"></p>\n\n<p>I am trying to generate a grid of synthetic images of cats from my own database of cat photos that I compiled using a crawler. I am using an adapted code originally intended for the MNSIT handwritten digits database (hence the shape of the grid). </p>\n\n<p>The network doesn't appear to be training, generating or discriminating properly because the epochs aren't taking long at all and what is being produced is very poor.</p>\n\n<p>To be clear, I've tried to adapt another author's code that I found online and I've added other snippets of code to try to get it to work. It's evident that my 'FrankenNet' has fallen to bits and my 'bolt it together and see what happens' approach has its limitations. </p>\n\n<p>Maybe I haven't loaded in the data correctly or perhaps there are a few other issues such as converting the data to a numpy array?</p>\n\n<p>I'd love some advice because I really want to generate something and I've spent a long time trying to work it out through trial and error with no results. I'd especially appreciate some specific suggestions about what lines I need to change, add or remove to get this beast up to scratch. </p>\n\n<p>Firstly, I have removed keras.datasets because I am not working with their database. </p>\n\n<p>Original code:</p>\n\n<pre><code>from keras.layers.advanced_activations import LeakyReLU\nfrom keras.datasets import mnist\n</code></pre>\n\n<p>Adapted GAN:</p>\n\n<pre><code>from keras.layers.advanced_activations import LeakyReLU\nfrom keras.optimizers import Adam\n</code></pre>\n\n<p>This is how the data is loaded from MNIST in the original GAN: </p>\n\n<pre><code>def load_minst_data():\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    x_train = (x_train.astype(np.float32) - 127.5)/127.5\n    x_train = x_train.reshape(60000, 784)\n    return (x_train, y_train, x_test, y_test)\n</code></pre>\n\n<p>And this is what I have replaced it with to try to load and train my own JPGs: </p>\n\n<pre><code>from os import listdir\nfrom PIL import Image as PImage\n\ndef loadImages(path):\n    # return array of images\n    imagesList = listdir(path)\n    loadedImages = []\n    for image in imagesList:\n        img = PImage.open(path + image)\n        loadedImages.append(img)\n    return loadedImages\n\nDATASET_NAME = 'catscats'\nROOT_DIR = '/Users/Darren/desktop'\nDATASET_DIR = f'{ROOT_DIR}/{DATASET_NAME}'\n input_files = [os.path.join(dp, f) for dp, dn, fn in \n os.walk(os.path.expanduser(f'{DATASET_DIR}/processed')) for f in fn\n               if f != '.DS_Store']\nimgs = np.ndarray(shape=(len(input_files), 100, 100, 3),\n                  dtype=np.int)\nfor i, input_file in enumerate(input_files):\n    # print('processing file: {}'.format(input_file))\n    image = imread(input_file)\n    imgs[i] = image\n    # your images in an array\n    imgs = loadImages(path)\n\n def loadImages():\n    (x_train, y_train), (x_test, y_test) = input_file\n    x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n    x_train = x_train.reshape(60000, 784)\n    return (x_train, y_train, x_test, y_test)\n</code></pre>\n",
                "tags": "<python><keras><tensorflow><gan>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16679",
            "_score": 6.5963306,
            "_source": {
                "title": "Input tensor for CNN should be of shape (n_rows, n_timeSteps, n_features) or (n_rows, n_features, n_timeSteps)?",
                "content": "Input tensor for CNN should be of shape (n_rows, n_timeSteps, n_features) or (n_rows, n_features, n_timeSteps)? <p>I have a regression task in which I want to predict the value y based on X values (with 4 features X1, X2, X3 and X4). For demonstration purposes I generate some random data:</p>\n\n<pre><code>import numpy as np\nfrom keras.layers.core import Dense\nfrom keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dropout\nfrom keras.optimizers import RMSprop\nfrom keras.models import Model\n\noptimizer = RMSprop(lr=0.001)\n\ny = np.random.rand(1000)\nX = np.random.rand(1000,4)\n</code></pre>\n\n<p>I can re-frame my input data in 2 different ways:</p>\n\n<pre><code>input_shape = X.shape\nX_reshaped_1 = X.reshape(input_shape[0], 1, 4)\nX_reshaped_2 = X.reshape(input_shape[0], 4, 1)\n</code></pre>\n\n<p>From <a href=\"https://datascience.stackexchange.com/a/38969/57691\">this</a> answer, <code>X_reshaped_2</code> is supposedly correct.\nAlso from <a href=\"https://machinelearningmastery.com/cnn-models-for-human-activity-recognition-time-series-classification/\" rel=\"nofollow noreferrer\">this</a> link, <code>X_reshaped_1</code> is used. If I want to create a model for <code>X_reshaped_1</code>, I would do :</p>\n\n<pre><code>input_tensor = Input(shape=(1, 4))\nlayer = Conv1D(filters=32, kernel_size=2, \n               activation='relu', padding='same')(input_tensor)\nlayer = Conv1D(filters = 64, kernel_size=3, \n               activation='relu', padding='same')(layer)\nlayer = Dropout(0.5)(layer)\nlayer = Flatten()(layer)\nlayer = Dense(10, activation='linear')(layer)\noutput_tensor = Dense(units=1, activation='linear')(layer)\n\n\nmodel = Model(input_tensor, output_tensor)\nmodel.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse', 'mae', 'mape'] )\nprint(model.summary())\n</code></pre>\n\n<p>which prints:</p>\n\n<pre><code>Layer (type)                 Output Shape              Param #   \n=================================================================\ninput_31 (InputLayer)        (None, 1, 4)              0         \n_________________________________________________________________\nconv1d_65 (Conv1D)           (None, 1, 32)             288       \n_________________________________________________________________\nconv1d_66 (Conv1D)           (None, 1, 64)             6208      \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 1, 64)             0         \n_________________________________________________________________\nflatten_24 (Flatten)         (None, 64)                0         \n_________________________________________________________________\ndense_43 (Dense)             (None, 10)                650       \n_________________________________________________________________\ndense_44 (Dense)             (None, 1)                 11        \n=================================================================\nTotal params: 7,157\nTrainable params: 7,157\nNon-trainable params: 0\n</code></pre>\n\n<p>If I use <code>X_reshaped_2</code> as input data, I would create a model like this:</p>\n\n<pre><code>input_tensor = Input(shape=(4, 1))\nlayer = Conv1D(filters=32, kernel_size=2, activation='relu')(input_tensor)\nlayer = Conv1D(filters = 64, kernel_size=3, activation='relu')(layer)\nlayer = Dropout(0.5)(layer)\nlayer = Flatten()(layer)\nlayer = Dense(10, activation='linear' )(layer)\noutput_tensor = Dense(units=1, activation='linear')(layer)\n\n\nmodel = Model(input_tensor, output_tensor)\nmodel.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse', 'mae', 'mape'] )\nprint(model.summary())\n</code></pre>\n\n<p>which prints:</p>\n\n<pre><code>Layer (type)                 Output Shape              Param #   \n=================================================================\ninput_34 (InputLayer)        (None, 4, 1)              0         \n_________________________________________________________________\nconv1d_71 (Conv1D)           (None, 3, 32)             96        \n_________________________________________________________________\nconv1d_72 (Conv1D)           (None, 1, 64)             6208      \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 1, 64)             0         \n_________________________________________________________________\nflatten_27 (Flatten)         (None, 64)                0         \n_________________________________________________________________\ndense_49 (Dense)             (None, 10)                650       \n_________________________________________________________________\ndense_50 (Dense)             (None, 1)                 11        \n=================================================================\nTotal params: 6,965\nTrainable params: 6,965\nNon-trainable params: 0\n</code></pre>\n\n<p>I have tried both models on my data and both are to some extent desirable. </p>\n\n<p>My question is:</p>\n\n<ol>\n<li><p>How these models learn? Specially, the model which uses <code>X_reshaped_1</code> seems odd to me, compared to <code>X_reshaped_2</code> which is a more typical use case of <code>CNN</code>s.</p></li>\n<li><p>Is using both models correct?</p></li>\n</ol>\n <python><keras><regression><cnn>",
                "codes": [],
                "question_id:": "54636",
                "question_votes:": "",
                "question_text:": "<p>I have a regression task in which I want to predict the value y based on X values (with 4 features X1, X2, X3 and X4). For demonstration purposes I generate some random data:</p>\n\n<pre><code>import numpy as np\nfrom keras.layers.core import Dense\nfrom keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dropout\nfrom keras.optimizers import RMSprop\nfrom keras.models import Model\n\noptimizer = RMSprop(lr=0.001)\n\ny = np.random.rand(1000)\nX = np.random.rand(1000,4)\n</code></pre>\n\n<p>I can re-frame my input data in 2 different ways:</p>\n\n<pre><code>input_shape = X.shape\nX_reshaped_1 = X.reshape(input_shape[0], 1, 4)\nX_reshaped_2 = X.reshape(input_shape[0], 4, 1)\n</code></pre>\n\n<p>From <a href=\"https://datascience.stackexchange.com/a/38969/57691\">this</a> answer, <code>X_reshaped_2</code> is supposedly correct.\nAlso from <a href=\"https://machinelearningmastery.com/cnn-models-for-human-activity-recognition-time-series-classification/\" rel=\"nofollow noreferrer\">this</a> link, <code>X_reshaped_1</code> is used. If I want to create a model for <code>X_reshaped_1</code>, I would do :</p>\n\n<pre><code>input_tensor = Input(shape=(1, 4))\nlayer = Conv1D(filters=32, kernel_size=2, \n               activation='relu', padding='same')(input_tensor)\nlayer = Conv1D(filters = 64, kernel_size=3, \n               activation='relu', padding='same')(layer)\nlayer = Dropout(0.5)(layer)\nlayer = Flatten()(layer)\nlayer = Dense(10, activation='linear')(layer)\noutput_tensor = Dense(units=1, activation='linear')(layer)\n\n\nmodel = Model(input_tensor, output_tensor)\nmodel.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse', 'mae', 'mape'] )\nprint(model.summary())\n</code></pre>\n\n<p>which prints:</p>\n\n<pre><code>Layer (type)                 Output Shape              Param #   \n=================================================================\ninput_31 (InputLayer)        (None, 1, 4)              0         \n_________________________________________________________________\nconv1d_65 (Conv1D)           (None, 1, 32)             288       \n_________________________________________________________________\nconv1d_66 (Conv1D)           (None, 1, 64)             6208      \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 1, 64)             0         \n_________________________________________________________________\nflatten_24 (Flatten)         (None, 64)                0         \n_________________________________________________________________\ndense_43 (Dense)             (None, 10)                650       \n_________________________________________________________________\ndense_44 (Dense)             (None, 1)                 11        \n=================================================================\nTotal params: 7,157\nTrainable params: 7,157\nNon-trainable params: 0\n</code></pre>\n\n<p>If I use <code>X_reshaped_2</code> as input data, I would create a model like this:</p>\n\n<pre><code>input_tensor = Input(shape=(4, 1))\nlayer = Conv1D(filters=32, kernel_size=2, activation='relu')(input_tensor)\nlayer = Conv1D(filters = 64, kernel_size=3, activation='relu')(layer)\nlayer = Dropout(0.5)(layer)\nlayer = Flatten()(layer)\nlayer = Dense(10, activation='linear' )(layer)\noutput_tensor = Dense(units=1, activation='linear')(layer)\n\n\nmodel = Model(input_tensor, output_tensor)\nmodel.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse', 'mae', 'mape'] )\nprint(model.summary())\n</code></pre>\n\n<p>which prints:</p>\n\n<pre><code>Layer (type)                 Output Shape              Param #   \n=================================================================\ninput_34 (InputLayer)        (None, 4, 1)              0         \n_________________________________________________________________\nconv1d_71 (Conv1D)           (None, 3, 32)             96        \n_________________________________________________________________\nconv1d_72 (Conv1D)           (None, 1, 64)             6208      \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 1, 64)             0         \n_________________________________________________________________\nflatten_27 (Flatten)         (None, 64)                0         \n_________________________________________________________________\ndense_49 (Dense)             (None, 10)                650       \n_________________________________________________________________\ndense_50 (Dense)             (None, 1)                 11        \n=================================================================\nTotal params: 6,965\nTrainable params: 6,965\nNon-trainable params: 0\n</code></pre>\n\n<p>I have tried both models on my data and both are to some extent desirable. </p>\n\n<p>My question is:</p>\n\n<ol>\n<li><p>How these models learn? Specially, the model which uses <code>X_reshaped_1</code> seems odd to me, compared to <code>X_reshaped_2</code> which is a more typical use case of <code>CNN</code>s.</p></li>\n<li><p>Is using both models correct?</p></li>\n</ol>\n",
                "tags": "<python><keras><regression><cnn>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8844",
            "_score": 6.581239,
            "_source": {
                "title": "Training an LSTM to track sine waves",
                "content": "Training an LSTM to track sine waves <p>I'm experimenting (read: playing around) with LSTMs on Keras. \nI want to train an LSTM network so it would \"track\" sine waves, that is, given sine waves with different wave length, phases and lengths, it would output the rest of wave. \nIn a sense, a many-to-many problem.</p>\n\n<p>I decided that the network would need to \"track\" 5 sine waves simultaneously. \nI would generate random sine waves and use the 50 last data points as the required output of the NN.</p>\n\n<p>My code is a follows:</p>\n\n<pre><code>from keras.models import Sequential\nfrom keras.layers import LSTM, Dense, TimeDistributed,Lambda, Dropout\nimport numpy as np\n\nmodel = Sequential()\n\nmodel.add(LSTM(32, return_sequences=True, input_shape=(None, 5)))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(5, return_sequences=True))\nmodel.add(Lambda(lambda x: x[:, -50:, :])) # Grab only the last 50 values\n\n\n\nprint(model.summary())\n\nmodel.compile(loss='mean_squared_error',\n              optimizer='adam')\n\n\ndef make_line(length):\n    shift= np.random.random()\n    wavelength = 5+10*np.random.random()\n    a=np.arange(length)\n    answer=np.sin(a/wavelength+shift)\n    return answer\n\n\n\n\ndef make_data(seq_num,seq_len,dim):\n    data=np.array([]).reshape(0,seq_len,dim)\n    for i in range (seq_num):\n        mini_data=np.array([]).reshape(0,seq_len)\n        for j in range (dim):\n            line = make_line(seq_len)\n            line=line.reshape(1,seq_len)            \n            mini_data=np.append(mini_data,line,axis=0)\n        mini_data=np.swapaxes(mini_data,1,0)\n        mini_data=mini_data.reshape(1,seq_len,dim)      \n        data=np.append(data,mini_data,axis=0)\n    return (data)\n\n\n\ndef train_generator():\n    while True:\n        sequence_length = np.random.randint(50, 150)+50     \n        data=make_data(1000,sequence_length,5)\n        x_train = data[:,:-50,:] # all but last 50      \n        y_train = (data[:, -50:, :]) # last 50      \n        yield x_train, y_train\n\n\nmodel.fit_generator(train_generator(), steps_per_epoch=30, epochs=100, verbose=1,validation_data=train_generator(),validation_steps=30)\nmodel.save('vi2h_model.h5')\n</code></pre>\n\n<p>I then try to generate data and use the model to predict the continuation of a sine wave:</p>\n\n<pre><code>def data_generator():\n    while True:\n        sequence_length = np.random.randint(50, 150)+50\n        data=make_data(1000,sequence_length,5)\n        x_train = data[:,:-50,:]    \n        y_train = (data[:, -50:, :])                \n        return x_train, y_train\n\n\nx,y= data_generator()   \n\nmodel = load_model('vi2h_model.h5')\npred=model.predict (x)\nnp.save ('pred.npy',pred)\nnp.save ('y.npy',y)\nnp.save ('x.npy',x)\n</code></pre>\n\n<p>When inspecting the ability of the network to predict the continuation of a sine wave (comparing y[0,:,0] to pred[0,:,0] for example, in order to compare the first sine wave of the first generated datum), see that my network performed very badly:</p>\n\n<p><a href=\"https://i.stack.imgur.com/i4qmK.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/i4qmK.jpg\" alt=\"The predicted vs actual 50 last points in a sample sine wave, placed after the part of the wave used as input for the NN\"></a> </p>\n\n<p>(Edit: legend: The predicted vs actual 50 last points in a sample sine wave (blue and orange, respectively), placed after the part of the wave used as input for the NN)</p>\n\n<p>What did I do wrong? And how should I my code to correctly track sine waves?\nMany thanks!</p>\n <python><deep-learning><keras><lstm><p>I have added a dense layer to the network:</p>\n\n<p>model = Sequential()</p>\n\n<pre><code>model.add(LSTM(32, return_sequences=True, input_shape=(None, 5)))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(TimeDistributed(Dense(5)))  # &lt;--- This is new :)\nmodel.add(Activation('linear')) \nmodel.add(Lambda(lambda x: x[:, -50:, :])) # Grab only the last 50 values\n</code></pre>\n\n<p>This has provided some improvement :</p>\n\n<p><a href=\"https://i.stack.imgur.com/5EuKl.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/5EuKl.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>These are two sine waves and the predictions of the last 50 data points of them.\nAs can be seen, the results have improved, with some of them being okay approximations of the sine waves. Other times... not so much.</p>\n\n<p>Still a lot better than the previous results.</p>\n\n<p>I then tried another approach: Instead of having one (multilayered) LSTM, in which I ignore all but the 50 inputs (in a sense trying to predict from each one of the 50 last values the value located 50 places after it... which might not be an ideal approach) I split the network into 2 LSTMs, with one receiving the input and \"injecting\" its results via a dense layer into the second LTSM layer which generates the output.</p>\n\n<pre><code>features_num=5 \n\nmodel.add(LSTM(40, return_sequences=True, input_shape=(None, 5)))\nmodel.add(LSTM(40, return_sequences=False))\n\nmodel.add(Dense(80))\nmodel.add(Activation('tanh')) \nmodel.add(RepeatVector(50)) # 50 output points\n\nmodel.add(LSTM(40, return_sequences=True))\nmodel.add(LSTM(40, return_sequences=True))\n\nmodel.add(TimeDistributed(Dense(features_num)))\nmodel.add(Activation('linear')) \n</code></pre>\n\n<p>Results are, for the most part, better:\n<a href=\"https://i.stack.imgur.com/jUkKn.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/jUkKn.jpg\" alt=\"enter image description here\"></a></p>\n",
                "codes": [
                    [
                        "model.add(LSTM(32, return_sequences=True, input_shape=(None, 5)))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(TimeDistributed(Dense(5)))  # <--- This is new :)\nmodel.add(Activation('linear')) \nmodel.add(Lambda(lambda x: x[:, -50:, :])) # Grab only the last 50 values\n",
                        "features_num=5 \n\nmodel.add(LSTM(40, return_sequences=True, input_shape=(None, 5)))\nmodel.add(LSTM(40, return_sequences=False))\n\nmodel.add(Dense(80))\nmodel.add(Activation('tanh')) \nmodel.add(RepeatVector(50)) # 50 output points\n\nmodel.add(LSTM(40, return_sequences=True))\nmodel.add(LSTM(40, return_sequences=True))\n\nmodel.add(TimeDistributed(Dense(features_num)))\nmodel.add(Activation('linear')) \n"
                    ]
                ],
                "question_id:": "31923",
                "question_votes:": "2",
                "question_text:": "<p>I'm experimenting (read: playing around) with LSTMs on Keras. \nI want to train an LSTM network so it would \"track\" sine waves, that is, given sine waves with different wave length, phases and lengths, it would output the rest of wave. \nIn a sense, a many-to-many problem.</p>\n\n<p>I decided that the network would need to \"track\" 5 sine waves simultaneously. \nI would generate random sine waves and use the 50 last data points as the required output of the NN.</p>\n\n<p>My code is a follows:</p>\n\n<pre><code>from keras.models import Sequential\nfrom keras.layers import LSTM, Dense, TimeDistributed,Lambda, Dropout\nimport numpy as np\n\nmodel = Sequential()\n\nmodel.add(LSTM(32, return_sequences=True, input_shape=(None, 5)))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(5, return_sequences=True))\nmodel.add(Lambda(lambda x: x[:, -50:, :])) # Grab only the last 50 values\n\n\n\nprint(model.summary())\n\nmodel.compile(loss='mean_squared_error',\n              optimizer='adam')\n\n\ndef make_line(length):\n    shift= np.random.random()\n    wavelength = 5+10*np.random.random()\n    a=np.arange(length)\n    answer=np.sin(a/wavelength+shift)\n    return answer\n\n\n\n\ndef make_data(seq_num,seq_len,dim):\n    data=np.array([]).reshape(0,seq_len,dim)\n    for i in range (seq_num):\n        mini_data=np.array([]).reshape(0,seq_len)\n        for j in range (dim):\n            line = make_line(seq_len)\n            line=line.reshape(1,seq_len)            \n            mini_data=np.append(mini_data,line,axis=0)\n        mini_data=np.swapaxes(mini_data,1,0)\n        mini_data=mini_data.reshape(1,seq_len,dim)      \n        data=np.append(data,mini_data,axis=0)\n    return (data)\n\n\n\ndef train_generator():\n    while True:\n        sequence_length = np.random.randint(50, 150)+50     \n        data=make_data(1000,sequence_length,5)\n        x_train = data[:,:-50,:] # all but last 50      \n        y_train = (data[:, -50:, :]) # last 50      \n        yield x_train, y_train\n\n\nmodel.fit_generator(train_generator(), steps_per_epoch=30, epochs=100, verbose=1,validation_data=train_generator(),validation_steps=30)\nmodel.save('vi2h_model.h5')\n</code></pre>\n\n<p>I then try to generate data and use the model to predict the continuation of a sine wave:</p>\n\n<pre><code>def data_generator():\n    while True:\n        sequence_length = np.random.randint(50, 150)+50\n        data=make_data(1000,sequence_length,5)\n        x_train = data[:,:-50,:]    \n        y_train = (data[:, -50:, :])                \n        return x_train, y_train\n\n\nx,y= data_generator()   \n\nmodel = load_model('vi2h_model.h5')\npred=model.predict (x)\nnp.save ('pred.npy',pred)\nnp.save ('y.npy',y)\nnp.save ('x.npy',x)\n</code></pre>\n\n<p>When inspecting the ability of the network to predict the continuation of a sine wave (comparing y[0,:,0] to pred[0,:,0] for example, in order to compare the first sine wave of the first generated datum), see that my network performed very badly:</p>\n\n<p><a href=\"https://i.stack.imgur.com/i4qmK.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/i4qmK.jpg\" alt=\"The predicted vs actual 50 last points in a sample sine wave, placed after the part of the wave used as input for the NN\"></a> </p>\n\n<p>(Edit: legend: The predicted vs actual 50 last points in a sample sine wave (blue and orange, respectively), placed after the part of the wave used as input for the NN)</p>\n\n<p>What did I do wrong? And how should I my code to correctly track sine waves?\nMany thanks!</p>\n",
                "tags": "<python><deep-learning><keras><lstm>",
                "answers": [
                    [
                        "31986",
                        "2",
                        "31923",
                        "",
                        "",
                        "<p>I have added a dense layer to the network:</p>\n\n<p>model = Sequential()</p>\n\n<pre><code>model.add(LSTM(32, return_sequences=True, input_shape=(None, 5)))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(TimeDistributed(Dense(5)))  # &lt;--- This is new :)\nmodel.add(Activation('linear')) \nmodel.add(Lambda(lambda x: x[:, -50:, :])) # Grab only the last 50 values\n</code></pre>\n\n<p>This has provided some improvement :</p>\n\n<p><a href=\"https://i.stack.imgur.com/5EuKl.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/5EuKl.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>These are two sine waves and the predictions of the last 50 data points of them.\nAs can be seen, the results have improved, with some of them being okay approximations of the sine waves. Other times... not so much.</p>\n\n<p>Still a lot better than the previous results.</p>\n\n<p>I then tried another approach: Instead of having one (multilayered) LSTM, in which I ignore all but the 50 inputs (in a sense trying to predict from each one of the 50 last values the value located 50 places after it... which might not be an ideal approach) I split the network into 2 LSTMs, with one receiving the input and \"injecting\" its results via a dense layer into the second LTSM layer which generates the output.</p>\n\n<pre><code>features_num=5 \n\nmodel.add(LSTM(40, return_sequences=True, input_shape=(None, 5)))\nmodel.add(LSTM(40, return_sequences=False))\n\nmodel.add(Dense(80))\nmodel.add(Activation('tanh')) \nmodel.add(RepeatVector(50)) # 50 output points\n\nmodel.add(LSTM(40, return_sequences=True))\nmodel.add(LSTM(40, return_sequences=True))\n\nmodel.add(TimeDistributed(Dense(features_num)))\nmodel.add(Activation('linear')) \n</code></pre>\n\n<p>Results are, for the most part, better:\n<a href=\"https://i.stack.imgur.com/jUkKn.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/jUkKn.jpg\" alt=\"enter image description here\"></a></p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7109",
            "_score": 6.5780897,
            "_source": {
                "title": "Trying to use TensorFlow to predict financial time series data",
                "content": "Trying to use TensorFlow to predict financial time series data <p>I'm new to ML and TensorFlow (I started about a few hours ago), and I'm trying to use it to predict the next few data points in a time series. I'm taking my input and doing this with it:</p>\n\n<pre><code>/----------- x ------------\\\n.-------------------------------.\n| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 |\n'-------------------------------'\n     \\----------- y ------------/\n</code></pre>\n\n<p>What I thought I was doing is using <em>x</em> as the input data and <em>y</em> as the desired output for that input, so that given 0-6 I could get 1-7 (the 7 in particular). However, when I run my graph with <em>x</em> as the input, what I get is a prediction that looks more like <em>x</em> than <em>y</em>.</p>\n\n<p>Here's the code (based on <a href=\"https://mapr.com/blog/deep-learning-tensorflow/\" rel=\"noreferrer\">this post</a> and <a href=\"http://technopreneurlife.com/deep-temporal-forecasting-with-recurrent-neural-networks-rnns/\" rel=\"noreferrer\">this post</a>):</p>\n\n\n\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plot\nimport pandas as pd\nimport csv\n\ndef load_data_points(filename):\n    print(\"Opening CSV file\")\n    with open(filename) as csvfile:\n        print(\"Creating CSV reader\")\n        reader = csv.reader(csvfile)\n        print(\"Reading CSV\")\n        return [[[float(p)] for p in row] for row in reader]\n\nflatten = lambda l: [item for sublist in l for item in sublist]\n\ndata_points = load_data_points('dataset.csv')\n\nprint(\"Loaded\")\n\nprediction_size = 10\nnum_test_rows = 1\nnum_data_rows = len(data_points) - num_test_rows\nrow_size = len(data_points[0]) - prediction_size\n\n# Training data\ndata_rows = data_points[:-num_test_rows]\nx_data_points = np.array([row[:-prediction_size] for row in data_rows]).reshape([-1, row_size, 1])\ny_data_points = np.array([row[prediction_size:] for row in data_rows]).reshape([-1, row_size, 1])\n\n# Test data\ntest_rows = data_points[-num_test_rows:]\nx_test_points = np.array([[data_points[0][:-prediction_size]]]).reshape([-1, row_size, 1])\ny_test_points = np.array([[data_points[0][prediction_size:]]]).reshape([-1, row_size, 1])\n\ntf.reset_default_graph()\n\nnum_hidden = 100\n\nx = tf.placeholder(tf.float32, [None, row_size, 1])\ny = tf.placeholder(tf.float32, [None, row_size, 1])\n\nbasic_cell = tf.contrib.rnn.BasicRNNCell(num_units=num_hidden, activation=tf.nn.relu)\nrnn_outputs, _ = tf.nn.dynamic_rnn(basic_cell, x, dtype=tf.float32)\n\nlearning_rate = 0.001\n\nstacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, num_hidden])\nstacked_outputs = tf.layers.dense(stacked_rnn_outputs, 1)\noutputs = tf.reshape(stacked_outputs, [-1, row_size, 1])\n\nloss = tf.reduce_sum(tf.square(outputs - y))\noptimizer = tf.train.AdamOptimizer(learning_rate)\ntraining_op = optimizer.minimize(loss)\n\ninit = tf.global_variables_initializer()\n\niterations = 1000\n\nwith tf.Session() as sess:\n    init.run()\n    for ep in range(iterations):\n        sess.run(training_op, feed_dict={x: x_data_points, y: y_data_points})\n        if ep % 100 == 0:\n            mse = loss.eval(feed_dict={x: x_data_points, y: y_data_points})\n            print(ep, \"\\tMSE:\", mse)\n\n    y_pred = sess.run(stacked_outputs, feed_dict={x: x_test_points})\n\n    plot.rcParams[\"figure.figsize\"] = (20, 10)\n\n    plot.title(\"Actual vs Predicted\")\n    plot.plot(pd.Series(np.ravel(x_test_points)), 'g:', markersize=2, label=\"X\")\n    plot.plot(pd.Series(np.ravel(y_test_points)), 'b--', markersize=2, label=\"Y\")\n    plot.plot(pd.Series(np.ravel(y_pred)), 'r-', markersize=2, label=\"Predicted\")\n    plot.legend(loc='upper left')\n    plot.xlabel(\"Time periods\")\n    plot.tick_params(\n        axis='y',\n        which='both',\n        left='off',\n        right='off',\n        labelleft='off')\n    plot.show()\n</code></pre>\n\n<p>The result shown in the graph below is a prediction that follows <em>x</em>, rather than being shifted to the left (and including the predicted points on the right) as it should be to resemble <em>y</em>. Obviously the desire is for the red line to be as close to the blue one as possible.</p>\n\n<p><img src=\"https://i.imgur.com/lbzAFzo.png\" alt=\"graph\"></p>\n\n<p>I have no idea what I'm doing with all this, so please ELI5.</p>\n\n<p>Oh, also, my data points are fairly small numbers (order of 0.0001). If I don't multiply them by, say, 1000000, the results are so small that the red line is almost flat at the bottom of the chart. Why? I'm guessing it's because of the squaring in the fitness function. Should data be normalized before use, and if so, to what? 0-1? If I use:</p>\n\n<pre><code>normalized_points = [(p - min_point) / (max_point - min_point) for p in data_points]\n</code></pre>\n\n<p>my prediction fluctuates more wildly as it progresses: <img src=\"https://i.imgur.com/Y0eL8Ai.png\" alt=\"fluctuating\"></p>\n\n<p><strong>Edit:</strong> I'm being dumb and only giving it one example to learn from, not 500, aren't I? So I should be giving it multiple 500-point samples, right?</p>\n <machine-learning><python><time-series><tensorflow><rnn><p>Ok let's go part by part. There's quite a few parts here where you do not take into consideration the bias in your network.</p>\n\n<h1>Choosing your inputs and output</h1>\n\n<p>If the vector 0-6 is determined there really is no need to output 1-7. The 1-6 is already known and adding additional outputs will only add complexity to your model. Unless you have substantial amounts of data you want to keep your model as simple as possible in order to get good performance. Thus, I would output a simple neuron with a continuous value. You can use RMSE as your loss function with a regression output from your neural network. </p>\n\n<p>Additionally, you should supplement the samples you put into your input space with some additional information that you might think would contain information about the trend line. For example, if I had 2 different products, bitcoin and gold, and their input vector was the same, I might expect the gold to have very little fluctuation but the bitcoin to have very high fluctuation. </p>\n\n<p>Your input features to your network contain all the information from which your network will learn. Thus, you want to make sure that you are supplying sufficient information to have a meaningful prediction. </p>\n\n<h1>Deep learning is data hungry</h1>\n\n<p>You will need approximately 100,000+ instances. Each instance is a set of features. These should be drawn independently and such that they are identically distributed. In other words, you want to get multiple trendlines from a varied source of data that you wish to use your network with and then you will randomly draw 0-6 points, that is your features, and 7 which will be your label. </p>\n\n<p>Consider the data distribution you are trying to learn. If you want your network to classify cats/dogs, you need to give a wide range of different looking cats and dogs such that the network can identify the variance which exists in both of these classes. If you restrict the data source too much it will have high bias and will not generalize to novel data that you will later feed into it. </p>\n\n<hr>\n\n<p>Try these things and let us know what happens.</p>\n<p>Perhaps the prediction being the same as the input reflects that your network is under-trained. So called persistence model for time series prediction, is often used a baseline for other models. Persistence model is  using the last observation as a prediction. It is simple and often yields reasonable accuracy. My guess is that your network starts by learning the persistence model, and only if you train it more and it is possible to make a better model, it will learn it - but this requires a lot of training.</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "26910",
                "question_votes:": "10",
                "question_text:": "<p>I'm new to ML and TensorFlow (I started about a few hours ago), and I'm trying to use it to predict the next few data points in a time series. I'm taking my input and doing this with it:</p>\n\n<pre><code>/----------- x ------------\\\n.-------------------------------.\n| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 |\n'-------------------------------'\n     \\----------- y ------------/\n</code></pre>\n\n<p>What I thought I was doing is using <em>x</em> as the input data and <em>y</em> as the desired output for that input, so that given 0-6 I could get 1-7 (the 7 in particular). However, when I run my graph with <em>x</em> as the input, what I get is a prediction that looks more like <em>x</em> than <em>y</em>.</p>\n\n<p>Here's the code (based on <a href=\"https://mapr.com/blog/deep-learning-tensorflow/\" rel=\"noreferrer\">this post</a> and <a href=\"http://technopreneurlife.com/deep-temporal-forecasting-with-recurrent-neural-networks-rnns/\" rel=\"noreferrer\">this post</a>):</p>\n\n\n\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plot\nimport pandas as pd\nimport csv\n\ndef load_data_points(filename):\n    print(\"Opening CSV file\")\n    with open(filename) as csvfile:\n        print(\"Creating CSV reader\")\n        reader = csv.reader(csvfile)\n        print(\"Reading CSV\")\n        return [[[float(p)] for p in row] for row in reader]\n\nflatten = lambda l: [item for sublist in l for item in sublist]\n\ndata_points = load_data_points('dataset.csv')\n\nprint(\"Loaded\")\n\nprediction_size = 10\nnum_test_rows = 1\nnum_data_rows = len(data_points) - num_test_rows\nrow_size = len(data_points[0]) - prediction_size\n\n# Training data\ndata_rows = data_points[:-num_test_rows]\nx_data_points = np.array([row[:-prediction_size] for row in data_rows]).reshape([-1, row_size, 1])\ny_data_points = np.array([row[prediction_size:] for row in data_rows]).reshape([-1, row_size, 1])\n\n# Test data\ntest_rows = data_points[-num_test_rows:]\nx_test_points = np.array([[data_points[0][:-prediction_size]]]).reshape([-1, row_size, 1])\ny_test_points = np.array([[data_points[0][prediction_size:]]]).reshape([-1, row_size, 1])\n\ntf.reset_default_graph()\n\nnum_hidden = 100\n\nx = tf.placeholder(tf.float32, [None, row_size, 1])\ny = tf.placeholder(tf.float32, [None, row_size, 1])\n\nbasic_cell = tf.contrib.rnn.BasicRNNCell(num_units=num_hidden, activation=tf.nn.relu)\nrnn_outputs, _ = tf.nn.dynamic_rnn(basic_cell, x, dtype=tf.float32)\n\nlearning_rate = 0.001\n\nstacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, num_hidden])\nstacked_outputs = tf.layers.dense(stacked_rnn_outputs, 1)\noutputs = tf.reshape(stacked_outputs, [-1, row_size, 1])\n\nloss = tf.reduce_sum(tf.square(outputs - y))\noptimizer = tf.train.AdamOptimizer(learning_rate)\ntraining_op = optimizer.minimize(loss)\n\ninit = tf.global_variables_initializer()\n\niterations = 1000\n\nwith tf.Session() as sess:\n    init.run()\n    for ep in range(iterations):\n        sess.run(training_op, feed_dict={x: x_data_points, y: y_data_points})\n        if ep % 100 == 0:\n            mse = loss.eval(feed_dict={x: x_data_points, y: y_data_points})\n            print(ep, \"\\tMSE:\", mse)\n\n    y_pred = sess.run(stacked_outputs, feed_dict={x: x_test_points})\n\n    plot.rcParams[\"figure.figsize\"] = (20, 10)\n\n    plot.title(\"Actual vs Predicted\")\n    plot.plot(pd.Series(np.ravel(x_test_points)), 'g:', markersize=2, label=\"X\")\n    plot.plot(pd.Series(np.ravel(y_test_points)), 'b--', markersize=2, label=\"Y\")\n    plot.plot(pd.Series(np.ravel(y_pred)), 'r-', markersize=2, label=\"Predicted\")\n    plot.legend(loc='upper left')\n    plot.xlabel(\"Time periods\")\n    plot.tick_params(\n        axis='y',\n        which='both',\n        left='off',\n        right='off',\n        labelleft='off')\n    plot.show()\n</code></pre>\n\n<p>The result shown in the graph below is a prediction that follows <em>x</em>, rather than being shifted to the left (and including the predicted points on the right) as it should be to resemble <em>y</em>. Obviously the desire is for the red line to be as close to the blue one as possible.</p>\n\n<p><img src=\"https://i.imgur.com/lbzAFzo.png\" alt=\"graph\"></p>\n\n<p>I have no idea what I'm doing with all this, so please ELI5.</p>\n\n<p>Oh, also, my data points are fairly small numbers (order of 0.0001). If I don't multiply them by, say, 1000000, the results are so small that the red line is almost flat at the bottom of the chart. Why? I'm guessing it's because of the squaring in the fitness function. Should data be normalized before use, and if so, to what? 0-1? If I use:</p>\n\n<pre><code>normalized_points = [(p - min_point) / (max_point - min_point) for p in data_points]\n</code></pre>\n\n<p>my prediction fluctuates more wildly as it progresses: <img src=\"https://i.imgur.com/Y0eL8Ai.png\" alt=\"fluctuating\"></p>\n\n<p><strong>Edit:</strong> I'm being dumb and only giving it one example to learn from, not 500, aren't I? So I should be giving it multiple 500-point samples, right?</p>\n",
                "tags": "<machine-learning><python><time-series><tensorflow><rnn>",
                "answers": [
                    [
                        "26940",
                        "2",
                        "26910",
                        "",
                        "",
                        "<p>Ok let's go part by part. There's quite a few parts here where you do not take into consideration the bias in your network.</p>\n\n<h1>Choosing your inputs and output</h1>\n\n<p>If the vector 0-6 is determined there really is no need to output 1-7. The 1-6 is already known and adding additional outputs will only add complexity to your model. Unless you have substantial amounts of data you want to keep your model as simple as possible in order to get good performance. Thus, I would output a simple neuron with a continuous value. You can use RMSE as your loss function with a regression output from your neural network. </p>\n\n<p>Additionally, you should supplement the samples you put into your input space with some additional information that you might think would contain information about the trend line. For example, if I had 2 different products, bitcoin and gold, and their input vector was the same, I might expect the gold to have very little fluctuation but the bitcoin to have very high fluctuation. </p>\n\n<p>Your input features to your network contain all the information from which your network will learn. Thus, you want to make sure that you are supplying sufficient information to have a meaningful prediction. </p>\n\n<h1>Deep learning is data hungry</h1>\n\n<p>You will need approximately 100,000+ instances. Each instance is a set of features. These should be drawn independently and such that they are identically distributed. In other words, you want to get multiple trendlines from a varied source of data that you wish to use your network with and then you will randomly draw 0-6 points, that is your features, and 7 which will be your label. </p>\n\n<p>Consider the data distribution you are trying to learn. If you want your network to classify cats/dogs, you need to give a wide range of different looking cats and dogs such that the network can identify the variance which exists in both of these classes. If you restrict the data source too much it will have high bias and will not generalize to novel data that you will later feed into it. </p>\n\n<hr>\n\n<p>Try these things and let us know what happens.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "33299",
                        "2",
                        "26910",
                        "",
                        "",
                        "<p>Perhaps the prediction being the same as the input reflects that your network is under-trained. So called persistence model for time series prediction, is often used a baseline for other models. Persistence model is  using the last observation as a prediction. It is simple and often yields reasonable accuracy. My guess is that your network starts by learning the persistence model, and only if you train it more and it is possible to make a better model, it will learn it - but this requires a lot of training.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9215",
            "_score": 6.519212,
            "_source": {
                "title": "Understanding LSTM behaviour: Validation loss smaller than training loss throughout training for regression problem",
                "content": "Understanding LSTM behaviour: Validation loss smaller than training loss throughout training for regression problem <p>I'm building a lstm model for regression on timeseries. To verify my implementation of the model and understand keras, I'm using a toyproblem to make sure I understand what's going on. Problem is I do not understand what's going on here. </p>\n\n<p>As I am fitting the model, training loss is constantly larger than validation loss, even for a balanced train/validation set (5000 samples each):</p>\n\n<p><a href=\"https://i.stack.imgur.com/Ip4yv.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Ip4yv.png\" alt=\"Model Loss\"></a></p>\n\n<p>In my understanding the two curves should be exactly the other way around such that training loss would be an upper bound for validation loss. </p>\n\n<p>Predictions are more or less ok here. However I'd still like to understand what's going on, as I see similar behavior of the loss in my real problem but there the predictions are rubbish. So I suspect, there's something going on with the model that I don't understand.</p>\n\n<p>Here's the code for my toy problem:</p>\n\n<pre><code>import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import LSTM\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\n#create testdata\nnEpochs = 12\nnTimestepsPerSeq = 5\nnFeatures = 5\n\ndef generate_examples(nSamples, nTimestepsPerSeq, nFeatures):\n    X = np.random.random((nSamples, nTimestepsPerSeq, nFeatures))\n\n    #make feature 1 categorical: [0,1,2]\n    X[:,:,0] = np.random.randint(0,3, X[:,:,0].shape)\n\n    #make feature 2 categorical: [-1, 0,1]\n    X[:,:,1] = np.random.randint(-1,2, X[:,:,1].shape)\n\n    #shift feature 3 by a constant\n    X[:,:,2] = X[:,:,2] + 2\n\n    #calc output\n    Y = np.zeros((1, nSamples))\n\n    #combine features and introduce non-linearity\n    Y = X[:,-1,0]*np.mean(X[:,-1,3]) + X[:,-1,2]*np.mean(X[:,-1,4]) + \\\n        (X[:,-1,0]*X[:,-1,1]*np.mean(X[:,-1,2]))**2\n\n    #add uniform noise\n    Y = Y*np.random.uniform(0.95,1.05,size=Y.shape)\n\n    #reshape for scaler instance:\n    # ValueError: Expected 2D array, got 1D array instead:\n    # array=[  1.27764489  27.56604355   1.39317709 ...,   1.57210734   8.18834281\n    # 1.66174279].\n    # Reshape your data either using array.reshape(-1, 1) if your data has a single fe\n    # ature or array.reshape(1, -1) if it contains a single sample.\n    Y = Y.reshape((-1,1))\n\n    return X,Y\n\nXtrain,Ytrain = generate_examples(5000, nTimestepsPerSeq, nFeatures)\nXval,Yval = generate_examples(5000, nTimestepsPerSeq, nFeatures)\nXtest,Ytest = generate_examples(20, nTimestepsPerSeq, nFeatures)\n\n#scale input data\nfor i in range(0,nFeatures):\n    #scaler = StandardScaler()\n    scaler = MinMaxScaler()\n    scaler = scaler.fit(Xtrain[:,:,i])\n    Xtrain[:,:,i] = scaler.transform(Xtrain[:,:,i])\n    Xval[:,:,i] = scaler.transform(Xval[:,:,i])\n    Xtest[:,:,i] = scaler.transform(Xtest[:,:,i])\n\ntargetScaler = MinMaxScaler()\ntargetScaler = targetScaler.fit(Ytrain)\n\n#transform target\nYtrain = targetScaler.transform(Ytrain)    \nYval = targetScaler.transform(Yval)    \nYtest = targetScaler.transform(Ytest) \n\n# defining the LSTM model\nmodel = Sequential()\nmodel.add(LSTM(200, input_shape=(Xtrain.shape[1], Xtrain.shape[2]), return_sequences=True))\nmodel.add(LSTM(200))\nmodel.add(Dense(1))\n\nmodel.compile(loss='mse', optimizer='adam', metrics=['acc'])\n\n# fitting the model\nhistory = model.fit(Xtrain, Ytrain, epochs=nEpochs, batch_size=50, validation_data=(Xval, Yval), shuffle=True, verbose=2)\n\n#test model\nyhat = model.predict(Xtest)\nprint(\"pediction vs truth:\")\nfor i in range(0,10):\n    print(yhat[i], Ytest[i])\n\n# summarize history for loss\nplt.subplot(1,1,1)\nplt.plot(history.history['loss'], '.-')\nplt.plot(history.history['val_loss'], '.-')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.show()\n</code></pre>\n\n<p>Edit: I added some output of an experiment:</p>\n\n<pre><code>Epoch 1/12\n - 6s - loss: 0.1056 - acc: 2.0000e-04 - val_loss: 0.0680 - val_acc: 0.0000e+00\nEpoch 2/12\n...\nEpoch 11/12\n - 4s - loss: 0.0033 - acc: 4.0000e-04 - val_loss: 0.0020 - val_acc: 0.0000e+00\nEpoch 12/12\n - 4s - loss: 0.0016 - acc: 4.0000e-04 - val_loss: 0.0016 - val_acc: 0.0000e+00\npediction vs truth:\n[ 0.25022525] [ 0.25465108]\n[ 0.98761547] [ 0.91661543]\n[ 1.06177747] [ 0.95979166]\n[ 0.0835482] [ 0.03742919]\n[ 0.02432941] [ 0.01149685]\n[ 0.00915699] [ 0.00887351]\n[ 0.2765356] [ 0.27340488]\n[ 0.02941256] [ 0.01685951]\n[-0.01059875] [ 0.00157809]\n[ 0.04762106] [ 0.01983566]\n</code></pre>\n <keras><lstm><loss-function><p>Training scores can be expected to be better than those of the validation when the machine you train can \"adapt\" to the specifics of the training examples while not successfully generalizing; the greater the adaption to the specifics of the training examples and the worse generalization, the bigger the gap between training and validation scores (in favor of the training scores). </p>\n\n<p>In cases in which training as well as validation examples are generated <em>de novo</em>, the network is not presented with the same examples over and over. It thus cannot overfit to accommodate them while losing the ability to respond correctly to the validation examples - which, after all, are generated by the same process as the training examples. For an example of such an approach you can have a look at my <a href=\"https://datascience.stackexchange.com/questions/32941/lstm-with-teacher-forcing-nn-fails-to-predict-the-sequence\">experiment</a>.      </p>\n\n<p>As you commented, this in not the case here, you generate the data only once. So this does not explain why you do not see overfit. Other explanations might be that this is because your network does not have enough trainable parameters to overfit, coupled with a relatively large number of training examples (and of course, generating the training and the validation examples with the same process). It might also be possible that you will see overfit if you invest more epochs into the training. Might be an interesting experiment.   </p>\n\n<p>Okay, so this explains why the validation score is not worse. But why is it better?</p>\n\n<p>Be advised that validation, as it is calculated at the end of each epoch, uses the \"best\" machine trained in that epoch (that is, the last one, but if constant improvement is the case then the last weights should yield the best results - at least for training loss, if not for validation), while the train loss is calculated as an average of the performance per each epoch.</p>\n\n<p>Thus, if the machine is constantly improving and does not overfit, the gap between the network's average performance in an epoch and its performance at the end of an epoch is translated into the gap between training and validation scores - in favor of the validation scores.</p>\n\n<p>Give or take minor variations that result from the random process of sample generation (even if data is generated only once, but especially if it is generated anew for each epoch).  </p>\n",
                "codes": [
                    []
                ],
                "question_id:": "32927",
                "question_votes:": "3",
                "question_text:": "<p>I'm building a lstm model for regression on timeseries. To verify my implementation of the model and understand keras, I'm using a toyproblem to make sure I understand what's going on. Problem is I do not understand what's going on here. </p>\n\n<p>As I am fitting the model, training loss is constantly larger than validation loss, even for a balanced train/validation set (5000 samples each):</p>\n\n<p><a href=\"https://i.stack.imgur.com/Ip4yv.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Ip4yv.png\" alt=\"Model Loss\"></a></p>\n\n<p>In my understanding the two curves should be exactly the other way around such that training loss would be an upper bound for validation loss. </p>\n\n<p>Predictions are more or less ok here. However I'd still like to understand what's going on, as I see similar behavior of the loss in my real problem but there the predictions are rubbish. So I suspect, there's something going on with the model that I don't understand.</p>\n\n<p>Here's the code for my toy problem:</p>\n\n<pre><code>import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import LSTM\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\n#create testdata\nnEpochs = 12\nnTimestepsPerSeq = 5\nnFeatures = 5\n\ndef generate_examples(nSamples, nTimestepsPerSeq, nFeatures):\n    X = np.random.random((nSamples, nTimestepsPerSeq, nFeatures))\n\n    #make feature 1 categorical: [0,1,2]\n    X[:,:,0] = np.random.randint(0,3, X[:,:,0].shape)\n\n    #make feature 2 categorical: [-1, 0,1]\n    X[:,:,1] = np.random.randint(-1,2, X[:,:,1].shape)\n\n    #shift feature 3 by a constant\n    X[:,:,2] = X[:,:,2] + 2\n\n    #calc output\n    Y = np.zeros((1, nSamples))\n\n    #combine features and introduce non-linearity\n    Y = X[:,-1,0]*np.mean(X[:,-1,3]) + X[:,-1,2]*np.mean(X[:,-1,4]) + \\\n        (X[:,-1,0]*X[:,-1,1]*np.mean(X[:,-1,2]))**2\n\n    #add uniform noise\n    Y = Y*np.random.uniform(0.95,1.05,size=Y.shape)\n\n    #reshape for scaler instance:\n    # ValueError: Expected 2D array, got 1D array instead:\n    # array=[  1.27764489  27.56604355   1.39317709 ...,   1.57210734   8.18834281\n    # 1.66174279].\n    # Reshape your data either using array.reshape(-1, 1) if your data has a single fe\n    # ature or array.reshape(1, -1) if it contains a single sample.\n    Y = Y.reshape((-1,1))\n\n    return X,Y\n\nXtrain,Ytrain = generate_examples(5000, nTimestepsPerSeq, nFeatures)\nXval,Yval = generate_examples(5000, nTimestepsPerSeq, nFeatures)\nXtest,Ytest = generate_examples(20, nTimestepsPerSeq, nFeatures)\n\n#scale input data\nfor i in range(0,nFeatures):\n    #scaler = StandardScaler()\n    scaler = MinMaxScaler()\n    scaler = scaler.fit(Xtrain[:,:,i])\n    Xtrain[:,:,i] = scaler.transform(Xtrain[:,:,i])\n    Xval[:,:,i] = scaler.transform(Xval[:,:,i])\n    Xtest[:,:,i] = scaler.transform(Xtest[:,:,i])\n\ntargetScaler = MinMaxScaler()\ntargetScaler = targetScaler.fit(Ytrain)\n\n#transform target\nYtrain = targetScaler.transform(Ytrain)    \nYval = targetScaler.transform(Yval)    \nYtest = targetScaler.transform(Ytest) \n\n# defining the LSTM model\nmodel = Sequential()\nmodel.add(LSTM(200, input_shape=(Xtrain.shape[1], Xtrain.shape[2]), return_sequences=True))\nmodel.add(LSTM(200))\nmodel.add(Dense(1))\n\nmodel.compile(loss='mse', optimizer='adam', metrics=['acc'])\n\n# fitting the model\nhistory = model.fit(Xtrain, Ytrain, epochs=nEpochs, batch_size=50, validation_data=(Xval, Yval), shuffle=True, verbose=2)\n\n#test model\nyhat = model.predict(Xtest)\nprint(\"pediction vs truth:\")\nfor i in range(0,10):\n    print(yhat[i], Ytest[i])\n\n# summarize history for loss\nplt.subplot(1,1,1)\nplt.plot(history.history['loss'], '.-')\nplt.plot(history.history['val_loss'], '.-')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.show()\n</code></pre>\n\n<p>Edit: I added some output of an experiment:</p>\n\n<pre><code>Epoch 1/12\n - 6s - loss: 0.1056 - acc: 2.0000e-04 - val_loss: 0.0680 - val_acc: 0.0000e+00\nEpoch 2/12\n...\nEpoch 11/12\n - 4s - loss: 0.0033 - acc: 4.0000e-04 - val_loss: 0.0020 - val_acc: 0.0000e+00\nEpoch 12/12\n - 4s - loss: 0.0016 - acc: 4.0000e-04 - val_loss: 0.0016 - val_acc: 0.0000e+00\npediction vs truth:\n[ 0.25022525] [ 0.25465108]\n[ 0.98761547] [ 0.91661543]\n[ 1.06177747] [ 0.95979166]\n[ 0.0835482] [ 0.03742919]\n[ 0.02432941] [ 0.01149685]\n[ 0.00915699] [ 0.00887351]\n[ 0.2765356] [ 0.27340488]\n[ 0.02941256] [ 0.01685951]\n[-0.01059875] [ 0.00157809]\n[ 0.04762106] [ 0.01983566]\n</code></pre>\n",
                "tags": "<keras><lstm><loss-function>",
                "answers": [
                    [
                        "32963",
                        "2",
                        "32927",
                        "",
                        "",
                        "<p>Training scores can be expected to be better than those of the validation when the machine you train can \"adapt\" to the specifics of the training examples while not successfully generalizing; the greater the adaption to the specifics of the training examples and the worse generalization, the bigger the gap between training and validation scores (in favor of the training scores). </p>\n\n<p>In cases in which training as well as validation examples are generated <em>de novo</em>, the network is not presented with the same examples over and over. It thus cannot overfit to accommodate them while losing the ability to respond correctly to the validation examples - which, after all, are generated by the same process as the training examples. For an example of such an approach you can have a look at my <a href=\"https://datascience.stackexchange.com/questions/32941/lstm-with-teacher-forcing-nn-fails-to-predict-the-sequence\">experiment</a>.      </p>\n\n<p>As you commented, this in not the case here, you generate the data only once. So this does not explain why you do not see overfit. Other explanations might be that this is because your network does not have enough trainable parameters to overfit, coupled with a relatively large number of training examples (and of course, generating the training and the validation examples with the same process). It might also be possible that you will see overfit if you invest more epochs into the training. Might be an interesting experiment.   </p>\n\n<p>Okay, so this explains why the validation score is not worse. But why is it better?</p>\n\n<p>Be advised that validation, as it is calculated at the end of each epoch, uses the \"best\" machine trained in that epoch (that is, the last one, but if constant improvement is the case then the last weights should yield the best results - at least for training loss, if not for validation), while the train loss is calculated as an average of the performance per each epoch.</p>\n\n<p>Thus, if the machine is constantly improving and does not overfit, the gap between the network's average performance in an epoch and its performance at the end of an epoch is translated into the gap between training and validation scores - in favor of the validation scores.</p>\n\n<p>Give or take minor variations that result from the random process of sample generation (even if data is generated only once, but especially if it is generated anew for each epoch).  </p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7807",
            "_score": 6.4518013,
            "_source": {
                "title": "Decision Trees split in scikit",
                "content": "Decision Trees split in scikit <p>I am working with the titanic dataset and using decision trees for analyzing the age covariate. I'd like just to see whether kids are more likely to survive than adults. I implemented my own Gini coefficient and I had plot the coefficient by age: dataset here <a href=\"https://github.com/juan-barragan/titanic/blob/master/titanic_ds.csv\" rel=\"nofollow noreferrer\">titanic ds</a></p>\n\n<pre><code>import pandas as pd\nimport seaborn\nimport matplotlib.pyplot as plt\nfrom sklearn import tree\nimport graphviz\nimport numpy as np\n\ndef gini_by_age(df, t):\n    df['age_group'] = df['age'].apply(lambda row : 0 if row &lt;= t else 1)\n    kids = df[df['age_group'] == 0]\n    kids0 = kids[kids['survived'] == 0]\n    kids1 = kids[kids['survived'] == 1]\n    adults = df[df['age_group'] == 1]\n    adults0 = adults[adults['survived'] == 0]\n    adults1 = adults[adults['survived'] == 1] \n    gk = 1 - (len(kids0)**2 + len(kids1)**2)/float(len(kids))**2\n    ga = 1 - (len(adults0)**2 + len(adults1)**2)/float(len(adults))**2\n\n    return gk + ga\n\ndef plot_gini_by_age(df):    \n    ages = range(2,25)\n    y = [gini_by_age(df, a) for a in ages]\n    plt.plot(ages, y)\n    plt.show()\n\ndef use_tree(df):\n    X = np.array(df['age']).reshape((len(df['age']),1))\n    y = df['survived']\n    clf = tree.DecisionTreeClassifier(max_depth=1).fit(X,y)    \n    dot_data = tree.export_graphviz(clf, out_file=None)\n    graph = graphviz.Source(dot_data)\n    graph.render(\"age\")\n\ntitanic_df = pd.read_csv(\"titanic_ds.csv\")\nages_cov = titanic_df[['age', 'survived']].dropna()\nplot_gini_by_age(ages_cov)\nuse_tree(ages_cov)\nprint gini_by_age(ages_cov, 5)\nprint gini_by_age(ages_cov, 8.5)\nprint gini_by_age(ages_cov, 15)\n</code></pre>\n\n<p>output:\n    0.925844132419\n    0.937732003001\n    0.963875889772\nI see from the plot that gini coefficient has local minima at roughly 5, 8 and 15 years old and the best is at 5. But scikit gives me 8.5 years old as the best split. What is wrong here?</p>\n <scikit-learn><decision-trees><p>I got it thanks to the scikit team, I put the answer here for the people to come. The split used in scikit uses weights in calculating the Gini coefficient, just add the following lines before returning:\n    ....\n    gk *= len(kids)/len(df)\n    ga *= len(adults)/len(df)</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "28972",
                "question_votes:": "",
                "question_text:": "<p>I am working with the titanic dataset and using decision trees for analyzing the age covariate. I'd like just to see whether kids are more likely to survive than adults. I implemented my own Gini coefficient and I had plot the coefficient by age: dataset here <a href=\"https://github.com/juan-barragan/titanic/blob/master/titanic_ds.csv\" rel=\"nofollow noreferrer\">titanic ds</a></p>\n\n<pre><code>import pandas as pd\nimport seaborn\nimport matplotlib.pyplot as plt\nfrom sklearn import tree\nimport graphviz\nimport numpy as np\n\ndef gini_by_age(df, t):\n    df['age_group'] = df['age'].apply(lambda row : 0 if row &lt;= t else 1)\n    kids = df[df['age_group'] == 0]\n    kids0 = kids[kids['survived'] == 0]\n    kids1 = kids[kids['survived'] == 1]\n    adults = df[df['age_group'] == 1]\n    adults0 = adults[adults['survived'] == 0]\n    adults1 = adults[adults['survived'] == 1] \n    gk = 1 - (len(kids0)**2 + len(kids1)**2)/float(len(kids))**2\n    ga = 1 - (len(adults0)**2 + len(adults1)**2)/float(len(adults))**2\n\n    return gk + ga\n\ndef plot_gini_by_age(df):    \n    ages = range(2,25)\n    y = [gini_by_age(df, a) for a in ages]\n    plt.plot(ages, y)\n    plt.show()\n\ndef use_tree(df):\n    X = np.array(df['age']).reshape((len(df['age']),1))\n    y = df['survived']\n    clf = tree.DecisionTreeClassifier(max_depth=1).fit(X,y)    \n    dot_data = tree.export_graphviz(clf, out_file=None)\n    graph = graphviz.Source(dot_data)\n    graph.render(\"age\")\n\ntitanic_df = pd.read_csv(\"titanic_ds.csv\")\nages_cov = titanic_df[['age', 'survived']].dropna()\nplot_gini_by_age(ages_cov)\nuse_tree(ages_cov)\nprint gini_by_age(ages_cov, 5)\nprint gini_by_age(ages_cov, 8.5)\nprint gini_by_age(ages_cov, 15)\n</code></pre>\n\n<p>output:\n    0.925844132419\n    0.937732003001\n    0.963875889772\nI see from the plot that gini coefficient has local minima at roughly 5, 8 and 15 years old and the best is at 5. But scikit gives me 8.5 years old as the best split. What is wrong here?</p>\n",
                "tags": "<scikit-learn><decision-trees>",
                "answers": [
                    [
                        "29106",
                        "2",
                        "28972",
                        "",
                        "",
                        "<p>I got it thanks to the scikit team, I put the answer here for the people to come. The split used in scikit uses weights in calculating the Gini coefficient, just add the following lines before returning:\n    ....\n    gk *= len(kids)/len(df)\n    ga *= len(adults)/len(df)</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17577",
            "_score": 6.4518013,
            "_source": {
                "title": "tensorflow.scatter_nd with batches?",
                "content": "tensorflow.scatter_nd with batches? <p>I would like to use <code>tf.scatter_nd</code> for inputs with <code>locations = (-1, 68, 16, 16, 2)</code> and <code>values = (-1, 68, 16, 16)</code>.</p>\n\n<p>I am having problems using <code>scatter_nd</code> with these inputs.</p>\n\n<p>My current workaround is using <code>tf.map_fn twice</code>:</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\nwith tf.Session():\n    BS = 32\n    locations = tf.constant(np.clip(np.random.normal(size=(BS, 68, 16, 16, 2))*112, 0, 111), dtype=\"int32\")\n    vals = tf.constant(np.random.normal(size=(BS, 68, 16, 16))*20, dtype=\"float32\")\n    def draw_lmarks(x):\n        def draw_lmarks_inner(x2):\n            return tf.scatter_nd(x2[0], x2[1], shape=(IMGSIZE, IMGSIZE))\n        return tf.map_fn(draw_lmarks_inner, x, dtype=\"float32\")\n    imgs = tf.map_fn(draw_lmarks, [locations, vals], dtype=\"float32\")\n    imgs = K.reshape(K.max(imgs, axis=1), [-1, IMGSIZE, IMGSIZE, 1])\n</code></pre>\n\n<p>I'd like to get rid of the two <code>map_fn</code> calls.</p>\n\n<p>Is there any alternative that I missed?</p>\n\n<p><strong>Edit:</strong>\nUsing <code>tf.tensor_scatter_update</code> enables me to get rid of one of the <code>map_fn</code> calls, and speed stuff up considerably, but i need the maximum (<code>tf.tensor_scatter_max</code>) which doesn't exists.\nThere is a <code>tf.scatter_max</code> tho but somehow i couldn't get that to work like expected.</p>\n\n<p>With tensor_scatter_update; ie. this:</p>\n\n<pre><code>img = tf.zeros((112,112), dtype=\"float32\")\ndef draw_lmarks(x):\n    return tf.tensor_scatter_update(img, x[0], x[1])\nimgs = tf.map_fn(draw_lmarks, [locations, vals], dtype=\"float32\")\n</code></pre>\n\n<p>i get an output like this<br>\n<a href=\"https://i.stack.imgur.com/ooQjR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ooQjR.png\" alt=\"enter image description here\"></a><br>\nwhile i need an output like this<br>\n<a href=\"https://i.stack.imgur.com/WCI9N.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WCI9N.png\" alt=\"enter image description here\"></a>  </p>\n <tensorflow>",
                "codes": [],
                "question_id:": "56517",
                "question_votes:": "",
                "question_text:": "<p>I would like to use <code>tf.scatter_nd</code> for inputs with <code>locations = (-1, 68, 16, 16, 2)</code> and <code>values = (-1, 68, 16, 16)</code>.</p>\n\n<p>I am having problems using <code>scatter_nd</code> with these inputs.</p>\n\n<p>My current workaround is using <code>tf.map_fn twice</code>:</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\nwith tf.Session():\n    BS = 32\n    locations = tf.constant(np.clip(np.random.normal(size=(BS, 68, 16, 16, 2))*112, 0, 111), dtype=\"int32\")\n    vals = tf.constant(np.random.normal(size=(BS, 68, 16, 16))*20, dtype=\"float32\")\n    def draw_lmarks(x):\n        def draw_lmarks_inner(x2):\n            return tf.scatter_nd(x2[0], x2[1], shape=(IMGSIZE, IMGSIZE))\n        return tf.map_fn(draw_lmarks_inner, x, dtype=\"float32\")\n    imgs = tf.map_fn(draw_lmarks, [locations, vals], dtype=\"float32\")\n    imgs = K.reshape(K.max(imgs, axis=1), [-1, IMGSIZE, IMGSIZE, 1])\n</code></pre>\n\n<p>I'd like to get rid of the two <code>map_fn</code> calls.</p>\n\n<p>Is there any alternative that I missed?</p>\n\n<p><strong>Edit:</strong>\nUsing <code>tf.tensor_scatter_update</code> enables me to get rid of one of the <code>map_fn</code> calls, and speed stuff up considerably, but i need the maximum (<code>tf.tensor_scatter_max</code>) which doesn't exists.\nThere is a <code>tf.scatter_max</code> tho but somehow i couldn't get that to work like expected.</p>\n\n<p>With tensor_scatter_update; ie. this:</p>\n\n<pre><code>img = tf.zeros((112,112), dtype=\"float32\")\ndef draw_lmarks(x):\n    return tf.tensor_scatter_update(img, x[0], x[1])\nimgs = tf.map_fn(draw_lmarks, [locations, vals], dtype=\"float32\")\n</code></pre>\n\n<p>i get an output like this<br>\n<a href=\"https://i.stack.imgur.com/ooQjR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ooQjR.png\" alt=\"enter image description here\"></a><br>\nwhile i need an output like this<br>\n<a href=\"https://i.stack.imgur.com/WCI9N.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WCI9N.png\" alt=\"enter image description here\"></a>  </p>\n",
                "tags": "<tensorflow>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13552",
            "_score": 6.4162893,
            "_source": {
                "title": "How to classify nationality name on the bases of user driving license with tensor-flow keras python?",
                "content": "How to classify nationality name on the bases of user driving license with tensor-flow keras python? <p>I am new to deep learning. I want to create a classifier which can predict nationality names on the bases of nationality on driving license id.\nTo accomplish that, I created a data set of <strong>USA</strong> driving license images. Then created training data-set, labels and features of data and a classification model.</p>\n\n<p>When I run my python script, the accuracy was 92%.\nWhen I tested my model with different images it gave wrong result.</p>\n\n<p>Python code like this:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport h5py\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.callbacks import TensorBoard\nimport pickle\nimport os\nimport cv2\nimport time\n\nDATADIR = '/home/anupam/Documents/workspace/DjangoProject/DF-Web/datafornix/USADL_DATASET'\n\n\nCATEGORIES = [\n\n              'Alabma',\n              'Connecticut',\n               'California',\n               'Delaware',\n               'Georgia',\n               'Indiana',\n               'Louisiana',\n               'Maine',\n              'Massachusetts',\n              'MaryLand',\n             'NewHamshire',\n              'NewJersey',\n              'NewYork',\n               'NewMexico',\n              'Pennsylvania',\n              'RohodeIsland',\n              'Vermont',\n              'Virginia',\n        ]\n\nencoder = LabelEncoder()\ncity_labels = encoder.fit_transform(CATEGORIES)\n# print(city_labels)\nencoder = OneHotEncoder(sparse=False)\ncity_labels = city_labels.reshape((18, 1))\nstate_array = encoder.fit_transform(city_labels)\n\ntraining_data = []\nIMG_SIZE = 200\n\n\ndef create_traing_dataset():\n    for category in CATEGORIES:\n        path = os.path.join(DATADIR, category)\n        class_num = CATEGORIES.index(category)\n        for img in os.listdir(path):\n            for x in state_array:\n                try:\n                    img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n                    training_data.append([new_array, x])\n                except Exception as e:\n                    pass\n\n\n\ncreate_traing_dataset()\n\n\n#Randomize the dataset\n\nimport random\n\nrandom.shuffle(training_data)\n\n#Create a model\nX = []\ny = []\n\nfor features,label in training_data:\n    X.append(features)\n    y.append(label)\n\n\n\nX = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n\n\npickle_out = open(\"X.pickle\",\"wb\")\npickle.dump(X, pickle_out)\npickle_out.close()\n\n\npickle_out = open(\"y.pickle\",\"wb\")\npickle.dump(y, pickle_out)\npickle_out.close()\n\n\npickle_in = open(\"X.pickle\",\"rb\")\nX = pickle.load(pickle_in)\n\npickle_in = open(\"y.pickle\",\"rb\")\ny = pickle.load(pickle_in)\ny_data = []\nfor i in y:\n    y_data.append(i[0])\n\ny = np.array(y_data)\nprint(y)\n\nX = X/255.0\nprint(X.size)\ndense_layers = [0]\nlayer_sizes = [64]\nconv_layers = [3]\n\nfor dense_layer in dense_layers:\n    for layer_size in layer_sizes:\n        for conv_layer in conv_layers:\n            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n            print(NAME)\n\n            model = Sequential()\n\n            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n            model.add(Activation('relu'))\n            model.add(MaxPooling2D(pool_size=(2, 2)))\n\n            for l in range(conv_layer-1):\n                model.add(Conv2D(layer_size, (3, 3)))\n                model.add(Activation('relu'))\n                model.add(MaxPooling2D(pool_size=(2, 2)))\n\n            model.add(Flatten())\n\n            for _ in range(dense_layer):\n                model.add(Dense(layer_size))\n                model.add(Activation('relu'))\n\n            model.add(Dense(1))\n            model.add(Activation('sigmoid'))\n\n            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n\n            model.compile(loss='binary_crossentropy',\n                          optimizer='adam',\n                          metrics=['accuracy'],\n                          )\n\n            model.fit(X, y,\n                      batch_size=32,\n                      epochs=10,\n                      validation_split=0.3,\n                      callbacks=[tensorboard])\n\nmodel.save('64x3-CNN.model')\n</code></pre>\n\n<p>And test classifier model like this:-</p>\n\n<pre><code>import cv2\nimport tensorflow as tf\n\nmodel = tf.keras.models.load_model(\"64x3-CNN.model\")\n\nCATEGORIES = [\n\n              'Alabma',\n              'Connecticut',\n               'California',\n               'Delaware',\n               'Georgia',\n               'Indiana',\n               'Louisiana',\n               'Maine',\n              'Massachusetts',\n              'MaryLand',\n             'NewHamshire',\n              'NewJersey',\n              'NewYork',\n               'NewMexico',\n              'Pennsylvania',\n              'RohodeIsland',\n              'Vermont',\n              'Virginia',\n        ]\n\n\n\ndef prepare(filepath):\n    IMG_SIZE = 200  # 50 in txt-based\n    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)  # read in the image, convert to grayscale\n    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)  # return the image with shaping that TF wants.\n\nprediction = model.predict([prepare('/home/anupam/Documents/workspace/DjangoProject/DF-Web/datafornix/download.jpeg')])  # REMEMBER YOU'RE PASSING A LIST OF THINGS YOU WISH TO PREDICT\nprint(prediction)\nprint(CATEGORIES[int(prediction[0][0])])\n</code></pre>\n\n<p>I think, I wrong with features and labels of training data set. If I wrong this. How I resolve that case??</p>\n\n<p>What is the approach to find best result??</p>\n\n<p>Please help to clear my above query.</p>\n\n<p>Thanks</p>\n <python><neural-network><keras><tensorflow><cnn><p>Inside for loops you are always creating a new model and then training it.</p>\n\n<p>Afte the loops, you are saving the model. Meaning that you only save the last model which was in a variable <code>model</code>.</p>\n\n<p>Also, you test your model only on one image. It's hard to say only on one image how good your model is. Test it on more images to check if it's good.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "46190",
                "question_votes:": "1",
                "question_text:": "<p>I am new to deep learning. I want to create a classifier which can predict nationality names on the bases of nationality on driving license id.\nTo accomplish that, I created a data set of <strong>USA</strong> driving license images. Then created training data-set, labels and features of data and a classification model.</p>\n\n<p>When I run my python script, the accuracy was 92%.\nWhen I tested my model with different images it gave wrong result.</p>\n\n<p>Python code like this:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport h5py\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.callbacks import TensorBoard\nimport pickle\nimport os\nimport cv2\nimport time\n\nDATADIR = '/home/anupam/Documents/workspace/DjangoProject/DF-Web/datafornix/USADL_DATASET'\n\n\nCATEGORIES = [\n\n              'Alabma',\n              'Connecticut',\n               'California',\n               'Delaware',\n               'Georgia',\n               'Indiana',\n               'Louisiana',\n               'Maine',\n              'Massachusetts',\n              'MaryLand',\n             'NewHamshire',\n              'NewJersey',\n              'NewYork',\n               'NewMexico',\n              'Pennsylvania',\n              'RohodeIsland',\n              'Vermont',\n              'Virginia',\n        ]\n\nencoder = LabelEncoder()\ncity_labels = encoder.fit_transform(CATEGORIES)\n# print(city_labels)\nencoder = OneHotEncoder(sparse=False)\ncity_labels = city_labels.reshape((18, 1))\nstate_array = encoder.fit_transform(city_labels)\n\ntraining_data = []\nIMG_SIZE = 200\n\n\ndef create_traing_dataset():\n    for category in CATEGORIES:\n        path = os.path.join(DATADIR, category)\n        class_num = CATEGORIES.index(category)\n        for img in os.listdir(path):\n            for x in state_array:\n                try:\n                    img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n                    training_data.append([new_array, x])\n                except Exception as e:\n                    pass\n\n\n\ncreate_traing_dataset()\n\n\n#Randomize the dataset\n\nimport random\n\nrandom.shuffle(training_data)\n\n#Create a model\nX = []\ny = []\n\nfor features,label in training_data:\n    X.append(features)\n    y.append(label)\n\n\n\nX = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n\n\npickle_out = open(\"X.pickle\",\"wb\")\npickle.dump(X, pickle_out)\npickle_out.close()\n\n\npickle_out = open(\"y.pickle\",\"wb\")\npickle.dump(y, pickle_out)\npickle_out.close()\n\n\npickle_in = open(\"X.pickle\",\"rb\")\nX = pickle.load(pickle_in)\n\npickle_in = open(\"y.pickle\",\"rb\")\ny = pickle.load(pickle_in)\ny_data = []\nfor i in y:\n    y_data.append(i[0])\n\ny = np.array(y_data)\nprint(y)\n\nX = X/255.0\nprint(X.size)\ndense_layers = [0]\nlayer_sizes = [64]\nconv_layers = [3]\n\nfor dense_layer in dense_layers:\n    for layer_size in layer_sizes:\n        for conv_layer in conv_layers:\n            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n            print(NAME)\n\n            model = Sequential()\n\n            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n            model.add(Activation('relu'))\n            model.add(MaxPooling2D(pool_size=(2, 2)))\n\n            for l in range(conv_layer-1):\n                model.add(Conv2D(layer_size, (3, 3)))\n                model.add(Activation('relu'))\n                model.add(MaxPooling2D(pool_size=(2, 2)))\n\n            model.add(Flatten())\n\n            for _ in range(dense_layer):\n                model.add(Dense(layer_size))\n                model.add(Activation('relu'))\n\n            model.add(Dense(1))\n            model.add(Activation('sigmoid'))\n\n            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n\n            model.compile(loss='binary_crossentropy',\n                          optimizer='adam',\n                          metrics=['accuracy'],\n                          )\n\n            model.fit(X, y,\n                      batch_size=32,\n                      epochs=10,\n                      validation_split=0.3,\n                      callbacks=[tensorboard])\n\nmodel.save('64x3-CNN.model')\n</code></pre>\n\n<p>And test classifier model like this:-</p>\n\n<pre><code>import cv2\nimport tensorflow as tf\n\nmodel = tf.keras.models.load_model(\"64x3-CNN.model\")\n\nCATEGORIES = [\n\n              'Alabma',\n              'Connecticut',\n               'California',\n               'Delaware',\n               'Georgia',\n               'Indiana',\n               'Louisiana',\n               'Maine',\n              'Massachusetts',\n              'MaryLand',\n             'NewHamshire',\n              'NewJersey',\n              'NewYork',\n               'NewMexico',\n              'Pennsylvania',\n              'RohodeIsland',\n              'Vermont',\n              'Virginia',\n        ]\n\n\n\ndef prepare(filepath):\n    IMG_SIZE = 200  # 50 in txt-based\n    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)  # read in the image, convert to grayscale\n    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)  # return the image with shaping that TF wants.\n\nprediction = model.predict([prepare('/home/anupam/Documents/workspace/DjangoProject/DF-Web/datafornix/download.jpeg')])  # REMEMBER YOU'RE PASSING A LIST OF THINGS YOU WISH TO PREDICT\nprint(prediction)\nprint(CATEGORIES[int(prediction[0][0])])\n</code></pre>\n\n<p>I think, I wrong with features and labels of training data set. If I wrong this. How I resolve that case??</p>\n\n<p>What is the approach to find best result??</p>\n\n<p>Please help to clear my above query.</p>\n\n<p>Thanks</p>\n",
                "tags": "<python><neural-network><keras><tensorflow><cnn>",
                "answers": [
                    [
                        "46200",
                        "2",
                        "46190",
                        "",
                        "",
                        "<p>Inside for loops you are always creating a new model and then training it.</p>\n\n<p>Afte the loops, you are saving the model. Meaning that you only save the last model which was in a variable <code>model</code>.</p>\n\n<p>Also, you test your model only on one image. It's hard to say only on one image how good your model is. Test it on more images to check if it's good.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17571",
            "_score": 6.4162893,
            "_source": {
                "title": "Problem in implementing CNN",
                "content": "Problem in implementing CNN <p>I am using the fashion MNIST dataset to try to work this out:</p>\n\n<p>I am using the data from the links:</p>\n\n<p>Training : \n<a href=\"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\" rel=\"nofollow noreferrer\">http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz</a></p>\n\n<p>training set labels: \n<a href=\"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\" rel=\"nofollow noreferrer\">http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz</a></p>\n\n<p>test set images \n<a href=\"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\" rel=\"nofollow noreferrer\">http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz</a></p>\n\n<p>test set labels \n<a href=\"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\" rel=\"nofollow noreferrer\">http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz</a></p>\n\n<p>I use the code to open the dataset:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def load_mnist(path, kind='train'):\n    import os\n    import gzip\n    import numpy as np\n\n    \"\"\"Load MNIST data from `path`\"\"\"\n    labels_path = os.path.join(path,\n                               '%s-labels-idx1-ubyte.gz'\n                               % kind)\n    images_path = os.path.join(path,\n                               '%s-images-idx3-ubyte.gz'\n                               % kind)\n\n    with gzip.open(labels_path, 'rb') as lbpath:\n        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n                               offset=8)\n\n    with gzip.open(images_path, 'rb') as imgpath:\n        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n                               offset=16).reshape(len(labels), 784)\n\n    return images, labels\n\nlabel = ['T-shirt/top',  'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt',\n         'Sneaker', 'Bag', 'Ankle boot']\n\ndata_dir = './'\nX_train, y_train = load_mnist('D:\\book', kind='train')\nX_test, y_test = load_mnist('D:\\book', kind='t10k')\n\nX_train = X_train.astype(np.float32) / 256.0\nX_test = X_test.astype(np.float32) / 256.0\n</code></pre>\n\n<p>I am trying to build a Convolutional Neural Network with the following architecture:\n- Convolutional Layer with 32 filters with size of 3x3\n- ReLU activation function\n- 2x2 MaxPooling\n- Convolutional Layer with 64 filters with size of 3x3\n- ReLU activation function\n- 2x2 MaxPooling\n- Fully connected layer with 512 units and ReLU activation function\n- Softmax activation layer for output layer\nFor 100 epochs using the SGD optimizer</p>\n\n<p>My Code is: </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>X_train = X_train.reshape([60000, 28, 28, 1])\nX_train = X_train.astype('float32') / 255.0\nX_test = X_test.reshape([10000, 28, 28, 1])\nX_test = X_test.astype('float32') / 255.0\nmodel = Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=[28,28,1]))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(10, activation='softmax'))\nmodel.summary()\ny_train = keras.utils.np_utils.to_categorical(y_train)\ny_test = keras.utils.np_utils.to_categorical(y_test)\nmodel.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(X_train, y_train, epochs=100)\n</code></pre>\n\n<p>But it is taking a lot of time for execution. It is like 30 minutes per epoch. I think I am doing something wrong in my code. Can someone help me figure that out?</p>\n <machine-learning><python><neural-network><data-mining><cnn><p>You should also be able reduce the number of epochs you train for. In the <code>.fit()</code> method you can add your test data so you can see how well the model does on the test data at the end of each epoch. This can help you see when the model starts over fitting.   </p>\n<p>The main problem in your code is that you are passing the whole data at once ,instead of that you should use a batch size of 500 or some other value .There is a parameter of batch size in model.fit()\nas well. And you should also reduce the number of epochs.</p>\n<p>There are various ways to reduce training time per epoch.</p>\n\n<ul>\n<li>Divide the dataset into batches, like @raghav gaur suggest.</li>\n<li>Train on GPU. By default, I think Keras will use CPU.</li>\n<li>Reduce the size of the neural networks. Print out the number of parameters to get an idea about the size of your network.</li>\n</ul>\n\n<p>A good practice for debugging is to overfit one batch of data with your model. If it can't do that, there's likely a bug in your model.</p>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "56503",
                "question_votes:": "",
                "question_text:": "<p>I am using the fashion MNIST dataset to try to work this out:</p>\n\n<p>I am using the data from the links:</p>\n\n<p>Training : \n<a href=\"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\" rel=\"nofollow noreferrer\">http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz</a></p>\n\n<p>training set labels: \n<a href=\"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\" rel=\"nofollow noreferrer\">http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz</a></p>\n\n<p>test set images \n<a href=\"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\" rel=\"nofollow noreferrer\">http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz</a></p>\n\n<p>test set labels \n<a href=\"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\" rel=\"nofollow noreferrer\">http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz</a></p>\n\n<p>I use the code to open the dataset:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def load_mnist(path, kind='train'):\n    import os\n    import gzip\n    import numpy as np\n\n    \"\"\"Load MNIST data from `path`\"\"\"\n    labels_path = os.path.join(path,\n                               '%s-labels-idx1-ubyte.gz'\n                               % kind)\n    images_path = os.path.join(path,\n                               '%s-images-idx3-ubyte.gz'\n                               % kind)\n\n    with gzip.open(labels_path, 'rb') as lbpath:\n        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n                               offset=8)\n\n    with gzip.open(images_path, 'rb') as imgpath:\n        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n                               offset=16).reshape(len(labels), 784)\n\n    return images, labels\n\nlabel = ['T-shirt/top',  'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt',\n         'Sneaker', 'Bag', 'Ankle boot']\n\ndata_dir = './'\nX_train, y_train = load_mnist('D:\\book', kind='train')\nX_test, y_test = load_mnist('D:\\book', kind='t10k')\n\nX_train = X_train.astype(np.float32) / 256.0\nX_test = X_test.astype(np.float32) / 256.0\n</code></pre>\n\n<p>I am trying to build a Convolutional Neural Network with the following architecture:\n- Convolutional Layer with 32 filters with size of 3x3\n- ReLU activation function\n- 2x2 MaxPooling\n- Convolutional Layer with 64 filters with size of 3x3\n- ReLU activation function\n- 2x2 MaxPooling\n- Fully connected layer with 512 units and ReLU activation function\n- Softmax activation layer for output layer\nFor 100 epochs using the SGD optimizer</p>\n\n<p>My Code is: </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>X_train = X_train.reshape([60000, 28, 28, 1])\nX_train = X_train.astype('float32') / 255.0\nX_test = X_test.reshape([10000, 28, 28, 1])\nX_test = X_test.astype('float32') / 255.0\nmodel = Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=[28,28,1]))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(10, activation='softmax'))\nmodel.summary()\ny_train = keras.utils.np_utils.to_categorical(y_train)\ny_test = keras.utils.np_utils.to_categorical(y_test)\nmodel.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(X_train, y_train, epochs=100)\n</code></pre>\n\n<p>But it is taking a lot of time for execution. It is like 30 minutes per epoch. I think I am doing something wrong in my code. Can someone help me figure that out?</p>\n",
                "tags": "<machine-learning><python><neural-network><data-mining><cnn>",
                "answers": [
                    [
                        "58400",
                        "2",
                        "56503",
                        "",
                        "",
                        "<p>You should also be able reduce the number of epochs you train for. In the <code>.fit()</code> method you can add your test data so you can see how well the model does on the test data at the end of each epoch. This can help you see when the model starts over fitting.   </p>\n",
                        "",
                        ""
                    ],
                    [
                        "56506",
                        "2",
                        "56503",
                        "",
                        "",
                        "<p>The main problem in your code is that you are passing the whole data at once ,instead of that you should use a batch size of 500 or some other value .There is a parameter of batch size in model.fit()\nas well. And you should also reduce the number of epochs.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "58389",
                        "2",
                        "56503",
                        "",
                        "",
                        "<p>There are various ways to reduce training time per epoch.</p>\n\n<ul>\n<li>Divide the dataset into batches, like @raghav gaur suggest.</li>\n<li>Train on GPU. By default, I think Keras will use CPU.</li>\n<li>Reduce the size of the neural networks. Print out the number of parameters to get an idea about the size of your network.</li>\n</ul>\n\n<p>A good practice for debugging is to overfit one batch of data with your model. If it can't do that, there's likely a bug in your model.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9826",
            "_score": 6.413751,
            "_source": {
                "title": "Implementation of GANs",
                "content": "Implementation of GANs <p>I'm working on a particle physics dataset and want to know what libraries I would need to implement GANs and other generative algorithms like  in Python. </p>\n <python><generative-models><p>You can use Keras, docs found <a href=\"https://keras.io/\" rel=\"nofollow noreferrer\">here</a>, to train a GAN. I have provided a GAN implementation in a previous answer <a href=\"https://datascience.stackexchange.com/questions/27715/using-generative-adversarial-network-to-generate-single-image/27787#27787\">here</a>. Here is an alternative version that I have used more recently (found online).</p>\n\n<pre><code>import numpy as np\nimport time\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten, Reshape\nfrom keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\nfrom keras.layers import LeakyReLU, Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import Adam, RMSprop\n\nimport matplotlib.pyplot as plt\n\nclass ElapsedTimer(object):\n    def __init__(self):\n        self.start_time = time.time()\n    def elapsed(self,sec):\n        if sec &lt; 60:\n            return str(sec) + \" sec\"\n        elif sec &lt; (60 * 60):\n            return str(sec / 60) + \" min\"\n        else:\n            return str(sec / (60 * 60)) + \" hr\"\n    def elapsed_time(self):\n        print(\"Elapsed: %s \" % self.elapsed(time.time() - self.start_time) )\n\nclass DCGAN(object):\n    def __init__(self, img_rows=28, img_cols=28, channel=1):\n\n        self.img_rows = img_rows\n        self.img_cols = img_cols\n        self.channel = channel\n        self.D = None   # discriminator\n        self.G = None   # generator\n        self.AM = None  # adversarial model\n        self.DM = None  # discriminator model\n\n    # (W\u2212F+2P)/S+1\n    def discriminator(self):\n        if self.D:\n            return self.D\n        self.D = Sequential()\n        depth = 64\n        dropout = 0.4\n        # In: 28 x 28 x 1, depth = 1\n        # Out: 14 x 14 x 1, depth=64\n        input_shape = (self.img_rows, self.img_cols, self.channel)\n        self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape,\\\n            padding='same'))\n        self.D.add(LeakyReLU(alpha=0.2))\n        self.D.add(Dropout(dropout))\n\n        self.D.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n        self.D.add(LeakyReLU(alpha=0.2))\n        self.D.add(Dropout(dropout))\n\n        self.D.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n        self.D.add(LeakyReLU(alpha=0.2))\n        self.D.add(Dropout(dropout))\n\n        self.D.add(Conv2D(depth*8, 5, strides=1, padding='same'))\n        self.D.add(LeakyReLU(alpha=0.2))\n        self.D.add(Dropout(dropout))\n\n        # Out: 1-dim probability\n        self.D.add(Flatten())\n        self.D.add(Dense(1))\n        self.D.add(Activation('sigmoid'))\n        self.D.summary()\n        return self.D\n\n    def generator(self):\n        if self.G:\n            return self.G\n        self.G = Sequential()\n        dropout = 0.4\n        depth = 64+64+64+64\n        dim = 7\n        # In: 100\n        # Out: dim x dim x depth\n        self.G.add(Dense(dim*dim*depth, input_dim=100))\n        self.G.add(BatchNormalization(momentum=0.9))\n        self.G.add(Activation('relu'))\n        self.G.add(Reshape((dim, dim, depth)))\n        self.G.add(Dropout(dropout))\n\n        # In: dim x dim x depth\n        # Out: 2*dim x 2*dim x depth/2\n        self.G.add(UpSampling2D())\n        self.G.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n        self.G.add(BatchNormalization(momentum=0.9))\n        self.G.add(Activation('relu'))\n\n        self.G.add(UpSampling2D())\n        self.G.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n        self.G.add(BatchNormalization(momentum=0.9))\n        self.G.add(Activation('relu'))\n\n        self.G.add(Conv2DTranspose(int(depth/8), 5, padding='same'))\n        self.G.add(BatchNormalization(momentum=0.9))\n        self.G.add(Activation('relu'))\n\n        # Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix\n        self.G.add(Conv2DTranspose(1, 5, padding='same'))\n        self.G.add(Activation('sigmoid'))\n        self.G.summary()\n        return self.G\n\n    def discriminator_model(self):\n        if self.DM:\n            return self.DM\n        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n        self.DM = Sequential()\n        self.DM.add(self.discriminator())\n        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n            metrics=['accuracy'])\n        return self.DM\n\n    def adversarial_model(self):\n        if self.AM:\n            return self.AM\n        optimizer = RMSprop(lr=0.0001, decay=3e-8)\n        self.AM = Sequential()\n        self.AM.add(self.generator())\n        self.AM.add(self.discriminator())\n        self.AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n            metrics=['accuracy'])\n        return self.AM\n\nclass MNIST_DCGAN(object):\n    def __init__(self):\n        self.img_rows = 28\n        self.img_cols = 28\n        self.channel = 1\n\n        self.x_train = input_data.read_data_sets(\"mnist\",\\\n            one_hot=True).train.images\n        self.x_train = self.x_train.reshape(-1, self.img_rows,\\\n            self.img_cols, 1).astype(np.float32)\n\n        self.DCGAN = DCGAN()\n        self.discriminator =  self.DCGAN.discriminator_model()\n        self.adversarial = self.DCGAN.adversarial_model()\n        self.generator = self.DCGAN.generator()\n\n    def train(self, train_steps=2000, batch_size=256, save_interval=0):\n        noise_input = None\n        if save_interval&gt;0:\n            noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n        for i in range(train_steps):\n            images_train = self.x_train[np.random.randint(0,\n                self.x_train.shape[0], size=batch_size), :, :, :]\n            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n            images_fake = self.generator.predict(noise)\n            x = np.concatenate((images_train, images_fake))\n            y = np.ones([2*batch_size, 1])\n            y[batch_size:, :] = 0\n            d_loss = self.discriminator.train_on_batch(x, y)\n\n            y = np.ones([batch_size, 1])\n            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n            a_loss = self.adversarial.train_on_batch(noise, y)\n            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n            print(log_mesg)\n            if save_interval&gt;0:\n                if (i+1)%save_interval==0:\n                    self.plot_images(save2file=True, samples=noise_input.shape[0],\\\n                        noise=noise_input, step=(i+1))\n\n    def plot_images(self, save2file=False, fake=True, samples=16, noise=None, step=0):\n        filename = 'mnist.png'\n        if fake:\n            if noise is None:\n                noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\n            else:\n                filename = \"mnist_%d.png\" % step\n            images = self.generator.predict(noise)\n        else:\n            i = np.random.randint(0, self.x_train.shape[0], samples)\n            images = self.x_train[i, :, :, :]\n\n        plt.figure(figsize=(10,10))\n        for i in range(images.shape[0]):\n            plt.subplot(4, 4, i+1)\n            image = images[i, :, :, :]\n            image = np.reshape(image, [self.img_rows, self.img_cols])\n            plt.imshow(image, cmap='gray')\n            plt.axis('off')\n        plt.tight_layout()\n        if save2file:\n            plt.savefig(filename)\n            plt.close('all')\n        else:\n            plt.show()\n\nif __name__ == '__main__':\n    mnist_dcgan = MNIST_DCGAN()\n    timer = ElapsedTimer()\n    mnist_dcgan.train(train_steps=10000, batch_size=256, save_interval=500)\n    timer.elapsed_time()\n    mnist_dcgan.plot_images(fake=True)\n    mnist_dcgan.plot_images(fake=False, save2file=True)\n</code></pre>\n",
                "codes": [
                    [
                        "import numpy as np\nimport time\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten, Reshape\nfrom keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\nfrom keras.layers import LeakyReLU, Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import Adam, RMSprop\n\nimport matplotlib.pyplot as plt\n\nclass ElapsedTimer(object):\n    def __init__(self):\n        self.start_time = time.time()\n    def elapsed(self,sec):\n        if sec < 60:\n            return str(sec) + \" sec\"\n        elif sec < (60 * 60):\n            return str(sec / 60) + \" min\"\n        else:\n            return str(sec / (60 * 60)) + \" hr\"\n    def elapsed_time(self):\n        print(\"Elapsed: %s \" % self.elapsed(time.time() - self.start_time) )\n\nclass DCGAN(object):\n    def __init__(self, img_rows=28, img_cols=28, channel=1):\n\n        self.img_rows = img_rows\n        self.img_cols = img_cols\n        self.channel = channel\n        self.D = None   # discriminator\n        self.G = None   # generator\n        self.AM = None  # adversarial model\n        self.DM = None  # discriminator model\n\n    # (W\u2212F+2P)/S+1\n    def discriminator(self):\n        if self.D:\n            return self.D\n        self.D = Sequential()\n        depth = 64\n        dropout = 0.4\n        # In: 28 x 28 x 1, depth = 1\n        # Out: 14 x 14 x 1, depth=64\n        input_shape = (self.img_rows, self.img_cols, self.channel)\n        self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape,\\\n            padding='same'))\n        self.D.add(LeakyReLU(alpha=0.2))\n        self.D.add(Dropout(dropout))\n\n        self.D.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n        self.D.add(LeakyReLU(alpha=0.2))\n        self.D.add(Dropout(dropout))\n\n        self.D.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n        self.D.add(LeakyReLU(alpha=0.2))\n        self.D.add(Dropout(dropout))\n\n        self.D.add(Conv2D(depth*8, 5, strides=1, padding='same'))\n        self.D.add(LeakyReLU(alpha=0.2))\n        self.D.add(Dropout(dropout))\n\n        # Out: 1-dim probability\n        self.D.add(Flatten())\n        self.D.add(Dense(1))\n        self.D.add(Activation('sigmoid'))\n        self.D.summary()\n        return self.D\n\n    def generator(self):\n        if self.G:\n            return self.G\n        self.G = Sequential()\n        dropout = 0.4\n        depth = 64+64+64+64\n        dim = 7\n        # In: 100\n        # Out: dim x dim x depth\n        self.G.add(Dense(dim*dim*depth, input_dim=100))\n        self.G.add(BatchNormalization(momentum=0.9))\n        self.G.add(Activation('relu'))\n        self.G.add(Reshape((dim, dim, depth)))\n        self.G.add(Dropout(dropout))\n\n        # In: dim x dim x depth\n        # Out: 2*dim x 2*dim x depth/2\n        self.G.add(UpSampling2D())\n        self.G.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n        self.G.add(BatchNormalization(momentum=0.9))\n        self.G.add(Activation('relu'))\n\n        self.G.add(UpSampling2D())\n        self.G.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n        self.G.add(BatchNormalization(momentum=0.9))\n        self.G.add(Activation('relu'))\n\n        self.G.add(Conv2DTranspose(int(depth/8), 5, padding='same'))\n        self.G.add(BatchNormalization(momentum=0.9))\n        self.G.add(Activation('relu'))\n\n        # Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix\n        self.G.add(Conv2DTranspose(1, 5, padding='same'))\n        self.G.add(Activation('sigmoid'))\n        self.G.summary()\n        return self.G\n\n    def discriminator_model(self):\n        if self.DM:\n            return self.DM\n        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n        self.DM = Sequential()\n        self.DM.add(self.discriminator())\n        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n            metrics=['accuracy'])\n        return self.DM\n\n    def adversarial_model(self):\n        if self.AM:\n            return self.AM\n        optimizer = RMSprop(lr=0.0001, decay=3e-8)\n        self.AM = Sequential()\n        self.AM.add(self.generator())\n        self.AM.add(self.discriminator())\n        self.AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n            metrics=['accuracy'])\n        return self.AM\n\nclass MNIST_DCGAN(object):\n    def __init__(self):\n        self.img_rows = 28\n        self.img_cols = 28\n        self.channel = 1\n\n        self.x_train = input_data.read_data_sets(\"mnist\",\\\n            one_hot=True).train.images\n        self.x_train = self.x_train.reshape(-1, self.img_rows,\\\n            self.img_cols, 1).astype(np.float32)\n\n        self.DCGAN = DCGAN()\n        self.discriminator =  self.DCGAN.discriminator_model()\n        self.adversarial = self.DCGAN.adversarial_model()\n        self.generator = self.DCGAN.generator()\n\n    def train(self, train_steps=2000, batch_size=256, save_interval=0):\n        noise_input = None\n        if save_interval>0:\n            noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n        for i in range(train_steps):\n            images_train = self.x_train[np.random.randint(0,\n                self.x_train.shape[0], size=batch_size), :, :, :]\n            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n            images_fake = self.generator.predict(noise)\n            x = np.concatenate((images_train, images_fake))\n            y = np.ones([2*batch_size, 1])\n            y[batch_size:, :] = 0\n            d_loss = self.discriminator.train_on_batch(x, y)\n\n            y = np.ones([batch_size, 1])\n            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n            a_loss = self.adversarial.train_on_batch(noise, y)\n            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n            print(log_mesg)\n            if save_interval>0:\n                if (i+1)%save_interval==0:\n                    self.plot_images(save2file=True, samples=noise_input.shape[0],\\\n                        noise=noise_input, step=(i+1))\n\n    def plot_images(self, save2file=False, fake=True, samples=16, noise=None, step=0):\n        filename = 'mnist.png'\n        if fake:\n            if noise is None:\n                noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\n            else:\n                filename = \"mnist_%d.png\" % step\n            images = self.generator.predict(noise)\n        else:\n            i = np.random.randint(0, self.x_train.shape[0], samples)\n            images = self.x_train[i, :, :, :]\n\n        plt.figure(figsize=(10,10))\n        for i in range(images.shape[0]):\n            plt.subplot(4, 4, i+1)\n            image = images[i, :, :, :]\n            image = np.reshape(image, [self.img_rows, self.img_cols])\n            plt.imshow(image, cmap='gray')\n            plt.axis('off')\n        plt.tight_layout()\n        if save2file:\n            plt.savefig(filename)\n            plt.close('all')\n        else:\n            plt.show()\n\nif __name__ == '__main__':\n    mnist_dcgan = MNIST_DCGAN()\n    timer = ElapsedTimer()\n    mnist_dcgan.train(train_steps=10000, batch_size=256, save_interval=500)\n    timer.elapsed_time()\n    mnist_dcgan.plot_images(fake=True)\n    mnist_dcgan.plot_images(fake=False, save2file=True)\n"
                    ]
                ],
                "question_id:": "35835",
                "question_votes:": "1",
                "question_text:": "<p>I'm working on a particle physics dataset and want to know what libraries I would need to implement GANs and other generative algorithms like  in Python. </p>\n",
                "tags": "<python><generative-models>",
                "answers": [
                    [
                        "35844",
                        "2",
                        "35835",
                        "",
                        "",
                        "<p>You can use Keras, docs found <a href=\"https://keras.io/\" rel=\"nofollow noreferrer\">here</a>, to train a GAN. I have provided a GAN implementation in a previous answer <a href=\"https://datascience.stackexchange.com/questions/27715/using-generative-adversarial-network-to-generate-single-image/27787#27787\">here</a>. Here is an alternative version that I have used more recently (found online).</p>\n\n<pre><code>import numpy as np\nimport time\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten, Reshape\nfrom keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\nfrom keras.layers import LeakyReLU, Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import Adam, RMSprop\n\nimport matplotlib.pyplot as plt\n\nclass ElapsedTimer(object):\n    def __init__(self):\n        self.start_time = time.time()\n    def elapsed(self,sec):\n        if sec &lt; 60:\n            return str(sec) + \" sec\"\n        elif sec &lt; (60 * 60):\n            return str(sec / 60) + \" min\"\n        else:\n            return str(sec / (60 * 60)) + \" hr\"\n    def elapsed_time(self):\n        print(\"Elapsed: %s \" % self.elapsed(time.time() - self.start_time) )\n\nclass DCGAN(object):\n    def __init__(self, img_rows=28, img_cols=28, channel=1):\n\n        self.img_rows = img_rows\n        self.img_cols = img_cols\n        self.channel = channel\n        self.D = None   # discriminator\n        self.G = None   # generator\n        self.AM = None  # adversarial model\n        self.DM = None  # discriminator model\n\n    # (W\u2212F+2P)/S+1\n    def discriminator(self):\n        if self.D:\n            return self.D\n        self.D = Sequential()\n        depth = 64\n        dropout = 0.4\n        # In: 28 x 28 x 1, depth = 1\n        # Out: 14 x 14 x 1, depth=64\n        input_shape = (self.img_rows, self.img_cols, self.channel)\n        self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape,\\\n            padding='same'))\n        self.D.add(LeakyReLU(alpha=0.2))\n        self.D.add(Dropout(dropout))\n\n        self.D.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n        self.D.add(LeakyReLU(alpha=0.2))\n        self.D.add(Dropout(dropout))\n\n        self.D.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n        self.D.add(LeakyReLU(alpha=0.2))\n        self.D.add(Dropout(dropout))\n\n        self.D.add(Conv2D(depth*8, 5, strides=1, padding='same'))\n        self.D.add(LeakyReLU(alpha=0.2))\n        self.D.add(Dropout(dropout))\n\n        # Out: 1-dim probability\n        self.D.add(Flatten())\n        self.D.add(Dense(1))\n        self.D.add(Activation('sigmoid'))\n        self.D.summary()\n        return self.D\n\n    def generator(self):\n        if self.G:\n            return self.G\n        self.G = Sequential()\n        dropout = 0.4\n        depth = 64+64+64+64\n        dim = 7\n        # In: 100\n        # Out: dim x dim x depth\n        self.G.add(Dense(dim*dim*depth, input_dim=100))\n        self.G.add(BatchNormalization(momentum=0.9))\n        self.G.add(Activation('relu'))\n        self.G.add(Reshape((dim, dim, depth)))\n        self.G.add(Dropout(dropout))\n\n        # In: dim x dim x depth\n        # Out: 2*dim x 2*dim x depth/2\n        self.G.add(UpSampling2D())\n        self.G.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n        self.G.add(BatchNormalization(momentum=0.9))\n        self.G.add(Activation('relu'))\n\n        self.G.add(UpSampling2D())\n        self.G.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n        self.G.add(BatchNormalization(momentum=0.9))\n        self.G.add(Activation('relu'))\n\n        self.G.add(Conv2DTranspose(int(depth/8), 5, padding='same'))\n        self.G.add(BatchNormalization(momentum=0.9))\n        self.G.add(Activation('relu'))\n\n        # Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix\n        self.G.add(Conv2DTranspose(1, 5, padding='same'))\n        self.G.add(Activation('sigmoid'))\n        self.G.summary()\n        return self.G\n\n    def discriminator_model(self):\n        if self.DM:\n            return self.DM\n        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n        self.DM = Sequential()\n        self.DM.add(self.discriminator())\n        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n            metrics=['accuracy'])\n        return self.DM\n\n    def adversarial_model(self):\n        if self.AM:\n            return self.AM\n        optimizer = RMSprop(lr=0.0001, decay=3e-8)\n        self.AM = Sequential()\n        self.AM.add(self.generator())\n        self.AM.add(self.discriminator())\n        self.AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n            metrics=['accuracy'])\n        return self.AM\n\nclass MNIST_DCGAN(object):\n    def __init__(self):\n        self.img_rows = 28\n        self.img_cols = 28\n        self.channel = 1\n\n        self.x_train = input_data.read_data_sets(\"mnist\",\\\n            one_hot=True).train.images\n        self.x_train = self.x_train.reshape(-1, self.img_rows,\\\n            self.img_cols, 1).astype(np.float32)\n\n        self.DCGAN = DCGAN()\n        self.discriminator =  self.DCGAN.discriminator_model()\n        self.adversarial = self.DCGAN.adversarial_model()\n        self.generator = self.DCGAN.generator()\n\n    def train(self, train_steps=2000, batch_size=256, save_interval=0):\n        noise_input = None\n        if save_interval&gt;0:\n            noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n        for i in range(train_steps):\n            images_train = self.x_train[np.random.randint(0,\n                self.x_train.shape[0], size=batch_size), :, :, :]\n            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n            images_fake = self.generator.predict(noise)\n            x = np.concatenate((images_train, images_fake))\n            y = np.ones([2*batch_size, 1])\n            y[batch_size:, :] = 0\n            d_loss = self.discriminator.train_on_batch(x, y)\n\n            y = np.ones([batch_size, 1])\n            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n            a_loss = self.adversarial.train_on_batch(noise, y)\n            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n            print(log_mesg)\n            if save_interval&gt;0:\n                if (i+1)%save_interval==0:\n                    self.plot_images(save2file=True, samples=noise_input.shape[0],\\\n                        noise=noise_input, step=(i+1))\n\n    def plot_images(self, save2file=False, fake=True, samples=16, noise=None, step=0):\n        filename = 'mnist.png'\n        if fake:\n            if noise is None:\n                noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\n            else:\n                filename = \"mnist_%d.png\" % step\n            images = self.generator.predict(noise)\n        else:\n            i = np.random.randint(0, self.x_train.shape[0], samples)\n            images = self.x_train[i, :, :, :]\n\n        plt.figure(figsize=(10,10))\n        for i in range(images.shape[0]):\n            plt.subplot(4, 4, i+1)\n            image = images[i, :, :, :]\n            image = np.reshape(image, [self.img_rows, self.img_cols])\n            plt.imshow(image, cmap='gray')\n            plt.axis('off')\n        plt.tight_layout()\n        if save2file:\n            plt.savefig(filename)\n            plt.close('all')\n        else:\n            plt.show()\n\nif __name__ == '__main__':\n    mnist_dcgan = MNIST_DCGAN()\n    timer = ElapsedTimer()\n    mnist_dcgan.train(train_steps=10000, batch_size=256, save_interval=500)\n    timer.elapsed_time()\n    mnist_dcgan.plot_images(fake=True)\n    mnist_dcgan.plot_images(fake=False, save2file=True)\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11298",
            "_score": 6.413751,
            "_source": {
                "title": "How can I perform backpropagation directly in matrix form?",
                "content": "How can I perform backpropagation directly in matrix form? <p>I had made a neural network library a few months ago, and I wasn't too familiar with matrices. So, instead of performing matrix dot products (between weights and inputs, then adding a bias matrix), I simply looped through each array element (for example, I looped through every weight), and as one would expect, it's slow.</p>\n\n<p>I recently rewrote the library and employed matrix dot products (with numpy) for forward propagation, and it is way faster than the original library.</p>\n\n<p><strong>Original Forward Propagation Code:</strong></p>\n\n<pre><code>x = 0\nwhile x &lt; layers: # Loop through layers\n    if x == 0: # If it is input layer\n        y = 0\n        while y &lt; len(layervalues[x]): # Loop through neurons\n            layervalues[x][y] = sigmoid(np.sum(np.multiply(weight[x][y], input)) + bias[x][y]) # Multiplies inputs with weights and adds biases\n            y = y + 1\n    elif x == (layers - 1):\n        y = 0\n        while y &lt; len(output): # Loop through neurons\n            output[y] = sigmoid(np.sum(np.multiply(weight[x][y], layervalues[(x - 1)])) + bias[x][y]) # Multiplies last hidden layer output with weights and adds biases\n            if pxl: # Used for debugging to prevent the output from passing through the sigmoid function\n                output[y] = np.sum(np.multiply(weight[x][y], layervalues[(x - 1)])) + bias[x][y]\n            y = y + 1\n    else:\n        y = 0\n        while y &lt; len(layervalues[x]): # Loop through neurons\n            layervalues[x][y] = sigmoid(np.sum(np.multiply(weight[x][y], layervalues[(x - 1)])) + bias[x][y]) # Multiplies previous layer outputs with weights and adds biases\n            y = y + 1\n    x = x + 1\n</code></pre>\n\n<p><strong>Newer Forward Propagation Code:</strong></p>\n\n<pre><code>ip = np.asarray(ip)\nip = np.reshape(ip, (len(ip), 1))\nfor x in range(len(self.struct) - 1):\n    if x == 0:\n        food = np.dot(self.weights[x], ip)\n    else:\n        food = np.dot(self.weights[x], food)\n    if backprop:\n        self.logz[x] = np.add(food, self.biases[x])\n        np.reshape(self.logz[x], (1, len(self.logz[x])))\n    food = activation(np.add(food, self.biases[x]), self.actfunc[x])\nif backprop == True:\n    return food\nelse:\n    return np.reshape(food, (1, len(food))).tolist()[0]\n</code></pre>\n\n<p>Now that forward propagation works comparatively well, I'm trying to attempt the same for backpropagation. I need to do this because the backpropagation code takes an unacceptably long time to generate gradients for networks that have many neurons in their layers.</p>\n\n<p>Here's my current backpropagation code:</p>\n\n<pre><code>netop = self.feedForward(ip, True)\noutput = np.asarray(output)\noutput = np.reshape(output, (len(output), 1))\ndelzdela = [None] * (len(self.struct) - 1)\nweightgrad = [None] * (len(self.struct) - 1)\nbiasgrad = [None] * (len(self.struct) - 1)\nfor x in range(len(self.weights)): # Loop to calculate gradients of neurons of hidden layers\n    weightgrad[x] = np.zeros((self.struct[x + 1], self.struct[x]), dtype=np.float64)\n    biasgrad[x] = np.zeros((self.struct[x + 1], 1), dtype=np.float64)\nfor x in range(len(self.struct) - 1):\n    if x == 0:\n        delzdela[-(x + 1)] = np.dot(2, np.subtract(netop, output))\n    else:\n        delzdela[-(x + 1)] = np.zeros((self.struct[-(x + 1)], 1))\n        for y in range(self.struct[-(x + 1)]):\n            for z in range(self.struct[-x]):\n                delzdela[-(x + 1)][y] += derivative(self.logz[-x][z], self.actfunc[-x]) * delzdela[-x][z] * self.weights[-x][z][y] \nfor x in range(len(self.struct) - 1): # Calculating gradients of weights\n    for y in range(self.struct[x]):\n        for z in range(self.struct[x + 1]):\n            if x == 0:\n                weightgrad[x][z][y] = ip[y] * derivative(self.logz[x][z], self.actfunc[x]) * delzdela[x][z]\n            else:\n                weightgrad[x][z][y] = activation(self.logz[x - 1][z], self.actfunc[x - 1]) * derivative(self.logz[x][z], self.actfunc[x]) * delzdela[x][z]\nfor x in range(len(self.struct) - 1): # Calculating gradients of biases\n    for y in range(self.struct[x + 1]):\n        biasgrad[x][y] = derivative(self.logz[x][y], self.actfunc[x]) * delzdela[x][y]\nreturn [weightgrad, biasgrad]\n</code></pre>\n\n<p>This code takes a training example (<code>ip</code>) and its label (<code>output</code>) and returns the gradient for this single training example.</p>\n\n<p>As you can see, I am looping through each index and dimension of the arrays, which is very slow.</p>\n\n<p>My question is how I can directly use matrix operations to perform backpropagation, instead of looping through every index and performing operations on individual numbers.</p>\n <python><neural-network><backpropagation><performance><matrix><p>You should avoid explicit for loops in Python, whenever possible. For that, you should use the power of <strong>broadcasting</strong> and <strong>vectorization</strong> of Python NumPy. You can refer to this  short video:</p>\n\n<p><a href=\"https://www.youtube.com/watch?v=qsIrQi0fzbY\" rel=\"nofollow noreferrer\">https://www.youtube.com/watch?v=qsIrQi0fzbY</a></p>\n\n<p>For the vectorized application of backpropagation algorithm, have a look at (5:09), the algorithm at the right-hand side; you can apply this inside an (inevitable) for loop for each layer l:</p>\n\n<p><a href=\"https://www.youtube.com/watch?v=qzPQ8cEsVK8&amp;list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0&amp;index=37\" rel=\"nofollow noreferrer\">https://www.youtube.com/watch?v=qzPQ8cEsVK8&amp;list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0&amp;index=37</a></p>\n\n<p>Those videos are from Coursera course \"Deep Learning\". In the lab assigments, I became able to write forward and backpropagation algorithms by only 6 lines each by vectorizing the flows through the layers. The course instructor, Andrew Ng really forces the importance of this; Python NumPy can use parallellization structures of the CPUs and GPUs, you get both compitationally efficient (nearly about 300x faster in the course experiment) and you can write those in with few lines of codes, getting rid of the scary explicit for loops. </p>\n\n<p>I wish I could share my own code here, yet  it is prohibited by the Honor Code of Coursera, and Andrew Ng describes those basic concepts better than any way I can.</p>\n\n<p>Hope I could help. Please do not hesitate to ask more.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "39882",
                "question_votes:": "",
                "question_text:": "<p>I had made a neural network library a few months ago, and I wasn't too familiar with matrices. So, instead of performing matrix dot products (between weights and inputs, then adding a bias matrix), I simply looped through each array element (for example, I looped through every weight), and as one would expect, it's slow.</p>\n\n<p>I recently rewrote the library and employed matrix dot products (with numpy) for forward propagation, and it is way faster than the original library.</p>\n\n<p><strong>Original Forward Propagation Code:</strong></p>\n\n<pre><code>x = 0\nwhile x &lt; layers: # Loop through layers\n    if x == 0: # If it is input layer\n        y = 0\n        while y &lt; len(layervalues[x]): # Loop through neurons\n            layervalues[x][y] = sigmoid(np.sum(np.multiply(weight[x][y], input)) + bias[x][y]) # Multiplies inputs with weights and adds biases\n            y = y + 1\n    elif x == (layers - 1):\n        y = 0\n        while y &lt; len(output): # Loop through neurons\n            output[y] = sigmoid(np.sum(np.multiply(weight[x][y], layervalues[(x - 1)])) + bias[x][y]) # Multiplies last hidden layer output with weights and adds biases\n            if pxl: # Used for debugging to prevent the output from passing through the sigmoid function\n                output[y] = np.sum(np.multiply(weight[x][y], layervalues[(x - 1)])) + bias[x][y]\n            y = y + 1\n    else:\n        y = 0\n        while y &lt; len(layervalues[x]): # Loop through neurons\n            layervalues[x][y] = sigmoid(np.sum(np.multiply(weight[x][y], layervalues[(x - 1)])) + bias[x][y]) # Multiplies previous layer outputs with weights and adds biases\n            y = y + 1\n    x = x + 1\n</code></pre>\n\n<p><strong>Newer Forward Propagation Code:</strong></p>\n\n<pre><code>ip = np.asarray(ip)\nip = np.reshape(ip, (len(ip), 1))\nfor x in range(len(self.struct) - 1):\n    if x == 0:\n        food = np.dot(self.weights[x], ip)\n    else:\n        food = np.dot(self.weights[x], food)\n    if backprop:\n        self.logz[x] = np.add(food, self.biases[x])\n        np.reshape(self.logz[x], (1, len(self.logz[x])))\n    food = activation(np.add(food, self.biases[x]), self.actfunc[x])\nif backprop == True:\n    return food\nelse:\n    return np.reshape(food, (1, len(food))).tolist()[0]\n</code></pre>\n\n<p>Now that forward propagation works comparatively well, I'm trying to attempt the same for backpropagation. I need to do this because the backpropagation code takes an unacceptably long time to generate gradients for networks that have many neurons in their layers.</p>\n\n<p>Here's my current backpropagation code:</p>\n\n<pre><code>netop = self.feedForward(ip, True)\noutput = np.asarray(output)\noutput = np.reshape(output, (len(output), 1))\ndelzdela = [None] * (len(self.struct) - 1)\nweightgrad = [None] * (len(self.struct) - 1)\nbiasgrad = [None] * (len(self.struct) - 1)\nfor x in range(len(self.weights)): # Loop to calculate gradients of neurons of hidden layers\n    weightgrad[x] = np.zeros((self.struct[x + 1], self.struct[x]), dtype=np.float64)\n    biasgrad[x] = np.zeros((self.struct[x + 1], 1), dtype=np.float64)\nfor x in range(len(self.struct) - 1):\n    if x == 0:\n        delzdela[-(x + 1)] = np.dot(2, np.subtract(netop, output))\n    else:\n        delzdela[-(x + 1)] = np.zeros((self.struct[-(x + 1)], 1))\n        for y in range(self.struct[-(x + 1)]):\n            for z in range(self.struct[-x]):\n                delzdela[-(x + 1)][y] += derivative(self.logz[-x][z], self.actfunc[-x]) * delzdela[-x][z] * self.weights[-x][z][y] \nfor x in range(len(self.struct) - 1): # Calculating gradients of weights\n    for y in range(self.struct[x]):\n        for z in range(self.struct[x + 1]):\n            if x == 0:\n                weightgrad[x][z][y] = ip[y] * derivative(self.logz[x][z], self.actfunc[x]) * delzdela[x][z]\n            else:\n                weightgrad[x][z][y] = activation(self.logz[x - 1][z], self.actfunc[x - 1]) * derivative(self.logz[x][z], self.actfunc[x]) * delzdela[x][z]\nfor x in range(len(self.struct) - 1): # Calculating gradients of biases\n    for y in range(self.struct[x + 1]):\n        biasgrad[x][y] = derivative(self.logz[x][y], self.actfunc[x]) * delzdela[x][y]\nreturn [weightgrad, biasgrad]\n</code></pre>\n\n<p>This code takes a training example (<code>ip</code>) and its label (<code>output</code>) and returns the gradient for this single training example.</p>\n\n<p>As you can see, I am looping through each index and dimension of the arrays, which is very slow.</p>\n\n<p>My question is how I can directly use matrix operations to perform backpropagation, instead of looping through every index and performing operations on individual numbers.</p>\n",
                "tags": "<python><neural-network><backpropagation><performance><matrix>",
                "answers": [
                    [
                        "39884",
                        "2",
                        "39882",
                        "",
                        "",
                        "<p>You should avoid explicit for loops in Python, whenever possible. For that, you should use the power of <strong>broadcasting</strong> and <strong>vectorization</strong> of Python NumPy. You can refer to this  short video:</p>\n\n<p><a href=\"https://www.youtube.com/watch?v=qsIrQi0fzbY\" rel=\"nofollow noreferrer\">https://www.youtube.com/watch?v=qsIrQi0fzbY</a></p>\n\n<p>For the vectorized application of backpropagation algorithm, have a look at (5:09), the algorithm at the right-hand side; you can apply this inside an (inevitable) for loop for each layer l:</p>\n\n<p><a href=\"https://www.youtube.com/watch?v=qzPQ8cEsVK8&amp;list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0&amp;index=37\" rel=\"nofollow noreferrer\">https://www.youtube.com/watch?v=qzPQ8cEsVK8&amp;list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0&amp;index=37</a></p>\n\n<p>Those videos are from Coursera course \"Deep Learning\". In the lab assigments, I became able to write forward and backpropagation algorithms by only 6 lines each by vectorizing the flows through the layers. The course instructor, Andrew Ng really forces the importance of this; Python NumPy can use parallellization structures of the CPUs and GPUs, you get both compitationally efficient (nearly about 300x faster in the course experiment) and you can write those in with few lines of codes, getting rid of the scary explicit for loops. </p>\n\n<p>I wish I could share my own code here, yet  it is prohibited by the Honor Code of Coursera, and Andrew Ng describes those basic concepts better than any way I can.</p>\n\n<p>Hope I could help. Please do not hesitate to ask more.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15186",
            "_score": 6.413751,
            "_source": {
                "title": "Need a little help Understanding how to build model's in Keras",
                "content": "Need a little help Understanding how to build model's in Keras <p>I am trying to make a CNN in Keras, and to test the validity of my model i am trying to get it to train on MNIST dataset, so i am sure that everything is working fine, but unfortunately model is barely training and i suspect that nothing updating.\nMy model is :</p>\n\n<pre><code>model=Sequential()\n\n#conv1_1\nmodel.add(Conv2D(128,kernel_size=3, strides=1,\n                 padding='SAME', use_bias=False, \n                 activation='relu',name='conv1_1',input_shape=(28,28,1)))\n#conv1_2\nmodel.add(Conv2D(128, kernel_size=3, strides=1,\n                 padding='SAME', use_bias=False, \n                 activation='relu',name='conv1_2'))\nmodel.add(MaxPooling2D(pool_size=2,strides=2))\n\n#conv2_1\nmodel.add(Conv2D(64, kernel_size=3, strides=1,\n                 padding='SAME', use_bias=False, \n                 activation='relu',name=\"conv2_1\"))\n\n#conv2_2\nmodel.add(Conv2D(64, kernel_size=3, strides=1,\n                 padding='SAME', use_bias=False, \n                 activation='relu',name='conv2_2'))\nmodel.add(MaxPooling2D(pool_size=2,strides=2))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu',name='Dense1'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(512, activation='relu',name='Dense2'))\nmodel.add(Dense(10, activation='softmax',name='output'))\n</code></pre>\n\n<p>Compiled with:</p>\n\n<pre><code>model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n\nmodel.fit(X_train,y_train,batch_size=10,validation_split=0.2,epochs=10)\n</code></pre>\n\n<p>My X_train and y_train look like:</p>\n\n<pre><code>plt.imshow(X_train[0].reshape(28,28))\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/ds7p6.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ds7p6.png\" alt=\"\"></a></p>\n\n<pre><code>y_train[0]\narray([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n</code></pre>\n\n<p>Here are the Results of first 3 epochs:</p>\n\n<pre><code>Epoch 1/10\n48000/48000 [==============================] - 45s 927us/step - loss: 14.2813 - acc: 0.1140 - val_loss: 14.4096 - val_acc: 0.1060\nEpoch 2/10\n48000/48000 [==============================] - 44s 915us/step - loss: 14.2813 - acc: 0.1140 - val_loss: 14.4096 - val_acc: 0.1060\nEpoch 3/10\n48000/48000 [==============================] - 44s 924us/step - loss: 14.2813 - acc: 0.1140 - val_loss: 14.4096 - val_acc: 0.1060\nEpoch 4/10\n48000/48000 [==============================] - 45s 930us/step - loss: 14.2813 - acc: 0.1140 - val_loss: 14.4096 - val_acc: 0.1060\n</code></pre>\n\n<p>This is my first Keras Model, and i think i am missing something important here.</p>\n <keras><cnn><mnist><p>There are two things I can suspect. First, the dropout rate at the last layer seems way to high. Its better to have a lower dropout rate after each CNN layer. Secondly, you should use a bias in your CNN layers.</p>\n\n<hr>\n\n<p>Try out this code as a starting point and then you can start tuning your model from here.</p>\n\n<p>Load the data</p>\n\n<pre><code>from keras.datasets import mnist\nimport numpy as np\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\n\nprint('Training data shape: ', x_train.shape)\nprint('Testing data shape : ', x_test.shape)\n</code></pre>\n\n<p>Import Keras stuff</p>\n\n<pre><code>import keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n</code></pre>\n\n<p>Now we reshape the data such that it can fit with the tensorflow backend. This requires the channel to be the last dimension. We will also set up our one-hot encoded outputs</p>\n\n<pre><code># The known number of output classes.\nnum_classes = 10\n\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test_reshaped = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n</code></pre>\n\n<p>Define the model</p>\n\n<pre><code>model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<p>Train the model</p>\n\n<pre><code>epochs = 10\nbatch_size = 128\n# Fit the model weights.\nmodel.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n</code></pre>\n\n<p>Evaluate the model</p>\n\n<pre><code>score = model.evaluate(x_test_reshaped, y_test_binary, verbose=0)\nprint('Model accuracy:')\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n</code></pre>\n<p>I have implemented your model to the astonishment, there is a very minute error that is hard to notice.</p>\n\n<p>The way, I was able to get better accuracy is by changing the optimizer to \"SGD\" or \"ADAM\".</p>\n\n<p>As you have used \"ADADELTA\" which is an extension of \"ADAGRAD\" optimizer. In \"ADAGRAD\" has good performs on sparse data &amp; while training a large scale neural network. Its monotonic learning rate usually proves too aggressive, stops learning too early.</p>\n\n<p><a href=\"https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1\" rel=\"nofollow noreferrer\">Refer to this link for understanding on optimizers</a></p>\n",
                "codes": [
                    [
                        "from keras.datasets import mnist\nimport numpy as np\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\n\nprint('Training data shape: ', x_train.shape)\nprint('Testing data shape : ', x_test.shape)\n",
                        "import keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n",
                        "# The known number of output classes.\nnum_classes = 10\n\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test_reshaped = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n",
                        "model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n",
                        "epochs = 10\nbatch_size = 128\n# Fit the model weights.\nmodel.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n",
                        "score = model.evaluate(x_test_reshaped, y_test_binary, verbose=0)\nprint('Model accuracy:')\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n"
                    ],
                    []
                ],
                "question_id:": "51354",
                "question_votes:": "2",
                "question_text:": "<p>I am trying to make a CNN in Keras, and to test the validity of my model i am trying to get it to train on MNIST dataset, so i am sure that everything is working fine, but unfortunately model is barely training and i suspect that nothing updating.\nMy model is :</p>\n\n<pre><code>model=Sequential()\n\n#conv1_1\nmodel.add(Conv2D(128,kernel_size=3, strides=1,\n                 padding='SAME', use_bias=False, \n                 activation='relu',name='conv1_1',input_shape=(28,28,1)))\n#conv1_2\nmodel.add(Conv2D(128, kernel_size=3, strides=1,\n                 padding='SAME', use_bias=False, \n                 activation='relu',name='conv1_2'))\nmodel.add(MaxPooling2D(pool_size=2,strides=2))\n\n#conv2_1\nmodel.add(Conv2D(64, kernel_size=3, strides=1,\n                 padding='SAME', use_bias=False, \n                 activation='relu',name=\"conv2_1\"))\n\n#conv2_2\nmodel.add(Conv2D(64, kernel_size=3, strides=1,\n                 padding='SAME', use_bias=False, \n                 activation='relu',name='conv2_2'))\nmodel.add(MaxPooling2D(pool_size=2,strides=2))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu',name='Dense1'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(512, activation='relu',name='Dense2'))\nmodel.add(Dense(10, activation='softmax',name='output'))\n</code></pre>\n\n<p>Compiled with:</p>\n\n<pre><code>model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n\nmodel.fit(X_train,y_train,batch_size=10,validation_split=0.2,epochs=10)\n</code></pre>\n\n<p>My X_train and y_train look like:</p>\n\n<pre><code>plt.imshow(X_train[0].reshape(28,28))\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/ds7p6.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ds7p6.png\" alt=\"\"></a></p>\n\n<pre><code>y_train[0]\narray([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n</code></pre>\n\n<p>Here are the Results of first 3 epochs:</p>\n\n<pre><code>Epoch 1/10\n48000/48000 [==============================] - 45s 927us/step - loss: 14.2813 - acc: 0.1140 - val_loss: 14.4096 - val_acc: 0.1060\nEpoch 2/10\n48000/48000 [==============================] - 44s 915us/step - loss: 14.2813 - acc: 0.1140 - val_loss: 14.4096 - val_acc: 0.1060\nEpoch 3/10\n48000/48000 [==============================] - 44s 924us/step - loss: 14.2813 - acc: 0.1140 - val_loss: 14.4096 - val_acc: 0.1060\nEpoch 4/10\n48000/48000 [==============================] - 45s 930us/step - loss: 14.2813 - acc: 0.1140 - val_loss: 14.4096 - val_acc: 0.1060\n</code></pre>\n\n<p>This is my first Keras Model, and i think i am missing something important here.</p>\n",
                "tags": "<keras><cnn><mnist>",
                "answers": [
                    [
                        "51356",
                        "2",
                        "51354",
                        "",
                        "",
                        "<p>There are two things I can suspect. First, the dropout rate at the last layer seems way to high. Its better to have a lower dropout rate after each CNN layer. Secondly, you should use a bias in your CNN layers.</p>\n\n<hr>\n\n<p>Try out this code as a starting point and then you can start tuning your model from here.</p>\n\n<p>Load the data</p>\n\n<pre><code>from keras.datasets import mnist\nimport numpy as np\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\n\nprint('Training data shape: ', x_train.shape)\nprint('Testing data shape : ', x_test.shape)\n</code></pre>\n\n<p>Import Keras stuff</p>\n\n<pre><code>import keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n</code></pre>\n\n<p>Now we reshape the data such that it can fit with the tensorflow backend. This requires the channel to be the last dimension. We will also set up our one-hot encoded outputs</p>\n\n<pre><code># The known number of output classes.\nnum_classes = 10\n\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test_reshaped = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n</code></pre>\n\n<p>Define the model</p>\n\n<pre><code>model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<p>Train the model</p>\n\n<pre><code>epochs = 10\nbatch_size = 128\n# Fit the model weights.\nmodel.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test_reshaped, y_test_binary))\n</code></pre>\n\n<p>Evaluate the model</p>\n\n<pre><code>score = model.evaluate(x_test_reshaped, y_test_binary, verbose=0)\nprint('Model accuracy:')\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n</code></pre>\n",
                        "",
                        "1"
                    ],
                    [
                        "51366",
                        "2",
                        "51354",
                        "",
                        "",
                        "<p>I have implemented your model to the astonishment, there is a very minute error that is hard to notice.</p>\n\n<p>The way, I was able to get better accuracy is by changing the optimizer to \"SGD\" or \"ADAM\".</p>\n\n<p>As you have used \"ADADELTA\" which is an extension of \"ADAGRAD\" optimizer. In \"ADAGRAD\" has good performs on sparse data &amp; while training a large scale neural network. Its monotonic learning rate usually proves too aggressive, stops learning too early.</p>\n\n<p><a href=\"https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1\" rel=\"nofollow noreferrer\">Refer to this link for understanding on optimizers</a></p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7186",
            "_score": 6.3989315,
            "_source": {
                "title": "Adapting the Keras variational autoencoder for denoising images",
                "content": "Adapting the Keras variational autoencoder for denoising images <p><em>I am asking this question here after it went unanswered in Stack Overflow.</em></p>\n\n<p>I'm trying to adapt the Keras example for VAE <a href=\"https://blog.keras.io/building-autoencoders-in-keras.html\" rel=\"nofollow noreferrer\">https://blog.keras.io/building-autoencoders-in-keras.html</a></p>\n\n<p>I have modified the code to use noisy mnist images as the input of the autoencoder and the original, noiseless mnist images as the output.</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\nfrom keras.layers import Input, Dense, Lambda, Layer\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras import metrics\nfrom keras.datasets import mnist\n\nbatch_size = 100\noriginal_dim = 784\nlatent_dim = 2\nintermediate_dim = 256\nepochs = 1\nepsilon_std = 1.0\n\n\n\nx = Input(shape=(original_dim,))\nh = Dense(intermediate_dim, activation='relu')(x)\nz_mean = Dense(latent_dim)(h)\nz_log_var = Dense(latent_dim)(h)\n\ndef sampling(args):\n    z_mean, z_log_var = args\n    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n                              stddev=epsilon_std)\n    return z_mean + K.exp(z_log_var / 2) * epsilon\n\n\nz = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n\n# we instantiate these layers separately so as to reuse them later\ndecoder_h = Dense(intermediate_dim, activation='relu')\ndecoder_mean = Dense(original_dim, activation='sigmoid')\nh_decoded = decoder_h(z)\nx_decoded_mean = decoder_mean(h_decoded)\n\n\n# Custom loss layer\nclass CustomVariationalLayer(Layer):\n    def __init__(self, **kwargs):\n        self.is_placeholder = True\n        super(CustomVariationalLayer, self).__init__(**kwargs)\n\n    def vae_loss(self, x, x_decoded_mean):\n        xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n        return K.mean(xent_loss + kl_loss)\n\n    def call(self, inputs):\n        x = inputs[0]\n        x_decoded_mean = inputs[1]\n        loss = self.vae_loss(x, x_decoded_mean)\n        self.add_loss(loss, inputs=inputs)\n        # We won't actually use the output.\n        return x\n\ny = CustomVariationalLayer()([x, x_decoded_mean])\nvae = Model(x, y)\nvae.compile(optimizer='rmsprop', loss=None)\n\n\n# train the VAE on MNIST digits\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n\nnoise_factor = 0.5\nx_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \nx_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n\nx_train_noisy = np.clip(x_train_noisy, 0., 1.)\nx_test_noisy = np.clip(x_test_noisy, 0., 1.)\n\n\n\nvae.fit(x_train_noisy, x_train,\n        shuffle=True,\n        epochs=epochs,\n        batch_size=batch_size,\n        validation_data=( x_test_noisy,x_test))\n</code></pre>\n\n<p>But I am getting the following error message:</p>\n\n<pre><code>File \"ask_vae.py\", line 86, in &lt;module&gt;\n    validation_data=( x_test_noisy,x_test))\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 1574, in fit\n    batch_size=batch_size)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 1411, in _standardize_user_data\n    exception_prefix='target')\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 58, in _standardize_input_data\n    'expected no data, but got:', data)\nValueError: ('Error when checking model target: expected no data, but got:', array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       ...,\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32))\n</code></pre>\n\n<p>It seems that the model is not capable of receiving an output ; it works when I change the output to None, like so:</p>\n\n<pre><code>vae.fit(x_train_noisy, None,\n        shuffle=True,\n        epochs=epochs,\n        batch_size=batch_size,\n        validation_data=( x_test_noisy,None))\n</code></pre>\n\n<p>Is that because of the way the Custom Loss Layer is defined? How should I proceed?</p>\n\n<p>Thanks :)</p>\n <python><keras><autoencoder><p>From your code it is seen that <code>loss=None</code> i.e you don't give a loss function to the model.</p>\n\n<p><code>vae.compile(optimizer='rmsprop', loss=None)</code></p>\n\n<p>This is why it does not expect any target values.</p>\n<p><em>Since I asked this question here as well, I am pasting my answer to it here.</em>\nI used a different way to define the VAE loss, as demonstrated in:</p>\n\n<p><a href=\"https://github.com/keras-team/keras/blob/keras-2/examples/variational_autoencoder.py\" rel=\"nofollow noreferrer\">https://github.com/keras-team/keras/blob/keras-2/examples/variational_autoencoder.py</a></p>\n\n<p>I changed it to allow for denoising of the data. It works now, but I'll have to play around with the hyperparameters to allow it to correctly reconstruct the original images.</p>\n\n<pre><code>import numpy as np\nimport time\nimport sys\nimport os\n\n\nfrom scipy.stats import norm\n\nfrom keras.layers import Input, Dense, Lambda\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras import metrics\nfrom keras.datasets import mnist\n\nfrom keras.callbacks import ModelCheckpoint\n\nfilepath_for_w='denoise_by_VAE_weights_1.h5'\n\n\n\n###########\n##########\nexperiment_dir= 'exp_'+str(int(time.time()))\nos.mkdir(experiment_dir)\nthis_script=sys.argv[0]\nfrom shutil import copyfile\ncopyfile(this_script, experiment_dir+'/'+this_script)\n##########\n###########\n\n\nbatch_size = 100\noriginal_dim = 784\nlatent_dim = 2\nintermediate_dim = 256\nepochs = 10\nepsilon_std = 1.0\n\nx = Input(batch_shape=(batch_size, original_dim))\nh = Dense(intermediate_dim, activation='relu')(x)\nz_mean = Dense(latent_dim)(h)\nz_log_var = Dense(latent_dim)(h)\n\n\ndef sampling(args):\n    z_mean, z_log_var = args\n    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n                              stddev=epsilon_std)\n    return z_mean + K.exp(z_log_var / 2) * epsilon\n\n# note that \"output_shape\" isn't necessary with the TensorFlow backend\nz = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n\n# we instantiate these layers separately so as to reuse them later\ndecoder_h = Dense(intermediate_dim, activation='relu')\ndecoder_mean = Dense(original_dim, activation='sigmoid')\nh_decoded = decoder_h(z)\nx_decoded_mean = decoder_mean(h_decoded)\n\n\ndef vae_loss(x, x_decoded_mean):\n    xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n    return xent_loss + kl_loss\n\nvae = Model(x, x_decoded_mean)\nvae.compile(optimizer='rmsprop', loss=vae_loss)\n\n\n\n\n# train the VAE on MNIST digits\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n\n#after loading the data, change to the new experiment dir\nos.chdir(experiment_dir) #\n##########################\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n\n\nnoise_factor = 0.5\n\nx_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \nx_test_noisy = np.clip(x_test_noisy, 0., 1.)\n\n\nfor i in range (10):\n\n    x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n    x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n\n    checkpointer=ModelCheckpoint(filepath_for_w, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n    vae.fit(x_train_noisy, x_train,\n            shuffle=True,\n            epochs=epochs,\n            batch_size=batch_size,\n            validation_data=(x_test_noisy, x_test),\n            callbacks=[checkpointer])\n    vae.load_weights(filepath_for_w) \n\n    #print (x_train.shape)\n    #print (x_test.shape)\n\n    decoded_imgs = vae.predict(x_test,batch_size=batch_size)\n    np.save('decoded'+str(i)+'.npy',decoded_imgs)\n\n\nnp.save('tested.npy',x_test_noisy)\n#np.save ('true_catagories.npy',y_test)\nnp.save('original.npy',x_test)\n</code></pre>\n",
                "codes": [
                    [],
                    [
                        "import numpy as np\nimport time\nimport sys\nimport os\n\n\nfrom scipy.stats import norm\n\nfrom keras.layers import Input, Dense, Lambda\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras import metrics\nfrom keras.datasets import mnist\n\nfrom keras.callbacks import ModelCheckpoint\n\nfilepath_for_w='denoise_by_VAE_weights_1.h5'\n\n\n\n###########\n##########\nexperiment_dir= 'exp_'+str(int(time.time()))\nos.mkdir(experiment_dir)\nthis_script=sys.argv[0]\nfrom shutil import copyfile\ncopyfile(this_script, experiment_dir+'/'+this_script)\n##########\n###########\n\n\nbatch_size = 100\noriginal_dim = 784\nlatent_dim = 2\nintermediate_dim = 256\nepochs = 10\nepsilon_std = 1.0\n\nx = Input(batch_shape=(batch_size, original_dim))\nh = Dense(intermediate_dim, activation='relu')(x)\nz_mean = Dense(latent_dim)(h)\nz_log_var = Dense(latent_dim)(h)\n\n\ndef sampling(args):\n    z_mean, z_log_var = args\n    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n                              stddev=epsilon_std)\n    return z_mean + K.exp(z_log_var / 2) * epsilon\n\n# note that \"output_shape\" isn't necessary with the TensorFlow backend\nz = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n\n# we instantiate these layers separately so as to reuse them later\ndecoder_h = Dense(intermediate_dim, activation='relu')\ndecoder_mean = Dense(original_dim, activation='sigmoid')\nh_decoded = decoder_h(z)\nx_decoded_mean = decoder_mean(h_decoded)\n\n\ndef vae_loss(x, x_decoded_mean):\n    xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n    return xent_loss + kl_loss\n\nvae = Model(x, x_decoded_mean)\nvae.compile(optimizer='rmsprop', loss=vae_loss)\n\n\n\n\n# train the VAE on MNIST digits\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n\n#after loading the data, change to the new experiment dir\nos.chdir(experiment_dir) #\n##########################\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n\n\nnoise_factor = 0.5\n\nx_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \nx_test_noisy = np.clip(x_test_noisy, 0., 1.)\n\n\nfor i in range (10):\n\n    x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n    x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n\n    checkpointer=ModelCheckpoint(filepath_for_w, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n    vae.fit(x_train_noisy, x_train,\n            shuffle=True,\n            epochs=epochs,\n            batch_size=batch_size,\n            validation_data=(x_test_noisy, x_test),\n            callbacks=[checkpointer])\n    vae.load_weights(filepath_for_w) \n\n    #print (x_train.shape)\n    #print (x_test.shape)\n\n    decoded_imgs = vae.predict(x_test,batch_size=batch_size)\n    np.save('decoded'+str(i)+'.npy',decoded_imgs)\n\n\nnp.save('tested.npy',x_test_noisy)\n#np.save ('true_catagories.npy',y_test)\nnp.save('original.npy',x_test)\n"
                    ]
                ],
                "question_id:": "27136",
                "question_votes:": "1",
                "question_text:": "<p><em>I am asking this question here after it went unanswered in Stack Overflow.</em></p>\n\n<p>I'm trying to adapt the Keras example for VAE <a href=\"https://blog.keras.io/building-autoencoders-in-keras.html\" rel=\"nofollow noreferrer\">https://blog.keras.io/building-autoencoders-in-keras.html</a></p>\n\n<p>I have modified the code to use noisy mnist images as the input of the autoencoder and the original, noiseless mnist images as the output.</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\nfrom keras.layers import Input, Dense, Lambda, Layer\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras import metrics\nfrom keras.datasets import mnist\n\nbatch_size = 100\noriginal_dim = 784\nlatent_dim = 2\nintermediate_dim = 256\nepochs = 1\nepsilon_std = 1.0\n\n\n\nx = Input(shape=(original_dim,))\nh = Dense(intermediate_dim, activation='relu')(x)\nz_mean = Dense(latent_dim)(h)\nz_log_var = Dense(latent_dim)(h)\n\ndef sampling(args):\n    z_mean, z_log_var = args\n    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n                              stddev=epsilon_std)\n    return z_mean + K.exp(z_log_var / 2) * epsilon\n\n\nz = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n\n# we instantiate these layers separately so as to reuse them later\ndecoder_h = Dense(intermediate_dim, activation='relu')\ndecoder_mean = Dense(original_dim, activation='sigmoid')\nh_decoded = decoder_h(z)\nx_decoded_mean = decoder_mean(h_decoded)\n\n\n# Custom loss layer\nclass CustomVariationalLayer(Layer):\n    def __init__(self, **kwargs):\n        self.is_placeholder = True\n        super(CustomVariationalLayer, self).__init__(**kwargs)\n\n    def vae_loss(self, x, x_decoded_mean):\n        xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n        return K.mean(xent_loss + kl_loss)\n\n    def call(self, inputs):\n        x = inputs[0]\n        x_decoded_mean = inputs[1]\n        loss = self.vae_loss(x, x_decoded_mean)\n        self.add_loss(loss, inputs=inputs)\n        # We won't actually use the output.\n        return x\n\ny = CustomVariationalLayer()([x, x_decoded_mean])\nvae = Model(x, y)\nvae.compile(optimizer='rmsprop', loss=None)\n\n\n# train the VAE on MNIST digits\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n\nnoise_factor = 0.5\nx_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \nx_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n\nx_train_noisy = np.clip(x_train_noisy, 0., 1.)\nx_test_noisy = np.clip(x_test_noisy, 0., 1.)\n\n\n\nvae.fit(x_train_noisy, x_train,\n        shuffle=True,\n        epochs=epochs,\n        batch_size=batch_size,\n        validation_data=( x_test_noisy,x_test))\n</code></pre>\n\n<p>But I am getting the following error message:</p>\n\n<pre><code>File \"ask_vae.py\", line 86, in &lt;module&gt;\n    validation_data=( x_test_noisy,x_test))\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 1574, in fit\n    batch_size=batch_size)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 1411, in _standardize_user_data\n    exception_prefix='target')\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 58, in _standardize_input_data\n    'expected no data, but got:', data)\nValueError: ('Error when checking model target: expected no data, but got:', array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       ...,\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32))\n</code></pre>\n\n<p>It seems that the model is not capable of receiving an output ; it works when I change the output to None, like so:</p>\n\n<pre><code>vae.fit(x_train_noisy, None,\n        shuffle=True,\n        epochs=epochs,\n        batch_size=batch_size,\n        validation_data=( x_test_noisy,None))\n</code></pre>\n\n<p>Is that because of the way the Custom Loss Layer is defined? How should I proceed?</p>\n\n<p>Thanks :)</p>\n",
                "tags": "<python><keras><autoencoder>",
                "answers": [
                    [
                        "54882",
                        "2",
                        "27136",
                        "",
                        "",
                        "<p>From your code it is seen that <code>loss=None</code> i.e you don't give a loss function to the model.</p>\n\n<p><code>vae.compile(optimizer='rmsprop', loss=None)</code></p>\n\n<p>This is why it does not expect any target values.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "27246",
                        "2",
                        "27136",
                        "",
                        "",
                        "<p><em>Since I asked this question here as well, I am pasting my answer to it here.</em>\nI used a different way to define the VAE loss, as demonstrated in:</p>\n\n<p><a href=\"https://github.com/keras-team/keras/blob/keras-2/examples/variational_autoencoder.py\" rel=\"nofollow noreferrer\">https://github.com/keras-team/keras/blob/keras-2/examples/variational_autoencoder.py</a></p>\n\n<p>I changed it to allow for denoising of the data. It works now, but I'll have to play around with the hyperparameters to allow it to correctly reconstruct the original images.</p>\n\n<pre><code>import numpy as np\nimport time\nimport sys\nimport os\n\n\nfrom scipy.stats import norm\n\nfrom keras.layers import Input, Dense, Lambda\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras import metrics\nfrom keras.datasets import mnist\n\nfrom keras.callbacks import ModelCheckpoint\n\nfilepath_for_w='denoise_by_VAE_weights_1.h5'\n\n\n\n###########\n##########\nexperiment_dir= 'exp_'+str(int(time.time()))\nos.mkdir(experiment_dir)\nthis_script=sys.argv[0]\nfrom shutil import copyfile\ncopyfile(this_script, experiment_dir+'/'+this_script)\n##########\n###########\n\n\nbatch_size = 100\noriginal_dim = 784\nlatent_dim = 2\nintermediate_dim = 256\nepochs = 10\nepsilon_std = 1.0\n\nx = Input(batch_shape=(batch_size, original_dim))\nh = Dense(intermediate_dim, activation='relu')(x)\nz_mean = Dense(latent_dim)(h)\nz_log_var = Dense(latent_dim)(h)\n\n\ndef sampling(args):\n    z_mean, z_log_var = args\n    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n                              stddev=epsilon_std)\n    return z_mean + K.exp(z_log_var / 2) * epsilon\n\n# note that \"output_shape\" isn't necessary with the TensorFlow backend\nz = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n\n# we instantiate these layers separately so as to reuse them later\ndecoder_h = Dense(intermediate_dim, activation='relu')\ndecoder_mean = Dense(original_dim, activation='sigmoid')\nh_decoded = decoder_h(z)\nx_decoded_mean = decoder_mean(h_decoded)\n\n\ndef vae_loss(x, x_decoded_mean):\n    xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n    return xent_loss + kl_loss\n\nvae = Model(x, x_decoded_mean)\nvae.compile(optimizer='rmsprop', loss=vae_loss)\n\n\n\n\n# train the VAE on MNIST digits\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n\n#after loading the data, change to the new experiment dir\nos.chdir(experiment_dir) #\n##########################\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n\n\nnoise_factor = 0.5\n\nx_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \nx_test_noisy = np.clip(x_test_noisy, 0., 1.)\n\n\nfor i in range (10):\n\n    x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n    x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n\n    checkpointer=ModelCheckpoint(filepath_for_w, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n    vae.fit(x_train_noisy, x_train,\n            shuffle=True,\n            epochs=epochs,\n            batch_size=batch_size,\n            validation_data=(x_test_noisy, x_test),\n            callbacks=[checkpointer])\n    vae.load_weights(filepath_for_w) \n\n    #print (x_train.shape)\n    #print (x_test.shape)\n\n    decoded_imgs = vae.predict(x_test,batch_size=batch_size)\n    np.save('decoded'+str(i)+'.npy',decoded_imgs)\n\n\nnp.save('tested.npy',x_test_noisy)\n#np.save ('true_catagories.npy',y_test)\nnp.save('original.npy',x_test)\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14637",
            "_score": 6.3388624,
            "_source": {
                "title": "Inverse Relationship Between Precision and Recall",
                "content": "Inverse Relationship Between Precision and Recall <p>I made some search to learn precision and recall and I saw some graphs represents inverse relationship between precision and recall and I started to think about it to clarify subject. I wonder the inverse relationship always hold? Suppose I have a binary classification problem and there are positive and negative labeled classes. After training some of the actual positive examples are predicted as true positives and some of them false negatives and some of the actual negative examples are predicted as true negatives and some of them false positives. To calculate precision and recall I use these formulas: \n<span class=\"math-container\">$$Precision = \\frac{TP}{TP + FP}$$</span> and <span class=\"math-container\">$$Recall = \\frac{TP}{TP + FN}$$</span> If I decrease false negatives then true positives increases and in that case don't precision and recall both increase?</p>\n <accuracy><confusion-matrix><p>If we decrease the false negative (select more positives), recall always increases, but precision may increase or decrease. Generally, for models better than random, precision and recall have an <strong>inverse</strong> relationship (<a href=\"https://datascience.stackexchange.com/a/49121/67328\">@pythinker</a>'s answer), but for models worse than random, they have a <strong>direct</strong> relationship (<a href=\"https://datascience.stackexchange.com/a/49129/67328\">@kbrose</a>'s example).</p>\n\n<p>It is worth noting that we can artificially build a sample that causes a model which is better-than-random on true distribution to perform worse-than-random, so we are assuming that the sample resembles the true distribution.</p>\n\n<h3>Recall</h3>\n\n<p>We have\n<span class=\"math-container\">$$TP = P - FN$$</span>\ntherefore, recall would be\n<span class=\"math-container\">$$r = \\frac{P-FN}{P} = 1- \\frac{FN}{P}$$</span>\nwhich always increases by decrease in <span class=\"math-container\">$FN$</span>.</p>\n\n<h3>Precision</h3>\n\n<p>For precision, the relation is not as straightforward. Lets start with two examples.</p>\n\n<p><strong>First case</strong>: decrease in precision, by decrease in false negative:</p>\n\n<pre><code>label   model prediction\n1       0.8\n0       0.2\n0       0.2\n1       0.2\n</code></pre>\n\n<p>For threshold <span class=\"math-container\">$0.5$</span> (false negative = <span class=\"math-container\">$\\{(1, 0.2)\\}$</span>), </p>\n\n<p><span class=\"math-container\">$$p = \\frac{1}{1+0}=1$$</span></p>\n\n<p>For threshold <span class=\"math-container\">$0.0$</span> (false negative = <span class=\"math-container\">$\\{\\}$</span>),</p>\n\n<p><span class=\"math-container\">$$p = \\frac{2}{2+2}=0.5$$</span></p>\n\n<p><strong>Second case</strong>: increase in precision, by decrease in false negative (the same as <a href=\"https://datascience.stackexchange.com/a/49129/67328\">@kbrose</a> example):</p>\n\n<pre><code>label   model prediction\n0       1.0\n1       0.4\n0       0.1\n</code></pre>\n\n<p>For threshold <span class=\"math-container\">$0.5$</span> (false negative = <span class=\"math-container\">$\\{(1, 0.4)\\}$</span>), </p>\n\n<p><span class=\"math-container\">$$p = \\frac{0}{0+1}=0$$</span></p>\n\n<p>For threshold <span class=\"math-container\">$0.0$</span> (false negative = <span class=\"math-container\">$\\{\\}$</span>),</p>\n\n<p><span class=\"math-container\">$$p = \\frac{1}{1+2}=0.33$$</span></p>\n\n<p>It is worth noting that ROC curve for this case is</p>\n\n<p><img src=\"https://i.stack.imgur.com/7Yszb.png\" width=\"600\" /></p>\n\n<h3>Analysis of precision based on ROC curve</h3>\n\n<p>When we lower the threshold, false negative decreases, and true positive [rate] increases, which is equivalent to <strong>moving to the right in ROC plot</strong>. I did a simulation for better-than-random, random, and worse-than-random models, and plotted ROC, recall, and precision:</p>\n\n<p><img src=\"https://i.stack.imgur.com/TWTsm.png\" width=\"600\" /></p>\n\n<p><img src=\"https://i.stack.imgur.com/RMI9u.png\" width=\"600\" /></p>\n\n<p><img src=\"https://i.stack.imgur.com/69wGa.png\" width=\"600\" /></p>\n\n<p>As you can see, by moving to the right, for better-than-random model, precision decreases, for random model, precision has substantial fluctuations, and for worse-than-random model precision increases. And there are slight fluctuations in all three cases.  Therefore,  </p>\n\n<blockquote>\n  <p>By increase in recall, if model is better than random, precision generally decreases. If mode is worse than random, precision generally increases.</p>\n</blockquote>\n\n<p>Here is the code for simulation:</p>\n\n<pre><code>import numpy as np\nfrom sklearn.metrics import roc_curve\nfrom matplotlib import pyplot\n\nnp.random.seed(123)\ncount = 2000\nP = int(count * 0.5)\nN = count - P\n# first half zero, second half one\ny_true = np.concatenate((np.zeros((N, 1)), np.ones((P, 1))))\n\ntitle = 'Better-than-random model'\n# title = 'Random model'\n# title = 'Worse-than-random model'\nif title == 'Better-than-random model':\n    # GOOD: model output increases from 0 to 1 with noise\n    y_score = np.array([p + np.random.randint(-1000, 1000)/3000\n                        for p in np.arange(0, 1, 1.0 / count)]).reshape((-1, 1))\nelif title == 'Random model':\n    # RANDOM: model output is purely random\n    y_score = np.array([np.random.randint(-1000, 1000)/3000\n                        for p in np.arange(0, 1, 1.0 / count)]).reshape((-1, 1))\nelif title == 'Worse-than-random model':\n    # SUB RANDOM: model output decreases from 0 to -1 (worse than random)\n    y_score = np.array([-p + np.random.randint(-1000, 1000)/1000\n                        for p in np.arange(0, 1, 1.0 / count)]).reshape((-1, 1))\n\n# calculate ROC (fpr, tpr) points\nfpr, tpr, thresholds = roc_curve(y_true, y_score)\n# calculate recall, precision, and accuracy for corresponding thresholds\n# recall = TP / P\nrecall = np.array([np.sum(y_true[y_score &gt; t])/P\n                   for t in thresholds]).reshape((-1, 1))\n# precision = TP / (TP + FP)\nprecision = np.array([np.sum(y_true[y_score &gt; t])/np.count_nonzero(y_score &gt; t)\n                      for t in thresholds]).reshape((-1, 1))\n# accuracy = (TP + TN) / (P + N)\naccuracy = np.array([(np.sum(y_true[y_score &gt; t]) + np.sum(1 - y_true[y_score &lt; t]))\n                     /len(y_score)\n                      for t in thresholds]).reshape((-1, 1))\n\n# Sort performance measures from min tpr to max tpr\nindex = np.argsort(tpr)\ntpr_sorted = tpr[index]\nrecall_sorted = recall[index]\nprecision_sorted = precision[index]\naccuracy_sorted = accuracy[index]\n\n# visualize\nfig, ax = pyplot.subplots(3, 1)\nfig.suptitle(title, fontsize=12)\n\nline = np.arange(0, len(thresholds))/len(thresholds)\nax[0].plot(fpr, tpr, label='ROC', color='purple')\nax[0].plot(line, line, '--', label='random', color='black')\nax[0].set_xlabel('fpr')\nax[0].legend(loc='center left', bbox_to_anchor=(1, 0.5))\nax[1].plot(line, recall, label='recall', color='blue')\nax[1].plot(line, precision, label='precision', color='red')\nax[1].plot(line, accuracy, label='accuracy', color='black')\nax[1].set_xlabel('1 - threshold')\nax[1].legend(loc='center left', bbox_to_anchor=(1, 0.5))\nax[2].plot(tpr_sorted, recall_sorted, label='recall', color='blue')\nax[2].plot(tpr_sorted, precision_sorted, label='precision', color='red')\nax[2].plot(tpr_sorted, accuracy_sorted, label='accuracy', color='black')\nax[2].set_xlabel('tpr (1 - fnr)')\nax[2].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n\nfig.tight_layout()\nfig.subplots_adjust(top=0.88)\npyplot.show()\n</code></pre>\n<p>You are correct @Tolga, both can increase at the same time. Consider the following data:</p>\n\n<pre><code>Prediction | True Class\n       1.0 | 0\n       0.5 | 1\n       0.0 | 0\n</code></pre>\n\n<p>If you set your cut off point as 0.75, then you have</p>\n\n<p><span class=\"math-container\">$$ Precision = \\frac{TP}{TP + FP} = \\frac{0}{0 + 1} = 0 $$</span>\n<span class=\"math-container\">$$ Recall = \\frac{TP}{TP + FN} = \\frac{0}{0 + 1} = 0$$</span></p>\n\n<p>then if you decrease your cut off point to 0.25, you have</p>\n\n<p><span class=\"math-container\">$$ Precision = \\frac{TP}{TP + FP} = \\frac{1}{1 + 1} = 0.5 $$</span>\n<span class=\"math-container\">$$ Recall = \\frac{TP}{TP + FN} = \\frac{1}{1 + 0} = 1$$</span></p>\n\n<p>and so you can see, both precision and recall increased when we decreased the number of False Negatives.</p>\n<p>Thanks for clear statement of the problem. The point is that if you want to decrease false negatives, you should sufficiently lower the threshold of your decision function. If the false negatives are decreased, as you mentioned, true positives increase but false positives <strong>can</strong> also increase. As a result, recall will increase and precision will decrease.</p>\n",
                "codes": [
                    [
                        "label   model prediction\n1       0.8\n0       0.2\n0       0.2\n1       0.2\n",
                        "label   model prediction\n0       1.0\n1       0.4\n0       0.1\n",
                        "import numpy as np\nfrom sklearn.metrics import roc_curve\nfrom matplotlib import pyplot\n\nnp.random.seed(123)\ncount = 2000\nP = int(count * 0.5)\nN = count - P\n# first half zero, second half one\ny_true = np.concatenate((np.zeros((N, 1)), np.ones((P, 1))))\n\ntitle = 'Better-than-random model'\n# title = 'Random model'\n# title = 'Worse-than-random model'\nif title == 'Better-than-random model':\n    # GOOD: model output increases from 0 to 1 with noise\n    y_score = np.array([p + np.random.randint(-1000, 1000)/3000\n                        for p in np.arange(0, 1, 1.0 / count)]).reshape((-1, 1))\nelif title == 'Random model':\n    # RANDOM: model output is purely random\n    y_score = np.array([np.random.randint(-1000, 1000)/3000\n                        for p in np.arange(0, 1, 1.0 / count)]).reshape((-1, 1))\nelif title == 'Worse-than-random model':\n    # SUB RANDOM: model output decreases from 0 to -1 (worse than random)\n    y_score = np.array([-p + np.random.randint(-1000, 1000)/1000\n                        for p in np.arange(0, 1, 1.0 / count)]).reshape((-1, 1))\n\n# calculate ROC (fpr, tpr) points\nfpr, tpr, thresholds = roc_curve(y_true, y_score)\n# calculate recall, precision, and accuracy for corresponding thresholds\n# recall = TP / P\nrecall = np.array([np.sum(y_true[y_score > t])/P\n                   for t in thresholds]).reshape((-1, 1))\n# precision = TP / (TP + FP)\nprecision = np.array([np.sum(y_true[y_score > t])/np.count_nonzero(y_score > t)\n                      for t in thresholds]).reshape((-1, 1))\n# accuracy = (TP + TN) / (P + N)\naccuracy = np.array([(np.sum(y_true[y_score > t]) + np.sum(1 - y_true[y_score < t]))\n                     /len(y_score)\n                      for t in thresholds]).reshape((-1, 1))\n\n# Sort performance measures from min tpr to max tpr\nindex = np.argsort(tpr)\ntpr_sorted = tpr[index]\nrecall_sorted = recall[index]\nprecision_sorted = precision[index]\naccuracy_sorted = accuracy[index]\n\n# visualize\nfig, ax = pyplot.subplots(3, 1)\nfig.suptitle(title, fontsize=12)\n\nline = np.arange(0, len(thresholds))/len(thresholds)\nax[0].plot(fpr, tpr, label='ROC', color='purple')\nax[0].plot(line, line, '--', label='random', color='black')\nax[0].set_xlabel('fpr')\nax[0].legend(loc='center left', bbox_to_anchor=(1, 0.5))\nax[1].plot(line, recall, label='recall', color='blue')\nax[1].plot(line, precision, label='precision', color='red')\nax[1].plot(line, accuracy, label='accuracy', color='black')\nax[1].set_xlabel('1 - threshold')\nax[1].legend(loc='center left', bbox_to_anchor=(1, 0.5))\nax[2].plot(tpr_sorted, recall_sorted, label='recall', color='blue')\nax[2].plot(tpr_sorted, precision_sorted, label='precision', color='red')\nax[2].plot(tpr_sorted, accuracy_sorted, label='accuracy', color='black')\nax[2].set_xlabel('tpr (1 - fnr)')\nax[2].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n\nfig.tight_layout()\nfig.subplots_adjust(top=0.88)\npyplot.show()\n"
                    ],
                    [
                        "Prediction | True Class\n       1.0 | 0\n       0.5 | 1\n       0.0 | 0\n"
                    ],
                    []
                ],
                "question_id:": "49117",
                "question_votes:": "7",
                "question_text:": "<p>I made some search to learn precision and recall and I saw some graphs represents inverse relationship between precision and recall and I started to think about it to clarify subject. I wonder the inverse relationship always hold? Suppose I have a binary classification problem and there are positive and negative labeled classes. After training some of the actual positive examples are predicted as true positives and some of them false negatives and some of the actual negative examples are predicted as true negatives and some of them false positives. To calculate precision and recall I use these formulas: \n<span class=\"math-container\">$$Precision = \\frac{TP}{TP + FP}$$</span> and <span class=\"math-container\">$$Recall = \\frac{TP}{TP + FN}$$</span> If I decrease false negatives then true positives increases and in that case don't precision and recall both increase?</p>\n",
                "tags": "<accuracy><confusion-matrix>",
                "answers": [
                    [
                        "49143",
                        "2",
                        "49117",
                        "",
                        "",
                        "<p>If we decrease the false negative (select more positives), recall always increases, but precision may increase or decrease. Generally, for models better than random, precision and recall have an <strong>inverse</strong> relationship (<a href=\"https://datascience.stackexchange.com/a/49121/67328\">@pythinker</a>'s answer), but for models worse than random, they have a <strong>direct</strong> relationship (<a href=\"https://datascience.stackexchange.com/a/49129/67328\">@kbrose</a>'s example).</p>\n\n<p>It is worth noting that we can artificially build a sample that causes a model which is better-than-random on true distribution to perform worse-than-random, so we are assuming that the sample resembles the true distribution.</p>\n\n<h3>Recall</h3>\n\n<p>We have\n<span class=\"math-container\">$$TP = P - FN$$</span>\ntherefore, recall would be\n<span class=\"math-container\">$$r = \\frac{P-FN}{P} = 1- \\frac{FN}{P}$$</span>\nwhich always increases by decrease in <span class=\"math-container\">$FN$</span>.</p>\n\n<h3>Precision</h3>\n\n<p>For precision, the relation is not as straightforward. Lets start with two examples.</p>\n\n<p><strong>First case</strong>: decrease in precision, by decrease in false negative:</p>\n\n<pre><code>label   model prediction\n1       0.8\n0       0.2\n0       0.2\n1       0.2\n</code></pre>\n\n<p>For threshold <span class=\"math-container\">$0.5$</span> (false negative = <span class=\"math-container\">$\\{(1, 0.2)\\}$</span>), </p>\n\n<p><span class=\"math-container\">$$p = \\frac{1}{1+0}=1$$</span></p>\n\n<p>For threshold <span class=\"math-container\">$0.0$</span> (false negative = <span class=\"math-container\">$\\{\\}$</span>),</p>\n\n<p><span class=\"math-container\">$$p = \\frac{2}{2+2}=0.5$$</span></p>\n\n<p><strong>Second case</strong>: increase in precision, by decrease in false negative (the same as <a href=\"https://datascience.stackexchange.com/a/49129/67328\">@kbrose</a> example):</p>\n\n<pre><code>label   model prediction\n0       1.0\n1       0.4\n0       0.1\n</code></pre>\n\n<p>For threshold <span class=\"math-container\">$0.5$</span> (false negative = <span class=\"math-container\">$\\{(1, 0.4)\\}$</span>), </p>\n\n<p><span class=\"math-container\">$$p = \\frac{0}{0+1}=0$$</span></p>\n\n<p>For threshold <span class=\"math-container\">$0.0$</span> (false negative = <span class=\"math-container\">$\\{\\}$</span>),</p>\n\n<p><span class=\"math-container\">$$p = \\frac{1}{1+2}=0.33$$</span></p>\n\n<p>It is worth noting that ROC curve for this case is</p>\n\n<p><img src=\"https://i.stack.imgur.com/7Yszb.png\" width=\"600\" /></p>\n\n<h3>Analysis of precision based on ROC curve</h3>\n\n<p>When we lower the threshold, false negative decreases, and true positive [rate] increases, which is equivalent to <strong>moving to the right in ROC plot</strong>. I did a simulation for better-than-random, random, and worse-than-random models, and plotted ROC, recall, and precision:</p>\n\n<p><img src=\"https://i.stack.imgur.com/TWTsm.png\" width=\"600\" /></p>\n\n<p><img src=\"https://i.stack.imgur.com/RMI9u.png\" width=\"600\" /></p>\n\n<p><img src=\"https://i.stack.imgur.com/69wGa.png\" width=\"600\" /></p>\n\n<p>As you can see, by moving to the right, for better-than-random model, precision decreases, for random model, precision has substantial fluctuations, and for worse-than-random model precision increases. And there are slight fluctuations in all three cases.  Therefore,  </p>\n\n<blockquote>\n  <p>By increase in recall, if model is better than random, precision generally decreases. If mode is worse than random, precision generally increases.</p>\n</blockquote>\n\n<p>Here is the code for simulation:</p>\n\n<pre><code>import numpy as np\nfrom sklearn.metrics import roc_curve\nfrom matplotlib import pyplot\n\nnp.random.seed(123)\ncount = 2000\nP = int(count * 0.5)\nN = count - P\n# first half zero, second half one\ny_true = np.concatenate((np.zeros((N, 1)), np.ones((P, 1))))\n\ntitle = 'Better-than-random model'\n# title = 'Random model'\n# title = 'Worse-than-random model'\nif title == 'Better-than-random model':\n    # GOOD: model output increases from 0 to 1 with noise\n    y_score = np.array([p + np.random.randint(-1000, 1000)/3000\n                        for p in np.arange(0, 1, 1.0 / count)]).reshape((-1, 1))\nelif title == 'Random model':\n    # RANDOM: model output is purely random\n    y_score = np.array([np.random.randint(-1000, 1000)/3000\n                        for p in np.arange(0, 1, 1.0 / count)]).reshape((-1, 1))\nelif title == 'Worse-than-random model':\n    # SUB RANDOM: model output decreases from 0 to -1 (worse than random)\n    y_score = np.array([-p + np.random.randint(-1000, 1000)/1000\n                        for p in np.arange(0, 1, 1.0 / count)]).reshape((-1, 1))\n\n# calculate ROC (fpr, tpr) points\nfpr, tpr, thresholds = roc_curve(y_true, y_score)\n# calculate recall, precision, and accuracy for corresponding thresholds\n# recall = TP / P\nrecall = np.array([np.sum(y_true[y_score &gt; t])/P\n                   for t in thresholds]).reshape((-1, 1))\n# precision = TP / (TP + FP)\nprecision = np.array([np.sum(y_true[y_score &gt; t])/np.count_nonzero(y_score &gt; t)\n                      for t in thresholds]).reshape((-1, 1))\n# accuracy = (TP + TN) / (P + N)\naccuracy = np.array([(np.sum(y_true[y_score &gt; t]) + np.sum(1 - y_true[y_score &lt; t]))\n                     /len(y_score)\n                      for t in thresholds]).reshape((-1, 1))\n\n# Sort performance measures from min tpr to max tpr\nindex = np.argsort(tpr)\ntpr_sorted = tpr[index]\nrecall_sorted = recall[index]\nprecision_sorted = precision[index]\naccuracy_sorted = accuracy[index]\n\n# visualize\nfig, ax = pyplot.subplots(3, 1)\nfig.suptitle(title, fontsize=12)\n\nline = np.arange(0, len(thresholds))/len(thresholds)\nax[0].plot(fpr, tpr, label='ROC', color='purple')\nax[0].plot(line, line, '--', label='random', color='black')\nax[0].set_xlabel('fpr')\nax[0].legend(loc='center left', bbox_to_anchor=(1, 0.5))\nax[1].plot(line, recall, label='recall', color='blue')\nax[1].plot(line, precision, label='precision', color='red')\nax[1].plot(line, accuracy, label='accuracy', color='black')\nax[1].set_xlabel('1 - threshold')\nax[1].legend(loc='center left', bbox_to_anchor=(1, 0.5))\nax[2].plot(tpr_sorted, recall_sorted, label='recall', color='blue')\nax[2].plot(tpr_sorted, precision_sorted, label='precision', color='red')\nax[2].plot(tpr_sorted, accuracy_sorted, label='accuracy', color='black')\nax[2].set_xlabel('tpr (1 - fnr)')\nax[2].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n\nfig.tight_layout()\nfig.subplots_adjust(top=0.88)\npyplot.show()\n</code></pre>\n",
                        "",
                        "4"
                    ],
                    [
                        "49129",
                        "2",
                        "49117",
                        "",
                        "",
                        "<p>You are correct @Tolga, both can increase at the same time. Consider the following data:</p>\n\n<pre><code>Prediction | True Class\n       1.0 | 0\n       0.5 | 1\n       0.0 | 0\n</code></pre>\n\n<p>If you set your cut off point as 0.75, then you have</p>\n\n<p><span class=\"math-container\">$$ Precision = \\frac{TP}{TP + FP} = \\frac{0}{0 + 1} = 0 $$</span>\n<span class=\"math-container\">$$ Recall = \\frac{TP}{TP + FN} = \\frac{0}{0 + 1} = 0$$</span></p>\n\n<p>then if you decrease your cut off point to 0.25, you have</p>\n\n<p><span class=\"math-container\">$$ Precision = \\frac{TP}{TP + FP} = \\frac{1}{1 + 1} = 0.5 $$</span>\n<span class=\"math-container\">$$ Recall = \\frac{TP}{TP + FN} = \\frac{1}{1 + 0} = 1$$</span></p>\n\n<p>and so you can see, both precision and recall increased when we decreased the number of False Negatives.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "49121",
                        "2",
                        "49117",
                        "",
                        "",
                        "<p>Thanks for clear statement of the problem. The point is that if you want to decrease false negatives, you should sufficiently lower the threshold of your decision function. If the false negatives are decreased, as you mentioned, true positives increase but false positives <strong>can</strong> also increase. As a result, recall will increase and precision will decrease.</p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8361",
            "_score": 6.3237486,
            "_source": {
                "title": "Neural network does not converge with negative symbols",
                "content": "Neural network does not converge with negative symbols <p>I've created a simple 2-2-1 feedforward ANN to predict an XOR using Keras.</p>\n\n<p>The activation function I'm using on all layers is a <em>tanh</em>, so in order to make use of the entire range of the function, <em>i.e.</em> [-1, 1], I've decided to use -1 instead of 0 as the symbol.</p>\n\n<p>My input data is, thus, <code>[[-1, -1], [-1, 1], [1, -1], [1, 1]]</code>, for an output of <code>[[-1], [1], [1], [-1]]</code>.</p>\n\n<p>I thought this would give better results since I'm using the entire range of the function and it supposedly would converge better because of that. Also, since I'm just using a different symbol, it should be the same as with using 0 and 1.</p>\n\n<p>However, my network can not converge (giving a 0.5 accuracy), and what baffles me the most is that using 0 and 1 as symbols converges, and at a much faster rate.</p>\n\n<p>Is there a reason for such a counter-intuitive (at least in my conception) thing to be happening?</p>\n <machine-learning><neural-network><keras><p>I tried this experiment and was able to get some positive results. I will describe what I tried then perhaps you can specify where the differences may lie and we can further explore them. From what I tried I would assume that you are simply not training long enough.</p>\n\n<h1>Creating the data</h1>\n\n<pre><code>import numpy as np\n\nn = 100000\nx_train = np.zeros((n,2))\ny_train = np.zeros((n,))\nfor i in range(n):\n    x_train[i,0] = np.random.choice([-1,1])\n    x_train[i,1] = np.random.choice([-1,1])\n    if x_train[i,0] == 1 and x_train[i,1] == 1 or x_train[i,0] == -1 and x_train[i,1] == -1:\n        y_train[i] = -1\n    else:\n        y_train[i] = 1\n\nx_train = x_train.reshape(n, 2,)\n\nn = 1000\nx_test = np.zeros((n,2))\ny_test = np.zeros((n,))\nfor i in range(n):\n    x_test[i,0] = np.random.choice([-1,1])\n    x_test[i,1] = np.random.choice([-1,1])\n    if x_test[i,0] == 1 and x_test[i,1] == 1 or x_test[i,0] == -1 and x_test[i,1] == -1:\n        y_test[i] = -1\n    else:\n        y_test[i] = 1\n\nx_test = x_test.reshape(n, 2,)\n\nprint(x_test[0].T) \nprint(y_test[0])\n</code></pre>\n\n<blockquote>\n  <p>[ 1.  1.] <br/>\n  -1.0</p>\n</blockquote>\n\n<h1>Build the model</h1>\n\n<p>As you describe the model is 2 input nodes, 2 hidden nodes and 1 output node. Every node is using tanh as its activation function.</p>\n\n<pre><code>input_shape = (2,)\n\nmodel = Sequential()\nmodel.add(Dense(2, activation='tanh',\n                 input_shape=input_shape))\nmodel.add(Dense(2, activation='tanh'))\nmodel.add(Dense(1, activation='tanh'))\n\nmodel.compile(loss=keras.losses.mean_squared_error,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<h1>Train the model</h1>\n\n<p>Because I generated many instances of the data I am only training for 10 epochs. However, if your input space is only the four possible inputs you may want thousands of epochs. Neural networks do take a long time to converge.</p>\n\n<pre><code>epochs = 10\nbatch_size = 128\n# Fit the model weights.\nhistory = model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\n</code></pre>\n\n<blockquote>\n  <p>Epoch 10/10 <br/>100000/100000 [==============================] - 1s\n  9us/step - loss: 9.3983e-05 - acc: 1.0000 - val_loss: 7.9096e-05 -\n  val_acc: 1.0000</p>\n</blockquote>\n\n<p><a href=\"https://i.stack.imgur.com/ukswR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ukswR.png\" alt=\"enter image description here\"></a></p>\n",
                "codes": [
                    [
                        "import numpy as np\n\nn = 100000\nx_train = np.zeros((n,2))\ny_train = np.zeros((n,))\nfor i in range(n):\n    x_train[i,0] = np.random.choice([-1,1])\n    x_train[i,1] = np.random.choice([-1,1])\n    if x_train[i,0] == 1 and x_train[i,1] == 1 or x_train[i,0] == -1 and x_train[i,1] == -1:\n        y_train[i] = -1\n    else:\n        y_train[i] = 1\n\nx_train = x_train.reshape(n, 2,)\n\nn = 1000\nx_test = np.zeros((n,2))\ny_test = np.zeros((n,))\nfor i in range(n):\n    x_test[i,0] = np.random.choice([-1,1])\n    x_test[i,1] = np.random.choice([-1,1])\n    if x_test[i,0] == 1 and x_test[i,1] == 1 or x_test[i,0] == -1 and x_test[i,1] == -1:\n        y_test[i] = -1\n    else:\n        y_test[i] = 1\n\nx_test = x_test.reshape(n, 2,)\n\nprint(x_test[0].T) \nprint(y_test[0])\n",
                        "input_shape = (2,)\n\nmodel = Sequential()\nmodel.add(Dense(2, activation='tanh',\n                 input_shape=input_shape))\nmodel.add(Dense(2, activation='tanh'))\nmodel.add(Dense(1, activation='tanh'))\n\nmodel.compile(loss=keras.losses.mean_squared_error,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n",
                        "epochs = 10\nbatch_size = 128\n# Fit the model weights.\nhistory = model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\n"
                    ]
                ],
                "question_id:": "30662",
                "question_votes:": "",
                "question_text:": "<p>I've created a simple 2-2-1 feedforward ANN to predict an XOR using Keras.</p>\n\n<p>The activation function I'm using on all layers is a <em>tanh</em>, so in order to make use of the entire range of the function, <em>i.e.</em> [-1, 1], I've decided to use -1 instead of 0 as the symbol.</p>\n\n<p>My input data is, thus, <code>[[-1, -1], [-1, 1], [1, -1], [1, 1]]</code>, for an output of <code>[[-1], [1], [1], [-1]]</code>.</p>\n\n<p>I thought this would give better results since I'm using the entire range of the function and it supposedly would converge better because of that. Also, since I'm just using a different symbol, it should be the same as with using 0 and 1.</p>\n\n<p>However, my network can not converge (giving a 0.5 accuracy), and what baffles me the most is that using 0 and 1 as symbols converges, and at a much faster rate.</p>\n\n<p>Is there a reason for such a counter-intuitive (at least in my conception) thing to be happening?</p>\n",
                "tags": "<machine-learning><neural-network><keras>",
                "answers": [
                    [
                        "30666",
                        "2",
                        "30662",
                        "",
                        "",
                        "<p>I tried this experiment and was able to get some positive results. I will describe what I tried then perhaps you can specify where the differences may lie and we can further explore them. From what I tried I would assume that you are simply not training long enough.</p>\n\n<h1>Creating the data</h1>\n\n<pre><code>import numpy as np\n\nn = 100000\nx_train = np.zeros((n,2))\ny_train = np.zeros((n,))\nfor i in range(n):\n    x_train[i,0] = np.random.choice([-1,1])\n    x_train[i,1] = np.random.choice([-1,1])\n    if x_train[i,0] == 1 and x_train[i,1] == 1 or x_train[i,0] == -1 and x_train[i,1] == -1:\n        y_train[i] = -1\n    else:\n        y_train[i] = 1\n\nx_train = x_train.reshape(n, 2,)\n\nn = 1000\nx_test = np.zeros((n,2))\ny_test = np.zeros((n,))\nfor i in range(n):\n    x_test[i,0] = np.random.choice([-1,1])\n    x_test[i,1] = np.random.choice([-1,1])\n    if x_test[i,0] == 1 and x_test[i,1] == 1 or x_test[i,0] == -1 and x_test[i,1] == -1:\n        y_test[i] = -1\n    else:\n        y_test[i] = 1\n\nx_test = x_test.reshape(n, 2,)\n\nprint(x_test[0].T) \nprint(y_test[0])\n</code></pre>\n\n<blockquote>\n  <p>[ 1.  1.] <br/>\n  -1.0</p>\n</blockquote>\n\n<h1>Build the model</h1>\n\n<p>As you describe the model is 2 input nodes, 2 hidden nodes and 1 output node. Every node is using tanh as its activation function.</p>\n\n<pre><code>input_shape = (2,)\n\nmodel = Sequential()\nmodel.add(Dense(2, activation='tanh',\n                 input_shape=input_shape))\nmodel.add(Dense(2, activation='tanh'))\nmodel.add(Dense(1, activation='tanh'))\n\nmodel.compile(loss=keras.losses.mean_squared_error,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<h1>Train the model</h1>\n\n<p>Because I generated many instances of the data I am only training for 10 epochs. However, if your input space is only the four possible inputs you may want thousands of epochs. Neural networks do take a long time to converge.</p>\n\n<pre><code>epochs = 10\nbatch_size = 128\n# Fit the model weights.\nhistory = model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\n</code></pre>\n\n<blockquote>\n  <p>Epoch 10/10 <br/>100000/100000 [==============================] - 1s\n  9us/step - loss: 9.3983e-05 - acc: 1.0000 - val_loss: 7.9096e-05 -\n  val_acc: 1.0000</p>\n</blockquote>\n\n<p><a href=\"https://i.stack.imgur.com/ukswR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ukswR.png\" alt=\"enter image description here\"></a></p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15266",
            "_score": 6.3237486,
            "_source": {
                "title": "Split a tensoflow model into two parts",
                "content": "Split a tensoflow model into two parts <p>I have a pre-trained tensorflow model for image classification. It has has some convolution and maxpooling layers followed by dense layers. </p>\n\n<p>I would like to split it in two pats. The first containing the convolutions/maxpooling part, the second containing the dense layers. Then I would like to feed the first part with an image, store the result into a file/variable and then using it as input for the second part.</p>\n\n<p>The idea is that I could encode on the fly images with the first part, save them to disk and then using the encoded files as input. In this way I can avoid storing the original images.</p>\n\n<p>I am writing an example of a whole model (based on Coursera's/deeplearning.ai \"Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning\") </p>\n\n<pre><code>import tensorflow as tf\nmnist = tf.keras.datasets.fashion_mnist\n(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\ntraining_images=training_images.reshape(60000, 28, 28, 1)\ntraining_images=training_images / 255.0\ntest_images = test_images.reshape(10000, 28, 28, 1)\ntest_images=test_images/255.0\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n  tf.keras.layers.MaxPooling2D(4, 4),\n  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n  tf.keras.layers.MaxPooling2D(2,2),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\nmodel.fit(training_images, training_labels, epochs=5)\n</code></pre>\n\n<p>In the example above,</p>\n\n<ul>\n<li>first_part would have the first 5 layers</li>\n<li>second_part would have the last two (and possibly an input layer)</li>\n</ul>\n\n<p>Thank you.</p>\n <python><tensorflow><p>After several attemps I have the following piece of code. I created two new networks and transferred the weights from the initial network to them.</p>\n\n<pre><code># first part of initial model\npart1_model = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n  tf.keras.layers.MaxPooling2D(4, 4),\n  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n  tf.keras.layers.MaxPooling2D(2,2),\n  tf.keras.layers.Flatten()\n])\npart1_model.layers[0].set_weights(model.layers[0].get_weights())\npart1_model.layers[1].set_weights(model.layers[1].get_weights())\npart1_model.layers[2].set_weights(model.layers[2].get_weights())\npart1_model.layers[3].set_weights(model.layers[3].get_weights())\npart1_model.layers[4].set_weights(model.layers[4].get_weights())\npart1_model.summary() \n\n# second part of initial model\npart2_model = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(128, activation='relu',input_shape=(1, 128)),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\npart2_model.summary()\npart2_model.layers[0].set_weights(model.layers[5].get_weights())\npart2_model.layers[1].set_weights(model.layers[6].get_weights())\n# predictions holds prediction for test set from initial model\npredictions = model.predict(test_images)\n\n# predictions1 holds output of first part when test set is used as input \npredictions1 = part1_model.predict(test_images)\n\nimport numpy as np\n# tmp is used to transform prediction1 in a format recognizable from part2\ntmp=np.zeros((10000,1,128))\nfor i in range(0,10000):\n    tmp[i,:,:]=predictions1[i,:]\n\n# predictions2 holds the output of second part when the result of first part (predictions1) is used as input    \npredictions2 = part2_model.predict(tmp)\n\n# check that the result of initial model is the same with the result of the two parts\nok=0\nfor i in range(0,10000):\n    if np.argmax(predictions[i])!=np.argmax(predictions2[i]):\n        print(i,\" False\")\n    else:\n        ok=ok+1\nprint(ok)\n# also sample some cases and check probabilities\nprint(\"last entry\")\nprint(predictions2[9999])\nprint(predictions[9999])\nprint(\"2nd entry\")\nprint(predictions2[1])\nprint(predictions[1])\n</code></pre>\n",
                "codes": [
                    [
                        "# first part of initial model\npart1_model = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n  tf.keras.layers.MaxPooling2D(4, 4),\n  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n  tf.keras.layers.MaxPooling2D(2,2),\n  tf.keras.layers.Flatten()\n])\npart1_model.layers[0].set_weights(model.layers[0].get_weights())\npart1_model.layers[1].set_weights(model.layers[1].get_weights())\npart1_model.layers[2].set_weights(model.layers[2].get_weights())\npart1_model.layers[3].set_weights(model.layers[3].get_weights())\npart1_model.layers[4].set_weights(model.layers[4].get_weights())\npart1_model.summary() \n\n# second part of initial model\npart2_model = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(128, activation='relu',input_shape=(1, 128)),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\npart2_model.summary()\npart2_model.layers[0].set_weights(model.layers[5].get_weights())\npart2_model.layers[1].set_weights(model.layers[6].get_weights())\n# predictions holds prediction for test set from initial model\npredictions = model.predict(test_images)\n\n# predictions1 holds output of first part when test set is used as input \npredictions1 = part1_model.predict(test_images)\n\nimport numpy as np\n# tmp is used to transform prediction1 in a format recognizable from part2\ntmp=np.zeros((10000,1,128))\nfor i in range(0,10000):\n    tmp[i,:,:]=predictions1[i,:]\n\n# predictions2 holds the output of second part when the result of first part (predictions1) is used as input    \npredictions2 = part2_model.predict(tmp)\n\n# check that the result of initial model is the same with the result of the two parts\nok=0\nfor i in range(0,10000):\n    if np.argmax(predictions[i])!=np.argmax(predictions2[i]):\n        print(i,\" False\")\n    else:\n        ok=ok+1\nprint(ok)\n# also sample some cases and check probabilities\nprint(\"last entry\")\nprint(predictions2[9999])\nprint(predictions[9999])\nprint(\"2nd entry\")\nprint(predictions2[1])\nprint(predictions[1])\n"
                    ]
                ],
                "question_id:": "51536",
                "question_votes:": "",
                "question_text:": "<p>I have a pre-trained tensorflow model for image classification. It has has some convolution and maxpooling layers followed by dense layers. </p>\n\n<p>I would like to split it in two pats. The first containing the convolutions/maxpooling part, the second containing the dense layers. Then I would like to feed the first part with an image, store the result into a file/variable and then using it as input for the second part.</p>\n\n<p>The idea is that I could encode on the fly images with the first part, save them to disk and then using the encoded files as input. In this way I can avoid storing the original images.</p>\n\n<p>I am writing an example of a whole model (based on Coursera's/deeplearning.ai \"Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning\") </p>\n\n<pre><code>import tensorflow as tf\nmnist = tf.keras.datasets.fashion_mnist\n(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\ntraining_images=training_images.reshape(60000, 28, 28, 1)\ntraining_images=training_images / 255.0\ntest_images = test_images.reshape(10000, 28, 28, 1)\ntest_images=test_images/255.0\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n  tf.keras.layers.MaxPooling2D(4, 4),\n  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n  tf.keras.layers.MaxPooling2D(2,2),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\nmodel.fit(training_images, training_labels, epochs=5)\n</code></pre>\n\n<p>In the example above,</p>\n\n<ul>\n<li>first_part would have the first 5 layers</li>\n<li>second_part would have the last two (and possibly an input layer)</li>\n</ul>\n\n<p>Thank you.</p>\n",
                "tags": "<python><tensorflow>",
                "answers": [
                    [
                        "51883",
                        "2",
                        "51536",
                        "",
                        "",
                        "<p>After several attemps I have the following piece of code. I created two new networks and transferred the weights from the initial network to them.</p>\n\n<pre><code># first part of initial model\npart1_model = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n  tf.keras.layers.MaxPooling2D(4, 4),\n  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n  tf.keras.layers.MaxPooling2D(2,2),\n  tf.keras.layers.Flatten()\n])\npart1_model.layers[0].set_weights(model.layers[0].get_weights())\npart1_model.layers[1].set_weights(model.layers[1].get_weights())\npart1_model.layers[2].set_weights(model.layers[2].get_weights())\npart1_model.layers[3].set_weights(model.layers[3].get_weights())\npart1_model.layers[4].set_weights(model.layers[4].get_weights())\npart1_model.summary() \n\n# second part of initial model\npart2_model = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(128, activation='relu',input_shape=(1, 128)),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\npart2_model.summary()\npart2_model.layers[0].set_weights(model.layers[5].get_weights())\npart2_model.layers[1].set_weights(model.layers[6].get_weights())\n# predictions holds prediction for test set from initial model\npredictions = model.predict(test_images)\n\n# predictions1 holds output of first part when test set is used as input \npredictions1 = part1_model.predict(test_images)\n\nimport numpy as np\n# tmp is used to transform prediction1 in a format recognizable from part2\ntmp=np.zeros((10000,1,128))\nfor i in range(0,10000):\n    tmp[i,:,:]=predictions1[i,:]\n\n# predictions2 holds the output of second part when the result of first part (predictions1) is used as input    \npredictions2 = part2_model.predict(tmp)\n\n# check that the result of initial model is the same with the result of the two parts\nok=0\nfor i in range(0,10000):\n    if np.argmax(predictions[i])!=np.argmax(predictions2[i]):\n        print(i,\" False\")\n    else:\n        ok=ok+1\nprint(ok)\n# also sample some cases and check probabilities\nprint(\"last entry\")\nprint(predictions2[9999])\nprint(predictions[9999])\nprint(\"2nd entry\")\nprint(predictions2[1])\nprint(predictions[1])\n</code></pre>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10514",
            "_score": 6.2872357,
            "_source": {
                "title": "Confusion Matrixs for Binary classifier",
                "content": "Confusion Matrixs for Binary classifier <p>I am new to modeling, and I am practicing building a logistic regression model. I would like to create a confusion matrix, but my code doesn't seem to work.</p>\n\n<p>Here is the code for the model (which works):</p>\n\n<pre><code>from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\n#train, test = train_test_split(hp[age], test_size=0.3)\n\n#from sklearn import preprocessing\nX = hp['age'].values.reshape((32561,1))\n#X = hp[['age','hours-per-week']].values\ny = hp['evalinvest'].values\n\nLogReg = LogisticRegression()\nLogReg.fit(X,y)\nprint(LogReg.score(X,y))\n\n0.916710174749\n</code></pre>\n\n<p>Here is where I am having diffculty:</p>\n\n<pre><code># Confusion Matrix\nimport numpy as np\nfrom sklearn.metrics import *\nCM = confusion_matrix(X,y)\nprint (\"\\n\\nConfusion matrix:\\n\", CM)\n</code></pre>\n\n<hr>\n\n<p>It runs and outputs results, but I don't feel like it is correct.</p>\n\n<p>Confusion matrix:</p>\n\n<pre><code> [[  0   0   0 ...,   0   0   0]\n [  0   0   0 ...,   0   0   0]\n [385  10   0 ...,   0   0   0]\n ..., \n [  1   0   0 ...,   0   0   0]\n [  3   0   0 ...,   0   0   0]\n [ 33  10   0 ...,   0   0   0]]\n</code></pre>\n\n<p>Then, when I run the following code, it doesn't work:</p>\n\n<pre><code>tn, fp, fn, tp = CM.ravel()\nprint (\"\\nTP, TN, FP, FN:\", tp, \",\", tn, \",\", fp, \",\", fn)\n</code></pre>\n\n<p>error:</p>\n\n<pre><code>---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-68-dca3ebbdc69a&gt; in &lt;module&gt;()\n----&gt; 1 tn, fp, fn, tp = CM.ravel()\n      2 print (\"\\nTP, TN, FP, FN:\", tp, \",\", tn, \",\", fp, \",\", fn)\n\nValueError: too many values to unpack (expected 4)\n</code></pre>\n <classification><logistic-regression><confusion-matrix><p>I think you are confused on many levels here.</p>\n\n<ul>\n<li>Logistic regression is a classifier. It gives you the probability that given an $x_{i}$, the probability it belongs to a class or classes.</li>\n<li>So you will be having your <code>evalinvest</code> as classes, not continuous values.</li>\n<li>When you call <code>predict</code> method on top of trained <code>LogisticRegression</code> model, it predicts class for each $x_{i}$ in your test set. So you expect a single array of class labels they belong to.</li>\n<li><code>sklearn.metrics.confusion_matrix</code> function takes in the original class values to the ones that are predicted by the model you had trained and returns what $x_{i}$ has been classified into what class. So it returns an <code>n(c) x n(c)</code> array where <code>n(c)</code> is the number of classes. So the diagonal of the matrix indicates the number of elements of class <code>i</code> being classified as class <code>i</code>. And an ideal model should be expected to get this numbers good. The mistake which you had made you sent in your <code>X</code> (train) matrix into it and <code>y</code> (labels) into it, which is wrong. You are supposed to send in <code>y_true</code>(true labels) and <code>y_pred</code> (predicted labels from the model). Check the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\" rel=\"nofollow noreferrer\">documentation</a> for more.</li>\n<li>Ideally the function should have thrown an error. But unfortunately you had only one row in your <code>X</code> and one in <code>y</code> and they both are of same size and it passed <code>assert</code> it had to make.</li>\n<li>And <code>np.ravel</code> converts an multi-dimensional array into <code>1D</code> array. So if you doing a binary classification, you would be having a <code>2x2</code> matrix, whose flattened array would have been four elements and the assignment would have worked. But the ravelling you had made releases $n(c)^2$ elements. So there you go <code>ValueError</code>. See the <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.ravel.html\" rel=\"nofollow noreferrer\">docs</a></li>\n</ul>\n\n<p>I hope my other <a href=\"https://datascience.stackexchange.com/questions/27132/decision-tree-used-for-calculating-precision-accuracy-and-recall-class-breakd/27137#27137\">answer</a> on confusion matrices may clear things a little more.</p>\n\n<p>Hope it clears some mistakes you are making.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "37687",
                "question_votes:": "",
                "question_text:": "<p>I am new to modeling, and I am practicing building a logistic regression model. I would like to create a confusion matrix, but my code doesn't seem to work.</p>\n\n<p>Here is the code for the model (which works):</p>\n\n<pre><code>from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\n#train, test = train_test_split(hp[age], test_size=0.3)\n\n#from sklearn import preprocessing\nX = hp['age'].values.reshape((32561,1))\n#X = hp[['age','hours-per-week']].values\ny = hp['evalinvest'].values\n\nLogReg = LogisticRegression()\nLogReg.fit(X,y)\nprint(LogReg.score(X,y))\n\n0.916710174749\n</code></pre>\n\n<p>Here is where I am having diffculty:</p>\n\n<pre><code># Confusion Matrix\nimport numpy as np\nfrom sklearn.metrics import *\nCM = confusion_matrix(X,y)\nprint (\"\\n\\nConfusion matrix:\\n\", CM)\n</code></pre>\n\n<hr>\n\n<p>It runs and outputs results, but I don't feel like it is correct.</p>\n\n<p>Confusion matrix:</p>\n\n<pre><code> [[  0   0   0 ...,   0   0   0]\n [  0   0   0 ...,   0   0   0]\n [385  10   0 ...,   0   0   0]\n ..., \n [  1   0   0 ...,   0   0   0]\n [  3   0   0 ...,   0   0   0]\n [ 33  10   0 ...,   0   0   0]]\n</code></pre>\n\n<p>Then, when I run the following code, it doesn't work:</p>\n\n<pre><code>tn, fp, fn, tp = CM.ravel()\nprint (\"\\nTP, TN, FP, FN:\", tp, \",\", tn, \",\", fp, \",\", fn)\n</code></pre>\n\n<p>error:</p>\n\n<pre><code>---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-68-dca3ebbdc69a&gt; in &lt;module&gt;()\n----&gt; 1 tn, fp, fn, tp = CM.ravel()\n      2 print (\"\\nTP, TN, FP, FN:\", tp, \",\", tn, \",\", fp, \",\", fn)\n\nValueError: too many values to unpack (expected 4)\n</code></pre>\n",
                "tags": "<classification><logistic-regression><confusion-matrix>",
                "answers": [
                    [
                        "37693",
                        "2",
                        "37687",
                        "",
                        "",
                        "<p>I think you are confused on many levels here.</p>\n\n<ul>\n<li>Logistic regression is a classifier. It gives you the probability that given an $x_{i}$, the probability it belongs to a class or classes.</li>\n<li>So you will be having your <code>evalinvest</code> as classes, not continuous values.</li>\n<li>When you call <code>predict</code> method on top of trained <code>LogisticRegression</code> model, it predicts class for each $x_{i}$ in your test set. So you expect a single array of class labels they belong to.</li>\n<li><code>sklearn.metrics.confusion_matrix</code> function takes in the original class values to the ones that are predicted by the model you had trained and returns what $x_{i}$ has been classified into what class. So it returns an <code>n(c) x n(c)</code> array where <code>n(c)</code> is the number of classes. So the diagonal of the matrix indicates the number of elements of class <code>i</code> being classified as class <code>i</code>. And an ideal model should be expected to get this numbers good. The mistake which you had made you sent in your <code>X</code> (train) matrix into it and <code>y</code> (labels) into it, which is wrong. You are supposed to send in <code>y_true</code>(true labels) and <code>y_pred</code> (predicted labels from the model). Check the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\" rel=\"nofollow noreferrer\">documentation</a> for more.</li>\n<li>Ideally the function should have thrown an error. But unfortunately you had only one row in your <code>X</code> and one in <code>y</code> and they both are of same size and it passed <code>assert</code> it had to make.</li>\n<li>And <code>np.ravel</code> converts an multi-dimensional array into <code>1D</code> array. So if you doing a binary classification, you would be having a <code>2x2</code> matrix, whose flattened array would have been four elements and the assignment would have worked. But the ravelling you had made releases $n(c)^2$ elements. So there you go <code>ValueError</code>. See the <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.ravel.html\" rel=\"nofollow noreferrer\">docs</a></li>\n</ul>\n\n<p>I hope my other <a href=\"https://datascience.stackexchange.com/questions/27132/decision-tree-used-for-calculating-precision-accuracy-and-recall-class-breakd/27137#27137\">answer</a> on confusion matrices may clear things a little more.</p>\n\n<p>Hope it clears some mistakes you are making.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12292",
            "_score": 6.2489395,
            "_source": {
                "title": "Hyperas LSTM configuration assignment error",
                "content": "Hyperas LSTM configuration assignment error <p>I have been working on my trivial keras lstm model trying to implement Hyperas with the following code that gives me an error I cannot resolve. I have just been experimenting around with Hyperas and it would be great to get this to work. My code in one file looks as follows:</p>\n\n<pre><code>from keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, Dropout, Activation\nfrom keras.layers import LSTM\nfrom keras.datasets import imdb\nfrom pandas import DataFrame\nfrom sklearn.preprocessing import MinMaxScaler\nfrom matplotlib import pyplot\nimport h5py\nfrom keras.callbacks import TensorBoard\nfrom numpy import *\n\nfrom hyperas import optim\nfrom hyperas.distributions import choice, uniform\nfrom hyperopt import Trials, STATUS_OK, tpe\nfrom configuration.data_loader import *\n\ndef data():\n\n    # normalise features\n    scaler = MinMaxScaler(feature_range=(0, 1))\n\n    X_train_df , y_train_df , X_val_df , y_val_df , X_test_df , y_test_df  = load_saved_datasets()\n\n    X_train_df =  scaler.fit_transform(X_train_df.get_values())\n    X_val_df =  scaler.fit_transform(X_val_df.get_values())\n\n    y_train_df = y_train_df.get_values()\n    y_val_df = y_val_df.get_values()\n\n    X_train = X_train_df\n    y_train = y_train_df\n    X_val = X_val_df\n    y_val = y_val_df\n\n    return (X_train, y_train, X_val, y_val)\n\n\ndef model(X_train, y_train, X_val, y_val):\n    \"\"\"\n\n    :param X_train: SCALED\n    :param y_train:\n    :param X_val: SCALED\n    :param y_val:\n    :return:\n    \"\"\"\n\n    X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n    X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))\n\n\n    model = Sequential()\n\n    # Layer 1\n    model.add(LSTM({{uniform(4,70)}},\n                    input_shape=(X_train.shape[1],X_train.shape[2])))\n    model.add(Activation({{choice(['tanh', 'relu'])}}))\n    model.add(Dropout({{uniform(0, 1)}}))\n\n    # If we choose 'four', add an additional fourth layer\n    if {{choice(['two', 'three'])}} == 'two':\n        # Layer 2\n        model.add(LSTM({{uniform(4,100)}},\n                       input_shape=(X_train.shape[1],X_train.shape[2])))\n        model.add(Activation({{choice(['tanh', 'relu'])}}))\n        model.add(Dropout({{uniform(0, 1)}}))\n\n\n    model.add(Dense(1))\n    model.add(Activation({{choice(['softmax', 'relu', 'tanh'])}}))\n\n    model.compile(loss='rmse', metrics=['accuracy'],\n                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n\n    result = model.fit(X_train, y_train,\n                       batch_size={{choice([64, 128])}},\n                       epochs=2,\n                       verbose=2,\n                       validation_data=(X_val, y_val))\n\n    #get the highest validation accuracy of the training epochs\n    validation_acc = amax(result.history['val_acc'])\n    print('Best validation acc of epoch:', validation_acc)\n    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n\ndef hyperas_main():\n\n    trials = Trials()\n    best_run, best_model = optim.minimize(data=data,\n                                        model=model,\n                                          algo=tpe.suggest,\n                                          max_evals=20,\n                                          trials=trials)\n\n    X_train, Y_train, X_test, Y_test = data()\n    print(\"Evaluation of best performing model:\")\n    print(best_model.evaluate(X_test, Y_test))\n    print(\"Best performing model chosen hyper-parameters:\")\n    print(best_run)\n\n    # print(\"Evalutation of best performing model:\")\n    # # print(best_model.evaluate(X_val, y_val))\n    # print(\"Best performing model chosen hyper-parameters:\")\n    # print(best_run)\n</code></pre>\n\n<p>Where the function load_saved_datasets() simply loads my sets with pandas.</p>\n\n<p>However, the error output looks as follows:</p>\n\n<pre><code>   &gt;&gt;&gt; Hyperas search space:\n\ndef get_space():\n    return {\n        'LSTM': hp.uniform('LSTM', 4,70),\n        'Activation': hp.choice('Activation', ['tanh', 'relu']),\n        'Dropout': hp.uniform('Dropout', 0, 1),\n        'Dropout_1': hp.choice('Dropout_1', ['two', 'three']),\n        'LSTM_1': hp.uniform('LSTM_1', 4,100),\n        'Activation_1': hp.choice('Activation_1', ['tanh', 'relu']),\n        'Dropout_2': hp.uniform('Dropout_2', 0, 1),\n        'Activation_2': hp.choice('Activation_2', ['softmax', 'relu', 'tanh']),\n        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n        'batch_size': hp.choice('batch_size', [64, 128]),\n    }\n\n&gt;&gt;&gt; Data\n  1: \n  2: \n  3: # normalise features\n  4: scaler = MinMaxScaler(feature_range=(0, 1))\n  5: \n  6: X_train_df , y_train_df , X_val_df , y_val_df , X_test_df , y_test_df  = load_saved_datasets()\n  7: \n  8: X_train_df =  scaler.fit_transform(X_train_df.get_values())\n  9: X_val_df =  scaler.fit_transform(X_val_df.get_values())\n 10: \n 11: y_train_df = y_train_df.get_values()\n 12: y_val_df = y_val_df.get_values()\n 13: \n 14: X_train = X_train_df\n 15: y_train = y_train_df\n 16: X_val = X_val_df\n 17: y_val = y_val_df\n 18: \n 19: \n 20: \n 21: \n&gt;&gt;&gt; Resulting replaced keras model:\n\n   1: def keras_fmin_fnct(space):\n   2: \n   3:     \"\"\"\n   4: \n   5:     :param X_train: SCALED\n   6:     :param y_train:\n   7:     :param X_val: SCALED\n   8:     :param y_val:\n   9:     :return:\n  10:     \"\"\"\n  11: \n  12:     X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n  13:     X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))\n  14: \n  15: \n  16:     model = Sequential()\n  17: \n  18:     # Layer 1\n  19:     model.add(LSTM(space['LSTM'],\n  20:                     input_shape=(X_train.shape[1],X_train.shape[2])))\n  21:     model.add(Activation(space['Activation']))\n  22:     model.add(Dropout(space['Dropout']))\n  23: \n  24:     # If we choose 'four', add an additional fourth layer\n  25:     if space['Dropout_1'] == 'two':\n  26:         # Layer 2\n  27:         model.add(LSTM(space['LSTM_1'],\n  28:                        input_shape=(X_train.shape[1],X_train.shape[2])))\n  29:         model.add(Activation(space['Activation_1']))\n  30:         model.add(Dropout(space['Dropout_2']))\n  31: \n  32: \n  33:     model.add(Dense(1))\n  34:     model.add(Activation(space['Activation_2']))\n  35: \n  36:     model.compile(loss='rmse', metrics=['accuracy'],\n  37:                   optimizer=space['optimizer'])\n  38: \n  39:     result = model.fit(X_train, y_train,\n  40:                        batch_size=space['batch_size'],\n  41:                        epochs=2,\n  42:                        verbose=2,\n  43:                        validation_data=(X_val, y_val))\n  44: \n  45:     #get the highest validation accuracy of the training epochs\n  46:     validation_acc = amax(result.history['val_acc'])\n  47:     print('Best validation acc of epoch:', validation_acc)\n  48:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n  49: \nTraceback (most recent call last):\n  File \"C:/Users/user/Desktop/AI/Backend/src/main.py\", line 40, in &lt;module&gt;\n    lstm_training.hyperas_main()\n  File \"C:\\Users\\user\\Desktop\\AI\\Backend\\src\\training\\lstm_training.py\", line 94, in hyperas_main\n    trials=trials)\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperas\\optim.py\", line 67, in minimize\n    verbose=verbose)\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperas\\optim.py\", line 133, in base_minimizer\n    return_argmin=True),\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperopt\\fmin.py\", line 307, in fmin\n    return_argmin=return_argmin,\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperopt\\base.py\", line 635, in fmin\n    return_argmin=return_argmin)\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperopt\\fmin.py\", line 320, in fmin\n    rval.exhaust()\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperopt\\fmin.py\", line 199, in exhaust\n    self.run(self.max_evals - n_done, block_until_done=self.async)\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperopt\\fmin.py\", line 173, in run\n    self.serial_evaluate()\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperopt\\fmin.py\", line 92, in serial_evaluate\n    result = self.domain.evaluate(spec, ctrl)\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperopt\\base.py\", line 840, in evaluate\n    rval = self.fn(pyll_rval)\n  File \"C:\\Users\\user\\Desktop\\AI\\Backend\\src\\temp_model.py\", line 110, in keras_fmin_fnct\nUnboundLocalError: local variable 'X_train' referenced before assignment\n</code></pre>\n\n<p>Where do I reference X_train before use? Is this due to naming conventions? Does the problem lie maybe with a computational graph?</p>\n\n<p>Any help is appreciated.</p>\n <python><keras><hyperparameter-tuning><p>Try putting your two reshape() statements at the end of the data() function instead of in the model() function, and in the hyperas_main() function, define data() before you run optim.minimize().</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "43216",
                "question_votes:": "1",
                "question_text:": "<p>I have been working on my trivial keras lstm model trying to implement Hyperas with the following code that gives me an error I cannot resolve. I have just been experimenting around with Hyperas and it would be great to get this to work. My code in one file looks as follows:</p>\n\n<pre><code>from keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, Dropout, Activation\nfrom keras.layers import LSTM\nfrom keras.datasets import imdb\nfrom pandas import DataFrame\nfrom sklearn.preprocessing import MinMaxScaler\nfrom matplotlib import pyplot\nimport h5py\nfrom keras.callbacks import TensorBoard\nfrom numpy import *\n\nfrom hyperas import optim\nfrom hyperas.distributions import choice, uniform\nfrom hyperopt import Trials, STATUS_OK, tpe\nfrom configuration.data_loader import *\n\ndef data():\n\n    # normalise features\n    scaler = MinMaxScaler(feature_range=(0, 1))\n\n    X_train_df , y_train_df , X_val_df , y_val_df , X_test_df , y_test_df  = load_saved_datasets()\n\n    X_train_df =  scaler.fit_transform(X_train_df.get_values())\n    X_val_df =  scaler.fit_transform(X_val_df.get_values())\n\n    y_train_df = y_train_df.get_values()\n    y_val_df = y_val_df.get_values()\n\n    X_train = X_train_df\n    y_train = y_train_df\n    X_val = X_val_df\n    y_val = y_val_df\n\n    return (X_train, y_train, X_val, y_val)\n\n\ndef model(X_train, y_train, X_val, y_val):\n    \"\"\"\n\n    :param X_train: SCALED\n    :param y_train:\n    :param X_val: SCALED\n    :param y_val:\n    :return:\n    \"\"\"\n\n    X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n    X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))\n\n\n    model = Sequential()\n\n    # Layer 1\n    model.add(LSTM({{uniform(4,70)}},\n                    input_shape=(X_train.shape[1],X_train.shape[2])))\n    model.add(Activation({{choice(['tanh', 'relu'])}}))\n    model.add(Dropout({{uniform(0, 1)}}))\n\n    # If we choose 'four', add an additional fourth layer\n    if {{choice(['two', 'three'])}} == 'two':\n        # Layer 2\n        model.add(LSTM({{uniform(4,100)}},\n                       input_shape=(X_train.shape[1],X_train.shape[2])))\n        model.add(Activation({{choice(['tanh', 'relu'])}}))\n        model.add(Dropout({{uniform(0, 1)}}))\n\n\n    model.add(Dense(1))\n    model.add(Activation({{choice(['softmax', 'relu', 'tanh'])}}))\n\n    model.compile(loss='rmse', metrics=['accuracy'],\n                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n\n    result = model.fit(X_train, y_train,\n                       batch_size={{choice([64, 128])}},\n                       epochs=2,\n                       verbose=2,\n                       validation_data=(X_val, y_val))\n\n    #get the highest validation accuracy of the training epochs\n    validation_acc = amax(result.history['val_acc'])\n    print('Best validation acc of epoch:', validation_acc)\n    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n\ndef hyperas_main():\n\n    trials = Trials()\n    best_run, best_model = optim.minimize(data=data,\n                                        model=model,\n                                          algo=tpe.suggest,\n                                          max_evals=20,\n                                          trials=trials)\n\n    X_train, Y_train, X_test, Y_test = data()\n    print(\"Evaluation of best performing model:\")\n    print(best_model.evaluate(X_test, Y_test))\n    print(\"Best performing model chosen hyper-parameters:\")\n    print(best_run)\n\n    # print(\"Evalutation of best performing model:\")\n    # # print(best_model.evaluate(X_val, y_val))\n    # print(\"Best performing model chosen hyper-parameters:\")\n    # print(best_run)\n</code></pre>\n\n<p>Where the function load_saved_datasets() simply loads my sets with pandas.</p>\n\n<p>However, the error output looks as follows:</p>\n\n<pre><code>   &gt;&gt;&gt; Hyperas search space:\n\ndef get_space():\n    return {\n        'LSTM': hp.uniform('LSTM', 4,70),\n        'Activation': hp.choice('Activation', ['tanh', 'relu']),\n        'Dropout': hp.uniform('Dropout', 0, 1),\n        'Dropout_1': hp.choice('Dropout_1', ['two', 'three']),\n        'LSTM_1': hp.uniform('LSTM_1', 4,100),\n        'Activation_1': hp.choice('Activation_1', ['tanh', 'relu']),\n        'Dropout_2': hp.uniform('Dropout_2', 0, 1),\n        'Activation_2': hp.choice('Activation_2', ['softmax', 'relu', 'tanh']),\n        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n        'batch_size': hp.choice('batch_size', [64, 128]),\n    }\n\n&gt;&gt;&gt; Data\n  1: \n  2: \n  3: # normalise features\n  4: scaler = MinMaxScaler(feature_range=(0, 1))\n  5: \n  6: X_train_df , y_train_df , X_val_df , y_val_df , X_test_df , y_test_df  = load_saved_datasets()\n  7: \n  8: X_train_df =  scaler.fit_transform(X_train_df.get_values())\n  9: X_val_df =  scaler.fit_transform(X_val_df.get_values())\n 10: \n 11: y_train_df = y_train_df.get_values()\n 12: y_val_df = y_val_df.get_values()\n 13: \n 14: X_train = X_train_df\n 15: y_train = y_train_df\n 16: X_val = X_val_df\n 17: y_val = y_val_df\n 18: \n 19: \n 20: \n 21: \n&gt;&gt;&gt; Resulting replaced keras model:\n\n   1: def keras_fmin_fnct(space):\n   2: \n   3:     \"\"\"\n   4: \n   5:     :param X_train: SCALED\n   6:     :param y_train:\n   7:     :param X_val: SCALED\n   8:     :param y_val:\n   9:     :return:\n  10:     \"\"\"\n  11: \n  12:     X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n  13:     X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))\n  14: \n  15: \n  16:     model = Sequential()\n  17: \n  18:     # Layer 1\n  19:     model.add(LSTM(space['LSTM'],\n  20:                     input_shape=(X_train.shape[1],X_train.shape[2])))\n  21:     model.add(Activation(space['Activation']))\n  22:     model.add(Dropout(space['Dropout']))\n  23: \n  24:     # If we choose 'four', add an additional fourth layer\n  25:     if space['Dropout_1'] == 'two':\n  26:         # Layer 2\n  27:         model.add(LSTM(space['LSTM_1'],\n  28:                        input_shape=(X_train.shape[1],X_train.shape[2])))\n  29:         model.add(Activation(space['Activation_1']))\n  30:         model.add(Dropout(space['Dropout_2']))\n  31: \n  32: \n  33:     model.add(Dense(1))\n  34:     model.add(Activation(space['Activation_2']))\n  35: \n  36:     model.compile(loss='rmse', metrics=['accuracy'],\n  37:                   optimizer=space['optimizer'])\n  38: \n  39:     result = model.fit(X_train, y_train,\n  40:                        batch_size=space['batch_size'],\n  41:                        epochs=2,\n  42:                        verbose=2,\n  43:                        validation_data=(X_val, y_val))\n  44: \n  45:     #get the highest validation accuracy of the training epochs\n  46:     validation_acc = amax(result.history['val_acc'])\n  47:     print('Best validation acc of epoch:', validation_acc)\n  48:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n  49: \nTraceback (most recent call last):\n  File \"C:/Users/user/Desktop/AI/Backend/src/main.py\", line 40, in &lt;module&gt;\n    lstm_training.hyperas_main()\n  File \"C:\\Users\\user\\Desktop\\AI\\Backend\\src\\training\\lstm_training.py\", line 94, in hyperas_main\n    trials=trials)\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperas\\optim.py\", line 67, in minimize\n    verbose=verbose)\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperas\\optim.py\", line 133, in base_minimizer\n    return_argmin=True),\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperopt\\fmin.py\", line 307, in fmin\n    return_argmin=return_argmin,\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperopt\\base.py\", line 635, in fmin\n    return_argmin=return_argmin)\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperopt\\fmin.py\", line 320, in fmin\n    rval.exhaust()\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperopt\\fmin.py\", line 199, in exhaust\n    self.run(self.max_evals - n_done, block_until_done=self.async)\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperopt\\fmin.py\", line 173, in run\n    self.serial_evaluate()\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperopt\\fmin.py\", line 92, in serial_evaluate\n    result = self.domain.evaluate(spec, ctrl)\n  File \"C:\\Users\\user\\Anaconda3\\envs\\AI\\lib\\site-packages\\hyperopt\\base.py\", line 840, in evaluate\n    rval = self.fn(pyll_rval)\n  File \"C:\\Users\\user\\Desktop\\AI\\Backend\\src\\temp_model.py\", line 110, in keras_fmin_fnct\nUnboundLocalError: local variable 'X_train' referenced before assignment\n</code></pre>\n\n<p>Where do I reference X_train before use? Is this due to naming conventions? Does the problem lie maybe with a computational graph?</p>\n\n<p>Any help is appreciated.</p>\n",
                "tags": "<python><keras><hyperparameter-tuning>",
                "answers": [
                    [
                        "44457",
                        "2",
                        "43216",
                        "",
                        "",
                        "<p>Try putting your two reshape() statements at the end of the data() function instead of in the model() function, and in the hyperas_main() function, define data() before you run optim.minimize().</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3581",
            "_score": 6.2486935,
            "_source": {
                "title": "Plotting different values in pandas histogram with different colors",
                "content": "Plotting different values in pandas histogram with different colors <p>I am working on a dataset. The dataset consists of 16 different features each feature having values belonging to the set (0,1,2). In order to check the distribution of values in each column, I used <code>pandas.DataFrame.hist()</code> method which gave me a plot as shown below:\n<a href=\"https://i.stack.imgur.com/73mY7.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/73mY7.png\" alt=\"Figure\"></a> </p>\n\n<p>I want to represent the distribution for each value in a column with different color. For example, in column1 all the values corresponding to '0' should be in red color while the values corresponding to '1' in green color and so on. How can I do this? Please help !!</p>\n <python><dataset><visualization><pandas><distribution><p>There isn't any built-in function to do this directly in pandas, but by getting the array collection of <code>AxesSubplot</code>, iterating on them to retrieve the matplotlib patches you can achieve the desired result.</p>\n\n<p>Here's some dummy data to play with:</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\ndf = pd.DataFrame(np.random.randint(low=0, high=3, size=(1000,16)))\n</code></pre>\n\n<p>Now, here's the magic:</p>\n\n<pre><code>import matplotlib.pyplot as plt\n\n# Plot and retrieve the axes\naxes = df.hist(figsize=(12,6), sharex=True, sharey=True)\n\n# Define a different color for the first three bars\ncolors = [\"#e74c3c\", \"#2ecc71\", \"#3498db\"]\n\nfor i, ax in enumerate(axes.reshape(-1)):\n    # Define a counter to ensure that if we have more than three bars with a value,\n    # we don't try to access out-of-range element in colors\n    k = 0\n\n    # Optional: remove grid, and top and right spines\n    ax.grid(False)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n\n    for rect in ax.patches:\n        # If there's a value in the rect and we have defined a color\n        if rect.get_height() &gt; 0 and k &lt; len(colors):\n            # Set the color\n            rect.set_color(colors[k])\n            # Increment the counter\n            k += 1\n\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/4w9Ac.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/4w9Ac.png\" alt=\"Resulting hist subplot with colors\"></a></p>\n",
                "codes": [
                    [
                        "import pandas as pd\nimport numpy as np\ndf = pd.DataFrame(np.random.randint(low=0, high=3, size=(1000,16)))\n",
                        "import matplotlib.pyplot as plt\n\n# Plot and retrieve the axes\naxes = df.hist(figsize=(12,6), sharex=True, sharey=True)\n\n# Define a different color for the first three bars\ncolors = [\"#e74c3c\", \"#2ecc71\", \"#3498db\"]\n\nfor i, ax in enumerate(axes.reshape(-1)):\n    # Define a counter to ensure that if we have more than three bars with a value,\n    # we don't try to access out-of-range element in colors\n    k = 0\n\n    # Optional: remove grid, and top and right spines\n    ax.grid(False)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n\n    for rect in ax.patches:\n        # If there's a value in the rect and we have defined a color\n        if rect.get_height() > 0 and k < len(colors):\n            # Set the color\n            rect.set_color(colors[k])\n            # Increment the counter\n            k += 1\n\nplt.show()\n"
                    ]
                ],
                "question_id:": "15043",
                "question_votes:": "5",
                "question_text:": "<p>I am working on a dataset. The dataset consists of 16 different features each feature having values belonging to the set (0,1,2). In order to check the distribution of values in each column, I used <code>pandas.DataFrame.hist()</code> method which gave me a plot as shown below:\n<a href=\"https://i.stack.imgur.com/73mY7.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/73mY7.png\" alt=\"Figure\"></a> </p>\n\n<p>I want to represent the distribution for each value in a column with different color. For example, in column1 all the values corresponding to '0' should be in red color while the values corresponding to '1' in green color and so on. How can I do this? Please help !!</p>\n",
                "tags": "<python><dataset><visualization><pandas><distribution>",
                "answers": [
                    [
                        "15185",
                        "2",
                        "15043",
                        "",
                        "",
                        "<p>There isn't any built-in function to do this directly in pandas, but by getting the array collection of <code>AxesSubplot</code>, iterating on them to retrieve the matplotlib patches you can achieve the desired result.</p>\n\n<p>Here's some dummy data to play with:</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\ndf = pd.DataFrame(np.random.randint(low=0, high=3, size=(1000,16)))\n</code></pre>\n\n<p>Now, here's the magic:</p>\n\n<pre><code>import matplotlib.pyplot as plt\n\n# Plot and retrieve the axes\naxes = df.hist(figsize=(12,6), sharex=True, sharey=True)\n\n# Define a different color for the first three bars\ncolors = [\"#e74c3c\", \"#2ecc71\", \"#3498db\"]\n\nfor i, ax in enumerate(axes.reshape(-1)):\n    # Define a counter to ensure that if we have more than three bars with a value,\n    # we don't try to access out-of-range element in colors\n    k = 0\n\n    # Optional: remove grid, and top and right spines\n    ax.grid(False)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n\n    for rect in ax.patches:\n        # If there's a value in the rect and we have defined a color\n        if rect.get_height() &gt; 0 and k &lt; len(colors):\n            # Set the color\n            rect.set_color(colors[k])\n            # Increment the counter\n            k += 1\n\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/4w9Ac.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/4w9Ac.png\" alt=\"Resulting hist subplot with colors\"></a></p>\n",
                        "",
                        "6"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6067",
            "_score": 6.2486935,
            "_source": {
                "title": "Deep Reinforcent Learning Model, experience replay",
                "content": "Deep Reinforcent Learning Model, experience replay <p>So I am working on a deep RL model in OpenAI Gym. I have everything else working except for my function that allows my agent experience replay.</p>\n\n<p>here is the code:</p>\n\n<pre><code>import tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom collections import deque\nfrom keras.optimizers import Adam\nimport numpy as np\nimport gym\nimport tensorflow as tf\nimport math\nimport random\n\n\n\nenv = gym.make('MountainCar-v0')\n\n#hyperparams\ngamma = .99 #discount factor for reward\nalpha = .01 #learning rate\nbeta  = .01 #decay\nbatch_size = 32\nmemory = deque(maxlen=2000)\nepsilon = 1.0\n\n\n#building model\nmodel = Sequential()\nmodel.add(Dense(12, activation='sigmoid', input_dim=2))\nmodel.add(Dense(12, activation='tanh'))\nmodel.add(Dense(2, activation='linear'))\nmodel.compile(loss='mse', optimizer=Adam(lr=alpha, decay=beta))\n\n\ndef preprocess_state(state):\n    return np.reshape(state, [1, 2])\n\ndef experience(state, action, reward, next_state, done):\n    # memory for replay\n    memory.append((state, action, reward, next_state, done))\n\nclass agent():\n\n\n\n\ndef choose_action(self, state):\n    rand_number = np.random.randint(2)\n# choosing random action 50%, acting greedily with respect to value func/policy (naive e-greedy)\n    return env.action_space.sample() if (np.random.random() &lt;= epsilon) else np.argmax(model.predict(state))\n\ndef replay(self):\n    x_batch, y_batch = [], []\n    minibatch = random.sample(memory, batch_size)\n    for state, action, reward, next_state, done in minibatch:\n        y_target = model.predict(state)\n        y_target[0][action] = reward if done else reward + gamma * np.max(model.predict(next_state)[0])\n        x_batch.append(state[0])\n        y_batch.append(y_target[0])\n\n\nagent = agent()\n\n\ndef run():\n\nfor episodes in range(1000):\n    state = preprocess_state(env.reset())\n    tot_reward = 0\n    done = False\n    while not done:\n        env.render()\n        action = agent.choose_action(state)\n        next_state, reward, done, t = env.step(action)\n        next_state = preprocess_state(next_state)\n        #record results\n\n        experience(state,action,reward,next_state,done)\n\n        tot_reward += reward\n\n        #replay for agent\n        if batch_size &lt; len(memory):\n            agent.replay()\n\n        print(\"episode: {} | score: {} |\".format(\n       episodes,tot_reward))\n\n        if done:\n            print \"You did it\"\n            break\n\nrun()\n</code></pre>\n\n<p>The issue is with this line:</p>\n\n<pre><code>  y_target[0][action] = reward if done else reward + gamma * np.max(model.predict(next_state)[0])\n</code></pre>\n\n<p>and the error: <a href=\"https://i.stack.imgur.com/2ZeGn.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/2ZeGn.png\" alt=\"enter image description here\"></a></p>\n <python><tensorflow><keras><reinforcement-learning>",
                "codes": [],
                "question_id:": "23853",
                "question_votes:": "1",
                "question_text:": "<p>So I am working on a deep RL model in OpenAI Gym. I have everything else working except for my function that allows my agent experience replay.</p>\n\n<p>here is the code:</p>\n\n<pre><code>import tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom collections import deque\nfrom keras.optimizers import Adam\nimport numpy as np\nimport gym\nimport tensorflow as tf\nimport math\nimport random\n\n\n\nenv = gym.make('MountainCar-v0')\n\n#hyperparams\ngamma = .99 #discount factor for reward\nalpha = .01 #learning rate\nbeta  = .01 #decay\nbatch_size = 32\nmemory = deque(maxlen=2000)\nepsilon = 1.0\n\n\n#building model\nmodel = Sequential()\nmodel.add(Dense(12, activation='sigmoid', input_dim=2))\nmodel.add(Dense(12, activation='tanh'))\nmodel.add(Dense(2, activation='linear'))\nmodel.compile(loss='mse', optimizer=Adam(lr=alpha, decay=beta))\n\n\ndef preprocess_state(state):\n    return np.reshape(state, [1, 2])\n\ndef experience(state, action, reward, next_state, done):\n    # memory for replay\n    memory.append((state, action, reward, next_state, done))\n\nclass agent():\n\n\n\n\ndef choose_action(self, state):\n    rand_number = np.random.randint(2)\n# choosing random action 50%, acting greedily with respect to value func/policy (naive e-greedy)\n    return env.action_space.sample() if (np.random.random() &lt;= epsilon) else np.argmax(model.predict(state))\n\ndef replay(self):\n    x_batch, y_batch = [], []\n    minibatch = random.sample(memory, batch_size)\n    for state, action, reward, next_state, done in minibatch:\n        y_target = model.predict(state)\n        y_target[0][action] = reward if done else reward + gamma * np.max(model.predict(next_state)[0])\n        x_batch.append(state[0])\n        y_batch.append(y_target[0])\n\n\nagent = agent()\n\n\ndef run():\n\nfor episodes in range(1000):\n    state = preprocess_state(env.reset())\n    tot_reward = 0\n    done = False\n    while not done:\n        env.render()\n        action = agent.choose_action(state)\n        next_state, reward, done, t = env.step(action)\n        next_state = preprocess_state(next_state)\n        #record results\n\n        experience(state,action,reward,next_state,done)\n\n        tot_reward += reward\n\n        #replay for agent\n        if batch_size &lt; len(memory):\n            agent.replay()\n\n        print(\"episode: {} | score: {} |\".format(\n       episodes,tot_reward))\n\n        if done:\n            print \"You did it\"\n            break\n\nrun()\n</code></pre>\n\n<p>The issue is with this line:</p>\n\n<pre><code>  y_target[0][action] = reward if done else reward + gamma * np.max(model.predict(next_state)[0])\n</code></pre>\n\n<p>and the error: <a href=\"https://i.stack.imgur.com/2ZeGn.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/2ZeGn.png\" alt=\"enter image description here\"></a></p>\n",
                "tags": "<python><tensorflow><keras><reinforcement-learning>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "18498",
            "_score": 6.2367034,
            "_source": {
                "title": "TensorFlow 2.0 low level MLP training doesn't converge",
                "content": "TensorFlow 2.0 low level MLP training doesn't converge <p>I'm new to tensorflow and I'm trying to implement and train a simple MLP network without using keras. I'm using a simple dataset with 600 samples and 7 featurs (6 numeric and 1 categorical.) The target variable is a binary (0/1) variable with dimension 1.</p>\n\n<p>I'm trying to solve this simple binary classification problem with a \"regression approach\". With keras I get very good results, comparable to the other developing environment I use (matlab/R) but without keras the training clearly doesn't converge.</p>\n\n<p>Here's my code:</p>\n\n<pre><code>#IMPORT LIBRARIES\nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\nimport pathlib\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport contextlib\nimport tensorflow as tf\nfrom tensorflow import keras\n\nprint(tf.__version__)\n#######################\n\n\n#IMPORT DATA\ndataset_path = \"C:/Users/Rob/Desktop/Data.csv\"\nraw_dataset = pd.read_csv(dataset_path\n                          , comment='\\t',sep=\",\"\n                          ,skipinitialspace=False)\n\n\ndataset = raw_dataset.copy()\n######################\n\n\n\n#CONVERT CATEGORICAL VARS TO DUMMY VARS\norigin = dataset.pop('Cat x')\ndataset['A'] = (origin == 'A')*1.0\ndataset['B'] = (origin == 'B')*1.0\n######################\n\n\n\n\n#SPLIT DATASET INTO TRAIN/TEST\ntrain_dataset = dataset.sample(frac=0.8,random_state=0)\ntest_dataset = dataset.drop(train_dataset.index)\n\ntrain_labels = train_dataset.pop('Target_1')\ntest_labels = test_dataset.pop('Target_1')\n########################\n\n\n\n\n#NORMALIZE DATA AND DEFINE FINAL DATASET FOR TRAINING\ntrain_stats = train_dataset.describe()\ntrain_stats = train_stats.transpose()\n\ndef norm(x):\n  return (x - train_stats['mean']) / train_stats['std']\nnormed_train_data = norm(train_dataset)\nnormed_test_data = norm(test_dataset)\n\nnormed_train_data_np = np.array(normed_train_data,dtype = \"float32\")\ntrain_labels_np = np.array(train_labels, dtype = \"float32\")\n\nnormed_test_data_np = np.array(normed_test_data,dtype = \"float32\")\ntest_labels_np = np.array(test_labels, dtype = \"float32\")\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((normed_train_data_np,train_labels_np))\ntrain_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n#######################\n\n\n\n\n\n#DEFINE MODEL\nn_hidden_1 = 10\nn_input = 7\nn_classes = 1\n\n\nw1 = tf.Variable(tf.random.normal([n_input, n_hidden_1]))\nw2 = tf.Variable(tf.random.normal([n_hidden_1, n_classes]))\nb1 = tf.Variable(tf.random.normal([n_hidden_1]))\nb2 = tf.Variable(tf.random.normal([n_classes]))\n\n\n@tf.function\ndef multilayer_perceptron(x, w1, w2, b1, b2):\n    layer_1 = tf.nn.tanh(tf.add(tf.matmul(x,w1),b1))\n    out_layer = tf.add(tf.matmul(layer_1, w2),b2)\n    return out_layer\n\n\noptimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-3)\nmse_loss_fn = tf.keras.losses.MeanSquaredError()\n\n#loss_metric = tf.keras.metrics.Mean()\n#######################\n\n\n\n\n\n\n#TRAIN MODEL\ntrainable_variables = [w1,w2,b1,b2]\nepochs = 10\n\n# Iterate over epochs.\nfor epoch in range(epochs):\n  print('Start of epoch %d' % (epoch,))\n  for x, y in train_dataset:\n    with tf.GradientTape() as tape:\n      prediction = multilayer_perceptron(x,w1,w2,b1,b2)\n      loss = mse_loss_fn(prediction, y)\n    gradients = tape.gradient(loss, trainable_variables)\n    optimizer.apply_gradients(zip(gradients, trainable_variables))\n#####################\n\n\n\n\n\n\n#INFERENCE AND EXPORT RESULTS\ntest_predictions = multilayer_perceptron(normed_test_data_np,w1,w2,b1,b2)\n\n\n\na = test_predictions.numpy()\na = a.reshape(120)\nb  = np.array([a,test_labels_np])\nb = b.T\ndf = pd.DataFrame(b,columns=['Pred', 'Target'])\ndf.to_csv(r'C:/Users/Rob/Desktop/Output3.csv')\n####################\n\n</code></pre>\n\n<p>Probably I'm missing something obvious.\nAny help?</p>\n\n<p>Thanks</p>\n <tensorflow><mlp>",
                "codes": [],
                "question_id:": "58464",
                "question_votes:": "",
                "question_text:": "<p>I'm new to tensorflow and I'm trying to implement and train a simple MLP network without using keras. I'm using a simple dataset with 600 samples and 7 featurs (6 numeric and 1 categorical.) The target variable is a binary (0/1) variable with dimension 1.</p>\n\n<p>I'm trying to solve this simple binary classification problem with a \"regression approach\". With keras I get very good results, comparable to the other developing environment I use (matlab/R) but without keras the training clearly doesn't converge.</p>\n\n<p>Here's my code:</p>\n\n<pre><code>#IMPORT LIBRARIES\nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\nimport pathlib\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport contextlib\nimport tensorflow as tf\nfrom tensorflow import keras\n\nprint(tf.__version__)\n#######################\n\n\n#IMPORT DATA\ndataset_path = \"C:/Users/Rob/Desktop/Data.csv\"\nraw_dataset = pd.read_csv(dataset_path\n                          , comment='\\t',sep=\",\"\n                          ,skipinitialspace=False)\n\n\ndataset = raw_dataset.copy()\n######################\n\n\n\n#CONVERT CATEGORICAL VARS TO DUMMY VARS\norigin = dataset.pop('Cat x')\ndataset['A'] = (origin == 'A')*1.0\ndataset['B'] = (origin == 'B')*1.0\n######################\n\n\n\n\n#SPLIT DATASET INTO TRAIN/TEST\ntrain_dataset = dataset.sample(frac=0.8,random_state=0)\ntest_dataset = dataset.drop(train_dataset.index)\n\ntrain_labels = train_dataset.pop('Target_1')\ntest_labels = test_dataset.pop('Target_1')\n########################\n\n\n\n\n#NORMALIZE DATA AND DEFINE FINAL DATASET FOR TRAINING\ntrain_stats = train_dataset.describe()\ntrain_stats = train_stats.transpose()\n\ndef norm(x):\n  return (x - train_stats['mean']) / train_stats['std']\nnormed_train_data = norm(train_dataset)\nnormed_test_data = norm(test_dataset)\n\nnormed_train_data_np = np.array(normed_train_data,dtype = \"float32\")\ntrain_labels_np = np.array(train_labels, dtype = \"float32\")\n\nnormed_test_data_np = np.array(normed_test_data,dtype = \"float32\")\ntest_labels_np = np.array(test_labels, dtype = \"float32\")\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((normed_train_data_np,train_labels_np))\ntrain_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n#######################\n\n\n\n\n\n#DEFINE MODEL\nn_hidden_1 = 10\nn_input = 7\nn_classes = 1\n\n\nw1 = tf.Variable(tf.random.normal([n_input, n_hidden_1]))\nw2 = tf.Variable(tf.random.normal([n_hidden_1, n_classes]))\nb1 = tf.Variable(tf.random.normal([n_hidden_1]))\nb2 = tf.Variable(tf.random.normal([n_classes]))\n\n\n@tf.function\ndef multilayer_perceptron(x, w1, w2, b1, b2):\n    layer_1 = tf.nn.tanh(tf.add(tf.matmul(x,w1),b1))\n    out_layer = tf.add(tf.matmul(layer_1, w2),b2)\n    return out_layer\n\n\noptimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-3)\nmse_loss_fn = tf.keras.losses.MeanSquaredError()\n\n#loss_metric = tf.keras.metrics.Mean()\n#######################\n\n\n\n\n\n\n#TRAIN MODEL\ntrainable_variables = [w1,w2,b1,b2]\nepochs = 10\n\n# Iterate over epochs.\nfor epoch in range(epochs):\n  print('Start of epoch %d' % (epoch,))\n  for x, y in train_dataset:\n    with tf.GradientTape() as tape:\n      prediction = multilayer_perceptron(x,w1,w2,b1,b2)\n      loss = mse_loss_fn(prediction, y)\n    gradients = tape.gradient(loss, trainable_variables)\n    optimizer.apply_gradients(zip(gradients, trainable_variables))\n#####################\n\n\n\n\n\n\n#INFERENCE AND EXPORT RESULTS\ntest_predictions = multilayer_perceptron(normed_test_data_np,w1,w2,b1,b2)\n\n\n\na = test_predictions.numpy()\na = a.reshape(120)\nb  = np.array([a,test_labels_np])\nb = b.T\ndf = pd.DataFrame(b,columns=['Pred', 'Target'])\ndf.to_csv(r'C:/Users/Rob/Desktop/Output3.csv')\n####################\n\n</code></pre>\n\n<p>Probably I'm missing something obvious.\nAny help?</p>\n\n<p>Thanks</p>\n",
                "tags": "<tensorflow><mlp>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3130",
            "_score": 6.22053,
            "_source": {
                "title": "Validation loss and accuracy remain constant",
                "content": "Validation loss and accuracy remain constant <p>I am trying to implement <a href=\"http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0137036\" rel=\"nofollow noreferrer\">this</a> paper on a set of medical images. I am doing it in Keras. The network essentially consists of 4 conv and max-pool layers followed by a fully connected layer and soft max classifier.</p>\n\n<p>As far as I know, I have followed the architecture mentioned in the paper. However, the validation loss and accuracy just remain flat throughout. The accuracy seems to be fixed at ~57.5%.</p>\n\n<p>Any help on where I might be going wrong would be greatly appreciated.</p>\n\n<p>My code:</p>\n\n<pre><code>from keras.models import Sequential\nfrom keras.layers import Activation, Dropout, Dense, Flatten  \nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nfrom PIL import Image\nimport numpy as np\nfrom sklearn.utils import shuffle\nfrom sklearn.cross_validation import train_test_split\nimport theano\nimport os\nimport glob as glob\nimport cv2\nfrom matplotlib import pyplot as plt\n\nnb_classes = 2\nimg_rows, img_cols = 100,100\nimg_channels = 3\n\n\n#################### DATA DIRECTORY SETTING######################\n\ndata = '/home/raghuram/Desktop/data'\nos.chdir(data)\nfile_list = os.listdir(data)\n##################################################################\n\n## Test lines\n#I = cv2.imread(file_list[1000])\n#print np.shape(I)\n####\nnon_responder_file_list = glob.glob('0_*FLAIR_*.png')\nresponder_file_list = glob.glob('1_*FLAIR_*.png')\nprint len(non_responder_file_list),len(responder_file_list)\n\nlabels = np.ones((len(file_list)),dtype = int)\nlabels[0:len(non_responder_file_list)] = 0\nimmatrix = np.array([np.array(cv2.imread(data+'/'+image)).flatten() for image in file_list])\n#img = immatrix[1000].reshape(100,100,3)\n#plt.imshow(img,cmap = 'gray')\n\n\ndata,Label = shuffle(immatrix,labels, random_state=2)\ntrain_data = [data,Label]\nX,y = (train_data[0],train_data[1])\n# Also need to look at how to preserve spatial extent in the conv network\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\nX_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\nX_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\nX_train /= 255\nX_test /= 255\n\nY_train = np_utils.to_categorical(y_train, nb_classes)\nY_test = np_utils.to_categorical(y_test, nb_classes)\n\nmodel = Sequential()\n\n## First conv layer and its activation followed by the max-pool layer#\nmodel.add(Convolution2D(16,5,5, border_mode = 'valid', subsample = (1,1), init = 'glorot_normal',input_shape = (3,100,100))) # Glorot normal is similar to Xavier initialization\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2),strides = None))\n# Output is 48x48\n\nprint 'First layer setup'\n###########################Second conv layer#################################\nmodel.add(Convolution2D(32,3,3,border_mode = 'same', subsample = (1,1),init = 'glorot_normal'))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.6))\nmodel.add(MaxPooling2D(pool_size = (2,2),strides = None))\n#############################################################################\n\nprint ' Second layer setup'\n# Output is 2x24\n\n##########################Third conv layer###################################\nmodel.add(Convolution2D(64,3,3, border_mode = 'same', subsample = (1,1), init = 'glorot_normal'))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.6))\nmodel.add(MaxPooling2D(pool_size = (2,2),strides = None))\n#############################################################################\n# Output is 12x12\n\nprint ' Third layer setup'\n###############################Fourth conv layer#############################\nmodel.add(Convolution2D(128,3,3, border_mode = 'same', subsample = (1,1), init = 'glorot_normal'))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.6))\nmodel.add(MaxPooling2D(pool_size = (2,2),strides = None))\n############################################################################# \n\nprint 'Fourth layer setup'\n\n# Output is 6x6x128\n# Create the FC layer of size 128x6x6#\nmodel.add(Flatten()) \nmodel.add(Dense(2,init = 'glorot_normal',input_dim = 128*6*6))\nmodel.add(Dropout(0.6))\nmodel.add(Activation('softmax'))\n\nprint 'Setting up fully connected layer'\nprint 'Now compiling the network'\nsgd = SGD(lr=0.01, decay=1e-4, momentum=0.6, nesterov=True)\nmodel.compile(loss = 'mse',optimizer = 'sgd', metrics=['accuracy'])\n\n# Fit the network to the data#\nprint 'Network setup successfully. Now fitting the network to the data'\nmodel. fit(X_train,Y_train,batch_size = 100, nb_epoch = 20, validation_split = None,verbose = 1)\nprint 'Testing'\nloss,accuracy = model.evaluate(X_test,Y_test,batch_size = 32,verbose = 1)\nprint \"Test fraction correct (Accuracy) = {:.2f}\".format(accuracy)\n</code></pre>\n <machine-learning><python><deep-learning><keras><p>It seems that you use MSE as the loss function, from a glimpse on the paper it seems they use NLL (cross entropy), MSE is considered prone to be sensitive to data imbalance among other issues and it may be the cause of the problem you experience, I would try training using categorical_crossentropy loss in your case, moreover learning rate of 0.01 seems too large I would try to play with it and try 0.001 or even 0.0001</p>\n<p>Though I am a bit late here, I would like to put my two cents in as it helped me solve a similar issue recently. What came to my rescue was scaling the features into (0,1) range besides the categorical cross-entropy loss. Nevertheless, it is worth saying that feature scaling helps only if the features belong to different metrics and possess way more variation (in orders of magnitudes) relative to one another, as was in my case. Also, scaling could be really useful if one uses the <code>hinge</code> loss, as max-margin classifiers are generally sensitive to the distances among feature values. Hope this helps some future visitors!</p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "13607",
                "question_votes:": "12",
                "question_text:": "<p>I am trying to implement <a href=\"http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0137036\" rel=\"nofollow noreferrer\">this</a> paper on a set of medical images. I am doing it in Keras. The network essentially consists of 4 conv and max-pool layers followed by a fully connected layer and soft max classifier.</p>\n\n<p>As far as I know, I have followed the architecture mentioned in the paper. However, the validation loss and accuracy just remain flat throughout. The accuracy seems to be fixed at ~57.5%.</p>\n\n<p>Any help on where I might be going wrong would be greatly appreciated.</p>\n\n<p>My code:</p>\n\n<pre><code>from keras.models import Sequential\nfrom keras.layers import Activation, Dropout, Dense, Flatten  \nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nfrom PIL import Image\nimport numpy as np\nfrom sklearn.utils import shuffle\nfrom sklearn.cross_validation import train_test_split\nimport theano\nimport os\nimport glob as glob\nimport cv2\nfrom matplotlib import pyplot as plt\n\nnb_classes = 2\nimg_rows, img_cols = 100,100\nimg_channels = 3\n\n\n#################### DATA DIRECTORY SETTING######################\n\ndata = '/home/raghuram/Desktop/data'\nos.chdir(data)\nfile_list = os.listdir(data)\n##################################################################\n\n## Test lines\n#I = cv2.imread(file_list[1000])\n#print np.shape(I)\n####\nnon_responder_file_list = glob.glob('0_*FLAIR_*.png')\nresponder_file_list = glob.glob('1_*FLAIR_*.png')\nprint len(non_responder_file_list),len(responder_file_list)\n\nlabels = np.ones((len(file_list)),dtype = int)\nlabels[0:len(non_responder_file_list)] = 0\nimmatrix = np.array([np.array(cv2.imread(data+'/'+image)).flatten() for image in file_list])\n#img = immatrix[1000].reshape(100,100,3)\n#plt.imshow(img,cmap = 'gray')\n\n\ndata,Label = shuffle(immatrix,labels, random_state=2)\ntrain_data = [data,Label]\nX,y = (train_data[0],train_data[1])\n# Also need to look at how to preserve spatial extent in the conv network\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\nX_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\nX_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\nX_train /= 255\nX_test /= 255\n\nY_train = np_utils.to_categorical(y_train, nb_classes)\nY_test = np_utils.to_categorical(y_test, nb_classes)\n\nmodel = Sequential()\n\n## First conv layer and its activation followed by the max-pool layer#\nmodel.add(Convolution2D(16,5,5, border_mode = 'valid', subsample = (1,1), init = 'glorot_normal',input_shape = (3,100,100))) # Glorot normal is similar to Xavier initialization\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2),strides = None))\n# Output is 48x48\n\nprint 'First layer setup'\n###########################Second conv layer#################################\nmodel.add(Convolution2D(32,3,3,border_mode = 'same', subsample = (1,1),init = 'glorot_normal'))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.6))\nmodel.add(MaxPooling2D(pool_size = (2,2),strides = None))\n#############################################################################\n\nprint ' Second layer setup'\n# Output is 2x24\n\n##########################Third conv layer###################################\nmodel.add(Convolution2D(64,3,3, border_mode = 'same', subsample = (1,1), init = 'glorot_normal'))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.6))\nmodel.add(MaxPooling2D(pool_size = (2,2),strides = None))\n#############################################################################\n# Output is 12x12\n\nprint ' Third layer setup'\n###############################Fourth conv layer#############################\nmodel.add(Convolution2D(128,3,3, border_mode = 'same', subsample = (1,1), init = 'glorot_normal'))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.6))\nmodel.add(MaxPooling2D(pool_size = (2,2),strides = None))\n############################################################################# \n\nprint 'Fourth layer setup'\n\n# Output is 6x6x128\n# Create the FC layer of size 128x6x6#\nmodel.add(Flatten()) \nmodel.add(Dense(2,init = 'glorot_normal',input_dim = 128*6*6))\nmodel.add(Dropout(0.6))\nmodel.add(Activation('softmax'))\n\nprint 'Setting up fully connected layer'\nprint 'Now compiling the network'\nsgd = SGD(lr=0.01, decay=1e-4, momentum=0.6, nesterov=True)\nmodel.compile(loss = 'mse',optimizer = 'sgd', metrics=['accuracy'])\n\n# Fit the network to the data#\nprint 'Network setup successfully. Now fitting the network to the data'\nmodel. fit(X_train,Y_train,batch_size = 100, nb_epoch = 20, validation_split = None,verbose = 1)\nprint 'Testing'\nloss,accuracy = model.evaluate(X_test,Y_test,batch_size = 32,verbose = 1)\nprint \"Test fraction correct (Accuracy) = {:.2f}\".format(accuracy)\n</code></pre>\n",
                "tags": "<machine-learning><python><deep-learning><keras>",
                "answers": [
                    [
                        "28145",
                        "2",
                        "13607",
                        "",
                        "",
                        "<p>It seems that you use MSE as the loss function, from a glimpse on the paper it seems they use NLL (cross entropy), MSE is considered prone to be sensitive to data imbalance among other issues and it may be the cause of the problem you experience, I would try training using categorical_crossentropy loss in your case, moreover learning rate of 0.01 seems too large I would try to play with it and try 0.001 or even 0.0001</p>\n",
                        "",
                        "4"
                    ],
                    [
                        "35701",
                        "2",
                        "13607",
                        "",
                        "",
                        "<p>Though I am a bit late here, I would like to put my two cents in as it helped me solve a similar issue recently. What came to my rescue was scaling the features into (0,1) range besides the categorical cross-entropy loss. Nevertheless, it is worth saying that feature scaling helps only if the features belong to different metrics and possess way more variation (in orders of magnitudes) relative to one another, as was in my case. Also, scaling could be really useful if one uses the <code>hinge</code> loss, as max-margin classifiers are generally sensitive to the distances among feature values. Hope this helps some future visitors!</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3095",
            "_score": 6.216078,
            "_source": {
                "title": "How to set class weights for imbalanced classes in Keras?",
                "content": "How to set class weights for imbalanced classes in Keras? <p>I know that there is a possibility in Keras with the <code>class_weights</code> parameter dictionary at fitting, but I couldn't find any example. Would somebody so kind to provide one?</p>\n\n<p>By the way, in this case the appropriate praxis is simply to weight up the minority class proportionally to its underrepresentation?</p>\n <classification><keras><weighted-data><p>You could simply implement the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html\" rel=\"noreferrer\"><code>class_weight</code></a> from <code>sklearn</code>:</p>\n\n<ol>\n<li><p>Let's import the module first</p>\n\n<pre><code>from sklearn.utils import class_weight\n</code></pre></li>\n<li><p>In order to calculate the class weight do the following</p>\n\n<pre><code>class_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(y_train),\n                                                 y_train)\n</code></pre></li>\n<li><p>Thirdly and lastly add it to the model fitting</p>\n\n<pre><code>model.fit(X_train, y_train, class_weight=class_weights)\n</code></pre></li>\n</ol>\n\n<p><strong>Attention</strong>: I edited this post and changed the variable name from <em>class_weight</em> to <em>class_weight<strong>s</em></strong> in order to not to overwrite the imported module. Adjust accordingly when copying code from the comments.</p>\n<p><strong>NOTE: See comments, this answer is outdated.</strong></p>\n\n<p>To weight all classes equally, you can now simply set class_weight to \"auto\" like so:</p>\n\n<pre><code>model.fit(X_train, Y_train, nb_epoch=5, batch_size=32, class_weight = 'auto')\n</code></pre>\n<p>class_weight is fine but as @Aalok said this won't work if you are one-hot encoding multilabeled classes. In this case, use <strong>sample_weight</strong>:</p>\n\n<blockquote>\n  <p>sample_weight: optional array of the same length as x, containing\n  weights to apply to the model's loss for each sample. In the case of\n  temporal data, you can pass a 2D array with shape (samples,\n  sequence_length), to apply a different weight to every timestep of\n  every sample. In this case you should make sure to specify\n  sample_weight_mode=\"temporal\" in compile().</p>\n</blockquote>\n\n<p><strong>sample_weights</strong> is used to <strong>provide a weight for each training sample</strong>. That means that you should pass a 1D array with the same number of elements as your training samples (indicating the weight for each of those samples).</p>\n\n<p><strong>class_weights</strong> is used to provide a <strong>weight or bias for each output class</strong>. This means you should pass a weight for each class that you are trying to classify.</p>\n\n<p>sample_weight must be given a numpy array, since its shape will be evaluated.</p>\n\n<p>See also this answer: <a href=\"https://stackoverflow.com/questions/48315094/using-sample-weight-in-keras-for-sequence-labelling\">https://stackoverflow.com/questions/48315094/using-sample-weight-in-keras-for-sequence-labelling</a></p>\n<p>Adding to the solution at <a href=\"https://github.com/keras-team/keras/issues/2115\" rel=\"nofollow noreferrer\">https://github.com/keras-team/keras/issues/2115</a>. If you need more than class weighting where you want different costs for false positives and false negatives. With the new keras version now you can just override the respective loss function as given below.\nNote that <code>weights</code> is a square matrix.</p>\n\n<pre><code>from tensorflow.python import keras\nfrom itertools import product\nimport numpy as np\nfrom tensorflow.python.keras.utils import losses_utils\n\nclass WeightedCategoricalCrossentropy(keras.losses.CategoricalCrossentropy):\n\n    def __init__(\n        self,\n        weights,\n        from_logits=False,\n        label_smoothing=0,\n        reduction=losses_utils.ReductionV2.SUM_OVER_BATCH_SIZE,\n        name='categorical_crossentropy',\n    ):\n        super().__init__(\n            from_logits, label_smoothing, reduction, name=f\"weighted_{name}\"\n        )\n        self.weights = weights\n\n    def call(self, y_true, y_pred):\n        weights = self.weights\n        nb_cl = len(weights)\n        final_mask = keras.backend.zeros_like(y_pred[:, 0])\n        y_pred_max = keras.backend.max(y_pred, axis=1)\n        y_pred_max = keras.backend.reshape(\n            y_pred_max, (keras.backend.shape(y_pred)[0], 1))\n        y_pred_max_mat = keras.backend.cast(\n            keras.backend.equal(y_pred, y_pred_max), keras.backend.floatx())\n        for c_p, c_t in product(range(nb_cl), range(nb_cl)):\n            final_mask += (\n                weights[c_t, c_p] * y_pred_max_mat[:, c_p] * y_true[:, c_t])\n        return super().call(y_true, y_pred) * final_mask\n</code></pre>\n<p>If you are talking about the regular case, where your network produces only one output, then your assumption is correct. In order to force your algorithm to treat every instance of <strong>class 1</strong> as 50 instances of <strong>class 0</strong> you have to:</p>\n\n<ol>\n<li><p>Define a dictionary with your labels and their associated weights</p>\n\n<pre><code>class_weight = {0: 1.,\n                1: 50.,\n                2: 2.}\n</code></pre></li>\n<li><p>Feed the dictionary as a parameter:</p>\n\n<pre><code>model.fit(X_train, Y_train, nb_epoch=5, batch_size=32, class_weight=class_weight)\n</code></pre></li>\n</ol>\n\n<p>EDIT:\n\"treat every instance of <strong>class 1</strong> as 50 instances of <strong>class 0</strong>\" means that in your loss function you assign higher value to these instances.\nHence, the loss becomes a weighted average, where the weight of each sample is specified by <strong>class_weight</strong> and its corresponding class. </p>\n\n<p>From Keras docs: <strong>class_weight</strong>: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). </p>\n<p>I found the following example of coding up class weights in the loss function using the minist dataset. See link here: <a href=\"https://github.com/keras-team/keras/issues/2115\" rel=\"nofollow noreferrer\">https://github.com/keras-team/keras/issues/2115</a></p>\n\n<pre><code>def w_categorical_crossentropy(y_true, y_pred, weights):\n    nb_cl = len(weights)\n    final_mask = K.zeros_like(y_pred[:, 0])\n    y_pred_max = K.max(y_pred, axis=1)\n    y_pred_max = K.reshape(y_pred_max, (K.shape(y_pred)[0], 1))\n    y_pred_max_mat = K.equal(y_pred, y_pred_max)\n    for c_p, c_t in product(range(nb_cl), range(nb_cl)):\n        final_mask += (weights[c_t, c_p] * y_pred_max_mat[:, c_p] * y_true[:, c_t])\n    return K.categorical_crossentropy(y_pred, y_true) * final_mask\n</code></pre>\n<p>I use this kind of rule for <code>class_weight</code> : </p>\n\n<pre><code>import numpy as np\nimport math\n\n# labels_dict : {ind_label: count_label}\n# mu : parameter to tune \n\ndef create_class_weight(labels_dict,mu=0.15):\n    total = np.sum(labels_dict.values())\n    keys = labels_dict.keys()\n    class_weight = dict()\n\n    for key in keys:\n        score = math.log(mu*total/float(labels_dict[key]))\n        class_weight[key] = score if score &gt; 1.0 else 1.0\n\n    return class_weight\n\n# random labels_dict\nlabels_dict = {0: 2813, 1: 78, 2: 2814, 3: 78, 4: 7914, 5: 248, 6: 7914, 7: 248}\n\ncreate_class_weight(labels_dict)\n</code></pre>\n\n<p><code>math.log</code> smooths the weights for very imbalanced classes !\nThis returns : </p>\n\n<pre><code>{0: 1.0,\n 1: 3.749820767859636,\n 2: 1.0,\n 3: 3.749820767859636,\n 4: 1.0,\n 5: 2.5931008483842453,\n 6: 1.0,\n 7: 2.5931008483842453}\n</code></pre>\n",
                "codes": [
                    [
                        "from sklearn.utils import class_weight\n",
                        "class_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(y_train),\n                                                 y_train)\n",
                        "model.fit(X_train, y_train, class_weight=class_weights)\n"
                    ],
                    [
                        "model.fit(X_train, Y_train, nb_epoch=5, batch_size=32, class_weight = 'auto')\n"
                    ],
                    [],
                    [
                        "from tensorflow.python import keras\nfrom itertools import product\nimport numpy as np\nfrom tensorflow.python.keras.utils import losses_utils\n\nclass WeightedCategoricalCrossentropy(keras.losses.CategoricalCrossentropy):\n\n    def __init__(\n        self,\n        weights,\n        from_logits=False,\n        label_smoothing=0,\n        reduction=losses_utils.ReductionV2.SUM_OVER_BATCH_SIZE,\n        name='categorical_crossentropy',\n    ):\n        super().__init__(\n            from_logits, label_smoothing, reduction, name=f\"weighted_{name}\"\n        )\n        self.weights = weights\n\n    def call(self, y_true, y_pred):\n        weights = self.weights\n        nb_cl = len(weights)\n        final_mask = keras.backend.zeros_like(y_pred[:, 0])\n        y_pred_max = keras.backend.max(y_pred, axis=1)\n        y_pred_max = keras.backend.reshape(\n            y_pred_max, (keras.backend.shape(y_pred)[0], 1))\n        y_pred_max_mat = keras.backend.cast(\n            keras.backend.equal(y_pred, y_pred_max), keras.backend.floatx())\n        for c_p, c_t in product(range(nb_cl), range(nb_cl)):\n            final_mask += (\n                weights[c_t, c_p] * y_pred_max_mat[:, c_p] * y_true[:, c_t])\n        return super().call(y_true, y_pred) * final_mask\n"
                    ],
                    [
                        "class_weight = {0: 1.,\n                1: 50.,\n                2: 2.}\n",
                        "model.fit(X_train, Y_train, nb_epoch=5, batch_size=32, class_weight=class_weight)\n"
                    ],
                    [
                        "def w_categorical_crossentropy(y_true, y_pred, weights):\n    nb_cl = len(weights)\n    final_mask = K.zeros_like(y_pred[:, 0])\n    y_pred_max = K.max(y_pred, axis=1)\n    y_pred_max = K.reshape(y_pred_max, (K.shape(y_pred)[0], 1))\n    y_pred_max_mat = K.equal(y_pred, y_pred_max)\n    for c_p, c_t in product(range(nb_cl), range(nb_cl)):\n        final_mask += (weights[c_t, c_p] * y_pred_max_mat[:, c_p] * y_true[:, c_t])\n    return K.categorical_crossentropy(y_pred, y_true) * final_mask\n"
                    ],
                    [
                        "import numpy as np\nimport math\n\n# labels_dict : {ind_label: count_label}\n# mu : parameter to tune \n\ndef create_class_weight(labels_dict,mu=0.15):\n    total = np.sum(labels_dict.values())\n    keys = labels_dict.keys()\n    class_weight = dict()\n\n    for key in keys:\n        score = math.log(mu*total/float(labels_dict[key]))\n        class_weight[key] = score if score > 1.0 else 1.0\n\n    return class_weight\n\n# random labels_dict\nlabels_dict = {0: 2813, 1: 78, 2: 2814, 3: 78, 4: 7914, 5: 248, 6: 7914, 7: 248}\n\ncreate_class_weight(labels_dict)\n",
                        "{0: 1.0,\n 1: 3.749820767859636,\n 2: 1.0,\n 3: 3.749820767859636,\n 4: 1.0,\n 5: 2.5931008483842453,\n 6: 1.0,\n 7: 2.5931008483842453}\n"
                    ]
                ],
                "question_id:": "13490",
                "question_votes:": "124",
                "question_text:": "<p>I know that there is a possibility in Keras with the <code>class_weights</code> parameter dictionary at fitting, but I couldn't find any example. Would somebody so kind to provide one?</p>\n\n<p>By the way, in this case the appropriate praxis is simply to weight up the minority class proportionally to its underrepresentation?</p>\n",
                "tags": "<classification><keras><weighted-data>",
                "answers": [
                    [
                        "18722",
                        "2",
                        "13490",
                        "",
                        "",
                        "<p>You could simply implement the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html\" rel=\"noreferrer\"><code>class_weight</code></a> from <code>sklearn</code>:</p>\n\n<ol>\n<li><p>Let's import the module first</p>\n\n<pre><code>from sklearn.utils import class_weight\n</code></pre></li>\n<li><p>In order to calculate the class weight do the following</p>\n\n<pre><code>class_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(y_train),\n                                                 y_train)\n</code></pre></li>\n<li><p>Thirdly and lastly add it to the model fitting</p>\n\n<pre><code>model.fit(X_train, y_train, class_weight=class_weights)\n</code></pre></li>\n</ol>\n\n<p><strong>Attention</strong>: I edited this post and changed the variable name from <em>class_weight</em> to <em>class_weight<strong>s</em></strong> in order to not to overwrite the imported module. Adjust accordingly when copying code from the comments.</p>\n",
                        "",
                        "118"
                    ],
                    [
                        "15623",
                        "2",
                        "13490",
                        "",
                        "",
                        "<p><strong>NOTE: See comments, this answer is outdated.</strong></p>\n\n<p>To weight all classes equally, you can now simply set class_weight to \"auto\" like so:</p>\n\n<pre><code>model.fit(X_train, Y_train, nb_epoch=5, batch_size=32, class_weight = 'auto')\n</code></pre>\n",
                        "",
                        "11"
                    ],
                    [
                        "42534",
                        "2",
                        "13490",
                        "",
                        "",
                        "<p>class_weight is fine but as @Aalok said this won't work if you are one-hot encoding multilabeled classes. In this case, use <strong>sample_weight</strong>:</p>\n\n<blockquote>\n  <p>sample_weight: optional array of the same length as x, containing\n  weights to apply to the model's loss for each sample. In the case of\n  temporal data, you can pass a 2D array with shape (samples,\n  sequence_length), to apply a different weight to every timestep of\n  every sample. In this case you should make sure to specify\n  sample_weight_mode=\"temporal\" in compile().</p>\n</blockquote>\n\n<p><strong>sample_weights</strong> is used to <strong>provide a weight for each training sample</strong>. That means that you should pass a 1D array with the same number of elements as your training samples (indicating the weight for each of those samples).</p>\n\n<p><strong>class_weights</strong> is used to provide a <strong>weight or bias for each output class</strong>. This means you should pass a weight for each class that you are trying to classify.</p>\n\n<p>sample_weight must be given a numpy array, since its shape will be evaluated.</p>\n\n<p>See also this answer: <a href=\"https://stackoverflow.com/questions/48315094/using-sample-weight-in-keras-for-sequence-labelling\">https://stackoverflow.com/questions/48315094/using-sample-weight-in-keras-for-sequence-labelling</a></p>\n",
                        "",
                        "2"
                    ],
                    [
                        "51547",
                        "2",
                        "13490",
                        "",
                        "",
                        "<p>Adding to the solution at <a href=\"https://github.com/keras-team/keras/issues/2115\" rel=\"nofollow noreferrer\">https://github.com/keras-team/keras/issues/2115</a>. If you need more than class weighting where you want different costs for false positives and false negatives. With the new keras version now you can just override the respective loss function as given below.\nNote that <code>weights</code> is a square matrix.</p>\n\n<pre><code>from tensorflow.python import keras\nfrom itertools import product\nimport numpy as np\nfrom tensorflow.python.keras.utils import losses_utils\n\nclass WeightedCategoricalCrossentropy(keras.losses.CategoricalCrossentropy):\n\n    def __init__(\n        self,\n        weights,\n        from_logits=False,\n        label_smoothing=0,\n        reduction=losses_utils.ReductionV2.SUM_OVER_BATCH_SIZE,\n        name='categorical_crossentropy',\n    ):\n        super().__init__(\n            from_logits, label_smoothing, reduction, name=f\"weighted_{name}\"\n        )\n        self.weights = weights\n\n    def call(self, y_true, y_pred):\n        weights = self.weights\n        nb_cl = len(weights)\n        final_mask = keras.backend.zeros_like(y_pred[:, 0])\n        y_pred_max = keras.backend.max(y_pred, axis=1)\n        y_pred_max = keras.backend.reshape(\n            y_pred_max, (keras.backend.shape(y_pred)[0], 1))\n        y_pred_max_mat = keras.backend.cast(\n            keras.backend.equal(y_pred, y_pred_max), keras.backend.floatx())\n        for c_p, c_t in product(range(nb_cl), range(nb_cl)):\n            final_mask += (\n                weights[c_t, c_p] * y_pred_max_mat[:, c_p] * y_true[:, c_t])\n        return super().call(y_true, y_pred) * final_mask\n</code></pre>\n",
                        "",
                        "1"
                    ],
                    [
                        "13496",
                        "2",
                        "13490",
                        "",
                        "",
                        "<p>If you are talking about the regular case, where your network produces only one output, then your assumption is correct. In order to force your algorithm to treat every instance of <strong>class 1</strong> as 50 instances of <strong>class 0</strong> you have to:</p>\n\n<ol>\n<li><p>Define a dictionary with your labels and their associated weights</p>\n\n<pre><code>class_weight = {0: 1.,\n                1: 50.,\n                2: 2.}\n</code></pre></li>\n<li><p>Feed the dictionary as a parameter:</p>\n\n<pre><code>model.fit(X_train, Y_train, nb_epoch=5, batch_size=32, class_weight=class_weight)\n</code></pre></li>\n</ol>\n\n<p>EDIT:\n\"treat every instance of <strong>class 1</strong> as 50 instances of <strong>class 0</strong>\" means that in your loss function you assign higher value to these instances.\nHence, the loss becomes a weighted average, where the weight of each sample is specified by <strong>class_weight</strong> and its corresponding class. </p>\n\n<p>From Keras docs: <strong>class_weight</strong>: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). </p>\n",
                        "",
                        "110"
                    ],
                    [
                        "42186",
                        "2",
                        "13490",
                        "",
                        "",
                        "<p>I found the following example of coding up class weights in the loss function using the minist dataset. See link here: <a href=\"https://github.com/keras-team/keras/issues/2115\" rel=\"nofollow noreferrer\">https://github.com/keras-team/keras/issues/2115</a></p>\n\n<pre><code>def w_categorical_crossentropy(y_true, y_pred, weights):\n    nb_cl = len(weights)\n    final_mask = K.zeros_like(y_pred[:, 0])\n    y_pred_max = K.max(y_pred, axis=1)\n    y_pred_max = K.reshape(y_pred_max, (K.shape(y_pred)[0], 1))\n    y_pred_max_mat = K.equal(y_pred, y_pred_max)\n    for c_p, c_t in product(range(nb_cl), range(nb_cl)):\n        final_mask += (weights[c_t, c_p] * y_pred_max_mat[:, c_p] * y_true[:, c_t])\n    return K.categorical_crossentropy(y_pred, y_true) * final_mask\n</code></pre>\n",
                        "",
                        ""
                    ],
                    [
                        "16467",
                        "2",
                        "13490",
                        "",
                        "",
                        "<p>I use this kind of rule for <code>class_weight</code> : </p>\n\n<pre><code>import numpy as np\nimport math\n\n# labels_dict : {ind_label: count_label}\n# mu : parameter to tune \n\ndef create_class_weight(labels_dict,mu=0.15):\n    total = np.sum(labels_dict.values())\n    keys = labels_dict.keys()\n    class_weight = dict()\n\n    for key in keys:\n        score = math.log(mu*total/float(labels_dict[key]))\n        class_weight[key] = score if score &gt; 1.0 else 1.0\n\n    return class_weight\n\n# random labels_dict\nlabels_dict = {0: 2813, 1: 78, 2: 2814, 3: 78, 4: 7914, 5: 248, 6: 7914, 7: 248}\n\ncreate_class_weight(labels_dict)\n</code></pre>\n\n<p><code>math.log</code> smooths the weights for very imbalanced classes !\nThis returns : </p>\n\n<pre><code>{0: 1.0,\n 1: 3.749820767859636,\n 2: 1.0,\n 3: 3.749820767859636,\n 4: 1.0,\n 5: 2.5931008483842453,\n 6: 1.0,\n 7: 2.5931008483842453}\n</code></pre>\n",
                        "",
                        "22"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8429",
            "_score": 6.216078,
            "_source": {
                "title": "Ideal aggregation function for Partially Connected Neural Network (PCNN)",
                "content": "Ideal aggregation function for Partially Connected Neural Network (PCNN) <p>I am building a Python library that creates Partially Connected Neural Networks based on input and output data (X,Y). The basic gist is that the network graph is arbitrarily updated with nodes and edges in the hidden layers.</p>\n\n<p>Example Data:</p>\n\n<pre><code>X = np.array([[0,0],[0,1],[1,0],[1,1]], dtype=np.float)\nY = np.array([[0],[1],[1],[0]], dtype=np.float)\n</code></pre>\n\n<p>Example Graph:\n<a href=\"https://i.stack.imgur.com/hxY8I.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/hxY8I.png\" alt=\"Partially Connected Neural Network\"></a></p>\n\n<p>I am currently using the <i>sum product</i> aggregation function to calculate each layer's values:</p>\n\n<p>$$ \n\\sum_{i=0}^n w_{ij}x_i\n$$</p>\n\n<p>The synapse weights are denoted by two subscripts $ij$. Subscript $i$ represents the previous neuron and subscript $j$ represents the current neuron under consideration. The sum product for current neuron $j$ is computed as:</p>\n\n<p>$$\ns_j = w_{0j}x_0 + w_{1j}x_1 + ... + w_{nj}x_n = \\sum_{i=0}^n w_{ij}x_i\n$$</p>\n\n<p>Is <i>sum product</i> an ideal aggregation function for PCNNs? Dot product won't work as the tensor sizes are almost always incompatible.</p>\n\n<p><strong>Update</strong>: As <code>Bence M\u00e9lyk\u00fati</code> suggested, my solution was to use a weight vector $w$ that is padded with zeros and reshaped for dot product. Here is how I accomplished it in my Python library:</p>\n\n<pre><code>from functools import reduce\nimport numpy as np\nimport math\n\n# An example of some input/sensor data\nX = np.array([[0,0],[0,1],[1,0],[1,1]], dtype=np.float16)\n# From the graph, two inbound synapses in layer 1, here randomly generated\nW = np.random.random((2,))\n\n# Enumerate the element count in each array\nxElements = reduce(lambda x, y: x*y, list(X.shape))\nwElements = reduce(lambda x, y: x*y, list(W.shape))\n\n# If previous layer has more elements than the weights in the current layer\nif xElements &gt; wElements:\n    # Create a list of zeros of shape X.shape\n    A = np.zeros(X.shape).flatten().tolist()\nelse:\n    # Otherwise, create a list with the larger number of elements in W\n    A = np.zeros(W.shape).flatten().tolist()\n\n# If the list is odd, add one element to ensure it is even\n# Done so the array can be reshaped to fit the data and dot product\nif len(A) % 2 != 0:\n    A.extend([np.float16(0.0)])\n\n# Fill the list with the elements from W\nfor ix,ele in enumerate(W):\n    A[ix] = ele\nA = np.array(A)\n\n# Convert list to an array and reshape to be compatible with dot product\nA = A.reshape(X.shape[-1],(math.floor(A.shape[0]/2)))\n\nresult = np.dot(X,A)\n</code></pre>\n\n<p>The result of the dot product looks like:</p>\n\n<pre><code>print(result)\narray([[0.        , 0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        ],\n       [0.45510922, 0.79058734, 0.        , 0.        ],\n       [0.45510922, 0.79058734, 0.        , 0.        ]])\n</code></pre>\n\n<p>Thanks Bence!</p>\n <neural-network><aggregation><p>What you call sum product is the same as a dot product of two vectors of equal length, $(w_{0j},w_{1j},\\dots,w_{nj})$ and $(x_0,x_1,\\dots,x_n)$.</p>\n\n<p>Based on your diagram, your difficulty is that you want to be able to define connections between neurons that are not in consecutive layers (in other words, the connections might skip layers). I assume that there are no directed edges (synapses) that would go in the opposite direction (from layer $n$ to layer $m$ for some $m&lt;n$). In this setting, you have to forward propagate information to layer $n$ from input $X$ and layers $1,2,\\ldots,n-1$. I don't know when and how often you want to 'update' your network topology. Do you want to change it during training?! (Otherwise you'd fix a partially connected NN and you wouldn't write update in your question.)</p>\n\n<p>For forward propagation in a fixed network topology, I would associate to neuron $j$ a vector of weights $(w_{ij})_{i\\in I_j}$, where $I_j$ is the set of neurons that bring information to $j$ (those $i$ where there exists a directed edge from $i$ to $j$). Then you could <strong>either</strong> cherry-pick the neurons $i$ from the set of all neurons (by maintaining a list of indexes to find them in the vector of all neurons) and put them into a vector $x$, which is now as long as $(w_{ij})_{i\\in I_j}$, and you can use <em>dot product</em> on the two vectors. (With <code>numpy</code> for Python, <code>numpy.dot</code> would work.) You would need to do this separately for all $j$ in the given layer. As these are receiving information from differing numbers of inputs and neurons, they indeed cannot be arranged into a matrix/tensor, not even receiving neurons of the same layer.</p>\n\n<p><strong>Or</strong> you could force all potential preceding neurons into one vector. Neuron $j$ of layer $n$ can only receive information from neurons $x=(&lt;$input nodes$&gt;$, $&lt;$neurons of layer $1&gt;$, $\\ldots$, $&lt;$neurons of layer $n-1&gt;)$. This is a vector, and you can define a vector $w$ of equal length for $j$, which would indeed have many zeros, and $x$ and $w$ can be multiplied. For all neurons of layer $n$, you could stack these $w$ as row vectors on top of each other into a matrix/tensor of size (the number of neurons in layer $n$) times (the size of input $+$ the number of neurons in layer $1$ $+\\ldots+$ the number of neurons in layer $n-1$) and use <code>np.dot</code> between this matrix and the $x$.</p>\n\n<p>How to do training (backpropagation) with such topologies is something you have to consider a bit. I suspect it will work without much adjustment compared to a fully connected neural network without layer skipping. In the second option, you would only need to zero out the weights which must be kept zero after each backpropagation update. This indeed carries overhead if you're not careful. But if you maintained a binary ($0$ or $1$) 'mask' matrix of which weights are live (which correspond to existing connections), then you would only ever update these weights in the backpropagation.</p>\n\n<p>Additionally, you may want to introduce a bias term $w_{-1j}$ (also known as intercept term, a constant offset) as if $x$ had an extra dimension that is kept constant $1$. After the aggregation with the sum product, you should also pass the result through a non-linear <a href=\"https://en.wikipedia.org/wiki/Activation_function\" rel=\"nofollow noreferrer\">activation function</a> before entering the value into the neuron in the next layer.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "30849",
                "question_votes:": "",
                "question_text:": "<p>I am building a Python library that creates Partially Connected Neural Networks based on input and output data (X,Y). The basic gist is that the network graph is arbitrarily updated with nodes and edges in the hidden layers.</p>\n\n<p>Example Data:</p>\n\n<pre><code>X = np.array([[0,0],[0,1],[1,0],[1,1]], dtype=np.float)\nY = np.array([[0],[1],[1],[0]], dtype=np.float)\n</code></pre>\n\n<p>Example Graph:\n<a href=\"https://i.stack.imgur.com/hxY8I.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/hxY8I.png\" alt=\"Partially Connected Neural Network\"></a></p>\n\n<p>I am currently using the <i>sum product</i> aggregation function to calculate each layer's values:</p>\n\n<p>$$ \n\\sum_{i=0}^n w_{ij}x_i\n$$</p>\n\n<p>The synapse weights are denoted by two subscripts $ij$. Subscript $i$ represents the previous neuron and subscript $j$ represents the current neuron under consideration. The sum product for current neuron $j$ is computed as:</p>\n\n<p>$$\ns_j = w_{0j}x_0 + w_{1j}x_1 + ... + w_{nj}x_n = \\sum_{i=0}^n w_{ij}x_i\n$$</p>\n\n<p>Is <i>sum product</i> an ideal aggregation function for PCNNs? Dot product won't work as the tensor sizes are almost always incompatible.</p>\n\n<p><strong>Update</strong>: As <code>Bence M\u00e9lyk\u00fati</code> suggested, my solution was to use a weight vector $w$ that is padded with zeros and reshaped for dot product. Here is how I accomplished it in my Python library:</p>\n\n<pre><code>from functools import reduce\nimport numpy as np\nimport math\n\n# An example of some input/sensor data\nX = np.array([[0,0],[0,1],[1,0],[1,1]], dtype=np.float16)\n# From the graph, two inbound synapses in layer 1, here randomly generated\nW = np.random.random((2,))\n\n# Enumerate the element count in each array\nxElements = reduce(lambda x, y: x*y, list(X.shape))\nwElements = reduce(lambda x, y: x*y, list(W.shape))\n\n# If previous layer has more elements than the weights in the current layer\nif xElements &gt; wElements:\n    # Create a list of zeros of shape X.shape\n    A = np.zeros(X.shape).flatten().tolist()\nelse:\n    # Otherwise, create a list with the larger number of elements in W\n    A = np.zeros(W.shape).flatten().tolist()\n\n# If the list is odd, add one element to ensure it is even\n# Done so the array can be reshaped to fit the data and dot product\nif len(A) % 2 != 0:\n    A.extend([np.float16(0.0)])\n\n# Fill the list with the elements from W\nfor ix,ele in enumerate(W):\n    A[ix] = ele\nA = np.array(A)\n\n# Convert list to an array and reshape to be compatible with dot product\nA = A.reshape(X.shape[-1],(math.floor(A.shape[0]/2)))\n\nresult = np.dot(X,A)\n</code></pre>\n\n<p>The result of the dot product looks like:</p>\n\n<pre><code>print(result)\narray([[0.        , 0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        ],\n       [0.45510922, 0.79058734, 0.        , 0.        ],\n       [0.45510922, 0.79058734, 0.        , 0.        ]])\n</code></pre>\n\n<p>Thanks Bence!</p>\n",
                "tags": "<neural-network><aggregation>",
                "answers": [
                    [
                        "30854",
                        "2",
                        "30849",
                        "",
                        "",
                        "<p>What you call sum product is the same as a dot product of two vectors of equal length, $(w_{0j},w_{1j},\\dots,w_{nj})$ and $(x_0,x_1,\\dots,x_n)$.</p>\n\n<p>Based on your diagram, your difficulty is that you want to be able to define connections between neurons that are not in consecutive layers (in other words, the connections might skip layers). I assume that there are no directed edges (synapses) that would go in the opposite direction (from layer $n$ to layer $m$ for some $m&lt;n$). In this setting, you have to forward propagate information to layer $n$ from input $X$ and layers $1,2,\\ldots,n-1$. I don't know when and how often you want to 'update' your network topology. Do you want to change it during training?! (Otherwise you'd fix a partially connected NN and you wouldn't write update in your question.)</p>\n\n<p>For forward propagation in a fixed network topology, I would associate to neuron $j$ a vector of weights $(w_{ij})_{i\\in I_j}$, where $I_j$ is the set of neurons that bring information to $j$ (those $i$ where there exists a directed edge from $i$ to $j$). Then you could <strong>either</strong> cherry-pick the neurons $i$ from the set of all neurons (by maintaining a list of indexes to find them in the vector of all neurons) and put them into a vector $x$, which is now as long as $(w_{ij})_{i\\in I_j}$, and you can use <em>dot product</em> on the two vectors. (With <code>numpy</code> for Python, <code>numpy.dot</code> would work.) You would need to do this separately for all $j$ in the given layer. As these are receiving information from differing numbers of inputs and neurons, they indeed cannot be arranged into a matrix/tensor, not even receiving neurons of the same layer.</p>\n\n<p><strong>Or</strong> you could force all potential preceding neurons into one vector. Neuron $j$ of layer $n$ can only receive information from neurons $x=(&lt;$input nodes$&gt;$, $&lt;$neurons of layer $1&gt;$, $\\ldots$, $&lt;$neurons of layer $n-1&gt;)$. This is a vector, and you can define a vector $w$ of equal length for $j$, which would indeed have many zeros, and $x$ and $w$ can be multiplied. For all neurons of layer $n$, you could stack these $w$ as row vectors on top of each other into a matrix/tensor of size (the number of neurons in layer $n$) times (the size of input $+$ the number of neurons in layer $1$ $+\\ldots+$ the number of neurons in layer $n-1$) and use <code>np.dot</code> between this matrix and the $x$.</p>\n\n<p>How to do training (backpropagation) with such topologies is something you have to consider a bit. I suspect it will work without much adjustment compared to a fully connected neural network without layer skipping. In the second option, you would only need to zero out the weights which must be kept zero after each backpropagation update. This indeed carries overhead if you're not careful. But if you maintained a binary ($0$ or $1$) 'mask' matrix of which weights are live (which correspond to existing connections), then you would only ever update these weights in the backpropagation.</p>\n\n<p>Additionally, you may want to introduce a bias term $w_{-1j}$ (also known as intercept term, a constant offset) as if $x$ had an extra dimension that is kept constant $1$. After the aggregation with the sum product, you should also pass the result through a non-linear <a href=\"https://en.wikipedia.org/wiki/Activation_function\" rel=\"nofollow noreferrer\">activation function</a> before entering the value into the neuron in the next layer.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16166",
            "_score": 6.1650605,
            "_source": {
                "title": "one-hot-encoding categorical data gives error",
                "content": "one-hot-encoding categorical data gives error <p>I am currently working on the Boston problem hosted on Kaggle.  The dataset is nothing like the Titanic dataset.  There are many categorical columns and I'm trying to one-hot-encode these columns.  I've decided to go with the column <code>MSZoning</code> to get the approach working and work out a strategy to apply it to other categorical columns.  This is a small snippet of the dataset:</p>\n\n<p><a href=\"https://i.stack.imgur.com/9zdWq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/9zdWq.png\" alt=\"enter image description here\"></a></p>\n\n<p>Here are the different types of values present in <code>MSZoning</code>, so obviously integer encoding only would be a bad idea:</p>\n\n<p><code>['RL' 'RM' 'C (all)' 'FV' 'RH']</code></p>\n\n<p>Here is my attempt on Python to assign <code>MSZoning</code> with the new one-hot-encoded data.  I do know that one-hot-encoding turns each value into a column of its own and assigns binary values to each of them so I realize that this isn't exactly a good idea.  I wanted to try it anyways:</p>\n\n<pre><code>import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\n\ntrain = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/train.csv\")\ntest = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/train.csv\")\n\nlabelEncoder = LabelEncoder()\n\ntrain['MSZoning'] = labelEncoder.fit_transform(train['MSZoning'])\ntrain_OHE = OneHotEncoder(categorical_features=train['MSZoning'])\ntrain['MSZoning'] = train_OHE.fit_transform(train['MSZoning']).toarray()\n\n\nprint(train['MSZoning'])\n</code></pre>\n\n<p>Which is giving me the following (obvious) error:</p>\n\n<pre><code>C:\\Users\\security\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n  \"use the ColumnTransformer instead.\", DeprecationWarning)\nTraceback (most recent call last):\n  File \"C:/Users/security/Downloads/AP/Boston-Kaggle/Boston.py\", line 11, in &lt;module&gt;\n    train['MSZoning'] = train_OHE.fit_transform(train['MSZoning']).toarray()\n  File \"C:\\Users\\security\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 511, in fit_transform\n    self._handle_deprecations(X)\n  File \"C:\\Users\\security\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 394, in _handle_deprecations\n    n_features = X.shape[1]\nIndexError: tuple index out of range\n</code></pre>\n\n<p>I did read through some Medium posts on this but they didn't exactly relate to what I was trying to do with my dataset as they were working with dummy data with a couple of categorical columns.  What I want to know is, how do I make use of one-hot-encoding after the (attempted) step?  </p>\n <machine-learning><python><scikit-learn><pandas><kaggle><p>Here is an approach using the encoders from sklearn</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\ntrain = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/train.csv\")\ntest = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/test.csv\")\n</code></pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>labelEncoder = LabelEncoder()\nMSZoning_label = labelEncoder.fit_transform(train['MSZoning'])\n</code></pre>\n\n<p>The order mapping of classes and labels from sklearn's LabelEncoder can be seen from its <code>classes_</code> property</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>labelEncoder.classes_\n</code></pre>\n\n<pre><code>array(['C (all)', 'FV', 'RH', 'RL', 'RM'], dtype=object)\n</code></pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>onehotEncoder = OneHotEncoder(n_values=len(labelEncoder.classes_))\nMSZoning_onehot_sparse = onehotEncoder.fit_transform([MSZoning_label])\n</code></pre>\n\n<ul>\n<li>Convert <code>MSZoning_onehot</code> from sparse array to dense array</li>\n<li>Reshape the dense array to be <code>(n_classes,n_examples)</code></li>\n<li>Convert from float to int type</li>\n</ul>\n\n<pre class=\"lang-py prettyprint-override\"><code>MSZoning_onehot = MSZoning_onehot_sparse.toarray().reshape(len(MSZoning_label),-1).astype(int)\n</code></pre>\n\n<p>Pack it back into a data frame if you wan't</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>MSZoning_label_onehot = pd.DataFrame(MSZoning_onehot,columns=labelEncoder.classes_)\nMSZoning_label_onehot.head(10)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/lm66R.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/lm66R.png\" alt=\"enter image description here\"></a></p>\n<p>First of all, I noticed you have loaded the same dataframe for both <code>train</code> and <code>test</code>. Change the code like this:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\n\ntrain = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/train.csv\")\ntest = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/test.csv\")\n</code></pre>\n\n<p>At this point, one-hot encode each variable you want with <code>pandas</code>' <code>get_dummies()</code> function:</p>\n\n<pre><code># Onhe-hot encode a given variable\nOHE_MSZoning = pd.get_dummies(train['MSZoning'])\n</code></pre>\n\n<p>It will be returned as a <code>pandas</code> dataframe. In my Jupyter Notebook it looks like this:</p>\n\n<pre><code>OHE_MSZoning.head()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/tStXh.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/tStXh.png\" alt=\"enter image description here\"></a></p>\n\n<p>You can repeat the same command for all the variables you want to one-hot encode.</p>\n\n<p>Hope this helps, otherwise let me know.</p>\n",
                "codes": [
                    [
                        "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\ntrain = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/train.csv\")\ntest = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/test.csv\")\n",
                        "labelEncoder = LabelEncoder()\nMSZoning_label = labelEncoder.fit_transform(train['MSZoning'])\n",
                        "labelEncoder.classes_\n",
                        "array(['C (all)', 'FV', 'RH', 'RL', 'RM'], dtype=object)\n",
                        "onehotEncoder = OneHotEncoder(n_values=len(labelEncoder.classes_))\nMSZoning_onehot_sparse = onehotEncoder.fit_transform([MSZoning_label])\n",
                        "MSZoning_onehot = MSZoning_onehot_sparse.toarray().reshape(len(MSZoning_label),-1).astype(int)\n",
                        "MSZoning_label_onehot = pd.DataFrame(MSZoning_onehot,columns=labelEncoder.classes_)\nMSZoning_label_onehot.head(10)\n"
                    ],
                    [
                        "import numpy as np\nimport pandas as pd\n\ntrain = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/train.csv\")\ntest = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/test.csv\")\n",
                        "# Onhe-hot encode a given variable\nOHE_MSZoning = pd.get_dummies(train['MSZoning'])\n",
                        "OHE_MSZoning.head()\n"
                    ]
                ],
                "question_id:": "53513",
                "question_votes:": "2",
                "question_text:": "<p>I am currently working on the Boston problem hosted on Kaggle.  The dataset is nothing like the Titanic dataset.  There are many categorical columns and I'm trying to one-hot-encode these columns.  I've decided to go with the column <code>MSZoning</code> to get the approach working and work out a strategy to apply it to other categorical columns.  This is a small snippet of the dataset:</p>\n\n<p><a href=\"https://i.stack.imgur.com/9zdWq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/9zdWq.png\" alt=\"enter image description here\"></a></p>\n\n<p>Here are the different types of values present in <code>MSZoning</code>, so obviously integer encoding only would be a bad idea:</p>\n\n<p><code>['RL' 'RM' 'C (all)' 'FV' 'RH']</code></p>\n\n<p>Here is my attempt on Python to assign <code>MSZoning</code> with the new one-hot-encoded data.  I do know that one-hot-encoding turns each value into a column of its own and assigns binary values to each of them so I realize that this isn't exactly a good idea.  I wanted to try it anyways:</p>\n\n<pre><code>import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\n\ntrain = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/train.csv\")\ntest = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/train.csv\")\n\nlabelEncoder = LabelEncoder()\n\ntrain['MSZoning'] = labelEncoder.fit_transform(train['MSZoning'])\ntrain_OHE = OneHotEncoder(categorical_features=train['MSZoning'])\ntrain['MSZoning'] = train_OHE.fit_transform(train['MSZoning']).toarray()\n\n\nprint(train['MSZoning'])\n</code></pre>\n\n<p>Which is giving me the following (obvious) error:</p>\n\n<pre><code>C:\\Users\\security\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n  \"use the ColumnTransformer instead.\", DeprecationWarning)\nTraceback (most recent call last):\n  File \"C:/Users/security/Downloads/AP/Boston-Kaggle/Boston.py\", line 11, in &lt;module&gt;\n    train['MSZoning'] = train_OHE.fit_transform(train['MSZoning']).toarray()\n  File \"C:\\Users\\security\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 511, in fit_transform\n    self._handle_deprecations(X)\n  File \"C:\\Users\\security\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 394, in _handle_deprecations\n    n_features = X.shape[1]\nIndexError: tuple index out of range\n</code></pre>\n\n<p>I did read through some Medium posts on this but they didn't exactly relate to what I was trying to do with my dataset as they were working with dummy data with a couple of categorical columns.  What I want to know is, how do I make use of one-hot-encoding after the (attempted) step?  </p>\n",
                "tags": "<machine-learning><python><scikit-learn><pandas><kaggle>",
                "answers": [
                    [
                        "53522",
                        "2",
                        "53513",
                        "",
                        "",
                        "<p>Here is an approach using the encoders from sklearn</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\ntrain = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/train.csv\")\ntest = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/test.csv\")\n</code></pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>labelEncoder = LabelEncoder()\nMSZoning_label = labelEncoder.fit_transform(train['MSZoning'])\n</code></pre>\n\n<p>The order mapping of classes and labels from sklearn's LabelEncoder can be seen from its <code>classes_</code> property</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>labelEncoder.classes_\n</code></pre>\n\n<pre><code>array(['C (all)', 'FV', 'RH', 'RL', 'RM'], dtype=object)\n</code></pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>onehotEncoder = OneHotEncoder(n_values=len(labelEncoder.classes_))\nMSZoning_onehot_sparse = onehotEncoder.fit_transform([MSZoning_label])\n</code></pre>\n\n<ul>\n<li>Convert <code>MSZoning_onehot</code> from sparse array to dense array</li>\n<li>Reshape the dense array to be <code>(n_classes,n_examples)</code></li>\n<li>Convert from float to int type</li>\n</ul>\n\n<pre class=\"lang-py prettyprint-override\"><code>MSZoning_onehot = MSZoning_onehot_sparse.toarray().reshape(len(MSZoning_label),-1).astype(int)\n</code></pre>\n\n<p>Pack it back into a data frame if you wan't</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>MSZoning_label_onehot = pd.DataFrame(MSZoning_onehot,columns=labelEncoder.classes_)\nMSZoning_label_onehot.head(10)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/lm66R.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/lm66R.png\" alt=\"enter image description here\"></a></p>\n",
                        "",
                        "3"
                    ],
                    [
                        "53515",
                        "2",
                        "53513",
                        "",
                        "",
                        "<p>First of all, I noticed you have loaded the same dataframe for both <code>train</code> and <code>test</code>. Change the code like this:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\n\ntrain = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/train.csv\")\ntest = pd.read_csv(\"https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/test.csv\")\n</code></pre>\n\n<p>At this point, one-hot encode each variable you want with <code>pandas</code>' <code>get_dummies()</code> function:</p>\n\n<pre><code># Onhe-hot encode a given variable\nOHE_MSZoning = pd.get_dummies(train['MSZoning'])\n</code></pre>\n\n<p>It will be returned as a <code>pandas</code> dataframe. In my Jupyter Notebook it looks like this:</p>\n\n<pre><code>OHE_MSZoning.head()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/tStXh.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/tStXh.png\" alt=\"enter image description here\"></a></p>\n\n<p>You can repeat the same command for all the variables you want to one-hot encode.</p>\n\n<p>Hope this helps, otherwise let me know.</p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8400",
            "_score": 6.118613,
            "_source": {
                "title": "How to Predict the future values of time horizon with Keras?",
                "content": "How to Predict the future values of time horizon with Keras? <p>I just built this <strong>LSTM neural network</strong> with Keras </p>\n\n<pre><code>    import numpy as np\n    import pandas as pd \n    from sklearn import preprocessing\n    from keras.layers.core import Dense, Dropout, Activation\n    from keras.activations import linear\n    from keras.layers.recurrent import LSTM\n    from keras.models import Sequential\n    from matplotlib import pyplot\n\n    #read and prepare data from datafile\n    data_file_name = \"DailyDemand.csv\"\n    data_csv = pd.read_csv(data_file_name, delimiter = ';',header=None, usecols=[1,2,3,4,5])\n    yt = data_csv[1:]\n    data = yt\n    data.columns = ['MoyenneTransactHier', 'MaxTransaction', 'MinTransaction','CountTransaction','Demand']\n    # print (data.head(10))\n    pd.options.display.float_format = '{:,.0f}'.format\n    data = data.dropna ()\n    y=data['Demand'].astype(int)\n    cols=['MoyenneTransactHier', 'MaxTransaction', 'MinTransaction','CountTransaction']\n    x=data[cols].astype(int)\n\n    #scaling data\n    scaler_x = preprocessing.MinMaxScaler(feature_range =(-1, 1))\n    x = np.array(x).reshape ((len(x),4 ))\n    x = scaler_x.fit_transform(x)\n    scaler_y = preprocessing.MinMaxScaler(feature_range =(-1, 1))\n    y = np.array(y).reshape ((len(y), 1))\n    y = scaler_y.fit_transform(y)\n    print(\"longeur de y\",len(y))\n    # Split train and test data\n    train_end = 80\n    x_train=x[0: train_end ,]\n    x_test=x[train_end +1: ,]\n    y_train=y[0: train_end]\n    y_test=y[train_end +1:] \n    x_train=x_train.reshape(x_train.shape +(1,))\n    x_test=x_test.reshape(x_test.shape + (1,))\n\n    print(\"Data well prepared\")\n    print ('x_train shape ', x_train.shape)\n    print ('y_train', y_train.shape)\n\n    #Design the model - LSTM Network\n    seed = 2016\n    np.random.seed(seed)\n    fit1 = Sequential ()\n    fit1.add(LSTM(\n        output_dim = 4,\n        activation='tanh',\n        input_shape =(4, 1)))\n    fit1.add(Dense(output_dim =1))\n    fit1.add(Activation(linear))\n    #rmsprop or sgd\n    batchsize = 1\n    fit1.compile(loss=\"mean_squared_error\",optimizer=\"rmsprop\")\n    #train the model\n    fit1.fit(x_train , y_train , batch_size = batchsize, nb_epoch =20, shuffle=True)\n\n    print(fit1.summary ())\n\n    #Model error\n    score_train = fit1.evaluate(x_train ,y_train ,batch_size =batchsize)\n    score_test = fit1.evaluate(x_test , y_test ,batch_size =batchsize)\n    print(\"in  train  MSE = \",round(score_train,4))\n    print(\"in test  MSE = \",round(score_test ,4))\n\n    #Make prediction\n    pred1=fit1.predict(x_test)\n    pred1 = scaler_y.inverse_transform(np.array(pred1).reshape ((len(pred1), 1)))\n    real_test = scaler_y.inverse_transform(np.array(y_test).reshape ((len(y_test), 1))).astype(int)\n\n    #save prediction\n    testData = pd.DataFrame(real_test)\n    preddData = pd.DataFrame(pred1)\n    dataF = pd.concat([testData,preddData], axis=1)\n    dataF.columns =['Real demand','Predicted Demand']\n    dataF.to_csv('Demandprediction.csv')\n\n    pyplot.plot(pred1, label='Forecast')\n    pyplot.plot(real_test,label='Actual')\n    pyplot.legend()\n    pyplot.show()\n</code></pre>\n\n<p>then it generates this result: \n<a href=\"https://i.stack.imgur.com/la8gj.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/la8gj.png\" alt=\"Prediction on the test data\"></a></p>\n\n<p>After building and training a good model on the historical data, I don't know how I can generate the prediction for future values? For example the demand of the next 10 days. Data are daily.</p>\n\n<p><a href=\"https://i.stack.imgur.com/ZTKMA.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/ZTKMA.png\" alt=\"this is an example of how the data is shaped\"></a></p>\n\n<p>NB: this is an example of how the data is shaped, the green is the label and the yellow one are the features.<br>\nafter <code>dropna()</code> (delete null values) it remains 100 data rows, I've used 80 in the training and the 20 in the test.</p>\n <machine-learning><python><keras><prediction><forecasting>This answer goes a little bit in a different direction, but I hope it still answers your question. It uses the idea of a rolling forecast/prediction.\n\n<p>Because you use the word <em>horizon</em>, I will assume you mean that you would like to predict 10 days into the future at a given time step. There are a few ways of doing this. With this kind of time-series problem, it is common to make the assumption that only a certain history will influence the next few time steps (neglecting seasonal effects). </p>\n\n<h3>Example in words:</h3>\n\n<p>So in your case, you might use e.g. the previous 60 days, and predict the next 10.\nTaking your 100 rows of data as an example, this means you can actually make <code>(100 - 60 - 9) = 31</code> predictions, each prediction of 10 time steps ahead (we will need these 31 <strong>predictive_blocks</strong> later). From 100 rows we lose the first 60 to fit the first model. Of the remaining 40 rows of data, we can predict 10 steps ahead (rows 61-70), then we shift the whole thing one row further and repeat. The last prediction of 10 future points would be for rows 91-100. After that we cannot predict 10 steps anymore, so we stop - and this is why we have to subtract that extra 9. [There are of course ways to continue making prediction, as to use all the data]</p>\n\n<h3>Example with a thousand words:</h3>\n\n<p>Let me paint the picture; to help explain the idea of a shifting window prediction.</p>\n\n<p>For each train set (e.g. from <code>t=0</code> to <code>t=5</code> in red - train set 1), you want to predict the following H time steps (corresponding to t=6 in orange - test set 1). In this, your horizon is simply one i.e. <code>H=1</code>.</p>\n\n<p><a href=\"https://i.stack.imgur.com/Iz3ij.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Iz3ij.png\" alt=\"Basic sketch of a rolling out-of-sample forecast\"></a></p>\n\n<p>From what I understand, you would like to predict the next 10 days, meaning you need <code>H=10</code>.</p>\n\n<p>In order to try this with your example, I think you will need to make two changes.</p>\n\n<h3>Change #1</h3>\n\n<p>The shape of your train and test sets will need to match the new horizon. Each sample of your model input (the <code>x_train</code> and <code>x_test</code> can stay the same as before. However, each sample in your test set will have to contain the next <code>H=10</code> values of the label, not just a single value.</p>\n\n<p>Here is a rough example of how you might do this:</p>\n\n<pre><code># Define our horizon\nH = 10\n\n# Create data split, using values from my example above\nwindow_size = 60\nnum_pred_blocks = 31    # as computed above\n\n# Loop over the train and test samples to create the sliding window sets\nx_train = []\ny_train = []\nfor i in range(num_pred_blocks):\n    x_train_block = x_train[i:(i + window_size)]    # 31 blocks of 60 * num-columns\n    x_train.append(x_train_block)\n    y_train_block = y_train[(i + window_size):(i + window_size + H)]    # 31 blocks of 10 * 1\n    y_train.append(y_train_block)\n</code></pre>\n\n<p>Because you are doing out-of-sample testing, your predictions are already interesting to look analyse. Once this runs, you can then create the equivalent test datasets with the new data you mentioned.</p>\n\n<p>Without knowing your data too well, I don't know if your should be predicting the y-values of the same row as the input, or of the following row. Additionally, depending on your data, you could be including the past values of <code>y</code> in each of the <code>x_train</code> blocks. In this case you'd simply swap <code>x</code> for the whole table i.e. <code>data[cols]</code>, where <code>new_cols = ['Demand'] + cols</code>.</p>\n\n<h3>Change #2</h3>\n\n<p>You will need to make the model reflect this horizon, by forcing it to output <code>H</code> values.</p>\n\n<p>Here is an example of how to specify the model:</p>\n\n<pre><code># Define our horizon\nH = 10\n\n# Create the model using the parameterised horizon\nfit1 = Sequential ()\nfit1.add(LSTM(output_dim = 4, activation='tanh', input_shape =(4, 1)))\nfit1.add(Dense(output_dim=30, activation='sigmoid')\nfit1.add(Dense(output_dim=H))    # our horizon is produced!\n</code></pre>\n\n<p><strong>Note:</strong>\nIn your model specification, you don't need to add the final linear <code>Activation</code>, as the preceding Dense layer by default includes a linear activation. See <a href=\"https://keras.io/layers/core/#dense\" rel=\"nofollow noreferrer\">the excellent documentation here</a>.</p>\n\n<p>This is a big topic and there are many things that you could try out. I agree with the comments on your question, that you will need a lot more data to allow an RNN to make a meaning representation of the model.</p>\n\n<p>If you are not just doing this to learn about LSTMs etc., another practical approach might be to look into simpler time-series models such as an <a href=\"https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average\" rel=\"nofollow noreferrer\">ARIMA model</a> (do not be intimidated by the complicated name - it is much simpler than an LSTM). Such models can be constructed quite easily with Python, using <a href=\"http://www.statsmodels.org/devel/index.html\" rel=\"nofollow noreferrer\">the statsmodels package</a>, which has <a href=\"http://www.statsmodels.org/devel/generated/statsmodels.tsa.arima_model.ARIMA.html#statsmodels.tsa.arima_model.ARIMA\" rel=\"nofollow noreferrer\">a nice implementation</a>.</p>\n",
                "codes": [
                    [
                        "# Define our horizon\nH = 10\n\n# Create data split, using values from my example above\nwindow_size = 60\nnum_pred_blocks = 31    # as computed above\n\n# Loop over the train and test samples to create the sliding window sets\nx_train = []\ny_train = []\nfor i in range(num_pred_blocks):\n    x_train_block = x_train[i:(i + window_size)]    # 31 blocks of 60 * num-columns\n    x_train.append(x_train_block)\n    y_train_block = y_train[(i + window_size):(i + window_size + H)]    # 31 blocks of 10 * 1\n    y_train.append(y_train_block)\n",
                        "# Define our horizon\nH = 10\n\n# Create the model using the parameterised horizon\nfit1 = Sequential ()\nfit1.add(LSTM(output_dim = 4, activation='tanh', input_shape =(4, 1)))\nfit1.add(Dense(output_dim=30, activation='sigmoid')\nfit1.add(Dense(output_dim=H))    # our horizon is produced!\n"
                    ]
                ],
                "question_id:": "30762",
                "question_votes:": "11",
                "question_text:": "<p>I just built this <strong>LSTM neural network</strong> with Keras </p>\n\n<pre><code>    import numpy as np\n    import pandas as pd \n    from sklearn import preprocessing\n    from keras.layers.core import Dense, Dropout, Activation\n    from keras.activations import linear\n    from keras.layers.recurrent import LSTM\n    from keras.models import Sequential\n    from matplotlib import pyplot\n\n    #read and prepare data from datafile\n    data_file_name = \"DailyDemand.csv\"\n    data_csv = pd.read_csv(data_file_name, delimiter = ';',header=None, usecols=[1,2,3,4,5])\n    yt = data_csv[1:]\n    data = yt\n    data.columns = ['MoyenneTransactHier', 'MaxTransaction', 'MinTransaction','CountTransaction','Demand']\n    # print (data.head(10))\n    pd.options.display.float_format = '{:,.0f}'.format\n    data = data.dropna ()\n    y=data['Demand'].astype(int)\n    cols=['MoyenneTransactHier', 'MaxTransaction', 'MinTransaction','CountTransaction']\n    x=data[cols].astype(int)\n\n    #scaling data\n    scaler_x = preprocessing.MinMaxScaler(feature_range =(-1, 1))\n    x = np.array(x).reshape ((len(x),4 ))\n    x = scaler_x.fit_transform(x)\n    scaler_y = preprocessing.MinMaxScaler(feature_range =(-1, 1))\n    y = np.array(y).reshape ((len(y), 1))\n    y = scaler_y.fit_transform(y)\n    print(\"longeur de y\",len(y))\n    # Split train and test data\n    train_end = 80\n    x_train=x[0: train_end ,]\n    x_test=x[train_end +1: ,]\n    y_train=y[0: train_end]\n    y_test=y[train_end +1:] \n    x_train=x_train.reshape(x_train.shape +(1,))\n    x_test=x_test.reshape(x_test.shape + (1,))\n\n    print(\"Data well prepared\")\n    print ('x_train shape ', x_train.shape)\n    print ('y_train', y_train.shape)\n\n    #Design the model - LSTM Network\n    seed = 2016\n    np.random.seed(seed)\n    fit1 = Sequential ()\n    fit1.add(LSTM(\n        output_dim = 4,\n        activation='tanh',\n        input_shape =(4, 1)))\n    fit1.add(Dense(output_dim =1))\n    fit1.add(Activation(linear))\n    #rmsprop or sgd\n    batchsize = 1\n    fit1.compile(loss=\"mean_squared_error\",optimizer=\"rmsprop\")\n    #train the model\n    fit1.fit(x_train , y_train , batch_size = batchsize, nb_epoch =20, shuffle=True)\n\n    print(fit1.summary ())\n\n    #Model error\n    score_train = fit1.evaluate(x_train ,y_train ,batch_size =batchsize)\n    score_test = fit1.evaluate(x_test , y_test ,batch_size =batchsize)\n    print(\"in  train  MSE = \",round(score_train,4))\n    print(\"in test  MSE = \",round(score_test ,4))\n\n    #Make prediction\n    pred1=fit1.predict(x_test)\n    pred1 = scaler_y.inverse_transform(np.array(pred1).reshape ((len(pred1), 1)))\n    real_test = scaler_y.inverse_transform(np.array(y_test).reshape ((len(y_test), 1))).astype(int)\n\n    #save prediction\n    testData = pd.DataFrame(real_test)\n    preddData = pd.DataFrame(pred1)\n    dataF = pd.concat([testData,preddData], axis=1)\n    dataF.columns =['Real demand','Predicted Demand']\n    dataF.to_csv('Demandprediction.csv')\n\n    pyplot.plot(pred1, label='Forecast')\n    pyplot.plot(real_test,label='Actual')\n    pyplot.legend()\n    pyplot.show()\n</code></pre>\n\n<p>then it generates this result: \n<a href=\"https://i.stack.imgur.com/la8gj.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/la8gj.png\" alt=\"Prediction on the test data\"></a></p>\n\n<p>After building and training a good model on the historical data, I don't know how I can generate the prediction for future values? For example the demand of the next 10 days. Data are daily.</p>\n\n<p><a href=\"https://i.stack.imgur.com/ZTKMA.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/ZTKMA.png\" alt=\"this is an example of how the data is shaped\"></a></p>\n\n<p>NB: this is an example of how the data is shaped, the green is the label and the yellow one are the features.<br>\nafter <code>dropna()</code> (delete null values) it remains 100 data rows, I've used 80 in the training and the 20 in the test.</p>\n",
                "tags": "<machine-learning><python><keras><prediction><forecasting>",
                "answers": [
                    [
                        "30908",
                        "2",
                        "30762",
                        "",
                        "",
                        "This answer goes a little bit in a different direction, but I hope it still answers your question. It uses the idea of a rolling forecast/prediction.\n\n<p>Because you use the word <em>horizon</em>, I will assume you mean that you would like to predict 10 days into the future at a given time step. There are a few ways of doing this. With this kind of time-series problem, it is common to make the assumption that only a certain history will influence the next few time steps (neglecting seasonal effects). </p>\n\n<h3>Example in words:</h3>\n\n<p>So in your case, you might use e.g. the previous 60 days, and predict the next 10.\nTaking your 100 rows of data as an example, this means you can actually make <code>(100 - 60 - 9) = 31</code> predictions, each prediction of 10 time steps ahead (we will need these 31 <strong>predictive_blocks</strong> later). From 100 rows we lose the first 60 to fit the first model. Of the remaining 40 rows of data, we can predict 10 steps ahead (rows 61-70), then we shift the whole thing one row further and repeat. The last prediction of 10 future points would be for rows 91-100. After that we cannot predict 10 steps anymore, so we stop - and this is why we have to subtract that extra 9. [There are of course ways to continue making prediction, as to use all the data]</p>\n\n<h3>Example with a thousand words:</h3>\n\n<p>Let me paint the picture; to help explain the idea of a shifting window prediction.</p>\n\n<p>For each train set (e.g. from <code>t=0</code> to <code>t=5</code> in red - train set 1), you want to predict the following H time steps (corresponding to t=6 in orange - test set 1). In this, your horizon is simply one i.e. <code>H=1</code>.</p>\n\n<p><a href=\"https://i.stack.imgur.com/Iz3ij.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Iz3ij.png\" alt=\"Basic sketch of a rolling out-of-sample forecast\"></a></p>\n\n<p>From what I understand, you would like to predict the next 10 days, meaning you need <code>H=10</code>.</p>\n\n<p>In order to try this with your example, I think you will need to make two changes.</p>\n\n<h3>Change #1</h3>\n\n<p>The shape of your train and test sets will need to match the new horizon. Each sample of your model input (the <code>x_train</code> and <code>x_test</code> can stay the same as before. However, each sample in your test set will have to contain the next <code>H=10</code> values of the label, not just a single value.</p>\n\n<p>Here is a rough example of how you might do this:</p>\n\n<pre><code># Define our horizon\nH = 10\n\n# Create data split, using values from my example above\nwindow_size = 60\nnum_pred_blocks = 31    # as computed above\n\n# Loop over the train and test samples to create the sliding window sets\nx_train = []\ny_train = []\nfor i in range(num_pred_blocks):\n    x_train_block = x_train[i:(i + window_size)]    # 31 blocks of 60 * num-columns\n    x_train.append(x_train_block)\n    y_train_block = y_train[(i + window_size):(i + window_size + H)]    # 31 blocks of 10 * 1\n    y_train.append(y_train_block)\n</code></pre>\n\n<p>Because you are doing out-of-sample testing, your predictions are already interesting to look analyse. Once this runs, you can then create the equivalent test datasets with the new data you mentioned.</p>\n\n<p>Without knowing your data too well, I don't know if your should be predicting the y-values of the same row as the input, or of the following row. Additionally, depending on your data, you could be including the past values of <code>y</code> in each of the <code>x_train</code> blocks. In this case you'd simply swap <code>x</code> for the whole table i.e. <code>data[cols]</code>, where <code>new_cols = ['Demand'] + cols</code>.</p>\n\n<h3>Change #2</h3>\n\n<p>You will need to make the model reflect this horizon, by forcing it to output <code>H</code> values.</p>\n\n<p>Here is an example of how to specify the model:</p>\n\n<pre><code># Define our horizon\nH = 10\n\n# Create the model using the parameterised horizon\nfit1 = Sequential ()\nfit1.add(LSTM(output_dim = 4, activation='tanh', input_shape =(4, 1)))\nfit1.add(Dense(output_dim=30, activation='sigmoid')\nfit1.add(Dense(output_dim=H))    # our horizon is produced!\n</code></pre>\n\n<p><strong>Note:</strong>\nIn your model specification, you don't need to add the final linear <code>Activation</code>, as the preceding Dense layer by default includes a linear activation. See <a href=\"https://keras.io/layers/core/#dense\" rel=\"nofollow noreferrer\">the excellent documentation here</a>.</p>\n\n<p>This is a big topic and there are many things that you could try out. I agree with the comments on your question, that you will need a lot more data to allow an RNN to make a meaning representation of the model.</p>\n\n<p>If you are not just doing this to learn about LSTMs etc., another practical approach might be to look into simpler time-series models such as an <a href=\"https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average\" rel=\"nofollow noreferrer\">ARIMA model</a> (do not be intimidated by the complicated name - it is much simpler than an LSTM). Such models can be constructed quite easily with Python, using <a href=\"http://www.statsmodels.org/devel/index.html\" rel=\"nofollow noreferrer\">the statsmodels package</a>, which has <a href=\"http://www.statsmodels.org/devel/generated/statsmodels.tsa.arima_model.ARIMA.html#statsmodels.tsa.arima_model.ARIMA\" rel=\"nofollow noreferrer\">a nice implementation</a>.</p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10240",
            "_score": 6.105115,
            "_source": {
                "title": "Invalid Argument Error when running simple Convolutional Neural Network",
                "content": "Invalid Argument Error when running simple Convolutional Neural Network <p>I am running a convolutional neural network with CSV files as training and test input. I am getting a strange error that I cannot solve.</p>\n\n<pre><code>    Traceback (most recent call last):\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1350, in _do_call\n    return fn(*args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1320, in _run_fn\n    self._extend_graph()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1381, in _extend_graph\n    self._session, graph_def.SerializeToString(), status)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\n    c_api.TF_GetCode(self.status.status))\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'Switch' with these attrs.  Registered devices: [CPU], Registered kernels:\n  device='CPU'; T in [DT_BOOL]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_INT32]\n  device='GPU'; T in [DT_STRING]\n  device='GPU'; T in [DT_BOOL]\n  device='GPU'; T in [DT_INT32]\n  device='GPU'; T in [DT_FLOAT]\n\n     [[Node: remove_squeezable_dimensions/cond/Switch_1 = Switch[T=DT_INT64, _class=[\"loc:@ArgMax\"]](ArgMax, remove_squeezable_dimensions/cond/pred_id)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/pi/Desktop/CNN.py\", line 151, in &lt;module&gt;\n    sess.run(init)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 895, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1128, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1344, in _do_run\n    options, run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1363, in _do_call\n    raise type(e)(node_def, op, message)\n</code></pre>\n\n<p>I am running Tensorflow 1.5 on a RaspberryPi 3. Here is the neural network below.</p>\n\n<pre><code>    import tensorflow as tf\nimport numpy as np\nimport csv\nimport pandas as pd\nimport os\n\nimage_height = 60\nimage_width = 1\n\nimage1_height = 15\nimage2_height = 1\n\nmodel_name = \"TensorflowCNN\"\n\n\n#Training Data Configuration\n\ntrain_data = np.asarray(pd.read_csv(\"/media/pi/DISK_IMG/TrainingInput.csv\", usecols=[1]))\nlis = train_data.tolist()\nlis = lis[0:60]\nlis = [x[0].strip('[]\\n,') for x in lis]\nnlis = []\nfor i in lis:\n    nlis.append(i.split())\nfor i in range(len(nlis)):\n    nlis[i] = [float(x) for x in nlis[i] if x != \"...,\"]\nnlis = [np.mean(x) for x in nlis]\ntrain_data = np.asarray(nlis)\n\n#Training Labels Configuration\n\ntrain_labels = np.asarray(pd.read_csv(\"/media/pi/DISK_IMG/TrainingInput.csv\", usecols=[2]))\nmylist = train_labels.tolist()\nmylist = mylist[0:60]\nmylist = [x[0] for x in mylist]\nindex = 0\nwhile index &lt; len(mylist):\n    if mylist[index] == \"GravelTraining\":\n        mylist[index] = 1\n    elif mylist[index] == \"WaterTraining\":\n        mylist[index] = 2\n    else:\n        mylist[index] = 3\n\n    index=index+1\n\ntrain_labels = np.asarray(mylist)\n\n#Validation Data Configuration\n\neval_data = np.asarray(pd.read_csv(\"/media/pi/DISK_IMG/TestingInput.csv\", usecols=[1]))\nList = eval_data.tolist()\nList = List[0:15]\neval_data = np.asarray(List)\n\n#Validation Labels Configuration\n\neval_labels = np.asarray(pd.read_csv(\"/media/pi/DISK_IMG/TestingInput.csv\", usecols=[2]))\nmyList = eval_labels.tolist()\nmyList = myList[0:15]\nindex = 0\nwhile index &lt; len(myList):\n    if myList[index] == \"GravelTesting\":\n        myList[index] = 1\n    elif myList[index] == \"WaterTesting\":\n        myList[index] = 2\n    else:\n        myList[index] = 3\n\n    index=index+1\neval_labels = np.asarray(myList)\n\ncategory_names = list(map(str, range(3)))\n\n#Processing and reshaping data\n\ntrain_data = np.reshape(train_data, (-1, image_height, image_width, 1))\ntrain_labels = np.reshape(train_labels, (-1, image_height, image_width, 1))\n\neval_data = np.reshape(eval_data, (-1, image1_height, image2_height, 1))\neval_labels = np.reshape(eval_labels, (-1, image1_height, image2_height, 1))\n\n\n#CLASS FOR THE CONVOLUTIONAL NEURAL NETWORK\n\n\nclass ConvNet:\n\n    def __init__(self, image_height, Image_width, num_classes, chan):\n\n        self.input_layer = tf.placeholder(dtype = tf.float32, shape = [1,image_height, Image_width, chan], name = \"inputs\")\n\n        conv_layer_1 = tf.layers.conv2d(self.input_layer, filters = 32, kernel_size = [5,5], padding = \"same\", activation = tf.nn.relu)\n        pooling_layer_1 = tf.layers.max_pooling2d(conv_layer_1, pool_size = [2,1], strides = 1)\n\n        flattened_pooling = tf.layers.flatten(pooling_layer_1)\n        dense_layer = tf.layers.dense(flattened_pooling, 60, activation = tf.nn.relu)\n\n        dropout = tf.layers.dropout(dense_layer, rate = 0.4, training = True)\n\n        output_dense_layer = tf.layers.dense(dropout, num_classes)\n\n        self.choice = tf.argmax(output_dense_layer, axis=1)\n        self.probabilities = tf.nn.softmax(output_dense_layer)\n\n        self.labels = tf.placeholder(dtype=tf.float32, name=\"labels\")\n        self.accuracy, self.accuracy_op = tf.metrics.accuracy(self.labels, self.choice)\n\n        one_hot_labels = tf.one_hot(indices=tf.cast(self.labels, dtype=tf.int32), depth=num_classes)\n        self.loss = tf.losses.softmax_cross_entropy(onehot_labels = one_hot_labels, logits=output_dense_layer)\n\n        optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-2)\n        self.train_operation = optimizer.minimize(loss=self.loss, global_step=tf.train.get_global_step())\n\n#Training process:variables\n\ntraining_steps = 20000\nbatch_size = 60\n\npath = \"./\" + model_name + \"-cnn/\"\n\nload_checkpoint = False\n\ntf.reset_default_graph()\ndataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\ndataset = dataset.shuffle(buffer_size=train_labels.shape[0])\ndataset = dataset.batch(batch_size)\ndataset = dataset.repeat()\n\ndataset_iterator = dataset.make_initializable_iterator()\nnext_element = dataset_iterator.get_next()\n\n#Final initialization of Neural Network and Training Process\n\ncnn = ConvNet(image_height, image_width, 3, 1)\nprint(\"milestone1\")\n\nsaver = tf.train.Saver(max_to_keep=2)\nprint('milestone2')\n\nif not os.path.exists(path):\n    os.makedirs(path)\nprint('milestone3')\n\n#Training Loop For neural network\n\nwith tf.Session() as sess:\n\n    sess.run(tf.global_variables_initializer())\n    print('milestone4')\n\n    sess.run(tf.local_variables_initializer())\n    sess.run(dataset_iterator.initializer)\n\n    for step in range(training_steps):\n\n        current_batch = sess.run(next_element)\n        batch_inputs = current_batch[0]\n        batch_labels = current_batch[1]\n        print(\"milestone5\")\n        sess.run((cnn.train_operation, cnn.accuracy_op), feed_dict={cnn.input_layer:batch_inputs, cnn.labels:batch_labels})\n\n        if step % 1 == 0 and step &gt; 0:\n            current_acc = sess.run(cnn.accuracy)\n            print(\"Accuracy at step \" + str(step) + \":\" + str(current_acc))\n            saver.save(sess, path + model_name, step)\n\n    print(\"Saving final checkpoint for training session.\")\n    saver.save(sess, path + model_name, step)\n</code></pre>\n\n<p>I would appreciate it if someone could point me in the right direction.</p>\n\n<p>_________________________________UPDATE___________________________________</p>\n\n<p>Based on an answer given earlier to this question, I updated my version of tensorflow. I now get this error:</p>\n\n<pre><code>2018-08-15 17:16:42.551134: F ./tensorflow/core/util/bcast.h:111] Check failed: vec.size() == NDIMS (1 vs. 2)\n</code></pre>\n\n<p>Aborted</p>\n\n<p>How should I fix this?</p>\n <tensorflow><python><p>From the error message you gave, it seems like it happens because of your hardware than your code.<br>\nNow Tensorflow officially supports for Raspberry Pi 3 since the version 1.8,\nso you may want to consider the higher version of TF for Raspberry Pi porting.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "36979",
                "question_votes:": "",
                "question_text:": "<p>I am running a convolutional neural network with CSV files as training and test input. I am getting a strange error that I cannot solve.</p>\n\n<pre><code>    Traceback (most recent call last):\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1350, in _do_call\n    return fn(*args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1320, in _run_fn\n    self._extend_graph()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1381, in _extend_graph\n    self._session, graph_def.SerializeToString(), status)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\n    c_api.TF_GetCode(self.status.status))\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'Switch' with these attrs.  Registered devices: [CPU], Registered kernels:\n  device='CPU'; T in [DT_BOOL]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_INT32]\n  device='GPU'; T in [DT_STRING]\n  device='GPU'; T in [DT_BOOL]\n  device='GPU'; T in [DT_INT32]\n  device='GPU'; T in [DT_FLOAT]\n\n     [[Node: remove_squeezable_dimensions/cond/Switch_1 = Switch[T=DT_INT64, _class=[\"loc:@ArgMax\"]](ArgMax, remove_squeezable_dimensions/cond/pred_id)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/pi/Desktop/CNN.py\", line 151, in &lt;module&gt;\n    sess.run(init)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 895, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1128, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1344, in _do_run\n    options, run_metadata)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1363, in _do_call\n    raise type(e)(node_def, op, message)\n</code></pre>\n\n<p>I am running Tensorflow 1.5 on a RaspberryPi 3. Here is the neural network below.</p>\n\n<pre><code>    import tensorflow as tf\nimport numpy as np\nimport csv\nimport pandas as pd\nimport os\n\nimage_height = 60\nimage_width = 1\n\nimage1_height = 15\nimage2_height = 1\n\nmodel_name = \"TensorflowCNN\"\n\n\n#Training Data Configuration\n\ntrain_data = np.asarray(pd.read_csv(\"/media/pi/DISK_IMG/TrainingInput.csv\", usecols=[1]))\nlis = train_data.tolist()\nlis = lis[0:60]\nlis = [x[0].strip('[]\\n,') for x in lis]\nnlis = []\nfor i in lis:\n    nlis.append(i.split())\nfor i in range(len(nlis)):\n    nlis[i] = [float(x) for x in nlis[i] if x != \"...,\"]\nnlis = [np.mean(x) for x in nlis]\ntrain_data = np.asarray(nlis)\n\n#Training Labels Configuration\n\ntrain_labels = np.asarray(pd.read_csv(\"/media/pi/DISK_IMG/TrainingInput.csv\", usecols=[2]))\nmylist = train_labels.tolist()\nmylist = mylist[0:60]\nmylist = [x[0] for x in mylist]\nindex = 0\nwhile index &lt; len(mylist):\n    if mylist[index] == \"GravelTraining\":\n        mylist[index] = 1\n    elif mylist[index] == \"WaterTraining\":\n        mylist[index] = 2\n    else:\n        mylist[index] = 3\n\n    index=index+1\n\ntrain_labels = np.asarray(mylist)\n\n#Validation Data Configuration\n\neval_data = np.asarray(pd.read_csv(\"/media/pi/DISK_IMG/TestingInput.csv\", usecols=[1]))\nList = eval_data.tolist()\nList = List[0:15]\neval_data = np.asarray(List)\n\n#Validation Labels Configuration\n\neval_labels = np.asarray(pd.read_csv(\"/media/pi/DISK_IMG/TestingInput.csv\", usecols=[2]))\nmyList = eval_labels.tolist()\nmyList = myList[0:15]\nindex = 0\nwhile index &lt; len(myList):\n    if myList[index] == \"GravelTesting\":\n        myList[index] = 1\n    elif myList[index] == \"WaterTesting\":\n        myList[index] = 2\n    else:\n        myList[index] = 3\n\n    index=index+1\neval_labels = np.asarray(myList)\n\ncategory_names = list(map(str, range(3)))\n\n#Processing and reshaping data\n\ntrain_data = np.reshape(train_data, (-1, image_height, image_width, 1))\ntrain_labels = np.reshape(train_labels, (-1, image_height, image_width, 1))\n\neval_data = np.reshape(eval_data, (-1, image1_height, image2_height, 1))\neval_labels = np.reshape(eval_labels, (-1, image1_height, image2_height, 1))\n\n\n#CLASS FOR THE CONVOLUTIONAL NEURAL NETWORK\n\n\nclass ConvNet:\n\n    def __init__(self, image_height, Image_width, num_classes, chan):\n\n        self.input_layer = tf.placeholder(dtype = tf.float32, shape = [1,image_height, Image_width, chan], name = \"inputs\")\n\n        conv_layer_1 = tf.layers.conv2d(self.input_layer, filters = 32, kernel_size = [5,5], padding = \"same\", activation = tf.nn.relu)\n        pooling_layer_1 = tf.layers.max_pooling2d(conv_layer_1, pool_size = [2,1], strides = 1)\n\n        flattened_pooling = tf.layers.flatten(pooling_layer_1)\n        dense_layer = tf.layers.dense(flattened_pooling, 60, activation = tf.nn.relu)\n\n        dropout = tf.layers.dropout(dense_layer, rate = 0.4, training = True)\n\n        output_dense_layer = tf.layers.dense(dropout, num_classes)\n\n        self.choice = tf.argmax(output_dense_layer, axis=1)\n        self.probabilities = tf.nn.softmax(output_dense_layer)\n\n        self.labels = tf.placeholder(dtype=tf.float32, name=\"labels\")\n        self.accuracy, self.accuracy_op = tf.metrics.accuracy(self.labels, self.choice)\n\n        one_hot_labels = tf.one_hot(indices=tf.cast(self.labels, dtype=tf.int32), depth=num_classes)\n        self.loss = tf.losses.softmax_cross_entropy(onehot_labels = one_hot_labels, logits=output_dense_layer)\n\n        optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-2)\n        self.train_operation = optimizer.minimize(loss=self.loss, global_step=tf.train.get_global_step())\n\n#Training process:variables\n\ntraining_steps = 20000\nbatch_size = 60\n\npath = \"./\" + model_name + \"-cnn/\"\n\nload_checkpoint = False\n\ntf.reset_default_graph()\ndataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\ndataset = dataset.shuffle(buffer_size=train_labels.shape[0])\ndataset = dataset.batch(batch_size)\ndataset = dataset.repeat()\n\ndataset_iterator = dataset.make_initializable_iterator()\nnext_element = dataset_iterator.get_next()\n\n#Final initialization of Neural Network and Training Process\n\ncnn = ConvNet(image_height, image_width, 3, 1)\nprint(\"milestone1\")\n\nsaver = tf.train.Saver(max_to_keep=2)\nprint('milestone2')\n\nif not os.path.exists(path):\n    os.makedirs(path)\nprint('milestone3')\n\n#Training Loop For neural network\n\nwith tf.Session() as sess:\n\n    sess.run(tf.global_variables_initializer())\n    print('milestone4')\n\n    sess.run(tf.local_variables_initializer())\n    sess.run(dataset_iterator.initializer)\n\n    for step in range(training_steps):\n\n        current_batch = sess.run(next_element)\n        batch_inputs = current_batch[0]\n        batch_labels = current_batch[1]\n        print(\"milestone5\")\n        sess.run((cnn.train_operation, cnn.accuracy_op), feed_dict={cnn.input_layer:batch_inputs, cnn.labels:batch_labels})\n\n        if step % 1 == 0 and step &gt; 0:\n            current_acc = sess.run(cnn.accuracy)\n            print(\"Accuracy at step \" + str(step) + \":\" + str(current_acc))\n            saver.save(sess, path + model_name, step)\n\n    print(\"Saving final checkpoint for training session.\")\n    saver.save(sess, path + model_name, step)\n</code></pre>\n\n<p>I would appreciate it if someone could point me in the right direction.</p>\n\n<p>_________________________________UPDATE___________________________________</p>\n\n<p>Based on an answer given earlier to this question, I updated my version of tensorflow. I now get this error:</p>\n\n<pre><code>2018-08-15 17:16:42.551134: F ./tensorflow/core/util/bcast.h:111] Check failed: vec.size() == NDIMS (1 vs. 2)\n</code></pre>\n\n<p>Aborted</p>\n\n<p>How should I fix this?</p>\n",
                "tags": "<tensorflow><python>",
                "answers": [
                    [
                        "36980",
                        "2",
                        "36979",
                        "",
                        "",
                        "<p>From the error message you gave, it seems like it happens because of your hardware than your code.<br>\nNow Tensorflow officially supports for Raspberry Pi 3 since the version 1.8,\nso you may want to consider the higher version of TF for Raspberry Pi porting.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15516",
            "_score": 6.105115,
            "_source": {
                "title": "How to download BAIR action free robot pushing dataset?",
                "content": "How to download BAIR action free robot pushing dataset? <p>I'm trying to download <code>BAIR action free robot pushing dataset</code>. I tried downloading from <a href=\"https://sites.google.com/view/sna-visual-mpc\" rel=\"nofollow noreferrer\">here</a>. In browser, it shows its size is 30GB, but downloads some data and then fails. I tried multiple attempts with no success. Then I tried to download using <code>wget</code></p>\n\n<pre><code>wget http://rail.eecs.berkeley.edu/datasets/bair_robot_pushing_dataset_v0.tar\n</code></pre>\n\n<p>Even with this, it shows total size is 30GB, but after downloading some 199MB, it ended saying download is complete</p>\n\n<pre><code>wget http://rail.eecs.berkeley.edu/datasets/bair_robot_pushing_dataset_v0.tar\n--2019-05-16 12:30:50--  http://rail.eecs.berkeley.edu/datasets/bair_robot_pushing_dataset_v0.tar\nResolving rail.eecs.berkeley.edu (rail.eecs.berkeley.edu)... 128.32.189.73\nConnecting to rail.eecs.berkeley.edu (rail.eecs.berkeley.edu)|128.32.189.73|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 32274964480 (30G) [application/x-tar]\nSaving to: \u2018bair_robot_pushing_dataset_v0.tar\u2019\n\nbair_robot_pushing_dataset_v0.tar                    0%[                                                                                                                 ] 189.95M   456KB/s    in 10m 59s \n\n2019-05-16 12:41:50 (295 KB/s) - Connection closed at byte 199172826. Retrying.\n\n--2019-05-16 12:41:51--  (try: 2)  http://rail.eecs.berkeley.edu/datasets/bair_robot_pushing_dataset_v0.tar\nConnecting to rail.eecs.berkeley.edu (rail.eecs.berkeley.edu)|128.32.189.73|:80... connected.\nHTTP request sent, awaiting response... 416 Requested range not satisfiable\n\n    The file is already fully retrieved; nothing to do.\n</code></pre>\n\n<p>Also, I found a script that downloads BAIR dataset <a href=\"https://github.com/alexlee-gk/video_prediction/blob/master/data/download_and_preprocess_dataset.sh\" rel=\"nofollow noreferrer\">here</a>. But I encountered the same problem here as well.</p>\n\n<p>I'm confused now. Is the dataset so small or am I doing something wrong?</p>\n <dataset><p>BAIR dataset can be downloaded here\n<a href=\"https://sites.google.com/berkeley.edu/robotic-interaction-datasets\" rel=\"nofollow noreferrer\">https://sites.google.com/berkeley.edu/robotic-interaction-datasets</a></p>\n\n<p>Additionally, here is the code to extract data from the dataset</p>\n\n<pre><code>import datetime\nimport os\nimport time\n\nimport cv2\nimport numpy as np\nimport skvideo.io\nimport tensorflow as tf\nfrom PIL import Image\nfrom tensorflow.python.platform import gfile\n\ndef get_next_video_data(data_dir):\n    filenames = gfile.Glob(os.path.join(data_dir, '*'))\n    if not filenames:\n        raise RuntimeError('No data files found.')\n\n    for f in filenames:\n        k = 0\n        for serialized_example in tf.python_io.tf_record_iterator(f):\n            example = tf.train.Example()\n            example.ParseFromString(serialized_example)\n            # print(example)        # To know what all features are present\n\n            actions = np.empty((0, 4), dtype='float')\n            endeffector_positions = np.empty((0, 3), dtype='float')\n            frames_aux1 = []\n            frames_main = []\n            i = 0\n            while True:\n                action_name = str(i) + '/action'\n                action_value = np.array(example.features.feature[action_name].float_list.value)\n                if action_value.shape == (0,):      # End of frames/data\n                    break\n                actions = np.vstack((actions, action_value))\n\n                endeffector_pos_name = str(i) + '/endeffector_pos'\n                endeffector_pos_value = list(example.features.feature[endeffector_pos_name].float_list.value)\n                endeffector_positions = np.vstack((endeffector_positions, endeffector_pos_value))\n\n                aux1_image_name = str(i) + '/image_aux1/encoded'\n                aux1_byte_str = example.features.feature[aux1_image_name].bytes_list.value[0]\n                aux1_img = Image.frombytes('RGB', (64, 64), aux1_byte_str)\n                aux1_arr = np.array(aux1_img.getdata()).reshape((aux1_img.size[1], aux1_img.size[0], 3))\n                frames_aux1.append(aux1_arr.reshape(1, 64, 64, 3))\n\n                main_image_name = str(i) + '/image_main/encoded'\n                main_byte_str = example.features.feature[main_image_name].bytes_list.value[0]\n                main_img = Image.frombytes('RGB', (64, 64), main_byte_str)\n                main_arr = np.array(main_img.getdata()).reshape((main_img.size[1], main_img.size[0], 3))\n                frames_main.append(main_arr.reshape(1, 64, 64, 3))\n                i += 1\n\n            np_frames_aux1 = np.concatenate(frames_aux1, axis=0)\n            np_frames_main = np.concatenate(frames_main, axis=0)\n            yield f, k, actions, endeffector_positions, np_frames_aux1, np_frames_main\n            k = k + 1\n\n\ndef extract_data(data_dir, output_dir, frame_rate):\n    \"\"\"\n    Extracts data in tfrecord format to gifs, frames and text files\n    :param data_dir:\n    :param output_dir:\n    :param frame_rate:\n    :return:\n    \"\"\"\n    if os.path.exists(output_dir):\n        if os.listdir(output_dir):\n            raise RuntimeError('Directory not empty: {0}'.format(output_dir))\n    else:\n        os.makedirs(output_dir)\n\n    seq_generator = get_next_video_data(data_dir)\n    while True:\n        try:\n            _, k, actions, endeff_pos, aux1_frames, main_frames = next(seq_generator)\n        except StopIteration:\n            break\n        video_out_dir = os.path.join(output_dir, '{0:03}'.format(k))\n        os.makedirs(video_out_dir)\n\n        # noinspection PyTypeChecker\n        np.savetxt(os.path.join(video_out_dir, 'actions.csv'), actions, delimiter=',')\n        # noinspection PyTypeChecker\n        np.savetxt(os.path.join(video_out_dir, 'endeffector_positions.csv'), endeff_pos, delimiter=',')\n        skvideo.io.vwrite(os.path.join(video_out_dir, 'aux1.gif'), aux1_frames, inputdict={'-r': str(frame_rate)})\n        skvideo.io.vwrite(os.path.join(video_out_dir, 'main.gif'), main_frames, inputdict={'-r': str(frame_rate)})\n        skvideo.io.vwrite(os.path.join(video_out_dir, 'aux1.mp4'), aux1_frames, inputdict={'-r': str(frame_rate)})\n        skvideo.io.vwrite(os.path.join(video_out_dir, 'main.mp4'), main_frames, inputdict={'-r': str(frame_rate)})\n\n        # Save frames\n        aux1_folder_path = os.path.join(video_out_dir, 'aux1_frames')\n        os.makedirs(aux1_folder_path)\n        for i, frame in enumerate(aux1_frames):\n            filepath = os.path.join(aux1_folder_path, 'frame_{0:03}.bmp'.format(i))\n            cv2.imwrite(filepath, cv2.cvtColor(frame.astype('uint8'), cv2.COLOR_RGB2BGR))\n        main_folder_path = os.path.join(video_out_dir, 'main_frames')\n        os.makedirs(main_folder_path)\n        for i, frame in enumerate(main_frames):\n            filepath = os.path.join(main_folder_path, 'frame_{0:03}.bmp'.format(i))\n            cv2.imwrite(filepath, cv2.cvtColor(frame.astype('uint8'), cv2.COLOR_RGB2BGR))\n        print('Saved video: {0:03}'.format(k))\n\n\ndef main():\n    data_dir = '../softmotion30_44k/test'\n    output_dir = '../ExtractedData/test'\n    frame_rate = 4\n    extract_data(data_dir, output_dir, frame_rate)\n    return\n\n\nif __name__ == '__main__':\n    print('Program started at ' + datetime.datetime.now().strftime('%d/%m/%Y %I:%M:%S %p'))\n    start_time = time.time()\n    main()\n    end_time = time.time()\n    print('Program ended at ' + datetime.datetime.now().strftime('%d/%m/%Y %I:%M:%S %p'))\n    print('Execution time: ' + str(datetime.timedelta(seconds=end_time - start_time)))\n</code></pre>\n\n<p><strong>References</strong>:\n<a href=\"https://github.com/edenton/svg/blob/master/data/convert_bair.py\" rel=\"nofollow noreferrer\">https://github.com/edenton/svg/blob/master/data/convert_bair.py</a></p>\n",
                "codes": [
                    [
                        "import datetime\nimport os\nimport time\n\nimport cv2\nimport numpy as np\nimport skvideo.io\nimport tensorflow as tf\nfrom PIL import Image\nfrom tensorflow.python.platform import gfile\n\ndef get_next_video_data(data_dir):\n    filenames = gfile.Glob(os.path.join(data_dir, '*'))\n    if not filenames:\n        raise RuntimeError('No data files found.')\n\n    for f in filenames:\n        k = 0\n        for serialized_example in tf.python_io.tf_record_iterator(f):\n            example = tf.train.Example()\n            example.ParseFromString(serialized_example)\n            # print(example)        # To know what all features are present\n\n            actions = np.empty((0, 4), dtype='float')\n            endeffector_positions = np.empty((0, 3), dtype='float')\n            frames_aux1 = []\n            frames_main = []\n            i = 0\n            while True:\n                action_name = str(i) + '/action'\n                action_value = np.array(example.features.feature[action_name].float_list.value)\n                if action_value.shape == (0,):      # End of frames/data\n                    break\n                actions = np.vstack((actions, action_value))\n\n                endeffector_pos_name = str(i) + '/endeffector_pos'\n                endeffector_pos_value = list(example.features.feature[endeffector_pos_name].float_list.value)\n                endeffector_positions = np.vstack((endeffector_positions, endeffector_pos_value))\n\n                aux1_image_name = str(i) + '/image_aux1/encoded'\n                aux1_byte_str = example.features.feature[aux1_image_name].bytes_list.value[0]\n                aux1_img = Image.frombytes('RGB', (64, 64), aux1_byte_str)\n                aux1_arr = np.array(aux1_img.getdata()).reshape((aux1_img.size[1], aux1_img.size[0], 3))\n                frames_aux1.append(aux1_arr.reshape(1, 64, 64, 3))\n\n                main_image_name = str(i) + '/image_main/encoded'\n                main_byte_str = example.features.feature[main_image_name].bytes_list.value[0]\n                main_img = Image.frombytes('RGB', (64, 64), main_byte_str)\n                main_arr = np.array(main_img.getdata()).reshape((main_img.size[1], main_img.size[0], 3))\n                frames_main.append(main_arr.reshape(1, 64, 64, 3))\n                i += 1\n\n            np_frames_aux1 = np.concatenate(frames_aux1, axis=0)\n            np_frames_main = np.concatenate(frames_main, axis=0)\n            yield f, k, actions, endeffector_positions, np_frames_aux1, np_frames_main\n            k = k + 1\n\n\ndef extract_data(data_dir, output_dir, frame_rate):\n    \"\"\"\n    Extracts data in tfrecord format to gifs, frames and text files\n    :param data_dir:\n    :param output_dir:\n    :param frame_rate:\n    :return:\n    \"\"\"\n    if os.path.exists(output_dir):\n        if os.listdir(output_dir):\n            raise RuntimeError('Directory not empty: {0}'.format(output_dir))\n    else:\n        os.makedirs(output_dir)\n\n    seq_generator = get_next_video_data(data_dir)\n    while True:\n        try:\n            _, k, actions, endeff_pos, aux1_frames, main_frames = next(seq_generator)\n        except StopIteration:\n            break\n        video_out_dir = os.path.join(output_dir, '{0:03}'.format(k))\n        os.makedirs(video_out_dir)\n\n        # noinspection PyTypeChecker\n        np.savetxt(os.path.join(video_out_dir, 'actions.csv'), actions, delimiter=',')\n        # noinspection PyTypeChecker\n        np.savetxt(os.path.join(video_out_dir, 'endeffector_positions.csv'), endeff_pos, delimiter=',')\n        skvideo.io.vwrite(os.path.join(video_out_dir, 'aux1.gif'), aux1_frames, inputdict={'-r': str(frame_rate)})\n        skvideo.io.vwrite(os.path.join(video_out_dir, 'main.gif'), main_frames, inputdict={'-r': str(frame_rate)})\n        skvideo.io.vwrite(os.path.join(video_out_dir, 'aux1.mp4'), aux1_frames, inputdict={'-r': str(frame_rate)})\n        skvideo.io.vwrite(os.path.join(video_out_dir, 'main.mp4'), main_frames, inputdict={'-r': str(frame_rate)})\n\n        # Save frames\n        aux1_folder_path = os.path.join(video_out_dir, 'aux1_frames')\n        os.makedirs(aux1_folder_path)\n        for i, frame in enumerate(aux1_frames):\n            filepath = os.path.join(aux1_folder_path, 'frame_{0:03}.bmp'.format(i))\n            cv2.imwrite(filepath, cv2.cvtColor(frame.astype('uint8'), cv2.COLOR_RGB2BGR))\n        main_folder_path = os.path.join(video_out_dir, 'main_frames')\n        os.makedirs(main_folder_path)\n        for i, frame in enumerate(main_frames):\n            filepath = os.path.join(main_folder_path, 'frame_{0:03}.bmp'.format(i))\n            cv2.imwrite(filepath, cv2.cvtColor(frame.astype('uint8'), cv2.COLOR_RGB2BGR))\n        print('Saved video: {0:03}'.format(k))\n\n\ndef main():\n    data_dir = '../softmotion30_44k/test'\n    output_dir = '../ExtractedData/test'\n    frame_rate = 4\n    extract_data(data_dir, output_dir, frame_rate)\n    return\n\n\nif __name__ == '__main__':\n    print('Program started at ' + datetime.datetime.now().strftime('%d/%m/%Y %I:%M:%S %p'))\n    start_time = time.time()\n    main()\n    end_time = time.time()\n    print('Program ended at ' + datetime.datetime.now().strftime('%d/%m/%Y %I:%M:%S %p'))\n    print('Execution time: ' + str(datetime.timedelta(seconds=end_time - start_time)))\n"
                    ]
                ],
                "question_id:": "52061",
                "question_votes:": "1",
                "question_text:": "<p>I'm trying to download <code>BAIR action free robot pushing dataset</code>. I tried downloading from <a href=\"https://sites.google.com/view/sna-visual-mpc\" rel=\"nofollow noreferrer\">here</a>. In browser, it shows its size is 30GB, but downloads some data and then fails. I tried multiple attempts with no success. Then I tried to download using <code>wget</code></p>\n\n<pre><code>wget http://rail.eecs.berkeley.edu/datasets/bair_robot_pushing_dataset_v0.tar\n</code></pre>\n\n<p>Even with this, it shows total size is 30GB, but after downloading some 199MB, it ended saying download is complete</p>\n\n<pre><code>wget http://rail.eecs.berkeley.edu/datasets/bair_robot_pushing_dataset_v0.tar\n--2019-05-16 12:30:50--  http://rail.eecs.berkeley.edu/datasets/bair_robot_pushing_dataset_v0.tar\nResolving rail.eecs.berkeley.edu (rail.eecs.berkeley.edu)... 128.32.189.73\nConnecting to rail.eecs.berkeley.edu (rail.eecs.berkeley.edu)|128.32.189.73|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 32274964480 (30G) [application/x-tar]\nSaving to: \u2018bair_robot_pushing_dataset_v0.tar\u2019\n\nbair_robot_pushing_dataset_v0.tar                    0%[                                                                                                                 ] 189.95M   456KB/s    in 10m 59s \n\n2019-05-16 12:41:50 (295 KB/s) - Connection closed at byte 199172826. Retrying.\n\n--2019-05-16 12:41:51--  (try: 2)  http://rail.eecs.berkeley.edu/datasets/bair_robot_pushing_dataset_v0.tar\nConnecting to rail.eecs.berkeley.edu (rail.eecs.berkeley.edu)|128.32.189.73|:80... connected.\nHTTP request sent, awaiting response... 416 Requested range not satisfiable\n\n    The file is already fully retrieved; nothing to do.\n</code></pre>\n\n<p>Also, I found a script that downloads BAIR dataset <a href=\"https://github.com/alexlee-gk/video_prediction/blob/master/data/download_and_preprocess_dataset.sh\" rel=\"nofollow noreferrer\">here</a>. But I encountered the same problem here as well.</p>\n\n<p>I'm confused now. Is the dataset so small or am I doing something wrong?</p>\n",
                "tags": "<dataset>",
                "answers": [
                    [
                        "56008",
                        "2",
                        "52061",
                        "",
                        "",
                        "<p>BAIR dataset can be downloaded here\n<a href=\"https://sites.google.com/berkeley.edu/robotic-interaction-datasets\" rel=\"nofollow noreferrer\">https://sites.google.com/berkeley.edu/robotic-interaction-datasets</a></p>\n\n<p>Additionally, here is the code to extract data from the dataset</p>\n\n<pre><code>import datetime\nimport os\nimport time\n\nimport cv2\nimport numpy as np\nimport skvideo.io\nimport tensorflow as tf\nfrom PIL import Image\nfrom tensorflow.python.platform import gfile\n\ndef get_next_video_data(data_dir):\n    filenames = gfile.Glob(os.path.join(data_dir, '*'))\n    if not filenames:\n        raise RuntimeError('No data files found.')\n\n    for f in filenames:\n        k = 0\n        for serialized_example in tf.python_io.tf_record_iterator(f):\n            example = tf.train.Example()\n            example.ParseFromString(serialized_example)\n            # print(example)        # To know what all features are present\n\n            actions = np.empty((0, 4), dtype='float')\n            endeffector_positions = np.empty((0, 3), dtype='float')\n            frames_aux1 = []\n            frames_main = []\n            i = 0\n            while True:\n                action_name = str(i) + '/action'\n                action_value = np.array(example.features.feature[action_name].float_list.value)\n                if action_value.shape == (0,):      # End of frames/data\n                    break\n                actions = np.vstack((actions, action_value))\n\n                endeffector_pos_name = str(i) + '/endeffector_pos'\n                endeffector_pos_value = list(example.features.feature[endeffector_pos_name].float_list.value)\n                endeffector_positions = np.vstack((endeffector_positions, endeffector_pos_value))\n\n                aux1_image_name = str(i) + '/image_aux1/encoded'\n                aux1_byte_str = example.features.feature[aux1_image_name].bytes_list.value[0]\n                aux1_img = Image.frombytes('RGB', (64, 64), aux1_byte_str)\n                aux1_arr = np.array(aux1_img.getdata()).reshape((aux1_img.size[1], aux1_img.size[0], 3))\n                frames_aux1.append(aux1_arr.reshape(1, 64, 64, 3))\n\n                main_image_name = str(i) + '/image_main/encoded'\n                main_byte_str = example.features.feature[main_image_name].bytes_list.value[0]\n                main_img = Image.frombytes('RGB', (64, 64), main_byte_str)\n                main_arr = np.array(main_img.getdata()).reshape((main_img.size[1], main_img.size[0], 3))\n                frames_main.append(main_arr.reshape(1, 64, 64, 3))\n                i += 1\n\n            np_frames_aux1 = np.concatenate(frames_aux1, axis=0)\n            np_frames_main = np.concatenate(frames_main, axis=0)\n            yield f, k, actions, endeffector_positions, np_frames_aux1, np_frames_main\n            k = k + 1\n\n\ndef extract_data(data_dir, output_dir, frame_rate):\n    \"\"\"\n    Extracts data in tfrecord format to gifs, frames and text files\n    :param data_dir:\n    :param output_dir:\n    :param frame_rate:\n    :return:\n    \"\"\"\n    if os.path.exists(output_dir):\n        if os.listdir(output_dir):\n            raise RuntimeError('Directory not empty: {0}'.format(output_dir))\n    else:\n        os.makedirs(output_dir)\n\n    seq_generator = get_next_video_data(data_dir)\n    while True:\n        try:\n            _, k, actions, endeff_pos, aux1_frames, main_frames = next(seq_generator)\n        except StopIteration:\n            break\n        video_out_dir = os.path.join(output_dir, '{0:03}'.format(k))\n        os.makedirs(video_out_dir)\n\n        # noinspection PyTypeChecker\n        np.savetxt(os.path.join(video_out_dir, 'actions.csv'), actions, delimiter=',')\n        # noinspection PyTypeChecker\n        np.savetxt(os.path.join(video_out_dir, 'endeffector_positions.csv'), endeff_pos, delimiter=',')\n        skvideo.io.vwrite(os.path.join(video_out_dir, 'aux1.gif'), aux1_frames, inputdict={'-r': str(frame_rate)})\n        skvideo.io.vwrite(os.path.join(video_out_dir, 'main.gif'), main_frames, inputdict={'-r': str(frame_rate)})\n        skvideo.io.vwrite(os.path.join(video_out_dir, 'aux1.mp4'), aux1_frames, inputdict={'-r': str(frame_rate)})\n        skvideo.io.vwrite(os.path.join(video_out_dir, 'main.mp4'), main_frames, inputdict={'-r': str(frame_rate)})\n\n        # Save frames\n        aux1_folder_path = os.path.join(video_out_dir, 'aux1_frames')\n        os.makedirs(aux1_folder_path)\n        for i, frame in enumerate(aux1_frames):\n            filepath = os.path.join(aux1_folder_path, 'frame_{0:03}.bmp'.format(i))\n            cv2.imwrite(filepath, cv2.cvtColor(frame.astype('uint8'), cv2.COLOR_RGB2BGR))\n        main_folder_path = os.path.join(video_out_dir, 'main_frames')\n        os.makedirs(main_folder_path)\n        for i, frame in enumerate(main_frames):\n            filepath = os.path.join(main_folder_path, 'frame_{0:03}.bmp'.format(i))\n            cv2.imwrite(filepath, cv2.cvtColor(frame.astype('uint8'), cv2.COLOR_RGB2BGR))\n        print('Saved video: {0:03}'.format(k))\n\n\ndef main():\n    data_dir = '../softmotion30_44k/test'\n    output_dir = '../ExtractedData/test'\n    frame_rate = 4\n    extract_data(data_dir, output_dir, frame_rate)\n    return\n\n\nif __name__ == '__main__':\n    print('Program started at ' + datetime.datetime.now().strftime('%d/%m/%Y %I:%M:%S %p'))\n    start_time = time.time()\n    main()\n    end_time = time.time()\n    print('Program ended at ' + datetime.datetime.now().strftime('%d/%m/%Y %I:%M:%S %p'))\n    print('Execution time: ' + str(datetime.timedelta(seconds=end_time - start_time)))\n</code></pre>\n\n<p><strong>References</strong>:\n<a href=\"https://github.com/edenton/svg/blob/master/data/convert_bair.py\" rel=\"nofollow noreferrer\">https://github.com/edenton/svg/blob/master/data/convert_bair.py</a></p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5835",
            "_score": 6.073275,
            "_source": {
                "title": "Categorical Variable Reduction using NN",
                "content": "Categorical Variable Reduction using NN <p>I was trying to categorical variable engineering following <a href=\"https://arxiv.org/abs/1604.06737\" rel=\"nofollow noreferrer\">this</a> paper. The code is the following:</p>\n\n<pre><code>import random\nimport pandas\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow.contrib import layers\nfrom tensorflow.contrib import learn\nfrom __future__ import print_function\n\nfrom sklearn.preprocessing import LabelEncoder\n</code></pre>\n\n<p>My dataset looks like the following. It's has 2 independent variable ('X1' &amp; 'X2')and 1 dependent variable ('lable'). 'X2' is the categorical variable. I want to create an embedding vector for this variable and run the simple linear regression to predict 'label'using Tensorflow.  I could use any other method. But since linear regression is easiest to understand, I'm trying that.</p>\n\n<pre><code>df = pd.DataFrame({'X1': np.array([\"A\",\"A\",\"B\",\"C\",\"B\",\"C\",\"B\",\"C\",\"C\",\"B\",\n                         \"A\",\"B\",\"A\",\"C\",\"A\",\"A\",\"C\"]),'X2': np.array([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n                         7.042,10.791,5.313,7.997,5.654,9.27,3.1]),\n                       'label': np.array([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])})\n</code></pre>\n\n<h1>For variable 'X1', I'm creating levels.</h1>\n\n<pre><code>encoder = LabelEncoder()\nencoder.fit(df.X1.values)\nX = encoder.transform(df.X1.values)\n</code></pre>\n\n<h1>Recreating dependent variable list.</h1>\n\n<pre><code>y = np.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n</code></pre>\n\n<h1>Setting Hyper-parameters</h1>\n\n<pre><code>training_epochs = 5\nlearning_rate = 1e-3\ncardinality = len(np.unique(X))\nembedding_size = 2\ninput_X_size = 1\nn_hidden = 10\n</code></pre>\n\n<h1>Setting up variables:</h1>\n\n<pre><code>embeddings = tf.Variable(tf.random_uniform([cardinality, embedding_size], -1.0, 1.0))\n\n\nh = tf.Variable(tf.truncated_normal((embedding_size + len(df.X1), n_hidden), stddev=0.1))\n\n\nW_out = tf.get_variable(name='out_w', shape=[n_hidden],\n                            initializer=tf.contrib.layers.xavier_initializer())\n</code></pre>\n\n<h1>Embedding:</h1>\n\n<pre><code>embedded_chars = tf.nn.embedding_lookup(embeddings, x)\nembedded_chars = tf.reshape(embedded_chars, [-1])\nembedded_chars= embedded_chars + np.array([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n</code></pre>\n\n<h1>Multiplying with Hidden Layers:</h1>\n\n<pre><code>layer_1 = tf.matmul(embedded_chars,h)\nlayer_1 = tf.nn.relu(layer_1)\nout_layer = tf.matmul(layer_1, W_out)\n</code></pre>\n\n<p># Define loss and optimizer</p>\n\n<pre><code>cost = tf.reduce_sum(tf.pow(out_layer-y, 2))/(2*n_samples)\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n</code></pre>\n\n<h1>Run the graph</h1>\n\n<p>init = tf.global_variables_initializer()</p>\n\n<pre><code># Launch the graph\nwith tf.Session() as sess:\n    sess.run(init)\n\n    for epoch in range(training_epochs):\n        avg_cost = 0.\n\n        _, c = sess.run([optimizer, cost],\n                        feed_dict={x: X, y: Y})\nprint(\"Ran without Error\")\n</code></pre>\n\n<p>While running the code, I'm getting the following error.</p>\n\n<blockquote>\n  <p>ValueError: Shape must be rank 2 but is rank 1 for 'MatMul_1' (op:\n  'MatMul') with input shapes: [17], [19,10].</p>\n</blockquote>\n\n<p>I'm not able to add the continuous variable with embedding variable. </p>\n\n<p>Can anyone please guide me how to do it?</p>\n\n<p>Thank you! </p>\n <neural-network><tensorflow><embeddings><p>You are multiplying matrices, so the dimensions have to match up.</p>\n\n<p>The following line reshapes the embedding layer to a rank 1 matrix, hence causing the error.</p>\n\n<pre><code>embedded_chars = tf.reshape(embedded_chars, [-1])\n</code></pre>\n\n<p>You may want to rethink the embedding portion of the code (the function's docstring), as that is what needs to be understood perfectly in order to define the computational graph.</p>\n",
                "codes": [
                    [
                        "embedded_chars = tf.reshape(embedded_chars, [-1])\n"
                    ]
                ],
                "question_id:": "23101",
                "question_votes:": "1",
                "question_text:": "<p>I was trying to categorical variable engineering following <a href=\"https://arxiv.org/abs/1604.06737\" rel=\"nofollow noreferrer\">this</a> paper. The code is the following:</p>\n\n<pre><code>import random\nimport pandas\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow.contrib import layers\nfrom tensorflow.contrib import learn\nfrom __future__ import print_function\n\nfrom sklearn.preprocessing import LabelEncoder\n</code></pre>\n\n<p>My dataset looks like the following. It's has 2 independent variable ('X1' &amp; 'X2')and 1 dependent variable ('lable'). 'X2' is the categorical variable. I want to create an embedding vector for this variable and run the simple linear regression to predict 'label'using Tensorflow.  I could use any other method. But since linear regression is easiest to understand, I'm trying that.</p>\n\n<pre><code>df = pd.DataFrame({'X1': np.array([\"A\",\"A\",\"B\",\"C\",\"B\",\"C\",\"B\",\"C\",\"C\",\"B\",\n                         \"A\",\"B\",\"A\",\"C\",\"A\",\"A\",\"C\"]),'X2': np.array([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n                         7.042,10.791,5.313,7.997,5.654,9.27,3.1]),\n                       'label': np.array([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])})\n</code></pre>\n\n<h1>For variable 'X1', I'm creating levels.</h1>\n\n<pre><code>encoder = LabelEncoder()\nencoder.fit(df.X1.values)\nX = encoder.transform(df.X1.values)\n</code></pre>\n\n<h1>Recreating dependent variable list.</h1>\n\n<pre><code>y = np.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n</code></pre>\n\n<h1>Setting Hyper-parameters</h1>\n\n<pre><code>training_epochs = 5\nlearning_rate = 1e-3\ncardinality = len(np.unique(X))\nembedding_size = 2\ninput_X_size = 1\nn_hidden = 10\n</code></pre>\n\n<h1>Setting up variables:</h1>\n\n<pre><code>embeddings = tf.Variable(tf.random_uniform([cardinality, embedding_size], -1.0, 1.0))\n\n\nh = tf.Variable(tf.truncated_normal((embedding_size + len(df.X1), n_hidden), stddev=0.1))\n\n\nW_out = tf.get_variable(name='out_w', shape=[n_hidden],\n                            initializer=tf.contrib.layers.xavier_initializer())\n</code></pre>\n\n<h1>Embedding:</h1>\n\n<pre><code>embedded_chars = tf.nn.embedding_lookup(embeddings, x)\nembedded_chars = tf.reshape(embedded_chars, [-1])\nembedded_chars= embedded_chars + np.array([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n</code></pre>\n\n<h1>Multiplying with Hidden Layers:</h1>\n\n<pre><code>layer_1 = tf.matmul(embedded_chars,h)\nlayer_1 = tf.nn.relu(layer_1)\nout_layer = tf.matmul(layer_1, W_out)\n</code></pre>\n\n<p># Define loss and optimizer</p>\n\n<pre><code>cost = tf.reduce_sum(tf.pow(out_layer-y, 2))/(2*n_samples)\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n</code></pre>\n\n<h1>Run the graph</h1>\n\n<p>init = tf.global_variables_initializer()</p>\n\n<pre><code># Launch the graph\nwith tf.Session() as sess:\n    sess.run(init)\n\n    for epoch in range(training_epochs):\n        avg_cost = 0.\n\n        _, c = sess.run([optimizer, cost],\n                        feed_dict={x: X, y: Y})\nprint(\"Ran without Error\")\n</code></pre>\n\n<p>While running the code, I'm getting the following error.</p>\n\n<blockquote>\n  <p>ValueError: Shape must be rank 2 but is rank 1 for 'MatMul_1' (op:\n  'MatMul') with input shapes: [17], [19,10].</p>\n</blockquote>\n\n<p>I'm not able to add the continuous variable with embedding variable. </p>\n\n<p>Can anyone please guide me how to do it?</p>\n\n<p>Thank you! </p>\n",
                "tags": "<neural-network><tensorflow><embeddings>",
                "answers": [
                    [
                        "34082",
                        "2",
                        "23101",
                        "",
                        "",
                        "<p>You are multiplying matrices, so the dimensions have to match up.</p>\n\n<p>The following line reshapes the embedding layer to a rank 1 matrix, hence causing the error.</p>\n\n<pre><code>embedded_chars = tf.reshape(embedded_chars, [-1])\n</code></pre>\n\n<p>You may want to rethink the embedding portion of the code (the function's docstring), as that is what needs to be understood perfectly in order to define the computational graph.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "1702",
            "_score": 6.064783,
            "_source": {
                "title": "How should a neural network for unbound function approximation be structured?",
                "content": "How should a neural network for unbound function approximation be structured? <p>I've heard that a multilayer perceptron can approximate any function arbitrarily exact, given enough neurons. I wanted to try it, so I wrote the following code:</p>\n\n\n\n<pre><code>#!/usr/bin/env python\n\n\"\"\"Example for learning a regression.\"\"\"\n\n\nimport tensorflow as tf\nimport numpy\n\n\ndef plot(xs, ys_truth, ys_pred):\n    \"\"\"\n    Plot the true values and the predicted values.\n\n    Parameters\n    ----------\n    xs : list\n        Numeric values\n    ys_truth : list\n        Numeric values, same length as `xs`\n    ys_pred : list\n        Numeric values, same length as `xs`\n    \"\"\"\n    import matplotlib.pyplot as plt\n    truth_plot, = plt.plot(xs, ys_truth, '-o', color='#00ff00')\n    pred_plot, = plt.plot(xs, ys_pred, '-o', color='#ff0000')\n    plt.legend([truth_plot, pred_plot],\n               ['Truth', 'Prediction'],\n               loc='upper center')\n    plt.savefig('plot.png')\n\n\n# Parameters\nlearning_rate = 0.1\nmomentum = 0.6\ntraining_epochs = 1000\ndisplay_step = 100\n\n# Generate training data\ntrain_X = []\ntrain_Y = []\n\n# First simple test: a linear function\nf = lambda x: x+4\n\n# Second, more complicated test: x^2\n# f = lambda x: x**2\n\nfor x in range(-20, 20):\n    train_X.append(float(x))\n    train_Y.append(f(x))\ntrain_X = numpy.asarray(train_X)\ntrain_Y = numpy.asarray(train_Y)\nn_samples = train_X.shape[0]\n\n# Graph input\nX = tf.placeholder(tf.float32)\nreshaped_X = tf.reshape(X, [-1, 1])\nY = tf.placeholder(\"float\")\n\n# Create Model\nW1 = tf.Variable(tf.truncated_normal([1, 100], stddev=0.1), name=\"weight\")\nb1 = tf.Variable(tf.constant(0.1, shape=[1, 100]), name=\"bias\")\nmul = tf.matmul(reshaped_X, W1)\nh1 = tf.nn.sigmoid(mul) + b1\nW2 = tf.Variable(tf.truncated_normal([100, 100], stddev=0.1), name=\"weight\")\nb2 = tf.Variable(tf.constant(0.1, shape=[100]), name=\"bias\")\nh2 = tf.nn.sigmoid(tf.matmul(h1, W2)) + b2\nW3 = tf.Variable(tf.truncated_normal([100, 1], stddev=0.1), name=\"weight\")\nb3 = tf.Variable(tf.constant(0.1, shape=[1]), name=\"bias\")\n# identity as activation to get arbitrary output\nactivation = tf.matmul(h2, W3) + b3\n\n# Minimize the squared errors\nl2_loss = tf.reduce_sum(tf.pow(activation-Y, 2))/(2*n_samples)\noptimizer = tf.train.MomentumOptimizer(learning_rate, momentum).minimize(l2_loss)\n\n# Initializing the variables\ninit = tf.initialize_all_variables()\n\n# Launch the graph\nwith tf.Session() as sess:\n    sess.run(init)\n\n    # Fit all training data\n    for epoch in range(training_epochs):\n        for (x, y) in zip(train_X, train_Y):\n            sess.run(optimizer, feed_dict={X: x, Y: y})\n\n        # Display logs per epoch step\n        if epoch % display_step == 0:\n            cost = sess.run(l2_loss, feed_dict={X: train_X, Y: train_Y})\n            print(\"cost=%s\\nW1=%s\" % (cost, sess.run(W1)))\n\n    print(\"Optimization Finished!\")\n    print(\"cost=%s W1=%s\" %\n          (sess.run(l2_loss, feed_dict={X: train_X, Y: train_Y}),\n           sess.run(W1)))  # \"b2=\", sess.run(b2)\n\n    # Get output and plot it\n    ys_pred = []\n    ys_truth = []\n\n    test_X = []\n    for x in range(-40, 40):\n        test_X.append(float(x))\n\n    for x in test_X:\n        ret = sess.run(activation, feed_dict={X: x})\n        ys_pred.append(list(ret)[0][0])\n        ys_truth.append(f(x))\n    plot(train_X.tolist(), ys_truth, ys_pred)\n</code></pre>\n\n<p>This kind of works for linear functions (at least for the training data, not so much for the testing data outside of the range):</p>\n\n<p><a href=\"https://i.stack.imgur.com/cIRSR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/cIRSR.png\" alt=\"enter image description here\"></a></p>\n\n<p>However, it doesn't work at all for non-linear function $x^2$:</p>\n\n<p><a href=\"https://i.stack.imgur.com/q6JbH.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/q6JbH.png\" alt=\"enter image description here\"></a></p>\n\n<p>Why does this neural network not work for such simple function approximation? What do I have to change to make the same network topology work for both functions?</p>\n <machine-learning><neural-network><tensorflow><p>This does not answere your question directly, but might include some helpful pointers:</p>\n\n<p>In the recent <a href=\"http://arxiv.org/abs/1512.03385\" rel=\"nofollow\" title=\"Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun Submitted on 10 Dec 2015\">Deep Residual Learning for Image Recognition</a> paper it is written:</p>\n\n<blockquote>\n  <p>If one hypothesizes that multiple nonlinear layers can asymptotically\n  approximate complicated functions[...]</p>\n  \n  <p>This hypothesis, however, is still an open question. See [<a href=\"http://arxiv.org/abs/1402.1869\" rel=\"nofollow\" title=\"G. Montufar, R. Pascanu, K. Cho, and Y. Bengio. On the number of linear regions of deep neural networks. In NIPS, 2014.\">28</a>].</p>\n</blockquote>\n",
                "codes": [
                    []
                ],
                "question_id:": "9495",
                "question_votes:": "1",
                "question_text:": "<p>I've heard that a multilayer perceptron can approximate any function arbitrarily exact, given enough neurons. I wanted to try it, so I wrote the following code:</p>\n\n\n\n<pre><code>#!/usr/bin/env python\n\n\"\"\"Example for learning a regression.\"\"\"\n\n\nimport tensorflow as tf\nimport numpy\n\n\ndef plot(xs, ys_truth, ys_pred):\n    \"\"\"\n    Plot the true values and the predicted values.\n\n    Parameters\n    ----------\n    xs : list\n        Numeric values\n    ys_truth : list\n        Numeric values, same length as `xs`\n    ys_pred : list\n        Numeric values, same length as `xs`\n    \"\"\"\n    import matplotlib.pyplot as plt\n    truth_plot, = plt.plot(xs, ys_truth, '-o', color='#00ff00')\n    pred_plot, = plt.plot(xs, ys_pred, '-o', color='#ff0000')\n    plt.legend([truth_plot, pred_plot],\n               ['Truth', 'Prediction'],\n               loc='upper center')\n    plt.savefig('plot.png')\n\n\n# Parameters\nlearning_rate = 0.1\nmomentum = 0.6\ntraining_epochs = 1000\ndisplay_step = 100\n\n# Generate training data\ntrain_X = []\ntrain_Y = []\n\n# First simple test: a linear function\nf = lambda x: x+4\n\n# Second, more complicated test: x^2\n# f = lambda x: x**2\n\nfor x in range(-20, 20):\n    train_X.append(float(x))\n    train_Y.append(f(x))\ntrain_X = numpy.asarray(train_X)\ntrain_Y = numpy.asarray(train_Y)\nn_samples = train_X.shape[0]\n\n# Graph input\nX = tf.placeholder(tf.float32)\nreshaped_X = tf.reshape(X, [-1, 1])\nY = tf.placeholder(\"float\")\n\n# Create Model\nW1 = tf.Variable(tf.truncated_normal([1, 100], stddev=0.1), name=\"weight\")\nb1 = tf.Variable(tf.constant(0.1, shape=[1, 100]), name=\"bias\")\nmul = tf.matmul(reshaped_X, W1)\nh1 = tf.nn.sigmoid(mul) + b1\nW2 = tf.Variable(tf.truncated_normal([100, 100], stddev=0.1), name=\"weight\")\nb2 = tf.Variable(tf.constant(0.1, shape=[100]), name=\"bias\")\nh2 = tf.nn.sigmoid(tf.matmul(h1, W2)) + b2\nW3 = tf.Variable(tf.truncated_normal([100, 1], stddev=0.1), name=\"weight\")\nb3 = tf.Variable(tf.constant(0.1, shape=[1]), name=\"bias\")\n# identity as activation to get arbitrary output\nactivation = tf.matmul(h2, W3) + b3\n\n# Minimize the squared errors\nl2_loss = tf.reduce_sum(tf.pow(activation-Y, 2))/(2*n_samples)\noptimizer = tf.train.MomentumOptimizer(learning_rate, momentum).minimize(l2_loss)\n\n# Initializing the variables\ninit = tf.initialize_all_variables()\n\n# Launch the graph\nwith tf.Session() as sess:\n    sess.run(init)\n\n    # Fit all training data\n    for epoch in range(training_epochs):\n        for (x, y) in zip(train_X, train_Y):\n            sess.run(optimizer, feed_dict={X: x, Y: y})\n\n        # Display logs per epoch step\n        if epoch % display_step == 0:\n            cost = sess.run(l2_loss, feed_dict={X: train_X, Y: train_Y})\n            print(\"cost=%s\\nW1=%s\" % (cost, sess.run(W1)))\n\n    print(\"Optimization Finished!\")\n    print(\"cost=%s W1=%s\" %\n          (sess.run(l2_loss, feed_dict={X: train_X, Y: train_Y}),\n           sess.run(W1)))  # \"b2=\", sess.run(b2)\n\n    # Get output and plot it\n    ys_pred = []\n    ys_truth = []\n\n    test_X = []\n    for x in range(-40, 40):\n        test_X.append(float(x))\n\n    for x in test_X:\n        ret = sess.run(activation, feed_dict={X: x})\n        ys_pred.append(list(ret)[0][0])\n        ys_truth.append(f(x))\n    plot(train_X.tolist(), ys_truth, ys_pred)\n</code></pre>\n\n<p>This kind of works for linear functions (at least for the training data, not so much for the testing data outside of the range):</p>\n\n<p><a href=\"https://i.stack.imgur.com/cIRSR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/cIRSR.png\" alt=\"enter image description here\"></a></p>\n\n<p>However, it doesn't work at all for non-linear function $x^2$:</p>\n\n<p><a href=\"https://i.stack.imgur.com/q6JbH.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/q6JbH.png\" alt=\"enter image description here\"></a></p>\n\n<p>Why does this neural network not work for such simple function approximation? What do I have to change to make the same network topology work for both functions?</p>\n",
                "tags": "<machine-learning><neural-network><tensorflow>",
                "answers": [
                    [
                        "9873",
                        "2",
                        "9495",
                        "",
                        "",
                        "<p>This does not answere your question directly, but might include some helpful pointers:</p>\n\n<p>In the recent <a href=\"http://arxiv.org/abs/1512.03385\" rel=\"nofollow\" title=\"Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun Submitted on 10 Dec 2015\">Deep Residual Learning for Image Recognition</a> paper it is written:</p>\n\n<blockquote>\n  <p>If one hypothesizes that multiple nonlinear layers can asymptotically\n  approximate complicated functions[...]</p>\n  \n  <p>This hypothesis, however, is still an open question. See [<a href=\"http://arxiv.org/abs/1402.1869\" rel=\"nofollow\" title=\"G. Montufar, R. Pascanu, K. Cho, and Y. Bengio. On the number of linear regions of deep neural networks. In NIPS, 2014.\">28</a>].</p>\n</blockquote>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11233",
            "_score": 6.0579834,
            "_source": {
                "title": "pandas: How to impute the categorical column by the nearest neighbors?",
                "content": "pandas: How to impute the categorical column by the nearest neighbors? <p>I've a categorical column with values such as right('r'), left('l') and straight('s'). I expect these to have a continuum periods in the data and want to impute nans with the most plausible value in the neighborhood. In the beginning of the input signal you can see nans embedded in an otherwise continuum 's' episode. My definition as to what characterizes an episode is occurrence of the corresponding symbol at least 5 times in a row. Also, in my interest to be given more weight to 'r' and 'l' when tied with 's'.</p>\n\n<pre><code>iput = ['s','s','s','s','s','s',np.nan,'s',np.nan,'s','s','s','s','r',np.nan,np.nan,'r','r','r','r','s','s','s','s','s',np.nan,np.nan,'s','s','s','l','l','l','l','l',np.nan,'l','l','l']\noput = ['s','s','s','s','s','s','s','s','s','s','s','s','s','r','r','r','r','r','r','r','s','s','s','s','s','s','s','s','s','s','l','l','l','l','l','l','l','l','l']\n</code></pre>\n\n<p>I tried knn as following but it is rather suitable for numerical column and also imputing nans with zeros.\nI was hoping for some ideas how to tackle this problem.\nfrom fancyimpute import KNN\nknnimpute = KNN(k=5)</p>\n\n<pre><code>&gt;&gt;&gt;x = np.array([0,np.nan,1,1,1,np.nan,2,2,2,2,np.nan,2,3,3,3,3,np.nan,1,1,2,2,np.nan,1,3,3,3,3])\n&gt;&gt;&gt;x2 = knnimpute.fit_transform(x.reshape(-1,1))\n&gt;&gt;&gt;x2\n&gt;&gt;&gt; \narray([[0.],\n           [0.],\n           [1.],\n           [1.],\n           [1.],\n           [0.],\n           [2.],\n           [2.],\n           [2.],\n           [2.],\n           [0.],\n           [2.],\n           [3.],\n           [3.],\n           [3.],\n           [3.],\n           [0.],\n           [1.],\n           [1.],\n           [2.],\n           [2.],\n           [0.],\n           [1.],\n           [3.],\n           [3.],\n           [3.],\n           [3.]])\n</code></pre>\n <python><pandas><preprocessing><numpy><data-imputation><p>The following script will give the value of the most frequent item to the nan value. It is a list of 7 items, since it checks the three samples before the nan, the nan itself and the three after the nan samples.</p>\n\n<pre><code>iput = ['s','s','s','s','s','s',np.nan,'s',np.nan,'s','s','s','s','r',np.nan,np.nan,'r','r','r','r','s','s','s','s','s',np.nan,np.nan,'s','s','s','l','l','l','l','l',np.nan,'l','l','l']\nfor i in range(len(iput)):\n    if type(iput[i]) is float:\n        iput[i]=max(iput[i-3:i+3],key=iput[i-3:i+3].count)\n</code></pre>\n",
                "codes": [
                    [
                        "iput = ['s','s','s','s','s','s',np.nan,'s',np.nan,'s','s','s','s','r',np.nan,np.nan,'r','r','r','r','s','s','s','s','s',np.nan,np.nan,'s','s','s','l','l','l','l','l',np.nan,'l','l','l']\nfor i in range(len(iput)):\n    if type(iput[i]) is float:\n        iput[i]=max(iput[i-3:i+3],key=iput[i-3:i+3].count)\n"
                    ]
                ],
                "question_id:": "39630",
                "question_votes:": "",
                "question_text:": "<p>I've a categorical column with values such as right('r'), left('l') and straight('s'). I expect these to have a continuum periods in the data and want to impute nans with the most plausible value in the neighborhood. In the beginning of the input signal you can see nans embedded in an otherwise continuum 's' episode. My definition as to what characterizes an episode is occurrence of the corresponding symbol at least 5 times in a row. Also, in my interest to be given more weight to 'r' and 'l' when tied with 's'.</p>\n\n<pre><code>iput = ['s','s','s','s','s','s',np.nan,'s',np.nan,'s','s','s','s','r',np.nan,np.nan,'r','r','r','r','s','s','s','s','s',np.nan,np.nan,'s','s','s','l','l','l','l','l',np.nan,'l','l','l']\noput = ['s','s','s','s','s','s','s','s','s','s','s','s','s','r','r','r','r','r','r','r','s','s','s','s','s','s','s','s','s','s','l','l','l','l','l','l','l','l','l']\n</code></pre>\n\n<p>I tried knn as following but it is rather suitable for numerical column and also imputing nans with zeros.\nI was hoping for some ideas how to tackle this problem.\nfrom fancyimpute import KNN\nknnimpute = KNN(k=5)</p>\n\n<pre><code>&gt;&gt;&gt;x = np.array([0,np.nan,1,1,1,np.nan,2,2,2,2,np.nan,2,3,3,3,3,np.nan,1,1,2,2,np.nan,1,3,3,3,3])\n&gt;&gt;&gt;x2 = knnimpute.fit_transform(x.reshape(-1,1))\n&gt;&gt;&gt;x2\n&gt;&gt;&gt; \narray([[0.],\n           [0.],\n           [1.],\n           [1.],\n           [1.],\n           [0.],\n           [2.],\n           [2.],\n           [2.],\n           [2.],\n           [0.],\n           [2.],\n           [3.],\n           [3.],\n           [3.],\n           [3.],\n           [0.],\n           [1.],\n           [1.],\n           [2.],\n           [2.],\n           [0.],\n           [1.],\n           [3.],\n           [3.],\n           [3.],\n           [3.]])\n</code></pre>\n",
                "tags": "<python><pandas><preprocessing><numpy><data-imputation>",
                "answers": [
                    [
                        "39640",
                        "2",
                        "39630",
                        "",
                        "",
                        "<p>The following script will give the value of the most frequent item to the nan value. It is a list of 7 items, since it checks the three samples before the nan, the nan itself and the three after the nan samples.</p>\n\n<pre><code>iput = ['s','s','s','s','s','s',np.nan,'s',np.nan,'s','s','s','s','r',np.nan,np.nan,'r','r','r','r','s','s','s','s','s',np.nan,np.nan,'s','s','s','l','l','l','l','l',np.nan,'l','l','l']\nfor i in range(len(iput)):\n    if type(iput[i]) is float:\n        iput[i]=max(iput[i-3:i+3],key=iput[i-3:i+3].count)\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14279",
            "_score": 6.0579834,
            "_source": {
                "title": "How do I train Xgboost classifier for ECG Signal data?",
                "content": "How do I train Xgboost classifier for ECG Signal data? <p>I am testing <a href=\"https://www.physionet.org/challenge/2017/sources/\" rel=\"nofollow noreferrer\">https://www.physionet.org/challenge/2017/sources/</a> submission. </p>\n\n<p>I like one of the submission code, which use <code>Xgboost</code> to train the classifier. Training data is in <code>.mat</code> file which can be converted to <code>csv</code> format. </p>\n\n<p>In below code, I have pretrained model <code>xgb.bin</code>, using which I can test any input signal. But I Want to train the model using different data and create my own training model.</p>\n\n<p>Here is the code which predicts class name for given input ecg file </p>\n\n<pre><code>def predict(data):\n\n    #data = io.loadmat(path)['val'][0]\n\n    from numpy import genfromtxt\n    data = genfromtxt('testdata/val.csv', delimiter=',')\n\n\n    features_noise = np.zeros((5, ))\n\n    snr, rr_num, var, fr, fr2 = find_noise_features(data)\n    features_noise[0] = snr\n    features_noise[1] = rr_num\n    features_noise[2] = var\n    features_noise[3] = fr\n    features_noise[4] = fr2\n    features = extract_basic_features(data, 30000)\n    features = np.hstack((features, features_noise.reshape(1, -1)))\n\n    mean_ = np.array([15.96300284066109753667, 0.00412371298595770857, 38811.34497233365254942328,\n                      0.48050717744965593115, 0.14397582347542958736])\n    scale_ = np.array([4.22917401559752281770, 0.00093664880988427878, 62350.76443798459513345733,\n                       0.15396567666240373873, 0.07085474966801086349])\n    features_noise -= mean_\n    features_noise /= scale_\n\n    prediction = 0\n    if features_noise[0] &lt; -2.9:\n        prediction = 3\n    if features_noise[2] &gt; 6.0:\n        prediction = 3\n    if features_noise[3] &gt; 3.0:\n        prediction = 3\n    if features_noise[4] &lt; -2.0:\n        prediction = 3\n\n    bst = xgb.Booster({'nthread': 4})\n    bst.load_model(\"xgb.bin\")\n\n    dfeatures = xgb.DMatrix(features)\n    prediction_prob = bst.predict(dfeatures)\n    prediction = np.argmax(prediction_prob)\n\n    return prediction\n\ndef run(data): \n    prediction = predict(data)\n    print(prediction)\n</code></pre>\n\n<p>I want to train this classifer using my own dataset. Above model is trained on <code>https://www.physionet.org/challenge/2017/training2017.zip</code> dataset. </p>\n\n<p><strong>Looking at above code, do you have any clue how can I train the model using Xgboost.</strong> </p>\n\n<p>Here is my thought steps </p>\n\n<ol>\n<li>Calculate <code>features</code> for all training signal in zip file</li>\n<li>Calculate <code>feature_noise</code> as it is in above code for all signals</li>\n<li>Calculate <code>dfeatures</code> features for each signals (Should I calculate it for each signals or for all signal together)</li>\n<li>Train <code>dfeatures</code> for all signals using Xgboost (How?)</li>\n<li>Store the xgboost model</li>\n</ol>\n\n<p>Is this correct steps to do?</p>\n <machine-learning><classification><xgboost>",
                "codes": [],
                "question_id:": "48141",
                "question_votes:": "1",
                "question_text:": "<p>I am testing <a href=\"https://www.physionet.org/challenge/2017/sources/\" rel=\"nofollow noreferrer\">https://www.physionet.org/challenge/2017/sources/</a> submission. </p>\n\n<p>I like one of the submission code, which use <code>Xgboost</code> to train the classifier. Training data is in <code>.mat</code> file which can be converted to <code>csv</code> format. </p>\n\n<p>In below code, I have pretrained model <code>xgb.bin</code>, using which I can test any input signal. But I Want to train the model using different data and create my own training model.</p>\n\n<p>Here is the code which predicts class name for given input ecg file </p>\n\n<pre><code>def predict(data):\n\n    #data = io.loadmat(path)['val'][0]\n\n    from numpy import genfromtxt\n    data = genfromtxt('testdata/val.csv', delimiter=',')\n\n\n    features_noise = np.zeros((5, ))\n\n    snr, rr_num, var, fr, fr2 = find_noise_features(data)\n    features_noise[0] = snr\n    features_noise[1] = rr_num\n    features_noise[2] = var\n    features_noise[3] = fr\n    features_noise[4] = fr2\n    features = extract_basic_features(data, 30000)\n    features = np.hstack((features, features_noise.reshape(1, -1)))\n\n    mean_ = np.array([15.96300284066109753667, 0.00412371298595770857, 38811.34497233365254942328,\n                      0.48050717744965593115, 0.14397582347542958736])\n    scale_ = np.array([4.22917401559752281770, 0.00093664880988427878, 62350.76443798459513345733,\n                       0.15396567666240373873, 0.07085474966801086349])\n    features_noise -= mean_\n    features_noise /= scale_\n\n    prediction = 0\n    if features_noise[0] &lt; -2.9:\n        prediction = 3\n    if features_noise[2] &gt; 6.0:\n        prediction = 3\n    if features_noise[3] &gt; 3.0:\n        prediction = 3\n    if features_noise[4] &lt; -2.0:\n        prediction = 3\n\n    bst = xgb.Booster({'nthread': 4})\n    bst.load_model(\"xgb.bin\")\n\n    dfeatures = xgb.DMatrix(features)\n    prediction_prob = bst.predict(dfeatures)\n    prediction = np.argmax(prediction_prob)\n\n    return prediction\n\ndef run(data): \n    prediction = predict(data)\n    print(prediction)\n</code></pre>\n\n<p>I want to train this classifer using my own dataset. Above model is trained on <code>https://www.physionet.org/challenge/2017/training2017.zip</code> dataset. </p>\n\n<p><strong>Looking at above code, do you have any clue how can I train the model using Xgboost.</strong> </p>\n\n<p>Here is my thought steps </p>\n\n<ol>\n<li>Calculate <code>features</code> for all training signal in zip file</li>\n<li>Calculate <code>feature_noise</code> as it is in above code for all signals</li>\n<li>Calculate <code>dfeatures</code> features for each signals (Should I calculate it for each signals or for all signal together)</li>\n<li>Train <code>dfeatures</code> for all signals using Xgboost (How?)</li>\n<li>Store the xgboost model</li>\n</ol>\n\n<p>Is this correct steps to do?</p>\n",
                "tags": "<machine-learning><classification><xgboost>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16704",
            "_score": 6.0579834,
            "_source": {
                "title": "Trying to get shannon entropy of image in tensorflow 2.0",
                "content": "Trying to get shannon entropy of image in tensorflow 2.0 <p>I'm trying to incorporate the shannon entropy of an image in my custom loss function in tensorflow. I tried to just find a function that does that in tensorflow and I found tfp.distributions.Distributions.entropy but when I do that, it gives me an error:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>    'tensorflow.python.framework.ops.EagerTensor' object has no attribute \n    '_name_and_control_scope'\n</code></pre>\n\n<p>and I don't know what that means and how I can fix the error.\nThe second thing I tried to do was just build the entropy function myself, and it works but I have an issue. First I'll give you the code:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>  def entropy(pic):\n  entropy_pic=tf.convert_to_tensor(pic,dtype=tf.float32)\n  h=100\n  w=100\n  flat_pic=tf.reshape(entropy_pic,(h*w,))\n  flat_pic=my_tf_round(flat_pic,3)\n  y,idx,count=tf.unique_with_counts(flat_pic,out_idx=tf.dtypes.int32)\n  tot=h*w\n  entropyy=0\n  for i in range(y.shape[0]):\n    p=tf.math.divide(count[i],tot)\n    p=tf.cast(p,dtype=tf.float32)\n    lg=tf.math.log(p)\n    lg=tf.cast(lg,dtype=tf.float32)\n    mult=tf.math.multiply(p,lg)\n    mult=tf.cast(mult,dtype=tf.float32)\n    entropyy=tf.math.subtract(entropyy,mult)\n  return entropyy\n</code></pre>\n\n<p>But when I try to compile my model as so:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>    model.compile(optimizer='rmsprop',loss=dl_tf_loss)\n</code></pre>\n\n<p>The loss function uses the entropy function, and in the entropy function I use tf.shape(y)[0] but when it compiles my model, it checks the loss function with a dynamic tensor and when I run the unique_with_counts function on an already dynamic tensor (with shape None,100,100,1) the y is a dynamic tensor of shape (None) and I can't use tf.shape(y)[0] and I don't know how to go around it.</p>\n\n<p>Also, I know that especially in tensorflow 2.0 I can just do the function in numpy and then change it back to a tensor with either the comman tf.conver_to_tensor or just use the tf.py_func function but I'm scared that when I try to train my model, it won't be able to automatically compute the gradient if my loss is not completely in tensorflow. If you disagree or know otherwise, I would love to hear it and of course also if you have an answer to my problem.</p>\n\n<p>Thanks!</p>\n <deep-learning><tensorflow><loss-function>",
                "codes": [],
                "question_id:": "54683",
                "question_votes:": "",
                "question_text:": "<p>I'm trying to incorporate the shannon entropy of an image in my custom loss function in tensorflow. I tried to just find a function that does that in tensorflow and I found tfp.distributions.Distributions.entropy but when I do that, it gives me an error:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>    'tensorflow.python.framework.ops.EagerTensor' object has no attribute \n    '_name_and_control_scope'\n</code></pre>\n\n<p>and I don't know what that means and how I can fix the error.\nThe second thing I tried to do was just build the entropy function myself, and it works but I have an issue. First I'll give you the code:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>  def entropy(pic):\n  entropy_pic=tf.convert_to_tensor(pic,dtype=tf.float32)\n  h=100\n  w=100\n  flat_pic=tf.reshape(entropy_pic,(h*w,))\n  flat_pic=my_tf_round(flat_pic,3)\n  y,idx,count=tf.unique_with_counts(flat_pic,out_idx=tf.dtypes.int32)\n  tot=h*w\n  entropyy=0\n  for i in range(y.shape[0]):\n    p=tf.math.divide(count[i],tot)\n    p=tf.cast(p,dtype=tf.float32)\n    lg=tf.math.log(p)\n    lg=tf.cast(lg,dtype=tf.float32)\n    mult=tf.math.multiply(p,lg)\n    mult=tf.cast(mult,dtype=tf.float32)\n    entropyy=tf.math.subtract(entropyy,mult)\n  return entropyy\n</code></pre>\n\n<p>But when I try to compile my model as so:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>    model.compile(optimizer='rmsprop',loss=dl_tf_loss)\n</code></pre>\n\n<p>The loss function uses the entropy function, and in the entropy function I use tf.shape(y)[0] but when it compiles my model, it checks the loss function with a dynamic tensor and when I run the unique_with_counts function on an already dynamic tensor (with shape None,100,100,1) the y is a dynamic tensor of shape (None) and I can't use tf.shape(y)[0] and I don't know how to go around it.</p>\n\n<p>Also, I know that especially in tensorflow 2.0 I can just do the function in numpy and then change it back to a tensor with either the comman tf.conver_to_tensor or just use the tf.py_func function but I'm scared that when I try to train my model, it won't be able to automatically compute the gradient if my loss is not completely in tensorflow. If you disagree or know otherwise, I would love to hear it and of course also if you have an answer to my problem.</p>\n\n<p>Thanks!</p>\n",
                "tags": "<deep-learning><tensorflow><loss-function>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11838",
            "_score": 6.017043,
            "_source": {
                "title": "How to apply class weight to a multi-output model?",
                "content": "How to apply class weight to a multi-output model? <p>I have a model with 2 categorical outputs.<br>\nThe first output layer can predict 2 classes: <em>[0, 1]</em><br>\nand the second output layer can predict 3 classes: <em>[0, 1, 2]</em>.</p>\n\n<p>How can I apply different class weight dictionaries for each of the outputs?  </p>\n\n<p>For example, how could I apply the dictionary <code>{0: 1, 1: 10}</code> to the first output,<br>\nand <code>{0: 5, 1: 1, 2: 10}</code> to the second output?</p>\n\n<p>I've tried to use the following class weights dictionary<br>\n<code>weight_class={'output1': {0: 1, 1: 10}, 'output2': {0: 5, 1: 1, 2: 10}}</code><br>\nBut the code fails with an error.</p>\n\n<p>My script also runs normally when i remove the <code>class_weight</code> parameter</p>\n\n<h2>Code Example</h2>\n\n<p>I've created a minimal example that reproduces the error</p>\n\n<pre><code>from tensorflow.python.keras.models import Model\nfrom tensorflow.python.keras.layers import Input, Dense\nfrom tensorflow.python.data import Dataset\nimport tensorflow as tf\nimport numpy as np\n\n\ndef preprocess_sample(features, labels):\n    label1, label2 = labels\n    label1 = tf.one_hot(label1, 2)\n    label2 = tf.one_hot(label2, 3)\n    return features, (label1, label2)\n\n\nbatch_size = 32\n\nnum_samples = 1000\nnum_features = 10\n\nfeatures = np.random.rand(num_samples, num_features)\nlabels1 = np.random.randint(2, size=num_samples)\nlabels2 = np.random.randint(3, size=num_samples)\n\ntrain = Dataset.from_tensor_slices((features, (labels1, labels2))).map(preprocess_sample).batch(batch_size).repeat()\n\n# Model\ninputs = Input(shape=(num_features, ))\noutput1 = Dense(2, activation='softmax', name='output1')(inputs)\noutput2 = Dense(3, activation='softmax', name='output2')(inputs)\nmodel = Model(inputs, [output1, output2])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\nclass_weights = {'output1': {0: 1, 1: 10}, 'output2': {0: 5, 1: 1, 2: 10}}\nmodel.fit(train, epochs=10, steps_per_epoch=num_samples // batch_size,\n          # class_weight=class_weights\n          )\n</code></pre>\n\n<p>This code runs successfully without the <code>class_weight</code> parameter.<br>\nBut when you add the <code>class_weight</code> parameter by uncommenting the line<br>\n<code># class_weight=class_weights</code> than the script fails with the following error:  </p>\n\n<pre><code>Traceback (most recent call last):\n  File \"test.py\", line 35, in &lt;module&gt;\n    class_weight=class_weights\n  File \"venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1536, in fit\n    validation_split=validation_split)\n  File \"venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 992, in _standardize_user_data\n    class_weight, batch_size)\n  File \"venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1165, in _standardize_weights\n    feed_sample_weight_modes)\n  File \"venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1164, in &lt;listcomp&gt;\n    for (ref, sw, cw, mode) in zip(y, sample_weights, class_weights,\n  File \"venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\", line 717, in standardize_weights\n    y_classes = np.argmax(y, axis=1)\n  File \"venv/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 1004, in argmax\n    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n  File \"venv/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 62, in _wrapfunc\n    return _wrapit(obj, method, *args, **kwds)\n  File \"venv/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 42, in _wrapit\n    result = getattr(asarray(obj), method)(*args, **kwds)\nnumpy.core._internal.AxisError: axis 1 is out of bounds for array of dimension 1\n</code></pre>\n\n<h1>Edit</h1>\n\n<p>I've also opened an <a href=\"https://github.com/keras-team/keras/issues/11735\" rel=\"nofollow noreferrer\">issue</a> in the Keras github page, but i wanted to ask the same question here to see if perhaps i'm missing something and doing something wrong.</p>\n <neural-network><keras><multiclass-classification><beginner><weighted-data><p>I wansn't able to use the <code>class_weight</code> parameter yet, but in the mean time i've found another way to apply class weighting to each output layer.  </p>\n\n<h2>Current solution</h2>\n\n<p>In <a href=\"https://github.com/keras-team/keras/issues/2115\" rel=\"nofollow noreferrer\">this</a> keras issue they have supplied an easy method to apply class weights via a custom loss that implements the required class weighing.</p>\n\n<pre><code>def weighted_categorical_crossentropy(y_true, y_pred, weights):\n    nb_cl = len(weights)\n    final_mask = K.zeros_like(y_pred[:, 0])\n    y_pred_max = K.max(y_pred, axis=1)\n    y_pred_max = K.reshape(y_pred_max, (K.shape(y_pred)[0], 1))\n    y_pred_max_mat = K.cast(K.equal(y_pred, y_pred_max), K.floatx())\n    for c_p, c_t in product(range(nb_cl), range(nb_cl)):\n        final_mask += (weights[c_t, c_p] * y_pred_max_mat[:, c_p] * y_true[:, c_t])\n    return K.categorical_crossentropy(y_pred, y_true) * final_mask\n</code></pre>\n\n<p>where <code>weights</code> is a <code>CxC</code> matrix (where <code>C</code> is the number of classes) that defines the class weights.<br>\nMore precisely, <code>weights[i, j]</code> defines the weight for an example of class <em>i</em> which was falsely classified as class <em>j</em>.</p>\n\n<h3>So how do we use it?</h3>\n\n<p>Keras allows to assign a loss function for each output.<br>\nso we could assign each output a loss fucntion with the correct <code>weights</code> matrix.  </p>\n\n<p>For example, to satisfy the request i made in the question we could suggest the following code.</p>\n\n<pre><code># Define the weight matrices\nw1 = np.ones((2, 2))\nw1[1, 0] = 10\nw1[1, 1] = 10\n\nw2 = np.ones((3, 3))\nw2[0, 0] = 5\nw2[0, 1] = 5\nw2[0, 2] = 5\nw2[2, 0] = 10\nw2[2, 1] = 10\nw2[2, 2] = 10    \n\n# Define the weighted loss functions\nfrom functools import partial\nloss1 = partial(weighted_categorical_crossentropy, weights=w1)\nloss2 = partial(weighted_categorical_crossentropy, weights=w2)\n\n# Finally, apply the loss functions to the outputs\nmodel.compile(loss={'output1': loss1, 'output2': loss2}, optimizer='adam')\n</code></pre>\n\n<p>And that accomplishes the request :)</p>\n\n<h2>Edit</h2>\n\n<p>There is a small edition that needs to be made.<br>\nThe loss functions must have a name, so we can supply this with the following:</p>\n\n<pre><code>loss1.__name__ = 'loss1'\nloss2.__name__ = 'loss2'\n</code></pre>\n",
                "codes": [
                    [
                        "def weighted_categorical_crossentropy(y_true, y_pred, weights):\n    nb_cl = len(weights)\n    final_mask = K.zeros_like(y_pred[:, 0])\n    y_pred_max = K.max(y_pred, axis=1)\n    y_pred_max = K.reshape(y_pred_max, (K.shape(y_pred)[0], 1))\n    y_pred_max_mat = K.cast(K.equal(y_pred, y_pred_max), K.floatx())\n    for c_p, c_t in product(range(nb_cl), range(nb_cl)):\n        final_mask += (weights[c_t, c_p] * y_pred_max_mat[:, c_p] * y_true[:, c_t])\n    return K.categorical_crossentropy(y_pred, y_true) * final_mask\n",
                        "# Define the weight matrices\nw1 = np.ones((2, 2))\nw1[1, 0] = 10\nw1[1, 1] = 10\n\nw2 = np.ones((3, 3))\nw2[0, 0] = 5\nw2[0, 1] = 5\nw2[0, 2] = 5\nw2[2, 0] = 10\nw2[2, 1] = 10\nw2[2, 2] = 10    \n\n# Define the weighted loss functions\nfrom functools import partial\nloss1 = partial(weighted_categorical_crossentropy, weights=w1)\nloss2 = partial(weighted_categorical_crossentropy, weights=w2)\n\n# Finally, apply the loss functions to the outputs\nmodel.compile(loss={'output1': loss1, 'output2': loss2}, optimizer='adam')\n",
                        "loss1.__name__ = 'loss1'\nloss2.__name__ = 'loss2'\n"
                    ]
                ],
                "question_id:": "41698",
                "question_votes:": "2",
                "question_text:": "<p>I have a model with 2 categorical outputs.<br>\nThe first output layer can predict 2 classes: <em>[0, 1]</em><br>\nand the second output layer can predict 3 classes: <em>[0, 1, 2]</em>.</p>\n\n<p>How can I apply different class weight dictionaries for each of the outputs?  </p>\n\n<p>For example, how could I apply the dictionary <code>{0: 1, 1: 10}</code> to the first output,<br>\nand <code>{0: 5, 1: 1, 2: 10}</code> to the second output?</p>\n\n<p>I've tried to use the following class weights dictionary<br>\n<code>weight_class={'output1': {0: 1, 1: 10}, 'output2': {0: 5, 1: 1, 2: 10}}</code><br>\nBut the code fails with an error.</p>\n\n<p>My script also runs normally when i remove the <code>class_weight</code> parameter</p>\n\n<h2>Code Example</h2>\n\n<p>I've created a minimal example that reproduces the error</p>\n\n<pre><code>from tensorflow.python.keras.models import Model\nfrom tensorflow.python.keras.layers import Input, Dense\nfrom tensorflow.python.data import Dataset\nimport tensorflow as tf\nimport numpy as np\n\n\ndef preprocess_sample(features, labels):\n    label1, label2 = labels\n    label1 = tf.one_hot(label1, 2)\n    label2 = tf.one_hot(label2, 3)\n    return features, (label1, label2)\n\n\nbatch_size = 32\n\nnum_samples = 1000\nnum_features = 10\n\nfeatures = np.random.rand(num_samples, num_features)\nlabels1 = np.random.randint(2, size=num_samples)\nlabels2 = np.random.randint(3, size=num_samples)\n\ntrain = Dataset.from_tensor_slices((features, (labels1, labels2))).map(preprocess_sample).batch(batch_size).repeat()\n\n# Model\ninputs = Input(shape=(num_features, ))\noutput1 = Dense(2, activation='softmax', name='output1')(inputs)\noutput2 = Dense(3, activation='softmax', name='output2')(inputs)\nmodel = Model(inputs, [output1, output2])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\nclass_weights = {'output1': {0: 1, 1: 10}, 'output2': {0: 5, 1: 1, 2: 10}}\nmodel.fit(train, epochs=10, steps_per_epoch=num_samples // batch_size,\n          # class_weight=class_weights\n          )\n</code></pre>\n\n<p>This code runs successfully without the <code>class_weight</code> parameter.<br>\nBut when you add the <code>class_weight</code> parameter by uncommenting the line<br>\n<code># class_weight=class_weights</code> than the script fails with the following error:  </p>\n\n<pre><code>Traceback (most recent call last):\n  File \"test.py\", line 35, in &lt;module&gt;\n    class_weight=class_weights\n  File \"venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1536, in fit\n    validation_split=validation_split)\n  File \"venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 992, in _standardize_user_data\n    class_weight, batch_size)\n  File \"venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1165, in _standardize_weights\n    feed_sample_weight_modes)\n  File \"venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1164, in &lt;listcomp&gt;\n    for (ref, sw, cw, mode) in zip(y, sample_weights, class_weights,\n  File \"venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\", line 717, in standardize_weights\n    y_classes = np.argmax(y, axis=1)\n  File \"venv/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 1004, in argmax\n    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n  File \"venv/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 62, in _wrapfunc\n    return _wrapit(obj, method, *args, **kwds)\n  File \"venv/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 42, in _wrapit\n    result = getattr(asarray(obj), method)(*args, **kwds)\nnumpy.core._internal.AxisError: axis 1 is out of bounds for array of dimension 1\n</code></pre>\n\n<h1>Edit</h1>\n\n<p>I've also opened an <a href=\"https://github.com/keras-team/keras/issues/11735\" rel=\"nofollow noreferrer\">issue</a> in the Keras github page, but i wanted to ask the same question here to see if perhaps i'm missing something and doing something wrong.</p>\n",
                "tags": "<neural-network><keras><multiclass-classification><beginner><weighted-data>",
                "answers": [
                    [
                        "41752",
                        "2",
                        "41698",
                        "",
                        "",
                        "<p>I wansn't able to use the <code>class_weight</code> parameter yet, but in the mean time i've found another way to apply class weighting to each output layer.  </p>\n\n<h2>Current solution</h2>\n\n<p>In <a href=\"https://github.com/keras-team/keras/issues/2115\" rel=\"nofollow noreferrer\">this</a> keras issue they have supplied an easy method to apply class weights via a custom loss that implements the required class weighing.</p>\n\n<pre><code>def weighted_categorical_crossentropy(y_true, y_pred, weights):\n    nb_cl = len(weights)\n    final_mask = K.zeros_like(y_pred[:, 0])\n    y_pred_max = K.max(y_pred, axis=1)\n    y_pred_max = K.reshape(y_pred_max, (K.shape(y_pred)[0], 1))\n    y_pred_max_mat = K.cast(K.equal(y_pred, y_pred_max), K.floatx())\n    for c_p, c_t in product(range(nb_cl), range(nb_cl)):\n        final_mask += (weights[c_t, c_p] * y_pred_max_mat[:, c_p] * y_true[:, c_t])\n    return K.categorical_crossentropy(y_pred, y_true) * final_mask\n</code></pre>\n\n<p>where <code>weights</code> is a <code>CxC</code> matrix (where <code>C</code> is the number of classes) that defines the class weights.<br>\nMore precisely, <code>weights[i, j]</code> defines the weight for an example of class <em>i</em> which was falsely classified as class <em>j</em>.</p>\n\n<h3>So how do we use it?</h3>\n\n<p>Keras allows to assign a loss function for each output.<br>\nso we could assign each output a loss fucntion with the correct <code>weights</code> matrix.  </p>\n\n<p>For example, to satisfy the request i made in the question we could suggest the following code.</p>\n\n<pre><code># Define the weight matrices\nw1 = np.ones((2, 2))\nw1[1, 0] = 10\nw1[1, 1] = 10\n\nw2 = np.ones((3, 3))\nw2[0, 0] = 5\nw2[0, 1] = 5\nw2[0, 2] = 5\nw2[2, 0] = 10\nw2[2, 1] = 10\nw2[2, 2] = 10    \n\n# Define the weighted loss functions\nfrom functools import partial\nloss1 = partial(weighted_categorical_crossentropy, weights=w1)\nloss2 = partial(weighted_categorical_crossentropy, weights=w2)\n\n# Finally, apply the loss functions to the outputs\nmodel.compile(loss={'output1': loss1, 'output2': loss2}, optimizer='adam')\n</code></pre>\n\n<p>And that accomplishes the request :)</p>\n\n<h2>Edit</h2>\n\n<p>There is a small edition that needs to be made.<br>\nThe loss functions must have a name, so we can supply this with the following:</p>\n\n<pre><code>loss1.__name__ = 'loss1'\nloss2.__name__ = 'loss2'\n</code></pre>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6220",
            "_score": 6.002393,
            "_source": {
                "title": "Prediction interval around LSTM time series forecast",
                "content": "Prediction interval around LSTM time series forecast <p>Is there a method to calculate the prediction interval (probability distribution) around a time series forecast from an LSTM (or other recurrent) neural network? </p>\n\n<p>Say, for example, I am predicting 10 samples into the future (t+1 to t+10), based on the last 10 observed samples (t-9 to t), I would expect the prediction at t+1 to be more accurate than the prediction at t+10. Typically, one might draw error bars around the prediction to show the interval. With an ARIMA model (under the assumption of normally distributed errors), I can calculate a prediction interval (e.g. 95%) around each predicted value. Can I calculate the same, (or something that relates to the prediction interval) from an LSTM model?</p>\n\n<p>I'm been working with LSTMs in Keras/Python, following lots of examples from <a href=\"https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\" rel=\"noreferrer\">machinelearningmastery.com</a>, from which my example code (below) is based on. I'm considering reframing the problem as classification into discrete bins, as that produces a confidence per class, but that seems a poor solution.</p>\n\n<p>There are a couple of similar topics (such as the below), but nothing seems to directly address the issue of prediction intervals from LSTM (or indeed other) neural networks:</p>\n\n<p><a href=\"https://stats.stackexchange.com/questions/25055/how-to-calculate-the-confidence-interval-for-time-series-prediction\">https://stats.stackexchange.com/questions/25055/how-to-calculate-the-confidence-interval-for-time-series-prediction</a></p>\n\n<p><a href=\"https://datascience.stackexchange.com/questions/12721/time-series-prediction-using-arima-vs-lstm\">Time series prediction using ARIMA vs LSTM</a></p>\n\n<pre><code>from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom math import sin\nfrom matplotlib import pyplot\nimport numpy as np\n\n# Build an LSTM network and train\ndef fit_lstm(X, y, batch_size, nb_epoch, neurons):\n    X = X.reshape(X.shape[0], 1, X.shape[1]) # add in another dimension to the X data\n    y = y.reshape(y.shape[0], y.shape[1])      # but don't add it to the y, as Dense has to be 1d?\n    model = Sequential()\n    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n    model.add(Dense(y.shape[1]))\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    for i in range(nb_epoch):\n        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n        model.reset_states()\n    return model\n\n# Configuration\nn = 5000    # total size of dataset\nSLIDING_WINDOW_LENGTH = 30\nSLIDING_WINDOW_STEP_SIZE = 1\nbatch_size = 10\ntest_size = 0.1 # fraction of dataset to hold back for testing\nnb_epochs = 100 # for training\nneurons = 8 # LSTM layer complexity\n\n# create dataset\n#raw_values = [sin(i/2) for i in range(n)]  # simple sine wave\nraw_values = [sin(i/2)+sin(i/6)+sin(i/36)+np.random.uniform(-1,1) for i in range(n)]  # double sine with noise\n#raw_values = [(i%4) for i in range(n)] # saw tooth\n\nall_data = np.array(raw_values).reshape(-1,1) # make into array, add anothe dimension for sci-kit compatibility\n\n# data is segmented using a sliding window mechanism\nall_data_windowed = [np.transpose(all_data[idx:idx+SLIDING_WINDOW_LENGTH]) for idx in np.arange(0,len(all_data)-SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP_SIZE)]\nall_data_windowed = np.concatenate(all_data_windowed, axis=0).astype(np.float32)\n\n# split data into train and test-sets\n# round datasets down to a multiple of the batch size\ntest_length = int(round((len(all_data_windowed) * test_size) / batch_size) * batch_size)\ntrain, test = all_data_windowed[:-test_length,:], all_data_windowed[-test_length:,:]\ntrain_length = int(np.floor(train.shape[0] / batch_size)*batch_size) \ntrain = train[:train_length,...]\n\nhalf_size = int(SLIDING_WINDOW_LENGTH/2) # split the examples half-half, to forecast the second half\nX_train, y_train = train[:,:half_size], train[:,half_size:]\nX_test, y_test = test[:,:half_size], test[:,half_size:]\n\n# fit the model\nlstm_model = fit_lstm(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epochs, neurons=neurons)\n\n# forecast the entire training dataset to build up state for forecasting\nX_train_reshaped = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\nlstm_model.predict(X_train_reshaped, batch_size=batch_size)\n\n# predict from test dataset\nX_test_reshaped = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\nyhat = lstm_model.predict(X_test_reshaped, batch_size=batch_size)\n\n#%% Plot prediction vs actual\n\nx_axis_input = range(half_size)\nx_axis_output = [x_axis_input[-1]] + list(half_size+np.array(range(half_size)))\n\nfig = pyplot.figure()\nax = fig.add_subplot(111)\nline1, = ax.plot(x_axis_input,np.zeros_like(x_axis_input), 'r-')\nline2, = ax.plot(x_axis_output,np.zeros_like(x_axis_output), 'o-')\nline3, = ax.plot(x_axis_output,np.zeros_like(x_axis_output), 'g-')\nax.set_xlim(np.min(x_axis_input),np.max(x_axis_output))\nax.set_ylim(-4,4)\npyplot.legend(('Input','Actual','Predicted'),loc='upper left')\npyplot.show()\n\n# update plot in a loop\nfor idx in range(y_test.shape[0]):\n\n    sample_input = X_test[idx]\n    sample_truth = [sample_input[-1]] + list(y_test[idx]) # join lists\n    sample_predicted = [sample_input[-1]] + list(yhat[idx])\n\n    line1.set_ydata(sample_input)\n    line2.set_ydata(sample_truth)\n    line3.set_ydata(sample_predicted)\n    fig.canvas.draw()\n    fig.canvas.flush_events()\n\n    pyplot.pause(.25)\n</code></pre>\n <machine-learning><deep-learning><time-series><prediction><lstm><p><strong>Conformal Prediction</strong> as a buzz word might be interesting for you because it works under many conditions - in particular it does not need normal distributed error and it works for almost any machine learning model. </p>\n\n<p>Two nice introductions are given by \n<a href=\"https://scottlocklin.wordpress.com/2016/12/05/predicting-with-confidence-the-best-machine-learning-idea-you-never-heard-of/\" rel=\"nofollow noreferrer\">Scott Locklin</a> and <a href=\"http://clrc.rhul.ac.uk/copa2017/presentations/CP_Tutorial_2017.pdf\" rel=\"nofollow noreferrer\">Henrik Linusson</a>.</p>\n<p>Directly, this is not possible. However, if you model it in a different way you can get out confidence intervals. You could instead of a normal regression approach it as estimating a continuous probability distribution. By doing this for every step you can plot your distribution. Ways to do this are Kernel Mixture Networks (<a href=\"https://janvdvegt.github.io/2017/06/07/Kernel-Mixture-Networks.html\" rel=\"noreferrer\">https://janvdvegt.github.io/2017/06/07/Kernel-Mixture-Networks.html</a>, disclosure, my blog) or Density Mixture Networks (<a href=\"http://www.cedar.buffalo.edu/~srihari/CSE574/Chap5/Chap5.7-MixDensityNetworks.pdf\" rel=\"noreferrer\">http://www.cedar.buffalo.edu/~srihari/CSE574/Chap5/Chap5.7-MixDensityNetworks.pdf</a>), the first uses kernels as base and estimates a mixture over these Kernels and the second one estimates a mixture of distributions, including the parameters of each of the distributions. You use the log likelihood for training the model.</p>\n\n<p>Another option for modeling the uncertainty is to use dropout during training and then also during inference. You do this multiple times and every time you get a sample from your posterior. You don't get distributions, only samples, but it's the easiest to implement and it works very well.</p>\n\n<p>In your case you have to think about the way you generate t+2 up to t+10. Depending on your current setup you might have to sample from the previous time step and feed that for the next one. That doesn't work very well with the first approach, nor with the second. If you have 10 outputs per time step (t+1 up to t+10) then all of these approaches are more clean but a bit less intuitive.</p>\n<p>I am going to diverge a little bit and argue that calculation confidence interval is in practice is usually not a valuable thing to do. The reason is there is always a whole bunch of assumptions you need to make. Even for the simplest linear regression, you need to have</p>\n\n<ul>\n<li>Linear relationship. </li>\n<li>Multivariate normality. </li>\n<li>No or little multicollinearity. </li>\n<li>No auto-correlation. </li>\n<li>Homoscedasticity.</li>\n</ul>\n\n<p>A much more pragmatic approach is to do a Monte Carlo simulation. If you already know or willing to make of assumption around the distribution of your input variables, take a whole bunch of sample and feed it to you LSTM, now you can empirically calculate your \"confidence interval\". </p>\n<p>Yes, you can. The only thing you need to change is the loss function. Implement the loss function used in quantile regression and integrate it. Also, you want to take a look at how you evaluate those intervals. For that, I would use ICP, MIL and RMIL metrics. </p>\n",
                "codes": [
                    [],
                    [],
                    [],
                    []
                ],
                "question_id:": "24403",
                "question_votes:": "12",
                "question_text:": "<p>Is there a method to calculate the prediction interval (probability distribution) around a time series forecast from an LSTM (or other recurrent) neural network? </p>\n\n<p>Say, for example, I am predicting 10 samples into the future (t+1 to t+10), based on the last 10 observed samples (t-9 to t), I would expect the prediction at t+1 to be more accurate than the prediction at t+10. Typically, one might draw error bars around the prediction to show the interval. With an ARIMA model (under the assumption of normally distributed errors), I can calculate a prediction interval (e.g. 95%) around each predicted value. Can I calculate the same, (or something that relates to the prediction interval) from an LSTM model?</p>\n\n<p>I'm been working with LSTMs in Keras/Python, following lots of examples from <a href=\"https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\" rel=\"noreferrer\">machinelearningmastery.com</a>, from which my example code (below) is based on. I'm considering reframing the problem as classification into discrete bins, as that produces a confidence per class, but that seems a poor solution.</p>\n\n<p>There are a couple of similar topics (such as the below), but nothing seems to directly address the issue of prediction intervals from LSTM (or indeed other) neural networks:</p>\n\n<p><a href=\"https://stats.stackexchange.com/questions/25055/how-to-calculate-the-confidence-interval-for-time-series-prediction\">https://stats.stackexchange.com/questions/25055/how-to-calculate-the-confidence-interval-for-time-series-prediction</a></p>\n\n<p><a href=\"https://datascience.stackexchange.com/questions/12721/time-series-prediction-using-arima-vs-lstm\">Time series prediction using ARIMA vs LSTM</a></p>\n\n<pre><code>from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom math import sin\nfrom matplotlib import pyplot\nimport numpy as np\n\n# Build an LSTM network and train\ndef fit_lstm(X, y, batch_size, nb_epoch, neurons):\n    X = X.reshape(X.shape[0], 1, X.shape[1]) # add in another dimension to the X data\n    y = y.reshape(y.shape[0], y.shape[1])      # but don't add it to the y, as Dense has to be 1d?\n    model = Sequential()\n    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n    model.add(Dense(y.shape[1]))\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    for i in range(nb_epoch):\n        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n        model.reset_states()\n    return model\n\n# Configuration\nn = 5000    # total size of dataset\nSLIDING_WINDOW_LENGTH = 30\nSLIDING_WINDOW_STEP_SIZE = 1\nbatch_size = 10\ntest_size = 0.1 # fraction of dataset to hold back for testing\nnb_epochs = 100 # for training\nneurons = 8 # LSTM layer complexity\n\n# create dataset\n#raw_values = [sin(i/2) for i in range(n)]  # simple sine wave\nraw_values = [sin(i/2)+sin(i/6)+sin(i/36)+np.random.uniform(-1,1) for i in range(n)]  # double sine with noise\n#raw_values = [(i%4) for i in range(n)] # saw tooth\n\nall_data = np.array(raw_values).reshape(-1,1) # make into array, add anothe dimension for sci-kit compatibility\n\n# data is segmented using a sliding window mechanism\nall_data_windowed = [np.transpose(all_data[idx:idx+SLIDING_WINDOW_LENGTH]) for idx in np.arange(0,len(all_data)-SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP_SIZE)]\nall_data_windowed = np.concatenate(all_data_windowed, axis=0).astype(np.float32)\n\n# split data into train and test-sets\n# round datasets down to a multiple of the batch size\ntest_length = int(round((len(all_data_windowed) * test_size) / batch_size) * batch_size)\ntrain, test = all_data_windowed[:-test_length,:], all_data_windowed[-test_length:,:]\ntrain_length = int(np.floor(train.shape[0] / batch_size)*batch_size) \ntrain = train[:train_length,...]\n\nhalf_size = int(SLIDING_WINDOW_LENGTH/2) # split the examples half-half, to forecast the second half\nX_train, y_train = train[:,:half_size], train[:,half_size:]\nX_test, y_test = test[:,:half_size], test[:,half_size:]\n\n# fit the model\nlstm_model = fit_lstm(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epochs, neurons=neurons)\n\n# forecast the entire training dataset to build up state for forecasting\nX_train_reshaped = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\nlstm_model.predict(X_train_reshaped, batch_size=batch_size)\n\n# predict from test dataset\nX_test_reshaped = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\nyhat = lstm_model.predict(X_test_reshaped, batch_size=batch_size)\n\n#%% Plot prediction vs actual\n\nx_axis_input = range(half_size)\nx_axis_output = [x_axis_input[-1]] + list(half_size+np.array(range(half_size)))\n\nfig = pyplot.figure()\nax = fig.add_subplot(111)\nline1, = ax.plot(x_axis_input,np.zeros_like(x_axis_input), 'r-')\nline2, = ax.plot(x_axis_output,np.zeros_like(x_axis_output), 'o-')\nline3, = ax.plot(x_axis_output,np.zeros_like(x_axis_output), 'g-')\nax.set_xlim(np.min(x_axis_input),np.max(x_axis_output))\nax.set_ylim(-4,4)\npyplot.legend(('Input','Actual','Predicted'),loc='upper left')\npyplot.show()\n\n# update plot in a loop\nfor idx in range(y_test.shape[0]):\n\n    sample_input = X_test[idx]\n    sample_truth = [sample_input[-1]] + list(y_test[idx]) # join lists\n    sample_predicted = [sample_input[-1]] + list(yhat[idx])\n\n    line1.set_ydata(sample_input)\n    line2.set_ydata(sample_truth)\n    line3.set_ydata(sample_predicted)\n    fig.canvas.draw()\n    fig.canvas.flush_events()\n\n    pyplot.pause(.25)\n</code></pre>\n",
                "tags": "<machine-learning><deep-learning><time-series><prediction><lstm>",
                "answers": [
                    [
                        "31629",
                        "2",
                        "24403",
                        "",
                        "",
                        "<p><strong>Conformal Prediction</strong> as a buzz word might be interesting for you because it works under many conditions - in particular it does not need normal distributed error and it works for almost any machine learning model. </p>\n\n<p>Two nice introductions are given by \n<a href=\"https://scottlocklin.wordpress.com/2016/12/05/predicting-with-confidence-the-best-machine-learning-idea-you-never-heard-of/\" rel=\"nofollow noreferrer\">Scott Locklin</a> and <a href=\"http://clrc.rhul.ac.uk/copa2017/presentations/CP_Tutorial_2017.pdf\" rel=\"nofollow noreferrer\">Henrik Linusson</a>.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "24404",
                        "2",
                        "24403",
                        "",
                        "",
                        "<p>Directly, this is not possible. However, if you model it in a different way you can get out confidence intervals. You could instead of a normal regression approach it as estimating a continuous probability distribution. By doing this for every step you can plot your distribution. Ways to do this are Kernel Mixture Networks (<a href=\"https://janvdvegt.github.io/2017/06/07/Kernel-Mixture-Networks.html\" rel=\"noreferrer\">https://janvdvegt.github.io/2017/06/07/Kernel-Mixture-Networks.html</a>, disclosure, my blog) or Density Mixture Networks (<a href=\"http://www.cedar.buffalo.edu/~srihari/CSE574/Chap5/Chap5.7-MixDensityNetworks.pdf\" rel=\"noreferrer\">http://www.cedar.buffalo.edu/~srihari/CSE574/Chap5/Chap5.7-MixDensityNetworks.pdf</a>), the first uses kernels as base and estimates a mixture over these Kernels and the second one estimates a mixture of distributions, including the parameters of each of the distributions. You use the log likelihood for training the model.</p>\n\n<p>Another option for modeling the uncertainty is to use dropout during training and then also during inference. You do this multiple times and every time you get a sample from your posterior. You don't get distributions, only samples, but it's the easiest to implement and it works very well.</p>\n\n<p>In your case you have to think about the way you generate t+2 up to t+10. Depending on your current setup you might have to sample from the previous time step and feed that for the next one. That doesn't work very well with the first approach, nor with the second. If you have 10 outputs per time step (t+1 up to t+10) then all of these approaches are more clean but a bit less intuitive.</p>\n",
                        "",
                        "8"
                    ],
                    [
                        "24434",
                        "2",
                        "24403",
                        "",
                        "",
                        "<p>I am going to diverge a little bit and argue that calculation confidence interval is in practice is usually not a valuable thing to do. The reason is there is always a whole bunch of assumptions you need to make. Even for the simplest linear regression, you need to have</p>\n\n<ul>\n<li>Linear relationship. </li>\n<li>Multivariate normality. </li>\n<li>No or little multicollinearity. </li>\n<li>No auto-correlation. </li>\n<li>Homoscedasticity.</li>\n</ul>\n\n<p>A much more pragmatic approach is to do a Monte Carlo simulation. If you already know or willing to make of assumption around the distribution of your input variables, take a whole bunch of sample and feed it to you LSTM, now you can empirically calculate your \"confidence interval\". </p>\n",
                        "",
                        "1"
                    ],
                    [
                        "27371",
                        "2",
                        "24403",
                        "",
                        "",
                        "<p>Yes, you can. The only thing you need to change is the loss function. Implement the loss function used in quantile regression and integrate it. Also, you want to take a look at how you evaluate those intervals. For that, I would use ICP, MIL and RMIL metrics. </p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17364",
            "_score": 6.002393,
            "_source": {
                "title": "Developing an encoder/decoder for image modification",
                "content": "Developing an encoder/decoder for image modification <p>On the project I am currently working on, my goal is to train a neural network to convert images of circles to ellipses in a way that models convolution/blurring in real imaging processes. </p>\n\n<p>What remains is to construct a neural network, preferably a CNN, that has the desired results - i.e. takes an image with circles as an input and returns an image with ellipses. However, I have not been able to do this. At best, neural nets (including CNNs) that I have used so far have at best returned blurred images of the circles. I can't tell whether it is the fault of the neural network or the fault of the preprocessing code I am using. </p>\n\n<p>Below, I will show you my code.</p>\n\n<p>First, importing the necessary modules:</p>\n\n<pre><code>import keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Activation, Reshape\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\nimport numpy as np\nimport pandas as pd\nfrom collections import OrderedDict\nimport itertools\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nimport math\nfrom math import sqrt\nfrom keras.models import Model, load_model\n</code></pre>\n\n<p>Next, creating and storing the input (circle) and output (ellipse) images:</p>\n\n<pre><code>def create_blank_image(size):\n    data = np.ndarray(shape=(size, size))\n    for i in range(0, size):\n        for j in range(0, size):\n            data[[i], [j]] = 0\n    #print(data)\n\n    return data\n\ndef circle_randomizer():\n    number_of_circles = random.randint(4,10)\n    intensity = np.ndarray(shape=(128, 128))\n    #print(number_of_circles)\n    radius_list = []\n\n\n    for i in range(number_of_circles):\n        radius_list.append(random.uniform(8, 10))\n    #print(radius_list)\n\n    center_coords = np.zeros((2,1))    \n    center_coords[[0],[0]] = random.uniform(0,size)\n    center_coords[[1],[0]] = random.uniform(0,size)\n\n    for i in range(number_of_circles):\n      #temp_array = np.ndarray(shape=(2,1))\n      #temp_array[[0],[0]] = random.uniform(0,size)\n      #temp_array[[1],[0]] = random.uniform(0,size)\n\n      if i &gt; 0:\n          j = 0\n          #print(i,j)\n          while j in range(i):\n              #print(i,j)\n              #print(center_coords)\n              temp_array = np.ndarray(shape=(2,1))\n              temp_array[[0],[0]] = random.uniform(0,size)\n              temp_array[[1],[0]] = random.uniform(0,size)\n              #while sqrt((center_coords[[0],[i]] - center_coords[[0],[j]])**2 + (center_coords[[1],[i]] - center_coords[[1],[j]])**2) &lt; radius_list[i] + radius_list[j]:\n              while sqrt((temp_array[[0],[0]] - center_coords[[0],[j]])**2 + (temp_array[[1],[0]] - center_coords[[1],[j]])**2) &lt; radius_list[i] + radius_list[j]:               \n                  temp_array[[0],[0]] = random.uniform(0,size)\n                  temp_array[[1],[0]] = random.uniform(0,size)\n                  j = 0\n              center_coords = np.concatenate((center_coords,temp_array), axis = 1)          \n              j = j + 1\n              #print('loop ran ' + str(j) + ' times')\n\n    return radius_list, center_coords\n\ndef image_creator(centers, radii, img_data, size):\n    x = np.arange(1, size, 1)\n    y = np.arange(1, size, 1)\n\n    for c in range(len(centers)):\n        x0 = centers[[c],[0]]\n        y0 = centers[[c],[1]]\n        radius = radii[c]\n        for i in range(0, size-1):\n            for j in range(0, size-1):\n                height2 = radius**2 - (x[i]-x0)**2 - (y[j]-y0)**2\n                if height2 &gt;= 0:\n                    img_data[[i], [j]] = sqrt(radius**2 - (x[i]-x0)**2 - (y[j]-y0)**2)\n\n    return img_data\n\ndef make_ellipses(size, radii, center_coords):\n    # idea: use a random number generator to create a random rotation of the x,y axes for the ellipse\n\n    # size is the length of a side of the square\n    # length is the length of the ellipse\n    # defined as equal to the radius of the circle later\n\n    my_label = np.ndarray(shape=(size, size))\n    x = np.arange(1, size, 1)\n    y = np.arange(1, size, 1)\n\n    # inefficiently zero the array\n    for i in range(0, size):\n        for j in range(0, size):\n            my_label[[i], [j]] = 0\n            # print(my_label)\n    for c in range(len(center_coords)):\n        x0 = center_coords[[c],[0]]\n        y0 = center_coords[[c],[1]]\n        #theta = random.uniform(0, 6.28318)\n        theta = 0.775\n\n        for i in range(0, size - 1):\n            for j in range(0, size - 1):\n                xprime = (x[i] - x0) * math.cos(theta) + (y[j] - y0) * math.sin(theta)\n                yprime = -(x[i] - x0) * math.sin(theta) + (y[j] - y0) * math.cos(theta)\n                height2 = (0.5 * radii[c]) ** 2 - 0.25 * xprime ** 2 - yprime ** 2\n                if height2 &gt;= 0:\n                    my_label[[i], [j]] = sqrt((0.5 * radii[c]) ** 2 - 0.25 * xprime ** 2 - yprime ** 2)\n\n    return my_label\n\nsize = 128\nradii, centers = circle_randomizer()\n#print(radii)\n#print(centers)\n\n#Make labels and samples consistent with rest of code\nN = 100\ncircle_images = []\nellipse_images = []\ncoords = []\nfor sample in range(0, N):\n    blank_image = create_blank_image(size)\n    radii, centers = circle_randomizer()\n    temp_image = image_creator(centers, radii, blank_image, size)\n    circle_images.append(temp_image)\n    temp_output = make_ellipses(size, radii, centers)\n    ellipse_images.append(temp_output)\n    coords.append(centers)\n#print(labels)\n#print(samples[0][40])\n</code></pre>\n\n<p>Storing the images in files:</p>\n\n<pre><code>filenames = []\nfor i in range(0,N):\n  np.save('ellipses_' + str(i) + '.npy', ellipse_images[i])\n  filenames.append('ellipses_' + str(i) + '.npy')\n  np.save('circles_' + str(i) + '.npy', circle_images[i])\ncircles_stack = np.stack(circle_images,axis=0)\nellipses_stack = np.stack(ellipse_images,axis=0)\nnp.save('ellipses_stack.npy', ellipses_stack)\nnp.save('circles_stack.npy', circles_stack)\n</code></pre>\n\n<p>Loading the images:</p>\n\n<pre><code># load training images and corresponding \"labels\"\n# training samples\ntraining_images_path = 'circles_stack.npy'\nlabels_path = 'ellipses_stack.npy'\n\nX = np.load(training_images_path,'r')/20.\ny = np.load(labels_path,'r')/20.\n</code></pre>\n\n<p>Defining the image preprocessing functions: (I'm not sure why preprocessing_X and preprocessing_y are different; this is code I've partially adopted from a research paper.)</p>\n\n<pre><code># Preprocessing for training images\ndef preprocessing_X(image_data, image_size):\n    image_data = image_data.reshape(image_data.shape[0], image_size[0], image_size[1], 1)\n    image_data = image_data.astype('float32')\n    image_data = (image_data - np.amin(image_data))/(np.amax(image_data) - np.amin(image_data))\n    return image_data\n\n\n\u200b\n# preprocessing for \"labels\" (ground truth)\ndef preprocessing_Y(image_data, image_size):\n    n_images = 0\n    label = np.array([])\n    for idx in range(image_data.shape[0]):\n        img = image_data[idx,:,:]\n        n, m = img.shape\n        img = np.array(OneHotEncoder(n_values=nb_classes).fit_transform(img.reshape(-1,1)).todense())\n        img = img.reshape(n, m, nb_classes)\n        label = np.append(label, img)\n        n_images += 1\n    label_4D = label.reshape(n_images, image_size[0], image_size[1], nb_classes)    \n    return label_4D\n</code></pre>\n\n<p>Preprocessing the images:</p>\n\n<pre><code># Split into train/test and make the shapes of tensors compatible with tensorflow format\nnb_classes = 10\ntarget_size = (128, 128)\n\n#Below line randomizes which images are picked for train/test sets. ~20% will go to test.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\nX_train = preprocessing_X(X_train, target_size)\nX_test = preprocessing_X(X_test, target_size)\ny_train = preprocessing_Y(y_train, target_size)\ny_test = preprocessing_Y(y_test, target_size)\n</code></pre>\n\n<p>Somebody suggested an encoder-decoder pair, but I do not know how to implement this. Any suggestions?</p>\n\n<p>EDIT: A commenter asked me to show the Keras model I've been using, so here it is:</p>\n\n<pre><code>model = Sequential()\nmodel.add(Conv2D(nb_classes, kernel_size=3, padding = 'same',\n                 activation='relu',\n                 input_shape=(128,128,1)))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(Conv2D(32, kernel_size = 3, activation='relu', padding = 'same'))\n#model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n#model.add(Dropout(0.25))\n#model.add(Flatten())\n#model.add(Dense(128, activation='relu'))\n#model.add(Dropout(0.5))\n#model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n\nmodel.add(UpSampling2D((2,2)))\n\nmodel.add(Conv2D(nb_classes, (1, 1), activation = 'linear', padding='same'))\nmodel.add(Activation('softmax'))\n</code></pre>\n\n<p>Compiling the model: </p>\n\n<pre><code>model.compile(loss='mean_squared_error',\n              optimizer='Adam',\n              metrics=['accuracy'])\n\nmodel.fit(X_train, y_train,\n          batch_size=128,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(X_test, y_test))\nscore = model.evaluate(X_test, y_test)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n\nmodel.save(\"/content/artificial_label_train.h5\")\nmodel.save_weights(\"/content/artificial_label_train_weights.h5\")\n</code></pre>\n <machine-learning><python><neural-network><autoencoder><image-preprocessing>",
                "codes": [],
                "question_id:": "56066",
                "question_votes:": "",
                "question_text:": "<p>On the project I am currently working on, my goal is to train a neural network to convert images of circles to ellipses in a way that models convolution/blurring in real imaging processes. </p>\n\n<p>What remains is to construct a neural network, preferably a CNN, that has the desired results - i.e. takes an image with circles as an input and returns an image with ellipses. However, I have not been able to do this. At best, neural nets (including CNNs) that I have used so far have at best returned blurred images of the circles. I can't tell whether it is the fault of the neural network or the fault of the preprocessing code I am using. </p>\n\n<p>Below, I will show you my code.</p>\n\n<p>First, importing the necessary modules:</p>\n\n<pre><code>import keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Activation, Reshape\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\nimport numpy as np\nimport pandas as pd\nfrom collections import OrderedDict\nimport itertools\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nimport math\nfrom math import sqrt\nfrom keras.models import Model, load_model\n</code></pre>\n\n<p>Next, creating and storing the input (circle) and output (ellipse) images:</p>\n\n<pre><code>def create_blank_image(size):\n    data = np.ndarray(shape=(size, size))\n    for i in range(0, size):\n        for j in range(0, size):\n            data[[i], [j]] = 0\n    #print(data)\n\n    return data\n\ndef circle_randomizer():\n    number_of_circles = random.randint(4,10)\n    intensity = np.ndarray(shape=(128, 128))\n    #print(number_of_circles)\n    radius_list = []\n\n\n    for i in range(number_of_circles):\n        radius_list.append(random.uniform(8, 10))\n    #print(radius_list)\n\n    center_coords = np.zeros((2,1))    \n    center_coords[[0],[0]] = random.uniform(0,size)\n    center_coords[[1],[0]] = random.uniform(0,size)\n\n    for i in range(number_of_circles):\n      #temp_array = np.ndarray(shape=(2,1))\n      #temp_array[[0],[0]] = random.uniform(0,size)\n      #temp_array[[1],[0]] = random.uniform(0,size)\n\n      if i &gt; 0:\n          j = 0\n          #print(i,j)\n          while j in range(i):\n              #print(i,j)\n              #print(center_coords)\n              temp_array = np.ndarray(shape=(2,1))\n              temp_array[[0],[0]] = random.uniform(0,size)\n              temp_array[[1],[0]] = random.uniform(0,size)\n              #while sqrt((center_coords[[0],[i]] - center_coords[[0],[j]])**2 + (center_coords[[1],[i]] - center_coords[[1],[j]])**2) &lt; radius_list[i] + radius_list[j]:\n              while sqrt((temp_array[[0],[0]] - center_coords[[0],[j]])**2 + (temp_array[[1],[0]] - center_coords[[1],[j]])**2) &lt; radius_list[i] + radius_list[j]:               \n                  temp_array[[0],[0]] = random.uniform(0,size)\n                  temp_array[[1],[0]] = random.uniform(0,size)\n                  j = 0\n              center_coords = np.concatenate((center_coords,temp_array), axis = 1)          \n              j = j + 1\n              #print('loop ran ' + str(j) + ' times')\n\n    return radius_list, center_coords\n\ndef image_creator(centers, radii, img_data, size):\n    x = np.arange(1, size, 1)\n    y = np.arange(1, size, 1)\n\n    for c in range(len(centers)):\n        x0 = centers[[c],[0]]\n        y0 = centers[[c],[1]]\n        radius = radii[c]\n        for i in range(0, size-1):\n            for j in range(0, size-1):\n                height2 = radius**2 - (x[i]-x0)**2 - (y[j]-y0)**2\n                if height2 &gt;= 0:\n                    img_data[[i], [j]] = sqrt(radius**2 - (x[i]-x0)**2 - (y[j]-y0)**2)\n\n    return img_data\n\ndef make_ellipses(size, radii, center_coords):\n    # idea: use a random number generator to create a random rotation of the x,y axes for the ellipse\n\n    # size is the length of a side of the square\n    # length is the length of the ellipse\n    # defined as equal to the radius of the circle later\n\n    my_label = np.ndarray(shape=(size, size))\n    x = np.arange(1, size, 1)\n    y = np.arange(1, size, 1)\n\n    # inefficiently zero the array\n    for i in range(0, size):\n        for j in range(0, size):\n            my_label[[i], [j]] = 0\n            # print(my_label)\n    for c in range(len(center_coords)):\n        x0 = center_coords[[c],[0]]\n        y0 = center_coords[[c],[1]]\n        #theta = random.uniform(0, 6.28318)\n        theta = 0.775\n\n        for i in range(0, size - 1):\n            for j in range(0, size - 1):\n                xprime = (x[i] - x0) * math.cos(theta) + (y[j] - y0) * math.sin(theta)\n                yprime = -(x[i] - x0) * math.sin(theta) + (y[j] - y0) * math.cos(theta)\n                height2 = (0.5 * radii[c]) ** 2 - 0.25 * xprime ** 2 - yprime ** 2\n                if height2 &gt;= 0:\n                    my_label[[i], [j]] = sqrt((0.5 * radii[c]) ** 2 - 0.25 * xprime ** 2 - yprime ** 2)\n\n    return my_label\n\nsize = 128\nradii, centers = circle_randomizer()\n#print(radii)\n#print(centers)\n\n#Make labels and samples consistent with rest of code\nN = 100\ncircle_images = []\nellipse_images = []\ncoords = []\nfor sample in range(0, N):\n    blank_image = create_blank_image(size)\n    radii, centers = circle_randomizer()\n    temp_image = image_creator(centers, radii, blank_image, size)\n    circle_images.append(temp_image)\n    temp_output = make_ellipses(size, radii, centers)\n    ellipse_images.append(temp_output)\n    coords.append(centers)\n#print(labels)\n#print(samples[0][40])\n</code></pre>\n\n<p>Storing the images in files:</p>\n\n<pre><code>filenames = []\nfor i in range(0,N):\n  np.save('ellipses_' + str(i) + '.npy', ellipse_images[i])\n  filenames.append('ellipses_' + str(i) + '.npy')\n  np.save('circles_' + str(i) + '.npy', circle_images[i])\ncircles_stack = np.stack(circle_images,axis=0)\nellipses_stack = np.stack(ellipse_images,axis=0)\nnp.save('ellipses_stack.npy', ellipses_stack)\nnp.save('circles_stack.npy', circles_stack)\n</code></pre>\n\n<p>Loading the images:</p>\n\n<pre><code># load training images and corresponding \"labels\"\n# training samples\ntraining_images_path = 'circles_stack.npy'\nlabels_path = 'ellipses_stack.npy'\n\nX = np.load(training_images_path,'r')/20.\ny = np.load(labels_path,'r')/20.\n</code></pre>\n\n<p>Defining the image preprocessing functions: (I'm not sure why preprocessing_X and preprocessing_y are different; this is code I've partially adopted from a research paper.)</p>\n\n<pre><code># Preprocessing for training images\ndef preprocessing_X(image_data, image_size):\n    image_data = image_data.reshape(image_data.shape[0], image_size[0], image_size[1], 1)\n    image_data = image_data.astype('float32')\n    image_data = (image_data - np.amin(image_data))/(np.amax(image_data) - np.amin(image_data))\n    return image_data\n\n\n\u200b\n# preprocessing for \"labels\" (ground truth)\ndef preprocessing_Y(image_data, image_size):\n    n_images = 0\n    label = np.array([])\n    for idx in range(image_data.shape[0]):\n        img = image_data[idx,:,:]\n        n, m = img.shape\n        img = np.array(OneHotEncoder(n_values=nb_classes).fit_transform(img.reshape(-1,1)).todense())\n        img = img.reshape(n, m, nb_classes)\n        label = np.append(label, img)\n        n_images += 1\n    label_4D = label.reshape(n_images, image_size[0], image_size[1], nb_classes)    \n    return label_4D\n</code></pre>\n\n<p>Preprocessing the images:</p>\n\n<pre><code># Split into train/test and make the shapes of tensors compatible with tensorflow format\nnb_classes = 10\ntarget_size = (128, 128)\n\n#Below line randomizes which images are picked for train/test sets. ~20% will go to test.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\nX_train = preprocessing_X(X_train, target_size)\nX_test = preprocessing_X(X_test, target_size)\ny_train = preprocessing_Y(y_train, target_size)\ny_test = preprocessing_Y(y_test, target_size)\n</code></pre>\n\n<p>Somebody suggested an encoder-decoder pair, but I do not know how to implement this. Any suggestions?</p>\n\n<p>EDIT: A commenter asked me to show the Keras model I've been using, so here it is:</p>\n\n<pre><code>model = Sequential()\nmodel.add(Conv2D(nb_classes, kernel_size=3, padding = 'same',\n                 activation='relu',\n                 input_shape=(128,128,1)))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(Conv2D(32, kernel_size = 3, activation='relu', padding = 'same'))\n#model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n#model.add(Dropout(0.25))\n#model.add(Flatten())\n#model.add(Dense(128, activation='relu'))\n#model.add(Dropout(0.5))\n#model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n\nmodel.add(UpSampling2D((2,2)))\n\nmodel.add(Conv2D(nb_classes, (1, 1), activation = 'linear', padding='same'))\nmodel.add(Activation('softmax'))\n</code></pre>\n\n<p>Compiling the model: </p>\n\n<pre><code>model.compile(loss='mean_squared_error',\n              optimizer='Adam',\n              metrics=['accuracy'])\n\nmodel.fit(X_train, y_train,\n          batch_size=128,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(X_test, y_test))\nscore = model.evaluate(X_test, y_test)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n\nmodel.save(\"/content/artificial_label_train.h5\")\nmodel.save_weights(\"/content/artificial_label_train_weights.h5\")\n</code></pre>\n",
                "tags": "<machine-learning><python><neural-network><autoencoder><image-preprocessing>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "2933",
            "_score": 5.966331,
            "_source": {
                "title": "Scikit Learn OneHotEncoded Features causing error in classifier",
                "content": "Scikit Learn OneHotEncoded Features causing error in classifier <p>I\u2019m trying to prepare data for input to a Decision Tree and Multinomial Na\u00efve Bayes Classifier.</p>\n\n<p>This is what my data looks like (pandas dataframe)</p>\n\n<pre><code>Label  Feat1  Feat2  Feat3  Feat4\n\n0        1     3       2      1\n1        0     1       1      2\n2        2     2       1      1\n3        3     3       2      3\n</code></pre>\n\n<p>I have split the data into dataLabel and dataFeatures.\nPrepared dataLabel using <code>dataLabel.ravel()</code></p>\n\n<p>I need to discretize features so the classifiers treat them as being categorical not numerical. </p>\n\n<p>I\u2019m trying to do this using <code>OneHotEncoder</code></p>\n\n<pre><code>enc = OneHotEncoder()\n\nenc.fit(dataFeatures)\nchk = enc.transform(dataFeatures)\nfrom sklearn.naive_bayes import MultinomialNB\n\nmnb = MultinomialNB()\n\nfrom sklearn import metrics\nfrom sklearn.cross_validation import cross_val_score\nscores = cross_val_score(mnb, Y, chk, cv=10, scoring='accuracy')\n</code></pre>\n\n<p>I get this error - <code>bad input shape (64, 16)</code></p>\n\n<p>This is the shape of label and input</p>\n\n<p><code>dataLabel.shape = 72</code>\n<code>chk.shape = 72,16</code></p>\n\n<p>Why won't the classifier accept the onehotencoded features?</p>\n\n<p><strong>EDIT adding how i got dataFeatures</strong></p>\n\n<p><code>dataFeatures = data[['Accpred', 'Gyrpred', 'Barpred', 'altpred']]</code></p>\n\n<p><code>Y = dataLabel.ravel()</code></p>\n <python><predictive-modeling><scikit-learn><categorical-data><pre><code>scores = cross_val_score(mnb, Y, chk, cv=10, scoring='accuracy')\n</code></pre>\n\n<p>You have your <code>Y</code> and <code>chk</code> switched. That's it. :)</p>\n\n<p>The signature of <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html\" rel=\"nofollow noreferrer\"><code>cross_val_score</code></a> is <code>sklearn.cross_validation.cross_val_score(estimator, X, y)</code>.</p>\n\n<p><code>X</code> is a matrix and <code>y</code> is a 1D vector with your class labels.</p>\n\n<p>unlike in R, most (or all?) sklearn models do not support categorical variables. Most of the time, encoding your feature matrix <code>X</code> into what is called <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" rel=\"nofollow noreferrer\">one-hot encoding</a> is good enough.</p>\n\n<p>Notice that, in some models, this hack is not the same as true native categorical support, and the performance of the model will be worse.</p>\n\n<p><strong>Invert One-Hot Encoding</strong></p>\n\n<p>Sklearn does not seem to have an easy method to invert the one-hot encoding.</p>\n\n<p>It is not trivial how to do this. I found <a href=\"https://stackoverflow.com/a/35898452/2680707\">this suggestion</a>:</p>\n\n<pre><code>def inverse(enc, out, shape):\n    return np.array([enc.active_features_[col] for col in out.sorted_indices().indices]).reshape(shape) - enc.feature_indices_[:-1]\n</code></pre>\n\n<p>Example:</p>\n\n<pre><code>import numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\nenc = OneHotEncoder()\nX = np.array([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]]))\nZ = enc.fit_transform(X)\nprint(inverse(enc, Z, X.shape))\n# [[0 0 3]\n#  [1 1 0]\n#  [0 2 1]\n#  [1 0 2]]\nprint(X)\n# [[0 0 3]\n#  [1 1 0]\n#  [0 2 1]\n#  [1 0 2]]\n</code></pre>\n\n<p>Notice:</p>\n\n<ul>\n<li>This only works when <code>HotOneEncoding(sparse=True)</code> (default) because it uses scipy sparse matrix methods (this could be changed by making the code only use numpy methods), but this is probably what you want since working with a dense matrix will kill your memory anyhow</li>\n<li>I think this will only work if your variables are within the range [0,something] because you lose that information in the transformation (no work-around for this other than you using something like <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html\" rel=\"nofollow noreferrer\">DictVectorizer</a> which offers you more control over the transformation.</li>\n</ul>\n",
                "codes": [
                    [
                        "scores = cross_val_score(mnb, Y, chk, cv=10, scoring='accuracy')\n",
                        "def inverse(enc, out, shape):\n    return np.array([enc.active_features_[col] for col in out.sorted_indices().indices]).reshape(shape) - enc.feature_indices_[:-1]\n",
                        "import numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\nenc = OneHotEncoder()\nX = np.array([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]]))\nZ = enc.fit_transform(X)\nprint(inverse(enc, Z, X.shape))\n# [[0 0 3]\n#  [1 1 0]\n#  [0 2 1]\n#  [1 0 2]]\nprint(X)\n# [[0 0 3]\n#  [1 1 0]\n#  [0 2 1]\n#  [1 0 2]]\n"
                    ]
                ],
                "question_id:": "12999",
                "question_votes:": "1",
                "question_text:": "<p>I\u2019m trying to prepare data for input to a Decision Tree and Multinomial Na\u00efve Bayes Classifier.</p>\n\n<p>This is what my data looks like (pandas dataframe)</p>\n\n<pre><code>Label  Feat1  Feat2  Feat3  Feat4\n\n0        1     3       2      1\n1        0     1       1      2\n2        2     2       1      1\n3        3     3       2      3\n</code></pre>\n\n<p>I have split the data into dataLabel and dataFeatures.\nPrepared dataLabel using <code>dataLabel.ravel()</code></p>\n\n<p>I need to discretize features so the classifiers treat them as being categorical not numerical. </p>\n\n<p>I\u2019m trying to do this using <code>OneHotEncoder</code></p>\n\n<pre><code>enc = OneHotEncoder()\n\nenc.fit(dataFeatures)\nchk = enc.transform(dataFeatures)\nfrom sklearn.naive_bayes import MultinomialNB\n\nmnb = MultinomialNB()\n\nfrom sklearn import metrics\nfrom sklearn.cross_validation import cross_val_score\nscores = cross_val_score(mnb, Y, chk, cv=10, scoring='accuracy')\n</code></pre>\n\n<p>I get this error - <code>bad input shape (64, 16)</code></p>\n\n<p>This is the shape of label and input</p>\n\n<p><code>dataLabel.shape = 72</code>\n<code>chk.shape = 72,16</code></p>\n\n<p>Why won't the classifier accept the onehotencoded features?</p>\n\n<p><strong>EDIT adding how i got dataFeatures</strong></p>\n\n<p><code>dataFeatures = data[['Accpred', 'Gyrpred', 'Barpred', 'altpred']]</code></p>\n\n<p><code>Y = dataLabel.ravel()</code></p>\n",
                "tags": "<python><predictive-modeling><scikit-learn><categorical-data>",
                "answers": [
                    [
                        "13001",
                        "2",
                        "12999",
                        "",
                        "",
                        "<pre><code>scores = cross_val_score(mnb, Y, chk, cv=10, scoring='accuracy')\n</code></pre>\n\n<p>You have your <code>Y</code> and <code>chk</code> switched. That's it. :)</p>\n\n<p>The signature of <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html\" rel=\"nofollow noreferrer\"><code>cross_val_score</code></a> is <code>sklearn.cross_validation.cross_val_score(estimator, X, y)</code>.</p>\n\n<p><code>X</code> is a matrix and <code>y</code> is a 1D vector with your class labels.</p>\n\n<p>unlike in R, most (or all?) sklearn models do not support categorical variables. Most of the time, encoding your feature matrix <code>X</code> into what is called <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" rel=\"nofollow noreferrer\">one-hot encoding</a> is good enough.</p>\n\n<p>Notice that, in some models, this hack is not the same as true native categorical support, and the performance of the model will be worse.</p>\n\n<p><strong>Invert One-Hot Encoding</strong></p>\n\n<p>Sklearn does not seem to have an easy method to invert the one-hot encoding.</p>\n\n<p>It is not trivial how to do this. I found <a href=\"https://stackoverflow.com/a/35898452/2680707\">this suggestion</a>:</p>\n\n<pre><code>def inverse(enc, out, shape):\n    return np.array([enc.active_features_[col] for col in out.sorted_indices().indices]).reshape(shape) - enc.feature_indices_[:-1]\n</code></pre>\n\n<p>Example:</p>\n\n<pre><code>import numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\nenc = OneHotEncoder()\nX = np.array([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]]))\nZ = enc.fit_transform(X)\nprint(inverse(enc, Z, X.shape))\n# [[0 0 3]\n#  [1 1 0]\n#  [0 2 1]\n#  [1 0 2]]\nprint(X)\n# [[0 0 3]\n#  [1 1 0]\n#  [0 2 1]\n#  [1 0 2]]\n</code></pre>\n\n<p>Notice:</p>\n\n<ul>\n<li>This only works when <code>HotOneEncoding(sparse=True)</code> (default) because it uses scipy sparse matrix methods (this could be changed by making the code only use numpy methods), but this is probably what you want since working with a dense matrix will kill your memory anyhow</li>\n<li>I think this will only work if your variables are within the range [0,something] because you lose that information in the transformation (no work-around for this other than you using something like <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html\" rel=\"nofollow noreferrer\">DictVectorizer</a> which offers you more control over the transformation.</li>\n</ul>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15203",
            "_score": 5.966331,
            "_source": {
                "title": "Dealing with the test set of imbalanced data",
                "content": "Dealing with the test set of imbalanced data <p>I am working on a problem dealing with unbalanced data that has a very specific request.</p>\n\n<p>I would like to know the following:</p>\n\n<p>When I have an imbalanced dataset and I do train test split, the test samples also have an imbalance. How can I at least balance the test set so that when I do the confusion matrix equal numbers are tested?</p>\n\n<p>Here's an example (Classification):</p>\n\n<p>If I have three groups: <code>A 60,B 30,C 20</code>. For simplicity, the test set is 10%. So, instead of having a train/test set of 54/6, 27/3, 18/2, I would like 58/2, 28/2 and 18/2 OR 54/2, 27/2, 18/2.</p>\n\n<p>How can I do this?</p>\n <machine-learning><classification><machine-learning-model><class-imbalance><imbalanced-learn><p>I would still use scikit-learn's built-in mechanism for train/test splitting but downsample after.</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# Create mock data\nn = 110\nX = np.arange(n).reshape((n, 1))\ny = [0]*60 + [1]*30 + [2]*20 # Uneven categories\n\n# Standard train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y) \n\n# Fixed number of samples from each category\nn_test = 2\n\n# A category sampling\na_indices = [i for i, n in enumerate(y_test) if n == 0]\na_indices_sub_sample = np.random.choice(a_indices, n_test, replace=False)\nX_test_a_category = X_test[a_indices_sub_sample]\n\n# B category sampling\nb_indices = [i for i, n in enumerate(y_test) if n == 1]\nb_indices_sub_sample = np.random.choice(b_indices, n_test, replace=False)\nX_test_b_category = X_test[b_indices_sub_sample]\n\n# C category sampling\nc_indices = [i for i, n in enumerate(y_test) if n == 2]\nc_indices_sub_sample = np.random.choice(c_indices, n_test, replace=False)\nX_test_c_category = X_test[c_indices_sub_sample]\n</code></pre>\n<p>For a case like this, it would probably be the easiest to do the train/test split manually. Here is a quick example with Pandas:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nimport numpy as np\n\n#\u00a0Create an empty dataframe with 60*A, 30*B, 20*C and some random target values\ndf = pd.DataFrame(columns=['category'])\ndf['category'] = ([\"A\"] * 60 + [\"B\"] * 30 + [\"C\"] * 20)\ndf['target'] = np.random.rand(len(df))\ndf.category.value_counts()\n</code></pre>\n\n<pre><code>&gt; A    60\n&gt; B    30\n&gt; C    20\n&gt; Name: category, dtype: int64\n</code></pre>\n\n<pre class=\"lang-py prettyprint-override\"><code># Obtain the size of the least represented category\nsmallest_category_size = np.min(df.category.value_counts().values)\n\n#\u00a0Size of the test split of the smallest category\ntest_size = 0.1\n\n# Test count (2 in this case)\ntest_count = int(test_size*smallest_category_size)\n\n# New train/test dataframes\ntrain_df = pd.DataFrame(columns=df.columns)\ntest_df = pd.DataFrame(columns=df.columns)\n\nfor cat in df.category.unique():\n    # Select only a part of the dataset containing one category\n    cat_df = df[df.category == cat]\n\n    # Create and shuffle boolean mask\n    mask = np.array((len(cat_df) - test_count) * [True] + test_count * [False])\n    np.random.shuffle(mask)\n\n    # Append the selected values to the train/test\n    train_df = train_df.append(cat_df[mask])\n    test_df = test_df.append(cat_df[~mask])\n</code></pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>train_df.category.value_counts()\n</code></pre>\n\n<pre><code>&gt; A    58\n&gt; B    28\n&gt; C    18\n&gt; Name: category, dtype: int64\n</code></pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>test_df.category.value_counts()\n</code></pre>\n\n<pre><code>&gt; A    2\n&gt; B    2\n&gt; C    2\n&gt; Name: category, dtype: int64\n</code></pre>\n",
                "codes": [
                    [
                        "import numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# Create mock data\nn = 110\nX = np.arange(n).reshape((n, 1))\ny = [0]*60 + [1]*30 + [2]*20 # Uneven categories\n\n# Standard train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y) \n\n# Fixed number of samples from each category\nn_test = 2\n\n# A category sampling\na_indices = [i for i, n in enumerate(y_test) if n == 0]\na_indices_sub_sample = np.random.choice(a_indices, n_test, replace=False)\nX_test_a_category = X_test[a_indices_sub_sample]\n\n# B category sampling\nb_indices = [i for i, n in enumerate(y_test) if n == 1]\nb_indices_sub_sample = np.random.choice(b_indices, n_test, replace=False)\nX_test_b_category = X_test[b_indices_sub_sample]\n\n# C category sampling\nc_indices = [i for i, n in enumerate(y_test) if n == 2]\nc_indices_sub_sample = np.random.choice(c_indices, n_test, replace=False)\nX_test_c_category = X_test[c_indices_sub_sample]\n"
                    ],
                    [
                        "import pandas as pd\nimport numpy as np\n\n#\u00a0Create an empty dataframe with 60*A, 30*B, 20*C and some random target values\ndf = pd.DataFrame(columns=['category'])\ndf['category'] = ([\"A\"] * 60 + [\"B\"] * 30 + [\"C\"] * 20)\ndf['target'] = np.random.rand(len(df))\ndf.category.value_counts()\n",
                        "> A    60\n> B    30\n> C    20\n> Name: category, dtype: int64\n",
                        "# Obtain the size of the least represented category\nsmallest_category_size = np.min(df.category.value_counts().values)\n\n#\u00a0Size of the test split of the smallest category\ntest_size = 0.1\n\n# Test count (2 in this case)\ntest_count = int(test_size*smallest_category_size)\n\n# New train/test dataframes\ntrain_df = pd.DataFrame(columns=df.columns)\ntest_df = pd.DataFrame(columns=df.columns)\n\nfor cat in df.category.unique():\n    # Select only a part of the dataset containing one category\n    cat_df = df[df.category == cat]\n\n    # Create and shuffle boolean mask\n    mask = np.array((len(cat_df) - test_count) * [True] + test_count * [False])\n    np.random.shuffle(mask)\n\n    # Append the selected values to the train/test\n    train_df = train_df.append(cat_df[mask])\n    test_df = test_df.append(cat_df[~mask])\n",
                        "train_df.category.value_counts()\n",
                        "> A    58\n> B    28\n> C    18\n> Name: category, dtype: int64\n",
                        "test_df.category.value_counts()\n",
                        "> A    2\n> B    2\n> C    2\n> Name: category, dtype: int64\n"
                    ]
                ],
                "question_id:": "51406",
                "question_votes:": "",
                "question_text:": "<p>I am working on a problem dealing with unbalanced data that has a very specific request.</p>\n\n<p>I would like to know the following:</p>\n\n<p>When I have an imbalanced dataset and I do train test split, the test samples also have an imbalance. How can I at least balance the test set so that when I do the confusion matrix equal numbers are tested?</p>\n\n<p>Here's an example (Classification):</p>\n\n<p>If I have three groups: <code>A 60,B 30,C 20</code>. For simplicity, the test set is 10%. So, instead of having a train/test set of 54/6, 27/3, 18/2, I would like 58/2, 28/2 and 18/2 OR 54/2, 27/2, 18/2.</p>\n\n<p>How can I do this?</p>\n",
                "tags": "<machine-learning><classification><machine-learning-model><class-imbalance><imbalanced-learn>",
                "answers": [
                    [
                        "51460",
                        "2",
                        "51406",
                        "",
                        "",
                        "<p>I would still use scikit-learn's built-in mechanism for train/test splitting but downsample after.</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# Create mock data\nn = 110\nX = np.arange(n).reshape((n, 1))\ny = [0]*60 + [1]*30 + [2]*20 # Uneven categories\n\n# Standard train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y) \n\n# Fixed number of samples from each category\nn_test = 2\n\n# A category sampling\na_indices = [i for i, n in enumerate(y_test) if n == 0]\na_indices_sub_sample = np.random.choice(a_indices, n_test, replace=False)\nX_test_a_category = X_test[a_indices_sub_sample]\n\n# B category sampling\nb_indices = [i for i, n in enumerate(y_test) if n == 1]\nb_indices_sub_sample = np.random.choice(b_indices, n_test, replace=False)\nX_test_b_category = X_test[b_indices_sub_sample]\n\n# C category sampling\nc_indices = [i for i, n in enumerate(y_test) if n == 2]\nc_indices_sub_sample = np.random.choice(c_indices, n_test, replace=False)\nX_test_c_category = X_test[c_indices_sub_sample]\n</code></pre>\n",
                        "",
                        "1"
                    ],
                    [
                        "51426",
                        "2",
                        "51406",
                        "",
                        "",
                        "<p>For a case like this, it would probably be the easiest to do the train/test split manually. Here is a quick example with Pandas:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nimport numpy as np\n\n#\u00a0Create an empty dataframe with 60*A, 30*B, 20*C and some random target values\ndf = pd.DataFrame(columns=['category'])\ndf['category'] = ([\"A\"] * 60 + [\"B\"] * 30 + [\"C\"] * 20)\ndf['target'] = np.random.rand(len(df))\ndf.category.value_counts()\n</code></pre>\n\n<pre><code>&gt; A    60\n&gt; B    30\n&gt; C    20\n&gt; Name: category, dtype: int64\n</code></pre>\n\n<pre class=\"lang-py prettyprint-override\"><code># Obtain the size of the least represented category\nsmallest_category_size = np.min(df.category.value_counts().values)\n\n#\u00a0Size of the test split of the smallest category\ntest_size = 0.1\n\n# Test count (2 in this case)\ntest_count = int(test_size*smallest_category_size)\n\n# New train/test dataframes\ntrain_df = pd.DataFrame(columns=df.columns)\ntest_df = pd.DataFrame(columns=df.columns)\n\nfor cat in df.category.unique():\n    # Select only a part of the dataset containing one category\n    cat_df = df[df.category == cat]\n\n    # Create and shuffle boolean mask\n    mask = np.array((len(cat_df) - test_count) * [True] + test_count * [False])\n    np.random.shuffle(mask)\n\n    # Append the selected values to the train/test\n    train_df = train_df.append(cat_df[mask])\n    test_df = test_df.append(cat_df[~mask])\n</code></pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>train_df.category.value_counts()\n</code></pre>\n\n<pre><code>&gt; A    58\n&gt; B    28\n&gt; C    18\n&gt; Name: category, dtype: int64\n</code></pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>test_df.category.value_counts()\n</code></pre>\n\n<pre><code>&gt; A    2\n&gt; B    2\n&gt; C    2\n&gt; Name: category, dtype: int64\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5257",
            "_score": 5.8785696,
            "_source": {
                "title": "Cluster documents and identify the prominent document in the cluster?",
                "content": "Cluster documents and identify the prominent document in the cluster? <p>I have a set of documents as given in the example below.</p>\n\n<pre><code>doc1 = {'Science': 0.7, 'History': 0.05, 'Politics': 0.15, 'Sports': 0.1}\ndoc2 = {'Science': 0.3, 'History': 0.5, 'Politics': 0.1, 'Sports': 0.1}\n</code></pre>\n\n<p>I want to cluster the documents and identify the most prominent document within the cluster.</p>\n\n<p>e.g, cluster 1 includes = {doc1, doc4, doc5. doc8} and I want to get the most prominent document that represents this cluster (e.g., doc8). (or to identify the main theme of the cluster)</p>\n\n<p>Please let me know a suitable approach to achieve this :)</p>\n <machine-learning><data-mining><clustering><p>A very simple approach would be to find some kind of centroid for each cluster (e.g. averaging the distributions of the documents belonging to each cluster respectively) and then calculating the cosine distance of each document within the cluster from the corresponding centroid. The document with the shorter distance will be the closest to the centroid, hence the most \"representative\".</p>\n\n<p>Continuing <a href=\"https://datascience.stackexchange.com/questions/19991/cluster-documents-based-on-topic-similarity/19999?noredirect=1#comment23532_19999\">from the previous example</a>:</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import pairwise_distances\nfrom scipy.spatial.distance import cosine\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.preprocessing import StandardScaler\n\n\n# Initialize some documents\ndoc1 = {'Science':0.8, 'History':0.05, 'Politics':0.15, 'Sports':0.1}\ndoc2 = {'News':0.2, 'Art':0.8, 'Politics':0.1, 'Sports':0.1}\ndoc3 = {'Science':0.8, 'History':0.1, 'Politics':0.05, 'News':0.1}\ndoc4 = {'Science':0.1, 'Weather':0.2, 'Art':0.7, 'Sports':0.1}\ncollection = [doc1, doc2, doc3, doc4]\ndf = pd.DataFrame(collection)\n# Fill missing values with zeros\ndf.fillna(0, inplace=True)\n# Get Feature Vectors\nfeature_matrix = df.as_matrix()\n\n# Fit DBSCAN\ndb = DBSCAN(min_samples=1, metric='precomputed').fit(pairwise_distances(feature_matrix, metric='cosine'))\nlabels = db.labels_\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nprint('Estimated number of clusters: %d' % n_clusters_)\n\n# Find the representatives\nrepresentatives = {}\nfor label in set(labels):\n    # Find indices of documents belonging to the same cluster\n    ind = np.argwhere(labels==label).reshape(-1,)\n    # Select these specific documetns\n    cluster_samples = feature_matrix[ind,:]\n    # Calculate their centroid as an average\n    centroid = np.average(cluster_samples, axis=0)\n    # Find the distance of each document from the centroid\n    distances = [cosine(sample_doc, centroid) for sample_doc in cluster_samples]\n    # Keep the document closest to the centroid as the representative\n    representatives[label] = cluster_samples[np.argsort(distances),:][0]\n\nfor label, doc in representatives.iteritems():\n    print(\"Label : %d -- Representative : %s\" % (label, str(doc)))\n</code></pre>\n",
                "codes": [
                    [
                        "import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import pairwise_distances\nfrom scipy.spatial.distance import cosine\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.preprocessing import StandardScaler\n\n\n# Initialize some documents\ndoc1 = {'Science':0.8, 'History':0.05, 'Politics':0.15, 'Sports':0.1}\ndoc2 = {'News':0.2, 'Art':0.8, 'Politics':0.1, 'Sports':0.1}\ndoc3 = {'Science':0.8, 'History':0.1, 'Politics':0.05, 'News':0.1}\ndoc4 = {'Science':0.1, 'Weather':0.2, 'Art':0.7, 'Sports':0.1}\ncollection = [doc1, doc2, doc3, doc4]\ndf = pd.DataFrame(collection)\n# Fill missing values with zeros\ndf.fillna(0, inplace=True)\n# Get Feature Vectors\nfeature_matrix = df.as_matrix()\n\n# Fit DBSCAN\ndb = DBSCAN(min_samples=1, metric='precomputed').fit(pairwise_distances(feature_matrix, metric='cosine'))\nlabels = db.labels_\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nprint('Estimated number of clusters: %d' % n_clusters_)\n\n# Find the representatives\nrepresentatives = {}\nfor label in set(labels):\n    # Find indices of documents belonging to the same cluster\n    ind = np.argwhere(labels==label).reshape(-1,)\n    # Select these specific documetns\n    cluster_samples = feature_matrix[ind,:]\n    # Calculate their centroid as an average\n    centroid = np.average(cluster_samples, axis=0)\n    # Find the distance of each document from the centroid\n    distances = [cosine(sample_doc, centroid) for sample_doc in cluster_samples]\n    # Keep the document closest to the centroid as the representative\n    representatives[label] = cluster_samples[np.argsort(distances),:][0]\n\nfor label, doc in representatives.iteritems():\n    print(\"Label : %d -- Representative : %s\" % (label, str(doc)))\n"
                    ]
                ],
                "question_id:": "20198",
                "question_votes:": "2",
                "question_text:": "<p>I have a set of documents as given in the example below.</p>\n\n<pre><code>doc1 = {'Science': 0.7, 'History': 0.05, 'Politics': 0.15, 'Sports': 0.1}\ndoc2 = {'Science': 0.3, 'History': 0.5, 'Politics': 0.1, 'Sports': 0.1}\n</code></pre>\n\n<p>I want to cluster the documents and identify the most prominent document within the cluster.</p>\n\n<p>e.g, cluster 1 includes = {doc1, doc4, doc5. doc8} and I want to get the most prominent document that represents this cluster (e.g., doc8). (or to identify the main theme of the cluster)</p>\n\n<p>Please let me know a suitable approach to achieve this :)</p>\n",
                "tags": "<machine-learning><data-mining><clustering>",
                "answers": [
                    [
                        "20209",
                        "2",
                        "20198",
                        "",
                        "",
                        "<p>A very simple approach would be to find some kind of centroid for each cluster (e.g. averaging the distributions of the documents belonging to each cluster respectively) and then calculating the cosine distance of each document within the cluster from the corresponding centroid. The document with the shorter distance will be the closest to the centroid, hence the most \"representative\".</p>\n\n<p>Continuing <a href=\"https://datascience.stackexchange.com/questions/19991/cluster-documents-based-on-topic-similarity/19999?noredirect=1#comment23532_19999\">from the previous example</a>:</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import pairwise_distances\nfrom scipy.spatial.distance import cosine\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.preprocessing import StandardScaler\n\n\n# Initialize some documents\ndoc1 = {'Science':0.8, 'History':0.05, 'Politics':0.15, 'Sports':0.1}\ndoc2 = {'News':0.2, 'Art':0.8, 'Politics':0.1, 'Sports':0.1}\ndoc3 = {'Science':0.8, 'History':0.1, 'Politics':0.05, 'News':0.1}\ndoc4 = {'Science':0.1, 'Weather':0.2, 'Art':0.7, 'Sports':0.1}\ncollection = [doc1, doc2, doc3, doc4]\ndf = pd.DataFrame(collection)\n# Fill missing values with zeros\ndf.fillna(0, inplace=True)\n# Get Feature Vectors\nfeature_matrix = df.as_matrix()\n\n# Fit DBSCAN\ndb = DBSCAN(min_samples=1, metric='precomputed').fit(pairwise_distances(feature_matrix, metric='cosine'))\nlabels = db.labels_\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nprint('Estimated number of clusters: %d' % n_clusters_)\n\n# Find the representatives\nrepresentatives = {}\nfor label in set(labels):\n    # Find indices of documents belonging to the same cluster\n    ind = np.argwhere(labels==label).reshape(-1,)\n    # Select these specific documetns\n    cluster_samples = feature_matrix[ind,:]\n    # Calculate their centroid as an average\n    centroid = np.average(cluster_samples, axis=0)\n    # Find the distance of each document from the centroid\n    distances = [cosine(sample_doc, centroid) for sample_doc in cluster_samples]\n    # Keep the document closest to the centroid as the representative\n    representatives[label] = cluster_samples[np.argsort(distances),:][0]\n\nfor label, doc in representatives.iteritems():\n    print(\"Label : %d -- Representative : %s\" % (label, str(doc)))\n</code></pre>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7507",
            "_score": 5.8785696,
            "_source": {
                "title": "How to run PCA and KNN on big-data",
                "content": "How to run PCA and KNN on big-data <p>I work with python and images of watches (examples: <a href=\"https://i.stack.imgur.com/BOTES.jpg\" rel=\"nofollow noreferrer\">watch_1</a>, <a href=\"https://i.stack.imgur.com/qPNEb.jpg\" rel=\"nofollow noreferrer\">watch_2</a>, <a href=\"https://i.stack.imgur.com/uISDl.jpg\" rel=\"nofollow noreferrer\">watch_3</a>). My aim is to take a photo of a random watch and then find the most similar watches to it in my database. Obviously, one main feature which distinguishes the watches are their shape (square, rectangular, round, oval) but there are also other ones.</p>\n\n<p>For now, I am just running a PCA and a KNN on rgb images of watches to find the most similar ones among them. My source code is the following:</p>\n\n<pre><code>import cv2\nimport numpy as np\nimport os\nfrom glob import glob\nfrom sklearn.decomposition import PCA\nfrom sklearn import neighbors\nfrom sklearn import preprocessing\n\n\ndata = []\n\n# Read images from file\nfor filename in glob('Watches/*.jpg'):\n\n    img = cv2.imread(filename)\n    height, width = img.shape[:2]\n    img = np.array(img)\n\n    # Check that all my images are of the same resolution\n    if height == 529 and width == 940:\n\n        # Reshape each image so that it is stored in one line\n        img = np.concatenate(img, axis=0)\n        img = np.concatenate(img, axis=0)\n        data.append(img)\n\n# Normalise data\ndata = np.array(data)\nNorm = preprocessing.Normalizer()\nNorm.fit(data)\ndata = Norm.transform(data)\n\n# PCA model\npca = PCA(0.95)\npca.fit(data)\ndata = pca.transform(data)\n\n# K-Nearest neighbours\nknn = neighbors.NearestNeighbors(n_neighbors=4, algorithm='ball_tree', metric='minkowski').fit(data)\ndistances, indices = knn.kneighbors(data)\n\nprint(indices)\n</code></pre>\n\n<p>However when I try to run this script for more than 1500 rgb images then I get a <code>MemoryError</code> at the point where the data are processed by the PCA method.</p>\n\n<p>Is this normal for a pc with 24GB RAM and 3.6GHz Intel Core CPU without any discrete GPU?</p>\n\n<p>How can I overcome this?</p>\n\n<p>Shall I use another method like Incremental PCA (or a deep learning algorithm) or simply shall I buy a discrete GPU?</p>\n <machine-learning><python><computer-vision><p>KNN is instance based so it will store all training instances in memory. Since you are using images this will add up quickly. KNN on untransformed images might not perform that well anyway, you could look into filter banks to transform your images to a bag-of-word-representation (which is smaller and more invariant).</p>\n\n<p>However if it is accuracy you are aiming for I would recommend skipping all that (it is very 2012 anyway) in favor of using deep learning, fi: construct an auto-encoder and determine similarity on the encoded representation of an image (which could in turn be done using knn btw). </p>\n",
                "codes": [
                    []
                ],
                "question_id:": "28030",
                "question_votes:": "3",
                "question_text:": "<p>I work with python and images of watches (examples: <a href=\"https://i.stack.imgur.com/BOTES.jpg\" rel=\"nofollow noreferrer\">watch_1</a>, <a href=\"https://i.stack.imgur.com/qPNEb.jpg\" rel=\"nofollow noreferrer\">watch_2</a>, <a href=\"https://i.stack.imgur.com/uISDl.jpg\" rel=\"nofollow noreferrer\">watch_3</a>). My aim is to take a photo of a random watch and then find the most similar watches to it in my database. Obviously, one main feature which distinguishes the watches are their shape (square, rectangular, round, oval) but there are also other ones.</p>\n\n<p>For now, I am just running a PCA and a KNN on rgb images of watches to find the most similar ones among them. My source code is the following:</p>\n\n<pre><code>import cv2\nimport numpy as np\nimport os\nfrom glob import glob\nfrom sklearn.decomposition import PCA\nfrom sklearn import neighbors\nfrom sklearn import preprocessing\n\n\ndata = []\n\n# Read images from file\nfor filename in glob('Watches/*.jpg'):\n\n    img = cv2.imread(filename)\n    height, width = img.shape[:2]\n    img = np.array(img)\n\n    # Check that all my images are of the same resolution\n    if height == 529 and width == 940:\n\n        # Reshape each image so that it is stored in one line\n        img = np.concatenate(img, axis=0)\n        img = np.concatenate(img, axis=0)\n        data.append(img)\n\n# Normalise data\ndata = np.array(data)\nNorm = preprocessing.Normalizer()\nNorm.fit(data)\ndata = Norm.transform(data)\n\n# PCA model\npca = PCA(0.95)\npca.fit(data)\ndata = pca.transform(data)\n\n# K-Nearest neighbours\nknn = neighbors.NearestNeighbors(n_neighbors=4, algorithm='ball_tree', metric='minkowski').fit(data)\ndistances, indices = knn.kneighbors(data)\n\nprint(indices)\n</code></pre>\n\n<p>However when I try to run this script for more than 1500 rgb images then I get a <code>MemoryError</code> at the point where the data are processed by the PCA method.</p>\n\n<p>Is this normal for a pc with 24GB RAM and 3.6GHz Intel Core CPU without any discrete GPU?</p>\n\n<p>How can I overcome this?</p>\n\n<p>Shall I use another method like Incremental PCA (or a deep learning algorithm) or simply shall I buy a discrete GPU?</p>\n",
                "tags": "<machine-learning><python><computer-vision>",
                "answers": [
                    [
                        "28031",
                        "2",
                        "28030",
                        "",
                        "",
                        "<p>KNN is instance based so it will store all training instances in memory. Since you are using images this will add up quickly. KNN on untransformed images might not perform that well anyway, you could look into filter banks to transform your images to a bag-of-word-representation (which is smaller and more invariant).</p>\n\n<p>However if it is accuracy you are aiming for I would recommend skipping all that (it is very 2012 anyway) in favor of using deep learning, fi: construct an auto-encoder and determine similarity on the encoded representation of an image (which could in turn be done using knn btw). </p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13256",
            "_score": 5.8785696,
            "_source": {
                "title": "LSTM Multi-state forecast",
                "content": "LSTM Multi-state forecast <p>I follow several tutorials about LSTM multi-step forecast to solve my problem.</p>\n\n<p><strong>My problem:</strong>\nI have a time series of price about 3 months (Jan 2018 to Mar 2018) and I assume there are seasonal.  So, my time series behaviors are changed because of such seasonal effects. </p>\n\n<p><strong>Q1</strong> \nDo I need to apply sliding window to prevent learning from too long sequence.  For example, each training sample takes prices of previous 14 days to predict the price of next 14 days.  In other words, my input is (t-1), (t-2), ... , (t-7) and my output is (t), (t+1), ... , (t+6).</p>\n\n<p><strong>Q2</strong>\nI read <a href=\"https://stackoverflow.com/questions/47594861/predicting-a-multiple-forward-time-step-of-a-time-series-using-lstm\">this post</a> and feel that it's interesting by just passing a whole sequence and let the model makes decision by itself using the advantage of setting <code>return_sequence=True</code> and <code>stateful=True</code>.  However, I'm a newbie to LSTM so I could not have clear understand how to apply it to the model according to such post.</p>\n\n<p>Suppose my data look like this</p>\n\n<pre><code>import pandas as pd\nimport numpy as pd\n\nnp.random.seed(40)\ndf = pd.DataFrame({\"Price\":list(np.random.choice(range(1000, 1500), 14)) + \n                           list(np.random.choice(range(1500, 2000), 14)) +\n                           list(np.random.choice(range(1800, 2500), 14)) +\n                           list(np.random.choice(range(1200, 1500), 14)) +\n                           list(np.random.choice(range(1500, 2000), 14)) +\n                           list(np.random.choice(range(1800, 2300), 14)) +\n                           list(np.random.choice(range(2500, 3000), 14)) +\n                           list(np.random.choice(range(2400, 2800), 14)) +\n                           list(np.random.choice(range(2600, 3000), 14)) +\n                           list(np.random.choice(range(2300, 2700), 14))},\n                   index=pd.date_range(start=\"2018-03-25\", periods=140))\n\ndf[\"Price\"] = df[\"Price\"].astype(float)\nscaler = MinMaxScaler(feature_range=(0, 1))\ndf[\"Scaled\"] = scaler.fit_transform(df[\"Price\"].values.reshape(-1, 1))\n</code></pre>\n\n<p>If I configure my model as follows</p>\n\n<pre><code>from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\n\nmodel = Sequential()\nmodel.add(LSTM(no_neuron, input_shape=(no_sample, timestep, no_feature)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\n</code></pre>\n\n<p>Is that make sense to set my <code>timestep=40, no_sample=140, no_feature=1</code> for my problem? and How to define batch size?</p>\n\n<p><strong>Q3</strong></p>\n\n<p>In my settings, I really need to predict the price from Apr 2018 until Dec 2018 is that possible to do even I have only data from Jan 2018 to Mar 2018?</p>\n <machine-learning><deep-learning><keras><time-series><lstm>",
                "codes": [],
                "question_id:": "45558",
                "question_votes:": "",
                "question_text:": "<p>I follow several tutorials about LSTM multi-step forecast to solve my problem.</p>\n\n<p><strong>My problem:</strong>\nI have a time series of price about 3 months (Jan 2018 to Mar 2018) and I assume there are seasonal.  So, my time series behaviors are changed because of such seasonal effects. </p>\n\n<p><strong>Q1</strong> \nDo I need to apply sliding window to prevent learning from too long sequence.  For example, each training sample takes prices of previous 14 days to predict the price of next 14 days.  In other words, my input is (t-1), (t-2), ... , (t-7) and my output is (t), (t+1), ... , (t+6).</p>\n\n<p><strong>Q2</strong>\nI read <a href=\"https://stackoverflow.com/questions/47594861/predicting-a-multiple-forward-time-step-of-a-time-series-using-lstm\">this post</a> and feel that it's interesting by just passing a whole sequence and let the model makes decision by itself using the advantage of setting <code>return_sequence=True</code> and <code>stateful=True</code>.  However, I'm a newbie to LSTM so I could not have clear understand how to apply it to the model according to such post.</p>\n\n<p>Suppose my data look like this</p>\n\n<pre><code>import pandas as pd\nimport numpy as pd\n\nnp.random.seed(40)\ndf = pd.DataFrame({\"Price\":list(np.random.choice(range(1000, 1500), 14)) + \n                           list(np.random.choice(range(1500, 2000), 14)) +\n                           list(np.random.choice(range(1800, 2500), 14)) +\n                           list(np.random.choice(range(1200, 1500), 14)) +\n                           list(np.random.choice(range(1500, 2000), 14)) +\n                           list(np.random.choice(range(1800, 2300), 14)) +\n                           list(np.random.choice(range(2500, 3000), 14)) +\n                           list(np.random.choice(range(2400, 2800), 14)) +\n                           list(np.random.choice(range(2600, 3000), 14)) +\n                           list(np.random.choice(range(2300, 2700), 14))},\n                   index=pd.date_range(start=\"2018-03-25\", periods=140))\n\ndf[\"Price\"] = df[\"Price\"].astype(float)\nscaler = MinMaxScaler(feature_range=(0, 1))\ndf[\"Scaled\"] = scaler.fit_transform(df[\"Price\"].values.reshape(-1, 1))\n</code></pre>\n\n<p>If I configure my model as follows</p>\n\n<pre><code>from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\n\nmodel = Sequential()\nmodel.add(LSTM(no_neuron, input_shape=(no_sample, timestep, no_feature)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\n</code></pre>\n\n<p>Is that make sense to set my <code>timestep=40, no_sample=140, no_feature=1</code> for my problem? and How to define batch size?</p>\n\n<p><strong>Q3</strong></p>\n\n<p>In my settings, I really need to predict the price from Apr 2018 until Dec 2018 is that possible to do even I have only data from Jan 2018 to Mar 2018?</p>\n",
                "tags": "<machine-learning><deep-learning><keras><time-series><lstm>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "2427",
            "_score": 5.864428,
            "_source": {
                "title": "Is there any ability to use two ore more inputs for Elman recurrent neural network?",
                "content": "Is there any ability to use two ore more inputs for Elman recurrent neural network? <p>I have a problem with using neurolab python library: I'm trying to predict some time-series with help of Elman recurrent neural network:</p>\n\n<pre><code>import neurolab as nl\nimport numpy as np\n\n# Create train samples\n# x = np.linspace(-7, 7, 20)\nx = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9, 7, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9, 8, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9, 10, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 10.7, 10.8, 10.9, 11, 11.1, 11.2, 11.3, 11.4, 11.5, 11.6, 11.7, 11.8, 11.9, 12, 12.1, 12.2, 12.3, 12.4, 12.5, 12.6, 12.7, 12.8, 12.9, 13, 13.1, 13.2, 13.3, 13.4, 13.5, 13.6, 13.7, 13.8, 13.9, 14, 14.1, 14.2, 14.3, 14.4, 14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5, 15.6, 15.7, 15.8, 15.9, 16, 16.1, 16.2, 16.3, 16.4, 16.5, 16.6, 16.7, 16.8, 16.9, 17, 17.1, 17.2, 17.3, 17.4, 17.5, 17.6, 17.7, 17.8, 17.9, 18, 18.1, 18.2, 18.3, 18.4, 18.5, 18.6, 18.7, 18.8, 18.9, 19, 19.1, 19.2, 19.3, 19.4, 19.5, 19.6, 19.7, 19.8, 19.9]\nx=np.asarray(x)\ny = [0.000, 0.296, 0.407, 0.488, 0.552, 0.607, 0.655, 0.697, 0.734, 0.769, 0.800, 0.829, 0.855, 0.880, 0.903, 0.925, 0.945, 0.964, 0.982, 0.998, 1.014, 1.029, 1.043, 1.057, 1.069, 1.081, 1.092, 1.103, 1.113, 1.123, 1.132, 1.141, 1.149, 1.157, 1.164, 1.171, 1.177, 1.184, 1.189, 1.195, 1.200, 1.205, 1.209, 1.214, 1.218, 1.221, 1.225, 1.228, 1.231, 1.234, 1.236, 1.238, 1.240, 1.242, 1.244, 1.245, 1.246, 1.247, 1.248, 1.249, 1.249, 1.250, 1.250, 1.250, 1.250, 1.250, 1.249, 1.248, 1.248, 1.247, 1.246, 1.245, 1.243, 1.242, 1.240, 1.239, 1.237, 1.235, 1.233, 1.231, 1.228, 1.226, 1.224, 1.221, 1.218, 1.215, 1.213, 1.210, 1.206, 1.203, 1.200, 1.197, 1.193, 1.190, 1.186, 1.182, 1.178, 1.174, 1.170, 1.166, 1.162, 1.158, 1.154, 1.149, 1.145, 1.140, 1.136, 1.131, 1.126, 1.122, 1.117, 1.112, 1.107, 1.102, 1.096, 1.091, 1.086, 1.081, 1.075, 1.070, 1.064, 1.059, 1.053, 1.047, 1.041, 1.036, 1.030, 1.024, 1.018, 1.012, 1.006, 0.999, 0.993, 0.987, 0.981, 0.974, 0.968, 0.961, 0.955, 0.948, 0.942, 0.935, 0.928, 0.922, 0.915, 0.908, 0.901, 0.894, 0.887, 0.880, 0.873, 0.866, 0.859, 0.852, 0.844, 0.837, 0.830, 0.822, 0.815, 0.807, 0.800, 0.792, 0.785, 0.777, 0.770, 0.762, 0.754, 0.747, 0.739, 0.731, 0.723, 0.715, 0.707, 0.699, 0.691, 0.683, 0.675, 0.667, 0.659, 0.651, 0.643, 0.634, 0.626, 0.618, 0.610, 0.601, 0.593, 0.584, 0.576, 0.567, 0.559, 0.550, 0.542, 0.533, 0.525, 0.516, 0.507, 0.498, 0.490, 0.481]\ny=np.asarray(y)\nsample = [20, 20.1, 20.2, 20.3, 20.4, 20.5, 20.6, 20.7, 20.8, 20.9, 21, 21.1, 21.2, 21.3, 21.4]\nsample=np.asarray(sample)\n\nsize = len(x)\n\ninp = x.reshape(size,1)\ntar = y.reshape(size,1)\nsmp = sample.reshape(len(sample),1)\n#print(inp)\nprint(tar)\n# Create network with 2 layers and random initialized\n#net = nl.net.newelm([[min(x), max(y)]],[5, 1]) # neurolab.net.newff(minmax, size, transf=None)\nnet = nl.net.newelm([[min(x), max(y)]], [16, 1], [nl.trans.TanSig(), nl.trans.PureLin()])\n# Set initialized functions and init\nnet.layers[0].initf = nl.init.InitRand([-0.1, 0.1], 'wb')\nnet.layers[1].initf = nl.init.InitRand([-0.1, 0.1], 'wb')\nnet.init()\n# Train network\nerror = net.train(inp, tar, epochs=1900, show=100, goal=0.0001)\n\n# Simulate network\nout = net.sim(smp)\nprint(out)\n</code></pre>\n\n<p>It works fine with only one input time series (input vector). But I need more than one, in fact, I do need five input vectors.\nExample:\nI'm going to predict 6 rows of \"to_be_predicted\" column. The data: <a href=\"http://pastebin.com/7z1DeikJ\" rel=\"nofollow\">pastebin.com/7z1DeikJ</a>. So columns \"usd\", \"euro\", \"GDP_bln\", \"inflation\", \"CPI\" are the inputs and \"to_be_predicted\" is a target in my case.</p>\n\n<p>Does anybody know how to solve this issue? Thanks for your help!</p>\n <python><neural-network><time-series>",
                "codes": [],
                "question_id:": "11531",
                "question_votes:": "1",
                "question_text:": "<p>I have a problem with using neurolab python library: I'm trying to predict some time-series with help of Elman recurrent neural network:</p>\n\n<pre><code>import neurolab as nl\nimport numpy as np\n\n# Create train samples\n# x = np.linspace(-7, 7, 20)\nx = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9, 7, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9, 8, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9, 10, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 10.7, 10.8, 10.9, 11, 11.1, 11.2, 11.3, 11.4, 11.5, 11.6, 11.7, 11.8, 11.9, 12, 12.1, 12.2, 12.3, 12.4, 12.5, 12.6, 12.7, 12.8, 12.9, 13, 13.1, 13.2, 13.3, 13.4, 13.5, 13.6, 13.7, 13.8, 13.9, 14, 14.1, 14.2, 14.3, 14.4, 14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5, 15.6, 15.7, 15.8, 15.9, 16, 16.1, 16.2, 16.3, 16.4, 16.5, 16.6, 16.7, 16.8, 16.9, 17, 17.1, 17.2, 17.3, 17.4, 17.5, 17.6, 17.7, 17.8, 17.9, 18, 18.1, 18.2, 18.3, 18.4, 18.5, 18.6, 18.7, 18.8, 18.9, 19, 19.1, 19.2, 19.3, 19.4, 19.5, 19.6, 19.7, 19.8, 19.9]\nx=np.asarray(x)\ny = [0.000, 0.296, 0.407, 0.488, 0.552, 0.607, 0.655, 0.697, 0.734, 0.769, 0.800, 0.829, 0.855, 0.880, 0.903, 0.925, 0.945, 0.964, 0.982, 0.998, 1.014, 1.029, 1.043, 1.057, 1.069, 1.081, 1.092, 1.103, 1.113, 1.123, 1.132, 1.141, 1.149, 1.157, 1.164, 1.171, 1.177, 1.184, 1.189, 1.195, 1.200, 1.205, 1.209, 1.214, 1.218, 1.221, 1.225, 1.228, 1.231, 1.234, 1.236, 1.238, 1.240, 1.242, 1.244, 1.245, 1.246, 1.247, 1.248, 1.249, 1.249, 1.250, 1.250, 1.250, 1.250, 1.250, 1.249, 1.248, 1.248, 1.247, 1.246, 1.245, 1.243, 1.242, 1.240, 1.239, 1.237, 1.235, 1.233, 1.231, 1.228, 1.226, 1.224, 1.221, 1.218, 1.215, 1.213, 1.210, 1.206, 1.203, 1.200, 1.197, 1.193, 1.190, 1.186, 1.182, 1.178, 1.174, 1.170, 1.166, 1.162, 1.158, 1.154, 1.149, 1.145, 1.140, 1.136, 1.131, 1.126, 1.122, 1.117, 1.112, 1.107, 1.102, 1.096, 1.091, 1.086, 1.081, 1.075, 1.070, 1.064, 1.059, 1.053, 1.047, 1.041, 1.036, 1.030, 1.024, 1.018, 1.012, 1.006, 0.999, 0.993, 0.987, 0.981, 0.974, 0.968, 0.961, 0.955, 0.948, 0.942, 0.935, 0.928, 0.922, 0.915, 0.908, 0.901, 0.894, 0.887, 0.880, 0.873, 0.866, 0.859, 0.852, 0.844, 0.837, 0.830, 0.822, 0.815, 0.807, 0.800, 0.792, 0.785, 0.777, 0.770, 0.762, 0.754, 0.747, 0.739, 0.731, 0.723, 0.715, 0.707, 0.699, 0.691, 0.683, 0.675, 0.667, 0.659, 0.651, 0.643, 0.634, 0.626, 0.618, 0.610, 0.601, 0.593, 0.584, 0.576, 0.567, 0.559, 0.550, 0.542, 0.533, 0.525, 0.516, 0.507, 0.498, 0.490, 0.481]\ny=np.asarray(y)\nsample = [20, 20.1, 20.2, 20.3, 20.4, 20.5, 20.6, 20.7, 20.8, 20.9, 21, 21.1, 21.2, 21.3, 21.4]\nsample=np.asarray(sample)\n\nsize = len(x)\n\ninp = x.reshape(size,1)\ntar = y.reshape(size,1)\nsmp = sample.reshape(len(sample),1)\n#print(inp)\nprint(tar)\n# Create network with 2 layers and random initialized\n#net = nl.net.newelm([[min(x), max(y)]],[5, 1]) # neurolab.net.newff(minmax, size, transf=None)\nnet = nl.net.newelm([[min(x), max(y)]], [16, 1], [nl.trans.TanSig(), nl.trans.PureLin()])\n# Set initialized functions and init\nnet.layers[0].initf = nl.init.InitRand([-0.1, 0.1], 'wb')\nnet.layers[1].initf = nl.init.InitRand([-0.1, 0.1], 'wb')\nnet.init()\n# Train network\nerror = net.train(inp, tar, epochs=1900, show=100, goal=0.0001)\n\n# Simulate network\nout = net.sim(smp)\nprint(out)\n</code></pre>\n\n<p>It works fine with only one input time series (input vector). But I need more than one, in fact, I do need five input vectors.\nExample:\nI'm going to predict 6 rows of \"to_be_predicted\" column. The data: <a href=\"http://pastebin.com/7z1DeikJ\" rel=\"nofollow\">pastebin.com/7z1DeikJ</a>. So columns \"usd\", \"euro\", \"GDP_bln\", \"inflation\", \"CPI\" are the inputs and \"to_be_predicted\" is a target in my case.</p>\n\n<p>Does anybody know how to solve this issue? Thanks for your help!</p>\n",
                "tags": "<python><neural-network><time-series>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7401",
            "_score": 5.864428,
            "_source": {
                "title": "Using Generative Adversarial Network to generate Single Image",
                "content": "Using Generative Adversarial Network to generate Single Image <p>Most generative adversarial networks learn the distribution of the dataset and then generate a sample of 10's to 100's of images with similar distributions. I am curious if there is any research regenerating a single image.</p>\n\n<p>I have looked into Super Resolution GAN's and they somewhat model this. They try to estimate a highly resolved image from its lower resolution counterpart. Could that be used to recreate an image?</p>\n\n<p>Thanks for the help.</p>\n <deep-learning><gan><generative-models><p>A generative adversarial network is comprised of two parts which are necessary for the training, the generator and the discriminator. They are playing a game against each other, the discriminator tried to learn what is real and what is fake, and the generator tries to create fake instances which will fool the discriminator. </p>\n\n<p>At the input of the discriminator you will use real images, for example the MNIST numbers. At the input of the generator you will put just random noise vectors. These vectors will then be shaped by the layers of the generator to create some image, hopefully resembling the MNIST dataset. If it fools the discriminator, it wins that round. Otherwise, it will tune its weights using backpropagation in order to produce better quality results in the next round. </p>\n\n<p>Once training is complete, you will detach the discriminator and use only the generator. Then for every single random noise vector fed to the input of the generator you will receive an associated image. </p>\n\n<p>Here is a GaN implementation. You will need to put a path \"./gan/images/\" i the directory where you are running this GaN.</p>\n\n<pre><code>import numpy as np\nimport time\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nfrom keras.layers import Input\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Activation, Flatten, Reshape\nfrom keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\nfrom keras.layers import LeakyReLU, Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.datasets import mnist\n\nimport matplotlib.pyplot as plt\n\nclass GAN():\n    def __init__(self):\n        self.img_rows = 28 \n        self.img_cols = 28\n        self.channels = 1\n        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n\n        optimizer = Adam(0.0002, 0.5)\n\n        # Build and compile the discriminator\n        self.discriminator = self.build_discriminator()\n        self.discriminator.compile(loss='binary_crossentropy', \n            optimizer=optimizer,\n            metrics=['accuracy'])\n\n        # Build and compile the generator\n        self.generator = self.build_generator()\n        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n        # The generator takes noise as input and generated imgs\n        z = Input(shape=(28,28,))\n        img = self.generator(z)\n\n        # For the combined model we will only train the generator\n        self.discriminator.trainable = False\n\n        # The valid takes generated images as input and determines validity\n        valid = self.discriminator(img)\n\n        # The combined model  (stacked generator and discriminator) takes\n        # noise as input =&gt; generates images =&gt; determines validity \n        self.combined = Model(z, valid)\n        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n    def build_generator(self):\n\n        noise_shape = (28,28,)\n\n        model = Sequential()\n\n        model.add(Reshape((28*28,), input_shape=noise_shape))\n        model.add(Dense(256))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(1024))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n        model.add(Reshape(self.img_shape))   \n\n        model.summary()\n\n        noise = Input(shape=noise_shape)\n        img = model(noise)\n\n        return Model(noise, img)\n\n    def build_discriminator(self):\n\n        img_shape = (self.img_rows, self.img_cols, self.channels)\n\n        model = Sequential()\n\n        model.add(Conv2D(32, kernel_size=(3, 3),\n                 input_shape=img_shape))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n\n        model.add(Flatten())\n        model.add(Dense(64))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dense(1, activation='sigmoid'))\n        model.summary()\n\n        img = Input(shape=img_shape)\n        validity = model(img)\n\n        return Model(img, validity)\n\n    def train(self, epochs, batch_size=128, save_interval=50):\n\n        # Load the dataset\n        (X_train, _), (_, _) = mnist.load_data()\n\n        # Rescale -1 to 1\n        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n        X_train = np.expand_dims(X_train, axis=3)\n\n        half_batch = int(batch_size / 2)\n\n        for epoch in range(epochs):\n\n            # ---------------------\n            #  Train Discriminator\n            # ---------------------\n\n            # Select a random half batch of images\n            idx = np.random.randint(0, X_train.shape[0], half_batch)\n            imgs = X_train[idx]\n\n            noise = np.random.normal(0, 1, (half_batch,28,28,))\n\n            # Generate a half batch of new images\n            gen_imgs = self.generator.predict(noise)\n\n            # Train the discriminator\n            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n\n            # ---------------------\n            #  Train Generator\n            # ---------------------\n\n            noise = np.random.normal(0, 1, (batch_size,28,28,))\n\n            # The generator wants the discriminator to label the generated samples\n            # as valid (ones)\n            valid_y = np.array([1] * batch_size)\n\n            # Train the generator\n            g_loss = self.combined.train_on_batch(noise, valid_y)\n\n            # Plot the progress\n            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n\n            # If at save interval =&gt; save generated image samples\n            if epoch % save_interval == 0:\n                self.save_imgs(epoch)\n\n    def save_imgs(self, epoch):\n        r, c = 5, 5\n        noise = np.random.normal(0, 1, (r * c, 28,28,))\n        gen_imgs = self.generator.predict(noise)\n\n        # Rescale images 0 - 1\n        gen_imgs = 0.5 * gen_imgs + 0.5\n\n        fig, axs = plt.subplots(r, c)\n        cnt = 0\n        for i in range(r):\n            for j in range(c):\n                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n                axs[i,j].axis('off')\n                cnt += 1\n        fig.savefig(\"gan/images/mnist_%d.png\" % epoch)\n        plt.close()\n\n\nif __name__ == '__main__':\n    gan = GAN()\n    gan.train(epochs=30000, batch_size=64, save_interval=200)\n</code></pre>\n",
                "codes": [
                    [
                        "import numpy as np\nimport time\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nfrom keras.layers import Input\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Activation, Flatten, Reshape\nfrom keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\nfrom keras.layers import LeakyReLU, Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.datasets import mnist\n\nimport matplotlib.pyplot as plt\n\nclass GAN():\n    def __init__(self):\n        self.img_rows = 28 \n        self.img_cols = 28\n        self.channels = 1\n        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n\n        optimizer = Adam(0.0002, 0.5)\n\n        # Build and compile the discriminator\n        self.discriminator = self.build_discriminator()\n        self.discriminator.compile(loss='binary_crossentropy', \n            optimizer=optimizer,\n            metrics=['accuracy'])\n\n        # Build and compile the generator\n        self.generator = self.build_generator()\n        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n        # The generator takes noise as input and generated imgs\n        z = Input(shape=(28,28,))\n        img = self.generator(z)\n\n        # For the combined model we will only train the generator\n        self.discriminator.trainable = False\n\n        # The valid takes generated images as input and determines validity\n        valid = self.discriminator(img)\n\n        # The combined model  (stacked generator and discriminator) takes\n        # noise as input => generates images => determines validity \n        self.combined = Model(z, valid)\n        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n    def build_generator(self):\n\n        noise_shape = (28,28,)\n\n        model = Sequential()\n\n        model.add(Reshape((28*28,), input_shape=noise_shape))\n        model.add(Dense(256))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(1024))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n        model.add(Reshape(self.img_shape))   \n\n        model.summary()\n\n        noise = Input(shape=noise_shape)\n        img = model(noise)\n\n        return Model(noise, img)\n\n    def build_discriminator(self):\n\n        img_shape = (self.img_rows, self.img_cols, self.channels)\n\n        model = Sequential()\n\n        model.add(Conv2D(32, kernel_size=(3, 3),\n                 input_shape=img_shape))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n\n        model.add(Flatten())\n        model.add(Dense(64))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dense(1, activation='sigmoid'))\n        model.summary()\n\n        img = Input(shape=img_shape)\n        validity = model(img)\n\n        return Model(img, validity)\n\n    def train(self, epochs, batch_size=128, save_interval=50):\n\n        # Load the dataset\n        (X_train, _), (_, _) = mnist.load_data()\n\n        # Rescale -1 to 1\n        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n        X_train = np.expand_dims(X_train, axis=3)\n\n        half_batch = int(batch_size / 2)\n\n        for epoch in range(epochs):\n\n            # ---------------------\n            #  Train Discriminator\n            # ---------------------\n\n            # Select a random half batch of images\n            idx = np.random.randint(0, X_train.shape[0], half_batch)\n            imgs = X_train[idx]\n\n            noise = np.random.normal(0, 1, (half_batch,28,28,))\n\n            # Generate a half batch of new images\n            gen_imgs = self.generator.predict(noise)\n\n            # Train the discriminator\n            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n\n            # ---------------------\n            #  Train Generator\n            # ---------------------\n\n            noise = np.random.normal(0, 1, (batch_size,28,28,))\n\n            # The generator wants the discriminator to label the generated samples\n            # as valid (ones)\n            valid_y = np.array([1] * batch_size)\n\n            # Train the generator\n            g_loss = self.combined.train_on_batch(noise, valid_y)\n\n            # Plot the progress\n            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n\n            # If at save interval => save generated image samples\n            if epoch % save_interval == 0:\n                self.save_imgs(epoch)\n\n    def save_imgs(self, epoch):\n        r, c = 5, 5\n        noise = np.random.normal(0, 1, (r * c, 28,28,))\n        gen_imgs = self.generator.predict(noise)\n\n        # Rescale images 0 - 1\n        gen_imgs = 0.5 * gen_imgs + 0.5\n\n        fig, axs = plt.subplots(r, c)\n        cnt = 0\n        for i in range(r):\n            for j in range(c):\n                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n                axs[i,j].axis('off')\n                cnt += 1\n        fig.savefig(\"gan/images/mnist_%d.png\" % epoch)\n        plt.close()\n\n\nif __name__ == '__main__':\n    gan = GAN()\n    gan.train(epochs=30000, batch_size=64, save_interval=200)\n"
                    ]
                ],
                "question_id:": "27715",
                "question_votes:": "",
                "question_text:": "<p>Most generative adversarial networks learn the distribution of the dataset and then generate a sample of 10's to 100's of images with similar distributions. I am curious if there is any research regenerating a single image.</p>\n\n<p>I have looked into Super Resolution GAN's and they somewhat model this. They try to estimate a highly resolved image from its lower resolution counterpart. Could that be used to recreate an image?</p>\n\n<p>Thanks for the help.</p>\n",
                "tags": "<deep-learning><gan><generative-models>",
                "answers": [
                    [
                        "27787",
                        "2",
                        "27715",
                        "",
                        "",
                        "<p>A generative adversarial network is comprised of two parts which are necessary for the training, the generator and the discriminator. They are playing a game against each other, the discriminator tried to learn what is real and what is fake, and the generator tries to create fake instances which will fool the discriminator. </p>\n\n<p>At the input of the discriminator you will use real images, for example the MNIST numbers. At the input of the generator you will put just random noise vectors. These vectors will then be shaped by the layers of the generator to create some image, hopefully resembling the MNIST dataset. If it fools the discriminator, it wins that round. Otherwise, it will tune its weights using backpropagation in order to produce better quality results in the next round. </p>\n\n<p>Once training is complete, you will detach the discriminator and use only the generator. Then for every single random noise vector fed to the input of the generator you will receive an associated image. </p>\n\n<p>Here is a GaN implementation. You will need to put a path \"./gan/images/\" i the directory where you are running this GaN.</p>\n\n<pre><code>import numpy as np\nimport time\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nfrom keras.layers import Input\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Activation, Flatten, Reshape\nfrom keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\nfrom keras.layers import LeakyReLU, Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.datasets import mnist\n\nimport matplotlib.pyplot as plt\n\nclass GAN():\n    def __init__(self):\n        self.img_rows = 28 \n        self.img_cols = 28\n        self.channels = 1\n        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n\n        optimizer = Adam(0.0002, 0.5)\n\n        # Build and compile the discriminator\n        self.discriminator = self.build_discriminator()\n        self.discriminator.compile(loss='binary_crossentropy', \n            optimizer=optimizer,\n            metrics=['accuracy'])\n\n        # Build and compile the generator\n        self.generator = self.build_generator()\n        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n        # The generator takes noise as input and generated imgs\n        z = Input(shape=(28,28,))\n        img = self.generator(z)\n\n        # For the combined model we will only train the generator\n        self.discriminator.trainable = False\n\n        # The valid takes generated images as input and determines validity\n        valid = self.discriminator(img)\n\n        # The combined model  (stacked generator and discriminator) takes\n        # noise as input =&gt; generates images =&gt; determines validity \n        self.combined = Model(z, valid)\n        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n    def build_generator(self):\n\n        noise_shape = (28,28,)\n\n        model = Sequential()\n\n        model.add(Reshape((28*28,), input_shape=noise_shape))\n        model.add(Dense(256))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(1024))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n        model.add(Reshape(self.img_shape))   \n\n        model.summary()\n\n        noise = Input(shape=noise_shape)\n        img = model(noise)\n\n        return Model(noise, img)\n\n    def build_discriminator(self):\n\n        img_shape = (self.img_rows, self.img_cols, self.channels)\n\n        model = Sequential()\n\n        model.add(Conv2D(32, kernel_size=(3, 3),\n                 input_shape=img_shape))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n\n        model.add(Flatten())\n        model.add(Dense(64))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dense(1, activation='sigmoid'))\n        model.summary()\n\n        img = Input(shape=img_shape)\n        validity = model(img)\n\n        return Model(img, validity)\n\n    def train(self, epochs, batch_size=128, save_interval=50):\n\n        # Load the dataset\n        (X_train, _), (_, _) = mnist.load_data()\n\n        # Rescale -1 to 1\n        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n        X_train = np.expand_dims(X_train, axis=3)\n\n        half_batch = int(batch_size / 2)\n\n        for epoch in range(epochs):\n\n            # ---------------------\n            #  Train Discriminator\n            # ---------------------\n\n            # Select a random half batch of images\n            idx = np.random.randint(0, X_train.shape[0], half_batch)\n            imgs = X_train[idx]\n\n            noise = np.random.normal(0, 1, (half_batch,28,28,))\n\n            # Generate a half batch of new images\n            gen_imgs = self.generator.predict(noise)\n\n            # Train the discriminator\n            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n\n            # ---------------------\n            #  Train Generator\n            # ---------------------\n\n            noise = np.random.normal(0, 1, (batch_size,28,28,))\n\n            # The generator wants the discriminator to label the generated samples\n            # as valid (ones)\n            valid_y = np.array([1] * batch_size)\n\n            # Train the generator\n            g_loss = self.combined.train_on_batch(noise, valid_y)\n\n            # Plot the progress\n            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n\n            # If at save interval =&gt; save generated image samples\n            if epoch % save_interval == 0:\n                self.save_imgs(epoch)\n\n    def save_imgs(self, epoch):\n        r, c = 5, 5\n        noise = np.random.normal(0, 1, (r * c, 28,28,))\n        gen_imgs = self.generator.predict(noise)\n\n        # Rescale images 0 - 1\n        gen_imgs = 0.5 * gen_imgs + 0.5\n\n        fig, axs = plt.subplots(r, c)\n        cnt = 0\n        for i in range(r):\n            for j in range(c):\n                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n                axs[i,j].axis('off')\n                cnt += 1\n        fig.savefig(\"gan/images/mnist_%d.png\" % epoch)\n        plt.close()\n\n\nif __name__ == '__main__':\n    gan = GAN()\n    gan.train(epochs=30000, batch_size=64, save_interval=200)\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10273",
            "_score": 5.864428,
            "_source": {
                "title": "What is wrong with this reinforcement learning environment ?",
                "content": "What is wrong with this reinforcement learning environment ? <p>I'm working on below reinforcement learning problem:\nI have bottle of fix capacity (say 5 liters). At the bottom of bottle there is cock to remove\nwater. The distribution of removal of water is not fixed. we can remove any amount of water from bottle, i.e. any continuous value between [0, 5]. </p>\n\n<p>At the top of the bottle one tap is mounted to fill water in the bottle.  RL agent can fill [0, 1, 2, 3, 4] liters in the bottle. Initial bottle level is any value between [0, 5].</p>\n\n<p>I want to train the agent in this environment to get optimal sequence of \nactions such that bottle will not get empty and overflow which implies continuous supply of water demand.</p>\n\n<p>Action space = [0, 1, 2, 3, 4] Discrete Space</p>\n\n<p>Observation Space = [0, Capacity of Bottle] i.e. [0, 5] Continuous Space</p>\n\n<p>Reward logic = if bottle empty due to action give negative rewards; if bottle overflow due to action give negative rewards</p>\n\n<p>I have decided to use python to create an environment. </p>\n\n<pre><code>from gym import spaces\nimport numpy as np\n\nclass WaterEnv():\n    def __init__(self, BottleCapacity = 5):\n        ## CONSTANTS\n        self.MinLevel = 0 # minimum water level\n        self.BottleCapacity = BottleCapacity # bottle capacity\n            # action space\n        self.action_space = spaces.Discrete(self.BottleCapacity)\n            # observation space\n        self.observation_space = spaces.Box(low=self.MinLevel, high=self.BottleCapacity,\n                                            shape=(1,))\n        # initial bottle level\n        self.initBlevel = self.observation_space.sample()\n\n    def step(self, action):\n        # water qty to remove\n        WaterRemoveQty = np.random.uniform(self.MinLevel, self.BottleCapacity, 1)\n\n        # updated water level after removal of water\n        UpdatedWaterLevel = (self.initBlevel - WaterRemoveQty)\n        # add water - action taken\n        UpdatedWaterLevel_ = UpdatedWaterLevel +  action\n\n        if UpdatedWaterLevel_ &lt;= self.MinLevel:\n            reward = -1\n            done = True\n        elif UpdatedWaterLevel_ &gt; self.BottleCapacity:\n            reward = -1\n            done = True\n        else:\n            reward = 0.5\n            done = False\n\n        return UpdatedWaterLevel_, reward, done\n\n    def reset(self):\n        \"\"\"\n        Reset the initial bottle value\n        \"\"\"\n        self.initBlevel = self.observation_space.sample()\n\n        return self.initBlevel\n\nimport random\nfrom collections import deque\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import sgd\n\nclass DQNAgent:\n    def __init__(self, state_size, action_size):\n        self.state_size = state_size\n        self.action_size = action_size\n        self.memory = deque(maxlen=2000) # memory size\n        self.gamma = 0.99    # discount rate\n        self.epsilon = 1.0  # exploration rate\n        self.epsilon_min = 0.01 # minmun exploration rate\n        self.epsilon_decay = 0.99 # exploration decay\n        self.learning_rate = 0.001 # learning rate\n        self.model = self._build_model()\n\n    def _build_model(self):\n        # Neural Net for Deep-Q learning Model\n        model = Sequential()\n        model.add(Dense(256, input_dim=self.state_size, activation='relu'))\n        model.add(Dense(256, activation='relu'))\n        model.add(Dense(self.action_size, activation='linear'))\n        model.compile(loss='mse',\n                      optimizer=sgd(lr=self.learning_rate))\n        return model\n\n    def remember(self, state, action, reward, next_state, done):\n        self.memory.append((state, action, reward, next_state, done))\n\n    def act(self, state):\n        if np.random.rand() &lt;= self.epsilon:\n            return random.randrange(self.action_size)\n        act_values = self.model.predict(state)\n        return np.argmax(act_values[0])  # returns action\n\n    def replay(self, batch_size):\n        minibatch = random.sample(self.memory, batch_size)\n        for state, action, reward, next_state, done in minibatch:\n            target = reward\n            if not done:\n                target = (reward + self.gamma *\n                          np.amax(self.model.predict(next_state)[0]))\n            target_f = self.model.predict(state)\n            target_f[0][action] = target\n            self.model.fit(state, target_f, epochs=1, verbose=0)\n        if self.epsilon &gt; self.epsilon_min:\n            self.epsilon *= self.epsilon_decay\n\n# create iSilo enviroment object\nenv = WaterEnv()\n\nstate_size = env.observation_space.shape[0]\naction_size = env.action_space.n\n\nminibatch = 32\n\n# Initialize agent\nagent = DQNAgent(state_size, action_size)\n\ndone = False\nlReward = []  # carry the reward upto end of simulation\nrewardAll = 0\nXArray = [] # carry the actions upto end of simulation\n\nEPOCHS = 1000\n\nfor e in range(EPOCHS):\n        #state = np.reshape(state, [1, 1])\n        # reset state in the beginning of each epoch\n        state = env.reset()\n        time_t = 0\n        rewardAll = 0\n\n        while True:\n            # Decide action\n            #state = np.reshape(state, [1, 1])\n            action = agent.act(state)\n\n            next_state,reward, done = env.step(action)\n            #reward = reward if not done else -10\n\n            # Remember the previous state, action, reward, and done\n            #next_state = np.reshape(next_state, [1, state_size])\n            agent.remember(state, action, reward, next_state, done)\n            # remembering the action for perfrormace check\n            XArray.append(action)\n            # Assign next_state the new current state for the next frame.\n            state = next_state\n\n            if done:\n                print(\"  episode: {}/{}, score: {}, e: {:.2}\"\n                      .format(e, EPOCHS, time_t, agent.epsilon))\n                break\n            rewardAll += reward\n\n            # experience and reply\n            if len(agent.memory) &gt; minibatch:\n                agent.replay(minibatch)\n\n        lReward.append(rewardAll) # append the rewards\n</code></pre>\n\n<p>After running the 1000 epoch, I observed that agent has not learned anything. Unable to find out whats going wrong. </p>\n <machine-learning><deep-learning><reinforcement-learning><dqn><openai-gym><p>I can see two issues:</p>\n\n<ol>\n<li><p>Your environment is not tracking changes to state, just random success/fail based on <code>self.initBlevel</code> which is never modified to reflect changes. Although you calculate and return the new state (as variable <code>UpdatedWaterLevel_</code>), this is not fed back into the system. You store it as the next \"state\" in the DQN replay table, but don't actually store it in the environment as the current state. You should do that - without it the replay table will be filled with incorrect values. There should be a variable that the environment has access to which represents the current state.</p></li>\n<li><p>You are running the system as an episodic problem, but do not re-set the environment for the start of a new episode. This is a \"hidden\" bug due to the issue above, but would immediately become a problem for you if you let the state go outside the bounds of the problem you have defined.</p></li>\n</ol>\n\n<p>Given the problem setup, I would expect the agent to learn to always fill the container to the maximum possible capacity (and it would then get drained by the amount of the random request). That would lead to infinitely long episodes, so you do still need discounting.</p>\n\n<p>Possibly your NN is over-complex for this simple task, which could make learning slower. But that's harder to tell. The relationship to expected future discounted reward based on current state and action is complex, so you might need a moderate size of network to capture that.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "37081",
                "question_votes:": "2",
                "question_text:": "<p>I'm working on below reinforcement learning problem:\nI have bottle of fix capacity (say 5 liters). At the bottom of bottle there is cock to remove\nwater. The distribution of removal of water is not fixed. we can remove any amount of water from bottle, i.e. any continuous value between [0, 5]. </p>\n\n<p>At the top of the bottle one tap is mounted to fill water in the bottle.  RL agent can fill [0, 1, 2, 3, 4] liters in the bottle. Initial bottle level is any value between [0, 5].</p>\n\n<p>I want to train the agent in this environment to get optimal sequence of \nactions such that bottle will not get empty and overflow which implies continuous supply of water demand.</p>\n\n<p>Action space = [0, 1, 2, 3, 4] Discrete Space</p>\n\n<p>Observation Space = [0, Capacity of Bottle] i.e. [0, 5] Continuous Space</p>\n\n<p>Reward logic = if bottle empty due to action give negative rewards; if bottle overflow due to action give negative rewards</p>\n\n<p>I have decided to use python to create an environment. </p>\n\n<pre><code>from gym import spaces\nimport numpy as np\n\nclass WaterEnv():\n    def __init__(self, BottleCapacity = 5):\n        ## CONSTANTS\n        self.MinLevel = 0 # minimum water level\n        self.BottleCapacity = BottleCapacity # bottle capacity\n            # action space\n        self.action_space = spaces.Discrete(self.BottleCapacity)\n            # observation space\n        self.observation_space = spaces.Box(low=self.MinLevel, high=self.BottleCapacity,\n                                            shape=(1,))\n        # initial bottle level\n        self.initBlevel = self.observation_space.sample()\n\n    def step(self, action):\n        # water qty to remove\n        WaterRemoveQty = np.random.uniform(self.MinLevel, self.BottleCapacity, 1)\n\n        # updated water level after removal of water\n        UpdatedWaterLevel = (self.initBlevel - WaterRemoveQty)\n        # add water - action taken\n        UpdatedWaterLevel_ = UpdatedWaterLevel +  action\n\n        if UpdatedWaterLevel_ &lt;= self.MinLevel:\n            reward = -1\n            done = True\n        elif UpdatedWaterLevel_ &gt; self.BottleCapacity:\n            reward = -1\n            done = True\n        else:\n            reward = 0.5\n            done = False\n\n        return UpdatedWaterLevel_, reward, done\n\n    def reset(self):\n        \"\"\"\n        Reset the initial bottle value\n        \"\"\"\n        self.initBlevel = self.observation_space.sample()\n\n        return self.initBlevel\n\nimport random\nfrom collections import deque\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import sgd\n\nclass DQNAgent:\n    def __init__(self, state_size, action_size):\n        self.state_size = state_size\n        self.action_size = action_size\n        self.memory = deque(maxlen=2000) # memory size\n        self.gamma = 0.99    # discount rate\n        self.epsilon = 1.0  # exploration rate\n        self.epsilon_min = 0.01 # minmun exploration rate\n        self.epsilon_decay = 0.99 # exploration decay\n        self.learning_rate = 0.001 # learning rate\n        self.model = self._build_model()\n\n    def _build_model(self):\n        # Neural Net for Deep-Q learning Model\n        model = Sequential()\n        model.add(Dense(256, input_dim=self.state_size, activation='relu'))\n        model.add(Dense(256, activation='relu'))\n        model.add(Dense(self.action_size, activation='linear'))\n        model.compile(loss='mse',\n                      optimizer=sgd(lr=self.learning_rate))\n        return model\n\n    def remember(self, state, action, reward, next_state, done):\n        self.memory.append((state, action, reward, next_state, done))\n\n    def act(self, state):\n        if np.random.rand() &lt;= self.epsilon:\n            return random.randrange(self.action_size)\n        act_values = self.model.predict(state)\n        return np.argmax(act_values[0])  # returns action\n\n    def replay(self, batch_size):\n        minibatch = random.sample(self.memory, batch_size)\n        for state, action, reward, next_state, done in minibatch:\n            target = reward\n            if not done:\n                target = (reward + self.gamma *\n                          np.amax(self.model.predict(next_state)[0]))\n            target_f = self.model.predict(state)\n            target_f[0][action] = target\n            self.model.fit(state, target_f, epochs=1, verbose=0)\n        if self.epsilon &gt; self.epsilon_min:\n            self.epsilon *= self.epsilon_decay\n\n# create iSilo enviroment object\nenv = WaterEnv()\n\nstate_size = env.observation_space.shape[0]\naction_size = env.action_space.n\n\nminibatch = 32\n\n# Initialize agent\nagent = DQNAgent(state_size, action_size)\n\ndone = False\nlReward = []  # carry the reward upto end of simulation\nrewardAll = 0\nXArray = [] # carry the actions upto end of simulation\n\nEPOCHS = 1000\n\nfor e in range(EPOCHS):\n        #state = np.reshape(state, [1, 1])\n        # reset state in the beginning of each epoch\n        state = env.reset()\n        time_t = 0\n        rewardAll = 0\n\n        while True:\n            # Decide action\n            #state = np.reshape(state, [1, 1])\n            action = agent.act(state)\n\n            next_state,reward, done = env.step(action)\n            #reward = reward if not done else -10\n\n            # Remember the previous state, action, reward, and done\n            #next_state = np.reshape(next_state, [1, state_size])\n            agent.remember(state, action, reward, next_state, done)\n            # remembering the action for perfrormace check\n            XArray.append(action)\n            # Assign next_state the new current state for the next frame.\n            state = next_state\n\n            if done:\n                print(\"  episode: {}/{}, score: {}, e: {:.2}\"\n                      .format(e, EPOCHS, time_t, agent.epsilon))\n                break\n            rewardAll += reward\n\n            # experience and reply\n            if len(agent.memory) &gt; minibatch:\n                agent.replay(minibatch)\n\n        lReward.append(rewardAll) # append the rewards\n</code></pre>\n\n<p>After running the 1000 epoch, I observed that agent has not learned anything. Unable to find out whats going wrong. </p>\n",
                "tags": "<machine-learning><deep-learning><reinforcement-learning><dqn><openai-gym>",
                "answers": [
                    [
                        "37089",
                        "2",
                        "37081",
                        "",
                        "",
                        "<p>I can see two issues:</p>\n\n<ol>\n<li><p>Your environment is not tracking changes to state, just random success/fail based on <code>self.initBlevel</code> which is never modified to reflect changes. Although you calculate and return the new state (as variable <code>UpdatedWaterLevel_</code>), this is not fed back into the system. You store it as the next \"state\" in the DQN replay table, but don't actually store it in the environment as the current state. You should do that - without it the replay table will be filled with incorrect values. There should be a variable that the environment has access to which represents the current state.</p></li>\n<li><p>You are running the system as an episodic problem, but do not re-set the environment for the start of a new episode. This is a \"hidden\" bug due to the issue above, but would immediately become a problem for you if you let the state go outside the bounds of the problem you have defined.</p></li>\n</ol>\n\n<p>Given the problem setup, I would expect the agent to learn to always fill the container to the maximum possible capacity (and it would then get drained by the amount of the random request). That would lead to infinitely long episodes, so you do still need discounting.</p>\n\n<p>Possibly your NN is over-complex for this simple task, which could make learning slower. But that's harder to tell. The relationship to expected future discounted reward based on current state and action is complex, so you might need a moderate size of network to capture that.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "18108",
            "_score": 5.8422728,
            "_source": {
                "title": "Unable to learn weights of a Word2Vec model",
                "content": "Unable to learn weights of a Word2Vec model <p>I was going to implement a word embedding model - namely Word2Vec - by following <a href=\"https://www.tensorflow.org/tutorials/representation/word2vec\" rel=\"nofollow noreferrer\">this TensorFlow tutorial</a> and adapting the code a little bit. Unfortunately, though, my model won't learn anything. I've used TensorBoard to keep track of the value of the loss function <em>and</em> to observe how the network's weights evolve over time. Here's what I found:</p>\n\n<ol>\n<li>The value of the loss function keeps fluctuating up and down</li>\n<li>The network's weights stay constant during the training process</li>\n</ol>\n\n<p>I honestly can't understand why this is happening. I've tried setting \"trainable=True\" explicitly when creating variables, but that didn't help either.\nHere's the code that I'm using right now:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import tensorflow as tf\nimport numpy as np\n\nvocabulary_size = 13046\nembedding_size = 256\nnum_noise = 1\nlearning_rate = 1e-3\nbatch_size = 1024\nepochs = 10\n\ndef make_hparam_string(embedding_size, num_noise, learning_rate, batch_size, epochs):\n    return f'es={embedding_size}_nn={num_noise}_lr={learning_rate}_bs={batch_size}_e={epochs}'\n\n# These are the hidden layer weights\nembeddings = tf.get_variable(name='embeddings', initializer=tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0), trainable=True)\n\n# 'nce' stands for 'Noise-contrastive estimation' and represents a particular loss function.\n# Check https://www.tensorflow.org/tutorials/representation/word2vec for more details.\n# 'nce_weights' and 'nce_biases' are simply the output weights and biases.\n# NOTE: for some reason, even though output weights will have shape (embedding_size, vocabulary_size),\n#       we have to initialize them with the shape (vocabulary_size, embedding_size)\nnce_weights = tf.get_variable(name='output_weights',\n                              initializer=tf.truncated_normal([vocabulary_size, embedding_size], stddev=1.0 / np.sqrt(embedding_size)), \n                              trainable=True)\nnce_biases = tf.get_variable(name='output_biases', initializer=tf.constant_initializer(0.1), shape=[vocabulary_size], trainable=True)\n\n# Placeholders for inputs\ntrain_inputs = tf.placeholder(tf.int32, shape=[None])    # [batch_size]\ntrain_labels = tf.placeholder(tf.int32, shape=[None, 1]) # [batch_size, 1]\n\n# This allows us to quickly retrieve the corresponding word embeddings for each word in 'train_inputs'\nmatched_embeddings = tf.nn.embedding_lookup(embeddings, train_inputs)\n\n# Compute the NCE loss, using a sample of the negative labels each time.\nloss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weights,\n                                     biases=nce_biases,\n                                     labels=train_labels,\n                                     inputs=matched_embeddings,\n                                     num_sampled=num_noise,\n                                     num_classes=vocabulary_size))\n\n# Use the SGD optimizer to minimize the loss function\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n\n# Add some summaries for TensorBoard\nloss_summary = tf.summary.scalar('nce_loss', loss)\ninput_embeddings_summary = tf.summary.histogram('input_embeddings', embeddings)\noutput_embeddings_summary = tf.summary.histogram('output_embeddings', nce_weights)\n\n################################################################################\n\n# Load data\ntarget_words = np.genfromtxt('target_words.txt', dtype=int, delimiter='\\n').reshape((-1, 1))\ncontext_words = np.genfromtxt('context_words.txt', dtype=int, delimiter='\\n').reshape((-1, 1))\n\n# Convert to tensors\ntarget_words_tensor = tf.convert_to_tensor(target_words)\ncontext_words_tensor = tf.convert_to_tensor(context_words)\n\n# Create a tf.data.Dataset object representing our dataset\ndataset = tf.data.Dataset.from_tensor_slices((target_words_tensor, context_words_tensor))\ndataset = dataset.shuffle(buffer_size=target_words.shape[0])\ndataset = dataset.batch(batch_size)\n\n# Create an iterator to iterate over the dataset\niterator = dataset.make_initializable_iterator()\nnext_batch = iterator.get_next()\n\n# Train the model\nwith tf.Session() as session:\n\n    # Initialize variables\n    session.run( tf.global_variables_initializer() )\n\n    merged_summary = tf.summary.merge_all()\n\n    # File writer for TensorBoard\n    hparam_string = make_hparam_string(embedding_size, num_noise, learning_rate, batch_size, epochs)\n    loss_writer = tf.summary.FileWriter(f'./tensorboard/{hparam_string}')\n\n    global_step = 0\n    for epoch in range(epochs):\n\n        session.run(iterator.initializer)\n        while True:\n            try:\n                inputs, labels = session.run(next_batch)\n\n                feed_dict = {train_inputs: inputs[:, 0], train_labels: labels}\n                _, cur_loss, all_summaries = session.run([optimizer, loss, merged_summary], feed_dict=feed_dict)\n\n                # Write sumaries to disk\n                loss_writer.add_summary(all_summaries, global_step=global_step)\n                global_step += 1\n\n                print(f'Current loss: {cur_loss}')\n\n            except tf.errors.OutOfRangeError:\n                print(f'Finished epoch {epoch}.')\n                break\n\n</code></pre>\n <machine-learning><python><tensorflow><word2vec><p>From your code it appears you are running for 10 epochs. It is highly improbable that your model will make significant progress in so few epochs. You might start to see learning after 1000 epochs, but large scale implementations of word2vec often require millions of epochs and take months to train to an acceptable level.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "57681",
                "question_votes:": "1",
                "question_text:": "<p>I was going to implement a word embedding model - namely Word2Vec - by following <a href=\"https://www.tensorflow.org/tutorials/representation/word2vec\" rel=\"nofollow noreferrer\">this TensorFlow tutorial</a> and adapting the code a little bit. Unfortunately, though, my model won't learn anything. I've used TensorBoard to keep track of the value of the loss function <em>and</em> to observe how the network's weights evolve over time. Here's what I found:</p>\n\n<ol>\n<li>The value of the loss function keeps fluctuating up and down</li>\n<li>The network's weights stay constant during the training process</li>\n</ol>\n\n<p>I honestly can't understand why this is happening. I've tried setting \"trainable=True\" explicitly when creating variables, but that didn't help either.\nHere's the code that I'm using right now:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import tensorflow as tf\nimport numpy as np\n\nvocabulary_size = 13046\nembedding_size = 256\nnum_noise = 1\nlearning_rate = 1e-3\nbatch_size = 1024\nepochs = 10\n\ndef make_hparam_string(embedding_size, num_noise, learning_rate, batch_size, epochs):\n    return f'es={embedding_size}_nn={num_noise}_lr={learning_rate}_bs={batch_size}_e={epochs}'\n\n# These are the hidden layer weights\nembeddings = tf.get_variable(name='embeddings', initializer=tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0), trainable=True)\n\n# 'nce' stands for 'Noise-contrastive estimation' and represents a particular loss function.\n# Check https://www.tensorflow.org/tutorials/representation/word2vec for more details.\n# 'nce_weights' and 'nce_biases' are simply the output weights and biases.\n# NOTE: for some reason, even though output weights will have shape (embedding_size, vocabulary_size),\n#       we have to initialize them with the shape (vocabulary_size, embedding_size)\nnce_weights = tf.get_variable(name='output_weights',\n                              initializer=tf.truncated_normal([vocabulary_size, embedding_size], stddev=1.0 / np.sqrt(embedding_size)), \n                              trainable=True)\nnce_biases = tf.get_variable(name='output_biases', initializer=tf.constant_initializer(0.1), shape=[vocabulary_size], trainable=True)\n\n# Placeholders for inputs\ntrain_inputs = tf.placeholder(tf.int32, shape=[None])    # [batch_size]\ntrain_labels = tf.placeholder(tf.int32, shape=[None, 1]) # [batch_size, 1]\n\n# This allows us to quickly retrieve the corresponding word embeddings for each word in 'train_inputs'\nmatched_embeddings = tf.nn.embedding_lookup(embeddings, train_inputs)\n\n# Compute the NCE loss, using a sample of the negative labels each time.\nloss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weights,\n                                     biases=nce_biases,\n                                     labels=train_labels,\n                                     inputs=matched_embeddings,\n                                     num_sampled=num_noise,\n                                     num_classes=vocabulary_size))\n\n# Use the SGD optimizer to minimize the loss function\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n\n# Add some summaries for TensorBoard\nloss_summary = tf.summary.scalar('nce_loss', loss)\ninput_embeddings_summary = tf.summary.histogram('input_embeddings', embeddings)\noutput_embeddings_summary = tf.summary.histogram('output_embeddings', nce_weights)\n\n################################################################################\n\n# Load data\ntarget_words = np.genfromtxt('target_words.txt', dtype=int, delimiter='\\n').reshape((-1, 1))\ncontext_words = np.genfromtxt('context_words.txt', dtype=int, delimiter='\\n').reshape((-1, 1))\n\n# Convert to tensors\ntarget_words_tensor = tf.convert_to_tensor(target_words)\ncontext_words_tensor = tf.convert_to_tensor(context_words)\n\n# Create a tf.data.Dataset object representing our dataset\ndataset = tf.data.Dataset.from_tensor_slices((target_words_tensor, context_words_tensor))\ndataset = dataset.shuffle(buffer_size=target_words.shape[0])\ndataset = dataset.batch(batch_size)\n\n# Create an iterator to iterate over the dataset\niterator = dataset.make_initializable_iterator()\nnext_batch = iterator.get_next()\n\n# Train the model\nwith tf.Session() as session:\n\n    # Initialize variables\n    session.run( tf.global_variables_initializer() )\n\n    merged_summary = tf.summary.merge_all()\n\n    # File writer for TensorBoard\n    hparam_string = make_hparam_string(embedding_size, num_noise, learning_rate, batch_size, epochs)\n    loss_writer = tf.summary.FileWriter(f'./tensorboard/{hparam_string}')\n\n    global_step = 0\n    for epoch in range(epochs):\n\n        session.run(iterator.initializer)\n        while True:\n            try:\n                inputs, labels = session.run(next_batch)\n\n                feed_dict = {train_inputs: inputs[:, 0], train_labels: labels}\n                _, cur_loss, all_summaries = session.run([optimizer, loss, merged_summary], feed_dict=feed_dict)\n\n                # Write sumaries to disk\n                loss_writer.add_summary(all_summaries, global_step=global_step)\n                global_step += 1\n\n                print(f'Current loss: {cur_loss}')\n\n            except tf.errors.OutOfRangeError:\n                print(f'Finished epoch {epoch}.')\n                break\n\n</code></pre>\n",
                "tags": "<machine-learning><python><tensorflow><word2vec>",
                "answers": [
                    [
                        "57872",
                        "2",
                        "57681",
                        "",
                        "",
                        "<p>From your code it appears you are running for 10 epochs. It is highly improbable that your model will make significant progress in so few epochs. You might start to see learning after 1000 epochs, but large scale implementations of word2vec often require millions of epochs and take months to train to an acceptable level.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7647",
            "_score": 5.826886,
            "_source": {
                "title": "LSTM: How to deal with nonstationarity when predicting a time series",
                "content": "LSTM: How to deal with nonstationarity when predicting a time series <p>I want to do one-step-ahead predictions for time series with LSTM.\nTo understand the algorithm, I built myself a toy example: A simple autocorrelated process.</p>\n\n<pre><code>def my_process(n, p, drift=0, displacement=0):\n    x = np.zeros(n)\n\n    for i in range(1, n):\n        x[i] = drift * i + p * x[i-1] + (1-p) * np.random.randn()\n    return x + displacement\n</code></pre>\n\n<p>Then I built an LSTM model in Keras, following <a href=\"https://www.kaggle.com/pablocastilla/predict-stock-prices-with-lstm\" rel=\"nofollow noreferrer\">this example</a>.\nI simulated processes with high autocorrelation <code>p=0.99</code> of length <code>n=10000</code>, trained the neural network on the first 80% of it and let it do one-step-ahead predictions for the remaning 20%.</p>\n\n<p>If I set <code>drift=0, displacement=0</code>, everything works fine:\n<a href=\"https://i.stack.imgur.com/m3efr.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/m3efr.png\" alt=\"enter image description here\"></a></p>\n\n<p>Then I set <code>drift=0, displacement=10</code> and things went pear-shaped (notice the different scale on the y-axis):\n<a href=\"https://i.stack.imgur.com/VaMQw.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/VaMQw.png\" alt=\"enter image description here\"></a></p>\n\n<p>This is not terribly surprising: LSTMs should be fed with normalized data!\nSo I normalized the data by rescaling it to the interval <span class=\"math-container\">$[-1, 1]$</span>.\nPhew, things are fine again:\n<a href=\"https://i.stack.imgur.com/9nGs9.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/9nGs9.png\" alt=\"enter image description here\"></a></p>\n\n<p>Then I set <code>drift=0.00001, displacement=10</code>, normalized the data again and ran the algorithm on it.\nThis does not look good:\n<a href=\"https://i.stack.imgur.com/iwrH5.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/iwrH5.png\" alt=\"enter image description here\"></a></p>\n\n<p>Apparently the LSTM cannot deal with a drift. \nWhat to do? (Yes, in this toy example I could simply subtract the drift; but for real-world time series, this is much harder).\nMaybe I could run my LSTM on the difference <span class=\"math-container\">$X_{t} - X_{t-1}$</span> instead of the original time series <span class=\"math-container\">$X_t$</span>. This will remove any constant drift from the time series.\nBut running the LSTM on the differenced time series does not work at all:\n<a href=\"https://i.stack.imgur.com/B4yLg.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/B4yLg.png\" alt=\"enter image description here\"></a></p>\n\n<p>My question: Why does my algorithm break down when I use it on the differenced time series?\nWhat is a good way to deal with drifts in time series?</p>\n\n<p>Here is the full code for my model:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Sequential\n\n\n# The LSTM model\nmy_model = Sequential()\n\nmy_model.add(LSTM(input_shape=(1, 1), units=50, return_sequences=True))\nmy_model.add(Dropout(0.2))\n\nmy_model.add(LSTM(units=100, return_sequences=False))\nmy_model.add(Dropout(0.2))\n\nmy_model.add(Dense(units=1))\nmy_model.add(Activation('linear'))\n\nmy_model.compile(loss='mse', optimizer='rmsprop')\n\n\ndef my_prediction(x, model, normalize=False, difference=False):\n    # Plot the process x\n    plt.figure(figsize=(15, 7))\n    plt.subplot(121)\n    plt.plot(x)\n    plt.title('Original data')\n\n    n = len(x)\n    thrs = int(0.8 * n)    # Train-test split\n    # Save starting values for test set to reverse differencing\n    x_test_0 = x[thrs + 1]\n    # Save minimum and maximum on test set to reverse normalization\n    x_min = min(x[:thrs])  \n    x_max = max(x[:thrs])\n\n    if difference:\n        x = np.diff(x)   # Take difference to remove drift\n    if normalize:\n        x = (2*x - x_min - x_max) / (x_max - x_min)   # Normalize to [-1, 1]\n\n    # Split into train and test set. The model will be trained on one-step-ahead predictions.\n    x_train, y_train, x_test, y_test = x[0:(thrs-1)], x[1:thrs], x[thrs:(n-1)], x[(thrs+1):n]\n\n    x_train, x_test = x_train.reshape(-1, 1, 1), x_test.reshape(-1, 1, 1)\n    y_train, y_test = y_train.reshape(-1, 1), y_test.reshape(-1, 1)\n\n    # Fit the model\n    model.fit(x_train, y_train, batch_size=200, epochs=10, validation_split=0.05, verbose=0)\n\n    # Predict the test set\n    y_pred = model.predict(x_test)\n\n    # Reverse differencing and normalization\n    if normalize:\n        y_pred = ((x_max - x_min) * y_pred + x_max + x_min) / 2\n        y_test = ((x_max - x_min) * y_test + x_max + x_min) / 2  \n    if difference:\n        y_pred = x_test_0 + np.cumsum(y_pred)\n        y_test = x_test_0 + np.cumsum(y_test)\n\n    # Plot estimation\n    plt.subplot(122)\n    plt.plot(y_pred[-100:], label='One-step-ahead-predictions')\n    plt.plot(y_test[-100:], label='Actual data')\n    plt.title('Prediction on test set')\n    plt.legend()\n    plt.show()\n\n# Make plots\nx = my_process(10000, 0.99, drift=0, displacement=0)\nmy_prediction(x, my_model, normalize=False, difference=False)\n\nx = my_process(10000, 0.99, drift=0, displacement=10)\nmy_prediction(x, my_model, normalize=False, difference=False)\n\nx = my_process(10000, 0.99, drift=0, displacement=10)\nmy_prediction(x, my_model, normalize=True, difference=False)\n\nx = my_process(10000, 0.99, drift=0.00001, displacement=10)\nmy_prediction(x, my_model, normalize=True, difference=False)\n\nx = my_process(10000, 0.99, drift=0.00001, displacement=10)\nmy_prediction(x, my_model, normalize=True, difference=True)\n</code></pre>\n <python><keras><time-series><lstm><p>Looking again at your autocorrelated process:</p>\n\n<pre><code>    def my_process(n, p, drift=0, displacement=0):\n        x = np.zeros(n)\n\n        for i in range(1, n):\n            x[i] = drift * i + p * x[i-1] + (1-p) * np.random.randn()\n    return x + displacement\n</code></pre>\n\n<p>It looks like things are breaking down when the value of <code>displacement</code> is high. This makes sense, as you say, because LSTMs need normalized data. </p>\n\n<p>The <code>drift</code> parameter is a bit different. When a small amount of drift is included, since <code>p</code> is large, the amount of drift is similar to the amount of random noise being added via <code>np.random.randn()</code>. </p>\n\n<p>In the plots for <code>drift=0.00001, displacement=10</code>, it looks like the predictions would be fine except for the y-shift. Because of this, I think the root of the problem is still in the <code>displacement</code> parameter, not the <code>drift</code> parameter. Differencing, as has been done, will not help with the <code>displacement</code> parameter; instead, it corrects for drift. </p>\n\n<p>I can't tell from your code, but it looks like perhaps the <code>displacement</code> was not accounted for in <code>model.predict</code>. That's my best guess. </p>\n<p>When you choose <code>x_min</code> and <code>x_max</code>, you are choosing it from <code>1:threshold</code> alone.\nSince your series is monotonically increasing (well almost..), the testing values are all values > 1.\nThis, the LSTM model has never seen during training at all.</p>\n\n<p>Is that why you are seeing what you are seeing?</p>\n\n<p>Can you try the same with <code>x_min</code> and <code>x_max</code> coming from the whole dataset instead?</p>\n",
                "codes": [
                    [
                        "    def my_process(n, p, drift=0, displacement=0):\n        x = np.zeros(n)\n\n        for i in range(1, n):\n            x[i] = drift * i + p * x[i-1] + (1-p) * np.random.randn()\n    return x + displacement\n"
                    ],
                    []
                ],
                "question_id:": "28463",
                "question_votes:": "9",
                "question_text:": "<p>I want to do one-step-ahead predictions for time series with LSTM.\nTo understand the algorithm, I built myself a toy example: A simple autocorrelated process.</p>\n\n<pre><code>def my_process(n, p, drift=0, displacement=0):\n    x = np.zeros(n)\n\n    for i in range(1, n):\n        x[i] = drift * i + p * x[i-1] + (1-p) * np.random.randn()\n    return x + displacement\n</code></pre>\n\n<p>Then I built an LSTM model in Keras, following <a href=\"https://www.kaggle.com/pablocastilla/predict-stock-prices-with-lstm\" rel=\"nofollow noreferrer\">this example</a>.\nI simulated processes with high autocorrelation <code>p=0.99</code> of length <code>n=10000</code>, trained the neural network on the first 80% of it and let it do one-step-ahead predictions for the remaning 20%.</p>\n\n<p>If I set <code>drift=0, displacement=0</code>, everything works fine:\n<a href=\"https://i.stack.imgur.com/m3efr.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/m3efr.png\" alt=\"enter image description here\"></a></p>\n\n<p>Then I set <code>drift=0, displacement=10</code> and things went pear-shaped (notice the different scale on the y-axis):\n<a href=\"https://i.stack.imgur.com/VaMQw.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/VaMQw.png\" alt=\"enter image description here\"></a></p>\n\n<p>This is not terribly surprising: LSTMs should be fed with normalized data!\nSo I normalized the data by rescaling it to the interval <span class=\"math-container\">$[-1, 1]$</span>.\nPhew, things are fine again:\n<a href=\"https://i.stack.imgur.com/9nGs9.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/9nGs9.png\" alt=\"enter image description here\"></a></p>\n\n<p>Then I set <code>drift=0.00001, displacement=10</code>, normalized the data again and ran the algorithm on it.\nThis does not look good:\n<a href=\"https://i.stack.imgur.com/iwrH5.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/iwrH5.png\" alt=\"enter image description here\"></a></p>\n\n<p>Apparently the LSTM cannot deal with a drift. \nWhat to do? (Yes, in this toy example I could simply subtract the drift; but for real-world time series, this is much harder).\nMaybe I could run my LSTM on the difference <span class=\"math-container\">$X_{t} - X_{t-1}$</span> instead of the original time series <span class=\"math-container\">$X_t$</span>. This will remove any constant drift from the time series.\nBut running the LSTM on the differenced time series does not work at all:\n<a href=\"https://i.stack.imgur.com/B4yLg.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/B4yLg.png\" alt=\"enter image description here\"></a></p>\n\n<p>My question: Why does my algorithm break down when I use it on the differenced time series?\nWhat is a good way to deal with drifts in time series?</p>\n\n<p>Here is the full code for my model:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Sequential\n\n\n# The LSTM model\nmy_model = Sequential()\n\nmy_model.add(LSTM(input_shape=(1, 1), units=50, return_sequences=True))\nmy_model.add(Dropout(0.2))\n\nmy_model.add(LSTM(units=100, return_sequences=False))\nmy_model.add(Dropout(0.2))\n\nmy_model.add(Dense(units=1))\nmy_model.add(Activation('linear'))\n\nmy_model.compile(loss='mse', optimizer='rmsprop')\n\n\ndef my_prediction(x, model, normalize=False, difference=False):\n    # Plot the process x\n    plt.figure(figsize=(15, 7))\n    plt.subplot(121)\n    plt.plot(x)\n    plt.title('Original data')\n\n    n = len(x)\n    thrs = int(0.8 * n)    # Train-test split\n    # Save starting values for test set to reverse differencing\n    x_test_0 = x[thrs + 1]\n    # Save minimum and maximum on test set to reverse normalization\n    x_min = min(x[:thrs])  \n    x_max = max(x[:thrs])\n\n    if difference:\n        x = np.diff(x)   # Take difference to remove drift\n    if normalize:\n        x = (2*x - x_min - x_max) / (x_max - x_min)   # Normalize to [-1, 1]\n\n    # Split into train and test set. The model will be trained on one-step-ahead predictions.\n    x_train, y_train, x_test, y_test = x[0:(thrs-1)], x[1:thrs], x[thrs:(n-1)], x[(thrs+1):n]\n\n    x_train, x_test = x_train.reshape(-1, 1, 1), x_test.reshape(-1, 1, 1)\n    y_train, y_test = y_train.reshape(-1, 1), y_test.reshape(-1, 1)\n\n    # Fit the model\n    model.fit(x_train, y_train, batch_size=200, epochs=10, validation_split=0.05, verbose=0)\n\n    # Predict the test set\n    y_pred = model.predict(x_test)\n\n    # Reverse differencing and normalization\n    if normalize:\n        y_pred = ((x_max - x_min) * y_pred + x_max + x_min) / 2\n        y_test = ((x_max - x_min) * y_test + x_max + x_min) / 2  \n    if difference:\n        y_pred = x_test_0 + np.cumsum(y_pred)\n        y_test = x_test_0 + np.cumsum(y_test)\n\n    # Plot estimation\n    plt.subplot(122)\n    plt.plot(y_pred[-100:], label='One-step-ahead-predictions')\n    plt.plot(y_test[-100:], label='Actual data')\n    plt.title('Prediction on test set')\n    plt.legend()\n    plt.show()\n\n# Make plots\nx = my_process(10000, 0.99, drift=0, displacement=0)\nmy_prediction(x, my_model, normalize=False, difference=False)\n\nx = my_process(10000, 0.99, drift=0, displacement=10)\nmy_prediction(x, my_model, normalize=False, difference=False)\n\nx = my_process(10000, 0.99, drift=0, displacement=10)\nmy_prediction(x, my_model, normalize=True, difference=False)\n\nx = my_process(10000, 0.99, drift=0.00001, displacement=10)\nmy_prediction(x, my_model, normalize=True, difference=False)\n\nx = my_process(10000, 0.99, drift=0.00001, displacement=10)\nmy_prediction(x, my_model, normalize=True, difference=True)\n</code></pre>\n",
                "tags": "<python><keras><time-series><lstm>",
                "answers": [
                    [
                        "28519",
                        "2",
                        "28463",
                        "",
                        "",
                        "<p>Looking again at your autocorrelated process:</p>\n\n<pre><code>    def my_process(n, p, drift=0, displacement=0):\n        x = np.zeros(n)\n\n        for i in range(1, n):\n            x[i] = drift * i + p * x[i-1] + (1-p) * np.random.randn()\n    return x + displacement\n</code></pre>\n\n<p>It looks like things are breaking down when the value of <code>displacement</code> is high. This makes sense, as you say, because LSTMs need normalized data. </p>\n\n<p>The <code>drift</code> parameter is a bit different. When a small amount of drift is included, since <code>p</code> is large, the amount of drift is similar to the amount of random noise being added via <code>np.random.randn()</code>. </p>\n\n<p>In the plots for <code>drift=0.00001, displacement=10</code>, it looks like the predictions would be fine except for the y-shift. Because of this, I think the root of the problem is still in the <code>displacement</code> parameter, not the <code>drift</code> parameter. Differencing, as has been done, will not help with the <code>displacement</code> parameter; instead, it corrects for drift. </p>\n\n<p>I can't tell from your code, but it looks like perhaps the <code>displacement</code> was not accounted for in <code>model.predict</code>. That's my best guess. </p>\n",
                        "",
                        "1"
                    ],
                    [
                        "35898",
                        "2",
                        "28463",
                        "",
                        "",
                        "<p>When you choose <code>x_min</code> and <code>x_max</code>, you are choosing it from <code>1:threshold</code> alone.\nSince your series is monotonically increasing (well almost..), the testing values are all values > 1.\nThis, the LSTM model has never seen during training at all.</p>\n\n<p>Is that why you are seeing what you are seeing?</p>\n\n<p>Can you try the same with <code>x_min</code> and <code>x_max</code> coming from the whole dataset instead?</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6917",
            "_score": 5.7938843,
            "_source": {
                "title": "How to implement \"one-to-many\" and \"many-to-many\" sequence prediction in Keras?",
                "content": "How to implement \"one-to-many\" and \"many-to-many\" sequence prediction in Keras? <p>I struggle to interpret the Keras coding difference for one-to-many (e. g. classification of single images) and many-to-many (e. g. classification of image sequences) sequence labeling. I frequently see two different kind of codes:</p>\n\n<p>Type 1 is where no TimeDistributed applied like this:</p>\n\n<pre><code>model=Sequential()\n\nmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode=\"valid\", input_shape=[1, 56,14]))\nmodel.add(Activation(\"relu\"))\nmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=pool_size))\n\nmodel.add(Reshape((56*14,)))\nmodel.add(Dropout(0.25))\nmodel.add(LSTM(5))\nmodel.add(Dense(50))\nmodel.add(Dense(nb_classes))\nmodel.add(Activation(\"softmax\"))\n</code></pre>\n\n<p>Type 2 is where TimeDistributed is applied like this:</p>\n\n<pre><code>model = Sequential()\n\nmodel.add(InputLayer(input_shape=(5, 224, 224, 3)))\nmodel.add(TimeDistributed(Convolution2D(64, (3, 3))))\nmodel.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\nmodel.add(LSTM(10))\nmodel.add(Dense(3))\n</code></pre>\n\n<p>My questions are:</p>\n\n<ul>\n<li><p>Is my assumption correct that Type 1 is the one-to-many kind and Type\n2 is the many-to-many kind? Or <code>TimeDistributed</code> has no relevance in\nthis aspect?</p></li>\n<li><p>In either case of one-to-many or many-to-many is the last dense layer\nsupposed to be 1 node \"long\" (emitting only one value in turn) and<br>\nthe previous recurrent layer is responsible to determine how many<br>\n1-long value to emit? Or the last dense layer is supposed to consist \nof N nodes where <code>N=max sequence length</code>? If so, what is the point of<br>\nusing RNN here when we could produce a similar input with multiple<br>\noutputs with N parallel \"vanilla\" estimators?</p></li>\n<li><p>How to define the number of timesteps in RNNs? Is it somehow<br>\ncorrelated with the output sequence length or is it just a<br>\nhyperparameter to tune?</p></li>\n<li><p>Inn case of my Type 1 example above what is the point of applying<br>\nLSTM when the model emits only one class prediction (of possible<br>\n<code>nb_classes</code>)? What if one omits the LSTM layer?</p></li>\n</ul>\n <keras><rnn><lstm><sequence><p>The point of using any recurrent layer is to have the output be a result of not only a single item independent of other items, but rather a sequence of items, such that the output of the layer's operation on one item in the sequence is the result of both that item and any item before it in the sequence. The number of timesteps defines how long such a sequence is. That is, how many items that should be handled in a sequence, and affect each other's resulting output.</p>\n\n<p>A LSTM layer operates in such a way that it accepts input on the form number_of_timesteps, dimensions_of_each_item. If the parameter return_sequences is set to False, which it is by default, the layer \"compounds\" the inputs of all the timesteps into a single output. If you consider a sequence of, say 10 items, a LSTM layer with return_sequences set to False will from such a sequence produce a single output item, and the attributes of this single item will be a result of all the items (timesteps) in the sequence. This is what you want in the case of a many-to-one design.</p>\n\n<p>A LSTM layer with return_sequences set to True will for each item (timestep) in an input sequence produce an output. This is done in such a way that at any timestep, the output will depend not only on the item that is currently being operated on, but also the previous items in the sequence. This is what you want in the case of a many-to-many design. </p>\n\n<p>As a LSTM layer takes a sequence of items as input, any layer before a LSTM layer in your model will need to produce a sequence as an output. In the case of your Type 1 model, the first few layers do not operate on sequences, but rather a single item at a time. This does hence not produce a sequence of items on which to operate for the LSTM.</p>\n\n<p>Using TimeDistributed makes it possible to have a layer operate on every item in a sequence without the items affecting each other. TimeDistributed layers thus operate on sequences of items, but there is no recursion.</p>\n\n<p>In the case of your type 2 model, the first layers will produce a sequence 5 timesteps long, and the operations done on each of the items in the sequence will be independent of each other, since the layers wrapped in TimeDistributed are non-recurrent. As the LSTM layer uses the default settings, return_sequences = False, the LSTM layer will produce a single output for each such sequence of 5 items. </p>\n\n<p>The final number of output nodes in your model depends completely on the use case. A single node is suitable for something like binary classification or for producing some sort of score.</p>\n<p>I think that you might be able to use my previous work.\nIn this code I create sine waves (of random wavelengths and phases) and train an LSTM to a sequence of points from these sine waves and output a sequence of 150 points completing each sine wave.</p>\n\n<p>This is the model:</p>\n\n<pre><code>    features_num=5 \n    latent_dim=40\n\n    ##\n    encoder_inputs = Input(shape=(None, features_num))\n    encoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoder_inputs)\n    encoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoded)\n    encoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoded)\n    encoded = LSTM(latent_dim, return_state=True)(encoded)\n\n    encoder = Model (input=encoder_inputs, output=encoded)\n    ##\n\n    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n    encoder_states = [state_h, state_c]\n\n    decoder_inputs=Input(shape=(1, features_num))\n    decoder_lstm_1 = LSTM(latent_dim, return_sequences=True, return_state=True)\n    decoder_lstm_2 = LSTM(latent_dim, return_sequences=True, return_state=True)\n    decoder_lstm_3 = LSTM(latent_dim, return_sequences=True, return_state=True)\n    decoder_lstm_4 = LSTM(latent_dim, return_sequences=True, return_state=True)\n\n    decoder_dense = Dense(features_num)\n\n    all_outputs = []\n    inputs = decoder_inputs\n\n\n    states_1=encoder_states\n   # Place holder values:\n    states_2=states_1; states_3=states_1; states_4=states_1\n\n    for _ in range(1):\n        # Run the decoder on the first timestep\n        outputs_1, state_h_1, state_c_1 = decoder_lstm_1(inputs, initial_state=states_1)\n        outputs_2, state_h_2, state_c_2 = decoder_lstm_2(outputs_1)\n        outputs_3, state_h_3, state_c_3 = decoder_lstm_3(outputs_2)\n        outputs_4, state_h_4, state_c_4 = decoder_lstm_4(outputs_3)\n\n        # Store the current prediction (we will concatenate all predictions later)\n        outputs = decoder_dense(outputs_4)\n        all_outputs.append(outputs)\n        # Reinject the outputs as inputs for the next loop iteration\n        # as well as update the states\n        inputs = outputs\n        states_1 = [state_h_1, state_c_1]\n        states_2 = [state_h_2, state_c_2]\n        states_3 = [state_h_3, state_c_3]\n        states_4 = [state_h_4, state_c_4]\n\n\n    for _ in range(149):\n        # Run the decoder on each timestep\n        outputs_1, state_h_1, state_c_1 = decoder_lstm_1(inputs, initial_state=states_1)\n        outputs_2, state_h_2, state_c_2 = decoder_lstm_2(outputs_1, initial_state=states_2)\n        outputs_3, state_h_3, state_c_3 = decoder_lstm_3(outputs_2, initial_state=states_3)\n        outputs_4, state_h_4, state_c_4 = decoder_lstm_4(outputs_3, initial_state=states_4)\n\n        # Store the current prediction (we will concatenate all predictions later)\n        outputs = decoder_dense(outputs_4)\n        all_outputs.append(outputs)\n        # Reinject the outputs as inputs for the next loop iteration\n        # as well as update the states\n        inputs = outputs\n        states_1 = [state_h_1, state_c_1]\n        states_2 = [state_h_2, state_c_2]\n        states_3 = [state_h_3, state_c_3]\n        states_4 = [state_h_4, state_c_4]\n\n\n    # Concatenate all predictions\n    decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)   \n\n    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\n    #model = load_model('pre_model.h5')\n\n\n    print(model.summary())\n</code></pre>\n\n<p>And this is the entire script:</p>\n\n<pre><code>from keras.models import Model\nfrom keras.layers import Input, LSTM, Dense, TimeDistributed,Lambda, Dropout, Activation ,RepeatVector\nfrom keras.callbacks import ModelCheckpoint \nimport numpy as np\n\nfrom keras.layers import Lambda\nfrom keras import backend as K\n\nfrom keras.models import load_model\n\nimport os\n\n\nfeatures_num=5 \nlatent_dim=40\n\n##\nencoder_inputs = Input(shape=(None, features_num))\nencoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoder_inputs)\nencoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoded)\nencoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoded)\nencoded = LSTM(latent_dim, return_state=True)(encoded)\n\nencoder = Model (input=encoder_inputs, output=encoded)\n##\n\nencoder_outputs, state_h, state_c = encoder(encoder_inputs)\nencoder_states = [state_h, state_c]\n\ndecoder_inputs=Input(shape=(1, features_num))\ndecoder_lstm_1 = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_lstm_2 = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_lstm_3 = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_lstm_4 = LSTM(latent_dim, return_sequences=True, return_state=True)\n\ndecoder_dense = Dense(features_num)\n\nall_outputs = []\ninputs = decoder_inputs\n\n# Place holder values:\nstates_1=encoder_states\nstates_2=states_1; states_3=states_1; states_4=states_1\n\nfor _ in range(1):\n    # Run the decoder on one timestep\n    outputs_1, state_h_1, state_c_1 = decoder_lstm_1(inputs, initial_state=states_1)\n    outputs_2, state_h_2, state_c_2 = decoder_lstm_2(outputs_1)\n    outputs_3, state_h_3, state_c_3 = decoder_lstm_3(outputs_2)\n    outputs_4, state_h_4, state_c_4 = decoder_lstm_4(outputs_3)\n\n    # Store the current prediction (we will concatenate all predictions later)\n    outputs = decoder_dense(outputs_4)\n    all_outputs.append(outputs)\n    # Reinject the outputs as inputs for the next loop iteration\n    # as well as update the states\n    inputs = outputs\n    states_1 = [state_h_1, state_c_1]\n    states_2 = [state_h_2, state_c_2]\n    states_3 = [state_h_3, state_c_3]\n    states_4 = [state_h_4, state_c_4]\n\n\nfor _ in range(149):\n    # Run the decoder on one timestep\n    outputs_1, state_h_1, state_c_1 = decoder_lstm_1(inputs, initial_state=states_1)\n    outputs_2, state_h_2, state_c_2 = decoder_lstm_2(outputs_1, initial_state=states_2)\n    outputs_3, state_h_3, state_c_3 = decoder_lstm_3(outputs_2, initial_state=states_3)\n    outputs_4, state_h_4, state_c_4 = decoder_lstm_4(outputs_3, initial_state=states_4)\n\n    # Store the current prediction (we will concatenate all predictions later)\n    outputs = decoder_dense(outputs_4)\n    all_outputs.append(outputs)\n    # Reinject the outputs as inputs for the next loop iteration\n    # as well as update the states\n    inputs = outputs\n    states_1 = [state_h_1, state_c_1]\n    states_2 = [state_h_2, state_c_2]\n    states_3 = [state_h_3, state_c_3]\n    states_4 = [state_h_4, state_c_4]\n\n\n# Concatenate all predictions\ndecoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)   \n\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\n#model = load_model('pre_model.h5')\n\n\nprint(model.summary())\n\n\nmodel.compile(loss='mean_squared_error', optimizer='adam')\n\n\ndef create_wavelength(min_wavelength, max_wavelength, fluxes_in_wavelength, category )  :         \n#category :: 0 - train ; 2 - validate ; 4- test. 1;3;5 - dead space\n    c=(category+np.random.random())/6         \n    k = fluxes_in_wavelength\n#\n    base= (np.trunc(k*np.random.random()*(max_wavelength-min_wavelength))       +k*min_wavelength)  /k\n    answer=base+c/k\n    return (answer)       \n\ndef make_line(length,category):\n    shift= np.random.random()\n    wavelength = create_wavelength(30,10,1,category)\n    a=np.arange(length)\n    answer=np.sin(a/wavelength+shift)\n    return answer\n\ndef make_data(seq_num,seq_len,dim,category):\n    data=np.array([]).reshape(0,seq_len,dim)\n    for i in range (seq_num):\n        mini_data=np.array([]).reshape(0,seq_len)\n        for j in range (dim):\n            line = make_line(seq_len,category)\n            line=line.reshape(1,seq_len)            \n            mini_data=np.append(mini_data,line,axis=0)\n        mini_data=np.swapaxes(mini_data,1,0)\n        mini_data=mini_data.reshape(1,seq_len,dim)      \n        data=np.append(data,mini_data,axis=0)\n    return (data)\n\n\ndef train_generator():\n    while True:\n        sequence_length = np.random.randint(150, 300)+150       \n        data=make_data(1000,sequence_length,features_num,0) # category=0 in train\n\n\n    #   decoder_target_data is the same as decoder_input_data but offset by one timestep\n\n        encoder_input_data = data[:,:-150,:] # all but last 150 \n\n        decoder_input_data = data[:,-151,:] # the one before the last 150.\n        decoder_input_data=decoder_input_data.reshape((decoder_input_data.shape[0],1,decoder_input_data.shape[1]))\n\n\n        decoder_target_data = (data[:, -150:, :]) # last 150        \n        yield [encoder_input_data, decoder_input_data], decoder_target_data\ndef val_generator():\n    while True:\n\n        sequence_length = np.random.randint(150, 300)+150       \n        data=make_data(1000,sequence_length,features_num,2) # category=2 in val\n\n        encoder_input_data = data[:,:-150,:] # all but last 150 \n\n        decoder_input_data = data[:,-151,:] # the one before the last 150.\n        decoder_input_data=decoder_input_data.reshape((decoder_input_data.shape[0],1,decoder_input_data.shape[1]))\n\n        decoder_target_data = (data[:, -150:, :]) # last 150        \n        yield [encoder_input_data, decoder_input_data], decoder_target_data\n\nfilepath_for_w= 'flux_p2p_s2s_model.h5' \ncheckpointer=ModelCheckpoint(filepath_for_w, monitor='val_loss', verbose=0, save_best_only=True, mode='auto', period=1)     \nmodel.fit_generator(train_generator(),callbacks=[checkpointer], steps_per_epoch=30, epochs=2000, verbose=1,validation_data=val_generator(),validation_steps=30)\nmodel.save(filepath_for_w)\n\n\n\n\ndef predict_wave(input_wave,input_for_decoder):  # input wave= x[n,:,:], ie points except the last 150; each wave has feature_num features. run this function for all such instances (=n)   \n    #print (input_wave.shape)\n    #print (input_for_decoder.shape)\n    pred= model.predict([input_wave,input_for_decoder])\n\n    return pred\n\ndef predict_many_waves_from_input(x):   \n    x, x2=x # x == encoder_input_data ; x==2 decoder_input_data\n\n    instance_num= x.shape[0]\n\n\n    multi_predict_collection=np.zeros((x.shape[0],150,x.shape[2]))\n\n    for n in range(instance_num):\n        input_wave=x[n,:,:].reshape(1,x.shape[1],x.shape[2])\n        input_for_decoder=x2[n,:,:].reshape(1,x2.shape[1],x2.shape[2])\n        wave_prediction=predict_wave(input_wave,input_for_decoder)\n        multi_predict_collection[n,:,:]=wave_prediction\n    return (multi_predict_collection)\n\ndef test_maker():\n    if True:        \n        sequence_length = np.random.randint(150, 300)+150       \n        data=make_data(470,sequence_length,features_num,4) # category=4 in test\n\n        encoder_input_data = data[:,:-150,:] # all but last 150 \n\n        decoder_input_data = data[:,-151,:] # the one before the last 150.\n        decoder_input_data=decoder_input_data.reshape((decoder_input_data.shape[0],1,decoder_input_data.shape[1]))\n\n        decoder_target_data = (data[:, -150:, :]) # last 150        \n        return [encoder_input_data, decoder_input_data],    decoder_target_data\n\nx,y= test_maker()   \n\n\n\na=predict_many_waves_from_input (x) # is that right..?\nx=x[0] # keep the wave (generated data except last 150 time points) \nprint (x.shape)\nprint (y.shape)\nprint (a.shape)\n\nnp.save ('a.npy',a)\nnp.save ('y.npy',y)\nnp.save ('x.npy',x)\n\n\n\nprint (np.mean(np.absolute(y[:,:,0]-a[:,:,0])))\nprint (np.mean(np.absolute(y[:,:,1]-a[:,:,1])))\nprint (np.mean(np.absolute(y[:,:,2]-a[:,:,2])))\nprint (np.mean(np.absolute(y[:,:,3]-a[:,:,3])))\nprint (np.mean(np.absolute(y[:,:,4]-a[:,:,4])))\n</code></pre>\n",
                "codes": [
                    [],
                    [
                        "    features_num=5 \n    latent_dim=40\n\n    ##\n    encoder_inputs = Input(shape=(None, features_num))\n    encoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoder_inputs)\n    encoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoded)\n    encoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoded)\n    encoded = LSTM(latent_dim, return_state=True)(encoded)\n\n    encoder = Model (input=encoder_inputs, output=encoded)\n    ##\n\n    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n    encoder_states = [state_h, state_c]\n\n    decoder_inputs=Input(shape=(1, features_num))\n    decoder_lstm_1 = LSTM(latent_dim, return_sequences=True, return_state=True)\n    decoder_lstm_2 = LSTM(latent_dim, return_sequences=True, return_state=True)\n    decoder_lstm_3 = LSTM(latent_dim, return_sequences=True, return_state=True)\n    decoder_lstm_4 = LSTM(latent_dim, return_sequences=True, return_state=True)\n\n    decoder_dense = Dense(features_num)\n\n    all_outputs = []\n    inputs = decoder_inputs\n\n\n    states_1=encoder_states\n   # Place holder values:\n    states_2=states_1; states_3=states_1; states_4=states_1\n\n    for _ in range(1):\n        # Run the decoder on the first timestep\n        outputs_1, state_h_1, state_c_1 = decoder_lstm_1(inputs, initial_state=states_1)\n        outputs_2, state_h_2, state_c_2 = decoder_lstm_2(outputs_1)\n        outputs_3, state_h_3, state_c_3 = decoder_lstm_3(outputs_2)\n        outputs_4, state_h_4, state_c_4 = decoder_lstm_4(outputs_3)\n\n        # Store the current prediction (we will concatenate all predictions later)\n        outputs = decoder_dense(outputs_4)\n        all_outputs.append(outputs)\n        # Reinject the outputs as inputs for the next loop iteration\n        # as well as update the states\n        inputs = outputs\n        states_1 = [state_h_1, state_c_1]\n        states_2 = [state_h_2, state_c_2]\n        states_3 = [state_h_3, state_c_3]\n        states_4 = [state_h_4, state_c_4]\n\n\n    for _ in range(149):\n        # Run the decoder on each timestep\n        outputs_1, state_h_1, state_c_1 = decoder_lstm_1(inputs, initial_state=states_1)\n        outputs_2, state_h_2, state_c_2 = decoder_lstm_2(outputs_1, initial_state=states_2)\n        outputs_3, state_h_3, state_c_3 = decoder_lstm_3(outputs_2, initial_state=states_3)\n        outputs_4, state_h_4, state_c_4 = decoder_lstm_4(outputs_3, initial_state=states_4)\n\n        # Store the current prediction (we will concatenate all predictions later)\n        outputs = decoder_dense(outputs_4)\n        all_outputs.append(outputs)\n        # Reinject the outputs as inputs for the next loop iteration\n        # as well as update the states\n        inputs = outputs\n        states_1 = [state_h_1, state_c_1]\n        states_2 = [state_h_2, state_c_2]\n        states_3 = [state_h_3, state_c_3]\n        states_4 = [state_h_4, state_c_4]\n\n\n    # Concatenate all predictions\n    decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)   \n\n    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\n    #model = load_model('pre_model.h5')\n\n\n    print(model.summary())\n",
                        "from keras.models import Model\nfrom keras.layers import Input, LSTM, Dense, TimeDistributed,Lambda, Dropout, Activation ,RepeatVector\nfrom keras.callbacks import ModelCheckpoint \nimport numpy as np\n\nfrom keras.layers import Lambda\nfrom keras import backend as K\n\nfrom keras.models import load_model\n\nimport os\n\n\nfeatures_num=5 \nlatent_dim=40\n\n##\nencoder_inputs = Input(shape=(None, features_num))\nencoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoder_inputs)\nencoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoded)\nencoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoded)\nencoded = LSTM(latent_dim, return_state=True)(encoded)\n\nencoder = Model (input=encoder_inputs, output=encoded)\n##\n\nencoder_outputs, state_h, state_c = encoder(encoder_inputs)\nencoder_states = [state_h, state_c]\n\ndecoder_inputs=Input(shape=(1, features_num))\ndecoder_lstm_1 = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_lstm_2 = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_lstm_3 = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_lstm_4 = LSTM(latent_dim, return_sequences=True, return_state=True)\n\ndecoder_dense = Dense(features_num)\n\nall_outputs = []\ninputs = decoder_inputs\n\n# Place holder values:\nstates_1=encoder_states\nstates_2=states_1; states_3=states_1; states_4=states_1\n\nfor _ in range(1):\n    # Run the decoder on one timestep\n    outputs_1, state_h_1, state_c_1 = decoder_lstm_1(inputs, initial_state=states_1)\n    outputs_2, state_h_2, state_c_2 = decoder_lstm_2(outputs_1)\n    outputs_3, state_h_3, state_c_3 = decoder_lstm_3(outputs_2)\n    outputs_4, state_h_4, state_c_4 = decoder_lstm_4(outputs_3)\n\n    # Store the current prediction (we will concatenate all predictions later)\n    outputs = decoder_dense(outputs_4)\n    all_outputs.append(outputs)\n    # Reinject the outputs as inputs for the next loop iteration\n    # as well as update the states\n    inputs = outputs\n    states_1 = [state_h_1, state_c_1]\n    states_2 = [state_h_2, state_c_2]\n    states_3 = [state_h_3, state_c_3]\n    states_4 = [state_h_4, state_c_4]\n\n\nfor _ in range(149):\n    # Run the decoder on one timestep\n    outputs_1, state_h_1, state_c_1 = decoder_lstm_1(inputs, initial_state=states_1)\n    outputs_2, state_h_2, state_c_2 = decoder_lstm_2(outputs_1, initial_state=states_2)\n    outputs_3, state_h_3, state_c_3 = decoder_lstm_3(outputs_2, initial_state=states_3)\n    outputs_4, state_h_4, state_c_4 = decoder_lstm_4(outputs_3, initial_state=states_4)\n\n    # Store the current prediction (we will concatenate all predictions later)\n    outputs = decoder_dense(outputs_4)\n    all_outputs.append(outputs)\n    # Reinject the outputs as inputs for the next loop iteration\n    # as well as update the states\n    inputs = outputs\n    states_1 = [state_h_1, state_c_1]\n    states_2 = [state_h_2, state_c_2]\n    states_3 = [state_h_3, state_c_3]\n    states_4 = [state_h_4, state_c_4]\n\n\n# Concatenate all predictions\ndecoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)   \n\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\n#model = load_model('pre_model.h5')\n\n\nprint(model.summary())\n\n\nmodel.compile(loss='mean_squared_error', optimizer='adam')\n\n\ndef create_wavelength(min_wavelength, max_wavelength, fluxes_in_wavelength, category )  :         \n#category :: 0 - train ; 2 - validate ; 4- test. 1;3;5 - dead space\n    c=(category+np.random.random())/6         \n    k = fluxes_in_wavelength\n#\n    base= (np.trunc(k*np.random.random()*(max_wavelength-min_wavelength))       +k*min_wavelength)  /k\n    answer=base+c/k\n    return (answer)       \n\ndef make_line(length,category):\n    shift= np.random.random()\n    wavelength = create_wavelength(30,10,1,category)\n    a=np.arange(length)\n    answer=np.sin(a/wavelength+shift)\n    return answer\n\ndef make_data(seq_num,seq_len,dim,category):\n    data=np.array([]).reshape(0,seq_len,dim)\n    for i in range (seq_num):\n        mini_data=np.array([]).reshape(0,seq_len)\n        for j in range (dim):\n            line = make_line(seq_len,category)\n            line=line.reshape(1,seq_len)            \n            mini_data=np.append(mini_data,line,axis=0)\n        mini_data=np.swapaxes(mini_data,1,0)\n        mini_data=mini_data.reshape(1,seq_len,dim)      \n        data=np.append(data,mini_data,axis=0)\n    return (data)\n\n\ndef train_generator():\n    while True:\n        sequence_length = np.random.randint(150, 300)+150       \n        data=make_data(1000,sequence_length,features_num,0) # category=0 in train\n\n\n    #   decoder_target_data is the same as decoder_input_data but offset by one timestep\n\n        encoder_input_data = data[:,:-150,:] # all but last 150 \n\n        decoder_input_data = data[:,-151,:] # the one before the last 150.\n        decoder_input_data=decoder_input_data.reshape((decoder_input_data.shape[0],1,decoder_input_data.shape[1]))\n\n\n        decoder_target_data = (data[:, -150:, :]) # last 150        \n        yield [encoder_input_data, decoder_input_data], decoder_target_data\ndef val_generator():\n    while True:\n\n        sequence_length = np.random.randint(150, 300)+150       \n        data=make_data(1000,sequence_length,features_num,2) # category=2 in val\n\n        encoder_input_data = data[:,:-150,:] # all but last 150 \n\n        decoder_input_data = data[:,-151,:] # the one before the last 150.\n        decoder_input_data=decoder_input_data.reshape((decoder_input_data.shape[0],1,decoder_input_data.shape[1]))\n\n        decoder_target_data = (data[:, -150:, :]) # last 150        \n        yield [encoder_input_data, decoder_input_data], decoder_target_data\n\nfilepath_for_w= 'flux_p2p_s2s_model.h5' \ncheckpointer=ModelCheckpoint(filepath_for_w, monitor='val_loss', verbose=0, save_best_only=True, mode='auto', period=1)     \nmodel.fit_generator(train_generator(),callbacks=[checkpointer], steps_per_epoch=30, epochs=2000, verbose=1,validation_data=val_generator(),validation_steps=30)\nmodel.save(filepath_for_w)\n\n\n\n\ndef predict_wave(input_wave,input_for_decoder):  # input wave= x[n,:,:], ie points except the last 150; each wave has feature_num features. run this function for all such instances (=n)   \n    #print (input_wave.shape)\n    #print (input_for_decoder.shape)\n    pred= model.predict([input_wave,input_for_decoder])\n\n    return pred\n\ndef predict_many_waves_from_input(x):   \n    x, x2=x # x == encoder_input_data ; x==2 decoder_input_data\n\n    instance_num= x.shape[0]\n\n\n    multi_predict_collection=np.zeros((x.shape[0],150,x.shape[2]))\n\n    for n in range(instance_num):\n        input_wave=x[n,:,:].reshape(1,x.shape[1],x.shape[2])\n        input_for_decoder=x2[n,:,:].reshape(1,x2.shape[1],x2.shape[2])\n        wave_prediction=predict_wave(input_wave,input_for_decoder)\n        multi_predict_collection[n,:,:]=wave_prediction\n    return (multi_predict_collection)\n\ndef test_maker():\n    if True:        \n        sequence_length = np.random.randint(150, 300)+150       \n        data=make_data(470,sequence_length,features_num,4) # category=4 in test\n\n        encoder_input_data = data[:,:-150,:] # all but last 150 \n\n        decoder_input_data = data[:,-151,:] # the one before the last 150.\n        decoder_input_data=decoder_input_data.reshape((decoder_input_data.shape[0],1,decoder_input_data.shape[1]))\n\n        decoder_target_data = (data[:, -150:, :]) # last 150        \n        return [encoder_input_data, decoder_input_data],    decoder_target_data\n\nx,y= test_maker()   \n\n\n\na=predict_many_waves_from_input (x) # is that right..?\nx=x[0] # keep the wave (generated data except last 150 time points) \nprint (x.shape)\nprint (y.shape)\nprint (a.shape)\n\nnp.save ('a.npy',a)\nnp.save ('y.npy',y)\nnp.save ('x.npy',x)\n\n\n\nprint (np.mean(np.absolute(y[:,:,0]-a[:,:,0])))\nprint (np.mean(np.absolute(y[:,:,1]-a[:,:,1])))\nprint (np.mean(np.absolute(y[:,:,2]-a[:,:,2])))\nprint (np.mean(np.absolute(y[:,:,3]-a[:,:,3])))\nprint (np.mean(np.absolute(y[:,:,4]-a[:,:,4])))\n"
                    ]
                ],
                "question_id:": "26401",
                "question_votes:": "11",
                "question_text:": "<p>I struggle to interpret the Keras coding difference for one-to-many (e. g. classification of single images) and many-to-many (e. g. classification of image sequences) sequence labeling. I frequently see two different kind of codes:</p>\n\n<p>Type 1 is where no TimeDistributed applied like this:</p>\n\n<pre><code>model=Sequential()\n\nmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode=\"valid\", input_shape=[1, 56,14]))\nmodel.add(Activation(\"relu\"))\nmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=pool_size))\n\nmodel.add(Reshape((56*14,)))\nmodel.add(Dropout(0.25))\nmodel.add(LSTM(5))\nmodel.add(Dense(50))\nmodel.add(Dense(nb_classes))\nmodel.add(Activation(\"softmax\"))\n</code></pre>\n\n<p>Type 2 is where TimeDistributed is applied like this:</p>\n\n<pre><code>model = Sequential()\n\nmodel.add(InputLayer(input_shape=(5, 224, 224, 3)))\nmodel.add(TimeDistributed(Convolution2D(64, (3, 3))))\nmodel.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\nmodel.add(LSTM(10))\nmodel.add(Dense(3))\n</code></pre>\n\n<p>My questions are:</p>\n\n<ul>\n<li><p>Is my assumption correct that Type 1 is the one-to-many kind and Type\n2 is the many-to-many kind? Or <code>TimeDistributed</code> has no relevance in\nthis aspect?</p></li>\n<li><p>In either case of one-to-many or many-to-many is the last dense layer\nsupposed to be 1 node \"long\" (emitting only one value in turn) and<br>\nthe previous recurrent layer is responsible to determine how many<br>\n1-long value to emit? Or the last dense layer is supposed to consist \nof N nodes where <code>N=max sequence length</code>? If so, what is the point of<br>\nusing RNN here when we could produce a similar input with multiple<br>\noutputs with N parallel \"vanilla\" estimators?</p></li>\n<li><p>How to define the number of timesteps in RNNs? Is it somehow<br>\ncorrelated with the output sequence length or is it just a<br>\nhyperparameter to tune?</p></li>\n<li><p>Inn case of my Type 1 example above what is the point of applying<br>\nLSTM when the model emits only one class prediction (of possible<br>\n<code>nb_classes</code>)? What if one omits the LSTM layer?</p></li>\n</ul>\n",
                "tags": "<keras><rnn><lstm><sequence>",
                "answers": [
                    [
                        "32401",
                        "2",
                        "26401",
                        "",
                        "",
                        "<p>The point of using any recurrent layer is to have the output be a result of not only a single item independent of other items, but rather a sequence of items, such that the output of the layer's operation on one item in the sequence is the result of both that item and any item before it in the sequence. The number of timesteps defines how long such a sequence is. That is, how many items that should be handled in a sequence, and affect each other's resulting output.</p>\n\n<p>A LSTM layer operates in such a way that it accepts input on the form number_of_timesteps, dimensions_of_each_item. If the parameter return_sequences is set to False, which it is by default, the layer \"compounds\" the inputs of all the timesteps into a single output. If you consider a sequence of, say 10 items, a LSTM layer with return_sequences set to False will from such a sequence produce a single output item, and the attributes of this single item will be a result of all the items (timesteps) in the sequence. This is what you want in the case of a many-to-one design.</p>\n\n<p>A LSTM layer with return_sequences set to True will for each item (timestep) in an input sequence produce an output. This is done in such a way that at any timestep, the output will depend not only on the item that is currently being operated on, but also the previous items in the sequence. This is what you want in the case of a many-to-many design. </p>\n\n<p>As a LSTM layer takes a sequence of items as input, any layer before a LSTM layer in your model will need to produce a sequence as an output. In the case of your Type 1 model, the first few layers do not operate on sequences, but rather a single item at a time. This does hence not produce a sequence of items on which to operate for the LSTM.</p>\n\n<p>Using TimeDistributed makes it possible to have a layer operate on every item in a sequence without the items affecting each other. TimeDistributed layers thus operate on sequences of items, but there is no recursion.</p>\n\n<p>In the case of your type 2 model, the first layers will produce a sequence 5 timesteps long, and the operations done on each of the items in the sequence will be independent of each other, since the layers wrapped in TimeDistributed are non-recurrent. As the LSTM layer uses the default settings, return_sequences = False, the LSTM layer will produce a single output for each such sequence of 5 items. </p>\n\n<p>The final number of output nodes in your model depends completely on the use case. A single node is suitable for something like binary classification or for producing some sort of score.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "36196",
                        "2",
                        "26401",
                        "",
                        "",
                        "<p>I think that you might be able to use my previous work.\nIn this code I create sine waves (of random wavelengths and phases) and train an LSTM to a sequence of points from these sine waves and output a sequence of 150 points completing each sine wave.</p>\n\n<p>This is the model:</p>\n\n<pre><code>    features_num=5 \n    latent_dim=40\n\n    ##\n    encoder_inputs = Input(shape=(None, features_num))\n    encoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoder_inputs)\n    encoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoded)\n    encoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoded)\n    encoded = LSTM(latent_dim, return_state=True)(encoded)\n\n    encoder = Model (input=encoder_inputs, output=encoded)\n    ##\n\n    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n    encoder_states = [state_h, state_c]\n\n    decoder_inputs=Input(shape=(1, features_num))\n    decoder_lstm_1 = LSTM(latent_dim, return_sequences=True, return_state=True)\n    decoder_lstm_2 = LSTM(latent_dim, return_sequences=True, return_state=True)\n    decoder_lstm_3 = LSTM(latent_dim, return_sequences=True, return_state=True)\n    decoder_lstm_4 = LSTM(latent_dim, return_sequences=True, return_state=True)\n\n    decoder_dense = Dense(features_num)\n\n    all_outputs = []\n    inputs = decoder_inputs\n\n\n    states_1=encoder_states\n   # Place holder values:\n    states_2=states_1; states_3=states_1; states_4=states_1\n\n    for _ in range(1):\n        # Run the decoder on the first timestep\n        outputs_1, state_h_1, state_c_1 = decoder_lstm_1(inputs, initial_state=states_1)\n        outputs_2, state_h_2, state_c_2 = decoder_lstm_2(outputs_1)\n        outputs_3, state_h_3, state_c_3 = decoder_lstm_3(outputs_2)\n        outputs_4, state_h_4, state_c_4 = decoder_lstm_4(outputs_3)\n\n        # Store the current prediction (we will concatenate all predictions later)\n        outputs = decoder_dense(outputs_4)\n        all_outputs.append(outputs)\n        # Reinject the outputs as inputs for the next loop iteration\n        # as well as update the states\n        inputs = outputs\n        states_1 = [state_h_1, state_c_1]\n        states_2 = [state_h_2, state_c_2]\n        states_3 = [state_h_3, state_c_3]\n        states_4 = [state_h_4, state_c_4]\n\n\n    for _ in range(149):\n        # Run the decoder on each timestep\n        outputs_1, state_h_1, state_c_1 = decoder_lstm_1(inputs, initial_state=states_1)\n        outputs_2, state_h_2, state_c_2 = decoder_lstm_2(outputs_1, initial_state=states_2)\n        outputs_3, state_h_3, state_c_3 = decoder_lstm_3(outputs_2, initial_state=states_3)\n        outputs_4, state_h_4, state_c_4 = decoder_lstm_4(outputs_3, initial_state=states_4)\n\n        # Store the current prediction (we will concatenate all predictions later)\n        outputs = decoder_dense(outputs_4)\n        all_outputs.append(outputs)\n        # Reinject the outputs as inputs for the next loop iteration\n        # as well as update the states\n        inputs = outputs\n        states_1 = [state_h_1, state_c_1]\n        states_2 = [state_h_2, state_c_2]\n        states_3 = [state_h_3, state_c_3]\n        states_4 = [state_h_4, state_c_4]\n\n\n    # Concatenate all predictions\n    decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)   \n\n    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\n    #model = load_model('pre_model.h5')\n\n\n    print(model.summary())\n</code></pre>\n\n<p>And this is the entire script:</p>\n\n<pre><code>from keras.models import Model\nfrom keras.layers import Input, LSTM, Dense, TimeDistributed,Lambda, Dropout, Activation ,RepeatVector\nfrom keras.callbacks import ModelCheckpoint \nimport numpy as np\n\nfrom keras.layers import Lambda\nfrom keras import backend as K\n\nfrom keras.models import load_model\n\nimport os\n\n\nfeatures_num=5 \nlatent_dim=40\n\n##\nencoder_inputs = Input(shape=(None, features_num))\nencoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoder_inputs)\nencoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoded)\nencoded = LSTM(latent_dim, return_state=False ,return_sequences=True)(encoded)\nencoded = LSTM(latent_dim, return_state=True)(encoded)\n\nencoder = Model (input=encoder_inputs, output=encoded)\n##\n\nencoder_outputs, state_h, state_c = encoder(encoder_inputs)\nencoder_states = [state_h, state_c]\n\ndecoder_inputs=Input(shape=(1, features_num))\ndecoder_lstm_1 = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_lstm_2 = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_lstm_3 = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_lstm_4 = LSTM(latent_dim, return_sequences=True, return_state=True)\n\ndecoder_dense = Dense(features_num)\n\nall_outputs = []\ninputs = decoder_inputs\n\n# Place holder values:\nstates_1=encoder_states\nstates_2=states_1; states_3=states_1; states_4=states_1\n\nfor _ in range(1):\n    # Run the decoder on one timestep\n    outputs_1, state_h_1, state_c_1 = decoder_lstm_1(inputs, initial_state=states_1)\n    outputs_2, state_h_2, state_c_2 = decoder_lstm_2(outputs_1)\n    outputs_3, state_h_3, state_c_3 = decoder_lstm_3(outputs_2)\n    outputs_4, state_h_4, state_c_4 = decoder_lstm_4(outputs_3)\n\n    # Store the current prediction (we will concatenate all predictions later)\n    outputs = decoder_dense(outputs_4)\n    all_outputs.append(outputs)\n    # Reinject the outputs as inputs for the next loop iteration\n    # as well as update the states\n    inputs = outputs\n    states_1 = [state_h_1, state_c_1]\n    states_2 = [state_h_2, state_c_2]\n    states_3 = [state_h_3, state_c_3]\n    states_4 = [state_h_4, state_c_4]\n\n\nfor _ in range(149):\n    # Run the decoder on one timestep\n    outputs_1, state_h_1, state_c_1 = decoder_lstm_1(inputs, initial_state=states_1)\n    outputs_2, state_h_2, state_c_2 = decoder_lstm_2(outputs_1, initial_state=states_2)\n    outputs_3, state_h_3, state_c_3 = decoder_lstm_3(outputs_2, initial_state=states_3)\n    outputs_4, state_h_4, state_c_4 = decoder_lstm_4(outputs_3, initial_state=states_4)\n\n    # Store the current prediction (we will concatenate all predictions later)\n    outputs = decoder_dense(outputs_4)\n    all_outputs.append(outputs)\n    # Reinject the outputs as inputs for the next loop iteration\n    # as well as update the states\n    inputs = outputs\n    states_1 = [state_h_1, state_c_1]\n    states_2 = [state_h_2, state_c_2]\n    states_3 = [state_h_3, state_c_3]\n    states_4 = [state_h_4, state_c_4]\n\n\n# Concatenate all predictions\ndecoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)   \n\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\n#model = load_model('pre_model.h5')\n\n\nprint(model.summary())\n\n\nmodel.compile(loss='mean_squared_error', optimizer='adam')\n\n\ndef create_wavelength(min_wavelength, max_wavelength, fluxes_in_wavelength, category )  :         \n#category :: 0 - train ; 2 - validate ; 4- test. 1;3;5 - dead space\n    c=(category+np.random.random())/6         \n    k = fluxes_in_wavelength\n#\n    base= (np.trunc(k*np.random.random()*(max_wavelength-min_wavelength))       +k*min_wavelength)  /k\n    answer=base+c/k\n    return (answer)       \n\ndef make_line(length,category):\n    shift= np.random.random()\n    wavelength = create_wavelength(30,10,1,category)\n    a=np.arange(length)\n    answer=np.sin(a/wavelength+shift)\n    return answer\n\ndef make_data(seq_num,seq_len,dim,category):\n    data=np.array([]).reshape(0,seq_len,dim)\n    for i in range (seq_num):\n        mini_data=np.array([]).reshape(0,seq_len)\n        for j in range (dim):\n            line = make_line(seq_len,category)\n            line=line.reshape(1,seq_len)            \n            mini_data=np.append(mini_data,line,axis=0)\n        mini_data=np.swapaxes(mini_data,1,0)\n        mini_data=mini_data.reshape(1,seq_len,dim)      \n        data=np.append(data,mini_data,axis=0)\n    return (data)\n\n\ndef train_generator():\n    while True:\n        sequence_length = np.random.randint(150, 300)+150       \n        data=make_data(1000,sequence_length,features_num,0) # category=0 in train\n\n\n    #   decoder_target_data is the same as decoder_input_data but offset by one timestep\n\n        encoder_input_data = data[:,:-150,:] # all but last 150 \n\n        decoder_input_data = data[:,-151,:] # the one before the last 150.\n        decoder_input_data=decoder_input_data.reshape((decoder_input_data.shape[0],1,decoder_input_data.shape[1]))\n\n\n        decoder_target_data = (data[:, -150:, :]) # last 150        \n        yield [encoder_input_data, decoder_input_data], decoder_target_data\ndef val_generator():\n    while True:\n\n        sequence_length = np.random.randint(150, 300)+150       \n        data=make_data(1000,sequence_length,features_num,2) # category=2 in val\n\n        encoder_input_data = data[:,:-150,:] # all but last 150 \n\n        decoder_input_data = data[:,-151,:] # the one before the last 150.\n        decoder_input_data=decoder_input_data.reshape((decoder_input_data.shape[0],1,decoder_input_data.shape[1]))\n\n        decoder_target_data = (data[:, -150:, :]) # last 150        \n        yield [encoder_input_data, decoder_input_data], decoder_target_data\n\nfilepath_for_w= 'flux_p2p_s2s_model.h5' \ncheckpointer=ModelCheckpoint(filepath_for_w, monitor='val_loss', verbose=0, save_best_only=True, mode='auto', period=1)     \nmodel.fit_generator(train_generator(),callbacks=[checkpointer], steps_per_epoch=30, epochs=2000, verbose=1,validation_data=val_generator(),validation_steps=30)\nmodel.save(filepath_for_w)\n\n\n\n\ndef predict_wave(input_wave,input_for_decoder):  # input wave= x[n,:,:], ie points except the last 150; each wave has feature_num features. run this function for all such instances (=n)   \n    #print (input_wave.shape)\n    #print (input_for_decoder.shape)\n    pred= model.predict([input_wave,input_for_decoder])\n\n    return pred\n\ndef predict_many_waves_from_input(x):   \n    x, x2=x # x == encoder_input_data ; x==2 decoder_input_data\n\n    instance_num= x.shape[0]\n\n\n    multi_predict_collection=np.zeros((x.shape[0],150,x.shape[2]))\n\n    for n in range(instance_num):\n        input_wave=x[n,:,:].reshape(1,x.shape[1],x.shape[2])\n        input_for_decoder=x2[n,:,:].reshape(1,x2.shape[1],x2.shape[2])\n        wave_prediction=predict_wave(input_wave,input_for_decoder)\n        multi_predict_collection[n,:,:]=wave_prediction\n    return (multi_predict_collection)\n\ndef test_maker():\n    if True:        \n        sequence_length = np.random.randint(150, 300)+150       \n        data=make_data(470,sequence_length,features_num,4) # category=4 in test\n\n        encoder_input_data = data[:,:-150,:] # all but last 150 \n\n        decoder_input_data = data[:,-151,:] # the one before the last 150.\n        decoder_input_data=decoder_input_data.reshape((decoder_input_data.shape[0],1,decoder_input_data.shape[1]))\n\n        decoder_target_data = (data[:, -150:, :]) # last 150        \n        return [encoder_input_data, decoder_input_data],    decoder_target_data\n\nx,y= test_maker()   \n\n\n\na=predict_many_waves_from_input (x) # is that right..?\nx=x[0] # keep the wave (generated data except last 150 time points) \nprint (x.shape)\nprint (y.shape)\nprint (a.shape)\n\nnp.save ('a.npy',a)\nnp.save ('y.npy',y)\nnp.save ('x.npy',x)\n\n\n\nprint (np.mean(np.absolute(y[:,:,0]-a[:,:,0])))\nprint (np.mean(np.absolute(y[:,:,1]-a[:,:,1])))\nprint (np.mean(np.absolute(y[:,:,2]-a[:,:,2])))\nprint (np.mean(np.absolute(y[:,:,3]-a[:,:,3])))\nprint (np.mean(np.absolute(y[:,:,4]-a[:,:,4])))\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14591",
            "_score": 5.7094765,
            "_source": {
                "title": "Backpropagation implementation help",
                "content": "Backpropagation implementation help <p>I'm trying to implement Nokland's <strong>Direct Feedback Alignment</strong> in Python following <a href=\"https://arxiv.org/pdf/1609.01596.pdf\" rel=\"nofollow noreferrer\">his paper</a>.\nHere's my implementation so far:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.utils.extmath import softmax\nfrom scipy.special import expit\n\ndef f_sigmoid(x): return expit(x)\ndef df_sigmoid(x): return f_sigmoid(x) * (1-f_sigmoid(x))\n\nf_activation  =  f_sigmoid\ndf_activation = df_sigmoid\n\nclass NeuralNet(object):\n\n    def __init__(self, num_input, num_hidden, num_output):\n\n        #Using Lillicrap's initialization between -0.5 and 0.5\n        self.W1 = np.random.uniform(-0.5, 0.5)\n        self.W2 = np.random.uniform(-0.5, 0.5)\n        self.W3 = np.random.uniform(-0.5, 0.5)\n        self.B1 = np.random.uniform(-0.5, 0.5, self.W1.size)\n        self.B2 = np.random.uniform(-0.5, 0.5, self.W2.size)\n\n    def forward(self, X): #HOW DO I INITIALIZE b1,b2,b3 ?\n        a1 = np.matmul( X, self.W1) + self.b1\n        h1 = f_activation(a1)\n\n        a2 = np.matmul(h1, self.W2) + self.b2\n        h2 = f_activation(a2)\n\n        a_y = np.matmul(h2, self.W3) + self.b3\n        y_hat = softmax(a_y)\n\n        return y_hat, h2, h1, a1, a2\n\n    def loss(self, predicted, target): pass\n\ndef backpropagation(self, X, y, lr):\n        h3, h2, h1, a1, a2 = self.forward(X)\n        y_hat = h3\n        e = y_hat - y\n\n        # Backpropagation\n        d2 = df_activation(a2) * np.matmul(e, self.W3.T)\n        d1 = df_activation(a1) * np.matmul(d2, self.W2.T)\n\n        # Feedback Alignment\n        \"\"\"no W anymore!\"\"\"\n        d2 = df_activation(a2) * np.matmul(e, self.B2)\n        d1 = df_activation(a1) * np.matmul(d2, self.B1)\n\n        # Direct Feedback Alignment    \n        d2 = df_activation(a2) * np.matmul(e, self.B2)\n        d1 = df_activation(a1) * np.matmul(e, self.B1)\n\n        # Indirect Feedback Alignment\n        d1 = df_activation(a1) * np.matmul(e, self.B1)\n        d2 = df_activation(a2) * np.matmul(d1, self.W2)\n\n        # Weights update, same for all methods\n        self.W3 = self.W3 - lr * np.matmul(h2.T,e)\n        self.W2 = self.W2 - lr * np.matmul(h1.T, d2)\n        self.W1 = self.W1 - lr * np.matmul(X.reshape((-1,1)), d1)\n\n        # Biases update, same for all methods\n        self.b3 = self.b3 - lr *e\n        self.b2 = self.b2 - lr * d2\n        self.b1 = self.b1 - lr * d1\n</code></pre>\n\n<p>I don't know how to initialize b1,b2,b3 in <code>forward</code> function. I'm also not sure about W and B in <code>__init__</code> </p>\n\n<p>Do you have any suggestions?</p>\n <neural-network><backpropagation>",
                "codes": [],
                "question_id:": "49000",
                "question_votes:": "",
                "question_text:": "<p>I'm trying to implement Nokland's <strong>Direct Feedback Alignment</strong> in Python following <a href=\"https://arxiv.org/pdf/1609.01596.pdf\" rel=\"nofollow noreferrer\">his paper</a>.\nHere's my implementation so far:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.utils.extmath import softmax\nfrom scipy.special import expit\n\ndef f_sigmoid(x): return expit(x)\ndef df_sigmoid(x): return f_sigmoid(x) * (1-f_sigmoid(x))\n\nf_activation  =  f_sigmoid\ndf_activation = df_sigmoid\n\nclass NeuralNet(object):\n\n    def __init__(self, num_input, num_hidden, num_output):\n\n        #Using Lillicrap's initialization between -0.5 and 0.5\n        self.W1 = np.random.uniform(-0.5, 0.5)\n        self.W2 = np.random.uniform(-0.5, 0.5)\n        self.W3 = np.random.uniform(-0.5, 0.5)\n        self.B1 = np.random.uniform(-0.5, 0.5, self.W1.size)\n        self.B2 = np.random.uniform(-0.5, 0.5, self.W2.size)\n\n    def forward(self, X): #HOW DO I INITIALIZE b1,b2,b3 ?\n        a1 = np.matmul( X, self.W1) + self.b1\n        h1 = f_activation(a1)\n\n        a2 = np.matmul(h1, self.W2) + self.b2\n        h2 = f_activation(a2)\n\n        a_y = np.matmul(h2, self.W3) + self.b3\n        y_hat = softmax(a_y)\n\n        return y_hat, h2, h1, a1, a2\n\n    def loss(self, predicted, target): pass\n\ndef backpropagation(self, X, y, lr):\n        h3, h2, h1, a1, a2 = self.forward(X)\n        y_hat = h3\n        e = y_hat - y\n\n        # Backpropagation\n        d2 = df_activation(a2) * np.matmul(e, self.W3.T)\n        d1 = df_activation(a1) * np.matmul(d2, self.W2.T)\n\n        # Feedback Alignment\n        \"\"\"no W anymore!\"\"\"\n        d2 = df_activation(a2) * np.matmul(e, self.B2)\n        d1 = df_activation(a1) * np.matmul(d2, self.B1)\n\n        # Direct Feedback Alignment    \n        d2 = df_activation(a2) * np.matmul(e, self.B2)\n        d1 = df_activation(a1) * np.matmul(e, self.B1)\n\n        # Indirect Feedback Alignment\n        d1 = df_activation(a1) * np.matmul(e, self.B1)\n        d2 = df_activation(a2) * np.matmul(d1, self.W2)\n\n        # Weights update, same for all methods\n        self.W3 = self.W3 - lr * np.matmul(h2.T,e)\n        self.W2 = self.W2 - lr * np.matmul(h1.T, d2)\n        self.W1 = self.W1 - lr * np.matmul(X.reshape((-1,1)), d1)\n\n        # Biases update, same for all methods\n        self.b3 = self.b3 - lr *e\n        self.b2 = self.b2 - lr * d2\n        self.b1 = self.b1 - lr * d1\n</code></pre>\n\n<p>I don't know how to initialize b1,b2,b3 in <code>forward</code> function. I'm also not sure about W and B in <code>__init__</code> </p>\n\n<p>Do you have any suggestions?</p>\n",
                "tags": "<neural-network><backpropagation>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15576",
            "_score": 5.666505,
            "_source": {
                "title": "Caffe CNN prediction gives poor accuracy on validation set despite success during training",
                "content": "Caffe CNN prediction gives poor accuracy on validation set despite success during training <p>I am new to Machine Learning, CNN and Caffe and I have an issue I would be very happy to solve.\nAs part of a University project I must use a Machine Learning method to classify images into 3 classes. I use Caffe on Python for the task.</p>\n\n<p><strong>LONG STORY SHORT</strong> (Code is attached later on): </p>\n\n<p>After finishing the training stage, which resulted in(from log file):</p>\n\n<pre><code>Test net output #0: accuracy = 1\nTest net output #1: loss = 0.000219849 (* 1 = 0.000219849 loss)\nOptimization Done.\nOptimization Done.\n</code></pre>\n\n<p>I tried to predict for a test set and received a constant prediction for all images.\nI have tried to check my code for correct functionality, and found that even when i use the validation set for predicting- I get a constant prediction. How can that be? shouldn't my net be able to classify those with great accuracy?</p>\n\n<p><strong>CODE</strong></p>\n\n<p><strong>TRAINING</strong>:</p>\n\n<pre><code> import  os\n\n import glob\n\n from datetime import datetime\n\n from config import cifar10_config as config\n\n import argparse\n ap = argparse.ArgumentParser()\n ap.add_argument(\"-l\", \"--logfile\", required=True, help=\"logfile\")\n ap.add_argument(\"-s\", \"--solver\",  required=True, help=\"solver\") \n\nargs = vars(ap.parse_args())\nLOGFILE = args[\"logfile\"]\nSOLVER  = args[\"solver\"]\n\nCAFFE_TRAINING = config.CAFFE_TOOLS_DIR + \"/bin/caffe.bin train \"      #i.e. \"/caffe/Caffe-SSD-Ristretto/distribute/bin/caffe.bin train \"\n\nprint(\"TRAINING WITH CAFFE\")\n\ncaffe_solver  = SOLVER\n\ncaffe_logfile = LOGFILE\n\ncaffe_command = CAFFE_TRAINING + ' --solver ' + caffe_solver + ' 2&gt;&amp;1 | tee ' + caffe_logfile\n\nstartTime1 = datetime.now()\n\nos.system(caffe_command)\n\nendTime1 = datetime.now()\n\ndiff1 = endTime1 - startTime1\n\nprint(\"\\n\")\n\nprint(\"Elapsed time for Caffe training (s): \", diff1.total_seconds())\n\nprint(\"\\n\")\n\n\n\n**PREDICT**(This version is the one in which I load the validation set images for prediction)\n\nimport os\n\nimport glob\n\nimport cv2\n\nimport sys\n\nsys.path.append(\"/home/ofer/caffe/python\")\n\nimport matplotlib.pyplot as plt\n\nimport matplotlib.cm as cm\n\nimport caffe\n\nimport lmdb\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n\nwarnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n\nimport numpy as np\n\nfrom PIL import Image\n\nfrom config import cifar10_config as config\n\nimport scipy\n\nfrom scipy.ndimage import gaussian_filter\n\nfrom scipy.ndimage import rotate\n\nimport argparse\n\nimport math\n\nfrom caffe.proto import caffe_pb2\n\ncaffe.set_mode_cpu()\n\n\nnet = caffe.Net('caffe/models/miniVggNet/m3/deploy2_3_miniVggNet.prototxt','caffe/models/miniVggNet/m3/snapshot_3_miniVggNet_/2-conv-layers/solver2_3_miniVggNet_iter_10000.caffemodel',caffe.TEST)\n\n\nTEST_DATASET =\"input/cifar10_jpg/val/*/*.jpg\"\n\n\ntest_img_paths = [img_path for img_path in glob.glob(TEST_DATASET)]\n\n\nNUMEL = len(test_img_paths)\n\n\nprint(NUMEL)\n\n\ntest_ids = np.zeros(([NUMEL,1]))\n\n\nprint(test_ids)\n\n\npreds = np.zeros(([NUMEL, 3]))\n\n\nidx = 0\n\n\ntot_true  = 0\n\n\ntot_false = 0\n\n\ntop5_true = 0\n\ntop5_false= 0\n\n\nlmdb_file = \"input/lmdb/train_lmdb\"\n\nlmdb_env = lmdb.open(lmdb_file)\n\nlmdb_txn = lmdb_env.begin()\n\nlmdb_cursor = lmdb_txn.cursor()\n\ndatum = caffe_pb2.Datum()\n\nprint(datum.channels,datum.height,datum.width)\nk=0\n\nprint(lmdb_cursor)\n\nfor key, value in lmdb_cursor:\n\nk+=1\n\ndatum.ParseFromString(value)\n\nlabel = datum.label\n\ndata=np.fromstring(datum.data, dtype=np.float32).reshape(datum.channels, datum.height, datum.width)\n\nimg=data\n\nimg=np.rollaxis(img, 1, 0)\n\nimg=np.rollaxis(img, 2, 0)\n\nimg=np.rollaxis(img, 2, 0)\n\nnet.blobs['data'].data[...] = img\n\nout = net.forward()\n\nbest_n = net.blobs['prob'].data[0].flatten().argsort()[-1: -6:-1]\n\nprint(\"DBG INFO: \", best_n)\n\npred_probas = out['prob']\n\nprint(pred_probas)\n\ntop5 = pred_probas.argsort()[-5:][::-1]\n\nif 'good' in img_path:\n\nlabel = 0\n\nelif 'miss' in img_path:\n\nlabel = 1\n\nelif 'excess' in img_path:\nlabel = 2  \n\nelse:\n\nlabel = -1 # non existing\n\nif label in top5 :\n\ntop5_true = top5_true + 1\n\nelse :\n\ntop5_false = top5_false + 1\n\ntest_ids[idx] = label\npreds[idx] = pred_probas\n\n\nprint(\"IMAGE: \" + img_path)\n\nprint(\"PREDICTED: %d\" % preds[idx].argmax())\n\nprint(\"EXPECTED : %d\" % test_ids[idx])\n\nprint '-------'\n\nfrom sklearn.preprocessing import LabelBinarizer\n\nfrom sklearn.metrics import classification_report\n\nlb     = LabelBinarizer()\n\ntestY  = lb.fit_transform(test_ids)\n\nlabelNames = [\"good\", \"miss\", \"excess\"]\n\nreport=classification_report(testY.argmax(axis=1), preds.argmax(axis=1), target_names=labelNames)\n\nprint(report)\n\nfrom sklearn.metrics import accuracy_score\n\nprint('SKLEARN Accuracy = %.2f' % accuracy_score(testY.argmax(axis=1), preds.argmax(axis=1)) )\n\nlist_predictions = np.array(preds.argmax(axis=1)) # actual predictions\nlist_str_num = np.array(testY.argmax(axis=1))    # ground truth\n\nfor ii in range(0, NUMEL) :\nn1 = list_str_num[ii]\nn2 = list_predictions[ii]\ndiff = n1 - n2\nif diff == 0 :\ntot_true = tot_true + 1\nelse:\ntot_false = tot_false+1\n\ntop5_accuracy = float(top5_true) / (top5_true + top5_false)\n\nprint(\"\\n\")\n\nprint('TOP-5 ACCURACY                    = %.2f ' % top5_accuracy)\n\nprint 'TOP-5 FALSE                       = ', top5_false\n\nprint 'TOP-5 TRUE                        = ', top5_true\n\nprint(\"\\n\")\n\nprint 'TOTAL NUMBER OF TRUE  PREDICTIONS = ', tot_true\n\nprint 'TOTAL NUMBER OF FALSE PREDICTIONS = ', tot_false\n\nif (tot_true+tot_false) != NUMEL :\n\nprint 'ERROR: number of total false and positive is not equal to the number of processed images'\n\nif (top5_true+top5_false) != NUMEL :\n\nprint 'ERROR: number of top5 total false and positive is not equal to the number of processed images'        \n\nrecall =  float(tot_true)/(tot_true+tot_false)\n\nprint('MANUALLY COMPUTED RECALL = %.2f ' % recall)\n</code></pre>\n <machine-learning><cnn><prediction><caffe>",
                "codes": [],
                "question_id:": "52194",
                "question_votes:": "",
                "question_text:": "<p>I am new to Machine Learning, CNN and Caffe and I have an issue I would be very happy to solve.\nAs part of a University project I must use a Machine Learning method to classify images into 3 classes. I use Caffe on Python for the task.</p>\n\n<p><strong>LONG STORY SHORT</strong> (Code is attached later on): </p>\n\n<p>After finishing the training stage, which resulted in(from log file):</p>\n\n<pre><code>Test net output #0: accuracy = 1\nTest net output #1: loss = 0.000219849 (* 1 = 0.000219849 loss)\nOptimization Done.\nOptimization Done.\n</code></pre>\n\n<p>I tried to predict for a test set and received a constant prediction for all images.\nI have tried to check my code for correct functionality, and found that even when i use the validation set for predicting- I get a constant prediction. How can that be? shouldn't my net be able to classify those with great accuracy?</p>\n\n<p><strong>CODE</strong></p>\n\n<p><strong>TRAINING</strong>:</p>\n\n<pre><code> import  os\n\n import glob\n\n from datetime import datetime\n\n from config import cifar10_config as config\n\n import argparse\n ap = argparse.ArgumentParser()\n ap.add_argument(\"-l\", \"--logfile\", required=True, help=\"logfile\")\n ap.add_argument(\"-s\", \"--solver\",  required=True, help=\"solver\") \n\nargs = vars(ap.parse_args())\nLOGFILE = args[\"logfile\"]\nSOLVER  = args[\"solver\"]\n\nCAFFE_TRAINING = config.CAFFE_TOOLS_DIR + \"/bin/caffe.bin train \"      #i.e. \"/caffe/Caffe-SSD-Ristretto/distribute/bin/caffe.bin train \"\n\nprint(\"TRAINING WITH CAFFE\")\n\ncaffe_solver  = SOLVER\n\ncaffe_logfile = LOGFILE\n\ncaffe_command = CAFFE_TRAINING + ' --solver ' + caffe_solver + ' 2&gt;&amp;1 | tee ' + caffe_logfile\n\nstartTime1 = datetime.now()\n\nos.system(caffe_command)\n\nendTime1 = datetime.now()\n\ndiff1 = endTime1 - startTime1\n\nprint(\"\\n\")\n\nprint(\"Elapsed time for Caffe training (s): \", diff1.total_seconds())\n\nprint(\"\\n\")\n\n\n\n**PREDICT**(This version is the one in which I load the validation set images for prediction)\n\nimport os\n\nimport glob\n\nimport cv2\n\nimport sys\n\nsys.path.append(\"/home/ofer/caffe/python\")\n\nimport matplotlib.pyplot as plt\n\nimport matplotlib.cm as cm\n\nimport caffe\n\nimport lmdb\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n\nwarnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n\nimport numpy as np\n\nfrom PIL import Image\n\nfrom config import cifar10_config as config\n\nimport scipy\n\nfrom scipy.ndimage import gaussian_filter\n\nfrom scipy.ndimage import rotate\n\nimport argparse\n\nimport math\n\nfrom caffe.proto import caffe_pb2\n\ncaffe.set_mode_cpu()\n\n\nnet = caffe.Net('caffe/models/miniVggNet/m3/deploy2_3_miniVggNet.prototxt','caffe/models/miniVggNet/m3/snapshot_3_miniVggNet_/2-conv-layers/solver2_3_miniVggNet_iter_10000.caffemodel',caffe.TEST)\n\n\nTEST_DATASET =\"input/cifar10_jpg/val/*/*.jpg\"\n\n\ntest_img_paths = [img_path for img_path in glob.glob(TEST_DATASET)]\n\n\nNUMEL = len(test_img_paths)\n\n\nprint(NUMEL)\n\n\ntest_ids = np.zeros(([NUMEL,1]))\n\n\nprint(test_ids)\n\n\npreds = np.zeros(([NUMEL, 3]))\n\n\nidx = 0\n\n\ntot_true  = 0\n\n\ntot_false = 0\n\n\ntop5_true = 0\n\ntop5_false= 0\n\n\nlmdb_file = \"input/lmdb/train_lmdb\"\n\nlmdb_env = lmdb.open(lmdb_file)\n\nlmdb_txn = lmdb_env.begin()\n\nlmdb_cursor = lmdb_txn.cursor()\n\ndatum = caffe_pb2.Datum()\n\nprint(datum.channels,datum.height,datum.width)\nk=0\n\nprint(lmdb_cursor)\n\nfor key, value in lmdb_cursor:\n\nk+=1\n\ndatum.ParseFromString(value)\n\nlabel = datum.label\n\ndata=np.fromstring(datum.data, dtype=np.float32).reshape(datum.channels, datum.height, datum.width)\n\nimg=data\n\nimg=np.rollaxis(img, 1, 0)\n\nimg=np.rollaxis(img, 2, 0)\n\nimg=np.rollaxis(img, 2, 0)\n\nnet.blobs['data'].data[...] = img\n\nout = net.forward()\n\nbest_n = net.blobs['prob'].data[0].flatten().argsort()[-1: -6:-1]\n\nprint(\"DBG INFO: \", best_n)\n\npred_probas = out['prob']\n\nprint(pred_probas)\n\ntop5 = pred_probas.argsort()[-5:][::-1]\n\nif 'good' in img_path:\n\nlabel = 0\n\nelif 'miss' in img_path:\n\nlabel = 1\n\nelif 'excess' in img_path:\nlabel = 2  \n\nelse:\n\nlabel = -1 # non existing\n\nif label in top5 :\n\ntop5_true = top5_true + 1\n\nelse :\n\ntop5_false = top5_false + 1\n\ntest_ids[idx] = label\npreds[idx] = pred_probas\n\n\nprint(\"IMAGE: \" + img_path)\n\nprint(\"PREDICTED: %d\" % preds[idx].argmax())\n\nprint(\"EXPECTED : %d\" % test_ids[idx])\n\nprint '-------'\n\nfrom sklearn.preprocessing import LabelBinarizer\n\nfrom sklearn.metrics import classification_report\n\nlb     = LabelBinarizer()\n\ntestY  = lb.fit_transform(test_ids)\n\nlabelNames = [\"good\", \"miss\", \"excess\"]\n\nreport=classification_report(testY.argmax(axis=1), preds.argmax(axis=1), target_names=labelNames)\n\nprint(report)\n\nfrom sklearn.metrics import accuracy_score\n\nprint('SKLEARN Accuracy = %.2f' % accuracy_score(testY.argmax(axis=1), preds.argmax(axis=1)) )\n\nlist_predictions = np.array(preds.argmax(axis=1)) # actual predictions\nlist_str_num = np.array(testY.argmax(axis=1))    # ground truth\n\nfor ii in range(0, NUMEL) :\nn1 = list_str_num[ii]\nn2 = list_predictions[ii]\ndiff = n1 - n2\nif diff == 0 :\ntot_true = tot_true + 1\nelse:\ntot_false = tot_false+1\n\ntop5_accuracy = float(top5_true) / (top5_true + top5_false)\n\nprint(\"\\n\")\n\nprint('TOP-5 ACCURACY                    = %.2f ' % top5_accuracy)\n\nprint 'TOP-5 FALSE                       = ', top5_false\n\nprint 'TOP-5 TRUE                        = ', top5_true\n\nprint(\"\\n\")\n\nprint 'TOTAL NUMBER OF TRUE  PREDICTIONS = ', tot_true\n\nprint 'TOTAL NUMBER OF FALSE PREDICTIONS = ', tot_false\n\nif (tot_true+tot_false) != NUMEL :\n\nprint 'ERROR: number of total false and positive is not equal to the number of processed images'\n\nif (top5_true+top5_false) != NUMEL :\n\nprint 'ERROR: number of top5 total false and positive is not equal to the number of processed images'        \n\nrecall =  float(tot_true)/(tot_true+tot_false)\n\nprint('MANUALLY COMPUTED RECALL = %.2f ' % recall)\n</code></pre>\n",
                "tags": "<machine-learning><cnn><prediction><caffe>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11004",
            "_score": 5.6285124,
            "_source": {
                "title": "Why this single layer network does'nt work",
                "content": "Why this single layer network does'nt work <p>I am trying following code (modified from <a href=\"https://www.kdnuggets.com/2017/10/seven-steps-deep-learning-keras.html\" rel=\"nofollow noreferrer\">https://www.kdnuggets.com/2017/10/seven-steps-deep-learning-keras.html</a> ): </p>\n\n<pre><code>def single_layer(input_shape, nb_classes): \n    print(\"input shape:\", input_shape)\n    print(\"print nb_classes:\", nb_classes)\n\n    from keras.models import Sequential\n    from keras.layers import Dense, Activation\n\n    model = Sequential()\n    model.add(Dense(nb_classes, input_shape=input_shape, activation='softmax')) \n\n    model.compile(optimizer='sgd', loss='categorical_crossentropy') \n    model.summary()\n    return model\n</code></pre>\n\n<p>However, when I try to fit this model with an <code>X_train</code> of dimensions <code>64,64,3</code> and 17 classes, following is the output with error: </p>\n\n<pre><code>input shape: (64, 64, 3)\nprint nb_classes: 17\nUsing TensorFlow backend.\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 64, 64, 17)        68        \n=================================================================\nTotal params: 68\nTrainable params: 68\nNon-trainable params: 0\n_________________________________________________________________\nTraceback (most recent call last):\n....\n....\n  File \"/home/abcd/.local/lib/python3.5/site-packages/keras/engine/training.py\", line 950, in fit\n    batch_size=batch_size)\n  File \"/home/abcd/.local/lib/python3.5/site-packages/keras/engine/training.py\", line 787, in _standardize_user_data\n    exception_prefix='target')\n  File \"/home/abcd/.local/lib/python3.5/site-packages/keras/engine/training_utils.py\", line 127, in standardize_input_data\n    'with shape ' + str(data_shape))\nValueError: Error when checking target: expected dense_1 to have 4 dimensions, but got array with shape (10396, 17)\n</code></pre>\n\n<p>Why this code is not working and how should it be modified to make it work?</p>\n <keras><p>I can't find the code in the link you posted to get more background information on what kind of data source it is that you are using.</p>\n\n<p>However, a data source that is <span class=\"math-container\">$60\\times60\\times3$</span> is described as being high dimensional. You have a total of 10,800 input features which need to be mapped down to 17 different classes. This is actually a very complex task and will not be successful using a single layer network. Such a simple network will not have enough parameters to capture the non-linearities between features in your input space. </p>\n\n<p>That being said, if you insist on using a single layer network with a data of size <span class=\"math-container\">$60\\times60\\times3$</span> with 17 input classes the code is as follows.</p>\n\n<p>Let's first create some artificial data of the same dimension as your data</p>\n\n<pre><code>import numpy as np\n\nn = 1000\nx_train = np.zeros((n,64,64,3))\ny_train = np.zeros((n,))\nfor i in range(n):\n    x_train[i,:,:,:] = np.random.random((64,64,3))\n    y_train[i] = np.random.randint(0,17)\n\nx_train = x_train.reshape(n,64,64,3,)\n\nn = 100\nx_test = np.zeros((n,64,64,3))\ny_test = np.zeros((n,))\nfor i in range(n):\n    x_test[i,:,:,:] = np.random.random((64,64,3))\n    y_test[i] = np.random.randint(0,17)\n\nx_test = x_test.reshape(n,64,64,3,)\n\nprint('Training data: ', x_train.shape)\nprint('Training labels: ', y_train.shape)\nprint('Testing data: ', x_test.shape)\nprint('Testing labels: ', y_test.shape)\n</code></pre>\n\n<blockquote>\n  <p>(1000, 64, 64, 3) <br/>\n  (1000,) <br/>\n  (100, 64, 64, 3) <br/>\n  (100,)</p>\n</blockquote>\n\n<p>For a classification task we should convert our outputs to categorical vectors. Where we use one-hot encoding to identify the correct class.</p>\n\n<pre><code>import keras\n\n# The known number of output classes.\nnum_classes = 17\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n</code></pre>\n\n<p>We then build the model. </p>\n\n<pre><code>from __future__ import print_function\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.models import model_from_json\nfrom keras import backend as K\n\ninput_shape = (64,64,3,)\n\nmodel = Sequential()\nmodel.add(Flatten(input_shape=input_shape))\nmodel.add(Dense(17, activation='softmax'))\n\n\nmodel.compile(loss=keras.losses.mean_squared_error,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<p>You can see the summary of the model by using </p>\n\n<pre><code>model.summary()\n</code></pre>\n\n<p>Then we can train this model using</p>\n\n<pre><code>batch_size = 128\nepochs = 10\nmodel.fit(x_train, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test_binary))\n</code></pre>\n\n<p>This code works. However, the data is completely random thus the model cannot learn anything. However, even if your data is easily distinguishable, as I said above, I do not expect this model to be complex enough to distinguish such a large input space from 17 different possible classes.</p>\n\n<p>If you post the data source you are using we can design a model to get a good result.</p>\n",
                "codes": [
                    [
                        "import numpy as np\n\nn = 1000\nx_train = np.zeros((n,64,64,3))\ny_train = np.zeros((n,))\nfor i in range(n):\n    x_train[i,:,:,:] = np.random.random((64,64,3))\n    y_train[i] = np.random.randint(0,17)\n\nx_train = x_train.reshape(n,64,64,3,)\n\nn = 100\nx_test = np.zeros((n,64,64,3))\ny_test = np.zeros((n,))\nfor i in range(n):\n    x_test[i,:,:,:] = np.random.random((64,64,3))\n    y_test[i] = np.random.randint(0,17)\n\nx_test = x_test.reshape(n,64,64,3,)\n\nprint('Training data: ', x_train.shape)\nprint('Training labels: ', y_train.shape)\nprint('Testing data: ', x_test.shape)\nprint('Testing labels: ', y_test.shape)\n",
                        "import keras\n\n# The known number of output classes.\nnum_classes = 17\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n",
                        "from __future__ import print_function\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.models import model_from_json\nfrom keras import backend as K\n\ninput_shape = (64,64,3,)\n\nmodel = Sequential()\nmodel.add(Flatten(input_shape=input_shape))\nmodel.add(Dense(17, activation='softmax'))\n\n\nmodel.compile(loss=keras.losses.mean_squared_error,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n",
                        "model.summary()\n",
                        "batch_size = 128\nepochs = 10\nmodel.fit(x_train, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test_binary))\n"
                    ]
                ],
                "question_id:": "38946",
                "question_votes:": "1",
                "question_text:": "<p>I am trying following code (modified from <a href=\"https://www.kdnuggets.com/2017/10/seven-steps-deep-learning-keras.html\" rel=\"nofollow noreferrer\">https://www.kdnuggets.com/2017/10/seven-steps-deep-learning-keras.html</a> ): </p>\n\n<pre><code>def single_layer(input_shape, nb_classes): \n    print(\"input shape:\", input_shape)\n    print(\"print nb_classes:\", nb_classes)\n\n    from keras.models import Sequential\n    from keras.layers import Dense, Activation\n\n    model = Sequential()\n    model.add(Dense(nb_classes, input_shape=input_shape, activation='softmax')) \n\n    model.compile(optimizer='sgd', loss='categorical_crossentropy') \n    model.summary()\n    return model\n</code></pre>\n\n<p>However, when I try to fit this model with an <code>X_train</code> of dimensions <code>64,64,3</code> and 17 classes, following is the output with error: </p>\n\n<pre><code>input shape: (64, 64, 3)\nprint nb_classes: 17\nUsing TensorFlow backend.\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 64, 64, 17)        68        \n=================================================================\nTotal params: 68\nTrainable params: 68\nNon-trainable params: 0\n_________________________________________________________________\nTraceback (most recent call last):\n....\n....\n  File \"/home/abcd/.local/lib/python3.5/site-packages/keras/engine/training.py\", line 950, in fit\n    batch_size=batch_size)\n  File \"/home/abcd/.local/lib/python3.5/site-packages/keras/engine/training.py\", line 787, in _standardize_user_data\n    exception_prefix='target')\n  File \"/home/abcd/.local/lib/python3.5/site-packages/keras/engine/training_utils.py\", line 127, in standardize_input_data\n    'with shape ' + str(data_shape))\nValueError: Error when checking target: expected dense_1 to have 4 dimensions, but got array with shape (10396, 17)\n</code></pre>\n\n<p>Why this code is not working and how should it be modified to make it work?</p>\n",
                "tags": "<keras>",
                "answers": [
                    [
                        "38949",
                        "2",
                        "38946",
                        "",
                        "",
                        "<p>I can't find the code in the link you posted to get more background information on what kind of data source it is that you are using.</p>\n\n<p>However, a data source that is <span class=\"math-container\">$60\\times60\\times3$</span> is described as being high dimensional. You have a total of 10,800 input features which need to be mapped down to 17 different classes. This is actually a very complex task and will not be successful using a single layer network. Such a simple network will not have enough parameters to capture the non-linearities between features in your input space. </p>\n\n<p>That being said, if you insist on using a single layer network with a data of size <span class=\"math-container\">$60\\times60\\times3$</span> with 17 input classes the code is as follows.</p>\n\n<p>Let's first create some artificial data of the same dimension as your data</p>\n\n<pre><code>import numpy as np\n\nn = 1000\nx_train = np.zeros((n,64,64,3))\ny_train = np.zeros((n,))\nfor i in range(n):\n    x_train[i,:,:,:] = np.random.random((64,64,3))\n    y_train[i] = np.random.randint(0,17)\n\nx_train = x_train.reshape(n,64,64,3,)\n\nn = 100\nx_test = np.zeros((n,64,64,3))\ny_test = np.zeros((n,))\nfor i in range(n):\n    x_test[i,:,:,:] = np.random.random((64,64,3))\n    y_test[i] = np.random.randint(0,17)\n\nx_test = x_test.reshape(n,64,64,3,)\n\nprint('Training data: ', x_train.shape)\nprint('Training labels: ', y_train.shape)\nprint('Testing data: ', x_test.shape)\nprint('Testing labels: ', y_test.shape)\n</code></pre>\n\n<blockquote>\n  <p>(1000, 64, 64, 3) <br/>\n  (1000,) <br/>\n  (100, 64, 64, 3) <br/>\n  (100,)</p>\n</blockquote>\n\n<p>For a classification task we should convert our outputs to categorical vectors. Where we use one-hot encoding to identify the correct class.</p>\n\n<pre><code>import keras\n\n# The known number of output classes.\nnum_classes = 17\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n</code></pre>\n\n<p>We then build the model. </p>\n\n<pre><code>from __future__ import print_function\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.models import model_from_json\nfrom keras import backend as K\n\ninput_shape = (64,64,3,)\n\nmodel = Sequential()\nmodel.add(Flatten(input_shape=input_shape))\nmodel.add(Dense(17, activation='softmax'))\n\n\nmodel.compile(loss=keras.losses.mean_squared_error,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<p>You can see the summary of the model by using </p>\n\n<pre><code>model.summary()\n</code></pre>\n\n<p>Then we can train this model using</p>\n\n<pre><code>batch_size = 128\nepochs = 10\nmodel.fit(x_train, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test_binary))\n</code></pre>\n\n<p>This code works. However, the data is completely random thus the model cannot learn anything. However, even if your data is easily distinguishable, as I said above, I do not expect this model to be complex enough to distinguish such a large input space from 17 different possible classes.</p>\n\n<p>If you post the data source you are using we can design a model to get a good result.</p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16759",
            "_score": 5.580156,
            "_source": {
                "title": "Getting 'ValueError: setting an array element with a sequence.' when attempting to fit mixed-type data",
                "content": "Getting 'ValueError: setting an array element with a sequence.' when attempting to fit mixed-type data <p>I have already seen <a href=\"https://stackoverflow.com/questions/53023341/python-scikit-learn-classification-with-mixed-data-types-text-numerical-categ\">this</a>, <a href=\"https://stackoverflow.com/questions/4674473/valueerror-setting-an-array-element-with-a-sequence\">this</a> and <a href=\"https://stackoverflow.com/questions/13310347/numpy-valueerror-setting-an-array-element-with-a-sequence-this-message-may-app/39114489\">this</a> question, but none of the suggestions seemed to fix my problem (so I have reverted them).</p>\n\n<p>I have the following code:</p>\n\n<pre><code>nlp = spacy.load('en_core_web_sm')\nparser = English()\n\nclass CleanTextTransformer(TransformerMixin):\n    def transform(self, X, **transform_params):\n        return [cleanText(text) for text in X]\n\n    def fit(self, X, y=None, **fit_params):\n        return self\n\n    def get_params(self, deep=True):\n        return {}\n\n\ndef cleanText(text):\n    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n    text = text.lower()\n    return text\n\n\ndef tokenizeText(sample):\n    tokens = parser(sample)\n    lemmas = []\n    for tok in tokens:\n        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n    tokens = lemmas\n    tokens = [tok for tok in tokens if tok not in STOPLIST]\n    tokens = [nlp(tok)[0].lemma_ for tok in tokens if tok not in SYMBOLS]\n    return tokens\n\nclass multilabelbin(TransformerMixin):\n    def __init__(self, *args, **kwargs):\n        self.encoder = MultiLabelBinarizer(*args, **kwargs)\n\n    def fit(self, x, y=0):\n        self.encoder.fit(x)\n        return self\n\n    def transform(self, x, y=0):\n        return self.encoder.transform(x)\n\n\ndef represent(rd, ed, number, category, text):\n    doc_train = rd\n    doc_test = ed\n\n    for column in category:\n        doc_train[column] = [tuple(doc.split(\",\")) for doc in rd[column]]\n        doc_test[column] = [tuple(doc.split(\",\")) for doc in ed[column]]\n\n        print(\"columns split\")\n\n        mlb = multilabelbin(sparse_output=False)\n        mlb.fit(doc_train)\n\n        transformed_r = mlb.transform(doc_train)\n        for row in range(len(doc_train[column])):\n            print(doc_train[column][row])\n            doc_train[column][row] = transformed_r[row]\n\n        transformed_e = mlb.transform(doc_test)\n        for row in range(len(doc_test[column])):\n            print(doc_test[column][row])\n            doc_test[column][row] = transformed_e[row]\n\n        print(\"categorical columns encoded using MultiLabelBinarizer()\")\n\n    for column in number:\n        ss = StandardScaler()\n        ss.fit(doc_train[column].values.reshape(-1, 1))\n\n        doc_train[column] = ss.transform(doc_train[column].values.reshape(-1, 1))\n        doc_test[column] = ss.transform(doc_test[column].values.reshape(-1, 1))\n        print(\"numbers scaled using StandardScaler()\")\n\n    for column in text:\n        cleaner = CleanTextTransformer()\n        cleaner.fit(doc_train[column].tolist())\n\n        doc_train[column] = cleaner.transform(doc_train[column])\n        doc_test[column] = cleaner.transform(doc_test[column])\n\n        print(doc_train[column])\n\n        vec = TfidfVectorizer(tokenizer=tokenizeText, ngram_range=(1, 1))\n        vec.fit(doc_train[column].tolist())\n\n        doc_train[column] = vec.transform(doc_train[column]).todense()\n        doc_test[column] = vec.transform(doc_test[column]).todense()\n\n        print(doc_train[column])\n\n        print(\"text vectorized\")\n\n    print(\"preprocessing completed successfully\")\n\n    return doc_train, doc_test\n\n\ndef train_classifier(train_docs, classAxis):\n    clf = OneVsRestClassifier(LogisticRegression(solver='saga'))\n\n    X = [list(train_docs[list(train_docs)[i]]) for i in range(1, len(train_docs))]\n    y = list(train_docs[classAxis])\n\n    classifier = clf.fit(X, y)\n    return classifier\n\ndf = pd.DataFrame(pd.read_csv(\"testdata.csv\", header=0))\ntest_data = pd.DataFrame(pd.read_csv(\"test.csv\", header=0))\n\ntrain, test = represent(df, test_data, [\"Cat2\", \"Cat5\"], [\"Cat6\"], [\"Cat1\", \"Cat3\", \"Cat4\", \"Cat7\"])\n\nprint(train, test)\n\nmodel = train_classifier(train, \"Class\")\n</code></pre>\n\n<p><code>train.csv</code> contains data in this format:</p>\n\n<p><a href=\"https://i.stack.imgur.com/eVGib.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/eVGib.png\" alt=\"format of data\"></a></p>\n\n<p><code>test.csv</code> is of the same format.</p>\n\n<p>As you can see, there are text values, number values and categorical values. My code firstly splits up the categorical values (which are comma-delimited), before running them through <code>MultiLabelBinarizer()</code>. Then, I simply scale the numbers. Finally, I process the text using the <code>spaCy</code> settings found in <a href=\"https://towardsdatascience.com/machine-learning-for-text-classification-using-spacy-in-python-b276b4051a49\" rel=\"nofollow noreferrer\">this tutorial</a>. I make sure to apply transformations to the test data, too, so there can be no inconsistency there. Finally, I <code>list</code>-enise everything in the <code>train_classifier</code> function, which supposedly should help... but it didn't. In the line <code>classifier = clf.fit(list(X), y)</code>, I get the following error:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"&lt;input&gt;\", line 1, in &lt;module&gt;\n  File \"C:\\Users\\User\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\191.7141.48\\helpers\\pydev\\_pydev_bundle\\pydev_umd.py\", line 197, in runfile\n    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script\n  File \"C:\\Users\\User\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\191.7141.48\\helpers\\pydev\\_pydev_imps\\_pydev_execfile.py\", line 18, in execfile\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\n  File \"C:/Users/User/PycharmProjects/ml/ml.py\", line 148, in &lt;module&gt;\n    model = train_classifier(train, \"Class\")\n  File \"C:/Users/User/PycharmProjects/ml/ml.py\", line 124, in train_classifier\n    classifier = clf.fit(list(X), y)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\multiclass.py\", line 215, in fit\n    for i, column in enumerate(columns))\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 917, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 716, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 182, in apply_async\n    result = ImmediateResult(func)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 549, in __init__\n    self.results = batch()\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in &lt;listcomp&gt;\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\multiclass.py\", line 80, in _fit_binary\n    estimator.fit(X, y)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\", line 1288, in fit\n    accept_large_sparse=solver != 'liblinear')\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 756, in check_X_y\n    estimator=estimator)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 527, in check_array\n    array = np.asarray(array, dtype=dtype, order=order)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\numpy\\core\\numeric.py\", line 538, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: setting an array element with a sequence.\n</code></pre>\n\n<p>I have tried to read through docs, and am not one to shy away from reading source code (and PyCharm helped me pinpoint the source of the error), but am no closer to fixing it. I feel like I have honestly tried everything on the first 3 pages of Google, but to no success.</p>\n\n<p>How can I fix this error? Why is it happening? Is my preprocessing wrong? I know it's a bit dodgy in places, but does this make is unfunctional? If so, how could I fix these issues in the preprocessor? Would this fix the <code>ValueError: setting an array element with a sequence.</code> error?</p>\n\n<p>Some notes:</p>\n\n<ul>\n<li>For some reason, <code>spaCy</code> seems to return 0.0 for most values in each column.</li>\n<li>I am unsure if I can just insert my <code>MultiLabelVectorizer()</code> output into the DataFrame like this (simply as the 2D arrays) - is this OK? Are there any more steps required?</li>\n<li>I have tried Pipelines for more semantic code, as well as using different classifiers for the different data types (e.g using Chi^2 for text, and other things for other types), but it always seemed to result in an endless well of bugs.</li>\n<li>I am unable to even pinpoint what throws this error: is it the column data, the text data or the number data? I don't know.</li>\n</ul>\n <machine-learning><python><scikit-learn><vector-space-models>",
                "codes": [],
                "question_id:": "54796",
                "question_votes:": "",
                "question_text:": "<p>I have already seen <a href=\"https://stackoverflow.com/questions/53023341/python-scikit-learn-classification-with-mixed-data-types-text-numerical-categ\">this</a>, <a href=\"https://stackoverflow.com/questions/4674473/valueerror-setting-an-array-element-with-a-sequence\">this</a> and <a href=\"https://stackoverflow.com/questions/13310347/numpy-valueerror-setting-an-array-element-with-a-sequence-this-message-may-app/39114489\">this</a> question, but none of the suggestions seemed to fix my problem (so I have reverted them).</p>\n\n<p>I have the following code:</p>\n\n<pre><code>nlp = spacy.load('en_core_web_sm')\nparser = English()\n\nclass CleanTextTransformer(TransformerMixin):\n    def transform(self, X, **transform_params):\n        return [cleanText(text) for text in X]\n\n    def fit(self, X, y=None, **fit_params):\n        return self\n\n    def get_params(self, deep=True):\n        return {}\n\n\ndef cleanText(text):\n    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n    text = text.lower()\n    return text\n\n\ndef tokenizeText(sample):\n    tokens = parser(sample)\n    lemmas = []\n    for tok in tokens:\n        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n    tokens = lemmas\n    tokens = [tok for tok in tokens if tok not in STOPLIST]\n    tokens = [nlp(tok)[0].lemma_ for tok in tokens if tok not in SYMBOLS]\n    return tokens\n\nclass multilabelbin(TransformerMixin):\n    def __init__(self, *args, **kwargs):\n        self.encoder = MultiLabelBinarizer(*args, **kwargs)\n\n    def fit(self, x, y=0):\n        self.encoder.fit(x)\n        return self\n\n    def transform(self, x, y=0):\n        return self.encoder.transform(x)\n\n\ndef represent(rd, ed, number, category, text):\n    doc_train = rd\n    doc_test = ed\n\n    for column in category:\n        doc_train[column] = [tuple(doc.split(\",\")) for doc in rd[column]]\n        doc_test[column] = [tuple(doc.split(\",\")) for doc in ed[column]]\n\n        print(\"columns split\")\n\n        mlb = multilabelbin(sparse_output=False)\n        mlb.fit(doc_train)\n\n        transformed_r = mlb.transform(doc_train)\n        for row in range(len(doc_train[column])):\n            print(doc_train[column][row])\n            doc_train[column][row] = transformed_r[row]\n\n        transformed_e = mlb.transform(doc_test)\n        for row in range(len(doc_test[column])):\n            print(doc_test[column][row])\n            doc_test[column][row] = transformed_e[row]\n\n        print(\"categorical columns encoded using MultiLabelBinarizer()\")\n\n    for column in number:\n        ss = StandardScaler()\n        ss.fit(doc_train[column].values.reshape(-1, 1))\n\n        doc_train[column] = ss.transform(doc_train[column].values.reshape(-1, 1))\n        doc_test[column] = ss.transform(doc_test[column].values.reshape(-1, 1))\n        print(\"numbers scaled using StandardScaler()\")\n\n    for column in text:\n        cleaner = CleanTextTransformer()\n        cleaner.fit(doc_train[column].tolist())\n\n        doc_train[column] = cleaner.transform(doc_train[column])\n        doc_test[column] = cleaner.transform(doc_test[column])\n\n        print(doc_train[column])\n\n        vec = TfidfVectorizer(tokenizer=tokenizeText, ngram_range=(1, 1))\n        vec.fit(doc_train[column].tolist())\n\n        doc_train[column] = vec.transform(doc_train[column]).todense()\n        doc_test[column] = vec.transform(doc_test[column]).todense()\n\n        print(doc_train[column])\n\n        print(\"text vectorized\")\n\n    print(\"preprocessing completed successfully\")\n\n    return doc_train, doc_test\n\n\ndef train_classifier(train_docs, classAxis):\n    clf = OneVsRestClassifier(LogisticRegression(solver='saga'))\n\n    X = [list(train_docs[list(train_docs)[i]]) for i in range(1, len(train_docs))]\n    y = list(train_docs[classAxis])\n\n    classifier = clf.fit(X, y)\n    return classifier\n\ndf = pd.DataFrame(pd.read_csv(\"testdata.csv\", header=0))\ntest_data = pd.DataFrame(pd.read_csv(\"test.csv\", header=0))\n\ntrain, test = represent(df, test_data, [\"Cat2\", \"Cat5\"], [\"Cat6\"], [\"Cat1\", \"Cat3\", \"Cat4\", \"Cat7\"])\n\nprint(train, test)\n\nmodel = train_classifier(train, \"Class\")\n</code></pre>\n\n<p><code>train.csv</code> contains data in this format:</p>\n\n<p><a href=\"https://i.stack.imgur.com/eVGib.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/eVGib.png\" alt=\"format of data\"></a></p>\n\n<p><code>test.csv</code> is of the same format.</p>\n\n<p>As you can see, there are text values, number values and categorical values. My code firstly splits up the categorical values (which are comma-delimited), before running them through <code>MultiLabelBinarizer()</code>. Then, I simply scale the numbers. Finally, I process the text using the <code>spaCy</code> settings found in <a href=\"https://towardsdatascience.com/machine-learning-for-text-classification-using-spacy-in-python-b276b4051a49\" rel=\"nofollow noreferrer\">this tutorial</a>. I make sure to apply transformations to the test data, too, so there can be no inconsistency there. Finally, I <code>list</code>-enise everything in the <code>train_classifier</code> function, which supposedly should help... but it didn't. In the line <code>classifier = clf.fit(list(X), y)</code>, I get the following error:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"&lt;input&gt;\", line 1, in &lt;module&gt;\n  File \"C:\\Users\\User\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\191.7141.48\\helpers\\pydev\\_pydev_bundle\\pydev_umd.py\", line 197, in runfile\n    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script\n  File \"C:\\Users\\User\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\191.7141.48\\helpers\\pydev\\_pydev_imps\\_pydev_execfile.py\", line 18, in execfile\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\n  File \"C:/Users/User/PycharmProjects/ml/ml.py\", line 148, in &lt;module&gt;\n    model = train_classifier(train, \"Class\")\n  File \"C:/Users/User/PycharmProjects/ml/ml.py\", line 124, in train_classifier\n    classifier = clf.fit(list(X), y)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\multiclass.py\", line 215, in fit\n    for i, column in enumerate(columns))\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 917, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 716, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 182, in apply_async\n    result = ImmediateResult(func)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 549, in __init__\n    self.results = batch()\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in &lt;listcomp&gt;\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\multiclass.py\", line 80, in _fit_binary\n    estimator.fit(X, y)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\", line 1288, in fit\n    accept_large_sparse=solver != 'liblinear')\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 756, in check_X_y\n    estimator=estimator)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 527, in check_array\n    array = np.asarray(array, dtype=dtype, order=order)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\numpy\\core\\numeric.py\", line 538, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: setting an array element with a sequence.\n</code></pre>\n\n<p>I have tried to read through docs, and am not one to shy away from reading source code (and PyCharm helped me pinpoint the source of the error), but am no closer to fixing it. I feel like I have honestly tried everything on the first 3 pages of Google, but to no success.</p>\n\n<p>How can I fix this error? Why is it happening? Is my preprocessing wrong? I know it's a bit dodgy in places, but does this make is unfunctional? If so, how could I fix these issues in the preprocessor? Would this fix the <code>ValueError: setting an array element with a sequence.</code> error?</p>\n\n<p>Some notes:</p>\n\n<ul>\n<li>For some reason, <code>spaCy</code> seems to return 0.0 for most values in each column.</li>\n<li>I am unsure if I can just insert my <code>MultiLabelVectorizer()</code> output into the DataFrame like this (simply as the 2D arrays) - is this OK? Are there any more steps required?</li>\n<li>I have tried Pipelines for more semantic code, as well as using different classifiers for the different data types (e.g using Chi^2 for text, and other things for other types), but it always seemed to result in an endless well of bugs.</li>\n<li>I am unable to even pinpoint what throws this error: is it the column data, the text data or the number data? I don't know.</li>\n</ul>\n",
                "tags": "<machine-learning><python><scikit-learn><vector-space-models>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4825",
            "_score": 5.574483,
            "_source": {
                "title": "Feature Extraction from Concolutional neural network (CNN) and use this feature to other classification algorithm",
                "content": "Feature Extraction from Concolutional neural network (CNN) and use this feature to other classification algorithm <p>As in <a href=\"https://arxiv.org/abs/1403.6382\" rel=\"nofollow noreferrer\">this</a> the author is using CNN to extract features of the images. And then doing SVM for further analysis. My question is how to extract features in CNN?</p>\n\n<p>E.g. Here is a CNN code I'm using:</p>\n\n<pre><code>%matplotlib inline\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport time\nfrom datetime import timedelta\nimport math\n\n# Convolutional Layer 1.\nfilter_size1 = 5          # Convolution filters are 5 x 5 pixels.\nnum_filters1 = 16         # There are 16 of these filters.\n\n# Convolutional Layer 2.\nfilter_size2 = 5          # Convolution filters are 5 x 5 pixels.\nnum_filters2 = 36         # There are 36 of these filters.\n\n# Fully-connected layer.\nfc_size = 128             # Number of neurons in fully-connected layer.\n\nfrom tensorflow.examples.tutorials.mnist import input_data\ndata = input_data.read_data_sets('data/MNIST/', one_hot=True)\n\ndata.test.cls = np.argmax(data.test.labels, axis=1)\n\n# We know that MNIST images are 28 pixels in each dimension.\nimg_size = 28\n\n# Images are stored in one-dimensional arrays of this length.\nimg_size_flat = img_size * img_size\n\n# Tuple with height and width of images used to reshape arrays.\nimg_shape = (img_size, img_size)\n\n# Number of colour channels for the images: 1 channel for gray-scale.\nnum_channels = 1\n\n# Number of classes, one class for each of 10 digits.\nnum_classes = 10\n\ndef new_weights(shape):\n    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n\ndef new_biases(length):\n    return tf.Variable(tf.constant(0.05, shape=[length]))\n\ndef new_conv_layer(input,              # The previous layer.\n                   num_input_channels, # Num. channels in prev. layer.\n                   filter_size,        # Width and height of each filter.\n                   num_filters,        # Number of filters.\n                   use_pooling=True):  # Use 2x2 max-pooling.\n\n    # Shape of the filter-weights for the convolution.\n    # This format is determined by the TensorFlow API.\n    shape = [filter_size, filter_size, num_input_channels, num_filters]\n\n    # Create new weights aka. filters with the given shape.\n    weights = new_weights(shape=shape)\n\n    # Create new biases, one for each filter.\n    biases = new_biases(length=num_filters)\n\n    # Create the TensorFlow operation for convolution.\n    # Note the strides are set to 1 in all dimensions.\n    # The first and last stride must always be 1,\n    # because the first is for the image-number and\n    # the last is for the input-channel.\n    # But e.g. strides=[1, 2, 2, 1] would mean that the filter\n    # is moved 2 pixels across the x- and y-axis of the image.\n    # The padding is set to 'SAME' which means the input image\n    # is padded with zeroes so the size of the output is the same.\n    layer = tf.nn.conv2d(input=input,\n                         filter=weights,\n                         strides=[1, 1, 1, 1],\n                         padding='SAME')\n\n    # Add the biases to the results of the convolution.\n    # A bias-value is added to each filter-channel.\n    layer += biases\n\n    # Use pooling to down-sample the image resolution?\n    if use_pooling:\n        # This is 2x2 max-pooling, which means that we\n        # consider 2x2 windows and select the largest value\n        # in each window. Then we move 2 pixels to the next window.\n        layer = tf.nn.max_pool(value=layer,\n                               ksize=[1, 2, 2, 1],\n                               strides=[1, 2, 2, 1],\n                               padding='SAME')\n\n    # Rectified Linear Unit (ReLU).\n    # It calculates max(x, 0) for each input pixel x.\n    # This adds some non-linearity to the formula and allows us\n    # to learn more complicated functions.\n    layer = tf.nn.relu(layer)\n\n    # Note that ReLU is normally executed before the pooling,\n    # but since relu(max_pool(x)) == max_pool(relu(x)) we can\n    # save 75% of the relu-operations by max-pooling first.\n\n    # We return both the resulting layer and the filter-weights\n    # because we will plot the weights later.\n    return layer, weights\n\ndef flatten_layer(layer):\n    # Get the shape of the input layer.\n    layer_shape = layer.get_shape()\n\n    # The shape of the input layer is assumed to be:\n    # layer_shape == [num_images, img_height, img_width, num_channels]\n\n    # The number of features is: img_height * img_width * num_channels\n    # We can use a function from TensorFlow to calculate this.\n    num_features = layer_shape[1:4].num_elements()\n\n    # Reshape the layer to [num_images, num_features].\n    # Note that we just set the size of the second dimension\n    # to num_features and the size of the first dimension to -1\n    # which means the size in that dimension is calculated\n    # so the total size of the tensor is unchanged from the reshaping.\n    layer_flat = tf.reshape(layer, [-1, num_features])\n\n    # The shape of the flattened layer is now:\n    # [num_images, img_height * img_width * num_channels]\n\n    # Return both the flattened layer and the number of features.\n    return layer_flat, num_features\n\n\ndef new_fc_layer(input,          # The previous layer.\n                 num_inputs,     # Num. inputs from prev. layer.\n                 num_outputs,    # Num. outputs.\n                 use_relu=True): # Use Rectified Linear Unit (ReLU)?\n\n    # Create new weights and biases.\n    weights = new_weights(shape=[num_inputs, num_outputs])\n    biases = new_biases(length=num_outputs)\n\n    # Calculate the layer as the matrix multiplication of\n    # the input and weights, and then add the bias-values.\n    layer = tf.matmul(input, weights) + biases\n\n    # Use ReLU?\n    if use_relu:\n        layer = tf.nn.relu(layer)\n\n    return layer\n\nx = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\nx_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\ny_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_true')\ny_true_cls = tf.argmax(y_true, dimension=1)\n\nlayer_conv1, weights_conv1 = \\\n    new_conv_layer(input=x_image,\n                   num_input_channels=num_channels,\n                   filter_size=filter_size1,\n                   num_filters=num_filters1,\n                   use_pooling=True)\n\nlayer_conv2, weights_conv2 = \\\n    new_conv_layer(input=layer_conv1,\n                   num_input_channels=num_filters1,\n                   filter_size=filter_size2,\n                   num_filters=num_filters2,\n                   use_pooling=True)\n\nlayer_fc1 = new_fc_layer(input=layer_flat,\n                         num_inputs=num_features,\n                         num_outputs=fc_size,\n                         use_relu=True)\n\nlayer_fc2 = new_fc_layer(input=layer_fc1,\n                         num_inputs=fc_size,\n                         num_outputs=num_classes,\n                         use_relu=False)\n\ny_pred = tf.nn.softmax(layer_fc2)\n\ny_pred_cls = tf.argmax(y_pred, dimension=1)\n\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,\n                                                        labels=y_true)\n\ncost = tf.reduce_mean(cross_entropy)\n\noptimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n\ncorrect_prediction = tf.equal(y_pred_cls, y_true_cls)\n\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\nsession = tf.Session()\n\nsession.run(tf.global_variables_initializer())\n\ntrain_batch_size = 64\n\n# Counter for total number of iterations performed so far.\ntotal_iterations = 0\n\ndef optimize(num_iterations):\n    # Ensure we update the global variable rather than a local copy.\n    global total_iterations\n\n    # Start-time used for printing time-usage below.\n    start_time = time.time()\n\n    for i in range(total_iterations,\n                   total_iterations + num_iterations):\n\n        # Get a batch of training examples.\n        # x_batch now holds a batch of images and\n        # y_true_batch are the true labels for those images.\n        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n\n        # Put the batch into a dict with the proper names\n        # for placeholder variables in the TensorFlow graph.\n        feed_dict_train = {x: x_batch,\n                           y_true: y_true_batch}\n\n        # Run the optimizer using this batch of training data.\n        # TensorFlow assigns the variables in feed_dict_train\n        # to the placeholder variables and then runs the optimizer.\n        session.run(optimizer, feed_dict=feed_dict_train)\n\n        # Print status every 100 iterations.\n        if i % 100 == 0:\n            # Calculate the accuracy on the training-set.\n            acc = session.run(accuracy, feed_dict=feed_dict_train)\n\n            # Message for printing.\n            msg = \"Optimization Iteration: {0:&gt;6}, Training Accuracy: {1:&gt;6.1%}\"\n\n            # Print it.\n            print(msg.format(i + 1, acc))\n\n    # Update the total number of iterations performed.\n    total_iterations += num_iterations\n\n    # Ending time.\n    end_time = time.time()\n\n    # Difference between start and end-times.\n    time_dif = end_time - start_time\n\n    # Print the time-usage.\n    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n\noptimize(num_iterations=900)\n\n\n\nprint_test_accuracy(show_example_errors=True)\n</code></pre>\n\n<p>In this case how to extract the features? Also, I want to know is the extracted features are different filters that we used or the final updated weights that we get after completion of CNN?</p>\n <neural-network><tensorflow><convnet><p>Before trying to extract features, you need to define your network. Suppose your network has an architecture like this:</p>\n\n<pre><code>Conv1 layer\nConv2 layer\nConv3 layer\nDense1 layer\nDense2 layer \n</code></pre>\n\n<p>Now you can extract features for each input for any layer (say for Conv2) in the following way:</p>\n\n<pre><code>conv2_tensor = sess.graph.get_tensor_by_name('Conv2')\n_, conv_val = sess.run([conv2_tensor],\n                                  {'x': image_data})\n</code></pre>\n",
                "codes": [
                    [
                        "Conv1 layer\nConv2 layer\nConv3 layer\nDense1 layer\nDense2 layer \n",
                        "conv2_tensor = sess.graph.get_tensor_by_name('Conv2')\n_, conv_val = sess.run([conv2_tensor],\n                                  {'x': image_data})\n"
                    ]
                ],
                "question_id:": "18944",
                "question_votes:": "1",
                "question_text:": "<p>As in <a href=\"https://arxiv.org/abs/1403.6382\" rel=\"nofollow noreferrer\">this</a> the author is using CNN to extract features of the images. And then doing SVM for further analysis. My question is how to extract features in CNN?</p>\n\n<p>E.g. Here is a CNN code I'm using:</p>\n\n<pre><code>%matplotlib inline\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport time\nfrom datetime import timedelta\nimport math\n\n# Convolutional Layer 1.\nfilter_size1 = 5          # Convolution filters are 5 x 5 pixels.\nnum_filters1 = 16         # There are 16 of these filters.\n\n# Convolutional Layer 2.\nfilter_size2 = 5          # Convolution filters are 5 x 5 pixels.\nnum_filters2 = 36         # There are 36 of these filters.\n\n# Fully-connected layer.\nfc_size = 128             # Number of neurons in fully-connected layer.\n\nfrom tensorflow.examples.tutorials.mnist import input_data\ndata = input_data.read_data_sets('data/MNIST/', one_hot=True)\n\ndata.test.cls = np.argmax(data.test.labels, axis=1)\n\n# We know that MNIST images are 28 pixels in each dimension.\nimg_size = 28\n\n# Images are stored in one-dimensional arrays of this length.\nimg_size_flat = img_size * img_size\n\n# Tuple with height and width of images used to reshape arrays.\nimg_shape = (img_size, img_size)\n\n# Number of colour channels for the images: 1 channel for gray-scale.\nnum_channels = 1\n\n# Number of classes, one class for each of 10 digits.\nnum_classes = 10\n\ndef new_weights(shape):\n    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n\ndef new_biases(length):\n    return tf.Variable(tf.constant(0.05, shape=[length]))\n\ndef new_conv_layer(input,              # The previous layer.\n                   num_input_channels, # Num. channels in prev. layer.\n                   filter_size,        # Width and height of each filter.\n                   num_filters,        # Number of filters.\n                   use_pooling=True):  # Use 2x2 max-pooling.\n\n    # Shape of the filter-weights for the convolution.\n    # This format is determined by the TensorFlow API.\n    shape = [filter_size, filter_size, num_input_channels, num_filters]\n\n    # Create new weights aka. filters with the given shape.\n    weights = new_weights(shape=shape)\n\n    # Create new biases, one for each filter.\n    biases = new_biases(length=num_filters)\n\n    # Create the TensorFlow operation for convolution.\n    # Note the strides are set to 1 in all dimensions.\n    # The first and last stride must always be 1,\n    # because the first is for the image-number and\n    # the last is for the input-channel.\n    # But e.g. strides=[1, 2, 2, 1] would mean that the filter\n    # is moved 2 pixels across the x- and y-axis of the image.\n    # The padding is set to 'SAME' which means the input image\n    # is padded with zeroes so the size of the output is the same.\n    layer = tf.nn.conv2d(input=input,\n                         filter=weights,\n                         strides=[1, 1, 1, 1],\n                         padding='SAME')\n\n    # Add the biases to the results of the convolution.\n    # A bias-value is added to each filter-channel.\n    layer += biases\n\n    # Use pooling to down-sample the image resolution?\n    if use_pooling:\n        # This is 2x2 max-pooling, which means that we\n        # consider 2x2 windows and select the largest value\n        # in each window. Then we move 2 pixels to the next window.\n        layer = tf.nn.max_pool(value=layer,\n                               ksize=[1, 2, 2, 1],\n                               strides=[1, 2, 2, 1],\n                               padding='SAME')\n\n    # Rectified Linear Unit (ReLU).\n    # It calculates max(x, 0) for each input pixel x.\n    # This adds some non-linearity to the formula and allows us\n    # to learn more complicated functions.\n    layer = tf.nn.relu(layer)\n\n    # Note that ReLU is normally executed before the pooling,\n    # but since relu(max_pool(x)) == max_pool(relu(x)) we can\n    # save 75% of the relu-operations by max-pooling first.\n\n    # We return both the resulting layer and the filter-weights\n    # because we will plot the weights later.\n    return layer, weights\n\ndef flatten_layer(layer):\n    # Get the shape of the input layer.\n    layer_shape = layer.get_shape()\n\n    # The shape of the input layer is assumed to be:\n    # layer_shape == [num_images, img_height, img_width, num_channels]\n\n    # The number of features is: img_height * img_width * num_channels\n    # We can use a function from TensorFlow to calculate this.\n    num_features = layer_shape[1:4].num_elements()\n\n    # Reshape the layer to [num_images, num_features].\n    # Note that we just set the size of the second dimension\n    # to num_features and the size of the first dimension to -1\n    # which means the size in that dimension is calculated\n    # so the total size of the tensor is unchanged from the reshaping.\n    layer_flat = tf.reshape(layer, [-1, num_features])\n\n    # The shape of the flattened layer is now:\n    # [num_images, img_height * img_width * num_channels]\n\n    # Return both the flattened layer and the number of features.\n    return layer_flat, num_features\n\n\ndef new_fc_layer(input,          # The previous layer.\n                 num_inputs,     # Num. inputs from prev. layer.\n                 num_outputs,    # Num. outputs.\n                 use_relu=True): # Use Rectified Linear Unit (ReLU)?\n\n    # Create new weights and biases.\n    weights = new_weights(shape=[num_inputs, num_outputs])\n    biases = new_biases(length=num_outputs)\n\n    # Calculate the layer as the matrix multiplication of\n    # the input and weights, and then add the bias-values.\n    layer = tf.matmul(input, weights) + biases\n\n    # Use ReLU?\n    if use_relu:\n        layer = tf.nn.relu(layer)\n\n    return layer\n\nx = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\nx_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\ny_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_true')\ny_true_cls = tf.argmax(y_true, dimension=1)\n\nlayer_conv1, weights_conv1 = \\\n    new_conv_layer(input=x_image,\n                   num_input_channels=num_channels,\n                   filter_size=filter_size1,\n                   num_filters=num_filters1,\n                   use_pooling=True)\n\nlayer_conv2, weights_conv2 = \\\n    new_conv_layer(input=layer_conv1,\n                   num_input_channels=num_filters1,\n                   filter_size=filter_size2,\n                   num_filters=num_filters2,\n                   use_pooling=True)\n\nlayer_fc1 = new_fc_layer(input=layer_flat,\n                         num_inputs=num_features,\n                         num_outputs=fc_size,\n                         use_relu=True)\n\nlayer_fc2 = new_fc_layer(input=layer_fc1,\n                         num_inputs=fc_size,\n                         num_outputs=num_classes,\n                         use_relu=False)\n\ny_pred = tf.nn.softmax(layer_fc2)\n\ny_pred_cls = tf.argmax(y_pred, dimension=1)\n\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,\n                                                        labels=y_true)\n\ncost = tf.reduce_mean(cross_entropy)\n\noptimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n\ncorrect_prediction = tf.equal(y_pred_cls, y_true_cls)\n\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\nsession = tf.Session()\n\nsession.run(tf.global_variables_initializer())\n\ntrain_batch_size = 64\n\n# Counter for total number of iterations performed so far.\ntotal_iterations = 0\n\ndef optimize(num_iterations):\n    # Ensure we update the global variable rather than a local copy.\n    global total_iterations\n\n    # Start-time used for printing time-usage below.\n    start_time = time.time()\n\n    for i in range(total_iterations,\n                   total_iterations + num_iterations):\n\n        # Get a batch of training examples.\n        # x_batch now holds a batch of images and\n        # y_true_batch are the true labels for those images.\n        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n\n        # Put the batch into a dict with the proper names\n        # for placeholder variables in the TensorFlow graph.\n        feed_dict_train = {x: x_batch,\n                           y_true: y_true_batch}\n\n        # Run the optimizer using this batch of training data.\n        # TensorFlow assigns the variables in feed_dict_train\n        # to the placeholder variables and then runs the optimizer.\n        session.run(optimizer, feed_dict=feed_dict_train)\n\n        # Print status every 100 iterations.\n        if i % 100 == 0:\n            # Calculate the accuracy on the training-set.\n            acc = session.run(accuracy, feed_dict=feed_dict_train)\n\n            # Message for printing.\n            msg = \"Optimization Iteration: {0:&gt;6}, Training Accuracy: {1:&gt;6.1%}\"\n\n            # Print it.\n            print(msg.format(i + 1, acc))\n\n    # Update the total number of iterations performed.\n    total_iterations += num_iterations\n\n    # Ending time.\n    end_time = time.time()\n\n    # Difference between start and end-times.\n    time_dif = end_time - start_time\n\n    # Print the time-usage.\n    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n\noptimize(num_iterations=900)\n\n\n\nprint_test_accuracy(show_example_errors=True)\n</code></pre>\n\n<p>In this case how to extract the features? Also, I want to know is the extracted features are different filters that we used or the final updated weights that we get after completion of CNN?</p>\n",
                "tags": "<neural-network><tensorflow><convnet>",
                "answers": [
                    [
                        "18945",
                        "2",
                        "18944",
                        "",
                        "",
                        "<p>Before trying to extract features, you need to define your network. Suppose your network has an architecture like this:</p>\n\n<pre><code>Conv1 layer\nConv2 layer\nConv3 layer\nDense1 layer\nDense2 layer \n</code></pre>\n\n<p>Now you can extract features for each input for any layer (say for Conv2) in the following way:</p>\n\n<pre><code>conv2_tensor = sess.graph.get_tensor_by_name('Conv2')\n_, conv_val = sess.run([conv2_tensor],\n                                  {'x': image_data})\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16526",
            "_score": 5.574483,
            "_source": {
                "title": "Reward negative derivative on linear regression",
                "content": "Reward negative derivative on linear regression <p>I'm actually new to Data Science and I'm trying to make a simple linear regression with only one feature X ( which I added the feature log(X) before adding a polynomial features) on a motley dataset using Python an all the Data Science stack that comes with it (numpy, pandas, sci-kit learn, ...) <br></p>\n\n<p>Here you can find a piece of code of my regression using scikitlearn:</p>\n\n<pre><code>def add_log(x):\n    return np.concatenate((x, np.log(x)), axis=1)\n\n # Fetch the training set\n_X = np.array(X).reshape(-1, 1) # X = [1, 26, 45, ..., 100, ..., 8000 ]\n_Y = np.array(Y).reshape(-1, 1) # Y = [1206.78, 412.4, 20.8, ..., 1.34, ..., 0.034]\nY_train = _Y\nX_train = add_log(_X) if use_log else _X\n\n# Create the pipeline\nsteps = [\n    ('scalar', StandardScaler()),\n    ('poly', PolynomialFeatures(6)),\n    ('model', Lasso(alpha=alpha, fit_intercept=True))\n]\n\n\n\npipeline = Pipeline(steps)\npipeline.fit(X_train, Y_train)\n</code></pre>\n\n<p>My feature X can go between <strong>1</strong> to <strong>~80 000</strong> and Y can go between <strong>0</strong> and <strong>~2M</strong><br></p>\n\n<p>There is one thing I know about the curve I should obtain is that it should always decrease so the derivative <strong>should be always negative</strong></p>\n\n<p>I make a little schema to explain what I expect vs what I have:\n<a href=\"https://i.stack.imgur.com/pycUG.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/pycUG.png\" alt=\"enter image description here\"></a>\nTherefore I would like to reward prediction where derivative <strong>is always negative</strong> even if my data suggest the opposite.</p>\n\n<p>Is there a way to do that with sci-kit learn?\nOr maybe I'm suggesting a bad solution to my problem and there is another way to obtain what I want ? <br></p>\n\n<p>Thank you</p>\n <scikit-learn><linear-regression><p>Its classic outlier. You could for example remove him or replace with new value(by Interpolation).\nYou have many ways to work around this problem.</p>\n\n<p>Links for you:</p>\n\n<p><a href=\"https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba\" rel=\"nofollow noreferrer\">https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba</a></p>\n\n<p>With some code:\n<a href=\"https://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623\" rel=\"nofollow noreferrer\">https://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623</a></p>\n<p>When you use linear regression you always need to define a parametric function you want to fit. So if you know that your fitted curve/line should have a negative slope, you could simply choose a linear function, such as: <code>y = b0 + b1*x + u</code> (no polys!). Judging from your figure, the slope (<code>b1</code>) should be negative. The consequence will be that you probably will not get a great fit since the function is not very flexible. But you will get an easy-to-interpret result. </p>\n\n<p>What you can do to improve performance in this case is to work on your features. You can center the features (divide by mean) or scale them (divide by 1000 or so). However, since this is a linear transformation you will not gain much from this. Another option would be to do a log-log transformation (take logs for <code>y</code> and <code>X</code>). This will give you an interpretation such as \"<em>if X increases by 1%, y changes by b1%</em>\". The advantage is that \"large\" values will become smaller, which gives a better fit on data with large(r) values. Since your data seems to be mostly positive, this could be an option. The model looks like: <code>log(y) = b0 + b1*log(x) + u</code>.</p>\n\n<p>Another approach would be to see if some of your observations are \"outliers\" and cause your estimated function to be \"wobbly\". You can - for instance - define a quadratic model such as: <code>y = b0 + b1*x + b2*x^2 + u</code>, estimate the model, and detect outliers based on Cook's distance. However, this approach seems arbitrary since you would need to remove observations until you get the desired slope. It is not a really good idea to select data until the data fit what we want to see. It may only be an option if just a few observations cause trouble (as it seems to be the case in your plot).</p>\n\n<p>Yet another possibility would be that you \"split\" your data. Here I assume that only observations in some range cause trouble (in you figure the \"low\" x's) while the rest of the observations (\"higer\" x's) follow a linear trend or so. I had exactly the same problem recently. I had a linear trend for the largest part of my x's, while only few observations had a highly non-linear pattern. I detected this using generalised additive models (GAM). Here is a tutorial for a <a href=\"https://codeburst.io/pygam-getting-started-with-generalized-additive-models-in-python-457df5b4705f\" rel=\"nofollow noreferrer\">Python implementation</a>. </p>\n\n<p>This was my result:\n<a href=\"https://i.stack.imgur.com/LFFiQ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/LFFiQ.png\" alt=\"enter image description here\"></a></p>\n\n<p>The figure shows that there is a mostly linear trend for the largest part of the data (lower 90% here). Only the upper 10% caused trouble. So I estimated a linear model, but added an interaction term to alow for a separate slope for the upper 10% of data. By doing so I got a reasonable linear estimate for the slope of the lower 90%, while avoiding a \"biased\" estimate by the \"wobbly\" upper 10%  of data. This works as follows: you generate a dummy/indicator variable which equals <code>I=1</code> for the \"wobbly\" data and <code>I=0</code> otherwise. Then you estimate a linear model like: <code>y = b0 + b1*X + b2*I + b3*I*X + u</code>. The result is that you get an extra intercept (<code>b2</code>) and slope (<code>b3</code>) for the \"wobbly\" part of the data indicated by <code>I</code>. This in turn means that you also get an extra slope for the non-wobbly part of the data (<code>b0, b1</code>).  </p>\n\n<p>Another thing: Why do you use lasso? Lasso is used to \"shrink\" features/variables. You only have one variable, so there is no need to shrink it. I would go for <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" rel=\"nofollow noreferrer\">ordinary least squares</a> (OLS), so a simple linear regression.</p>\n<p><a href=\"https://datascience.stackexchange.com/questions/18258/how-to-force-weights-to-be-non-negative-in-linear-regression\">This question</a> seems related, and I think <a href=\"https://datascience.stackexchange.com/a/19791/75152\">Adarsh's answer</a> can help you out.</p>\n\n<blockquote>\n  <p>Lasso has a parameter positive which can be set to True and force the coefficients to be positive. Further, setting the Regularization coefficient alpha to lie close to 0 makes the Lasso mimic Linear Regression with no regularization.</p>\n</blockquote>\n\n<p>In your case, you need the coefficients to be negative instead of positive.  If you flip the sign of your target value, then this becomes equivalent to forcing positive coefficients.  I think the following modification to your code would work:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def add_log(x):\n    return np.concatenate((x, np.log(x)), axis=1)\n\n# Fetch the training set\n_X = np.array(X).reshape(-1, 1) # X = [1, 26, 45, ..., 100, ..., 8000 ]\n_Y = np.array(Y).reshape(-1, 1) # Y = [1206.78, 412.4, 20.8, ..., 1.34, ..., 0.034]\n\n# flip the sign of the targets\nY_train = -1 * _Y\nX_train = add_log(_X) if use_log else _X\n\n# Create the pipeline\nsteps = [\n    ('scalar', StandardScaler()),\n    ('poly', PolynomialFeatures(6)),\n    ('model', Lasso(alpha=alpha, fit_intercept=True, positive=True))\n]\n\npipeline = Pipeline(steps)\npipeline.fit(X_train, Y_train)\n\n# Don't forget to flip the sign of your model output\n<span class=\"math-container\">```</span>\n</code></pre>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "54289",
                "question_votes:": "4",
                "question_text:": "<p>I'm actually new to Data Science and I'm trying to make a simple linear regression with only one feature X ( which I added the feature log(X) before adding a polynomial features) on a motley dataset using Python an all the Data Science stack that comes with it (numpy, pandas, sci-kit learn, ...) <br></p>\n\n<p>Here you can find a piece of code of my regression using scikitlearn:</p>\n\n<pre><code>def add_log(x):\n    return np.concatenate((x, np.log(x)), axis=1)\n\n # Fetch the training set\n_X = np.array(X).reshape(-1, 1) # X = [1, 26, 45, ..., 100, ..., 8000 ]\n_Y = np.array(Y).reshape(-1, 1) # Y = [1206.78, 412.4, 20.8, ..., 1.34, ..., 0.034]\nY_train = _Y\nX_train = add_log(_X) if use_log else _X\n\n# Create the pipeline\nsteps = [\n    ('scalar', StandardScaler()),\n    ('poly', PolynomialFeatures(6)),\n    ('model', Lasso(alpha=alpha, fit_intercept=True))\n]\n\n\n\npipeline = Pipeline(steps)\npipeline.fit(X_train, Y_train)\n</code></pre>\n\n<p>My feature X can go between <strong>1</strong> to <strong>~80 000</strong> and Y can go between <strong>0</strong> and <strong>~2M</strong><br></p>\n\n<p>There is one thing I know about the curve I should obtain is that it should always decrease so the derivative <strong>should be always negative</strong></p>\n\n<p>I make a little schema to explain what I expect vs what I have:\n<a href=\"https://i.stack.imgur.com/pycUG.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/pycUG.png\" alt=\"enter image description here\"></a>\nTherefore I would like to reward prediction where derivative <strong>is always negative</strong> even if my data suggest the opposite.</p>\n\n<p>Is there a way to do that with sci-kit learn?\nOr maybe I'm suggesting a bad solution to my problem and there is another way to obtain what I want ? <br></p>\n\n<p>Thank you</p>\n",
                "tags": "<scikit-learn><linear-regression>",
                "answers": [
                    [
                        "55295",
                        "2",
                        "54289",
                        "",
                        "",
                        "<p>Its classic outlier. You could for example remove him or replace with new value(by Interpolation).\nYou have many ways to work around this problem.</p>\n\n<p>Links for you:</p>\n\n<p><a href=\"https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba\" rel=\"nofollow noreferrer\">https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba</a></p>\n\n<p>With some code:\n<a href=\"https://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623\" rel=\"nofollow noreferrer\">https://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623</a></p>\n",
                        "",
                        "4"
                    ],
                    [
                        "55298",
                        "2",
                        "54289",
                        "",
                        "",
                        "<p>When you use linear regression you always need to define a parametric function you want to fit. So if you know that your fitted curve/line should have a negative slope, you could simply choose a linear function, such as: <code>y = b0 + b1*x + u</code> (no polys!). Judging from your figure, the slope (<code>b1</code>) should be negative. The consequence will be that you probably will not get a great fit since the function is not very flexible. But you will get an easy-to-interpret result. </p>\n\n<p>What you can do to improve performance in this case is to work on your features. You can center the features (divide by mean) or scale them (divide by 1000 or so). However, since this is a linear transformation you will not gain much from this. Another option would be to do a log-log transformation (take logs for <code>y</code> and <code>X</code>). This will give you an interpretation such as \"<em>if X increases by 1%, y changes by b1%</em>\". The advantage is that \"large\" values will become smaller, which gives a better fit on data with large(r) values. Since your data seems to be mostly positive, this could be an option. The model looks like: <code>log(y) = b0 + b1*log(x) + u</code>.</p>\n\n<p>Another approach would be to see if some of your observations are \"outliers\" and cause your estimated function to be \"wobbly\". You can - for instance - define a quadratic model such as: <code>y = b0 + b1*x + b2*x^2 + u</code>, estimate the model, and detect outliers based on Cook's distance. However, this approach seems arbitrary since you would need to remove observations until you get the desired slope. It is not a really good idea to select data until the data fit what we want to see. It may only be an option if just a few observations cause trouble (as it seems to be the case in your plot).</p>\n\n<p>Yet another possibility would be that you \"split\" your data. Here I assume that only observations in some range cause trouble (in you figure the \"low\" x's) while the rest of the observations (\"higer\" x's) follow a linear trend or so. I had exactly the same problem recently. I had a linear trend for the largest part of my x's, while only few observations had a highly non-linear pattern. I detected this using generalised additive models (GAM). Here is a tutorial for a <a href=\"https://codeburst.io/pygam-getting-started-with-generalized-additive-models-in-python-457df5b4705f\" rel=\"nofollow noreferrer\">Python implementation</a>. </p>\n\n<p>This was my result:\n<a href=\"https://i.stack.imgur.com/LFFiQ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/LFFiQ.png\" alt=\"enter image description here\"></a></p>\n\n<p>The figure shows that there is a mostly linear trend for the largest part of the data (lower 90% here). Only the upper 10% caused trouble. So I estimated a linear model, but added an interaction term to alow for a separate slope for the upper 10% of data. By doing so I got a reasonable linear estimate for the slope of the lower 90%, while avoiding a \"biased\" estimate by the \"wobbly\" upper 10%  of data. This works as follows: you generate a dummy/indicator variable which equals <code>I=1</code> for the \"wobbly\" data and <code>I=0</code> otherwise. Then you estimate a linear model like: <code>y = b0 + b1*X + b2*I + b3*I*X + u</code>. The result is that you get an extra intercept (<code>b2</code>) and slope (<code>b3</code>) for the \"wobbly\" part of the data indicated by <code>I</code>. This in turn means that you also get an extra slope for the non-wobbly part of the data (<code>b0, b1</code>).  </p>\n\n<p>Another thing: Why do you use lasso? Lasso is used to \"shrink\" features/variables. You only have one variable, so there is no need to shrink it. I would go for <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" rel=\"nofollow noreferrer\">ordinary least squares</a> (OLS), so a simple linear regression.</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "55296",
                        "2",
                        "54289",
                        "",
                        "",
                        "<p><a href=\"https://datascience.stackexchange.com/questions/18258/how-to-force-weights-to-be-non-negative-in-linear-regression\">This question</a> seems related, and I think <a href=\"https://datascience.stackexchange.com/a/19791/75152\">Adarsh's answer</a> can help you out.</p>\n\n<blockquote>\n  <p>Lasso has a parameter positive which can be set to True and force the coefficients to be positive. Further, setting the Regularization coefficient alpha to lie close to 0 makes the Lasso mimic Linear Regression with no regularization.</p>\n</blockquote>\n\n<p>In your case, you need the coefficients to be negative instead of positive.  If you flip the sign of your target value, then this becomes equivalent to forcing positive coefficients.  I think the following modification to your code would work:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def add_log(x):\n    return np.concatenate((x, np.log(x)), axis=1)\n\n# Fetch the training set\n_X = np.array(X).reshape(-1, 1) # X = [1, 26, 45, ..., 100, ..., 8000 ]\n_Y = np.array(Y).reshape(-1, 1) # Y = [1206.78, 412.4, 20.8, ..., 1.34, ..., 0.034]\n\n# flip the sign of the targets\nY_train = -1 * _Y\nX_train = add_log(_X) if use_log else _X\n\n# Create the pipeline\nsteps = [\n    ('scalar', StandardScaler()),\n    ('poly', PolynomialFeatures(6)),\n    ('model', Lasso(alpha=alpha, fit_intercept=True, positive=True))\n]\n\npipeline = Pipeline(steps)\npipeline.fit(X_train, Y_train)\n\n# Don't forget to flip the sign of your model output\n<span class=\"math-container\">```</span>\n</code></pre>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7263",
            "_score": 5.54984,
            "_source": {
                "title": "How to run a python script on GCP Compute Engine?",
                "content": "How to run a python script on GCP Compute Engine? <p>I want to run some machine learning algorithms such as PCA and KNN with a relatively large dataset of images (>2000 rgb images) in order to classify these images.</p>\n\n<p>My source code is the following:</p>\n\n<pre><code>import cv2\nimport numpy as np\nimport os\nfrom glob import glob\nfrom sklearn.decomposition import PCA\nfrom sklearn import neighbors\nfrom sklearn import preprocessing\n\n\ndata = []\n\n# Read images from file\nfor filename in glob('Images/*.jpg'):\n\n    img = cv2.imread(filename)\n    height, width = img.shape[:2]\n    img = np.array(img)\n\n    # Check that all my images are of the same resolution\n    if height == 529 and width == 940:\n\n        # Reshape each image so that it is stored in one line\n        img = np.concatenate(img, axis=0)\n        img = np.concatenate(img, axis=0)\n        data.append(img)\n\n# Normalise data\ndata = np.array(data)\nNorm = preprocessing.Normalizer()\nNorm.fit(data)\ndata = Norm.transform(data)\n\n# PCA model\npca = PCA(0.95)\npca.fit(data)\ndata = pca.transform(data)\n\n# K-Nearest neighbours\nknn = neighbors.NearestNeighbors(n_neighbors=4, algorithm='ball_tree', metric='minkowski').fit(data)\ndistances, indices = knn.kneighbors(data)\n\nprint(indices)\n</code></pre>\n\n<p>However, my laptop is not sufficient for this task as it needs many hours in order to process more than 700 rgb images. So I need to use the computational resources of an online platform (e.g. like the ones provided by GCP).</p>\n\n<p>Can I simply make a call from Pycharm to Compute Engine API (after a I have created a virtual machine in it) to run my python script?</p>\n\n<p>Or is it possible either to install PyCharm in the virtual machine and run the python script in it or to write my source code in a docker container?</p>\n\n<p>In all, how can I simply run a python script on GCP Compute Engine without wasting time in needless things?</p>\n <machine-learning><python><p>First, you will need to install Cloud SDK: <a href=\"https://cloud.google.com/sdk/downloads#apt-get\" rel=\"nofollow noreferrer\">https://cloud.google.com/sdk/downloads#apt-get</a></p>\n\n<p>Then, the simplest way is to run your script through your Terminal (mac and I presume the instructions also work on Linux):</p>\n\n<ol>\n<li>Configure your project: gcloud config set project insert_your_project_name</li>\n<li>Set up SSH keys: gcloud compute config-ssh</li>\n<li>Connect to the VM: gcloud beta compute ssh vm_name --internal-ip</li>\n<li>Run script: python your_script.py</li>\n</ol>\n\n<p>You can also connect PyCharm directly to GCP and run everything on your VM but you will need PyCharm Pro, otherwise the deployment option is not available. Let me know if this works.</p>\n\n<p>Also, if you want to use the interactive version of setting your project then in step 1 do this instead: gcloud init</p>\n<p>The other option is to setup jupyter notebook on GCP. You can use the following command to run jupyter notebook in background.</p>\n\n<pre><code>nohup jupyter notebpook --ip=0.0.0.0 &amp;\n</code></pre>\n\n<p>Now you can do tunneling by doing an ssh into GCP:</p>\n\n<pre><code>ssh username@&lt;public_ip&gt; -L 8888:127.0.0.1:8888\n</code></pre>\n\n<p>Now you should be able to access jupyter notebook from your local machine with the following url in the browser</p>\n\n<pre><code>127.0.0.1:8888\n</code></pre>\n",
                "codes": [
                    [],
                    [
                        "nohup jupyter notebpook --ip=0.0.0.0 &\n",
                        "ssh username@<public_ip> -L 8888:127.0.0.1:8888\n",
                        "127.0.0.1:8888\n"
                    ]
                ],
                "question_id:": "27352",
                "question_votes:": "2",
                "question_text:": "<p>I want to run some machine learning algorithms such as PCA and KNN with a relatively large dataset of images (>2000 rgb images) in order to classify these images.</p>\n\n<p>My source code is the following:</p>\n\n<pre><code>import cv2\nimport numpy as np\nimport os\nfrom glob import glob\nfrom sklearn.decomposition import PCA\nfrom sklearn import neighbors\nfrom sklearn import preprocessing\n\n\ndata = []\n\n# Read images from file\nfor filename in glob('Images/*.jpg'):\n\n    img = cv2.imread(filename)\n    height, width = img.shape[:2]\n    img = np.array(img)\n\n    # Check that all my images are of the same resolution\n    if height == 529 and width == 940:\n\n        # Reshape each image so that it is stored in one line\n        img = np.concatenate(img, axis=0)\n        img = np.concatenate(img, axis=0)\n        data.append(img)\n\n# Normalise data\ndata = np.array(data)\nNorm = preprocessing.Normalizer()\nNorm.fit(data)\ndata = Norm.transform(data)\n\n# PCA model\npca = PCA(0.95)\npca.fit(data)\ndata = pca.transform(data)\n\n# K-Nearest neighbours\nknn = neighbors.NearestNeighbors(n_neighbors=4, algorithm='ball_tree', metric='minkowski').fit(data)\ndistances, indices = knn.kneighbors(data)\n\nprint(indices)\n</code></pre>\n\n<p>However, my laptop is not sufficient for this task as it needs many hours in order to process more than 700 rgb images. So I need to use the computational resources of an online platform (e.g. like the ones provided by GCP).</p>\n\n<p>Can I simply make a call from Pycharm to Compute Engine API (after a I have created a virtual machine in it) to run my python script?</p>\n\n<p>Or is it possible either to install PyCharm in the virtual machine and run the python script in it or to write my source code in a docker container?</p>\n\n<p>In all, how can I simply run a python script on GCP Compute Engine without wasting time in needless things?</p>\n",
                "tags": "<machine-learning><python>",
                "answers": [
                    [
                        "27353",
                        "2",
                        "27352",
                        "",
                        "",
                        "<p>First, you will need to install Cloud SDK: <a href=\"https://cloud.google.com/sdk/downloads#apt-get\" rel=\"nofollow noreferrer\">https://cloud.google.com/sdk/downloads#apt-get</a></p>\n\n<p>Then, the simplest way is to run your script through your Terminal (mac and I presume the instructions also work on Linux):</p>\n\n<ol>\n<li>Configure your project: gcloud config set project insert_your_project_name</li>\n<li>Set up SSH keys: gcloud compute config-ssh</li>\n<li>Connect to the VM: gcloud beta compute ssh vm_name --internal-ip</li>\n<li>Run script: python your_script.py</li>\n</ol>\n\n<p>You can also connect PyCharm directly to GCP and run everything on your VM but you will need PyCharm Pro, otherwise the deployment option is not available. Let me know if this works.</p>\n\n<p>Also, if you want to use the interactive version of setting your project then in step 1 do this instead: gcloud init</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "27374",
                        "2",
                        "27352",
                        "",
                        "",
                        "<p>The other option is to setup jupyter notebook on GCP. You can use the following command to run jupyter notebook in background.</p>\n\n<pre><code>nohup jupyter notebpook --ip=0.0.0.0 &amp;\n</code></pre>\n\n<p>Now you can do tunneling by doing an ssh into GCP:</p>\n\n<pre><code>ssh username@&lt;public_ip&gt; -L 8888:127.0.0.1:8888\n</code></pre>\n\n<p>Now you should be able to access jupyter notebook from your local machine with the following url in the browser</p>\n\n<pre><code>127.0.0.1:8888\n</code></pre>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12221",
            "_score": 5.54984,
            "_source": {
                "title": "error while running lasso.py",
                "content": "error while running lasso.py <p>The following is the error code generated while running lasso.py.\nCan anybody help in fixing the same. </p>\n\n<p>Here is the code: </p>\n\n<pre><code>from cvxpy import *\nimport numpy as np\nimport cvxopt\nfrom multiprocessing import Pool\n\n# Problem data.\nn = 10\nm = 5\nA = cvxopt.normal(n,m)\nb = cvxopt.normal(n)\ngamma = Parameter(nonneg=True)\n\n# Construct the problem.\nx = Variable(m)\nobjective = Minimize(sum_squares(A*x - b) + gamma*norm(x, 1))\np = Problem(objective)\n\n# Assign a value to gamma and find the optimal x.\ndef get_x(gamma_value):\n    gamma.value = gamma_value\n    result = p.solve()\n    return x.value\n\ngammas = np.logspace(-1, 2, num=100)\n# Serial computation.\nx_values = [get_x(value) for value in gammas]\n\n# Parallel computation.\npool = Pool(processes = 4)\npar_x = pool.map(get_x, gammas)\n\nfor v1,v2 in zip(x_values, par_x):\n    if np.linalg.norm(v1 - v2) &gt; 1e-5:\n        print(\"error\")\n</code></pre>\n\n<p>Error: while running</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"lasso.py\", line 31, in &lt;module&gt;\n    objective = Minimize(sum_squares(A*x - b) + gamma*norm(x, 1))\n  File \"/usr/local/lib/python3.5/dist-packages/cvxpy-1.0.11-py3.5-linux-x86_64.egg/cvxpy/expressions/expression.py\", line 45, in cast_op\n    return binary_op(self, other)\n  File \"/usr/local/lib/python3.5/dist-packages/cvxpy-1.0.11-py3.5-linux-x86_64.egg/cvxpy/expressions/expression.py\", line 435, in __sub__\n    return self + -other\n  File \"/usr/local/lib/python3.5/dist-packages/cvxpy-1.0.11-py3.5-linux-x86_64.egg/cvxpy/expressions/expression.py\", line 45, in cast_op\n    return binary_op(self, other)\n  File \"/usr/local/lib/python3.5/dist-packages/cvxpy-1.0.11-py3.5-linux-x86_64.egg/cvxpy/expressions/expression.py\", line 423, in __add__\n    return cvxtypes.add_expr()([self, other])\n  File \"/usr/local/lib/python3.5/dist-packages/cvxpy-1.0.11-py3.5-linux-x86_64.egg/cvxpy/atoms/affine/add_expr.py\", line 33, in __init__\n    super(AddExpression, self).__init__(*arg_groups)\n  File \"/usr/local/lib/python3.5/dist-packages/cvxpy-1.0.11-py3.5-linux-x86_64.egg/cvxpy/atoms/atom.py\", line 41, in __init__\n    self._shape = self.shape_from_args()\n  File \"/usr/local/lib/python3.5/dist-packages/cvxpy-1.0.11-py3.5-linux-x86_64.egg/cvxpy/atoms/affine/add_expr.py\", line 41, in shape_from_args\n    return u.shape.sum_shapes([arg.shape for arg in self.args])\n  File \"/usr/local/lib/python3.5/dist-packages/cvxpy-1.0.11-py3.5-linux-x86_64.egg/cvxpy/utilities/shape.py\", line 49, in sum_shapes\n    len(shapes)*\" %s\" % tuple(shapes))\nValueError: Cannot broadcast dimensions  (10,) (10, 1)\n</code></pre>\n\n<p>As suggested by multiple links, I tried with all possible python and library versions. But I am unable to fix this. Kindly throw some light. </p>\n <python><classification><optimization><data-science-model><anaconda><p>(A*x)  Expression has dimensionality of (10, ) and b has shape of ( 10, 1) - this is why you see this error. </p>\n\n<p>My fix solves the error, but you should double check the results</p>\n\n<pre><code>objective = Minimize(sum_squares(A*x - np.array(b).reshape(10,)) + gamma*norm(x, 1))\n</code></pre>\n\n<p>Hope this helps!</p>\n",
                "codes": [
                    [
                        "objective = Minimize(sum_squares(A*x - np.array(b).reshape(10,)) + gamma*norm(x, 1))\n"
                    ]
                ],
                "question_id:": "42993",
                "question_votes:": "",
                "question_text:": "<p>The following is the error code generated while running lasso.py.\nCan anybody help in fixing the same. </p>\n\n<p>Here is the code: </p>\n\n<pre><code>from cvxpy import *\nimport numpy as np\nimport cvxopt\nfrom multiprocessing import Pool\n\n# Problem data.\nn = 10\nm = 5\nA = cvxopt.normal(n,m)\nb = cvxopt.normal(n)\ngamma = Parameter(nonneg=True)\n\n# Construct the problem.\nx = Variable(m)\nobjective = Minimize(sum_squares(A*x - b) + gamma*norm(x, 1))\np = Problem(objective)\n\n# Assign a value to gamma and find the optimal x.\ndef get_x(gamma_value):\n    gamma.value = gamma_value\n    result = p.solve()\n    return x.value\n\ngammas = np.logspace(-1, 2, num=100)\n# Serial computation.\nx_values = [get_x(value) for value in gammas]\n\n# Parallel computation.\npool = Pool(processes = 4)\npar_x = pool.map(get_x, gammas)\n\nfor v1,v2 in zip(x_values, par_x):\n    if np.linalg.norm(v1 - v2) &gt; 1e-5:\n        print(\"error\")\n</code></pre>\n\n<p>Error: while running</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"lasso.py\", line 31, in &lt;module&gt;\n    objective = Minimize(sum_squares(A*x - b) + gamma*norm(x, 1))\n  File \"/usr/local/lib/python3.5/dist-packages/cvxpy-1.0.11-py3.5-linux-x86_64.egg/cvxpy/expressions/expression.py\", line 45, in cast_op\n    return binary_op(self, other)\n  File \"/usr/local/lib/python3.5/dist-packages/cvxpy-1.0.11-py3.5-linux-x86_64.egg/cvxpy/expressions/expression.py\", line 435, in __sub__\n    return self + -other\n  File \"/usr/local/lib/python3.5/dist-packages/cvxpy-1.0.11-py3.5-linux-x86_64.egg/cvxpy/expressions/expression.py\", line 45, in cast_op\n    return binary_op(self, other)\n  File \"/usr/local/lib/python3.5/dist-packages/cvxpy-1.0.11-py3.5-linux-x86_64.egg/cvxpy/expressions/expression.py\", line 423, in __add__\n    return cvxtypes.add_expr()([self, other])\n  File \"/usr/local/lib/python3.5/dist-packages/cvxpy-1.0.11-py3.5-linux-x86_64.egg/cvxpy/atoms/affine/add_expr.py\", line 33, in __init__\n    super(AddExpression, self).__init__(*arg_groups)\n  File \"/usr/local/lib/python3.5/dist-packages/cvxpy-1.0.11-py3.5-linux-x86_64.egg/cvxpy/atoms/atom.py\", line 41, in __init__\n    self._shape = self.shape_from_args()\n  File \"/usr/local/lib/python3.5/dist-packages/cvxpy-1.0.11-py3.5-linux-x86_64.egg/cvxpy/atoms/affine/add_expr.py\", line 41, in shape_from_args\n    return u.shape.sum_shapes([arg.shape for arg in self.args])\n  File \"/usr/local/lib/python3.5/dist-packages/cvxpy-1.0.11-py3.5-linux-x86_64.egg/cvxpy/utilities/shape.py\", line 49, in sum_shapes\n    len(shapes)*\" %s\" % tuple(shapes))\nValueError: Cannot broadcast dimensions  (10,) (10, 1)\n</code></pre>\n\n<p>As suggested by multiple links, I tried with all possible python and library versions. But I am unable to fix this. Kindly throw some light. </p>\n",
                "tags": "<python><classification><optimization><data-science-model><anaconda>",
                "answers": [
                    [
                        "42997",
                        "2",
                        "42993",
                        "",
                        "",
                        "<p>(A*x)  Expression has dimensionality of (10, ) and b has shape of ( 10, 1) - this is why you see this error. </p>\n\n<p>My fix solves the error, but you should double check the results</p>\n\n<pre><code>objective = Minimize(sum_squares(A*x - np.array(b).reshape(10,)) + gamma*norm(x, 1))\n</code></pre>\n\n<p>Hope this helps!</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13323",
            "_score": 5.54984,
            "_source": {
                "title": "How can positional encodings including a sine operation be linearly transformable for any offset?",
                "content": "How can positional encodings including a sine operation be linearly transformable for any offset? <p>In the paper <a href=\"https://arxiv.org/pdf/1706.03762.pdf\" rel=\"nofollow noreferrer\">\"Attention is all you need\"</a> the authors add a positional encoding to each token in the sequence (section 3.5). The following encoding is chosen:</p>\n\n<p><span class=\"math-container\">$ PE(pos, 2dim) = sin(pos / 10000 ^ {2dim/d_{model}} ) $</span></p>\n\n<p><span class=\"math-container\">$ PE(pos, 2dim+1) = cos(pos / 10000 ^ {2dim/d_{model}} ) $</span></p>\n\n<p>The text states that \"for any fixed offset <span class=\"math-container\">$k$</span>, <span class=\"math-container\">$PE(pos+k)$</span> can be represented as a linear function of <span class=\"math-container\">$PE(pos)$</span>\". This did not seem obvious due to me due to the nonlinearity of the sine function. Other resources like <a href=\"http://mlexplained.com/2017/12/29/attention-is-all-you-need-explained/\" rel=\"nofollow noreferrer\">Attention is all you need Explained</a> mention this property but do not go deeper into it.</p>\n\n<p>I decided to experiment with this by attempting to map a number of outputs from the <span class=\"math-container\">$PE(pos)$</span> function to outputs with a given offset <span class=\"math-container\">$k$</span>. </p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef PE_even(pos, dim):\n    \"\"\" This corresponds to the 2dim state. \"\"\"\n    size = 10000\n    d_Model = 512\n    return np.sin(pos / (size ** (2 * dim / d_Model)))\n\npositions = pd.Series(np.arange(0, 1000))\n\nk = 10\na = positions.apply(lambda p: PE_even(p, 64))\nb = positions.apply(lambda p: PE_even(p + k, 64))\n\nX = a.values.reshape(-1, 1)\ny = b.values\nr = LinearRegression()\nr.fit(X, y)\nr.score(X, y)\n</code></pre>\n\n<p>However, no offset nor any range of numbers in these dimensions yields a suitable fit. As <span class=\"math-container\">$k$</span> increases and the sine waves resulting from the <span class=\"math-container\">$PE(pos)$</span> function get out of sync, the correlation of the transformation and the truth decreases. Even using simple neural networks with and without linearities does not yield a good fit. </p>\n\n<p>Did I misapprehend the statement in the paper, or is my code or understanding of the underlying math here faulty?</p>\n <machine-learning><math><linear-algebra><p>I elected to ask this question on the Mathematics Stack Exchange and I thought it prudent to add the answer here:</p>\n\n<p><a href=\"https://math.stackexchange.com/q/3119882\">https://math.stackexchange.com/q/3119882</a></p>\n\n<p>From what I have learned from <a href=\"https://math.stackexchange.com/users/30382/servaes\">@Servaes</a>, who was kind enough to answer the question, there is a function </p>\n\n<p><span class=\"math-container\">$\\operatorname{PE}(\\text{pos}+k,2d)=\\operatorname{PE}(\\text{pos},2d)\\cos(k/c^d)+\\operatorname{PE}(\\text{pos},2d+1)\\sin(k/c^d)$</span></p>\n\n<p>that allows for the property of transforming any positional encoding into one with a given offset. However, due to the required use of the sin() and cos() functions this is not a linear transformation. </p>\n",
                "codes": [
                    []
                ],
                "question_id:": "45691",
                "question_votes:": "1",
                "question_text:": "<p>In the paper <a href=\"https://arxiv.org/pdf/1706.03762.pdf\" rel=\"nofollow noreferrer\">\"Attention is all you need\"</a> the authors add a positional encoding to each token in the sequence (section 3.5). The following encoding is chosen:</p>\n\n<p><span class=\"math-container\">$ PE(pos, 2dim) = sin(pos / 10000 ^ {2dim/d_{model}} ) $</span></p>\n\n<p><span class=\"math-container\">$ PE(pos, 2dim+1) = cos(pos / 10000 ^ {2dim/d_{model}} ) $</span></p>\n\n<p>The text states that \"for any fixed offset <span class=\"math-container\">$k$</span>, <span class=\"math-container\">$PE(pos+k)$</span> can be represented as a linear function of <span class=\"math-container\">$PE(pos)$</span>\". This did not seem obvious due to me due to the nonlinearity of the sine function. Other resources like <a href=\"http://mlexplained.com/2017/12/29/attention-is-all-you-need-explained/\" rel=\"nofollow noreferrer\">Attention is all you need Explained</a> mention this property but do not go deeper into it.</p>\n\n<p>I decided to experiment with this by attempting to map a number of outputs from the <span class=\"math-container\">$PE(pos)$</span> function to outputs with a given offset <span class=\"math-container\">$k$</span>. </p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef PE_even(pos, dim):\n    \"\"\" This corresponds to the 2dim state. \"\"\"\n    size = 10000\n    d_Model = 512\n    return np.sin(pos / (size ** (2 * dim / d_Model)))\n\npositions = pd.Series(np.arange(0, 1000))\n\nk = 10\na = positions.apply(lambda p: PE_even(p, 64))\nb = positions.apply(lambda p: PE_even(p + k, 64))\n\nX = a.values.reshape(-1, 1)\ny = b.values\nr = LinearRegression()\nr.fit(X, y)\nr.score(X, y)\n</code></pre>\n\n<p>However, no offset nor any range of numbers in these dimensions yields a suitable fit. As <span class=\"math-container\">$k$</span> increases and the sine waves resulting from the <span class=\"math-container\">$PE(pos)$</span> function get out of sync, the correlation of the transformation and the truth decreases. Even using simple neural networks with and without linearities does not yield a good fit. </p>\n\n<p>Did I misapprehend the statement in the paper, or is my code or understanding of the underlying math here faulty?</p>\n",
                "tags": "<machine-learning><math><linear-algebra>",
                "answers": [
                    [
                        "46008",
                        "2",
                        "45691",
                        "",
                        "",
                        "<p>I elected to ask this question on the Mathematics Stack Exchange and I thought it prudent to add the answer here:</p>\n\n<p><a href=\"https://math.stackexchange.com/q/3119882\">https://math.stackexchange.com/q/3119882</a></p>\n\n<p>From what I have learned from <a href=\"https://math.stackexchange.com/users/30382/servaes\">@Servaes</a>, who was kind enough to answer the question, there is a function </p>\n\n<p><span class=\"math-container\">$\\operatorname{PE}(\\text{pos}+k,2d)=\\operatorname{PE}(\\text{pos},2d)\\cos(k/c^d)+\\operatorname{PE}(\\text{pos},2d+1)\\sin(k/c^d)$</span></p>\n\n<p>that allows for the property of transforming any positional encoding into one with a given offset. However, due to the required use of the sin() and cos() functions this is not a linear transformation. </p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14931",
            "_score": 5.54984,
            "_source": {
                "title": "Why the loss is nan by using linear activation function in the last layer?",
                "content": "Why the loss is nan by using linear activation function in the last layer? <p>I want to use neural network to solve a simple regression problem, and I try to program by myself accroding to lecture <a href=\"http://cs231n.stanford.edu/slides/2016/winter1516_lecture4.pdf\" rel=\"nofollow noreferrer\">Backpropagation and Neural Networks </a>.\nHowever, I meet loss divergence problem.</p>\n\n<p>My neural network can be descried as:</p>\n\n<p><span class=\"math-container\">$l_{1}=\\frac{1}{1+e^{-(W_0 x + b_0)}}$</span></p>\n\n<p><span class=\"math-container\">$l_{2}={W_1 l_1 + b_1}$</span></p>\n\n<p>And loss is:</p>\n\n<p><span class=\"math-container\">$loss = {(y-l_2)^T(y - l_2)}$</span></p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(1)\nx_pre = 2*np.random.normal(size = (1000,1))\ny = x_pre**2 + -0.2*np.cos(3*np.pi*x_pre) \ny = y.reshape(y.shape[0],1)\n\ndef standard(data):\n    mu = np.mean(data)\n    std = np.var(data)\n    return (data - mu)/std\nx = standard(x_pre)\n\nndim = 10\nw0 = 2*np.random.random((1,ndim))-1\nw1 = 2*np.random.random((ndim,1))-1\nnp.random.seed(10)\nb0 = np.random.normal(size = (1000,ndim))\nb1 = np.random.normal(size = (1000,1))\nlr = 1\nfor j in range(4):\n    l1 = 1/(1+ np.exp(-(np.dot(x,w0)+ b0))) \n    l2 = np.dot(l1,w1)+ b1#1/(1+ np.exp(-(np.dot(l1,w1)+ b1)))\n    l2_delta= np.mean(y - l2)*2*(y-l2)#mse\n    l1_delta = l2_delta.dot(w1.T)*(l1*(1-l1))\n    w1 += lr*l1.T.dot(l2_delta)\n    w0 += lr*x.T.dot(l1_delta)\n    b0 += lr* l1_delta\n    b1 += lr*l2_delta\n    print('loss',np.mean(y - l2))\nl1 = 1/(1+ np.exp(-(np.dot(x,w0))))\nl2 = 1/(1+ np.exp(-np.dot(l1,w1)))\ny_hap =  l2\n\nprint(np.sum(np.square(y-y_hap)))\nplt.plot(np.arange(len(y)),y,'r')\nplt.plot(np.arange(len(y_hap)),y_hap,'g')\nplt.show()\n</code></pre>\n\n<p>output result:</p>\n\n<pre><code>loss 3.485080512494127\nloss -30525.316587393125\nloss -3293457250652.145\nloss -5.777133209515429e+28\n</code></pre>\n\n<p>Anyone knows how to solve it?</p>\n <deep-learning><python><p>There seem a lot of initialization problems.</p>\n\n<ol>\n<li>There ain't too many biases. Its just 1 per layer. Your shape of\nbiases seems wrong.</li>\n<li><p>You may have got the network right in shapes since it doesn't return shape errors. But bear in mind, it seems highly likely #1 is\ntrue.</p></li>\n<li><p>Same goes to w0 and w1.</p></li>\n</ol>\n\n<p>Consider checking all dims again. If you need, I'm attaching a sample Neural Network implementation in python.</p>\n\n<p><a href=\"https://raw.githubusercontent.com/MasterSkepticista/NEAT_py/master/network.py\" rel=\"nofollow noreferrer\">https://raw.githubusercontent.com/MasterSkepticista/NEAT_py/master/network.py</a></p>\n\n<p>This is as it happens to be taught in Andrew Ng's course. </p>\n",
                "codes": [
                    []
                ],
                "question_id:": "49802",
                "question_votes:": "1",
                "question_text:": "<p>I want to use neural network to solve a simple regression problem, and I try to program by myself accroding to lecture <a href=\"http://cs231n.stanford.edu/slides/2016/winter1516_lecture4.pdf\" rel=\"nofollow noreferrer\">Backpropagation and Neural Networks </a>.\nHowever, I meet loss divergence problem.</p>\n\n<p>My neural network can be descried as:</p>\n\n<p><span class=\"math-container\">$l_{1}=\\frac{1}{1+e^{-(W_0 x + b_0)}}$</span></p>\n\n<p><span class=\"math-container\">$l_{2}={W_1 l_1 + b_1}$</span></p>\n\n<p>And loss is:</p>\n\n<p><span class=\"math-container\">$loss = {(y-l_2)^T(y - l_2)}$</span></p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(1)\nx_pre = 2*np.random.normal(size = (1000,1))\ny = x_pre**2 + -0.2*np.cos(3*np.pi*x_pre) \ny = y.reshape(y.shape[0],1)\n\ndef standard(data):\n    mu = np.mean(data)\n    std = np.var(data)\n    return (data - mu)/std\nx = standard(x_pre)\n\nndim = 10\nw0 = 2*np.random.random((1,ndim))-1\nw1 = 2*np.random.random((ndim,1))-1\nnp.random.seed(10)\nb0 = np.random.normal(size = (1000,ndim))\nb1 = np.random.normal(size = (1000,1))\nlr = 1\nfor j in range(4):\n    l1 = 1/(1+ np.exp(-(np.dot(x,w0)+ b0))) \n    l2 = np.dot(l1,w1)+ b1#1/(1+ np.exp(-(np.dot(l1,w1)+ b1)))\n    l2_delta= np.mean(y - l2)*2*(y-l2)#mse\n    l1_delta = l2_delta.dot(w1.T)*(l1*(1-l1))\n    w1 += lr*l1.T.dot(l2_delta)\n    w0 += lr*x.T.dot(l1_delta)\n    b0 += lr* l1_delta\n    b1 += lr*l2_delta\n    print('loss',np.mean(y - l2))\nl1 = 1/(1+ np.exp(-(np.dot(x,w0))))\nl2 = 1/(1+ np.exp(-np.dot(l1,w1)))\ny_hap =  l2\n\nprint(np.sum(np.square(y-y_hap)))\nplt.plot(np.arange(len(y)),y,'r')\nplt.plot(np.arange(len(y_hap)),y_hap,'g')\nplt.show()\n</code></pre>\n\n<p>output result:</p>\n\n<pre><code>loss 3.485080512494127\nloss -30525.316587393125\nloss -3293457250652.145\nloss -5.777133209515429e+28\n</code></pre>\n\n<p>Anyone knows how to solve it?</p>\n",
                "tags": "<deep-learning><python>",
                "answers": [
                    [
                        "49803",
                        "2",
                        "49802",
                        "",
                        "",
                        "<p>There seem a lot of initialization problems.</p>\n\n<ol>\n<li>There ain't too many biases. Its just 1 per layer. Your shape of\nbiases seems wrong.</li>\n<li><p>You may have got the network right in shapes since it doesn't return shape errors. But bear in mind, it seems highly likely #1 is\ntrue.</p></li>\n<li><p>Same goes to w0 and w1.</p></li>\n</ol>\n\n<p>Consider checking all dims again. If you need, I'm attaching a sample Neural Network implementation in python.</p>\n\n<p><a href=\"https://raw.githubusercontent.com/MasterSkepticista/NEAT_py/master/network.py\" rel=\"nofollow noreferrer\">https://raw.githubusercontent.com/MasterSkepticista/NEAT_py/master/network.py</a></p>\n\n<p>This is as it happens to be taught in Andrew Ng's course. </p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15485",
            "_score": 5.54984,
            "_source": {
                "title": "Long-term Recurrent Convolutional Networks (Keras) for Game Bot",
                "content": "Long-term Recurrent Convolutional Networks (Keras) for Game Bot <p>I want to use CNN and LSTM to make a Game Bot. Basic idea is to capture 32 frames of gameplay, and then, for that sequence, predict an output. My gamebot is more like a self driving car. Capturing the road, and deciding whether to drive straight, left or right.</p>\n\n<p>Shape of my input data, (numpy array):\n<code>(1000, 32, 56, 86, 1)</code></p>\n\n<p>1000 is the total number of sequences. 32 is the sequence length. (56, 86) corresponds to (row, col) and 1 represent the channel (grayscale).</p>\n\n<p>Each label is of the form\n<code>[0, 0, 1]</code> one-hot encoded lists.</p>\n\n<p>I have the data saved as <code>.npy</code> files. </p>\n\n<p>20 .npy files each of which have <code>[[seq of frames], label for the seq]</code>)</p>\n\n<p><a href=\"https://i.stack.imgur.com/Dg1JE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Dg1JE.png\" alt=\"LRCN\"></a></p>\n\n<p>The above image was taken from this paper: <a href=\"https://arxiv.org/pdf/1411.4389v3.pdf\" rel=\"nofollow noreferrer\">Link to paper (.pdf)</a></p>\n\n<p>Activity Recognition is exactly what I want to do! I don't know how to though. I can't simply load in all my data, it gives me a memory error.</p>\n\n<p>I did come up with the idea of using a generator.</p>\n\n<pre><code>def generate_batches(files, batch_size):\n\n    counter = 0\n\n    while True:\n        fname = files[counter]\n        print(fname)\n\n        counter = (counter + 1) % len(files)\n        data_bundle = np.load(fname)\n        train_x = []\n        train_y = []\n\n        for images, label in data_bundle:\n            train_x.append(images / 255.0)\n            train_y.append(label)\n\n        train_x = np.array(train_x)\n        train_x = train_x.reshape(train_x.shape[0],\n                                  train_x.shape[1],\n                                  train_x.shape[2],\n                                  train_x.shape[3],\n                                  1)\n\n        train_y = np.array(train_y)\n\n        for cbatch in range(0, train_x.shape[0], batch_size):\n            yield (train_x[cbatch: (cbatch + batch_size), :, :],\n                   train_y[cbatch: (cbatch + batch_size)])\n\n</code></pre>\n\n<p>I'm not sure of the architecture of the network to use. CNN wants one image as input, but LSTM requires the sequence. How do I build a model which would do that? </p>\n\n<p>Model I built so far, that gave me no success.</p>\n\n<pre><code>train_files = []\n\nfor i in range(1, 21):\n    filename = f'Balanced_data/training_data_{i}_sequential_balanced.npy'\n    train_files.append(filename)\n\ngen = generate_batches(train_files, 32)\n\nmodel = Sequential()\n\nmodel.add(InputLayer(input_shape=(32, 56, 86, 1)))\n\nmodel.add(Conv2D(16, (3, 3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(8))\n\nmodel.add(LSTM(8, return_sequences=True))\n\nmodel.add(Dense(3))\n\nmodel.add(GlobalAveragePooling1D())\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',\n              metrics=['accuracy'])\n\nprint(model.summary())\n\nhistory = model.fit_generator(generator=gen, steps_per_epoch=982, epochs=2,  # 31404 total no of sequences divided by 32 batch size, 982\n                              verbose=1)\n</code></pre>\n\n<p>I'm sure there is a better way to build the model. Also, I'm not very sure about the code for <code>generator</code> and the <code>fit_generator</code> line. And usually, I would use <code>sklearn.model_selection.train_test_split</code>  Can I do something like that with the generator too??</p>\n <neural-network><keras><tensorflow><cnn><lstm>",
                "codes": [],
                "question_id:": "52003",
                "question_votes:": "",
                "question_text:": "<p>I want to use CNN and LSTM to make a Game Bot. Basic idea is to capture 32 frames of gameplay, and then, for that sequence, predict an output. My gamebot is more like a self driving car. Capturing the road, and deciding whether to drive straight, left or right.</p>\n\n<p>Shape of my input data, (numpy array):\n<code>(1000, 32, 56, 86, 1)</code></p>\n\n<p>1000 is the total number of sequences. 32 is the sequence length. (56, 86) corresponds to (row, col) and 1 represent the channel (grayscale).</p>\n\n<p>Each label is of the form\n<code>[0, 0, 1]</code> one-hot encoded lists.</p>\n\n<p>I have the data saved as <code>.npy</code> files. </p>\n\n<p>20 .npy files each of which have <code>[[seq of frames], label for the seq]</code>)</p>\n\n<p><a href=\"https://i.stack.imgur.com/Dg1JE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Dg1JE.png\" alt=\"LRCN\"></a></p>\n\n<p>The above image was taken from this paper: <a href=\"https://arxiv.org/pdf/1411.4389v3.pdf\" rel=\"nofollow noreferrer\">Link to paper (.pdf)</a></p>\n\n<p>Activity Recognition is exactly what I want to do! I don't know how to though. I can't simply load in all my data, it gives me a memory error.</p>\n\n<p>I did come up with the idea of using a generator.</p>\n\n<pre><code>def generate_batches(files, batch_size):\n\n    counter = 0\n\n    while True:\n        fname = files[counter]\n        print(fname)\n\n        counter = (counter + 1) % len(files)\n        data_bundle = np.load(fname)\n        train_x = []\n        train_y = []\n\n        for images, label in data_bundle:\n            train_x.append(images / 255.0)\n            train_y.append(label)\n\n        train_x = np.array(train_x)\n        train_x = train_x.reshape(train_x.shape[0],\n                                  train_x.shape[1],\n                                  train_x.shape[2],\n                                  train_x.shape[3],\n                                  1)\n\n        train_y = np.array(train_y)\n\n        for cbatch in range(0, train_x.shape[0], batch_size):\n            yield (train_x[cbatch: (cbatch + batch_size), :, :],\n                   train_y[cbatch: (cbatch + batch_size)])\n\n</code></pre>\n\n<p>I'm not sure of the architecture of the network to use. CNN wants one image as input, but LSTM requires the sequence. How do I build a model which would do that? </p>\n\n<p>Model I built so far, that gave me no success.</p>\n\n<pre><code>train_files = []\n\nfor i in range(1, 21):\n    filename = f'Balanced_data/training_data_{i}_sequential_balanced.npy'\n    train_files.append(filename)\n\ngen = generate_batches(train_files, 32)\n\nmodel = Sequential()\n\nmodel.add(InputLayer(input_shape=(32, 56, 86, 1)))\n\nmodel.add(Conv2D(16, (3, 3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(8))\n\nmodel.add(LSTM(8, return_sequences=True))\n\nmodel.add(Dense(3))\n\nmodel.add(GlobalAveragePooling1D())\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',\n              metrics=['accuracy'])\n\nprint(model.summary())\n\nhistory = model.fit_generator(generator=gen, steps_per_epoch=982, epochs=2,  # 31404 total no of sequences divided by 32 batch size, 982\n                              verbose=1)\n</code></pre>\n\n<p>I'm sure there is a better way to build the model. Also, I'm not very sure about the code for <code>generator</code> and the <code>fit_generator</code> line. And usually, I would use <code>sklearn.model_selection.train_test_split</code>  Can I do something like that with the generator too??</p>\n",
                "tags": "<neural-network><keras><tensorflow><cnn><lstm>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7004",
            "_score": 5.548531,
            "_source": {
                "title": "Why does TFLearn DCGAN not run on my GPU (on Windows)?",
                "content": "Why does TFLearn DCGAN not run on my GPU (on Windows)? <p>I have collected the <a href=\"https://github.com/tflearn/tflearn/blob/master/examples/images/dcgan.py\" rel=\"nofollow noreferrer\">TFLearn DCGAN example</a> code and put it into my local Jupyter environment. Furthermore, I have changed some comments and added <code>with tf.device('/gpu:0'):</code> right before calling <code>gan.fit(...)</code>, resulting in the following code:</p>\n\n<pre><code># coding: utf-8\n\n# In[1]:\n\n\nget_ipython().magic('matplotlib inline')\nfrom __future__ import division, print_function, absolute_import\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport tflearn\n\n\n# In[2]:\n\n\n# Data loading and preprocessing\nimport tflearn.datasets.mnist as mnist\nX, Y, testX, testY = mnist.load_data()\nX = np.reshape(X, newshape=[-1, 28, 28, 1])\n\n\n# In[3]:\n\n\n# Noise data input\nz_dim = 200\ntotal_samples = len(X)\n\n\n# In[4]:\n\n\n# Generator\ndef generator(x, reuse=False):\n    with tf.variable_scope('Generator', reuse=reuse):\n        x = tflearn.fully_connected(x, n_units=7 * 7 * 128)\n        x = tflearn.batch_normalization(x)\n        x = tf.nn.tanh(x)\n        x = tf.reshape(x, shape=[-1, 7, 7, 128])\n        x = tflearn.upsample_2d(x, 2)\n        x = tflearn.conv_2d(x, 64, 5, activation='tanh')\n        x = tflearn.upsample_2d(x, 2)\n        x = tflearn.conv_2d(x, 1, 5, activation='sigmoid')\n        return x\n\n\n# In[5]:\n\n\n# Discriminator\ndef discriminator(x, reuse=False):\n    with tf.variable_scope('Discriminator', reuse=reuse):\n        x = tflearn.conv_2d(x, 64, 5, activation='tanh')\n        x = tflearn.avg_pool_2d(x, 2)\n        x = tflearn.conv_2d(x, 128, 5, activation='tanh')\n        x = tflearn.avg_pool_2d(x, 2)\n        x = tflearn.fully_connected(x, 1028, activation='tanh')\n        x = tflearn.fully_connected(x, 2)\n        x = tf.nn.softmax(x)\n        return x\n\n\n# In[6]:\n\n\n# Input data\ngen_input = tflearn.input_data(shape=[None, z_dim], name='input_gen_noise')\ninput_disc_noise = tflearn.input_data(shape=[None, z_dim], name='input_disc_noise')\ninput_disc_real = tflearn.input_data(shape=[None, 28, 28, 1], name='input_disc_real')\n\n\n# In[7]:\n\n\n# Build discriminator\ndisc_fake = discriminator(generator(input_disc_noise))\ndisc_real = discriminator(input_disc_real, reuse=True)\ndisc_net = tf.concat([disc_fake, disc_real], axis=0)\n\n\n# In[8]:\n\n\n# Build stacked Generator/Discriminator\ngen_net = generator(gen_input, reuse=True)\nstacked_gan_net = discriminator(gen_net, reuse=True)\n\n\n# In[9]:\n\n\n# Build training ops for Discriminator\n# Each network optimization should only update its own variable, thus we need\n# to retrieve each network variable (with get_layer_variables_by_name)\ndisc_vars = tflearn.get_layer_variables_by_name('Discriminator')\n# We need 2 target placeholders, for both the real and fake image target\ndisc_target = tflearn.multi_target_data(['target_disc_fake', 'target_disc_real'],\n                                        shape=[None, 2])\ndisc_model = tflearn.regression(disc_net, optimizer='adam',\n                                placeholder=disc_target,\n                                loss='categorical_crossentropy',\n                                trainable_vars=disc_vars,\n                                batch_size=64, name='target_disc',\n                                op_name='DISC')\n\n\n# In[10]:\n\n\n# Build training ops for Generator\ngen_vars = tflearn.get_layer_variables_by_name('Generator')\ngan_model = tflearn.regression(stacked_gan_net, optimizer='adam',\n                               loss='categorical_crossentropy',\n                               trainable_vars=gen_vars,\n                               batch_size=64, name='target_gen',\n                               op_name='GEN')\n\n\n# In[11]:\n\n\n# Define GAN model, that outputs the generated images\ngan = tflearn.DNN(gan_model, tensorboard_verbose=3)\n\n\n# In[12]:\n\n\n# Training\n# Prepare input data to feed to the discriminator\ndisc_noise = np.random.uniform(-1., 1., size=[total_samples, z_dim])\n# Prepare target data to feed to the discriminator (0: fake image, 1: real image)\ny_disc_fake = np.zeros(shape=[total_samples])\ny_disc_real = np.ones(shape=[total_samples])\ny_disc_fake = tflearn.data_utils.to_categorical(y_disc_fake, 2)\ny_disc_real = tflearn.data_utils.to_categorical(y_disc_real, 2)\n\n\n# In[13]:\n\n\n# Prepare input data to feed to the stacked Generator/Discriminator\ngen_noise = np.random.uniform(-1., 1., size=[total_samples, z_dim])\n# Prepare target data to feed to the Discriminator\n# The Generator tries to fool the Discriminator, thus target is 1 (real images)\ny_gen = np.ones(shape=[total_samples])\ny_gen = tflearn.data_utils.to_categorical(y_gen, 2)\n\n\n# In[14]:\n\n\n# Start training, feed both noise and real images\nwith tf.device('/gpu:0'):\n    gan.fit(X_inputs={'input_gen_noise': gen_noise,\n                      'input_disc_noise': disc_noise,\n                      'input_disc_real': X},\n            Y_targets={'target_gen': y_gen,\n                       'target_disc_fake': y_disc_fake,\n                       'target_disc_real': y_disc_real},\n            n_epoch=10)\n\n\n# In[15]:\n\n\n# Create another model from the Generator graph to generate some samples\n# for testing (re-using the same session to re-use the weights learnt)\ngen = tflearn.DNN(gen_net, session=gan.session)\n\n\n# In[16]:\n\n\nf, a = plt.subplots(4, 10, figsize=(10, 4))\nfor i in range(10):\n    # Noise input\n    z = np.random.uniform(-1., 1., size=[4, z_dim])\n    g = np.array(gen.predict({'input_gen_noise': z}))\n    for j in range(4):\n        # Generate image from noise. Extend to 3 channels for matplot figure.\n        img = np.reshape(np.repeat(g[j][:, :, np.newaxis], 3, axis=2),\n                         newshape=(28, 28, 3))\n        a[j][i].imshow(img)\n\nf.show()\nplt.draw()\n</code></pre>\n\n<p>I want to run this code on my NVIDIA GPU. I already have CUDA and cuDNN installed on my machine. Upon examining Windows Task Manager during training, I see that my CPU is stressed and my GPU lies dorment.</p>\n\n<p><a href=\"https://i.stack.imgur.com/RWZ1k.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/RWZ1k.png\" alt=\"Windows Task Manager during training\"></a></p>\n\n<p>Can anyone give advice on how to properly implement <code>with tf.device('/gpu:0'):</code> as it's clear that the above code does not run on my NVIDIA GPU?</p>\n <machine-learning><python><tensorflow><gan><tflearn><p>The parts of your code that need to be inside the <code>with tf.device('/gpu:0'):</code> context is the actual computation graph, where the neural network lives. All the parameters that should be updated on the GPU should be defined within there. I don't know tflearn very well, but I assume if you wrap the code from <code>IN 6</code> to <code>IN 12</code> inside the context manager, it should work.</p>\n\n<p>What happens is that when you define the variables (weights) and the operations in your graph is that you create them but also have to place them and save the reference. Normally this would happen inside your RAM and the variable itself is an adress to the RAM. In the case of TensorFlow, two things are different. First of all, sometimes you want to place some things or all the things on your GPU, due to some inherent advantages that it has for the types of computations that happen in TensorFlow. By using these context managers you show where you want to place them. </p>\n\n<p>The <code>fit</code> that you had inside your context manager will only call the training operations that are already defined on your CPU.</p>\n\n<p>It seems slightly verbose to do it this way, but you get a lot of flexibility with this. You can spread your graph over multiple GPUs, or do part of the compute on the CPU because it's faster there, or you don't have enough GPU RAM for the full graph.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "26622",
                "question_votes:": "2",
                "question_text:": "<p>I have collected the <a href=\"https://github.com/tflearn/tflearn/blob/master/examples/images/dcgan.py\" rel=\"nofollow noreferrer\">TFLearn DCGAN example</a> code and put it into my local Jupyter environment. Furthermore, I have changed some comments and added <code>with tf.device('/gpu:0'):</code> right before calling <code>gan.fit(...)</code>, resulting in the following code:</p>\n\n<pre><code># coding: utf-8\n\n# In[1]:\n\n\nget_ipython().magic('matplotlib inline')\nfrom __future__ import division, print_function, absolute_import\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport tflearn\n\n\n# In[2]:\n\n\n# Data loading and preprocessing\nimport tflearn.datasets.mnist as mnist\nX, Y, testX, testY = mnist.load_data()\nX = np.reshape(X, newshape=[-1, 28, 28, 1])\n\n\n# In[3]:\n\n\n# Noise data input\nz_dim = 200\ntotal_samples = len(X)\n\n\n# In[4]:\n\n\n# Generator\ndef generator(x, reuse=False):\n    with tf.variable_scope('Generator', reuse=reuse):\n        x = tflearn.fully_connected(x, n_units=7 * 7 * 128)\n        x = tflearn.batch_normalization(x)\n        x = tf.nn.tanh(x)\n        x = tf.reshape(x, shape=[-1, 7, 7, 128])\n        x = tflearn.upsample_2d(x, 2)\n        x = tflearn.conv_2d(x, 64, 5, activation='tanh')\n        x = tflearn.upsample_2d(x, 2)\n        x = tflearn.conv_2d(x, 1, 5, activation='sigmoid')\n        return x\n\n\n# In[5]:\n\n\n# Discriminator\ndef discriminator(x, reuse=False):\n    with tf.variable_scope('Discriminator', reuse=reuse):\n        x = tflearn.conv_2d(x, 64, 5, activation='tanh')\n        x = tflearn.avg_pool_2d(x, 2)\n        x = tflearn.conv_2d(x, 128, 5, activation='tanh')\n        x = tflearn.avg_pool_2d(x, 2)\n        x = tflearn.fully_connected(x, 1028, activation='tanh')\n        x = tflearn.fully_connected(x, 2)\n        x = tf.nn.softmax(x)\n        return x\n\n\n# In[6]:\n\n\n# Input data\ngen_input = tflearn.input_data(shape=[None, z_dim], name='input_gen_noise')\ninput_disc_noise = tflearn.input_data(shape=[None, z_dim], name='input_disc_noise')\ninput_disc_real = tflearn.input_data(shape=[None, 28, 28, 1], name='input_disc_real')\n\n\n# In[7]:\n\n\n# Build discriminator\ndisc_fake = discriminator(generator(input_disc_noise))\ndisc_real = discriminator(input_disc_real, reuse=True)\ndisc_net = tf.concat([disc_fake, disc_real], axis=0)\n\n\n# In[8]:\n\n\n# Build stacked Generator/Discriminator\ngen_net = generator(gen_input, reuse=True)\nstacked_gan_net = discriminator(gen_net, reuse=True)\n\n\n# In[9]:\n\n\n# Build training ops for Discriminator\n# Each network optimization should only update its own variable, thus we need\n# to retrieve each network variable (with get_layer_variables_by_name)\ndisc_vars = tflearn.get_layer_variables_by_name('Discriminator')\n# We need 2 target placeholders, for both the real and fake image target\ndisc_target = tflearn.multi_target_data(['target_disc_fake', 'target_disc_real'],\n                                        shape=[None, 2])\ndisc_model = tflearn.regression(disc_net, optimizer='adam',\n                                placeholder=disc_target,\n                                loss='categorical_crossentropy',\n                                trainable_vars=disc_vars,\n                                batch_size=64, name='target_disc',\n                                op_name='DISC')\n\n\n# In[10]:\n\n\n# Build training ops for Generator\ngen_vars = tflearn.get_layer_variables_by_name('Generator')\ngan_model = tflearn.regression(stacked_gan_net, optimizer='adam',\n                               loss='categorical_crossentropy',\n                               trainable_vars=gen_vars,\n                               batch_size=64, name='target_gen',\n                               op_name='GEN')\n\n\n# In[11]:\n\n\n# Define GAN model, that outputs the generated images\ngan = tflearn.DNN(gan_model, tensorboard_verbose=3)\n\n\n# In[12]:\n\n\n# Training\n# Prepare input data to feed to the discriminator\ndisc_noise = np.random.uniform(-1., 1., size=[total_samples, z_dim])\n# Prepare target data to feed to the discriminator (0: fake image, 1: real image)\ny_disc_fake = np.zeros(shape=[total_samples])\ny_disc_real = np.ones(shape=[total_samples])\ny_disc_fake = tflearn.data_utils.to_categorical(y_disc_fake, 2)\ny_disc_real = tflearn.data_utils.to_categorical(y_disc_real, 2)\n\n\n# In[13]:\n\n\n# Prepare input data to feed to the stacked Generator/Discriminator\ngen_noise = np.random.uniform(-1., 1., size=[total_samples, z_dim])\n# Prepare target data to feed to the Discriminator\n# The Generator tries to fool the Discriminator, thus target is 1 (real images)\ny_gen = np.ones(shape=[total_samples])\ny_gen = tflearn.data_utils.to_categorical(y_gen, 2)\n\n\n# In[14]:\n\n\n# Start training, feed both noise and real images\nwith tf.device('/gpu:0'):\n    gan.fit(X_inputs={'input_gen_noise': gen_noise,\n                      'input_disc_noise': disc_noise,\n                      'input_disc_real': X},\n            Y_targets={'target_gen': y_gen,\n                       'target_disc_fake': y_disc_fake,\n                       'target_disc_real': y_disc_real},\n            n_epoch=10)\n\n\n# In[15]:\n\n\n# Create another model from the Generator graph to generate some samples\n# for testing (re-using the same session to re-use the weights learnt)\ngen = tflearn.DNN(gen_net, session=gan.session)\n\n\n# In[16]:\n\n\nf, a = plt.subplots(4, 10, figsize=(10, 4))\nfor i in range(10):\n    # Noise input\n    z = np.random.uniform(-1., 1., size=[4, z_dim])\n    g = np.array(gen.predict({'input_gen_noise': z}))\n    for j in range(4):\n        # Generate image from noise. Extend to 3 channels for matplot figure.\n        img = np.reshape(np.repeat(g[j][:, :, np.newaxis], 3, axis=2),\n                         newshape=(28, 28, 3))\n        a[j][i].imshow(img)\n\nf.show()\nplt.draw()\n</code></pre>\n\n<p>I want to run this code on my NVIDIA GPU. I already have CUDA and cuDNN installed on my machine. Upon examining Windows Task Manager during training, I see that my CPU is stressed and my GPU lies dorment.</p>\n\n<p><a href=\"https://i.stack.imgur.com/RWZ1k.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/RWZ1k.png\" alt=\"Windows Task Manager during training\"></a></p>\n\n<p>Can anyone give advice on how to properly implement <code>with tf.device('/gpu:0'):</code> as it's clear that the above code does not run on my NVIDIA GPU?</p>\n",
                "tags": "<machine-learning><python><tensorflow><gan><tflearn>",
                "answers": [
                    [
                        "26737",
                        "2",
                        "26622",
                        "",
                        "",
                        "<p>The parts of your code that need to be inside the <code>with tf.device('/gpu:0'):</code> context is the actual computation graph, where the neural network lives. All the parameters that should be updated on the GPU should be defined within there. I don't know tflearn very well, but I assume if you wrap the code from <code>IN 6</code> to <code>IN 12</code> inside the context manager, it should work.</p>\n\n<p>What happens is that when you define the variables (weights) and the operations in your graph is that you create them but also have to place them and save the reference. Normally this would happen inside your RAM and the variable itself is an adress to the RAM. In the case of TensorFlow, two things are different. First of all, sometimes you want to place some things or all the things on your GPU, due to some inherent advantages that it has for the types of computations that happen in TensorFlow. By using these context managers you show where you want to place them. </p>\n\n<p>The <code>fit</code> that you had inside your context manager will only call the training operations that are already defined on your CPU.</p>\n\n<p>It seems slightly verbose to do it this way, but you get a lot of flexibility with this. You can spread your graph over multiple GPUs, or do part of the compute on the CPU because it's faster there, or you don't have enough GPU RAM for the full graph.</p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11287",
            "_score": 5.548531,
            "_source": {
                "title": "Model Not Learning with Sparse Dataset (LSTM with Keras)",
                "content": "Model Not Learning with Sparse Dataset (LSTM with Keras) <p>This classification problem is apparently simple and I have no idea why it's not working, perhaps I'm doing a conceptual mistake. I'm trying to make a predictor which will classify minutes on a clock as <code>0</code> for no requests or <code>1</code> for a request in that time instant. So far, the model can't seem to learn past giving everything <code>0</code>'s or putting zeros before all the requests happen. The best case scenario I've got so far is:</p>\n\n<p><a href=\"https://i.stack.imgur.com/89Ju9.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/89Ju9.png\" alt=\"enter image description here\"></a></p>\n\n<p>I've been trying to implement all the things I've learned related to Neural Networks and my code works in the following manner:</p>\n\n<ol>\n<li>Create the Clock.</li>\n<li>Create some Requests (I've made them last longer so the dataset is less sparse).</li>\n<li>Scale (MinMax) the independent variable (clock).</li>\n<li>Create a custom loss function for the sparse dataset (I've tried it with a regular logits, but it can't go much further than giving zeros to almost everything; so I penalized mistakes made on the instants with requests).</li>\n<li>Create the model, composed of 3 stacked LSTM layers (Both a regular NN and an LSTM have been tried).</li>\n</ol>\n\n<p>Other techniques that have also been tried are Dropout, Gradient Clipping (for exploding gradients) and extremely small learning rates with ADAM (on the order of <span class=\"math-container\">$10^{-5}$</span>). Basically, I just can't go much further than an accuracy of around 73.33%.</p>\n\n<p>The code below is indeed longer than I would like to believe I'm allowed to post here, but it is also, hopefully, rather simple to read. Thank you for trying to help me.</p>\n\n<pre><code># Data Pre-processing\n\n## The Clock\n\nclock = []\nfor i in range(0,24):\n    for j in range(0,60):\n        if i &lt; 10:\n            if j &lt; 10:\n                clock.append('0' + str(i) + '0' + str(j))\n            else:\n                clock.append('0' + str(i) + str(j))\n        else:\n            if j &lt; 10:\n                clock.append(str(i) + '0' + str(j))\n            else:\n                clock.append(str(i) + str(j))\n\n## Requests\n\nlevels = 2\nrequest_full = [0]*len(clock)\nrequest_1300 = []\nrequest_1500 = []\nrequest_1800 = []\nrequest_2100 = []\nrequest_2300 = []\nfor i in range(0,60):\n    if i &lt; 10:\n        request_1300.append(['13' + '0' + str(i), 1])\n        request_1500.append(['15' + '0' + str(i), 1])\n        request_1800.append(['18' + '0' + str(i), 1])\n        request_2100.append(['21' + '0' + str(i), 1])\n        request_2300.append(['23' + '0' + str(i), 1])\n    else:\n        request_1300.append(['13' + str(i), 1])\n        request_1500.append(['15' + str(i), 1])\n        request_1800.append(['18' + str(i), 1])\n        request_2100.append(['21' + str(i), 1])\n        request_2300.append(['23' + str(i), 1])\n\nrequest_list = [i for i in \n                request_1300 + \n                request_1500 + \n                request_1800 + \n                request_2100 + \n                request_2300]\n\nfor i,j in request_list:\n    idx = clock.index(i)\n    request_full[idx] = j\n\nimport numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame({'clock': clock, 'requests': request_full})\n\ndf.to_csv('test1.csv', sep = ',')\n\nclock = df['clock'].values\nclock = np.reshape(clock, (len(clock), 1))\nrequests = df['requests'].values\nrequests = np.reshape(requests, (len(requests), 1))\n\n## Feature Scaling\nfrom sklearn.preprocessing import MinMaxScaler\n\nsc = MinMaxScaler(feature_range = (0, 1))\ntraining_set_scaled = sc.fit_transform(clock)\n\nX_train = []\ny_train = []\nfor i in range(60, len(clock)):\n    X_train.append(training_set_scaled[i-60:i, 0])\n    y_train.append(requests[i, 0])\nX_train, y_train = np.array(X_train), np.array(y_train)\n\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras import optimizers\nimport tensorflow as tf\n\ndef sparse_penalty_logits(y_true, y_pred):\n    penalty = 10\n\n    loss = tf.where(tf.greater(y_true, 0),\n                    penalty*tf.nn.sigmoid_cross_entropy_with_logits(logits = y_pred,\n                                                                    labels = y_true),\n                    tf.nn.sigmoid_cross_entropy_with_logits(logits = y_pred,\n                                                            labels = y_true))\n\n    return loss\n\n# Initialising the RNN\nclassifier = Sequential()\n\n# Adding the first LSTM layer and some Dropout regularisation\nclassifier.add(LSTM(units = 60, \n                    return_sequences = True,\n                    input_shape = (X_train.shape[1], 1)))\nclassifier.add(Dropout(0.2))\n\n\n# 2nd Layer\nclassifier.add(LSTM(units = 60, \n                    return_sequences = True))\n#classifier.add(Dropout(0.2))\n\n# 3rd Layer\nclassifier.add(LSTM(units = 60, \n                    return_sequences = False))\n#classifier.add(Dropout(0.2))\n\n# Adding the output layer\nclassifier.add(Dense(units = 1, \n                     activation = 'sigmoid'))\n\n# Compiling the RNN\nadam = optimizers.Adam(lr = 10**(-5), \n                       clipnorm = 1, \n                       clipvalue = 0.5)\n\nclassifier.compile(optimizer = adam, \n                   loss = sparse_penalty_logits,\n                   metrics = ['binary_accuracy'])\n\n# Fitting the RNN to the Training set\nclassifier.fit(X_train, \n               y_train, \n               epochs = 100)\n\n\n# Making the predictions with the dataset\ny_pred = classifier.predict(X_train)\ny_pred_bin = (y_pred &gt; 0.5)\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_train, y_pred_bin)\n\n# Plotting\nimport matplotlib.pyplot as plt\n\nplt.plot(y_pred, color = 'green', label = 'model')\nplt.plot(y_pred_bin, color = 'red', label = 'model binary')\nplt.plot(y_train, color = 'blue', label = 'training')\nplt.legend()\nplt.show()\nplt.close()\n</code></pre>\n <python><neural-network><deep-learning><keras><lstm><p>First of all, this has been quite a journey to solve. I had to ask for a friend's help who, in turn, presented me to a friend of his. The solution is something that appears somewhat intuitive to me, but, nevertheless, was not at all on my radar.</p>\n\n<p>Basically, since we only have one row of data to look at, the fit is going to be too sharp for the NN, so it will most likely always plateau and stick to spitting out only zeros. To make things easier for the NN, the suggested solution is to apply some noise to our data, so that the system won't think that it needs to get a very sharp fit in order to do its job. </p>\n\n<p>Despite this little trick, it is still very hard for the NN to get a good fit because it's still one row, so, now, if we use ADAM (which dynamically reduces the learning rate), it might get stuck in local minima and never come out. The last tip then is to use incredibly high learning rates, in my case, between 0.2 and 0.3. The learning process will not be stable either and, thus, lastly, it's necessary to use an absurd amount of epochs (20,000) with callbacks to register the most optimal weights. This way, my friend's friend solution got us to 99.8% accuracy.</p>\n\n<p>Despite the good performance, quite frankly, he and I are both in agreement that the most reliable and fast solution to this problem is actually to use a Decision Tree type of algorithm.</p>\n\n<p>I am not able to provide the source code of the solution here due to a request of its author.</p>\n<p>I would suggest you try neural poisson processes. What you are try to predict is a point process with a fixed (or variable in hawkes processes) density function. As such I am not sure simply modeling it as a sequence can give you reasonable performance. </p>\n",
                "codes": [
                    [],
                    []
                ],
                "question_id:": "39838",
                "question_votes:": "2",
                "question_text:": "<p>This classification problem is apparently simple and I have no idea why it's not working, perhaps I'm doing a conceptual mistake. I'm trying to make a predictor which will classify minutes on a clock as <code>0</code> for no requests or <code>1</code> for a request in that time instant. So far, the model can't seem to learn past giving everything <code>0</code>'s or putting zeros before all the requests happen. The best case scenario I've got so far is:</p>\n\n<p><a href=\"https://i.stack.imgur.com/89Ju9.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/89Ju9.png\" alt=\"enter image description here\"></a></p>\n\n<p>I've been trying to implement all the things I've learned related to Neural Networks and my code works in the following manner:</p>\n\n<ol>\n<li>Create the Clock.</li>\n<li>Create some Requests (I've made them last longer so the dataset is less sparse).</li>\n<li>Scale (MinMax) the independent variable (clock).</li>\n<li>Create a custom loss function for the sparse dataset (I've tried it with a regular logits, but it can't go much further than giving zeros to almost everything; so I penalized mistakes made on the instants with requests).</li>\n<li>Create the model, composed of 3 stacked LSTM layers (Both a regular NN and an LSTM have been tried).</li>\n</ol>\n\n<p>Other techniques that have also been tried are Dropout, Gradient Clipping (for exploding gradients) and extremely small learning rates with ADAM (on the order of <span class=\"math-container\">$10^{-5}$</span>). Basically, I just can't go much further than an accuracy of around 73.33%.</p>\n\n<p>The code below is indeed longer than I would like to believe I'm allowed to post here, but it is also, hopefully, rather simple to read. Thank you for trying to help me.</p>\n\n<pre><code># Data Pre-processing\n\n## The Clock\n\nclock = []\nfor i in range(0,24):\n    for j in range(0,60):\n        if i &lt; 10:\n            if j &lt; 10:\n                clock.append('0' + str(i) + '0' + str(j))\n            else:\n                clock.append('0' + str(i) + str(j))\n        else:\n            if j &lt; 10:\n                clock.append(str(i) + '0' + str(j))\n            else:\n                clock.append(str(i) + str(j))\n\n## Requests\n\nlevels = 2\nrequest_full = [0]*len(clock)\nrequest_1300 = []\nrequest_1500 = []\nrequest_1800 = []\nrequest_2100 = []\nrequest_2300 = []\nfor i in range(0,60):\n    if i &lt; 10:\n        request_1300.append(['13' + '0' + str(i), 1])\n        request_1500.append(['15' + '0' + str(i), 1])\n        request_1800.append(['18' + '0' + str(i), 1])\n        request_2100.append(['21' + '0' + str(i), 1])\n        request_2300.append(['23' + '0' + str(i), 1])\n    else:\n        request_1300.append(['13' + str(i), 1])\n        request_1500.append(['15' + str(i), 1])\n        request_1800.append(['18' + str(i), 1])\n        request_2100.append(['21' + str(i), 1])\n        request_2300.append(['23' + str(i), 1])\n\nrequest_list = [i for i in \n                request_1300 + \n                request_1500 + \n                request_1800 + \n                request_2100 + \n                request_2300]\n\nfor i,j in request_list:\n    idx = clock.index(i)\n    request_full[idx] = j\n\nimport numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame({'clock': clock, 'requests': request_full})\n\ndf.to_csv('test1.csv', sep = ',')\n\nclock = df['clock'].values\nclock = np.reshape(clock, (len(clock), 1))\nrequests = df['requests'].values\nrequests = np.reshape(requests, (len(requests), 1))\n\n## Feature Scaling\nfrom sklearn.preprocessing import MinMaxScaler\n\nsc = MinMaxScaler(feature_range = (0, 1))\ntraining_set_scaled = sc.fit_transform(clock)\n\nX_train = []\ny_train = []\nfor i in range(60, len(clock)):\n    X_train.append(training_set_scaled[i-60:i, 0])\n    y_train.append(requests[i, 0])\nX_train, y_train = np.array(X_train), np.array(y_train)\n\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras import optimizers\nimport tensorflow as tf\n\ndef sparse_penalty_logits(y_true, y_pred):\n    penalty = 10\n\n    loss = tf.where(tf.greater(y_true, 0),\n                    penalty*tf.nn.sigmoid_cross_entropy_with_logits(logits = y_pred,\n                                                                    labels = y_true),\n                    tf.nn.sigmoid_cross_entropy_with_logits(logits = y_pred,\n                                                            labels = y_true))\n\n    return loss\n\n# Initialising the RNN\nclassifier = Sequential()\n\n# Adding the first LSTM layer and some Dropout regularisation\nclassifier.add(LSTM(units = 60, \n                    return_sequences = True,\n                    input_shape = (X_train.shape[1], 1)))\nclassifier.add(Dropout(0.2))\n\n\n# 2nd Layer\nclassifier.add(LSTM(units = 60, \n                    return_sequences = True))\n#classifier.add(Dropout(0.2))\n\n# 3rd Layer\nclassifier.add(LSTM(units = 60, \n                    return_sequences = False))\n#classifier.add(Dropout(0.2))\n\n# Adding the output layer\nclassifier.add(Dense(units = 1, \n                     activation = 'sigmoid'))\n\n# Compiling the RNN\nadam = optimizers.Adam(lr = 10**(-5), \n                       clipnorm = 1, \n                       clipvalue = 0.5)\n\nclassifier.compile(optimizer = adam, \n                   loss = sparse_penalty_logits,\n                   metrics = ['binary_accuracy'])\n\n# Fitting the RNN to the Training set\nclassifier.fit(X_train, \n               y_train, \n               epochs = 100)\n\n\n# Making the predictions with the dataset\ny_pred = classifier.predict(X_train)\ny_pred_bin = (y_pred &gt; 0.5)\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_train, y_pred_bin)\n\n# Plotting\nimport matplotlib.pyplot as plt\n\nplt.plot(y_pred, color = 'green', label = 'model')\nplt.plot(y_pred_bin, color = 'red', label = 'model binary')\nplt.plot(y_train, color = 'blue', label = 'training')\nplt.legend()\nplt.show()\nplt.close()\n</code></pre>\n",
                "tags": "<python><neural-network><deep-learning><keras><lstm>",
                "answers": [
                    [
                        "42306",
                        "2",
                        "39838",
                        "",
                        "",
                        "<p>First of all, this has been quite a journey to solve. I had to ask for a friend's help who, in turn, presented me to a friend of his. The solution is something that appears somewhat intuitive to me, but, nevertheless, was not at all on my radar.</p>\n\n<p>Basically, since we only have one row of data to look at, the fit is going to be too sharp for the NN, so it will most likely always plateau and stick to spitting out only zeros. To make things easier for the NN, the suggested solution is to apply some noise to our data, so that the system won't think that it needs to get a very sharp fit in order to do its job. </p>\n\n<p>Despite this little trick, it is still very hard for the NN to get a good fit because it's still one row, so, now, if we use ADAM (which dynamically reduces the learning rate), it might get stuck in local minima and never come out. The last tip then is to use incredibly high learning rates, in my case, between 0.2 and 0.3. The learning process will not be stable either and, thus, lastly, it's necessary to use an absurd amount of epochs (20,000) with callbacks to register the most optimal weights. This way, my friend's friend solution got us to 99.8% accuracy.</p>\n\n<p>Despite the good performance, quite frankly, he and I are both in agreement that the most reliable and fast solution to this problem is actually to use a Decision Tree type of algorithm.</p>\n\n<p>I am not able to provide the source code of the solution here due to a request of its author.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "39917",
                        "2",
                        "39838",
                        "",
                        "",
                        "<p>I would suggest you try neural poisson processes. What you are try to predict is a point process with a fixed (or variable in hawkes processes) density function. As such I am not sure simply modeling it as a sequence can give you reasonable performance. </p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4722",
            "_score": 5.487381,
            "_source": {
                "title": "Detecting outlier with combining two vectors",
                "content": "Detecting outlier with combining two vectors <p>I want to combine the following vectors in a way that just the red point (number 7) becomes inconsistent with other points( become an outlier and become distant from other points) and other points become consistent with each other. Please note that I have tested mahalanobis distance and Kullback-Leibler divergence between two vectors but they were not so good and detects. </p>\n\n<p>a=[1.3269   1.3354  1.3318  1.3282  1.34666 1.3460  1.36084 1.3526  1.3539  1.3510  1.3480  1.3479  1.34893]</p>\n\n<p>b=[0.0352,0.0992,0.1570,0.1431,0.1634,0.1629,0.1046,0.1655,0.1635,0.1642,0.1658,0.1666,0.15735]</p>\n\n<p><a href=\"https://i.stack.imgur.com/E5Spn.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/E5Spn.png\" alt=\"enter image description here\"></a> <a href=\"https://i.stack.imgur.com/6srGb.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/6srGb.png\" alt=\"enter image description here\"></a></p>\n\n<p>Thanks in advance. </p>\n <data-mining><feature-extraction><feature-engineering><anomaly-detection><outlier><p>I don't really agree with the idea of \"wanting\" a point to be an outlier and then massaging the algorithm to make it so. You have 2 dimensions and its either an outlier or its not.</p>\n\n<p>If one standardizes the data and then deciphers the Mahalanobis distances, point 6 is only one of two points that sit outside of a certain threshold (point 0 being the other point). Beyond that theres not much you can do beyond some sort of nonlinear transformation which you know to be true due to some deterministic knowledge you have about a particular phenomenon.</p>\n\n<p>Anyways... here's the two outlier version in case you weren't standardizing your data first:</p>\n\n<pre><code>from pandas import DataFrame, read_csv\ndfR = read_csv('~/Machine_Learning/ipython_notebooks/AB_outlier.csv')\ndf=(dfR-dfR.mean())/dfR.std()\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.covariance import EmpiricalCovariance, MinCovDet\nemp_cov = EmpiricalCovariance().fit(df)\n\nfig = plt.figure()\nplt.subplots_adjust(hspace=-.1, wspace=.4, top=.95, bottom=.05)\n\n# Show data set\nsubfig1 = plt.subplot(3, 1, 1)\nmy_plot = subfig1.scatter(df.A,df.B)\nsubfig1.set_xlim(subfig1.get_xlim()[0], 11.)\nsubfig1.set_title(\"Mahalanobis distances\")\n\n# Show contours of the distance functions\nxx, yy = np.meshgrid(np.linspace(plt.xlim()[0], plt.xlim()[1], 100),\n                 np.linspace(plt.ylim()[0], plt.ylim()[1], 100))\nzz = np.c_[xx.ravel(), yy.ravel()]\n\nmahal_emp_cov = emp_cov.mahalanobis(zz)\nmahal_emp_cov = mahal_emp_cov.reshape(xx.shape)\nemp_cov_contour = subfig1.contour(xx, yy, np.sqrt(mahal_emp_cov),\n                              cmap=plt.cm.PuBu_r,\n                              linestyles='dashed')\n\nsubfig1.legend([emp_cov_contour.collections[1],\n            my_plot],\n           ['MLE dist'],\n           loc=\"upper right\", borderaxespad=0)\nplt.xticks(())\nplt.yticks(())\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/xUdbm.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/xUdbm.png\" alt=\"Plot of standardized data with Mahalanobis distance lines\"></a></p>\n\n<p>Hope this helps!</p>\n<p>From the second graph it seems pretty easy to identify the outlier. You could probably just fit a simple polynomial (or some other function) and then flag all points that have a distance greater than 2 standard deviations (or whatever seems appropriate) from the fitted curve. </p>\n\n<p><a href=\"https://i.stack.imgur.com/0HEzS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/0HEzS.png\" alt=\"enter image description here\"></a></p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nb=np.array([0.0352,0.0992,0.1570,0.1431,0.1634,0.1629,0.1046\n            ,0.1655,0.1635,0.1642,0.1658,0.1666,0.15735])\nx = np.arange(13)\np = np.poly1d(np.polyfit(x,b,4))\ny = p(x)\n\nplt.plot(x,b,'ro')\nplt.plot(x,y,'b-')\nplt.show()\n</code></pre>\n<h2>Autoencoder Solution</h2>\n\n<p>You could try an autoencoder. The autoencoder would take an input vector and it would try to recreate it as an output. So you take your input, and measure the distance between the input and the predicted output variable, using your metric of choice (euclidean should work but try various). Larger distances can be thought of as more abnormal. So you can stack rank your observations from weirdest to most normal.</p>\n\n<p>Make sure that you are only training the autoencoder on normal data though. This would of course assume that you have more than the 13 samples that you are looking at. If not this probably isn't going to work very well, just because of the small sample.</p>\n\n<h2>KDE Solution</h2>\n\n<p>The idea is to use Kernel Density Estimation to generate a non-parametric joint density of your data set. You then find what the probability of finding a value that extreme would be. Here is some code using python's sklearn package:</p>\n\n<pre><code>from sklearn.neighbors.kde import KernelDensity\nimport numpy as np\nX=np.matrix([[1.3269, 1.3354, 1.3318, 1.3282, 1.34666, 1.3460, 1.36084, 1.3526, 1.3539, 1.3510, 1.3480, 1.3479, 1.34893],[0.0352, 0.0992, 0.1570, 0.1431, 0.1634, 0.1629, 0.1046, 0.1655, 0.1635, 0.1642, 0.1658, 0.1666, 0.15735]])\nkde = KernelDensity(kernel='gaussian', bandwidth=.45).fit(X.T)\nscore=kde.score_samples(X.T)\nprob=np.exp(score)\nprint(prob/prob[6])\n</code></pre>\n\n<p>This code shows that the observations in the lowest probability density areas are observations 1,2 and 7. Of course this would work better with a larger sample, and you need to fuss with the bandwidth to calibrate it, but that this should do it.</p>\n",
                "codes": [
                    [
                        "from pandas import DataFrame, read_csv\ndfR = read_csv('~/Machine_Learning/ipython_notebooks/AB_outlier.csv')\ndf=(dfR-dfR.mean())/dfR.std()\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.covariance import EmpiricalCovariance, MinCovDet\nemp_cov = EmpiricalCovariance().fit(df)\n\nfig = plt.figure()\nplt.subplots_adjust(hspace=-.1, wspace=.4, top=.95, bottom=.05)\n\n# Show data set\nsubfig1 = plt.subplot(3, 1, 1)\nmy_plot = subfig1.scatter(df.A,df.B)\nsubfig1.set_xlim(subfig1.get_xlim()[0], 11.)\nsubfig1.set_title(\"Mahalanobis distances\")\n\n# Show contours of the distance functions\nxx, yy = np.meshgrid(np.linspace(plt.xlim()[0], plt.xlim()[1], 100),\n                 np.linspace(plt.ylim()[0], plt.ylim()[1], 100))\nzz = np.c_[xx.ravel(), yy.ravel()]\n\nmahal_emp_cov = emp_cov.mahalanobis(zz)\nmahal_emp_cov = mahal_emp_cov.reshape(xx.shape)\nemp_cov_contour = subfig1.contour(xx, yy, np.sqrt(mahal_emp_cov),\n                              cmap=plt.cm.PuBu_r,\n                              linestyles='dashed')\n\nsubfig1.legend([emp_cov_contour.collections[1],\n            my_plot],\n           ['MLE dist'],\n           loc=\"upper right\", borderaxespad=0)\nplt.xticks(())\nplt.yticks(())\n"
                    ],
                    [
                        "import numpy as np\nimport matplotlib.pyplot as plt\n\nb=np.array([0.0352,0.0992,0.1570,0.1431,0.1634,0.1629,0.1046\n            ,0.1655,0.1635,0.1642,0.1658,0.1666,0.15735])\nx = np.arange(13)\np = np.poly1d(np.polyfit(x,b,4))\ny = p(x)\n\nplt.plot(x,b,'ro')\nplt.plot(x,y,'b-')\nplt.show()\n"
                    ],
                    [
                        "from sklearn.neighbors.kde import KernelDensity\nimport numpy as np\nX=np.matrix([[1.3269, 1.3354, 1.3318, 1.3282, 1.34666, 1.3460, 1.36084, 1.3526, 1.3539, 1.3510, 1.3480, 1.3479, 1.34893],[0.0352, 0.0992, 0.1570, 0.1431, 0.1634, 0.1629, 0.1046, 0.1655, 0.1635, 0.1642, 0.1658, 0.1666, 0.15735]])\nkde = KernelDensity(kernel='gaussian', bandwidth=.45).fit(X.T)\nscore=kde.score_samples(X.T)\nprob=np.exp(score)\nprint(prob/prob[6])\n"
                    ]
                ],
                "question_id:": "18597",
                "question_votes:": "1",
                "question_text:": "<p>I want to combine the following vectors in a way that just the red point (number 7) becomes inconsistent with other points( become an outlier and become distant from other points) and other points become consistent with each other. Please note that I have tested mahalanobis distance and Kullback-Leibler divergence between two vectors but they were not so good and detects. </p>\n\n<p>a=[1.3269   1.3354  1.3318  1.3282  1.34666 1.3460  1.36084 1.3526  1.3539  1.3510  1.3480  1.3479  1.34893]</p>\n\n<p>b=[0.0352,0.0992,0.1570,0.1431,0.1634,0.1629,0.1046,0.1655,0.1635,0.1642,0.1658,0.1666,0.15735]</p>\n\n<p><a href=\"https://i.stack.imgur.com/E5Spn.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/E5Spn.png\" alt=\"enter image description here\"></a> <a href=\"https://i.stack.imgur.com/6srGb.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/6srGb.png\" alt=\"enter image description here\"></a></p>\n\n<p>Thanks in advance. </p>\n",
                "tags": "<data-mining><feature-extraction><feature-engineering><anomaly-detection><outlier>",
                "answers": [
                    [
                        "18601",
                        "2",
                        "18597",
                        "",
                        "",
                        "<p>I don't really agree with the idea of \"wanting\" a point to be an outlier and then massaging the algorithm to make it so. You have 2 dimensions and its either an outlier or its not.</p>\n\n<p>If one standardizes the data and then deciphers the Mahalanobis distances, point 6 is only one of two points that sit outside of a certain threshold (point 0 being the other point). Beyond that theres not much you can do beyond some sort of nonlinear transformation which you know to be true due to some deterministic knowledge you have about a particular phenomenon.</p>\n\n<p>Anyways... here's the two outlier version in case you weren't standardizing your data first:</p>\n\n<pre><code>from pandas import DataFrame, read_csv\ndfR = read_csv('~/Machine_Learning/ipython_notebooks/AB_outlier.csv')\ndf=(dfR-dfR.mean())/dfR.std()\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.covariance import EmpiricalCovariance, MinCovDet\nemp_cov = EmpiricalCovariance().fit(df)\n\nfig = plt.figure()\nplt.subplots_adjust(hspace=-.1, wspace=.4, top=.95, bottom=.05)\n\n# Show data set\nsubfig1 = plt.subplot(3, 1, 1)\nmy_plot = subfig1.scatter(df.A,df.B)\nsubfig1.set_xlim(subfig1.get_xlim()[0], 11.)\nsubfig1.set_title(\"Mahalanobis distances\")\n\n# Show contours of the distance functions\nxx, yy = np.meshgrid(np.linspace(plt.xlim()[0], plt.xlim()[1], 100),\n                 np.linspace(plt.ylim()[0], plt.ylim()[1], 100))\nzz = np.c_[xx.ravel(), yy.ravel()]\n\nmahal_emp_cov = emp_cov.mahalanobis(zz)\nmahal_emp_cov = mahal_emp_cov.reshape(xx.shape)\nemp_cov_contour = subfig1.contour(xx, yy, np.sqrt(mahal_emp_cov),\n                              cmap=plt.cm.PuBu_r,\n                              linestyles='dashed')\n\nsubfig1.legend([emp_cov_contour.collections[1],\n            my_plot],\n           ['MLE dist'],\n           loc=\"upper right\", borderaxespad=0)\nplt.xticks(())\nplt.yticks(())\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/xUdbm.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/xUdbm.png\" alt=\"Plot of standardized data with Mahalanobis distance lines\"></a></p>\n\n<p>Hope this helps!</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "18599",
                        "2",
                        "18597",
                        "",
                        "",
                        "<p>From the second graph it seems pretty easy to identify the outlier. You could probably just fit a simple polynomial (or some other function) and then flag all points that have a distance greater than 2 standard deviations (or whatever seems appropriate) from the fitted curve. </p>\n\n<p><a href=\"https://i.stack.imgur.com/0HEzS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/0HEzS.png\" alt=\"enter image description here\"></a></p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nb=np.array([0.0352,0.0992,0.1570,0.1431,0.1634,0.1629,0.1046\n            ,0.1655,0.1635,0.1642,0.1658,0.1666,0.15735])\nx = np.arange(13)\np = np.poly1d(np.polyfit(x,b,4))\ny = p(x)\n\nplt.plot(x,b,'ro')\nplt.plot(x,y,'b-')\nplt.show()\n</code></pre>\n",
                        "",
                        "1"
                    ],
                    [
                        "18598",
                        "2",
                        "18597",
                        "",
                        "",
                        "<h2>Autoencoder Solution</h2>\n\n<p>You could try an autoencoder. The autoencoder would take an input vector and it would try to recreate it as an output. So you take your input, and measure the distance between the input and the predicted output variable, using your metric of choice (euclidean should work but try various). Larger distances can be thought of as more abnormal. So you can stack rank your observations from weirdest to most normal.</p>\n\n<p>Make sure that you are only training the autoencoder on normal data though. This would of course assume that you have more than the 13 samples that you are looking at. If not this probably isn't going to work very well, just because of the small sample.</p>\n\n<h2>KDE Solution</h2>\n\n<p>The idea is to use Kernel Density Estimation to generate a non-parametric joint density of your data set. You then find what the probability of finding a value that extreme would be. Here is some code using python's sklearn package:</p>\n\n<pre><code>from sklearn.neighbors.kde import KernelDensity\nimport numpy as np\nX=np.matrix([[1.3269, 1.3354, 1.3318, 1.3282, 1.34666, 1.3460, 1.36084, 1.3526, 1.3539, 1.3510, 1.3480, 1.3479, 1.34893],[0.0352, 0.0992, 0.1570, 0.1431, 0.1634, 0.1629, 0.1046, 0.1655, 0.1635, 0.1642, 0.1658, 0.1666, 0.15735]])\nkde = KernelDensity(kernel='gaussian', bandwidth=.45).fit(X.T)\nscore=kde.score_samples(X.T)\nprob=np.exp(score)\nprint(prob/prob[6])\n</code></pre>\n\n<p>This code shows that the observations in the lowest probability density areas are observations 1,2 and 7. Of course this would work better with a larger sample, and you need to fuss with the bandwidth to calibrate it, but that this should do it.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15611",
            "_score": 5.430101,
            "_source": {
                "title": "Improve accuracy of Keras multiclass image classification with pretrained VGG16 conv_base",
                "content": "Improve accuracy of Keras multiclass image classification with pretrained VGG16 conv_base <p>In the moment, I'm training my first \"larger\" image classification model with Keras (22 classes, 2000 train samples, 500 val samples each class). I use a pretrained model (VGG16). My current model is a modified version of a sample code by F. Chollet (<a href=\"https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.3-using-a-pretrained-convnet.ipynb\" rel=\"nofollow noreferrer\">https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.3-using-a-pretrained-convnet.ipynb</a>).</p>\n\n<p><strong>Current results:</strong></p>\n\n<ul>\n<li>Validation accuracy is just over 80%</li>\n<li>Moderate tendence of overfitting observed (viz. validation loss is not going down any further after approx. 150 epochs)</li>\n<li>Consequently no further improvement in the validation accuracy</li>\n</ul>\n\n<p>I have tried a few things, such as increasing the capacity of the network and adding new/additional layers. However, by doing so, I was not able to improve the accuracy. </p>\n\n<p>Since model training takes quite some time, I would like to ask for tips, how to improve the model accuracy in this setting [Note: I can not increase the number of training samples per class].</p>\n\n<p><strong>So my question(s) are:</strong></p>\n\n<ol>\n<li>Accuracy: Is a validation accuracy of about 80% in this setting (22 classes) more on the \"okay\" side or not? What is a reasonable accuracy (or benchmark) in such a setting? I train on relatively distinct images, such as \"beach\", \"train\", \"car\", \"portrait\" etc.</li>\n<li>Model design: What would be the \"next obvious thing\" to improve the model accuracy? Is there a hyperparameter which I should change/target first (e.g. learning rate, batch size etc.)? Or should I (agressively) increase the capacity of the network? Or (agressively) add more layers?</li>\n<li>Pretrained models: Are there (noteable) differences in the pretrained models, viz. would it be worth to switch from VGG16 to some other model?</li>\n<li>Overfitting: To efficiently fight overfitting in image classification, is a i) more agressive dropout, ii) L2 regulation, or iii) batch layer normalization the best way to go?</li>\n</ol>\n\n<p>Any hints are highly apprechiated. If there is some sample code or online resource out there, would be great. Thanks!</p>\n\n<p><strong>Here is my current model in detail:</strong> </p>\n\n<pre><code>from keras.applications import VGG16\nimport os, datetime, statistics\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n###############################################\n# DIR with training images\nbase_dir = 'C:/kerasimages'\n# Number training images\nntrain = 2000\n# Number validation images\nnval  = 500\n# Batch size\nbatch_size = 20\n# Epochs fine tuning\nep = 600\n# Epochs first step\nep_first = 50\n# Number of classes (for training, output layer)\nnclasses = 22\n###############################################\n\nconv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'val')\n\ndatagen = ImageDataGenerator(rescale=1./255)\n\ndef extract_features(directory, sample_count):\n    features = np.zeros(shape=(sample_count, 4, 4, 512))\n    labels = np.zeros(shape=(sample_count))\n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='binary')\n    i = 0\n    for inputs_batch, labels_batch in generator:\n        features_batch = conv_base.predict(inputs_batch)\n        features[i * batch_size : (i + 1) * batch_size] = features_batch\n        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n        i += 1\n        if i * batch_size &gt;= sample_count:\n            break\n    return features, labels\n\n# Lables and features\ntrain_features, train_labels = extract_features(train_dir, ntrain)\nvalidation_features, validation_labels = extract_features(validation_dir, nval)\ntrain_labels = to_categorical(train_labels)\nvalidation_labels = to_categorical(validation_labels)\ntrain_features = np.reshape(train_features, (ntrain, 4 * 4 * 512))\nvalidation_features = np.reshape(validation_features, (nval, 4 * 4 * 512))\n\n#######################################\n# Model\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(2048, activation='relu'))#256\nmodel.add(Dropout(0.20))\nmodel.add(layers.Dense(1024, activation='relu'))#256\nmodel.add(Dropout(0.20))\nmodel.add(layers.Dense(512, activation='relu'))#256\nmodel.add(Dropout(0.20))\nmodel.add(layers.Dense(nclasses, activation='softmax'))\nconv_base.trainable = False\n\n#######################################\n# Data generators\ntrain_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='categorical')\n\n# Model compile / fit\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=2e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=ep_first,\n      validation_data=validation_generator,\n      validation_steps=50,\n      verbose=2)\n\n#######################################\n# Fine tuning\nconv_base.trainable = True\n\nset_trainable = False\nfor layer in conv_base.layers:\n    if layer.name == 'block5_conv1':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=ep,\n      validation_data=validation_generator,\n      validation_steps=50)\n</code></pre>\n <python><keras><image-classification><multiclass-classification><vgg16>",
                "codes": [],
                "question_id:": "52276",
                "question_votes:": "",
                "question_text:": "<p>In the moment, I'm training my first \"larger\" image classification model with Keras (22 classes, 2000 train samples, 500 val samples each class). I use a pretrained model (VGG16). My current model is a modified version of a sample code by F. Chollet (<a href=\"https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.3-using-a-pretrained-convnet.ipynb\" rel=\"nofollow noreferrer\">https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.3-using-a-pretrained-convnet.ipynb</a>).</p>\n\n<p><strong>Current results:</strong></p>\n\n<ul>\n<li>Validation accuracy is just over 80%</li>\n<li>Moderate tendence of overfitting observed (viz. validation loss is not going down any further after approx. 150 epochs)</li>\n<li>Consequently no further improvement in the validation accuracy</li>\n</ul>\n\n<p>I have tried a few things, such as increasing the capacity of the network and adding new/additional layers. However, by doing so, I was not able to improve the accuracy. </p>\n\n<p>Since model training takes quite some time, I would like to ask for tips, how to improve the model accuracy in this setting [Note: I can not increase the number of training samples per class].</p>\n\n<p><strong>So my question(s) are:</strong></p>\n\n<ol>\n<li>Accuracy: Is a validation accuracy of about 80% in this setting (22 classes) more on the \"okay\" side or not? What is a reasonable accuracy (or benchmark) in such a setting? I train on relatively distinct images, such as \"beach\", \"train\", \"car\", \"portrait\" etc.</li>\n<li>Model design: What would be the \"next obvious thing\" to improve the model accuracy? Is there a hyperparameter which I should change/target first (e.g. learning rate, batch size etc.)? Or should I (agressively) increase the capacity of the network? Or (agressively) add more layers?</li>\n<li>Pretrained models: Are there (noteable) differences in the pretrained models, viz. would it be worth to switch from VGG16 to some other model?</li>\n<li>Overfitting: To efficiently fight overfitting in image classification, is a i) more agressive dropout, ii) L2 regulation, or iii) batch layer normalization the best way to go?</li>\n</ol>\n\n<p>Any hints are highly apprechiated. If there is some sample code or online resource out there, would be great. Thanks!</p>\n\n<p><strong>Here is my current model in detail:</strong> </p>\n\n<pre><code>from keras.applications import VGG16\nimport os, datetime, statistics\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n###############################################\n# DIR with training images\nbase_dir = 'C:/kerasimages'\n# Number training images\nntrain = 2000\n# Number validation images\nnval  = 500\n# Batch size\nbatch_size = 20\n# Epochs fine tuning\nep = 600\n# Epochs first step\nep_first = 50\n# Number of classes (for training, output layer)\nnclasses = 22\n###############################################\n\nconv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'val')\n\ndatagen = ImageDataGenerator(rescale=1./255)\n\ndef extract_features(directory, sample_count):\n    features = np.zeros(shape=(sample_count, 4, 4, 512))\n    labels = np.zeros(shape=(sample_count))\n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='binary')\n    i = 0\n    for inputs_batch, labels_batch in generator:\n        features_batch = conv_base.predict(inputs_batch)\n        features[i * batch_size : (i + 1) * batch_size] = features_batch\n        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n        i += 1\n        if i * batch_size &gt;= sample_count:\n            break\n    return features, labels\n\n# Lables and features\ntrain_features, train_labels = extract_features(train_dir, ntrain)\nvalidation_features, validation_labels = extract_features(validation_dir, nval)\ntrain_labels = to_categorical(train_labels)\nvalidation_labels = to_categorical(validation_labels)\ntrain_features = np.reshape(train_features, (ntrain, 4 * 4 * 512))\nvalidation_features = np.reshape(validation_features, (nval, 4 * 4 * 512))\n\n#######################################\n# Model\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(2048, activation='relu'))#256\nmodel.add(Dropout(0.20))\nmodel.add(layers.Dense(1024, activation='relu'))#256\nmodel.add(Dropout(0.20))\nmodel.add(layers.Dense(512, activation='relu'))#256\nmodel.add(Dropout(0.20))\nmodel.add(layers.Dense(nclasses, activation='softmax'))\nconv_base.trainable = False\n\n#######################################\n# Data generators\ntrain_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='categorical')\n\n# Model compile / fit\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=2e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=ep_first,\n      validation_data=validation_generator,\n      validation_steps=50,\n      verbose=2)\n\n#######################################\n# Fine tuning\nconv_base.trainable = True\n\nset_trainable = False\nfor layer in conv_base.layers:\n    if layer.name == 'block5_conv1':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=ep,\n      validation_data=validation_generator,\n      validation_steps=50)\n</code></pre>\n",
                "tags": "<python><keras><image-classification><multiclass-classification><vgg16>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16917",
            "_score": 5.430101,
            "_source": {
                "title": "Replication of Andrew Ng's Sparse Autoencoder",
                "content": "Replication of Andrew Ng's Sparse Autoencoder <p>for the past three days I have been trying to replicate the results presented in Andrew Ng's sparse autoencoding lecture (<a href=\"https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf\" rel=\"nofollow noreferrer\">https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf</a>) however I have been unable to do this. I'm sure I have implemented the algorithm to the T. I am using a dataset of natural images of faces (yes I've tried CIFAR10 and CIFAR100 as well). If anyone has experience replicating the paper or could help me debug that would be greatly appreciated! I am not seeing the gabor filters that Andrew shows on the last page of the paper!</p>\n\n<pre><code>import torch.nn as nn\nimport torch\nimport torch.optim as optim\nfrom PIL import Image\nimport torchvision.transforms.functional as TF\nimport numpy as np\nfrom torch.optim.lr_scheduler import StepLR\nimport os\nimport math\nfrom skimage.io import imread\nfrom random import randint\n\n#Gets random patches from RGB images then returns matrix of vectorized grayscale\n# [N samples, M pixels] E.G. [10_000, 100]\ndef get(data_dir, patch_size=10, num_samples=10_000):\n\n    samples = []\n\n    dirs = [file for file in os.listdir(data_dir)]\n    num_patches_per_sample = math.ceil(num_samples / len(dirs))\n    for sub_dir_idx in range(len(dirs)):\n        #Read in image\n        imgOrg = imread(os.path.join(data_dir, dirs[sub_dir_idx]))\n        for i in range(num_patches_per_sample):\n            rand_x = randint(0, imgOrg.shape[0] - patch_size)\n            rand_y = randint(0, imgOrg.shape[1] - patch_size)\n            img = Image.fromarray(imgOrg[rand_x:rand_x + patch_size, rand_y:rand_y + patch_size, :])\n            img = TF.to_grayscale(img)\n            img = np.array(img)\n            samples.append(np.reshape(img, [-1]))\n\n    return torch.as_tensor(samples, dtype=torch.float) / 255\n\n#Normalizes input by subtracting out the mean\ndef normalize(samples):\n    for sample in samples:\n        sample -= sample.mean()\n    return samples\n\ndef zca_whitening_matrix(X):\n    \"\"\"\n    Function to compute ZCA whitening matrix (aka Mahalanobis whitening).\n    INPUT:  X: [M x N] matrix.\n        Rows: Variables\n        Columns: Observations\n    OUTPUT: ZCAMatrix: [M x M] matrix\n    \"\"\"\n    # Covariance matrix [column-wise variables]: Sigma = (X-mu)' * (X-mu) / N\n    sigma = np.cov(X, rowvar=True) # [M x M]\n    # Singular Value Decomposition. X = U * np.diag(S) * V\n    U,S,V = np.linalg.svd(sigma)\n        # U: [M x M] eigenvectors of sigma.\n        # S: [M x 1] eigenvalues of sigma.\n        # V: [M x M] transpose of U\n    # Whitening constant: prevents division by zero\n    epsilon = 1e-5\n    # ZCA Whitening matrix: U * Lambda * U'\n    ZCAMatrix = np.dot(U, np.dot(np.diag(1.0/np.sqrt(S + epsilon)), U.T)) # [M x M]\n    return ZCAMatrix\n\n#Autoencoder\nclass AE(nn.Module):\n    def __init__(self, in_features, h_features):\n        super(AE, self).__init__()\n        self.f1 = nn.Linear(in_features, h_features)\n        self.f2 = nn.Linear(h_features, in_features)\n\n    def forward(self, x):\n        x = self.f1(x)\n        encoded = torch.sigmoid(x)\n        decoded = self.f2(encoded)\n        return (encoded, decoded)\n\n\n#Get data\nsamples = get('D:\\sparseHMAX-v1.2\\data\\Faces_easy')\nsamples = normalize(samples)\n\n#Transpose for ZCA whitening\nsamples = samples.t()\n#Whiten\nzmat = zca_whitening_matrix(samples)\n#Project data onto zmap\nsamples = torch.matmul(torch.as_tensor(zmat).float(), samples)\n#Transpose back for training\nsamples = samples.t()\n\n#Use non-stochastic gradient descent\nbatch_size = len(samples)\n#Define autoencoders with 100 input and 100 hidden units\nnet = AE(100, 100)\n\nout_freq = max(int(5000 / batch_size), 1) #Freq of loss print out\noptimizer = optim.Adam(net.parameters(), lr=1e-2, amsgrad=True, weight_decay=0.001)\nscheduler = StepLR(optimizer, step_size=10_000, gamma=0.1)\nepochs = 50_000\nrho = 0.01 #Used to KL Div\nsparsity_lambda = 1e-1\nmin_loss = 1_000_000_000\n\nfor epoch in range(epochs):\n    running_loss = 0.0\n    running_MSE_loss = 0.0\n    running_KL_loss = 0.0\n    for i in range(int(len(samples) / batch_size)):\n        x = samples[i * batch_size:(i + 1) * batch_size]\n        h, y = net(x.float())\n\n        #Calculate KL Div\n        p_hat = h.mean(0)\n\n        kl_div = torch.sum(rho * (rho / p_hat).log() + (1 - rho) * ((1 - rho) / (1 - p_hat)).log())\n        MSE_loss = torch.sum((y - x.float())**2) / batch_size / 2\n        KL_loss = sparsity_lambda * kl_div\n        loss = MSE_loss + KL_loss\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss\n        running_KL_loss += KL_loss\n        running_MSE_loss += MSE_loss\n\n        if (i + 1)%out_freq == 0:\n            latest_loss = running_loss / out_freq\n            print(\"[%d, %5d] loss: %.10f\" % (epoch + 1, i + 1, latest_loss))\n            print(\"M: %.5f \\t R: %.5f \\t RR: %.5f\" % (running_MSE_loss / out_freq, running_KL_loss / out_freq, running_KL_loss / out_freq / sparsity_lambda))\n            if latest_loss &lt; min_loss:\n                torch.save(net, './netKL')\n                torch.save(optimizer, './optimKL')\n                min_loss = latest_loss\n            running_loss = 0\n            running_MSE_loss = 0\n            running_KL_loss = 0\n    scheduler.step()\n\n#Plot filters\nimport matplotlib.pyplot as plt\nweights = list(net.parameters())[0].detach().to('cpu')\nfig = plt.figure(figsize=(40, 40))\nfor i in range(weights.shape[0]):\n    filt = torch.reshape(weights[i,:], [10, 10])\n    filt = filt / torch.sqrt(torch.sum(filt**2))\n    ax = fig.add_subplot(10, 10, i + 1)\n    ax.imshow(filt, cmap='Greys')\n\nfig.savefig('./filtersGreyKLDivCIFAR10-b' + str(sparsity_lambda) + '.png')\nplt.close(fig)\n</code></pre>\n <autoencoder><pytorch><features>",
                "codes": [],
                "question_id:": "55105",
                "question_votes:": "",
                "question_text:": "<p>for the past three days I have been trying to replicate the results presented in Andrew Ng's sparse autoencoding lecture (<a href=\"https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf\" rel=\"nofollow noreferrer\">https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf</a>) however I have been unable to do this. I'm sure I have implemented the algorithm to the T. I am using a dataset of natural images of faces (yes I've tried CIFAR10 and CIFAR100 as well). If anyone has experience replicating the paper or could help me debug that would be greatly appreciated! I am not seeing the gabor filters that Andrew shows on the last page of the paper!</p>\n\n<pre><code>import torch.nn as nn\nimport torch\nimport torch.optim as optim\nfrom PIL import Image\nimport torchvision.transforms.functional as TF\nimport numpy as np\nfrom torch.optim.lr_scheduler import StepLR\nimport os\nimport math\nfrom skimage.io import imread\nfrom random import randint\n\n#Gets random patches from RGB images then returns matrix of vectorized grayscale\n# [N samples, M pixels] E.G. [10_000, 100]\ndef get(data_dir, patch_size=10, num_samples=10_000):\n\n    samples = []\n\n    dirs = [file for file in os.listdir(data_dir)]\n    num_patches_per_sample = math.ceil(num_samples / len(dirs))\n    for sub_dir_idx in range(len(dirs)):\n        #Read in image\n        imgOrg = imread(os.path.join(data_dir, dirs[sub_dir_idx]))\n        for i in range(num_patches_per_sample):\n            rand_x = randint(0, imgOrg.shape[0] - patch_size)\n            rand_y = randint(0, imgOrg.shape[1] - patch_size)\n            img = Image.fromarray(imgOrg[rand_x:rand_x + patch_size, rand_y:rand_y + patch_size, :])\n            img = TF.to_grayscale(img)\n            img = np.array(img)\n            samples.append(np.reshape(img, [-1]))\n\n    return torch.as_tensor(samples, dtype=torch.float) / 255\n\n#Normalizes input by subtracting out the mean\ndef normalize(samples):\n    for sample in samples:\n        sample -= sample.mean()\n    return samples\n\ndef zca_whitening_matrix(X):\n    \"\"\"\n    Function to compute ZCA whitening matrix (aka Mahalanobis whitening).\n    INPUT:  X: [M x N] matrix.\n        Rows: Variables\n        Columns: Observations\n    OUTPUT: ZCAMatrix: [M x M] matrix\n    \"\"\"\n    # Covariance matrix [column-wise variables]: Sigma = (X-mu)' * (X-mu) / N\n    sigma = np.cov(X, rowvar=True) # [M x M]\n    # Singular Value Decomposition. X = U * np.diag(S) * V\n    U,S,V = np.linalg.svd(sigma)\n        # U: [M x M] eigenvectors of sigma.\n        # S: [M x 1] eigenvalues of sigma.\n        # V: [M x M] transpose of U\n    # Whitening constant: prevents division by zero\n    epsilon = 1e-5\n    # ZCA Whitening matrix: U * Lambda * U'\n    ZCAMatrix = np.dot(U, np.dot(np.diag(1.0/np.sqrt(S + epsilon)), U.T)) # [M x M]\n    return ZCAMatrix\n\n#Autoencoder\nclass AE(nn.Module):\n    def __init__(self, in_features, h_features):\n        super(AE, self).__init__()\n        self.f1 = nn.Linear(in_features, h_features)\n        self.f2 = nn.Linear(h_features, in_features)\n\n    def forward(self, x):\n        x = self.f1(x)\n        encoded = torch.sigmoid(x)\n        decoded = self.f2(encoded)\n        return (encoded, decoded)\n\n\n#Get data\nsamples = get('D:\\sparseHMAX-v1.2\\data\\Faces_easy')\nsamples = normalize(samples)\n\n#Transpose for ZCA whitening\nsamples = samples.t()\n#Whiten\nzmat = zca_whitening_matrix(samples)\n#Project data onto zmap\nsamples = torch.matmul(torch.as_tensor(zmat).float(), samples)\n#Transpose back for training\nsamples = samples.t()\n\n#Use non-stochastic gradient descent\nbatch_size = len(samples)\n#Define autoencoders with 100 input and 100 hidden units\nnet = AE(100, 100)\n\nout_freq = max(int(5000 / batch_size), 1) #Freq of loss print out\noptimizer = optim.Adam(net.parameters(), lr=1e-2, amsgrad=True, weight_decay=0.001)\nscheduler = StepLR(optimizer, step_size=10_000, gamma=0.1)\nepochs = 50_000\nrho = 0.01 #Used to KL Div\nsparsity_lambda = 1e-1\nmin_loss = 1_000_000_000\n\nfor epoch in range(epochs):\n    running_loss = 0.0\n    running_MSE_loss = 0.0\n    running_KL_loss = 0.0\n    for i in range(int(len(samples) / batch_size)):\n        x = samples[i * batch_size:(i + 1) * batch_size]\n        h, y = net(x.float())\n\n        #Calculate KL Div\n        p_hat = h.mean(0)\n\n        kl_div = torch.sum(rho * (rho / p_hat).log() + (1 - rho) * ((1 - rho) / (1 - p_hat)).log())\n        MSE_loss = torch.sum((y - x.float())**2) / batch_size / 2\n        KL_loss = sparsity_lambda * kl_div\n        loss = MSE_loss + KL_loss\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss\n        running_KL_loss += KL_loss\n        running_MSE_loss += MSE_loss\n\n        if (i + 1)%out_freq == 0:\n            latest_loss = running_loss / out_freq\n            print(\"[%d, %5d] loss: %.10f\" % (epoch + 1, i + 1, latest_loss))\n            print(\"M: %.5f \\t R: %.5f \\t RR: %.5f\" % (running_MSE_loss / out_freq, running_KL_loss / out_freq, running_KL_loss / out_freq / sparsity_lambda))\n            if latest_loss &lt; min_loss:\n                torch.save(net, './netKL')\n                torch.save(optimizer, './optimKL')\n                min_loss = latest_loss\n            running_loss = 0\n            running_MSE_loss = 0\n            running_KL_loss = 0\n    scheduler.step()\n\n#Plot filters\nimport matplotlib.pyplot as plt\nweights = list(net.parameters())[0].detach().to('cpu')\nfig = plt.figure(figsize=(40, 40))\nfor i in range(weights.shape[0]):\n    filt = torch.reshape(weights[i,:], [10, 10])\n    filt = filt / torch.sqrt(torch.sum(filt**2))\n    ax = fig.add_subplot(10, 10, i + 1)\n    ax.imshow(filt, cmap='Greys')\n\nfig.savefig('./filtersGreyKLDivCIFAR10-b' + str(sparsity_lambda) + '.png')\nplt.close(fig)\n</code></pre>\n",
                "tags": "<autoencoder><pytorch><features>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9342",
            "_score": 5.37519,
            "_source": {
                "title": "autoencoder for features selection",
                "content": "autoencoder for features selection <p>I m using a data set with 41 features numerics and nominals the 42 one is the class (normal or not) first I changed all the nominals features to numeric since the autoencoder requires that the imput vector should be numeric. so the number of features incresed from 42 to 122. I removed the class colomn because AE use unlabelled data and I used it to reduce dimensionality from 121 to 10 ( 121> 50->10->50-121) now I want to build a MLP to classify the data I divided the data set into 3 parts: train, validate and test set, I want to put the 10 features selected by the AE instead of the 121 but I dont know how (code?). and how add the class colomn again to the data set to do a supervised classification with MLP?\n<a href=\"https://i.stack.imgur.com/DQVCv.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/DQVCv.png\" alt=\"enter image description here\"></a></p>\n <machine-learning><python><deep-learning><keras><tensorflow><p>An autoencoder is meant to do exactly what you are asking. It is a means to take an input feature vector with $m$ values, $X \\in \\mathbb{R}^m$ and compress it into a vector $z \\in \\mathbb{R}^n$ when $n &lt; m$. To do this we will design a network that is compressed in the middle such that it looks this.</p>\n\n<p><a href=\"https://i.stack.imgur.com/VXwGF.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/VXwGF.png\" alt=\"enter image description here\"></a></p>\n\n<p>We train this network by comparing the output $X'$ to the input $X$. This will cause $X'$ to tend towards $X$, thus despite the feature compression in the network, the output will preserve sufficient information about the input such that the input $X$ can be recovered.</p>\n\n<p>Once this network is trained, we can then truncate everything after the layer which outputs the vector $z$. Then you can use the feature vector $z$ as the input features to train a different neural network which you can use to classify your instances as normal or not. During this process you will NOT tune any of the weights of the autoencoder. It will only be used as a feed-forward network. </p>\n\n<hr>\n\n<h1>The autoencoder</h1>\n\n<p>We will train an autoencoder on the MNIST dataset. </p>\n\n<p>First we will download all the data </p>\n\n<pre><code>from keras.datasets import mnist\nimport numpy as np\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\n\nprint('Training data shape: ', x_train.shape)\nprint('Testing data shape : ', x_test.shape)\n</code></pre>\n\n<blockquote>\n  <p>Training data shape:  (60000, 28, 28) <br/>Testing data shape :  (10000,\n  28, 28)</p>\n</blockquote>\n\n<p>Let us see the distribution of our output classes for the MNIST data</p>\n\n<pre><code>import matplotlib.pyplot as plt\n%matplotlib inline\n\ntraining_counts = [None] * 10 \ntesting_counts = [None] * 10\nfor i in range(10):\n    training_counts[i] = len(y_train[y_train == i])/len(y_train)\n    testing_counts[i] = len(y_test[y_test == i])/len(y_test)\n\n# the histogram of the data\ntrain_bar = plt.bar(np.arange(10)-0.2, training_counts, align='center', color = 'r', alpha=0.75, width = 0.41, label='Training')\ntest_bar = plt.bar(np.arange(10)+0.2, testing_counts, align='center', color = 'b', alpha=0.75, width = 0.41, label = 'Testing')\n\nplt.xlabel('Labels')\nplt.xticks((0,1,2,3,4,5,6,7,8,9))\nplt.ylabel('Count (%)')\nplt.title('Label distribution in the training and test set')\nplt.legend(bbox_to_anchor=(1.05, 1), handles=[train_bar, test_bar], loc=2)\nplt.grid(True)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/EmxRB.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/EmxRB.png\" alt=\"enter image description here\"></a></p>\n\n<p>Let us look at some examples of the MNIST dataset</p>\n\n<pre><code>import matplotlib.pyplot as plt\n%matplotlib inline\n\n# utility function for showing images\ndef show_imgs(x_test, decoded_imgs=None, n=10):\n    plt.figure(figsize=(20, 4))\n    for i in range(n):\n        ax = plt.subplot(2, n, i+1)\n        plt.imshow(x_test[i].reshape(28,28))\n        plt.gray()\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n        if decoded_imgs is not None:\n            ax = plt.subplot(2, n, i+ 1 +n)\n            plt.imshow(decoded_imgs[i].reshape(28,28))\n            plt.gray()\n            ax.get_xaxis().set_visible(False)\n            ax.get_yaxis().set_visible(False)\n    plt.show()\n\nshow_imgs(x_train, x_test)\nprint('Training labels: ', y_train[0:10])\nprint('Testing labels : ', y_test[0:10])\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/hEnve.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/hEnve.png\" alt=\"enter image description here\"></a></p>\n\n<blockquote>\n  <p>Training labels:  [5 0 4 1 9 2 1 3 1 4] <br/>Testing labels :  [7 2 1 0 4 1 4 9 5 9]</p>\n</blockquote>\n\n<p>These are some imports we will use or not for making our model. Note: not all of these are needed but I'm too lazy to sift through and pick the useful ones.</p>\n\n<pre><code>from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\nfrom keras.models import Model\nfrom keras import backend as K\n</code></pre>\n\n<p>Let us build our model. Notice we have the encoder, this maps the input from the higher dimension to the constrained dimension in the middle of the network. It goes from a vector of dimension 784 at the input to a vector $z$ of dimension 128. Then we have a decoder that is a mirror of the encoder which will try to decompress the vector $z$.</p>\n\n<pre><code>input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n</code></pre>\n\n<p>input_img = Input(shape=(28, 28, 1))  # adapt this if using <code>channels_first</code> image data format</p>\n\n<pre><code>x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nencoded = MaxPooling2D((2, 2), padding='same')(x)\n\n# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(16, (3, 3), activation='relu')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\nautoencoder = Model(input_img, decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n</code></pre>\n\n<p>You can see a description of the model using </p>\n\n<pre><code>autoencoder.summary()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/uQPGH.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/uQPGH.png\" alt=\"enter image description here\"></a></p>\n\n<p>Now let us train this model</p>\n\n<pre><code>from keras.callbacks import TensorBoard\nepochs = 50\nbatch_size = 128\n\nautoencoder.fit(x_train_reshaped, x_train_reshaped, epochs=epochs, batch_size=batch_size,\n               shuffle=True, validation_data=(x_test_reshaped, x_test_reshaped), verbose=1,\n               callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n</code></pre>\n\n<p>This will take a while. I will get back to you when it is done training. However, once this is done we will take the autoencoder model and we will separate the encoder and decoder part. We will trash away the decoder and only use the encoder. </p>\n\n<p>Then we will use that as a forefront to any model we want to use to classify these digits. We will pass every image through our encoder, to get this compressed information vector $z$ and we will use that as the input to our classification model. </p>\n\n<h1>The classifier</h1>\n\n<p>The classification model will then look something like</p>\n\n<pre><code># The known number of output classes.\nnum_classes = 10\n\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test_reshaped = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n</code></pre>\n\n<p>The classification model</p>\n\n<pre><code>model  ==  Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<p>We will train the classification model</p>\n\n<pre><code># Save the model# Save t \nmodel_json = model.to_json()\nwith open(\"weights/model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\n# Save the weights using a checkpoint.\nfilepath=\"weights/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n\nepochs = 100\nbatch_size = 128\n# Fit the model weights.\nmodel.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          callbacks=callbacks_list,\n          validation_data=(x_test_reshaped, y_test_binary))\n\nscore = model.evaluate(x_test_reshaped, y_test_binary, verbose=0)\nprint('Model accuracy:')\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n\nprint('Predict the classes: ')\nprediction = model.predict_classes(x_test_reshaped[0:10])\nshow_imgs(x_test)\nprint('Predicted classes: ', prediction)\n</code></pre>\n",
                "codes": [
                    [
                        "from keras.datasets import mnist\nimport numpy as np\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\n\nprint('Training data shape: ', x_train.shape)\nprint('Testing data shape : ', x_test.shape)\n",
                        "import matplotlib.pyplot as plt\n%matplotlib inline\n\ntraining_counts = [None] * 10 \ntesting_counts = [None] * 10\nfor i in range(10):\n    training_counts[i] = len(y_train[y_train == i])/len(y_train)\n    testing_counts[i] = len(y_test[y_test == i])/len(y_test)\n\n# the histogram of the data\ntrain_bar = plt.bar(np.arange(10)-0.2, training_counts, align='center', color = 'r', alpha=0.75, width = 0.41, label='Training')\ntest_bar = plt.bar(np.arange(10)+0.2, testing_counts, align='center', color = 'b', alpha=0.75, width = 0.41, label = 'Testing')\n\nplt.xlabel('Labels')\nplt.xticks((0,1,2,3,4,5,6,7,8,9))\nplt.ylabel('Count (%)')\nplt.title('Label distribution in the training and test set')\nplt.legend(bbox_to_anchor=(1.05, 1), handles=[train_bar, test_bar], loc=2)\nplt.grid(True)\nplt.show()\n",
                        "import matplotlib.pyplot as plt\n%matplotlib inline\n\n# utility function for showing images\ndef show_imgs(x_test, decoded_imgs=None, n=10):\n    plt.figure(figsize=(20, 4))\n    for i in range(n):\n        ax = plt.subplot(2, n, i+1)\n        plt.imshow(x_test[i].reshape(28,28))\n        plt.gray()\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n        if decoded_imgs is not None:\n            ax = plt.subplot(2, n, i+ 1 +n)\n            plt.imshow(decoded_imgs[i].reshape(28,28))\n            plt.gray()\n            ax.get_xaxis().set_visible(False)\n            ax.get_yaxis().set_visible(False)\n    plt.show()\n\nshow_imgs(x_train, x_test)\nprint('Training labels: ', y_train[0:10])\nprint('Testing labels : ', y_test[0:10])\n",
                        "from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\nfrom keras.models import Model\nfrom keras import backend as K\n",
                        "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
                        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nencoded = MaxPooling2D((2, 2), padding='same')(x)\n\n# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(16, (3, 3), activation='relu')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\nautoencoder = Model(input_img, decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
                        "autoencoder.summary()\n",
                        "from keras.callbacks import TensorBoard\nepochs = 50\nbatch_size = 128\n\nautoencoder.fit(x_train_reshaped, x_train_reshaped, epochs=epochs, batch_size=batch_size,\n               shuffle=True, validation_data=(x_test_reshaped, x_test_reshaped), verbose=1,\n               callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n",
                        "# The known number of output classes.\nnum_classes = 10\n\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test_reshaped = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n",
                        "model  ==  Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n",
                        "# Save the model# Save t \nmodel_json = model.to_json()\nwith open(\"weights/model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\n# Save the weights using a checkpoint.\nfilepath=\"weights/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n\nepochs = 100\nbatch_size = 128\n# Fit the model weights.\nmodel.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          callbacks=callbacks_list,\n          validation_data=(x_test_reshaped, y_test_binary))\n\nscore = model.evaluate(x_test_reshaped, y_test_binary, verbose=0)\nprint('Model accuracy:')\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n\nprint('Predict the classes: ')\nprediction = model.predict_classes(x_test_reshaped[0:10])\nshow_imgs(x_test)\nprint('Predicted classes: ', prediction)\n"
                    ]
                ],
                "question_id:": "33338",
                "question_votes:": "2",
                "question_text:": "<p>I m using a data set with 41 features numerics and nominals the 42 one is the class (normal or not) first I changed all the nominals features to numeric since the autoencoder requires that the imput vector should be numeric. so the number of features incresed from 42 to 122. I removed the class colomn because AE use unlabelled data and I used it to reduce dimensionality from 121 to 10 ( 121> 50->10->50-121) now I want to build a MLP to classify the data I divided the data set into 3 parts: train, validate and test set, I want to put the 10 features selected by the AE instead of the 121 but I dont know how (code?). and how add the class colomn again to the data set to do a supervised classification with MLP?\n<a href=\"https://i.stack.imgur.com/DQVCv.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/DQVCv.png\" alt=\"enter image description here\"></a></p>\n",
                "tags": "<machine-learning><python><deep-learning><keras><tensorflow>",
                "answers": [
                    [
                        "33342",
                        "2",
                        "33338",
                        "",
                        "",
                        "<p>An autoencoder is meant to do exactly what you are asking. It is a means to take an input feature vector with $m$ values, $X \\in \\mathbb{R}^m$ and compress it into a vector $z \\in \\mathbb{R}^n$ when $n &lt; m$. To do this we will design a network that is compressed in the middle such that it looks this.</p>\n\n<p><a href=\"https://i.stack.imgur.com/VXwGF.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/VXwGF.png\" alt=\"enter image description here\"></a></p>\n\n<p>We train this network by comparing the output $X'$ to the input $X$. This will cause $X'$ to tend towards $X$, thus despite the feature compression in the network, the output will preserve sufficient information about the input such that the input $X$ can be recovered.</p>\n\n<p>Once this network is trained, we can then truncate everything after the layer which outputs the vector $z$. Then you can use the feature vector $z$ as the input features to train a different neural network which you can use to classify your instances as normal or not. During this process you will NOT tune any of the weights of the autoencoder. It will only be used as a feed-forward network. </p>\n\n<hr>\n\n<h1>The autoencoder</h1>\n\n<p>We will train an autoencoder on the MNIST dataset. </p>\n\n<p>First we will download all the data </p>\n\n<pre><code>from keras.datasets import mnist\nimport numpy as np\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\n\nprint('Training data shape: ', x_train.shape)\nprint('Testing data shape : ', x_test.shape)\n</code></pre>\n\n<blockquote>\n  <p>Training data shape:  (60000, 28, 28) <br/>Testing data shape :  (10000,\n  28, 28)</p>\n</blockquote>\n\n<p>Let us see the distribution of our output classes for the MNIST data</p>\n\n<pre><code>import matplotlib.pyplot as plt\n%matplotlib inline\n\ntraining_counts = [None] * 10 \ntesting_counts = [None] * 10\nfor i in range(10):\n    training_counts[i] = len(y_train[y_train == i])/len(y_train)\n    testing_counts[i] = len(y_test[y_test == i])/len(y_test)\n\n# the histogram of the data\ntrain_bar = plt.bar(np.arange(10)-0.2, training_counts, align='center', color = 'r', alpha=0.75, width = 0.41, label='Training')\ntest_bar = plt.bar(np.arange(10)+0.2, testing_counts, align='center', color = 'b', alpha=0.75, width = 0.41, label = 'Testing')\n\nplt.xlabel('Labels')\nplt.xticks((0,1,2,3,4,5,6,7,8,9))\nplt.ylabel('Count (%)')\nplt.title('Label distribution in the training and test set')\nplt.legend(bbox_to_anchor=(1.05, 1), handles=[train_bar, test_bar], loc=2)\nplt.grid(True)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/EmxRB.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/EmxRB.png\" alt=\"enter image description here\"></a></p>\n\n<p>Let us look at some examples of the MNIST dataset</p>\n\n<pre><code>import matplotlib.pyplot as plt\n%matplotlib inline\n\n# utility function for showing images\ndef show_imgs(x_test, decoded_imgs=None, n=10):\n    plt.figure(figsize=(20, 4))\n    for i in range(n):\n        ax = plt.subplot(2, n, i+1)\n        plt.imshow(x_test[i].reshape(28,28))\n        plt.gray()\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n        if decoded_imgs is not None:\n            ax = plt.subplot(2, n, i+ 1 +n)\n            plt.imshow(decoded_imgs[i].reshape(28,28))\n            plt.gray()\n            ax.get_xaxis().set_visible(False)\n            ax.get_yaxis().set_visible(False)\n    plt.show()\n\nshow_imgs(x_train, x_test)\nprint('Training labels: ', y_train[0:10])\nprint('Testing labels : ', y_test[0:10])\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/hEnve.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/hEnve.png\" alt=\"enter image description here\"></a></p>\n\n<blockquote>\n  <p>Training labels:  [5 0 4 1 9 2 1 3 1 4] <br/>Testing labels :  [7 2 1 0 4 1 4 9 5 9]</p>\n</blockquote>\n\n<p>These are some imports we will use or not for making our model. Note: not all of these are needed but I'm too lazy to sift through and pick the useful ones.</p>\n\n<pre><code>from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\nfrom keras.models import Model\nfrom keras import backend as K\n</code></pre>\n\n<p>Let us build our model. Notice we have the encoder, this maps the input from the higher dimension to the constrained dimension in the middle of the network. It goes from a vector of dimension 784 at the input to a vector $z$ of dimension 128. Then we have a decoder that is a mirror of the encoder which will try to decompress the vector $z$.</p>\n\n<pre><code>input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n</code></pre>\n\n<p>input_img = Input(shape=(28, 28, 1))  # adapt this if using <code>channels_first</code> image data format</p>\n\n<pre><code>x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nencoded = MaxPooling2D((2, 2), padding='same')(x)\n\n# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(16, (3, 3), activation='relu')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\nautoencoder = Model(input_img, decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n</code></pre>\n\n<p>You can see a description of the model using </p>\n\n<pre><code>autoencoder.summary()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/uQPGH.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/uQPGH.png\" alt=\"enter image description here\"></a></p>\n\n<p>Now let us train this model</p>\n\n<pre><code>from keras.callbacks import TensorBoard\nepochs = 50\nbatch_size = 128\n\nautoencoder.fit(x_train_reshaped, x_train_reshaped, epochs=epochs, batch_size=batch_size,\n               shuffle=True, validation_data=(x_test_reshaped, x_test_reshaped), verbose=1,\n               callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n</code></pre>\n\n<p>This will take a while. I will get back to you when it is done training. However, once this is done we will take the autoencoder model and we will separate the encoder and decoder part. We will trash away the decoder and only use the encoder. </p>\n\n<p>Then we will use that as a forefront to any model we want to use to classify these digits. We will pass every image through our encoder, to get this compressed information vector $z$ and we will use that as the input to our classification model. </p>\n\n<h1>The classifier</h1>\n\n<p>The classification model will then look something like</p>\n\n<pre><code># The known number of output classes.\nnum_classes = 10\n\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# Channels go last for TensorFlow backend\nx_train_reshaped = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test_reshaped = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n</code></pre>\n\n<p>The classification model</p>\n\n<pre><code>model  ==  Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n</code></pre>\n\n<p>We will train the classification model</p>\n\n<pre><code># Save the model# Save t \nmodel_json = model.to_json()\nwith open(\"weights/model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\n# Save the weights using a checkpoint.\nfilepath=\"weights/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n\nepochs = 100\nbatch_size = 128\n# Fit the model weights.\nmodel.fit(x_train_reshaped, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          callbacks=callbacks_list,\n          validation_data=(x_test_reshaped, y_test_binary))\n\nscore = model.evaluate(x_test_reshaped, y_test_binary, verbose=0)\nprint('Model accuracy:')\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n\nprint('Predict the classes: ')\nprediction = model.predict_classes(x_test_reshaped[0:10])\nshow_imgs(x_test)\nprint('Predicted classes: ', prediction)\n</code></pre>\n",
                        "",
                        "9"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "8176",
            "_score": 5.3442507,
            "_source": {
                "title": "How to Save TensorFlow model using estimator.export_savemodel()",
                "content": "How to Save TensorFlow model using estimator.export_savemodel() <p>How can i <strong>Save</strong> the <strong>TensorFlow model</strong> using <code>estimator.export_savedmode()</code> ?</p>\n\n<p>Especially, what should i put inside the <code>serving_input_receiver_fn()</code>?</p>\n\n<p>I have created a Custom Estimator based on VGGNet Architecture, i am using my own images and doing some transformation (you can see them in <code>_parse_function()</code>) on the images.</p>\n\n<p>I have read the documentation <a href=\"https://www.tensorflow.org/programmers_guide/saved_model\" rel=\"nofollow noreferrer\">here</a>, but i am exactly not sure what to write for my code (please see below). Ultimately i want to save the model and use TensorFlow Serving.</p>\n\n<pre><code>    from __future__ import absolute_import\n    from __future__ import division\n    from __future__ import print_function\n\n    import tensorflow as tf\n    import numpy as np\n    from sklearn.model_selection import train_test_split\n    import os\n    import matplotlib.pyplot as plt\n    import matplotlib.image as mpimg\n    import scipy\n    from scipy import ndimage\n    import scipy.misc\n\n    tf.logging.set_verbosity(tf.logging.INFO)\n\n    def cnn_model_fn(features, labels, mode):\n        \"\"\"Model function for CNN.\"\"\"\n        # Input Layer\n        input_layer = tf.reshape(features, [-1, 224, 224, 3])\n\n    # Convolutional Layer #1\n    conv1 = tf.layers.conv2d(\n      inputs=input_layer,\n      filters=64,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n    # Convolutional Layer #2\n    conv2 = tf.layers.conv2d(\n      inputs=conv1,\n      filters=64,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n    # Pooling Layer #1\n    pool1 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n\n    # Convolutional Layer #3\n    conv3 = tf.layers.conv2d(\n      inputs=pool1,\n      filters=128,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    # Convolutional Layer #4\n    conv4 = tf.layers.conv2d(\n      inputs=conv3,\n      filters=128,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n    pool2 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)\n\n    # Convolutional Layer #5\n    conv5 = tf.layers.conv2d(\n      inputs=pool2,\n      filters=256,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    # Convolutional Layer #6\n    conv6 = tf.layers.conv2d(\n      inputs=conv5,\n      filters=256,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    # Convolutional Layer #7\n    conv7 = tf.layers.conv2d(\n      inputs=conv6,\n      filters=256,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    pool3 = tf.layers.max_pooling2d(inputs=conv7, pool_size=[2, 2], strides=2)\n\n    # Convolutional Layer #8\n    conv8 = tf.layers.conv2d(\n      inputs=pool3,\n      filters=512,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    # Convolutional Layer #9\n    conv9 = tf.layers.conv2d(\n      inputs=conv8,\n      filters=512,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    # Convolutional Layer #10\n    conv10 = tf.layers.conv2d(\n      inputs=conv9,\n      filters=512,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n    pool4 = tf.layers.max_pooling2d(inputs=conv10, pool_size=[2, 2], strides=2)\n\n    # Convolutional Layer #11\n    conv11 = tf.layers.conv2d(\n      inputs=pool4,\n      filters=512,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    # Convolutional Layer #12\n    conv12 = tf.layers.conv2d(\n      inputs=conv11,\n      filters=512,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    # Convolutional Layer #12\n    conv13 = tf.layers.conv2d(\n      inputs=conv12,\n      filters=512,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    pool5 = tf.layers.max_pooling2d(inputs=conv13, pool_size=[2, 2], strides=2)\n    # Dense Layer\n    pool5_flat = tf.reshape(pool5, [-1, 7 * 7 * 512])\n    dense1 = tf.layers.dense(inputs=pool5_flat, units=4096, activation=tf.nn.relu)\n    dense2 = tf.layers.dense(inputs=dense1, units=4096, activation=tf.nn.relu)\n    dense3 = tf.layers.dense(inputs=dense2, units=1024, activation=tf.nn.relu)\n\n    dropout = tf.layers.dropout(\n      inputs=dense3, rate=0.001, training=mode == tf.estimator.ModeKeys.TRAIN)\n\n    logits1 = tf.layers.dense(inputs=dropout, units=2)\n    logits2 = tf.layers.dense(inputs=dropout, units=4)\n\n    predictions = {\n        \"classes1\": tf.argmax(input=logits1, axis=1),\n        \"classes2\": tf.argmax(input=logits2, axis=1),\n        \"probabilities1\": tf.nn.softmax(logits1, name=\"softmax_tensor_1\"),\n        \"probabilities2\": tf.nn.softmax(logits2, name=\"softmax_tensor_2\")\n    }\n\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n    # Calculate Loss (for both TRAIN and EVAL modes)\n    loss1 = tf.losses.sparse_softmax_cross_entropy(labels=labels[:,0], logits=logits1)\n    loss2 = tf.losses.sparse_softmax_cross_entropy(labels=labels[:,1], logits=logits2)\n    loss = loss1 + loss2\n\n    # Configure the Training Op (for TRAIN mode)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n        train_op = optimizer.minimize(\n            loss=loss,\n            global_step=tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n    # Add evaluation metrics (for EVAL mode)\n    eval_metric_ops = {\n        \"accuracy1\": tf.metrics.accuracy(\n            labels=labels[:,0], predictions=predictions[\"classes1\"]),\n        \"accuracy2\": tf.metrics.accuracy(\n            labels=labels[:,1], predictions=predictions[\"classes2\"]),\n        \"precision1\": tf.metrics.precision(labels=labels[:,0], predictions=predictions[\"classes1\"]),\n        \"precision2\": tf.metrics.precision(labels=labels[:,1], predictions=predictions[\"classes2\"]),\n        \"recall1\": tf.metrics.recall(labels=labels[:,0], predictions=predictions[\"classes1\"]),\n        \"recall2\": tf.metrics.recall(labels=labels[:,1], predictions=predictions[\"classes2\"])\n    }\n\n    return tf.estimator.EstimatorSpec(\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n\n    def _parse_function(filename, label):\n        image_string = tf.read_file(filename)\n        image_decoded = tf.image.decode_image(image_string)\n        image_typecasted = tf.cast(image_decoded, tf.float32)\n        image_reshaped = tf.reshape(image_typecasted, [-1, 224, 224, 3])\n        return image_reshaped, label\n\n    def _parse_function(filename):\n        image_string = tf.read_file(filename)\n        image_decoded = tf.image.decode_image(image_string)\n        image_typecasted = tf.cast(image_decoded, tf.float32)\n        image_reshaped = tf.reshape(image_typecasted, [-1, 224, 224, 3])\n        return image_reshaped\n\n    def stratified_train_test_split_():\n        filenamelist = []\n        labelslist = []\n        DIRECTORY = 'path_to'\n\n    for filename in os.listdir(DIRECTORY):\n        fullfilename = DIRECTORY + filename\n        if filename.endswith('.back.0.jpg'):\n            #back image, original orientation\n            filenamelist.append(fullfilename)\n            temp = [0,0]\n            labelslist.append(temp)\n\n        elif filename.endswith('.back.90.jpg'):\n            #back image, rotated clockwise 90\n            filenamelist.append(fullfilename)\n            temp = [0,1]\n            labelslist.append(temp)\n\n        elif filename.endswith('.back.180.jpg'):\n            #back image, rotated clockwise 180\n            filenamelist.append(fullfilename)\n            temp = [0,2]\n            labelslist.append(temp)\n\n        elif filename.endswith('.back.270.jpg'):\n            #back image, rotated clockwise 270\n            filenamelist.append(fullfilename)\n            temp = [0,3]\n            labelslist.append(temp)\n\n        elif filename.endswith('.front.0.jpg'):\n            #front image, rotated clockwise 0\n            filenamelist.append(fullfilename)\n            temp = [1,0]\n            labelslist.append(temp)\n\n        elif filename.endswith('.front.90.jpg'):\n            #front image, rotated clockwise 90\n            filenamelist.append(fullfilename)\n            temp = [1,1]\n            labelslist.append(temp)\n\n        elif filename.endswith('.front.180.jpg'):\n            #front image, rotated clockwise 180\n            filenamelist.append(fullfilename)\n            temp = [1,2]\n            labelslist.append(temp)\n\n        elif filename.endswith('.front.270.jpg'):\n            #front image, rotated clockwise 270\n            filenamelist.append(fullfilename)\n            temp = [1,3]\n            labelslist.append(temp)\n\n    X_train, X_test, y_train, y_test = train_test_split(filenamelist, labelslist, test_size=0.20, random_state=42, shuffle=True, stratify=labelslist)\n    return X_train, X_test, y_train, y_test\n\n\ndef my_input_fn_train(X_train, y_train):\n    filenames = tf.constant(X_train)\n    labels = tf.constant(y_train)\n    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n    dataset = dataset.map(_parse_function)\n    # # Shuffle, repeat, and batch the examples.\n    dataset = dataset.shuffle(5000).repeat().batch(64)\n    # # Build the Iterator, and return the read end of the pipeline.\n    return dataset.make_one_shot_iterator().get_next()\n\ndef my_input_fn_test(X_test, y_test):\n    filenames = tf.constant(X_test)\n    labels = tf.constant(y_test)\n    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n    dataset = dataset.map(_parse_function)\n    # # Shuffle, repeat, and batch the examples.\n    dataset = dataset.shuffle(5000).repeat(1).batch(64)        \n    # # Build the Iterator, and return the read end of the pipeline.\n    return dataset.make_one_shot_iterator().get_next()\n\ndef my_input_fn_predict(filename):    \n    filenames = tf.constant(filename)\n    dataset = tf.data.Dataset.from_tensors((filenames))\n    dataset = dataset.map(_parse_function)\n    return dataset.make_one_shot_iterator().get_next()\n\ndef main(unused_argv):\n\n    # Create the Estimator\n    mnist_classifier = tf.estimator.Estimator(\n    model_fn=cnn_model_fn, \n    model_dir=\"path_to_model_directory\",\n    config = tf.estimator.RunConfig( save_checkpoints_steps=None, save_checkpoints_secs=600, save_summary_steps=5))\n    # Set up logging for predictions\n    tensors_to_log_1 = {\"probabilities1\": \"softmax_tensor_1\"}\n    tensors_to_log_2 = {\"probabilities2\": \"softmax_tensor_2\"}\n    logging_hook_1 = tf.train.LoggingTensorHook(\n        tensors=tensors_to_log_1, every_n_iter=100)\n    logging_hook_2 = tf.train.LoggingTensorHook(\n        tensors=tensors_to_log_2, every_n_iter=100)\n\n    #Splitting the train test split seperately\n    X_train, X_test, y_train, y_test = stratified_train_test_split_()\n\n    #Removed the training, testing and prediction calls.\n\n    #Code for exporting the models using \n    def serving_input_receiver_fn():\n      #????\n\n    mnist_classifier.export_savedmodel(export_dir_base, serving_input_fn)\n\nif __name__ == \"__main__\":\n  tf.app.run()\n</code></pre>\n <machine-learning><deep-learning><tensorflow><estimators>",
                "codes": [],
                "question_id:": "30132",
                "question_votes:": "1",
                "question_text:": "<p>How can i <strong>Save</strong> the <strong>TensorFlow model</strong> using <code>estimator.export_savedmode()</code> ?</p>\n\n<p>Especially, what should i put inside the <code>serving_input_receiver_fn()</code>?</p>\n\n<p>I have created a Custom Estimator based on VGGNet Architecture, i am using my own images and doing some transformation (you can see them in <code>_parse_function()</code>) on the images.</p>\n\n<p>I have read the documentation <a href=\"https://www.tensorflow.org/programmers_guide/saved_model\" rel=\"nofollow noreferrer\">here</a>, but i am exactly not sure what to write for my code (please see below). Ultimately i want to save the model and use TensorFlow Serving.</p>\n\n<pre><code>    from __future__ import absolute_import\n    from __future__ import division\n    from __future__ import print_function\n\n    import tensorflow as tf\n    import numpy as np\n    from sklearn.model_selection import train_test_split\n    import os\n    import matplotlib.pyplot as plt\n    import matplotlib.image as mpimg\n    import scipy\n    from scipy import ndimage\n    import scipy.misc\n\n    tf.logging.set_verbosity(tf.logging.INFO)\n\n    def cnn_model_fn(features, labels, mode):\n        \"\"\"Model function for CNN.\"\"\"\n        # Input Layer\n        input_layer = tf.reshape(features, [-1, 224, 224, 3])\n\n    # Convolutional Layer #1\n    conv1 = tf.layers.conv2d(\n      inputs=input_layer,\n      filters=64,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n    # Convolutional Layer #2\n    conv2 = tf.layers.conv2d(\n      inputs=conv1,\n      filters=64,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n    # Pooling Layer #1\n    pool1 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n\n    # Convolutional Layer #3\n    conv3 = tf.layers.conv2d(\n      inputs=pool1,\n      filters=128,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    # Convolutional Layer #4\n    conv4 = tf.layers.conv2d(\n      inputs=conv3,\n      filters=128,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n    pool2 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)\n\n    # Convolutional Layer #5\n    conv5 = tf.layers.conv2d(\n      inputs=pool2,\n      filters=256,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    # Convolutional Layer #6\n    conv6 = tf.layers.conv2d(\n      inputs=conv5,\n      filters=256,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    # Convolutional Layer #7\n    conv7 = tf.layers.conv2d(\n      inputs=conv6,\n      filters=256,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    pool3 = tf.layers.max_pooling2d(inputs=conv7, pool_size=[2, 2], strides=2)\n\n    # Convolutional Layer #8\n    conv8 = tf.layers.conv2d(\n      inputs=pool3,\n      filters=512,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    # Convolutional Layer #9\n    conv9 = tf.layers.conv2d(\n      inputs=conv8,\n      filters=512,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    # Convolutional Layer #10\n    conv10 = tf.layers.conv2d(\n      inputs=conv9,\n      filters=512,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n    pool4 = tf.layers.max_pooling2d(inputs=conv10, pool_size=[2, 2], strides=2)\n\n    # Convolutional Layer #11\n    conv11 = tf.layers.conv2d(\n      inputs=pool4,\n      filters=512,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    # Convolutional Layer #12\n    conv12 = tf.layers.conv2d(\n      inputs=conv11,\n      filters=512,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    # Convolutional Layer #12\n    conv13 = tf.layers.conv2d(\n      inputs=conv12,\n      filters=512,\n      kernel_size=[3, 3],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n    pool5 = tf.layers.max_pooling2d(inputs=conv13, pool_size=[2, 2], strides=2)\n    # Dense Layer\n    pool5_flat = tf.reshape(pool5, [-1, 7 * 7 * 512])\n    dense1 = tf.layers.dense(inputs=pool5_flat, units=4096, activation=tf.nn.relu)\n    dense2 = tf.layers.dense(inputs=dense1, units=4096, activation=tf.nn.relu)\n    dense3 = tf.layers.dense(inputs=dense2, units=1024, activation=tf.nn.relu)\n\n    dropout = tf.layers.dropout(\n      inputs=dense3, rate=0.001, training=mode == tf.estimator.ModeKeys.TRAIN)\n\n    logits1 = tf.layers.dense(inputs=dropout, units=2)\n    logits2 = tf.layers.dense(inputs=dropout, units=4)\n\n    predictions = {\n        \"classes1\": tf.argmax(input=logits1, axis=1),\n        \"classes2\": tf.argmax(input=logits2, axis=1),\n        \"probabilities1\": tf.nn.softmax(logits1, name=\"softmax_tensor_1\"),\n        \"probabilities2\": tf.nn.softmax(logits2, name=\"softmax_tensor_2\")\n    }\n\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n    # Calculate Loss (for both TRAIN and EVAL modes)\n    loss1 = tf.losses.sparse_softmax_cross_entropy(labels=labels[:,0], logits=logits1)\n    loss2 = tf.losses.sparse_softmax_cross_entropy(labels=labels[:,1], logits=logits2)\n    loss = loss1 + loss2\n\n    # Configure the Training Op (for TRAIN mode)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n        train_op = optimizer.minimize(\n            loss=loss,\n            global_step=tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n    # Add evaluation metrics (for EVAL mode)\n    eval_metric_ops = {\n        \"accuracy1\": tf.metrics.accuracy(\n            labels=labels[:,0], predictions=predictions[\"classes1\"]),\n        \"accuracy2\": tf.metrics.accuracy(\n            labels=labels[:,1], predictions=predictions[\"classes2\"]),\n        \"precision1\": tf.metrics.precision(labels=labels[:,0], predictions=predictions[\"classes1\"]),\n        \"precision2\": tf.metrics.precision(labels=labels[:,1], predictions=predictions[\"classes2\"]),\n        \"recall1\": tf.metrics.recall(labels=labels[:,0], predictions=predictions[\"classes1\"]),\n        \"recall2\": tf.metrics.recall(labels=labels[:,1], predictions=predictions[\"classes2\"])\n    }\n\n    return tf.estimator.EstimatorSpec(\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n\n    def _parse_function(filename, label):\n        image_string = tf.read_file(filename)\n        image_decoded = tf.image.decode_image(image_string)\n        image_typecasted = tf.cast(image_decoded, tf.float32)\n        image_reshaped = tf.reshape(image_typecasted, [-1, 224, 224, 3])\n        return image_reshaped, label\n\n    def _parse_function(filename):\n        image_string = tf.read_file(filename)\n        image_decoded = tf.image.decode_image(image_string)\n        image_typecasted = tf.cast(image_decoded, tf.float32)\n        image_reshaped = tf.reshape(image_typecasted, [-1, 224, 224, 3])\n        return image_reshaped\n\n    def stratified_train_test_split_():\n        filenamelist = []\n        labelslist = []\n        DIRECTORY = 'path_to'\n\n    for filename in os.listdir(DIRECTORY):\n        fullfilename = DIRECTORY + filename\n        if filename.endswith('.back.0.jpg'):\n            #back image, original orientation\n            filenamelist.append(fullfilename)\n            temp = [0,0]\n            labelslist.append(temp)\n\n        elif filename.endswith('.back.90.jpg'):\n            #back image, rotated clockwise 90\n            filenamelist.append(fullfilename)\n            temp = [0,1]\n            labelslist.append(temp)\n\n        elif filename.endswith('.back.180.jpg'):\n            #back image, rotated clockwise 180\n            filenamelist.append(fullfilename)\n            temp = [0,2]\n            labelslist.append(temp)\n\n        elif filename.endswith('.back.270.jpg'):\n            #back image, rotated clockwise 270\n            filenamelist.append(fullfilename)\n            temp = [0,3]\n            labelslist.append(temp)\n\n        elif filename.endswith('.front.0.jpg'):\n            #front image, rotated clockwise 0\n            filenamelist.append(fullfilename)\n            temp = [1,0]\n            labelslist.append(temp)\n\n        elif filename.endswith('.front.90.jpg'):\n            #front image, rotated clockwise 90\n            filenamelist.append(fullfilename)\n            temp = [1,1]\n            labelslist.append(temp)\n\n        elif filename.endswith('.front.180.jpg'):\n            #front image, rotated clockwise 180\n            filenamelist.append(fullfilename)\n            temp = [1,2]\n            labelslist.append(temp)\n\n        elif filename.endswith('.front.270.jpg'):\n            #front image, rotated clockwise 270\n            filenamelist.append(fullfilename)\n            temp = [1,3]\n            labelslist.append(temp)\n\n    X_train, X_test, y_train, y_test = train_test_split(filenamelist, labelslist, test_size=0.20, random_state=42, shuffle=True, stratify=labelslist)\n    return X_train, X_test, y_train, y_test\n\n\ndef my_input_fn_train(X_train, y_train):\n    filenames = tf.constant(X_train)\n    labels = tf.constant(y_train)\n    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n    dataset = dataset.map(_parse_function)\n    # # Shuffle, repeat, and batch the examples.\n    dataset = dataset.shuffle(5000).repeat().batch(64)\n    # # Build the Iterator, and return the read end of the pipeline.\n    return dataset.make_one_shot_iterator().get_next()\n\ndef my_input_fn_test(X_test, y_test):\n    filenames = tf.constant(X_test)\n    labels = tf.constant(y_test)\n    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n    dataset = dataset.map(_parse_function)\n    # # Shuffle, repeat, and batch the examples.\n    dataset = dataset.shuffle(5000).repeat(1).batch(64)        \n    # # Build the Iterator, and return the read end of the pipeline.\n    return dataset.make_one_shot_iterator().get_next()\n\ndef my_input_fn_predict(filename):    \n    filenames = tf.constant(filename)\n    dataset = tf.data.Dataset.from_tensors((filenames))\n    dataset = dataset.map(_parse_function)\n    return dataset.make_one_shot_iterator().get_next()\n\ndef main(unused_argv):\n\n    # Create the Estimator\n    mnist_classifier = tf.estimator.Estimator(\n    model_fn=cnn_model_fn, \n    model_dir=\"path_to_model_directory\",\n    config = tf.estimator.RunConfig( save_checkpoints_steps=None, save_checkpoints_secs=600, save_summary_steps=5))\n    # Set up logging for predictions\n    tensors_to_log_1 = {\"probabilities1\": \"softmax_tensor_1\"}\n    tensors_to_log_2 = {\"probabilities2\": \"softmax_tensor_2\"}\n    logging_hook_1 = tf.train.LoggingTensorHook(\n        tensors=tensors_to_log_1, every_n_iter=100)\n    logging_hook_2 = tf.train.LoggingTensorHook(\n        tensors=tensors_to_log_2, every_n_iter=100)\n\n    #Splitting the train test split seperately\n    X_train, X_test, y_train, y_test = stratified_train_test_split_()\n\n    #Removed the training, testing and prediction calls.\n\n    #Code for exporting the models using \n    def serving_input_receiver_fn():\n      #????\n\n    mnist_classifier.export_savedmodel(export_dir_base, serving_input_fn)\n\nif __name__ == \"__main__\":\n  tf.app.run()\n</code></pre>\n",
                "tags": "<machine-learning><deep-learning><tensorflow><estimators>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10031",
            "_score": 5.336341,
            "_source": {
                "title": "Multivariable time-series forecast with NN vs RNN",
                "content": "Multivariable time-series forecast with NN vs RNN <p>I am doing some comparison of RNN with other methodologies to check if the RNNs can improve some more \"classical\" models.\nIn fact, I am doing it with multiple features (similar to what was done <a href=\"https://datascience.stackexchange.com/questions/17024/rnns-with-multiple-features\">here</a>) with a time-series function where the target is a function of other variables. The objective is to predict the target evolution (forecast for different time-horizons) having as input the target and also features that might be important for that evolution (are function of the target). I made the following time-series dataset as an example.</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\n\n# Create dataset\ntime = np.arange(1000)\nf_1 = np.sin(time)\nf_2 = np.cos(time)\nf_3 = np.tan(time)\ntarget = np.roll(f_1, 1) + np.roll(f_2,2) + np.roll(f_3,3)\ndf = pd.DataFrame({'target': target, 'f_1': f_1, 'f_2': f_2, 'f_3': f_3})\n</code></pre>\n\n<p>So, I create a dataset where I make samples with 4 variables (target + features) using the previous 60 values (<strong>n_prev</strong>) to predict the following 20 values (<strong>n_next</strong>).</p>\n\n<pre><code>def _load_data_multiVar(df, n_prev=60, n_next=20):  \n    docX, docY = [], []\n    for i in range(len(df)-n_prev-n_next):\n        docX.append(df.iloc[i:i+n_prev].as_matrix())\n        docY.append(df.iloc[i+n_prev:i+n_prev+n_next]['target'].as_matrix())\n    alsX = np.array(docX)\n    alsY = np.array(docY)\n    return alsX, alsY\n</code></pre>\n\n<p>This creates the dimensions (20% test size) of:\nX_train:  (720, 60, 4)  - y_train:  (720, 20)\nX_test:  (120, 60, 4)  - y_test:  (120, 20)</p>\n\n<p>So now, I can predict the following 20 values with RNN altogether, or traing NN for each time horizon and merge later on.\nSo that's what I've tried (trying to make a similar complex models) and the results shown that the NN are much better than the RNN, also for the time-horizon 0.</p>\n\n<p><a href=\"https://i.stack.imgur.com/0Vxt9.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/0Vxt9.png\" alt=\"RNN multivariable forecast for different time horizons\"></a>\n<a href=\"https://i.stack.imgur.com/zEk4N.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zEk4N.png\" alt=\"NN multivariable forecast for different time horizons\"></a></p>\n\n<p>The number of the legend is the time-horizon forecast.</p>\n\n<p>As it can be seen, the RNN Root Mean Squared Error is surprisingly high, which is what I am not correctly understanding as RNN are using LSTMs where input is a repetitive function with features that should improve its knowledge. I might be doing something wrong, or maybe the RNNs are not good for this kind of problems.</p>\n\n<p>Why is the RNN RMSE higher than the NN RMSE, in this case?</p>\n\n<p>Here is the full working code to check the used RNN and NN parameter/configuration:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.recurrent import LSTM\n\n###############################################################################\ndef _load_data_multiVar(df, n_prev=60, n_next=20):  \n    docX, docY = [], []\n    for i in range(len(df)-n_prev-n_next):\n        docX.append(df.iloc[i:i+n_prev].as_matrix())\n        docY.append(df.iloc[i+n_prev:i+n_prev+n_next]['target'].as_matrix())\n    alsX = np.array(docX)\n    alsY = np.array(docY)\n    return alsX, alsY\n\n###############################################################################\n\ndef Model_NN_keras(input_features):\n    from keras.models import Sequential\n    from keras.layers.core import Dense, Activation, Dropout\n    from keras.optimizers import Adam\n\n    hidden_1_size = 128\n    hidden_2_size = 128\n\n    model = Sequential()\n    model.add(Dense(hidden_1_size, input_shape=(input_features,)))\n    model.add(Dropout(0.2)) \n    model.add(Dense(hidden_2_size, activation='relu'))\n    model.add(Dense(1, activation='linear'))\n    model.compile(loss='mean_squared_error',    optimizer=\"rmsprop\")\n    print model.summary()\n    return model\n\ndef Model_RNN_keras(input_features, window_size, output_features):\n    hidden_neurons = 300\n    model = Sequential()\n    model.add(LSTM(hidden_neurons, return_sequences=False, input_shape=(window_size,input_features)))\n    model.add(Dense(output_features))\n    model.add(Activation(\"linear\"))\n    model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")\n    print model.summary()\n    return model\n\n\n###############################################################################\nif __name__ == \"__main__\":\n\n    # Create dataset\n    time = np.arange(1000)\n    f_1 = np.sin(time)\n    f_2 = np.cos(time)\n    f_3 = np.tan(time)\n    target = np.roll(f_1, 1) + np.roll(f_2,2) + np.roll(f_3,3)\n    df = pd.DataFrame({'target': target, 'f_1': f_1, 'f_2': f_2, 'f_3': f_3})\n\n    # Split train/test [X(num. samples, prev. window size for trend, num. features), y(num. samples, next window size to predict)]\n    test_size = 0.2\n    ntrn = int(len(df) * (1 - test_size))\n    X_train, y_train = _load_data_multiVar(df.iloc[0:ntrn], n_prev=60, n_next=20)\n    X_test, y_test = _load_data_multiVar(df.iloc[ntrn:], n_prev=60, n_next=20)\n    print 'X_train: ', X_train.shape, ' - y_train: ', y_train.shape\n    print 'X_test: ', X_test.shape, ' - y_test: ', y_test.shape\n\n    ########## NN ##########\n    # Plot\n    f, axarr = plt.subplots(7, sharex=True, figsize=(16,7), dpi=100)\n    index = 0\n    for tmhrzn in range(20):\n\n        if(tmhrzn % 3 != 0):\n            continue\n\n        X_train_NN = X_train.reshape(X_train.shape[0],-1)\n        X_test_NN = X_test.reshape(X_test.shape[0],-1)\n        y_train_NN = y_train[:,tmhrzn]\n        y_test_NN = y_test[:,tmhrzn]\n        print 'X_train_NN: ', X_train_NN.shape, ' - y_train_NN: ', y_train_NN.shape\n        model = Model_NN_keras(X_train.shape[1]*X_train.shape[2])\n        model.fit(X_train_NN, y_train_NN, batch_size=64, epochs=10, validation_split=0.05)\n        y_pred_NN = np.squeeze(model.predict(X_test_NN))    \n        print 'y_pred_NN: ', y_pred_NN.shape, ' - y_test_NN: ', y_test_NN.shape\n\n\n        axarr[index].plot(range(len(y_pred_NN)), y_pred_NN, color='g', ls='--', lw=1, label='Pred_%.2d' % tmhrzn)\n        axarr[index].plot(range(len(y_test_NN)), y_test_NN, color='k', ls='-', lw=1, label='Real_%.2d' % tmhrzn)\n        axarr[index].legend()\n        axarr[index].set_xlim([-5,135])\n        axarr[index].set_ylim([-20,30])\n        axarr[index].text(0., 10., 'RMSE: %.3f' % np.sqrt(np.sum((y_pred_NN - y_test_NN) ** 2)/len(y_test_NN)) )\n        if(index != 6):\n            axarr[index].set_xticklabels([])\n        index += 1\n\n    plt.subplots_adjust(hspace=None)\n    plt.suptitle('NN')\n    plt.show()\n    exit()\n\n    ########## RNN ##########\n    model = Model_RNN_keras(X_train.shape[2], X_train.shape[1], y_train.shape[1])\n    model.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.05)\n    y_pred = model.predict(X_test)\n    print 'y_pred: ', y_pred.shape, ' - y_test: ', y_test.shape\n    rmse = np.sqrt(((y_pred - y_test) ** 2).mean(axis=0))\n    print 'rmse: ', rmse, rmse.shape\n\n    # Plot\n    f, axarr = plt.subplots(7, sharex=True, figsize=(16,7), dpi=100)\n    index = 0\n    for tmhrzn in range(20):\n\n        if(tmhrzn % 3 != 0):\n            continue\n\n        axarr[index].plot(range(y_pred.shape[0]), y_pred[:,tmhrzn], color='g', ls='--', lw=1, label='Pred_%.2d' % tmhrzn)\n        axarr[index].plot(range(y_test.shape[0]), y_test[:,tmhrzn], color='k', ls='-', lw=1, label='Real_%.2d' % tmhrzn)\n        axarr[index].legend()\n        axarr[index].set_xlim([-5,135])\n        axarr[index].set_ylim([-20,30])\n        axarr[index].text(0., 10., 'RMSE: %.3f' % rmse[tmhrzn] )\n        if(index != 6):\n            axarr[index].set_xticklabels([])\n        index += 1\n\n    plt.subplots_adjust(hspace=None)\n    plt.suptitle('RNN')\n    plt.show()\n</code></pre>\n <python><keras><time-series><rnn><recurrent-neural-net>",
                "codes": [],
                "question_id:": "36453",
                "question_votes:": "1",
                "question_text:": "<p>I am doing some comparison of RNN with other methodologies to check if the RNNs can improve some more \"classical\" models.\nIn fact, I am doing it with multiple features (similar to what was done <a href=\"https://datascience.stackexchange.com/questions/17024/rnns-with-multiple-features\">here</a>) with a time-series function where the target is a function of other variables. The objective is to predict the target evolution (forecast for different time-horizons) having as input the target and also features that might be important for that evolution (are function of the target). I made the following time-series dataset as an example.</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\n\n# Create dataset\ntime = np.arange(1000)\nf_1 = np.sin(time)\nf_2 = np.cos(time)\nf_3 = np.tan(time)\ntarget = np.roll(f_1, 1) + np.roll(f_2,2) + np.roll(f_3,3)\ndf = pd.DataFrame({'target': target, 'f_1': f_1, 'f_2': f_2, 'f_3': f_3})\n</code></pre>\n\n<p>So, I create a dataset where I make samples with 4 variables (target + features) using the previous 60 values (<strong>n_prev</strong>) to predict the following 20 values (<strong>n_next</strong>).</p>\n\n<pre><code>def _load_data_multiVar(df, n_prev=60, n_next=20):  \n    docX, docY = [], []\n    for i in range(len(df)-n_prev-n_next):\n        docX.append(df.iloc[i:i+n_prev].as_matrix())\n        docY.append(df.iloc[i+n_prev:i+n_prev+n_next]['target'].as_matrix())\n    alsX = np.array(docX)\n    alsY = np.array(docY)\n    return alsX, alsY\n</code></pre>\n\n<p>This creates the dimensions (20% test size) of:\nX_train:  (720, 60, 4)  - y_train:  (720, 20)\nX_test:  (120, 60, 4)  - y_test:  (120, 20)</p>\n\n<p>So now, I can predict the following 20 values with RNN altogether, or traing NN for each time horizon and merge later on.\nSo that's what I've tried (trying to make a similar complex models) and the results shown that the NN are much better than the RNN, also for the time-horizon 0.</p>\n\n<p><a href=\"https://i.stack.imgur.com/0Vxt9.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/0Vxt9.png\" alt=\"RNN multivariable forecast for different time horizons\"></a>\n<a href=\"https://i.stack.imgur.com/zEk4N.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zEk4N.png\" alt=\"NN multivariable forecast for different time horizons\"></a></p>\n\n<p>The number of the legend is the time-horizon forecast.</p>\n\n<p>As it can be seen, the RNN Root Mean Squared Error is surprisingly high, which is what I am not correctly understanding as RNN are using LSTMs where input is a repetitive function with features that should improve its knowledge. I might be doing something wrong, or maybe the RNNs are not good for this kind of problems.</p>\n\n<p>Why is the RNN RMSE higher than the NN RMSE, in this case?</p>\n\n<p>Here is the full working code to check the used RNN and NN parameter/configuration:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.recurrent import LSTM\n\n###############################################################################\ndef _load_data_multiVar(df, n_prev=60, n_next=20):  \n    docX, docY = [], []\n    for i in range(len(df)-n_prev-n_next):\n        docX.append(df.iloc[i:i+n_prev].as_matrix())\n        docY.append(df.iloc[i+n_prev:i+n_prev+n_next]['target'].as_matrix())\n    alsX = np.array(docX)\n    alsY = np.array(docY)\n    return alsX, alsY\n\n###############################################################################\n\ndef Model_NN_keras(input_features):\n    from keras.models import Sequential\n    from keras.layers.core import Dense, Activation, Dropout\n    from keras.optimizers import Adam\n\n    hidden_1_size = 128\n    hidden_2_size = 128\n\n    model = Sequential()\n    model.add(Dense(hidden_1_size, input_shape=(input_features,)))\n    model.add(Dropout(0.2)) \n    model.add(Dense(hidden_2_size, activation='relu'))\n    model.add(Dense(1, activation='linear'))\n    model.compile(loss='mean_squared_error',    optimizer=\"rmsprop\")\n    print model.summary()\n    return model\n\ndef Model_RNN_keras(input_features, window_size, output_features):\n    hidden_neurons = 300\n    model = Sequential()\n    model.add(LSTM(hidden_neurons, return_sequences=False, input_shape=(window_size,input_features)))\n    model.add(Dense(output_features))\n    model.add(Activation(\"linear\"))\n    model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")\n    print model.summary()\n    return model\n\n\n###############################################################################\nif __name__ == \"__main__\":\n\n    # Create dataset\n    time = np.arange(1000)\n    f_1 = np.sin(time)\n    f_2 = np.cos(time)\n    f_3 = np.tan(time)\n    target = np.roll(f_1, 1) + np.roll(f_2,2) + np.roll(f_3,3)\n    df = pd.DataFrame({'target': target, 'f_1': f_1, 'f_2': f_2, 'f_3': f_3})\n\n    # Split train/test [X(num. samples, prev. window size for trend, num. features), y(num. samples, next window size to predict)]\n    test_size = 0.2\n    ntrn = int(len(df) * (1 - test_size))\n    X_train, y_train = _load_data_multiVar(df.iloc[0:ntrn], n_prev=60, n_next=20)\n    X_test, y_test = _load_data_multiVar(df.iloc[ntrn:], n_prev=60, n_next=20)\n    print 'X_train: ', X_train.shape, ' - y_train: ', y_train.shape\n    print 'X_test: ', X_test.shape, ' - y_test: ', y_test.shape\n\n    ########## NN ##########\n    # Plot\n    f, axarr = plt.subplots(7, sharex=True, figsize=(16,7), dpi=100)\n    index = 0\n    for tmhrzn in range(20):\n\n        if(tmhrzn % 3 != 0):\n            continue\n\n        X_train_NN = X_train.reshape(X_train.shape[0],-1)\n        X_test_NN = X_test.reshape(X_test.shape[0],-1)\n        y_train_NN = y_train[:,tmhrzn]\n        y_test_NN = y_test[:,tmhrzn]\n        print 'X_train_NN: ', X_train_NN.shape, ' - y_train_NN: ', y_train_NN.shape\n        model = Model_NN_keras(X_train.shape[1]*X_train.shape[2])\n        model.fit(X_train_NN, y_train_NN, batch_size=64, epochs=10, validation_split=0.05)\n        y_pred_NN = np.squeeze(model.predict(X_test_NN))    \n        print 'y_pred_NN: ', y_pred_NN.shape, ' - y_test_NN: ', y_test_NN.shape\n\n\n        axarr[index].plot(range(len(y_pred_NN)), y_pred_NN, color='g', ls='--', lw=1, label='Pred_%.2d' % tmhrzn)\n        axarr[index].plot(range(len(y_test_NN)), y_test_NN, color='k', ls='-', lw=1, label='Real_%.2d' % tmhrzn)\n        axarr[index].legend()\n        axarr[index].set_xlim([-5,135])\n        axarr[index].set_ylim([-20,30])\n        axarr[index].text(0., 10., 'RMSE: %.3f' % np.sqrt(np.sum((y_pred_NN - y_test_NN) ** 2)/len(y_test_NN)) )\n        if(index != 6):\n            axarr[index].set_xticklabels([])\n        index += 1\n\n    plt.subplots_adjust(hspace=None)\n    plt.suptitle('NN')\n    plt.show()\n    exit()\n\n    ########## RNN ##########\n    model = Model_RNN_keras(X_train.shape[2], X_train.shape[1], y_train.shape[1])\n    model.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.05)\n    y_pred = model.predict(X_test)\n    print 'y_pred: ', y_pred.shape, ' - y_test: ', y_test.shape\n    rmse = np.sqrt(((y_pred - y_test) ** 2).mean(axis=0))\n    print 'rmse: ', rmse, rmse.shape\n\n    # Plot\n    f, axarr = plt.subplots(7, sharex=True, figsize=(16,7), dpi=100)\n    index = 0\n    for tmhrzn in range(20):\n\n        if(tmhrzn % 3 != 0):\n            continue\n\n        axarr[index].plot(range(y_pred.shape[0]), y_pred[:,tmhrzn], color='g', ls='--', lw=1, label='Pred_%.2d' % tmhrzn)\n        axarr[index].plot(range(y_test.shape[0]), y_test[:,tmhrzn], color='k', ls='-', lw=1, label='Real_%.2d' % tmhrzn)\n        axarr[index].legend()\n        axarr[index].set_xlim([-5,135])\n        axarr[index].set_ylim([-20,30])\n        axarr[index].text(0., 10., 'RMSE: %.3f' % rmse[tmhrzn] )\n        if(index != 6):\n            axarr[index].set_xticklabels([])\n        index += 1\n\n    plt.subplots_adjust(hspace=None)\n    plt.suptitle('RNN')\n    plt.show()\n</code></pre>\n",
                "tags": "<python><keras><time-series><rnn><recurrent-neural-net>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11096",
            "_score": 5.2966537,
            "_source": {
                "title": "Probabilistic Outlier Detection (edited + clarified)",
                "content": "Probabilistic Outlier Detection (edited + clarified) <p>Measured data <span class=\"math-container\">$D \\in \\mathbb{R}^3$</span>, every <span class=\"math-container\">$d^i \\in D$</span> is <span class=\"math-container\">$d^i_{(x)}$</span>, where the  <span class=\"math-container\">$x=[x_1, x_2]$</span>. <em>Simply said</em>, the measured data are function of <span class=\"math-container\">$x$</span>. It is known, the dependency is linear, such as:</p>\n\n<p><span class=\"math-container\">$$d^i_1 = a_1^Tx+b_1$$</span>\n<span class=\"math-container\">$$d^i_2 = a_2^Tx+b_2$$</span>\n<span class=\"math-container\">$$d^i_3 = a_3^Tx+b_3$$</span></p>\n\n<p>where <span class=\"math-container\">$a_{1-3} \\in \\mathbb{R}^2$</span> and <span class=\"math-container\">$b_{1-3} \\in \\mathbb{R}$</span>, so that <span class=\"math-container\">$d^i_{1-3}$</span> is a set of 3 simple 2D planes, over <span class=\"math-container\">$x=[x_1, x_2]$</span>. </p>\n\n<p>While it is known, that <span class=\"math-container\">$d^i_{(x)}$</span> is function of <span class=\"math-container\">$x$</span>, the <span class=\"math-container\">$x$</span> is not measured. Therefore the parameters <span class=\"math-container\">$a_{1-3}$</span> and <span class=\"math-container\">$b_{1-3}$</span> are difficult to find. <em>The data interpretation is simplified to 3 dimensions for visual clarity, real problem is of higher dimension.</em></p>\n\n<h2>Data Example</h2>\n\n<p>The figures below show <span class=\"math-container\">$d^i_{1-3}$</span>, as a function of <span class=\"math-container\">$x=[x_1, x_2]$</span>, <em>assuming the <span class=\"math-container\">$x$</span> is measurable</em>. This is only to visualize the data set.</p>\n\n<ul>\n<li>dimension 1 of <span class=\"math-container\">$d^i$</span>\n<a href=\"https://i.stack.imgur.com/0TBGm.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/0TBGm.png\" alt=\"dimension 1\"></a></li>\n<li>dimension 2 of <span class=\"math-container\">$d^i$</span>\n<a href=\"https://i.stack.imgur.com/PvfM4.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PvfM4.png\" alt=\"dimension  2\"></a></li>\n<li>dimension 3 of <span class=\"math-container\">$d^i$</span>\n<a href=\"https://i.stack.imgur.com/clrI7.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/clrI7.png\" alt=\"dimension  3\"></a></li>\n</ul>\n\n<h2>Problem formulation</h2>\n\n<p>How to assign probability <span class=\"math-container\">$p(d^i)$</span> to measured <span class=\"math-container\">$d^i$</span>, such that it reflects the fact that it lies in the feasibility region (the 3 green hyper-planes) ?</p>\n\n<p><strong>1)</strong> <em>Simply said</em>, how to train the model using <span class=\"math-container\">$d^i = [d^i_1, d^i_2, d^i_3]$</span> to spot the outlier <span class=\"math-container\">$d' = [d^q_1, d^q_2, d^k_3]$</span>. The outlier is marked by red dot and deviates only in the 3rd dimension. (please, suggest ways that work in higher dimensions as well).</p>\n\n<p><strong>In practice, <span class=\"math-container\">$x=[x_1, x_2]$</span> is not measured !</strong></p>\n\n<p><strong>2)</strong> Does the knowledge of the linearity of <span class=\"math-container\">$d^i_{(x)}$</span>, help ? What if the dependency is not linear ?</p>\n\n<h2>Idea</h2>\n\n<p>I think I can have 3 simple Gaussian PDFs, where each PDF gives the probability for one {<span class=\"math-container\">$d^i_1$</span>, <span class=\"math-container\">$d^i_2$</span>, <span class=\"math-container\">$d^i_3$</span>}, and the parameters (mean and variance) are function of the other 2 <span class=\"math-container\">$d^i_{1-3}$</span>. For example:</p>\n\n<p><span class=\"math-container\">$$p(d^i_1) = N(d^i_1|\\mathrm{E}_{(d^i_2, d^i_3)},\\mathrm{Var}_{(d^i_2, d^i_3)})$$</span></p>\n\n<p>then it follows for the other 2 dimensions:</p>\n\n<p><span class=\"math-container\">$$p(d^i_2) = N(d^i_2|\\mathrm{E}_{(d^i_4, d^i_3)},\\mathrm{Var}_{(d^i_4, d^i_3)})$$</span>\n<span class=\"math-container\">$$p(d^i_3) = N(d^i_3|\\mathrm{E}_{(d^i_1, d^i_2)},\\mathrm{Var}_{(d^i_1, d^i_2)})$$</span></p>\n\n<h2>P.S.</h2>\n\n<p>The outlier <span class=\"math-container\">$d'$</span> is placed at the border (y=0), just to enhance the visibility. The outlier can be measured with any value of <span class=\"math-container\">$x=[x_1, x_2]$</span>.</p>\n <predictive-modeling><outlier><gaussian><p>In essence anomaly detection is about finding a metric with which to measure the similarity between instances and then determining a threshold when crossed constitutes an anomaly. There are parametric anomaly detection algorithms which require some hyper-parameters to be set or information about the distribution to be known. There are also non-parametric techniques which do not have these stringent requirements. </p>\n\n<p>Let's consider the simple case of identifying anomalies in a population based on height. We can assume this to be a 1D Gaussian distribution. Now we need a similarity metric, let's use Euclidean distance for simplicity (the difference in individual's heights). Next we need a threshold. </p>\n\n<h1>Classical statistics</h1>\n\n<p>Classical methods would parametrize the Gaussian distribution of your population. Let us assume that after polling our population we identify that the mean height is 170cm with a variance of 15cm. Now we can set the threshold to be any multiple of the variance <span class=\"math-container\">$\\sigma$</span>. Typically we choose <span class=\"math-container\">$3\\sigma$</span> as a thresholds since the ingroup would include 99.7% of the population, all those outside of the <span class=\"math-container\">$3\\sigma$</span> range can thus confidently be said to be anomalous. </p>\n\n<p>You can also look at the application of a generalized likelihood ratio test (GLRT) to find anomalies.</p>\n\n<p>Let's visualize this</p>\n\n<pre><code>import numpy as np\n\ndata = np.random.normal(170, 15, 10000)\n\nplt.hist(data)\nplt.plot([215,215],[0,3000])\nplt.plot([125,125],[0,3000])\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/4Dc9P.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/4Dc9P.png\" alt=\"enter image description here\"></a></p>\n\n<h1>Parametric techniques</h1>\n\n<p>The examples will require that we have prior information regarding the distribution of the data. This technique will fit an ellipse around the Gaussian distribution of our data in order to contain the elements with the highest in-group correlation.</p>\n\n<pre><code>from sklearn.covariance import EllipticEnvelope\nestimator = EllipticEnvelope()\nestimator.fit(data.reshape(-1,1))\n\nplt.scatter(data, np.random.randint(0,1,10000), c=estimator.predict(data.reshape(-1,1)))\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/NXwDd.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/NXwDd.png\" alt=\"enter image description here\"></a></p>\n\n<p>We see that the yellow dots are the 'normal' instances and the dark blue ones are the anomalies. You can also notice that this algorithm selects an anomaly threshold very similar to the one we obtained using classical statistics methods.</p>\n\n<h1>Non-parametric algorithms</h1>\n\n<p>This is a play on the Random Forests algorithm based on an ensemble of decision trees. The decision trees are trained to identify anomalies through information loss decisions and isolating instances of your data.</p>\n\n<pre><code>from sklearn.ensemble import IsolationForest\nestimator = IsolationForest()\nestimator.fit(data.reshape(-1,1))\nplt.scatter(data, np.random.randint(0,1,10000), c=estimator.predict(data.reshape(-1,1)))\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/vtjWQ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/vtjWQ.png\" alt=\"enter image description here\"></a></p>\n\n<h1>Non-parametric <span class=\"math-container\">$p$</span>-value estimation algorithms</h1>\n\n<p>These are personal favorite and have been very successful in a number of tasks.</p>\n\n<p>Learning Minimum Volume Sets\n<a href=\"http://www.stat.rice.edu/~cscott/pubs/minvol06jmlr.pdf\" rel=\"nofollow noreferrer\">http://www.stat.rice.edu/~cscott/pubs/minvol06jmlr.pdf</a></p>\n\n<p>Anomaly Detection with Score functions based on Nearest Neighbor Graphs\n<a href=\"https://arxiv.org/abs/0910.5461\" rel=\"nofollow noreferrer\">https://arxiv.org/abs/0910.5461</a></p>\n\n<p>New statistic in P-value estimation for anomaly detection\n<a href=\"http://ieeexplore.ieee.org/document/6319713/\" rel=\"nofollow noreferrer\">http://ieeexplore.ieee.org/document/6319713/</a></p>\n\n<hr>\n\n<p>I don't have time tonight but tomorrow evening I will elaborate on the GLRT, and the <span class=\"math-container\">$p$</span>-value estimation algorithms.</p>\n\n<hr>\n\n<h1>Extending the above to more dimensions</h1>\n\n<p>Of course all the described algorithm can be extended to <span class=\"math-container\">$n$</span>-dimensions. This is hard to plot so we will go through a 2D example and a 3D example. However, determining the probability of these being anomalies is not so simple. For some of these algorithms you will need to devise some sort of distance metric.</p>\n\n<h2>2D example</h2>\n\n<p>Let's consider this artificial data. Where tall people above 170cm have eye colors with a blue content of mean 1 and variance 0.5. And short people have lower blue content at a mean 0 and variance 0.5 (let's just assume eyes can have negative pigmentation whatever that could possibly mean).</p>\n\n<pre><code>import numpy as np\n\nn = 10000\nX = np.zeros((n,2))\nX[:,0] = np.random.normal(170, 15, n)\nfor i in range(n):\n    if X[i,0] &lt; 170:\n        X[i,1] = np.random.normal(0, 0.5)\n    else:\n        X[i,1] = np.random.normal(1, 0.5)\n\nplt.scatter(X[:,0], X[:,1])\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/ElH3A.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ElH3A.png\" alt=\"enter image description here\"></a></p>\n\n<h3>Classical statistics</h3>\n\n<p>Any p-value test used in classical statistics can be extended to multiple dimensions. This is the easiest when the features are uncorrelated. When this is the case the probability of each feature can be multiplied together. If this is not the case then you need to compute the p-value for a 2D Gaussian distribution. </p>\n\n<p>For our case this is even worse! It's bimodal (there are two means for a feature). You can see this <a href=\"https://en.wikipedia.org/wiki/Multimodal_distribution\" rel=\"nofollow noreferrer\">here</a>. Our data would look something like this image from the Wiki.</p>\n\n<p><a href=\"https://i.stack.imgur.com/oascg.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/oascg.png\" alt=\"enter image description here\"></a></p>\n\n<p>I hope you can appreciate how difficult this problem is to solve. Luckily this is no longer the classical era of statistics. </p>\n\n<h2>Parametric techniques</h2>\n\n<p>These algorithms can easily be moved onto <span class=\"math-container\">$n$</span>-dimensions.</p>\n\n<pre><code>from sklearn.covariance import EllipticEnvelope\nestimator = EllipticEnvelope()\nestimator.fit(X)\nplt.scatter(X[:,0], X[:,1], c=estimator.predict(X))\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/WaZRQ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WaZRQ.png\" alt=\"enter image description here\"></a></p>\n\n<p>In the 1D example we discussed how this algorithm assumes a unimodal Gaussian distribution. This is not the case for our current data and you can see the failures of this model. It seems to classify many extreme examples as being part of the nominal set when they should have likely been identified as anomalies. </p>\n\n<h2>Non-parametric techniques</h2>\n\n<p>This technique can also be applied to <span class=\"math-container\">$n$</span>-dimensional data. Moreover, it can be used for multimodal Gaussian distributions as you can see we get better results.</p>\n\n<pre><code>from sklearn.ensemble import IsolationForest\nestimator = IsolationForest()\nestimator.fit(X)\nplt.scatter(X[:,0], X[:,1], c=estimator.predict(X))\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/drcSv.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/drcSv.png\" alt=\"enter image description here\"></a></p>\n",
                "codes": [
                    [
                        "import numpy as np\n\ndata = np.random.normal(170, 15, 10000)\n\nplt.hist(data)\nplt.plot([215,215],[0,3000])\nplt.plot([125,125],[0,3000])\nplt.show()\n",
                        "from sklearn.covariance import EllipticEnvelope\nestimator = EllipticEnvelope()\nestimator.fit(data.reshape(-1,1))\n\nplt.scatter(data, np.random.randint(0,1,10000), c=estimator.predict(data.reshape(-1,1)))\nplt.show()\n",
                        "from sklearn.ensemble import IsolationForest\nestimator = IsolationForest()\nestimator.fit(data.reshape(-1,1))\nplt.scatter(data, np.random.randint(0,1,10000), c=estimator.predict(data.reshape(-1,1)))\nplt.show()\n",
                        "import numpy as np\n\nn = 10000\nX = np.zeros((n,2))\nX[:,0] = np.random.normal(170, 15, n)\nfor i in range(n):\n    if X[i,0] < 170:\n        X[i,1] = np.random.normal(0, 0.5)\n    else:\n        X[i,1] = np.random.normal(1, 0.5)\n\nplt.scatter(X[:,0], X[:,1])\nplt.show()\n",
                        "from sklearn.covariance import EllipticEnvelope\nestimator = EllipticEnvelope()\nestimator.fit(X)\nplt.scatter(X[:,0], X[:,1], c=estimator.predict(X))\nplt.show()\n",
                        "from sklearn.ensemble import IsolationForest\nestimator = IsolationForest()\nestimator.fit(X)\nplt.scatter(X[:,0], X[:,1], c=estimator.predict(X))\nplt.show()\n"
                    ]
                ],
                "question_id:": "39165",
                "question_votes:": "2",
                "question_text:": "<p>Measured data <span class=\"math-container\">$D \\in \\mathbb{R}^3$</span>, every <span class=\"math-container\">$d^i \\in D$</span> is <span class=\"math-container\">$d^i_{(x)}$</span>, where the  <span class=\"math-container\">$x=[x_1, x_2]$</span>. <em>Simply said</em>, the measured data are function of <span class=\"math-container\">$x$</span>. It is known, the dependency is linear, such as:</p>\n\n<p><span class=\"math-container\">$$d^i_1 = a_1^Tx+b_1$$</span>\n<span class=\"math-container\">$$d^i_2 = a_2^Tx+b_2$$</span>\n<span class=\"math-container\">$$d^i_3 = a_3^Tx+b_3$$</span></p>\n\n<p>where <span class=\"math-container\">$a_{1-3} \\in \\mathbb{R}^2$</span> and <span class=\"math-container\">$b_{1-3} \\in \\mathbb{R}$</span>, so that <span class=\"math-container\">$d^i_{1-3}$</span> is a set of 3 simple 2D planes, over <span class=\"math-container\">$x=[x_1, x_2]$</span>. </p>\n\n<p>While it is known, that <span class=\"math-container\">$d^i_{(x)}$</span> is function of <span class=\"math-container\">$x$</span>, the <span class=\"math-container\">$x$</span> is not measured. Therefore the parameters <span class=\"math-container\">$a_{1-3}$</span> and <span class=\"math-container\">$b_{1-3}$</span> are difficult to find. <em>The data interpretation is simplified to 3 dimensions for visual clarity, real problem is of higher dimension.</em></p>\n\n<h2>Data Example</h2>\n\n<p>The figures below show <span class=\"math-container\">$d^i_{1-3}$</span>, as a function of <span class=\"math-container\">$x=[x_1, x_2]$</span>, <em>assuming the <span class=\"math-container\">$x$</span> is measurable</em>. This is only to visualize the data set.</p>\n\n<ul>\n<li>dimension 1 of <span class=\"math-container\">$d^i$</span>\n<a href=\"https://i.stack.imgur.com/0TBGm.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/0TBGm.png\" alt=\"dimension 1\"></a></li>\n<li>dimension 2 of <span class=\"math-container\">$d^i$</span>\n<a href=\"https://i.stack.imgur.com/PvfM4.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PvfM4.png\" alt=\"dimension  2\"></a></li>\n<li>dimension 3 of <span class=\"math-container\">$d^i$</span>\n<a href=\"https://i.stack.imgur.com/clrI7.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/clrI7.png\" alt=\"dimension  3\"></a></li>\n</ul>\n\n<h2>Problem formulation</h2>\n\n<p>How to assign probability <span class=\"math-container\">$p(d^i)$</span> to measured <span class=\"math-container\">$d^i$</span>, such that it reflects the fact that it lies in the feasibility region (the 3 green hyper-planes) ?</p>\n\n<p><strong>1)</strong> <em>Simply said</em>, how to train the model using <span class=\"math-container\">$d^i = [d^i_1, d^i_2, d^i_3]$</span> to spot the outlier <span class=\"math-container\">$d' = [d^q_1, d^q_2, d^k_3]$</span>. The outlier is marked by red dot and deviates only in the 3rd dimension. (please, suggest ways that work in higher dimensions as well).</p>\n\n<p><strong>In practice, <span class=\"math-container\">$x=[x_1, x_2]$</span> is not measured !</strong></p>\n\n<p><strong>2)</strong> Does the knowledge of the linearity of <span class=\"math-container\">$d^i_{(x)}$</span>, help ? What if the dependency is not linear ?</p>\n\n<h2>Idea</h2>\n\n<p>I think I can have 3 simple Gaussian PDFs, where each PDF gives the probability for one {<span class=\"math-container\">$d^i_1$</span>, <span class=\"math-container\">$d^i_2$</span>, <span class=\"math-container\">$d^i_3$</span>}, and the parameters (mean and variance) are function of the other 2 <span class=\"math-container\">$d^i_{1-3}$</span>. For example:</p>\n\n<p><span class=\"math-container\">$$p(d^i_1) = N(d^i_1|\\mathrm{E}_{(d^i_2, d^i_3)},\\mathrm{Var}_{(d^i_2, d^i_3)})$$</span></p>\n\n<p>then it follows for the other 2 dimensions:</p>\n\n<p><span class=\"math-container\">$$p(d^i_2) = N(d^i_2|\\mathrm{E}_{(d^i_4, d^i_3)},\\mathrm{Var}_{(d^i_4, d^i_3)})$$</span>\n<span class=\"math-container\">$$p(d^i_3) = N(d^i_3|\\mathrm{E}_{(d^i_1, d^i_2)},\\mathrm{Var}_{(d^i_1, d^i_2)})$$</span></p>\n\n<h2>P.S.</h2>\n\n<p>The outlier <span class=\"math-container\">$d'$</span> is placed at the border (y=0), just to enhance the visibility. The outlier can be measured with any value of <span class=\"math-container\">$x=[x_1, x_2]$</span>.</p>\n",
                "tags": "<predictive-modeling><outlier><gaussian>",
                "answers": [
                    [
                        "39169",
                        "2",
                        "39165",
                        "",
                        "",
                        "<p>In essence anomaly detection is about finding a metric with which to measure the similarity between instances and then determining a threshold when crossed constitutes an anomaly. There are parametric anomaly detection algorithms which require some hyper-parameters to be set or information about the distribution to be known. There are also non-parametric techniques which do not have these stringent requirements. </p>\n\n<p>Let's consider the simple case of identifying anomalies in a population based on height. We can assume this to be a 1D Gaussian distribution. Now we need a similarity metric, let's use Euclidean distance for simplicity (the difference in individual's heights). Next we need a threshold. </p>\n\n<h1>Classical statistics</h1>\n\n<p>Classical methods would parametrize the Gaussian distribution of your population. Let us assume that after polling our population we identify that the mean height is 170cm with a variance of 15cm. Now we can set the threshold to be any multiple of the variance <span class=\"math-container\">$\\sigma$</span>. Typically we choose <span class=\"math-container\">$3\\sigma$</span> as a thresholds since the ingroup would include 99.7% of the population, all those outside of the <span class=\"math-container\">$3\\sigma$</span> range can thus confidently be said to be anomalous. </p>\n\n<p>You can also look at the application of a generalized likelihood ratio test (GLRT) to find anomalies.</p>\n\n<p>Let's visualize this</p>\n\n<pre><code>import numpy as np\n\ndata = np.random.normal(170, 15, 10000)\n\nplt.hist(data)\nplt.plot([215,215],[0,3000])\nplt.plot([125,125],[0,3000])\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/4Dc9P.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/4Dc9P.png\" alt=\"enter image description here\"></a></p>\n\n<h1>Parametric techniques</h1>\n\n<p>The examples will require that we have prior information regarding the distribution of the data. This technique will fit an ellipse around the Gaussian distribution of our data in order to contain the elements with the highest in-group correlation.</p>\n\n<pre><code>from sklearn.covariance import EllipticEnvelope\nestimator = EllipticEnvelope()\nestimator.fit(data.reshape(-1,1))\n\nplt.scatter(data, np.random.randint(0,1,10000), c=estimator.predict(data.reshape(-1,1)))\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/NXwDd.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/NXwDd.png\" alt=\"enter image description here\"></a></p>\n\n<p>We see that the yellow dots are the 'normal' instances and the dark blue ones are the anomalies. You can also notice that this algorithm selects an anomaly threshold very similar to the one we obtained using classical statistics methods.</p>\n\n<h1>Non-parametric algorithms</h1>\n\n<p>This is a play on the Random Forests algorithm based on an ensemble of decision trees. The decision trees are trained to identify anomalies through information loss decisions and isolating instances of your data.</p>\n\n<pre><code>from sklearn.ensemble import IsolationForest\nestimator = IsolationForest()\nestimator.fit(data.reshape(-1,1))\nplt.scatter(data, np.random.randint(0,1,10000), c=estimator.predict(data.reshape(-1,1)))\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/vtjWQ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/vtjWQ.png\" alt=\"enter image description here\"></a></p>\n\n<h1>Non-parametric <span class=\"math-container\">$p$</span>-value estimation algorithms</h1>\n\n<p>These are personal favorite and have been very successful in a number of tasks.</p>\n\n<p>Learning Minimum Volume Sets\n<a href=\"http://www.stat.rice.edu/~cscott/pubs/minvol06jmlr.pdf\" rel=\"nofollow noreferrer\">http://www.stat.rice.edu/~cscott/pubs/minvol06jmlr.pdf</a></p>\n\n<p>Anomaly Detection with Score functions based on Nearest Neighbor Graphs\n<a href=\"https://arxiv.org/abs/0910.5461\" rel=\"nofollow noreferrer\">https://arxiv.org/abs/0910.5461</a></p>\n\n<p>New statistic in P-value estimation for anomaly detection\n<a href=\"http://ieeexplore.ieee.org/document/6319713/\" rel=\"nofollow noreferrer\">http://ieeexplore.ieee.org/document/6319713/</a></p>\n\n<hr>\n\n<p>I don't have time tonight but tomorrow evening I will elaborate on the GLRT, and the <span class=\"math-container\">$p$</span>-value estimation algorithms.</p>\n\n<hr>\n\n<h1>Extending the above to more dimensions</h1>\n\n<p>Of course all the described algorithm can be extended to <span class=\"math-container\">$n$</span>-dimensions. This is hard to plot so we will go through a 2D example and a 3D example. However, determining the probability of these being anomalies is not so simple. For some of these algorithms you will need to devise some sort of distance metric.</p>\n\n<h2>2D example</h2>\n\n<p>Let's consider this artificial data. Where tall people above 170cm have eye colors with a blue content of mean 1 and variance 0.5. And short people have lower blue content at a mean 0 and variance 0.5 (let's just assume eyes can have negative pigmentation whatever that could possibly mean).</p>\n\n<pre><code>import numpy as np\n\nn = 10000\nX = np.zeros((n,2))\nX[:,0] = np.random.normal(170, 15, n)\nfor i in range(n):\n    if X[i,0] &lt; 170:\n        X[i,1] = np.random.normal(0, 0.5)\n    else:\n        X[i,1] = np.random.normal(1, 0.5)\n\nplt.scatter(X[:,0], X[:,1])\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/ElH3A.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ElH3A.png\" alt=\"enter image description here\"></a></p>\n\n<h3>Classical statistics</h3>\n\n<p>Any p-value test used in classical statistics can be extended to multiple dimensions. This is the easiest when the features are uncorrelated. When this is the case the probability of each feature can be multiplied together. If this is not the case then you need to compute the p-value for a 2D Gaussian distribution. </p>\n\n<p>For our case this is even worse! It's bimodal (there are two means for a feature). You can see this <a href=\"https://en.wikipedia.org/wiki/Multimodal_distribution\" rel=\"nofollow noreferrer\">here</a>. Our data would look something like this image from the Wiki.</p>\n\n<p><a href=\"https://i.stack.imgur.com/oascg.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/oascg.png\" alt=\"enter image description here\"></a></p>\n\n<p>I hope you can appreciate how difficult this problem is to solve. Luckily this is no longer the classical era of statistics. </p>\n\n<h2>Parametric techniques</h2>\n\n<p>These algorithms can easily be moved onto <span class=\"math-container\">$n$</span>-dimensions.</p>\n\n<pre><code>from sklearn.covariance import EllipticEnvelope\nestimator = EllipticEnvelope()\nestimator.fit(X)\nplt.scatter(X[:,0], X[:,1], c=estimator.predict(X))\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/WaZRQ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WaZRQ.png\" alt=\"enter image description here\"></a></p>\n\n<p>In the 1D example we discussed how this algorithm assumes a unimodal Gaussian distribution. This is not the case for our current data and you can see the failures of this model. It seems to classify many extreme examples as being part of the nominal set when they should have likely been identified as anomalies. </p>\n\n<h2>Non-parametric techniques</h2>\n\n<p>This technique can also be applied to <span class=\"math-container\">$n$</span>-dimensional data. Moreover, it can be used for multimodal Gaussian distributions as you can see we get better results.</p>\n\n<pre><code>from sklearn.ensemble import IsolationForest\nestimator = IsolationForest()\nestimator.fit(X)\nplt.scatter(X[:,0], X[:,1], c=estimator.predict(X))\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/drcSv.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/drcSv.png\" alt=\"enter image description here\"></a></p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4836",
            "_score": 5.255928,
            "_source": {
                "title": "Training LSTM Recurrent Network in TensorFlow",
                "content": "Training LSTM Recurrent Network in TensorFlow <p>I have trained RNN's before \"by hand\" using basic tools like Numpy or BLAS, but I am having trouble getting a simple RNN to converge in TF. <a href=\"https://github.com/aidan-plenert-macdonald/lstm-practice/blob/master/lstm.py\" rel=\"nofollow noreferrer\">Full Code</a></p>\n\n<p>I tried standard things like adjusting the learning rate, the momentum, and adding noise to the gradient, but I am concerned that I don't understand what TF is doing underneath.</p>\n\n<p>In a couple tutorials, it appeared that in TF you train the networks like Echo State Networks where the hidden state is evolved on random interconnections to train up a reservoir, then you use a linear (or non-linear) transformation to map the hidden state onto your labels.</p>\n\n<p>I examined the gradients that Tensorflow uses to train, and it appears that it is training the internal state transition matrices as one would expect if using \"Back-Propagation Through Time\", which I can't tell if it is trying to use.</p>\n\n<p>Can you help me understand what I am doing/understanding incorrectly with regards to training RNN's in TF?</p>\n\n<pre><code>cell_layer = tf.contrib.rnn.BasicLSTMCell(state_size, state_is_tuple=True)\ncell = tf.contrib.rnn.MultiRNNCell([cell_layer]*1)\nx, y_ = tf.placeholder(tf.float32, shape=(batch_size,1)), tf.placeholder(tf.float32, shape=(batch_size,1))\noutputs, states = tf.nn.dynamic_rnn(cell, tf.expand_dims(x, -1), dtype=tf.float32)# init_state)\n\nW = tf.Variable(tf.random_uniform((state_size, 1), -1.0, 1.0))\nb = tf.Variable(tf.random_uniform((1, 1), -1.0, 1.0))\ny = tf.matmul(tf.reshape(outputs, (-1, state_size)), W) + b\n\nloss = tf.reduce_mean(tf.square(y - y_))\nopt = tf.train.MomentumOptimizer(1e-3, 0.9)\ngrad = [(g + tf.random_uniform(v.shape, -1.0, 1.0) * tf.reduce_mean(tf.abs(v))*noise, v)\n        for g, v in opt.compute_gradients(loss)]\ntrain = opt.apply_gradients(grad)\n</code></pre>\n\n<p>EDIT: Loss plot</p>\n\n<p><a href=\"https://i.stack.imgur.com/XjLNK.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/XjLNK.png\" alt=\"Loss vs. Iteration\"></a></p>\n\n<p>I am less concerned about the loss than I am about the fact that there appear to not be any dynamics in between iterations. It appears to converge to the average. Below are some of the later losses and a part of the sequence to be predicted.</p>\n\n<pre><code>Loss:  11.9126\nActual:  bcdefghijklabcdefghijklabcdefghijklabcde\nPred:    ffffffffffffffffffffffffffffffffffffffff\n\nLoss:  11.9092\nActual:  bcdefghijklabcdefghijklabcdefghijklabcde\nPred:    ffffffffffffffffffffffffffffffffffffffff\n\nLoss:  11.918\nActual:  bcdefghijklabcdefghijklabcdefghijklabcde\nPred:    ffffffffffffffffffffffffffffffffffffffff\n\nLoss:  11.9274\nActual:  bcdefghijklabcdefghijklabcdefghijklabcde\nPred:    ffffffffffffffffffffffffffffffffffffffff\n</code></pre>\n\n<p>Note</p>\n\n<pre><code>&gt;&gt;&gt; s = 'bcdefghijklabcdefghijklabcdefghijklabcde'\n&gt;&gt;&gt; n = map(ord, s)\n&gt;&gt;&gt; chr(sum(n)/len(n))\n'f'\n</code></pre>\n <tensorflow><rnn><p>I removed the gradient noise (which did not seem to help, at least as you did it) and replaced your momentum optimizer with Adam using the default hyperparameters and it just worked. After 10,000 epochs I got a loss of ~8 with bcdefghijklabcdefghijklabcdefghijklabcde (actual) vs ccdeeffgghhiccdeeffgghhiccdeeffgghhiccde (predicted).</p>\n\n<p>The moral is that optimizing neural networks is still an art.</p>\n\n<p><a href=\"https://i.stack.imgur.com/C0P3i.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/C0P3i.png\" alt=\"Plot every 100 iterations\"></a></p>\n\n<p>p.s. It seems weird to use a regression loss with a classification problem.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "18983",
                "question_votes:": "1",
                "question_text:": "<p>I have trained RNN's before \"by hand\" using basic tools like Numpy or BLAS, but I am having trouble getting a simple RNN to converge in TF. <a href=\"https://github.com/aidan-plenert-macdonald/lstm-practice/blob/master/lstm.py\" rel=\"nofollow noreferrer\">Full Code</a></p>\n\n<p>I tried standard things like adjusting the learning rate, the momentum, and adding noise to the gradient, but I am concerned that I don't understand what TF is doing underneath.</p>\n\n<p>In a couple tutorials, it appeared that in TF you train the networks like Echo State Networks where the hidden state is evolved on random interconnections to train up a reservoir, then you use a linear (or non-linear) transformation to map the hidden state onto your labels.</p>\n\n<p>I examined the gradients that Tensorflow uses to train, and it appears that it is training the internal state transition matrices as one would expect if using \"Back-Propagation Through Time\", which I can't tell if it is trying to use.</p>\n\n<p>Can you help me understand what I am doing/understanding incorrectly with regards to training RNN's in TF?</p>\n\n<pre><code>cell_layer = tf.contrib.rnn.BasicLSTMCell(state_size, state_is_tuple=True)\ncell = tf.contrib.rnn.MultiRNNCell([cell_layer]*1)\nx, y_ = tf.placeholder(tf.float32, shape=(batch_size,1)), tf.placeholder(tf.float32, shape=(batch_size,1))\noutputs, states = tf.nn.dynamic_rnn(cell, tf.expand_dims(x, -1), dtype=tf.float32)# init_state)\n\nW = tf.Variable(tf.random_uniform((state_size, 1), -1.0, 1.0))\nb = tf.Variable(tf.random_uniform((1, 1), -1.0, 1.0))\ny = tf.matmul(tf.reshape(outputs, (-1, state_size)), W) + b\n\nloss = tf.reduce_mean(tf.square(y - y_))\nopt = tf.train.MomentumOptimizer(1e-3, 0.9)\ngrad = [(g + tf.random_uniform(v.shape, -1.0, 1.0) * tf.reduce_mean(tf.abs(v))*noise, v)\n        for g, v in opt.compute_gradients(loss)]\ntrain = opt.apply_gradients(grad)\n</code></pre>\n\n<p>EDIT: Loss plot</p>\n\n<p><a href=\"https://i.stack.imgur.com/XjLNK.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/XjLNK.png\" alt=\"Loss vs. Iteration\"></a></p>\n\n<p>I am less concerned about the loss than I am about the fact that there appear to not be any dynamics in between iterations. It appears to converge to the average. Below are some of the later losses and a part of the sequence to be predicted.</p>\n\n<pre><code>Loss:  11.9126\nActual:  bcdefghijklabcdefghijklabcdefghijklabcde\nPred:    ffffffffffffffffffffffffffffffffffffffff\n\nLoss:  11.9092\nActual:  bcdefghijklabcdefghijklabcdefghijklabcde\nPred:    ffffffffffffffffffffffffffffffffffffffff\n\nLoss:  11.918\nActual:  bcdefghijklabcdefghijklabcdefghijklabcde\nPred:    ffffffffffffffffffffffffffffffffffffffff\n\nLoss:  11.9274\nActual:  bcdefghijklabcdefghijklabcdefghijklabcde\nPred:    ffffffffffffffffffffffffffffffffffffffff\n</code></pre>\n\n<p>Note</p>\n\n<pre><code>&gt;&gt;&gt; s = 'bcdefghijklabcdefghijklabcdefghijklabcde'\n&gt;&gt;&gt; n = map(ord, s)\n&gt;&gt;&gt; chr(sum(n)/len(n))\n'f'\n</code></pre>\n",
                "tags": "<tensorflow><rnn>",
                "answers": [
                    [
                        "19017",
                        "2",
                        "18983",
                        "",
                        "",
                        "<p>I removed the gradient noise (which did not seem to help, at least as you did it) and replaced your momentum optimizer with Adam using the default hyperparameters and it just worked. After 10,000 epochs I got a loss of ~8 with bcdefghijklabcdefghijklabcdefghijklabcde (actual) vs ccdeeffgghhiccdeeffgghhiccdeeffgghhiccde (predicted).</p>\n\n<p>The moral is that optimizing neural networks is still an art.</p>\n\n<p><a href=\"https://i.stack.imgur.com/C0P3i.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/C0P3i.png\" alt=\"Plot every 100 iterations\"></a></p>\n\n<p>p.s. It seems weird to use a regression loss with a classification problem.</p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7069",
            "_score": 5.255928,
            "_source": {
                "title": "Is it possible to use the saved xgboost model (with one-hot encoding features) on unseen data (without one-hot encoding) for prediction?",
                "content": "Is it possible to use the saved xgboost model (with one-hot encoding features) on unseen data (without one-hot encoding) for prediction? <p>I think the question is self-explanatory. But let's say you have a data with a few features with categorical data, and when building a model for example XGBoost you one-hot encode categorical features. Now you want to do prediction based on test data using the saved model. Obviously the test data needs to be one-hot encoded and need have similar features as training set. The question is whether it is possible to find a way not one-hot encode the test data and directly use it for prediction? Would this be somehow possible? </p>\n\n<p>To me it appears that whatever comes in to my saved model need to be as it was used during training i.e. one-hot encoded features! But this is not neat, especially when building widgets and dashboards!</p>\n\n<p>Any comments/hints are appreciated. </p>\n <machine-learning><xgboost><prediction><p>A model is built on a specific set of features, which may include categorical features encoded using one-hot encoding.  If you have new data with additional categories, your model has no idea how to interpret the significance of those categories.  You should either map the new value to <em>none</em> of the 1-hot values identified in training, or to an 'other' value.</p>\n\n<p>For example, say you trained on data that had color=[blue,green].  Your one-hot fields would have color_blue and color_green.  You could also have a field called color=other, that you might use to encode very infrequent values.  That's a data preparation choice. So for 'red', you could encode that as either:</p>\n\n<ul>\n<li>color_green = 0</li>\n<li>color_blue = 0</li>\n</ul>\n\n<p>or</p>\n\n<ul>\n<li>color_green = 0</li>\n<li>color_blue = 0</li>\n<li>color_other = 1</li>\n</ul>\n\n<p>Using either of these techniques will work with xgboost, but as xgboost only accepts numeric inputs, you will have to choose one of these methods as a data pre-processing step.</p>\n<p>Since its pretty old post, possibly this response is helpful for others.</p>\n\n<p>Its true that some of the algo's accept data in Categorical format and internally converts into OneHotEncoding. In such cases, model accept the data in raw format and doesnt require any explicit conversion handling.</p>\n\n<p>In case if it's not supported, we have to save both the models, i.e.</p>\n\n<ol>\n<li>Model used for Encoding the data</li>\n<li>Model used for predicting the data</li>\n</ol>\n\n<p>In a simpler way we can save related models in a single file as well.\nRefer code snippet below:</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import OneHotEncoder\nimport pickle as pk\nimport pandas as pd\nimport numpy as np\n\nX,y = pd.read_csv(&lt;\"Some_file.csv\"&gt;) #replace with actual csv file\nfile = open(\"models.pkl\", \"wb\")\n\nencoder = OneHotEncoder(sparse=False)\noneHotEncodedFeature = encoder.fit_transform(X[&lt;'Categorical_feature'&gt;].values.reshape(-1,1))\npk.dump(encoder,file)\n\n# Some processing for concatenating oneHotEncodedFeature with other features and assume it its X again.\nlinReg = LinearRegression()\nlinReg.fit(X,y)\npk.dump(encoder,linReg)\nfile.close()\n\n#Now for prediction in future i.e. during production setup\n\nfile = open(\"model.pkl\", \"rb\")\ntrained_encoder = pk.load(file)\ntrained_model_for_prediction = pk.load(file)\n</code></pre>\n",
                "codes": [
                    [],
                    [
                        "from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import OneHotEncoder\nimport pickle as pk\nimport pandas as pd\nimport numpy as np\n\nX,y = pd.read_csv(<\"Some_file.csv\">) #replace with actual csv file\nfile = open(\"models.pkl\", \"wb\")\n\nencoder = OneHotEncoder(sparse=False)\noneHotEncodedFeature = encoder.fit_transform(X[<'Categorical_feature'>].values.reshape(-1,1))\npk.dump(encoder,file)\n\n# Some processing for concatenating oneHotEncodedFeature with other features and assume it its X again.\nlinReg = LinearRegression()\nlinReg.fit(X,y)\npk.dump(encoder,linReg)\nfile.close()\n\n#Now for prediction in future i.e. during production setup\n\nfile = open(\"model.pkl\", \"rb\")\ntrained_encoder = pk.load(file)\ntrained_model_for_prediction = pk.load(file)\n"
                    ]
                ],
                "question_id:": "26797",
                "question_votes:": "1",
                "question_text:": "<p>I think the question is self-explanatory. But let's say you have a data with a few features with categorical data, and when building a model for example XGBoost you one-hot encode categorical features. Now you want to do prediction based on test data using the saved model. Obviously the test data needs to be one-hot encoded and need have similar features as training set. The question is whether it is possible to find a way not one-hot encode the test data and directly use it for prediction? Would this be somehow possible? </p>\n\n<p>To me it appears that whatever comes in to my saved model need to be as it was used during training i.e. one-hot encoded features! But this is not neat, especially when building widgets and dashboards!</p>\n\n<p>Any comments/hints are appreciated. </p>\n",
                "tags": "<machine-learning><xgboost><prediction>",
                "answers": [
                    [
                        "26798",
                        "2",
                        "26797",
                        "",
                        "",
                        "<p>A model is built on a specific set of features, which may include categorical features encoded using one-hot encoding.  If you have new data with additional categories, your model has no idea how to interpret the significance of those categories.  You should either map the new value to <em>none</em> of the 1-hot values identified in training, or to an 'other' value.</p>\n\n<p>For example, say you trained on data that had color=[blue,green].  Your one-hot fields would have color_blue and color_green.  You could also have a field called color=other, that you might use to encode very infrequent values.  That's a data preparation choice. So for 'red', you could encode that as either:</p>\n\n<ul>\n<li>color_green = 0</li>\n<li>color_blue = 0</li>\n</ul>\n\n<p>or</p>\n\n<ul>\n<li>color_green = 0</li>\n<li>color_blue = 0</li>\n<li>color_other = 1</li>\n</ul>\n\n<p>Using either of these techniques will work with xgboost, but as xgboost only accepts numeric inputs, you will have to choose one of these methods as a data pre-processing step.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "53767",
                        "2",
                        "26797",
                        "",
                        "",
                        "<p>Since its pretty old post, possibly this response is helpful for others.</p>\n\n<p>Its true that some of the algo's accept data in Categorical format and internally converts into OneHotEncoding. In such cases, model accept the data in raw format and doesnt require any explicit conversion handling.</p>\n\n<p>In case if it's not supported, we have to save both the models, i.e.</p>\n\n<ol>\n<li>Model used for Encoding the data</li>\n<li>Model used for predicting the data</li>\n</ol>\n\n<p>In a simpler way we can save related models in a single file as well.\nRefer code snippet below:</p>\n\n<pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import OneHotEncoder\nimport pickle as pk\nimport pandas as pd\nimport numpy as np\n\nX,y = pd.read_csv(&lt;\"Some_file.csv\"&gt;) #replace with actual csv file\nfile = open(\"models.pkl\", \"wb\")\n\nencoder = OneHotEncoder(sparse=False)\noneHotEncodedFeature = encoder.fit_transform(X[&lt;'Categorical_feature'&gt;].values.reshape(-1,1))\npk.dump(encoder,file)\n\n# Some processing for concatenating oneHotEncodedFeature with other features and assume it its X again.\nlinReg = LinearRegression()\nlinReg.fit(X,y)\npk.dump(encoder,linReg)\nfile.close()\n\n#Now for prediction in future i.e. during production setup\n\nfile = open(\"model.pkl\", \"rb\")\ntrained_encoder = pk.load(file)\ntrained_model_for_prediction = pk.load(file)\n</code></pre>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16265",
            "_score": 5.255928,
            "_source": {
                "title": "Reproduce Linear Regression Classification Masking Graph of ESL",
                "content": "Reproduce Linear Regression Classification Masking Graph of ESL <p>I would like to reproduce the following graph from the Elements of Statistical Learning Chapter 4 Linear Methods for Classification. It shows the classification masking problem if using linear regression, in which the decision boundaries coincide into one line.  <a href=\"https://i.stack.imgur.com/QzdfDm.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/QzdfDm.png\" alt=\"Classification masking from ESL\"></a> </p>\n\n<p>To reproduce the graph, I generated a dataset using 'make_blobs' from 'sklearn'. Unfortunately, I get the following graph instead, where the decision boundaries don't coincide. The decision boundary between class <span class=\"math-container\">$i$</span> and <span class=\"math-container\">$j$</span> is the line <span class=\"math-container\">$(x_1, x_2)$</span> satisfying \n<span class=\"math-container\">\\begin{equation}\nb_{0,i} + b^T_i (x_1,x_2) = b_{0,j} + b^T_j(x_1,x_2)\n\\end{equation}</span> \nTo make the decision boundaries coincide, we must have \n<span class=\"math-container\">\\begin{align}\nb_2 - b_1 &amp;= b_3 - b_2 \\\\\nb_{0,2} - b_{0,1} &amp;= b_{0,3} - b_{0,2}\n\\end{align}</span></p>\n\n<p>We know that in linear regression, the coefficients <span class=\"math-container\">$B = (X^TX)^{-1}X^TY$</span>. Does it mean I can't simply use 'make_blobs' to randomly generate some datasets? What kind of conditions must the dataset satisfy, in order to make the decision boundaries coincide? </p>\n\n<p>I paste my python code below. How should I modify my code to reproduce the graph in ESL?</p>\n\n<p><a href=\"https://i.stack.imgur.com/mKa5Ym.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/mKa5Ym.png\" alt=\"My re-produce work\"></a></p>\n\n<pre><code>import numpy as np\n\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\n\nimport matplotlib.pyplot as  plt\nfrom matplotlib import cm\n\nn_samples = 3000\ncenters = ((-5,-5), (0,0), (5,5))\nX, y = make_blobs(n_samples=n_samples, n_features=2, centers=centers, cluster_std=1,\n                  random_state=0)    \n\n\n# =============================================================================\n# Transform Y into one-hot-vector    \n# =============================================================================\ny_unique = np.unique(y)\nenc = OneHotEncoder(categories=[y_unique], sparse=True)\nY = enc.fit_transform(y.reshape(-1,1))\n\nlr = LinearRegression().fit(X,Y.todense())\nB0 = lr.intercept_\nB = lr.coef_\n# =============================================================================\n# Compute the decision boundaries\n# =============================================================================\nx_plt = np.arange(-8,8,0.1)\n\ndef get_boundary_y_values( x_plt, B0, B, class1, class2):\n    c = B0[class1] - B0[class2]\n    b = B[class2] - B[class1]\n    if b[1] != 0 :\n        return (c - b[0]*x_plt)/b[1]\n    else:\n        print(\"y is 0\")\n        return 0\n\ny1_plt = get_boundary_y_values(x_plt, B0, B, 0, 1)\ny2_plt = get_boundary_y_values(x_plt, B0, B, 0, 2)    \ny3_plt = get_boundary_y_values(x_plt, B0, B, 1, 2)    \n\n#=============================================================================\n# Plotting the output\n# =============================================================================\n\ncolors = cm.rainbow(np.linspace(0,1,y_unique.size))\nfor this_y, color in zip(y_unique, colors):\n    this_x = X[y==this_y]\n    plt.scatter(this_x[:,0], this_x[:,1], marker='.', color=color, \n                label=\"Class %s\" %this_y) \n\nplt.plot(x_plt, y1_plt, 'r')\nplt.plot(x_plt, y2_plt, 'b')\nplt.plot(x_plt, y3_plt, 'm')\n</code></pre>\n <machine-learning><python><classification><linear-regression>",
                "codes": [],
                "question_id:": "53700",
                "question_votes:": "",
                "question_text:": "<p>I would like to reproduce the following graph from the Elements of Statistical Learning Chapter 4 Linear Methods for Classification. It shows the classification masking problem if using linear regression, in which the decision boundaries coincide into one line.  <a href=\"https://i.stack.imgur.com/QzdfDm.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/QzdfDm.png\" alt=\"Classification masking from ESL\"></a> </p>\n\n<p>To reproduce the graph, I generated a dataset using 'make_blobs' from 'sklearn'. Unfortunately, I get the following graph instead, where the decision boundaries don't coincide. The decision boundary between class <span class=\"math-container\">$i$</span> and <span class=\"math-container\">$j$</span> is the line <span class=\"math-container\">$(x_1, x_2)$</span> satisfying \n<span class=\"math-container\">\\begin{equation}\nb_{0,i} + b^T_i (x_1,x_2) = b_{0,j} + b^T_j(x_1,x_2)\n\\end{equation}</span> \nTo make the decision boundaries coincide, we must have \n<span class=\"math-container\">\\begin{align}\nb_2 - b_1 &amp;= b_3 - b_2 \\\\\nb_{0,2} - b_{0,1} &amp;= b_{0,3} - b_{0,2}\n\\end{align}</span></p>\n\n<p>We know that in linear regression, the coefficients <span class=\"math-container\">$B = (X^TX)^{-1}X^TY$</span>. Does it mean I can't simply use 'make_blobs' to randomly generate some datasets? What kind of conditions must the dataset satisfy, in order to make the decision boundaries coincide? </p>\n\n<p>I paste my python code below. How should I modify my code to reproduce the graph in ESL?</p>\n\n<p><a href=\"https://i.stack.imgur.com/mKa5Ym.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/mKa5Ym.png\" alt=\"My re-produce work\"></a></p>\n\n<pre><code>import numpy as np\n\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\n\nimport matplotlib.pyplot as  plt\nfrom matplotlib import cm\n\nn_samples = 3000\ncenters = ((-5,-5), (0,0), (5,5))\nX, y = make_blobs(n_samples=n_samples, n_features=2, centers=centers, cluster_std=1,\n                  random_state=0)    \n\n\n# =============================================================================\n# Transform Y into one-hot-vector    \n# =============================================================================\ny_unique = np.unique(y)\nenc = OneHotEncoder(categories=[y_unique], sparse=True)\nY = enc.fit_transform(y.reshape(-1,1))\n\nlr = LinearRegression().fit(X,Y.todense())\nB0 = lr.intercept_\nB = lr.coef_\n# =============================================================================\n# Compute the decision boundaries\n# =============================================================================\nx_plt = np.arange(-8,8,0.1)\n\ndef get_boundary_y_values( x_plt, B0, B, class1, class2):\n    c = B0[class1] - B0[class2]\n    b = B[class2] - B[class1]\n    if b[1] != 0 :\n        return (c - b[0]*x_plt)/b[1]\n    else:\n        print(\"y is 0\")\n        return 0\n\ny1_plt = get_boundary_y_values(x_plt, B0, B, 0, 1)\ny2_plt = get_boundary_y_values(x_plt, B0, B, 0, 2)    \ny3_plt = get_boundary_y_values(x_plt, B0, B, 1, 2)    \n\n#=============================================================================\n# Plotting the output\n# =============================================================================\n\ncolors = cm.rainbow(np.linspace(0,1,y_unique.size))\nfor this_y, color in zip(y_unique, colors):\n    this_x = X[y==this_y]\n    plt.scatter(this_x[:,0], this_x[:,1], marker='.', color=color, \n                label=\"Class %s\" %this_y) \n\nplt.plot(x_plt, y1_plt, 'r')\nplt.plot(x_plt, y2_plt, 'b')\nplt.plot(x_plt, y3_plt, 'm')\n</code></pre>\n",
                "tags": "<machine-learning><python><classification><linear-regression>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7322",
            "_score": 5.2454157,
            "_source": {
                "title": "Keras LSTM with 1D time series",
                "content": "Keras LSTM with 1D time series <p>I'm learning how to use Keras and I've had reasonable success with my labelled dataset using the examples on Chollet's <em>Deep Learning for Python</em>. The data set is ~1000 Time Series with length 3125 with 3 potential classes.</p>\n\n<p>I'd like to go beyond the basic <em>Dense</em> layers which give me about 70% prediction rate and the book goes on to discuss LSTM and RNN layers.</p>\n\n<p>All the examples seem to use datasets with multiple features for each timeseries and I'm struggling to work out how to implement my data as a result.</p>\n\n<p>If for example, I have 1000x3125 Time Series, how do I feed that into something like the SimpleRNN or LSTM layer? Am I missing some fundamental knowledge of what these layers do?</p>\n\n<h3>Current code:</h3>\n\n<pre><code>import pandas as pd\nimport numpy as np\nimport os\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM, Dropout, SimpleRNN, Embedding, Reshape\nfrom keras.utils import to_categorical\nfrom keras import regularizers\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\ndef readData():\n    # Get labels from the labels.txt file\n    labels = pd.read_csv('labels.txt', header = None)\n    labels = labels.values\n    labels = labels-1\n    print('One Hot Encoding Data...')\n    labels = to_categorical(labels)\n\n    data = pd.read_csv('ts.txt', header = None)\n\n    return data, labels\n\nprint('Reading data...')\ndata, labels = readData()\n\nprint('Splitting Data')\ndata_train, data_test, labels_train, labels_test = train_test_split(data, labels)\n\nprint('Building Model...')\n#Create model\nmodel = Sequential()\n## LSTM / RNN goes here ##\nmodel.add(Dense(3, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nprint('Training NN...')\nhistory = model.fit(data_train, labels_train, epochs=1000, batch_size=50,\n    validation_split=0.25,verbose=2)\n\nresults = model.evaluate(data_test, labels_test)\n\npredictions = model.predict(data_test)\n\nprint(predictions[0].shape)\nprint(np.sum(predictions[0]))\nprint(np.argmax(predictions[0]))\n\nprint(results)\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n</code></pre>\n <python><deep-learning><time-series><lstm><rnn><p>LSTM layers require data of a different shape.</p>\n\n<p>From your description, I understand the starting dataset to have 3125 rows and 1000 columns, where each row is one time-step. The target variable should then have 3125 rows and 1 column, where each value can be one of three possible values. So it sounds like you're doing a classification problem. To check this in code, I would do:</p>\n\n<pre><code>&gt;&gt;&gt; X.shape\n(3125, 1000)\n\n&gt;&gt;&gt; y.shape\n(1000,)\n</code></pre>\n\n<p>The LSTM class requires each single sample to consist of a 'block' of time. Let's say you want to have a block of 100 time-steps. This means <code>X[0:100]</code> is a single input sample, which corresponds to the target variable at <code>y[100]</code>. this means your window size (a.k.a number of time-steps or number of lags) is equal to 100. As stated above, you have 3125 samples, so <code>N = 3125</code>. To form the first block, we unfortunately have to discard the first 100 samples of <code>y</code>, as we cannot form an entire block of 100 from the available data (we would end up needing the data points before <code>X[0]</code>).</p>\n\n<p>Given all this, an LSTM requires you to deliver batches of shape <code>(N - window_size, window_size, num_features)</code>, which translates into <code>(3125 - 100, 100, 1000)</code> == <code>(3025, 100, 1000)</code>.</p>\n\n<p>Creating these time-blocks is a bit of a hassle, but create a good function once, then save it  :)</p>\n\n<p>There is more work to be done, perhaps look at more in depth examples of my explanation above <a href=\"https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/\" rel=\"noreferrer\">here</a>... or have a read of the <a href=\"https://keras.io/layers/recurrent/#lstm\" rel=\"noreferrer\">LSTM documentation</a>, (or better still, <a href=\"https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L1906\" rel=\"noreferrer\">the source code!</a>).</p>\n\n<p>The final model would then be simple enough (based on your code):</p>\n\n<pre><code>#Create model\nmodel = Sequential()\nmodel.add(LSTM(units=32, activation='relu',\n               input_shape=(100, 1000))    # the batch size is neglected!\nmodel.add(Dense(3, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',\n              metrics=['accuracy'])\n</code></pre>\n\n<p>Have a look at <a href=\"https://keras.io/getting-started/sequential-model-guide/#specifying-the-input-shape\" rel=\"noreferrer\">the documentation regarding input shape for the <code>Sequential</code> model</a>. It basically says that we don't need to specify the number of batches within <code>input_shape</code>. It can be done with e.g. <code>batch_size=50</code>, if you require it to be a fixed number.</p>\n\n<p>I know the <code>input_shape</code> argument is not in the documentation for <code>LSTM</code>, but the class itself inherits from <a href=\"https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L212\" rel=\"noreferrer\"><code>RNN</code></a>, which in turn inherits from <a href=\"https://github.com/keras-team/keras/blob/master/keras/engine/topology.py#L191\" rel=\"noreferrer\"><code>Layer</code></a> - so it will be able to use the info you provide.</p>\n\n<p><strong>One last tip:</strong> if you plan on adding several LSTM layers ('stacking' them), then you shall need to add one more argument to all but the <em>last</em> <code>LSTM</code>, namely, the <code>return_sequences=True</code>.</p>\n",
                "codes": [
                    [
                        ">>> X.shape\n(3125, 1000)\n\n>>> y.shape\n(1000,)\n",
                        "#Create model\nmodel = Sequential()\nmodel.add(LSTM(units=32, activation='relu',\n               input_shape=(100, 1000))    # the batch size is neglected!\nmodel.add(Dense(3, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',\n              metrics=['accuracy'])\n"
                    ]
                ],
                "question_id:": "27533",
                "question_votes:": "9",
                "question_text:": "<p>I'm learning how to use Keras and I've had reasonable success with my labelled dataset using the examples on Chollet's <em>Deep Learning for Python</em>. The data set is ~1000 Time Series with length 3125 with 3 potential classes.</p>\n\n<p>I'd like to go beyond the basic <em>Dense</em> layers which give me about 70% prediction rate and the book goes on to discuss LSTM and RNN layers.</p>\n\n<p>All the examples seem to use datasets with multiple features for each timeseries and I'm struggling to work out how to implement my data as a result.</p>\n\n<p>If for example, I have 1000x3125 Time Series, how do I feed that into something like the SimpleRNN or LSTM layer? Am I missing some fundamental knowledge of what these layers do?</p>\n\n<h3>Current code:</h3>\n\n<pre><code>import pandas as pd\nimport numpy as np\nimport os\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM, Dropout, SimpleRNN, Embedding, Reshape\nfrom keras.utils import to_categorical\nfrom keras import regularizers\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\ndef readData():\n    # Get labels from the labels.txt file\n    labels = pd.read_csv('labels.txt', header = None)\n    labels = labels.values\n    labels = labels-1\n    print('One Hot Encoding Data...')\n    labels = to_categorical(labels)\n\n    data = pd.read_csv('ts.txt', header = None)\n\n    return data, labels\n\nprint('Reading data...')\ndata, labels = readData()\n\nprint('Splitting Data')\ndata_train, data_test, labels_train, labels_test = train_test_split(data, labels)\n\nprint('Building Model...')\n#Create model\nmodel = Sequential()\n## LSTM / RNN goes here ##\nmodel.add(Dense(3, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nprint('Training NN...')\nhistory = model.fit(data_train, labels_train, epochs=1000, batch_size=50,\n    validation_split=0.25,verbose=2)\n\nresults = model.evaluate(data_test, labels_test)\n\npredictions = model.predict(data_test)\n\nprint(predictions[0].shape)\nprint(np.sum(predictions[0]))\nprint(np.argmax(predictions[0]))\n\nprint(results)\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n</code></pre>\n",
                "tags": "<python><deep-learning><time-series><lstm><rnn>",
                "answers": [
                    [
                        "27535",
                        "2",
                        "27533",
                        "",
                        "",
                        "<p>LSTM layers require data of a different shape.</p>\n\n<p>From your description, I understand the starting dataset to have 3125 rows and 1000 columns, where each row is one time-step. The target variable should then have 3125 rows and 1 column, where each value can be one of three possible values. So it sounds like you're doing a classification problem. To check this in code, I would do:</p>\n\n<pre><code>&gt;&gt;&gt; X.shape\n(3125, 1000)\n\n&gt;&gt;&gt; y.shape\n(1000,)\n</code></pre>\n\n<p>The LSTM class requires each single sample to consist of a 'block' of time. Let's say you want to have a block of 100 time-steps. This means <code>X[0:100]</code> is a single input sample, which corresponds to the target variable at <code>y[100]</code>. this means your window size (a.k.a number of time-steps or number of lags) is equal to 100. As stated above, you have 3125 samples, so <code>N = 3125</code>. To form the first block, we unfortunately have to discard the first 100 samples of <code>y</code>, as we cannot form an entire block of 100 from the available data (we would end up needing the data points before <code>X[0]</code>).</p>\n\n<p>Given all this, an LSTM requires you to deliver batches of shape <code>(N - window_size, window_size, num_features)</code>, which translates into <code>(3125 - 100, 100, 1000)</code> == <code>(3025, 100, 1000)</code>.</p>\n\n<p>Creating these time-blocks is a bit of a hassle, but create a good function once, then save it  :)</p>\n\n<p>There is more work to be done, perhaps look at more in depth examples of my explanation above <a href=\"https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/\" rel=\"noreferrer\">here</a>... or have a read of the <a href=\"https://keras.io/layers/recurrent/#lstm\" rel=\"noreferrer\">LSTM documentation</a>, (or better still, <a href=\"https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L1906\" rel=\"noreferrer\">the source code!</a>).</p>\n\n<p>The final model would then be simple enough (based on your code):</p>\n\n<pre><code>#Create model\nmodel = Sequential()\nmodel.add(LSTM(units=32, activation='relu',\n               input_shape=(100, 1000))    # the batch size is neglected!\nmodel.add(Dense(3, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',\n              metrics=['accuracy'])\n</code></pre>\n\n<p>Have a look at <a href=\"https://keras.io/getting-started/sequential-model-guide/#specifying-the-input-shape\" rel=\"noreferrer\">the documentation regarding input shape for the <code>Sequential</code> model</a>. It basically says that we don't need to specify the number of batches within <code>input_shape</code>. It can be done with e.g. <code>batch_size=50</code>, if you require it to be a fixed number.</p>\n\n<p>I know the <code>input_shape</code> argument is not in the documentation for <code>LSTM</code>, but the class itself inherits from <a href=\"https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L212\" rel=\"noreferrer\"><code>RNN</code></a>, which in turn inherits from <a href=\"https://github.com/keras-team/keras/blob/master/keras/engine/topology.py#L191\" rel=\"noreferrer\"><code>Layer</code></a> - so it will be able to use the info you provide.</p>\n\n<p><strong>One last tip:</strong> if you plan on adding several LSTM layers ('stacking' them), then you shall need to add one more argument to all but the <em>last</em> <code>LSTM</code>, namely, the <code>return_sequences=True</code>.</p>\n",
                        "",
                        "10"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11925",
            "_score": 5.2454157,
            "_source": {
                "title": "Programming a Neural Network in Python",
                "content": "Programming a Neural Network in Python <p>In order to get some understanding of machine learning (i'm super new to this) I'm programming a neural network and try to train a sinefunction with it. The set-up is as follows:</p>\n\n<ul>\n<li>Backpropagation algorithm with stochastic gradient descent</li>\n<li>1 input (x between [0,2*pi], sine function as target) plus optionally\na biasinput. The sine function is scaled to [0,1]</li>\n<li>a variable no. of hidden layers with a variable no. of hidden units</li>\n<li>sigmoid activation functions</li>\n<li>weights initialized randomly between -0.05 and 0.05</li>\n</ul>\n\n<p>I expected a network with for example 4 hidden layers and 25 hidden units in each hidden layer to be deep enough to predict a sine, but instead the 'learned' output sticks to roughly the average of the scaled sinefunction (i.e 0.5).</p>\n\n<p>I was wondering if somebody has had a similar experience and how it was fixed, or whether I am overlooking/misunderstanding something in my code. In this image ( <a href=\"https://i.stack.imgur.com/h6glp.png\" rel=\"nofollow noreferrer\">https://i.stack.imgur.com/h6glp.png</a> ) I have illustrated the setup and some nomenclature of my code shown below.</p>\n\n<p>Thank you for your time and help!</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nclass neural(object):\n\ndef __init__(self,samples,n_in,n_hidden,n_hlayers,eta,bias):\n    self.samples = samples\n    self.n_in = n_in\n    self.n_out = n_in\n    self.n_hidden = n_hidden\n    self.n_hlayers = n_hlayers\n    self.eta = eta\n    self.bias = bias\n\n    # Prepare data with range [0,1)\n    if self.bias is True:\n        x = 2*np.pi*np.random.rand(self.samples,self.n_in)\n        t = (np.sin(x)+1)/2\n\n        x = np.append(x,np.ones([self.samples,1]),axis=1)\n        self.n_in += 1\n    else:\n        x = 2*np.pi*np.random.rand(self.samples,self.n_in)          \n        t = (np.sin(x)+1)/2\n\n    # Partitioning\n    self.x_train = x[0:self.samples/2]\n    self.t_train = t[0:self.samples/2]\n    self.x_test = x[self.samples/2:]\n    self.t_test = t[self.samples/2:]\n\n    # Create weight matrices\n    self.get_weights()\n\n\ndef get_weights(self):\n    # Initialize weights with values [-b,+b)\n    a = 0.1\n    b = 0.05\n\n    # Weigths from input layer to 1st hidden layer\n    self.w_ih = a*np.random.rand(self.n_hidden, self.n_in)-b\n\n    # Weigths between hidden layers\n    if self.n_hlayers &gt; 1:\n        self.w_hh = np.zeros([self.n_hidden,self.n_hidden,self.n_hlayers-1])\n        for i in range(0,self.n_hlayers-1):\n            self.w_hh[:,:,i] = a*np.random.rand(self.n_hidden, self.n_hidden)-b\n\n    # Weigths from last hidden layer to output layer\n    self.w_ho = a*np.random.rand(self.n_out,self.n_hidden)-b   \n\n\ndef train(self,xi,ti): \n    # 1. Feedforward \n    # Output z from the first hidden layer (right next to the input layer)\n    z = np.zeros([self.n_hidden,1,self.n_hlayers])\n    z[:,:,0] = fsigmoid(np.dot(self.w_ih,xi))\n\n    # Output from other hidden layers\n    if self.n_hlayers &gt; 1:          \n        for i in range(0,self.n_hlayers-1):\n            z[:,:,i+1] = fsigmoid(np.dot(self.w_hh[:,:,i],z[:,:,i]))\n\n    # Output from output layer        \n    o = fsigmoid(np.dot(self.w_ho,z[:,:,-1])) \n\n    # 2. Backpropagation \n    delta_o = o*(np.ones([self.n_out,1])-o)*(ti-o)\n    delta_who = self.eta*np.dot(delta_o,z[:,:,-1].T)\n\n    if self.n_hlayers &gt; 1:\n        # Preallocate 3D array to contain all layers\n        delta_h = np.zeros([self.n_hidden,1,self.n_hlayers])\n        delta_whh = np.zeros([self.n_hidden,self.n_hidden,self.n_hlayers-1])\n\n        # Backpropagation from outer layer to first hidden layer\n        delta_h[:,:,-1] = z[:,:,-1]*(1-z[:,:,-1])*np.dot(self.w_ho.T,delta_o)\n        delta_whh[:,:,-1] = self.eta*np.dot(delta_h[:,:,-1],z[:,:,-2].T)\n\n        # Backpropagation between other hidden layers (walking from right \n        # to left in the network)\n        for i in range(-2,-1*self.n_hlayers,-1):\n            delta_h[:,:,i] = z[:,:,i]*(1-z[:,:,i])*np.dot(self.w_hh[:,:,i+1].T,delta_h[:,:,i+1])\n            delta_whh[:,:,i] = self.eta*np.dot(delta_h[:,:,i],z[:,:,i-1].T) \n\n    # To the input layer\n    if self.n_hlayers &gt; 1:\n        i = -1*self.n_hlayers\n        delta_h[:,:,i] = z[:,:,i]*(1-z[:,:,i])*np.dot(self.w_hh[:,:,i+1].T,delta_h[:,:,i+1])\n        delta_wih = self.eta*np.dot(delta_h[:,:,i],xi.T) \n    else:\n       delta_h = z[:,:,-1]*(1-z[:,:,-1])*np.dot(delta_who.T,delta_o)\n       delta_wih = self.eta*np.dot(delta_h,xi.T)           \n\n    # 3. Update weights\n    self.w_ho += delta_who\n    self.w_ih += delta_wih\n    if self.n_hlayers &gt; 1:\n        self.w_hh += delta_whh\n\n    return o\n\n\ndef fsigmoid(y):\n    sigma = 1/(1+np.exp(-y))\n    return sigma\n\n\ndef relu(y):\n    z = (abs(y)+y)/2\n    return z\n\n\nif __name__ == '__main__':\n\n    network = neural(samples=20000,n_in=1,n_hidden=25,n_hlayers=4,eta=0.01,bias=False)\n\n    # For each training example pair &lt;x(i),t(i)&gt;\n    err = []\n    out = []\n    for i in range(0,network.samples/2):\n        print 'Iteration',i+1\n        xi = network.x_train[i].reshape([network.n_in,1])\n        ti = network.t_train[i].reshape([network.n_out,1])\n        output = network.train(xi,ti)\n\n        # Error of training set\n        RMSerr = np.sqrt(np.sum((output-ti)**2)/network.n_out)\n        err.append(RMSerr)\n\n        # To do: add error of validationset set (prevent overfitting)\n\n        # Save trained output\n        out.append(output[0])\n\n    plt.close('all') \n    plt.plot(network.x_train,out,'.')\n    plt.hold(True)\n    plt.plot(network.x_train,network.t_train,'x')\n</code></pre>\n <python><neural-network>",
                "codes": [],
                "question_id:": "41982",
                "question_votes:": "1",
                "question_text:": "<p>In order to get some understanding of machine learning (i'm super new to this) I'm programming a neural network and try to train a sinefunction with it. The set-up is as follows:</p>\n\n<ul>\n<li>Backpropagation algorithm with stochastic gradient descent</li>\n<li>1 input (x between [0,2*pi], sine function as target) plus optionally\na biasinput. The sine function is scaled to [0,1]</li>\n<li>a variable no. of hidden layers with a variable no. of hidden units</li>\n<li>sigmoid activation functions</li>\n<li>weights initialized randomly between -0.05 and 0.05</li>\n</ul>\n\n<p>I expected a network with for example 4 hidden layers and 25 hidden units in each hidden layer to be deep enough to predict a sine, but instead the 'learned' output sticks to roughly the average of the scaled sinefunction (i.e 0.5).</p>\n\n<p>I was wondering if somebody has had a similar experience and how it was fixed, or whether I am overlooking/misunderstanding something in my code. In this image ( <a href=\"https://i.stack.imgur.com/h6glp.png\" rel=\"nofollow noreferrer\">https://i.stack.imgur.com/h6glp.png</a> ) I have illustrated the setup and some nomenclature of my code shown below.</p>\n\n<p>Thank you for your time and help!</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nclass neural(object):\n\ndef __init__(self,samples,n_in,n_hidden,n_hlayers,eta,bias):\n    self.samples = samples\n    self.n_in = n_in\n    self.n_out = n_in\n    self.n_hidden = n_hidden\n    self.n_hlayers = n_hlayers\n    self.eta = eta\n    self.bias = bias\n\n    # Prepare data with range [0,1)\n    if self.bias is True:\n        x = 2*np.pi*np.random.rand(self.samples,self.n_in)\n        t = (np.sin(x)+1)/2\n\n        x = np.append(x,np.ones([self.samples,1]),axis=1)\n        self.n_in += 1\n    else:\n        x = 2*np.pi*np.random.rand(self.samples,self.n_in)          \n        t = (np.sin(x)+1)/2\n\n    # Partitioning\n    self.x_train = x[0:self.samples/2]\n    self.t_train = t[0:self.samples/2]\n    self.x_test = x[self.samples/2:]\n    self.t_test = t[self.samples/2:]\n\n    # Create weight matrices\n    self.get_weights()\n\n\ndef get_weights(self):\n    # Initialize weights with values [-b,+b)\n    a = 0.1\n    b = 0.05\n\n    # Weigths from input layer to 1st hidden layer\n    self.w_ih = a*np.random.rand(self.n_hidden, self.n_in)-b\n\n    # Weigths between hidden layers\n    if self.n_hlayers &gt; 1:\n        self.w_hh = np.zeros([self.n_hidden,self.n_hidden,self.n_hlayers-1])\n        for i in range(0,self.n_hlayers-1):\n            self.w_hh[:,:,i] = a*np.random.rand(self.n_hidden, self.n_hidden)-b\n\n    # Weigths from last hidden layer to output layer\n    self.w_ho = a*np.random.rand(self.n_out,self.n_hidden)-b   \n\n\ndef train(self,xi,ti): \n    # 1. Feedforward \n    # Output z from the first hidden layer (right next to the input layer)\n    z = np.zeros([self.n_hidden,1,self.n_hlayers])\n    z[:,:,0] = fsigmoid(np.dot(self.w_ih,xi))\n\n    # Output from other hidden layers\n    if self.n_hlayers &gt; 1:          \n        for i in range(0,self.n_hlayers-1):\n            z[:,:,i+1] = fsigmoid(np.dot(self.w_hh[:,:,i],z[:,:,i]))\n\n    # Output from output layer        \n    o = fsigmoid(np.dot(self.w_ho,z[:,:,-1])) \n\n    # 2. Backpropagation \n    delta_o = o*(np.ones([self.n_out,1])-o)*(ti-o)\n    delta_who = self.eta*np.dot(delta_o,z[:,:,-1].T)\n\n    if self.n_hlayers &gt; 1:\n        # Preallocate 3D array to contain all layers\n        delta_h = np.zeros([self.n_hidden,1,self.n_hlayers])\n        delta_whh = np.zeros([self.n_hidden,self.n_hidden,self.n_hlayers-1])\n\n        # Backpropagation from outer layer to first hidden layer\n        delta_h[:,:,-1] = z[:,:,-1]*(1-z[:,:,-1])*np.dot(self.w_ho.T,delta_o)\n        delta_whh[:,:,-1] = self.eta*np.dot(delta_h[:,:,-1],z[:,:,-2].T)\n\n        # Backpropagation between other hidden layers (walking from right \n        # to left in the network)\n        for i in range(-2,-1*self.n_hlayers,-1):\n            delta_h[:,:,i] = z[:,:,i]*(1-z[:,:,i])*np.dot(self.w_hh[:,:,i+1].T,delta_h[:,:,i+1])\n            delta_whh[:,:,i] = self.eta*np.dot(delta_h[:,:,i],z[:,:,i-1].T) \n\n    # To the input layer\n    if self.n_hlayers &gt; 1:\n        i = -1*self.n_hlayers\n        delta_h[:,:,i] = z[:,:,i]*(1-z[:,:,i])*np.dot(self.w_hh[:,:,i+1].T,delta_h[:,:,i+1])\n        delta_wih = self.eta*np.dot(delta_h[:,:,i],xi.T) \n    else:\n       delta_h = z[:,:,-1]*(1-z[:,:,-1])*np.dot(delta_who.T,delta_o)\n       delta_wih = self.eta*np.dot(delta_h,xi.T)           \n\n    # 3. Update weights\n    self.w_ho += delta_who\n    self.w_ih += delta_wih\n    if self.n_hlayers &gt; 1:\n        self.w_hh += delta_whh\n\n    return o\n\n\ndef fsigmoid(y):\n    sigma = 1/(1+np.exp(-y))\n    return sigma\n\n\ndef relu(y):\n    z = (abs(y)+y)/2\n    return z\n\n\nif __name__ == '__main__':\n\n    network = neural(samples=20000,n_in=1,n_hidden=25,n_hlayers=4,eta=0.01,bias=False)\n\n    # For each training example pair &lt;x(i),t(i)&gt;\n    err = []\n    out = []\n    for i in range(0,network.samples/2):\n        print 'Iteration',i+1\n        xi = network.x_train[i].reshape([network.n_in,1])\n        ti = network.t_train[i].reshape([network.n_out,1])\n        output = network.train(xi,ti)\n\n        # Error of training set\n        RMSerr = np.sqrt(np.sum((output-ti)**2)/network.n_out)\n        err.append(RMSerr)\n\n        # To do: add error of validationset set (prevent overfitting)\n\n        # Save trained output\n        out.append(output[0])\n\n    plt.close('all') \n    plt.plot(network.x_train,out,'.')\n    plt.hold(True)\n    plt.plot(network.x_train,network.t_train,'x')\n</code></pre>\n",
                "tags": "<python><neural-network>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3557",
            "_score": 5.073058,
            "_source": {
                "title": "Backpropagation derivation problem",
                "content": "Backpropagation derivation problem <p>I read a few tutorials on neural network backpropagation and decided to implement one from scratch. I tried to find this single error for the past few days I have in my code with no success.</p>\n\n<p>I followed <a href=\"https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\" rel=\"nofollow noreferrer\">this</a> tutorial  in hopes of being able to implement a sine function approximator. This is a simple network: 1 input neuron, 10 hidden neurons and 1 output neuron. The activation function is sigmoid in the second layer. The exact same model easily works in Tensorflow.</p>\n\n<pre><code>def sigmoid(x):\n    return 1 / (1 + np.math.e ** -x)\n\n\ndef sigmoid_deriv(x):\n    return sigmoid(x) * (1 - sigmoid(x))\n\n\nx_data = np.random.rand(500) * 15.0\ny_data = [sin(x) for x in x_data]\n\nETA = .01\n\nlayer1 = 0\nlayer1_weights = np.random.rand(10) * 2. - 1.\nlayer2 = np.zeros(10)\nlayer2_weights = np.random.rand(10) * 2. - 1.\nlayer3 = 0\n\nfor loop_iter in range(500000):\n    # data init\n    index = np.random.randint(0, 500)\n    x = x_data[index]\n    y = y_data[index]\n\n    # forward propagation\n    # layer 1\n    layer1 = x\n\n    # layer 2\n    layer2 = layer1_weights * layer1\n\n    # layer 3\n    layer3 = sum(sigmoid(layer2) * layer2_weights)\n\n    # error\n    error = .5 * (layer3 - y) ** 2  # L2 loss\n\n    # backpropagation\n    # error_wrt_layer3 * layer3_wrt_weights_layer2\n    error_wrt_layer2_weights = (y - layer3) * sigmoid(layer2)\n    # error_wrt_layer3 * layer3_wrt_out_layer2 * out_layer2_wrt_in_layer2 * in_layer2_wrt_weights_layer1\n    error_wrt_layer1_weights = (y - layer3) * layer2_weights * sigmoid_deriv(sigmoid(layer2)) * layer1\n\n    # update the weights\n    layer2_weights -= ETA * error_wrt_layer2_weights\n    layer1_weights -= ETA * error_wrt_layer1_weights\n\n    if loop_iter % 10000 == 0:\n        print(error)\n</code></pre>\n\n<p>The unexpected behavior is simply that the network doesn't converge. Please, review my error_wrt_... derivatives. The problem should be there.</p>\n\n<p>Here's the Tensorflow code it works flawlessly with:</p>\n\n<pre><code>x_data = np.array(np.random.rand(500)).reshape(500, 1)\ny_data = np.array([sin(x) for x in x_data]).reshape(500, 1)\n\nx = tf.placeholder(tf.float32, shape=[None, 1])\ny_true = tf.placeholder(tf.float32, shape=[None, 1])\nW = tf.Variable(tf.random_uniform([1, 10], -1.0, 1.0))\nhidden1 = tf.nn.sigmoid(tf.matmul(x, W))\nW_hidden = tf.Variable(tf.random_uniform([10, 1], -1.0, 1.0))\noutput = tf.matmul(hidden1, W_hidden)\n\nloss = tf.square(output - y_true) / 2.\noptimizer = tf.train.GradientDescentOptimizer(.01)\ntrain = optimizer.minimize(loss)\n\ninit = tf.initialize_all_variables()\nsess = tf.Session()\nsess.run(init)\n\nfor i in range(500000):\n    rand_index = np.random.randint(0, 500)\n    _, error = sess.run([train, loss], feed_dict={x: [x_data[rand_index]],\n                                              y_true: [y_data[rand_index]]})\n    if i % 10000 == 0:\n        print(error)\n\nsess.close()\n</code></pre>\n <deep-learning><backpropagation><p>I think your biggest problem is the lack of biases. Between the input layer and the hidden layer, you should not only transform by the weights but should also add a bias. This bias will shift your sigmoid function to the left or right. Take a look at this code (I made some adaptations).</p>\n\n<p>What is important:</p>\n\n<ol>\n<li>Added biases.</li>\n<li>Altered your error_w such that they are correct.</li>\n<li>Made some good random starting points for biases (<code>np.random.rand(width) * 15. - 7.5</code>) such that all biases are random points on the desired x-scale.</li>\n<li>Made a plot that shows the initial guess and final.</li>\n</ol>\n\n<p>Let me know if some parts are not clear:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\ndef sigmoid(x):\n    return 1 / (1 + np.math.e ** -x)\n\n\ndef sigmoid_deriv(x):\n    return sigmoid(x) * (1 - sigmoid(x))\n\ndef guess(x):\n    layer1 = x\n    z_2 = layer1_weights * layer1 + layer1_biases\n    a_2 =sigmoid(z_2)\n    z_3 = np.dot(a_2, layer2_weights) + layer2_biases\n    # a_3 = sigmoid(z_3)\n    a_3 = z_3\n    return a_3\n\n\nx_data = np.random.rand(500) * 15.0 - 7.5\ny_data = [np.sin(x) for x in x_data]\n\nETA = 0.05\nwidth = 10\n\nlayer1_weights = np.random.rand(width) * 2. - 1.\nlayer1_biases = np.random.rand(width) * 15. - 7.5\nlayer2_weights = np.random.rand(width) * 2. - 1.\nlayer2_biases = np.random.rand(1)* 2. - 1.\n\nerror_all = []\n\nx_all = x_data\ny_all = [guess(x_i) for x_i in x_all]\n\nplt.plot(x_all,y_all, '.')\nplt.plot(x_data, y_data, '.')\nplt.show()\n\nepochs = 500000\n\n\n\nfor loop_iter in range(epochs):\n    # data init\n    index = np.random.randint(0, 500)\n    x = x_data[index]\n    y = y_data[index]\n\n    # forward propagation\n    # layer 1\n    layer1 = x\n\n    # layer 2\n    #TODO add the sigmoid function here\n\n    z_2 = layer1_weights * layer1 + layer1_biases\n    a_2 =sigmoid(z_2)\n\n    # layer 3\n    #TODO remove simgmoid here (not that is really matters, but values at each layer are after sigmoid\n    z_3 = np.dot(a_2, layer2_weights) + layer2_biases\n    # a_3 = sigmoid(z_3)\n    a_3 = z_3\n\n\n    # error\n    error = .5 * (a_3 - y) ** 2  # L2 loss\n\n    # backpropagation\n    # error_wrt_layer3 * layer3_wrt_weights_layer2\n\n    # error_wrt_layer2_weights = (y - layer3) * sigmoid(layer2)\n\n    delta = (a_3 - y)\n\n    error_wrt_layer2_weights = delta * a_2\n    error_wrt_layer2_biases = delta\n\n    # error_wrt_layer3 * layer3_wrt_out_layer2 * out_layer2_wrt_in_layer2 * in_layer2_wrt_weights_layer1\n\n    # error_wrt_layer1_weights = (y - layer3) * layer2_weights * sigmoid_deriv(sigmoid(layer2)) * layer1\n    error_wrt_layer1_weights = delta * np.dot(sigmoid_deriv(z_2), layer2_weights) * layer1\n    # error_wrt_layer1_weights = 0\n\n    error_wrt_layer1_biases =  delta * np.dot(sigmoid_deriv(z_2), layer2_weights)\n\n\n    # a = 0\n    # while a ==0:\n    #   a*0\n\n    # update the weights\n    layer2_weights -= ETA * error_wrt_layer2_weights\n    layer1_weights -= ETA * error_wrt_layer1_weights\n    layer2_biases -= ETA * error_wrt_layer2_biases\n    layer1_biases -= ETA * error_wrt_layer1_biases\n\n    error_all.append(error)\n\n    if loop_iter % 10000 == 0:\n        print(error)\n\n\n\n# plt.plot(error_all)\n# plt.show()\n\nx_all = x_data\ny_all = [guess(x_i) for x_i in x_all]\n\nplt.plot(x_all,y_all, '.')\nplt.plot(x_data, y_data, '.')\nplt.show()\n</code></pre>\n",
                "codes": [
                    [
                        "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef sigmoid(x):\n    return 1 / (1 + np.math.e ** -x)\n\n\ndef sigmoid_deriv(x):\n    return sigmoid(x) * (1 - sigmoid(x))\n\ndef guess(x):\n    layer1 = x\n    z_2 = layer1_weights * layer1 + layer1_biases\n    a_2 =sigmoid(z_2)\n    z_3 = np.dot(a_2, layer2_weights) + layer2_biases\n    # a_3 = sigmoid(z_3)\n    a_3 = z_3\n    return a_3\n\n\nx_data = np.random.rand(500) * 15.0 - 7.5\ny_data = [np.sin(x) for x in x_data]\n\nETA = 0.05\nwidth = 10\n\nlayer1_weights = np.random.rand(width) * 2. - 1.\nlayer1_biases = np.random.rand(width) * 15. - 7.5\nlayer2_weights = np.random.rand(width) * 2. - 1.\nlayer2_biases = np.random.rand(1)* 2. - 1.\n\nerror_all = []\n\nx_all = x_data\ny_all = [guess(x_i) for x_i in x_all]\n\nplt.plot(x_all,y_all, '.')\nplt.plot(x_data, y_data, '.')\nplt.show()\n\nepochs = 500000\n\n\n\nfor loop_iter in range(epochs):\n    # data init\n    index = np.random.randint(0, 500)\n    x = x_data[index]\n    y = y_data[index]\n\n    # forward propagation\n    # layer 1\n    layer1 = x\n\n    # layer 2\n    #TODO add the sigmoid function here\n\n    z_2 = layer1_weights * layer1 + layer1_biases\n    a_2 =sigmoid(z_2)\n\n    # layer 3\n    #TODO remove simgmoid here (not that is really matters, but values at each layer are after sigmoid\n    z_3 = np.dot(a_2, layer2_weights) + layer2_biases\n    # a_3 = sigmoid(z_3)\n    a_3 = z_3\n\n\n    # error\n    error = .5 * (a_3 - y) ** 2  # L2 loss\n\n    # backpropagation\n    # error_wrt_layer3 * layer3_wrt_weights_layer2\n\n    # error_wrt_layer2_weights = (y - layer3) * sigmoid(layer2)\n\n    delta = (a_3 - y)\n\n    error_wrt_layer2_weights = delta * a_2\n    error_wrt_layer2_biases = delta\n\n    # error_wrt_layer3 * layer3_wrt_out_layer2 * out_layer2_wrt_in_layer2 * in_layer2_wrt_weights_layer1\n\n    # error_wrt_layer1_weights = (y - layer3) * layer2_weights * sigmoid_deriv(sigmoid(layer2)) * layer1\n    error_wrt_layer1_weights = delta * np.dot(sigmoid_deriv(z_2), layer2_weights) * layer1\n    # error_wrt_layer1_weights = 0\n\n    error_wrt_layer1_biases =  delta * np.dot(sigmoid_deriv(z_2), layer2_weights)\n\n\n    # a = 0\n    # while a ==0:\n    #   a*0\n\n    # update the weights\n    layer2_weights -= ETA * error_wrt_layer2_weights\n    layer1_weights -= ETA * error_wrt_layer1_weights\n    layer2_biases -= ETA * error_wrt_layer2_biases\n    layer1_biases -= ETA * error_wrt_layer1_biases\n\n    error_all.append(error)\n\n    if loop_iter % 10000 == 0:\n        print(error)\n\n\n\n# plt.plot(error_all)\n# plt.show()\n\nx_all = x_data\ny_all = [guess(x_i) for x_i in x_all]\n\nplt.plot(x_all,y_all, '.')\nplt.plot(x_data, y_data, '.')\nplt.show()\n"
                    ]
                ],
                "question_id:": "14978",
                "question_votes:": "2",
                "question_text:": "<p>I read a few tutorials on neural network backpropagation and decided to implement one from scratch. I tried to find this single error for the past few days I have in my code with no success.</p>\n\n<p>I followed <a href=\"https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\" rel=\"nofollow noreferrer\">this</a> tutorial  in hopes of being able to implement a sine function approximator. This is a simple network: 1 input neuron, 10 hidden neurons and 1 output neuron. The activation function is sigmoid in the second layer. The exact same model easily works in Tensorflow.</p>\n\n<pre><code>def sigmoid(x):\n    return 1 / (1 + np.math.e ** -x)\n\n\ndef sigmoid_deriv(x):\n    return sigmoid(x) * (1 - sigmoid(x))\n\n\nx_data = np.random.rand(500) * 15.0\ny_data = [sin(x) for x in x_data]\n\nETA = .01\n\nlayer1 = 0\nlayer1_weights = np.random.rand(10) * 2. - 1.\nlayer2 = np.zeros(10)\nlayer2_weights = np.random.rand(10) * 2. - 1.\nlayer3 = 0\n\nfor loop_iter in range(500000):\n    # data init\n    index = np.random.randint(0, 500)\n    x = x_data[index]\n    y = y_data[index]\n\n    # forward propagation\n    # layer 1\n    layer1 = x\n\n    # layer 2\n    layer2 = layer1_weights * layer1\n\n    # layer 3\n    layer3 = sum(sigmoid(layer2) * layer2_weights)\n\n    # error\n    error = .5 * (layer3 - y) ** 2  # L2 loss\n\n    # backpropagation\n    # error_wrt_layer3 * layer3_wrt_weights_layer2\n    error_wrt_layer2_weights = (y - layer3) * sigmoid(layer2)\n    # error_wrt_layer3 * layer3_wrt_out_layer2 * out_layer2_wrt_in_layer2 * in_layer2_wrt_weights_layer1\n    error_wrt_layer1_weights = (y - layer3) * layer2_weights * sigmoid_deriv(sigmoid(layer2)) * layer1\n\n    # update the weights\n    layer2_weights -= ETA * error_wrt_layer2_weights\n    layer1_weights -= ETA * error_wrt_layer1_weights\n\n    if loop_iter % 10000 == 0:\n        print(error)\n</code></pre>\n\n<p>The unexpected behavior is simply that the network doesn't converge. Please, review my error_wrt_... derivatives. The problem should be there.</p>\n\n<p>Here's the Tensorflow code it works flawlessly with:</p>\n\n<pre><code>x_data = np.array(np.random.rand(500)).reshape(500, 1)\ny_data = np.array([sin(x) for x in x_data]).reshape(500, 1)\n\nx = tf.placeholder(tf.float32, shape=[None, 1])\ny_true = tf.placeholder(tf.float32, shape=[None, 1])\nW = tf.Variable(tf.random_uniform([1, 10], -1.0, 1.0))\nhidden1 = tf.nn.sigmoid(tf.matmul(x, W))\nW_hidden = tf.Variable(tf.random_uniform([10, 1], -1.0, 1.0))\noutput = tf.matmul(hidden1, W_hidden)\n\nloss = tf.square(output - y_true) / 2.\noptimizer = tf.train.GradientDescentOptimizer(.01)\ntrain = optimizer.minimize(loss)\n\ninit = tf.initialize_all_variables()\nsess = tf.Session()\nsess.run(init)\n\nfor i in range(500000):\n    rand_index = np.random.randint(0, 500)\n    _, error = sess.run([train, loss], feed_dict={x: [x_data[rand_index]],\n                                              y_true: [y_data[rand_index]]})\n    if i % 10000 == 0:\n        print(error)\n\nsess.close()\n</code></pre>\n",
                "tags": "<deep-learning><backpropagation>",
                "answers": [
                    [
                        "14980",
                        "2",
                        "14978",
                        "",
                        "",
                        "<p>I think your biggest problem is the lack of biases. Between the input layer and the hidden layer, you should not only transform by the weights but should also add a bias. This bias will shift your sigmoid function to the left or right. Take a look at this code (I made some adaptations).</p>\n\n<p>What is important:</p>\n\n<ol>\n<li>Added biases.</li>\n<li>Altered your error_w such that they are correct.</li>\n<li>Made some good random starting points for biases (<code>np.random.rand(width) * 15. - 7.5</code>) such that all biases are random points on the desired x-scale.</li>\n<li>Made a plot that shows the initial guess and final.</li>\n</ol>\n\n<p>Let me know if some parts are not clear:</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\ndef sigmoid(x):\n    return 1 / (1 + np.math.e ** -x)\n\n\ndef sigmoid_deriv(x):\n    return sigmoid(x) * (1 - sigmoid(x))\n\ndef guess(x):\n    layer1 = x\n    z_2 = layer1_weights * layer1 + layer1_biases\n    a_2 =sigmoid(z_2)\n    z_3 = np.dot(a_2, layer2_weights) + layer2_biases\n    # a_3 = sigmoid(z_3)\n    a_3 = z_3\n    return a_3\n\n\nx_data = np.random.rand(500) * 15.0 - 7.5\ny_data = [np.sin(x) for x in x_data]\n\nETA = 0.05\nwidth = 10\n\nlayer1_weights = np.random.rand(width) * 2. - 1.\nlayer1_biases = np.random.rand(width) * 15. - 7.5\nlayer2_weights = np.random.rand(width) * 2. - 1.\nlayer2_biases = np.random.rand(1)* 2. - 1.\n\nerror_all = []\n\nx_all = x_data\ny_all = [guess(x_i) for x_i in x_all]\n\nplt.plot(x_all,y_all, '.')\nplt.plot(x_data, y_data, '.')\nplt.show()\n\nepochs = 500000\n\n\n\nfor loop_iter in range(epochs):\n    # data init\n    index = np.random.randint(0, 500)\n    x = x_data[index]\n    y = y_data[index]\n\n    # forward propagation\n    # layer 1\n    layer1 = x\n\n    # layer 2\n    #TODO add the sigmoid function here\n\n    z_2 = layer1_weights * layer1 + layer1_biases\n    a_2 =sigmoid(z_2)\n\n    # layer 3\n    #TODO remove simgmoid here (not that is really matters, but values at each layer are after sigmoid\n    z_3 = np.dot(a_2, layer2_weights) + layer2_biases\n    # a_3 = sigmoid(z_3)\n    a_3 = z_3\n\n\n    # error\n    error = .5 * (a_3 - y) ** 2  # L2 loss\n\n    # backpropagation\n    # error_wrt_layer3 * layer3_wrt_weights_layer2\n\n    # error_wrt_layer2_weights = (y - layer3) * sigmoid(layer2)\n\n    delta = (a_3 - y)\n\n    error_wrt_layer2_weights = delta * a_2\n    error_wrt_layer2_biases = delta\n\n    # error_wrt_layer3 * layer3_wrt_out_layer2 * out_layer2_wrt_in_layer2 * in_layer2_wrt_weights_layer1\n\n    # error_wrt_layer1_weights = (y - layer3) * layer2_weights * sigmoid_deriv(sigmoid(layer2)) * layer1\n    error_wrt_layer1_weights = delta * np.dot(sigmoid_deriv(z_2), layer2_weights) * layer1\n    # error_wrt_layer1_weights = 0\n\n    error_wrt_layer1_biases =  delta * np.dot(sigmoid_deriv(z_2), layer2_weights)\n\n\n    # a = 0\n    # while a ==0:\n    #   a*0\n\n    # update the weights\n    layer2_weights -= ETA * error_wrt_layer2_weights\n    layer1_weights -= ETA * error_wrt_layer1_weights\n    layer2_biases -= ETA * error_wrt_layer2_biases\n    layer1_biases -= ETA * error_wrt_layer1_biases\n\n    error_all.append(error)\n\n    if loop_iter % 10000 == 0:\n        print(error)\n\n\n\n# plt.plot(error_all)\n# plt.show()\n\nx_all = x_data\ny_all = [guess(x_i) for x_i in x_all]\n\nplt.plot(x_all,y_all, '.')\nplt.plot(x_data, y_data, '.')\nplt.show()\n</code></pre>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "9493",
            "_score": 5.073058,
            "_source": {
                "title": "Loss plateaus off in neural style transfer",
                "content": "Loss plateaus off in neural style transfer <p>I am writing an implementation of style transfer by loading a vgg model from keras and supplying it to a tensorflow model.</p>\n\n<p>I am using an adam optimizer. The loss function is reducing but it is very slow and plateaus off at about 10<sup>8</sup>. Additionally the generated image color seems to be changing correctly but it is still clearly noise. </p>\n\n<p>Also, the style loss is huge (order of 10<sup>8</sup>) whereas content loss is much smaller(order of 10<sup>5</sup>). This is weird as the paper for style transfer says to scale content loss down by a factor of 100 or 1000 when calculating total loss.</p>\n\n<p>I tried increasing the learning rate but that only makes the gradient overshoot.</p>\n\n<p>I suspect there must be a bug in my implementation but despite searching endlessly I have been unable to find what's wrong.</p>\n\n<p>Here's the code:</p>\n\n<pre><code># coding: utf-8\n# In[1]:\n\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# In[2]:\n\n\ncontent_image_path = './skyline.jpg'\nstyle_image_path = './starry_night.jpg'\noutput_image_path = './output.jpg'\n\n# In[4]:\n\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\n\n# In[5]:\n\ncontent_image = image.load_img(content_image_path, target_size=(224, 224))\n#plt.imshow(content_image)\ncontent_arr = image.img_to_array(content_image)\ncontent_arr = tf.convert_to_tensor(preprocess_input(np.expand_dims(content_arr, axis=0)), tf.float64)\nsess.run(tf.shape(content_arr))\n\n# In[6]:\n\nstyle_image = image.load_img(style_image_path, target_size=(224, 224))\n#plt.imshow(style_image)\nstyle_arr = image.img_to_array(style_image)\nstyle_arr = tf.convert_to_tensor(preprocess_input(np.expand_dims(style_arr, axis=0)), tf.float64)\nsess.run(tf.shape(style_arr))\n\n# In[7]:\n\n#generate random image with pixel values b/w 0 -&gt; 255\no_input = np.random.randint(low=0, high=256, size=(224, 224, 3)).astype('float64')\nplt.imshow(o_input)\no_input_old = np.copy(o_input)\no_input = preprocess_input(np.expand_dims(o_input, axis=0))\nprint(o_input_old)\n\no_input_var = tf.Variable(o_input, name=\"gen_img_vector\", trainable=True)\n\n# In[8]:\n\ncontent_model = VGG16(include_top=False, weights='imagenet', input_tensor=content_arr, input_shape=(224, 224, 3))\nstyle_model = VGG16(include_top=False, weights='imagenet', input_tensor=style_arr, input_shape=(224, 224, 3))\ntrain_model = VGG16(include_top=False, weights='imagenet', input_tensor=o_input_var, input_shape=(224, 224, 3))\n\n# In[10]:\n\ncontent_model.summary()\n\n# In[11]:\n\ndef get_feature_rep(layer_type, layer_names, model):\n\n    outputs = []\n    for name in layer_names:\n        out = model.get_layer(name=name).output\n\n        N = tf.shape(out)[3]#number of channels\n        M = tf.multiply(tf.shape(out)[1], tf.shape(out)[2])#product of dimensions\n\n        out = tf.transpose(tf.reshape(out, (M, N)))#Flattens each channel into 1-D tensor &amp; reshapes layer\n        if layer_type == 'style':\n            out = get_gram_matrix(out)\n        print(out)\n        outputs.append(out)\n    return outputs\n\n# In[12]:\n\ndef get_gram_matrix(F):\n    G = tf.matmul(F, tf.transpose(F))\n    return G\n\n\n# In[13]:\n\n\ndef style_loss(Gs, As):\n\n    total = tf.Variable(tf.constant(0.0, tf.float64), name=\"style_loss\", trainable=False)\n    style_reps = list(zip(Gs, As))\n\n    for layer in style_reps:\n        loss = tf.reduce_sum(tf.cast(tf.squared_difference(layer[0], layer[1]), tf.float64), [0, 1])\n        N_layer = tf.shape(layer[0])[0]\n        M_layer = tf.shape(layer[0])[1]\n        den = tf.square(tf.cast(tf.multiply(N_layer, M_layer), tf.float64))\n        loss = loss/den\n        loss = loss*0.2/4.0 #weighting loss\n        total = total + loss\n\n    return total\n\n\n# In[14]:\n\ndef content_loss(P, F):\n#     loss = tf.Variable(tf.constant(0.0, tf.float64), name=\"content_loss\", trainable=False)\n    loss = tf.reduce_sum(tf.cast(tf.squared_difference(P, F), tf.float64), [0, 1])\n    loss = loss/2.0\n    return loss\n\n# In[15]:\n\ncontent_layer_names = ['block4_conv2']\nstyle_layer_names = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1']\n\n# In[32]:\n\nP = tf.squeeze(get_feature_rep('content', content_layer_names, content_model))\n\n# In[34]:\n\nF = tf.squeeze(get_feature_rep('content', content_layer_names, train_model))\n\n# In[18]:\n\n#Each member of As consists of a feature map corresponding to a particular layer (dim. channels x pixels per channel)\nAs = get_feature_rep('style', style_layer_names, style_model)\n\n# In[19]:\n\nGs = get_feature_rep('style', style_layer_names, train_model)\n\n# In[20]:\n\nstyleloss = style_loss(Gs, As)\n\n# In[21]:\n\ncontentloss = content_loss(P, F)\n\n# In[22]:\n\ntotal_loss = tf.add(styleloss, tf.multiply(tf.constant(0.01, tf.float64), contentloss))\n\n\n# In[23]:\n\noptimizer = tf.train.AdamOptimizer(5).minimize(total_loss, var_list=[o_input_var])\n\n# In[26]:\n\ndef reprocess(x):\n    VGG_MEAN = [123.68, 116.78, 103.94]\n    means = tf.reshape(tf.constant(VGG_MEAN, tf.float64), [1, 1, 3])\n    #Undo mean imagenet scale preprocessing\n    x = tf.add(x, means)\n    tf.clip_by_value(x, 0, 255)\n    #bgr to rgb\n    x = x[..., ::-1]\n    return x\n\n# In[27]:\n\nsaver = tf.train.Saver(tf.global_variables())\n\n# In[28]:\n\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(init)\n\n#     saver.restore(sess, './model/nst_model.ckpt')\n\n    for epoch in range(100):\n        _, styleloss_curr, contentloss_curr, loss_curr, new_arr = sess.run([optimizer, styleloss, contentloss, total_loss, o_input_var])\n\n        print('Epoch: %i    Content Loss: %.2f    Style Loss: %.2f    Total Loss: %.2f' % (epoch, contentloss_curr, styleloss_curr, loss_curr))\n\n        if epoch % 15 == 0:\n            saver.save(sess, './model/nst_model.ckpt')\n\n# In[30]:\n\nwith tf.Session() as sess:\n    new_arr = reprocess(new_arr)\n    new_im = sess.run(tf.cast(tf.round(tf.squeeze(new_arr)), tf.uint8))\n#     new_im = new_im[...,::-1]\n#     print(sess.run(new_arr[0]/255))\n    print(sess.run(tf.shape(new_im)))\n    plt.imshow(new_im)\n</code></pre>\n\n<p>Here are plots of the style (blue) and content (red) losses after 150 iterations (6-7 minutes):\n<a href=\"https://i.stack.imgur.com/jEU5e.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/jEU5e.png\" alt=\"Style Transfer Losses\"></a></p>\n\n<p>Typical implementations are known to converge after 15-20 minutes with the loss dropping drastically initially. In this case the image generated is basically colored noise even after 500 iterations.</p>\n <python><deep-learning><keras><tensorflow><neural-style-transfer>",
                "codes": [],
                "question_id:": "33808",
                "question_votes:": "2",
                "question_text:": "<p>I am writing an implementation of style transfer by loading a vgg model from keras and supplying it to a tensorflow model.</p>\n\n<p>I am using an adam optimizer. The loss function is reducing but it is very slow and plateaus off at about 10<sup>8</sup>. Additionally the generated image color seems to be changing correctly but it is still clearly noise. </p>\n\n<p>Also, the style loss is huge (order of 10<sup>8</sup>) whereas content loss is much smaller(order of 10<sup>5</sup>). This is weird as the paper for style transfer says to scale content loss down by a factor of 100 or 1000 when calculating total loss.</p>\n\n<p>I tried increasing the learning rate but that only makes the gradient overshoot.</p>\n\n<p>I suspect there must be a bug in my implementation but despite searching endlessly I have been unable to find what's wrong.</p>\n\n<p>Here's the code:</p>\n\n<pre><code># coding: utf-8\n# In[1]:\n\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# In[2]:\n\n\ncontent_image_path = './skyline.jpg'\nstyle_image_path = './starry_night.jpg'\noutput_image_path = './output.jpg'\n\n# In[4]:\n\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\n\n# In[5]:\n\ncontent_image = image.load_img(content_image_path, target_size=(224, 224))\n#plt.imshow(content_image)\ncontent_arr = image.img_to_array(content_image)\ncontent_arr = tf.convert_to_tensor(preprocess_input(np.expand_dims(content_arr, axis=0)), tf.float64)\nsess.run(tf.shape(content_arr))\n\n# In[6]:\n\nstyle_image = image.load_img(style_image_path, target_size=(224, 224))\n#plt.imshow(style_image)\nstyle_arr = image.img_to_array(style_image)\nstyle_arr = tf.convert_to_tensor(preprocess_input(np.expand_dims(style_arr, axis=0)), tf.float64)\nsess.run(tf.shape(style_arr))\n\n# In[7]:\n\n#generate random image with pixel values b/w 0 -&gt; 255\no_input = np.random.randint(low=0, high=256, size=(224, 224, 3)).astype('float64')\nplt.imshow(o_input)\no_input_old = np.copy(o_input)\no_input = preprocess_input(np.expand_dims(o_input, axis=0))\nprint(o_input_old)\n\no_input_var = tf.Variable(o_input, name=\"gen_img_vector\", trainable=True)\n\n# In[8]:\n\ncontent_model = VGG16(include_top=False, weights='imagenet', input_tensor=content_arr, input_shape=(224, 224, 3))\nstyle_model = VGG16(include_top=False, weights='imagenet', input_tensor=style_arr, input_shape=(224, 224, 3))\ntrain_model = VGG16(include_top=False, weights='imagenet', input_tensor=o_input_var, input_shape=(224, 224, 3))\n\n# In[10]:\n\ncontent_model.summary()\n\n# In[11]:\n\ndef get_feature_rep(layer_type, layer_names, model):\n\n    outputs = []\n    for name in layer_names:\n        out = model.get_layer(name=name).output\n\n        N = tf.shape(out)[3]#number of channels\n        M = tf.multiply(tf.shape(out)[1], tf.shape(out)[2])#product of dimensions\n\n        out = tf.transpose(tf.reshape(out, (M, N)))#Flattens each channel into 1-D tensor &amp; reshapes layer\n        if layer_type == 'style':\n            out = get_gram_matrix(out)\n        print(out)\n        outputs.append(out)\n    return outputs\n\n# In[12]:\n\ndef get_gram_matrix(F):\n    G = tf.matmul(F, tf.transpose(F))\n    return G\n\n\n# In[13]:\n\n\ndef style_loss(Gs, As):\n\n    total = tf.Variable(tf.constant(0.0, tf.float64), name=\"style_loss\", trainable=False)\n    style_reps = list(zip(Gs, As))\n\n    for layer in style_reps:\n        loss = tf.reduce_sum(tf.cast(tf.squared_difference(layer[0], layer[1]), tf.float64), [0, 1])\n        N_layer = tf.shape(layer[0])[0]\n        M_layer = tf.shape(layer[0])[1]\n        den = tf.square(tf.cast(tf.multiply(N_layer, M_layer), tf.float64))\n        loss = loss/den\n        loss = loss*0.2/4.0 #weighting loss\n        total = total + loss\n\n    return total\n\n\n# In[14]:\n\ndef content_loss(P, F):\n#     loss = tf.Variable(tf.constant(0.0, tf.float64), name=\"content_loss\", trainable=False)\n    loss = tf.reduce_sum(tf.cast(tf.squared_difference(P, F), tf.float64), [0, 1])\n    loss = loss/2.0\n    return loss\n\n# In[15]:\n\ncontent_layer_names = ['block4_conv2']\nstyle_layer_names = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1']\n\n# In[32]:\n\nP = tf.squeeze(get_feature_rep('content', content_layer_names, content_model))\n\n# In[34]:\n\nF = tf.squeeze(get_feature_rep('content', content_layer_names, train_model))\n\n# In[18]:\n\n#Each member of As consists of a feature map corresponding to a particular layer (dim. channels x pixels per channel)\nAs = get_feature_rep('style', style_layer_names, style_model)\n\n# In[19]:\n\nGs = get_feature_rep('style', style_layer_names, train_model)\n\n# In[20]:\n\nstyleloss = style_loss(Gs, As)\n\n# In[21]:\n\ncontentloss = content_loss(P, F)\n\n# In[22]:\n\ntotal_loss = tf.add(styleloss, tf.multiply(tf.constant(0.01, tf.float64), contentloss))\n\n\n# In[23]:\n\noptimizer = tf.train.AdamOptimizer(5).minimize(total_loss, var_list=[o_input_var])\n\n# In[26]:\n\ndef reprocess(x):\n    VGG_MEAN = [123.68, 116.78, 103.94]\n    means = tf.reshape(tf.constant(VGG_MEAN, tf.float64), [1, 1, 3])\n    #Undo mean imagenet scale preprocessing\n    x = tf.add(x, means)\n    tf.clip_by_value(x, 0, 255)\n    #bgr to rgb\n    x = x[..., ::-1]\n    return x\n\n# In[27]:\n\nsaver = tf.train.Saver(tf.global_variables())\n\n# In[28]:\n\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(init)\n\n#     saver.restore(sess, './model/nst_model.ckpt')\n\n    for epoch in range(100):\n        _, styleloss_curr, contentloss_curr, loss_curr, new_arr = sess.run([optimizer, styleloss, contentloss, total_loss, o_input_var])\n\n        print('Epoch: %i    Content Loss: %.2f    Style Loss: %.2f    Total Loss: %.2f' % (epoch, contentloss_curr, styleloss_curr, loss_curr))\n\n        if epoch % 15 == 0:\n            saver.save(sess, './model/nst_model.ckpt')\n\n# In[30]:\n\nwith tf.Session() as sess:\n    new_arr = reprocess(new_arr)\n    new_im = sess.run(tf.cast(tf.round(tf.squeeze(new_arr)), tf.uint8))\n#     new_im = new_im[...,::-1]\n#     print(sess.run(new_arr[0]/255))\n    print(sess.run(tf.shape(new_im)))\n    plt.imshow(new_im)\n</code></pre>\n\n<p>Here are plots of the style (blue) and content (red) losses after 150 iterations (6-7 minutes):\n<a href=\"https://i.stack.imgur.com/jEU5e.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/jEU5e.png\" alt=\"Style Transfer Losses\"></a></p>\n\n<p>Typical implementations are known to converge after 15-20 minutes with the loss dropping drastically initially. In this case the image generated is basically colored noise even after 500 iterations.</p>\n",
                "tags": "<python><deep-learning><keras><tensorflow><neural-style-transfer>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11009",
            "_score": 5.073058,
            "_source": {
                "title": "Keras Conv1D for simple data target prediction",
                "content": "Keras Conv1D for simple data target prediction <p>I am trying to use conv1D layer from Keras for predicting Species in <a href=\"https://en.wikipedia.org/wiki/Iris_flower_data_set\" rel=\"nofollow noreferrer\">iris dataset</a> (which has 4 numeric features and one categorical target). Following is my code:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\n\nirisdf = pd.read_csv('iris.csv')\n\nXall = irisdf.drop('Species', axis=1)\nprint(Xall.shape)\nXall = np.expand_dims(Xall.values, axis=2) \nprint(Xall.shape)\n\nYall = irisdf['Species']\nnb_classes =  3\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, InputLayer, Dropout, Flatten, BatchNormalization, Conv1D\ninput_shape = (Xall.shape[1:],)\nprint(input_shape)\nmodel = Sequential([\n    InputLayer(input_shape=input_shape), \n    Conv1D(32, 2),\n    Dense(nb_classes, activation='softmax')\n])\nmodel.compile(loss=keras.losses.mean_squared_error,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\nmodel.summary()\nmodel.fit(Xall, Yall, epochs=25, verbose=True)\n</code></pre>\n\n<p>However, it is giving following error: </p>\n\n<pre><code>Traceback (most recent call last):\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/eager/execute.py\", line 141, in make_shape\n    shape = tensor_shape.as_shape(v)\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\", line 946, in as_shape\n    return TensorShape(shape)\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\", line 541, in __init__\n    self._dims = [as_dimension(d) for d in dims_iter]\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\", line 541, in &lt;listcomp&gt;\n    self._dims = [as_dimension(d) for d in dims_iter]\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\", line 482, in as_dimension\n    return Dimension(value)\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\", line 37, in __init__\n    self._value = int(value)\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'tuple'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"rnkeras_conv1d_iris.py\", line 40, in &lt;module&gt;\n    InputLayer(input_shape=input_shape), \n  File \"/home/abcde/.local/lib/python3.5/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/abcde/.local/lib/python3.5/site-packages/keras/engine/input_layer.py\", line 86, in __init__\n    name=self.name)\n  File \"/home/abcde/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 515, in placeholder\n    x = tf.placeholder(dtype, shape=shape, name=name)\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1735, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4923, in placeholder\n    shape = _execute.make_shape(shape, \"shape\")\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/eager/execute.py\", line 143, in make_shape\n    raise TypeError(\"Error converting %s to a TensorShape: %s.\" % (arg_name, e))\nTypeError: Error converting shape to a TensorShape: int() argument must be a string, a bytes-like object or a number, not 'tuple'.\n</code></pre>\n\n<p>Where is the problem and how can it be solved?</p>\n\n<p>(PS: If you find this question to be interesting/important, please upvote it;)</p>\n <neural-network><keras><predictive-modeling><convnet><convolution><p>Your error is coming from the Keras framework not working with strings as the output labels. You will want to transform these to 1-hot encoded vectors to train your model. Here is some code to do this. </p>\n\n<h1>Getting the data</h1>\n\n<pre><code>import pandas as pd\ndf = pd.read_csv('iris.csv', header=None, names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])\n</code></pre>\n\n<p>This will assign a class label, we will one-hot encode them later</p>\n\n<pre><code>df['labels'] =df['species'].astype('category').cat.codes\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/C3MUP.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/C3MUP.png\" alt=\"enter image description here\"></a></p>\n\n<h1>Splitting the data and reshaping the data</h1>\n\n<p>First we will split the data into a training and testing set. Then we will one-hot encode the labels. And finally we will structure the inputs to match what is expected from Keras. To use a 1D convolution we need to add a spatial dimension.</p>\n\n<pre><code>from sklearn.model_selection import train_test_split\nimport keras\n\nX = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\nY = df['labels']\nx_train, x_test, y_train, y_test = train_test_split(np.asarray(X), np.asarray(Y), test_size=0.33, shuffle= True)\n\n# The known number of output classes.\nnum_classes = 3\n\n# Input image dimensions\ninput_shape = (4,)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n\nx_train = x_train.reshape(100, 4,1)\nx_test = x_test.reshape(50, 4,1)\n</code></pre>\n\n<h1>The model</h1>\n\n<p>Your model was insufficient to get good results so I added an additional hidden layer into the mix to get acceptable results. </p>\n\n<pre><code>from keras.models import Sequential\nfrom __future__ import print_function\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv1D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n\nmodel = Sequential()\nmodel.add(Conv1D(32, (3), input_shape=(4,1), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='softmax'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nmodel.summary()\n</code></pre>\n\n<p>Now let's train the model</p>\n\n<pre><code>batch_size = 128\nepochs = 10\nmodel.fit(x_train, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test_binary))\n</code></pre>\n\n<blockquote>\n  <p>100/100 [==============================] - 0s 50us/step - loss: 1.0906 - acc: 0.6400 - val_loss: 1.0893 - val_acc: 0.7000</p>\n</blockquote>\n\n<p>We get 70% accuracy, that's not so bad. But it can be improved by changing the model to better suit the data source.</p>\n",
                "codes": [
                    [
                        "import pandas as pd\ndf = pd.read_csv('iris.csv', header=None, names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])\n",
                        "df['labels'] =df['species'].astype('category').cat.codes\n",
                        "from sklearn.model_selection import train_test_split\nimport keras\n\nX = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\nY = df['labels']\nx_train, x_test, y_train, y_test = train_test_split(np.asarray(X), np.asarray(Y), test_size=0.33, shuffle= True)\n\n# The known number of output classes.\nnum_classes = 3\n\n# Input image dimensions\ninput_shape = (4,)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n\nx_train = x_train.reshape(100, 4,1)\nx_test = x_test.reshape(50, 4,1)\n",
                        "from keras.models import Sequential\nfrom __future__ import print_function\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv1D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n\nmodel = Sequential()\nmodel.add(Conv1D(32, (3), input_shape=(4,1), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='softmax'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nmodel.summary()\n",
                        "batch_size = 128\nepochs = 10\nmodel.fit(x_train, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test_binary))\n"
                    ]
                ],
                "question_id:": "38957",
                "question_votes:": "4",
                "question_text:": "<p>I am trying to use conv1D layer from Keras for predicting Species in <a href=\"https://en.wikipedia.org/wiki/Iris_flower_data_set\" rel=\"nofollow noreferrer\">iris dataset</a> (which has 4 numeric features and one categorical target). Following is my code:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\n\nirisdf = pd.read_csv('iris.csv')\n\nXall = irisdf.drop('Species', axis=1)\nprint(Xall.shape)\nXall = np.expand_dims(Xall.values, axis=2) \nprint(Xall.shape)\n\nYall = irisdf['Species']\nnb_classes =  3\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, InputLayer, Dropout, Flatten, BatchNormalization, Conv1D\ninput_shape = (Xall.shape[1:],)\nprint(input_shape)\nmodel = Sequential([\n    InputLayer(input_shape=input_shape), \n    Conv1D(32, 2),\n    Dense(nb_classes, activation='softmax')\n])\nmodel.compile(loss=keras.losses.mean_squared_error,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\nmodel.summary()\nmodel.fit(Xall, Yall, epochs=25, verbose=True)\n</code></pre>\n\n<p>However, it is giving following error: </p>\n\n<pre><code>Traceback (most recent call last):\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/eager/execute.py\", line 141, in make_shape\n    shape = tensor_shape.as_shape(v)\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\", line 946, in as_shape\n    return TensorShape(shape)\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\", line 541, in __init__\n    self._dims = [as_dimension(d) for d in dims_iter]\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\", line 541, in &lt;listcomp&gt;\n    self._dims = [as_dimension(d) for d in dims_iter]\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\", line 482, in as_dimension\n    return Dimension(value)\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\", line 37, in __init__\n    self._value = int(value)\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'tuple'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"rnkeras_conv1d_iris.py\", line 40, in &lt;module&gt;\n    InputLayer(input_shape=input_shape), \n  File \"/home/abcde/.local/lib/python3.5/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/abcde/.local/lib/python3.5/site-packages/keras/engine/input_layer.py\", line 86, in __init__\n    name=self.name)\n  File \"/home/abcde/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 515, in placeholder\n    x = tf.placeholder(dtype, shape=shape, name=name)\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1735, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4923, in placeholder\n    shape = _execute.make_shape(shape, \"shape\")\n  File \"/home/abcde/.local/lib/python3.5/site-packages/tensorflow/python/eager/execute.py\", line 143, in make_shape\n    raise TypeError(\"Error converting %s to a TensorShape: %s.\" % (arg_name, e))\nTypeError: Error converting shape to a TensorShape: int() argument must be a string, a bytes-like object or a number, not 'tuple'.\n</code></pre>\n\n<p>Where is the problem and how can it be solved?</p>\n\n<p>(PS: If you find this question to be interesting/important, please upvote it;)</p>\n",
                "tags": "<neural-network><keras><predictive-modeling><convnet><convolution>",
                "answers": [
                    [
                        "38969",
                        "2",
                        "38957",
                        "",
                        "",
                        "<p>Your error is coming from the Keras framework not working with strings as the output labels. You will want to transform these to 1-hot encoded vectors to train your model. Here is some code to do this. </p>\n\n<h1>Getting the data</h1>\n\n<pre><code>import pandas as pd\ndf = pd.read_csv('iris.csv', header=None, names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])\n</code></pre>\n\n<p>This will assign a class label, we will one-hot encode them later</p>\n\n<pre><code>df['labels'] =df['species'].astype('category').cat.codes\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/C3MUP.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/C3MUP.png\" alt=\"enter image description here\"></a></p>\n\n<h1>Splitting the data and reshaping the data</h1>\n\n<p>First we will split the data into a training and testing set. Then we will one-hot encode the labels. And finally we will structure the inputs to match what is expected from Keras. To use a 1D convolution we need to add a spatial dimension.</p>\n\n<pre><code>from sklearn.model_selection import train_test_split\nimport keras\n\nX = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\nY = df['labels']\nx_train, x_test, y_train, y_test = train_test_split(np.asarray(X), np.asarray(Y), test_size=0.33, shuffle= True)\n\n# The known number of output classes.\nnum_classes = 3\n\n# Input image dimensions\ninput_shape = (4,)\n\n# Convert class vectors to binary class matrices. This uses 1 hot encoding.\ny_train_binary = keras.utils.to_categorical(y_train, num_classes)\ny_test_binary = keras.utils.to_categorical(y_test, num_classes)\n\nx_train = x_train.reshape(100, 4,1)\nx_test = x_test.reshape(50, 4,1)\n</code></pre>\n\n<h1>The model</h1>\n\n<p>Your model was insufficient to get good results so I added an additional hidden layer into the mix to get acceptable results. </p>\n\n<pre><code>from keras.models import Sequential\nfrom __future__ import print_function\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv1D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n\nmodel = Sequential()\nmodel.add(Conv1D(32, (3), input_shape=(4,1), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='softmax'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nmodel.summary()\n</code></pre>\n\n<p>Now let's train the model</p>\n\n<pre><code>batch_size = 128\nepochs = 10\nmodel.fit(x_train, y_train_binary,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test_binary))\n</code></pre>\n\n<blockquote>\n  <p>100/100 [==============================] - 0s 50us/step - loss: 1.0906 - acc: 0.6400 - val_loss: 1.0893 - val_acc: 0.7000</p>\n</blockquote>\n\n<p>We get 70% accuracy, that's not so bad. But it can be improved by changing the model to better suit the data source.</p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4509",
            "_score": 4.991581,
            "_source": {
                "title": "XGBoost for binary classification: choosing the right threshold",
                "content": "XGBoost for binary classification: choosing the right threshold <p>I am working on a highly-imbalanced binary-labeled dataset, where number of <em>true</em> labels is just 7% from the whole dataset. But some combination of features could yield higher than average number of ones in a subset.</p>\n\n<p>E.g. we have the following dataset with a single feature (color):</p>\n\n<blockquote>\n  <p>180 red samples \u2014  0</p>\n  \n  <p>20 red samples \u2014 1</p>\n  \n  <p>300 green samples \u2014 0</p>\n  \n  <p>100 green samples \u2014 1</p>\n</blockquote>\n\n<p>We can build a simple decision tree:</p>\n\n<pre><code>                      (color)\n\n                red /       \\ green\n\n P(1 | red) = 0.1              P(1 | green) = 0.25\n</code></pre>\n\n<blockquote>\n  <p>P(1) = 0.2 for the overall dataset</p>\n</blockquote>\n\n<p>If I run XGBoost on this dataset it can predict probabilities no larger that 0.25. Which means, that if I make a decision at 0.5 threshold:</p>\n\n<ul>\n<li>0 - P &lt; 0.5</li>\n<li>1 - P >= 0.5</li>\n</ul>\n\n<p>Then I will always get all samples labeled as <em>zeroes</em>. Hope that I clearly described the problem.</p>\n\n<p>Now, on the initial dataset I am getting the following plot (threshold at x-axis):</p>\n\n<p><a href=\"https://i.stack.imgur.com/XYiDR.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/XYiDR.png\" alt=\"enter image description here\"></a></p>\n\n<p>Having maximum of <em>f1_score</em> at threshold = 0.1. Now I have two questions:</p>\n\n<ul>\n<li>should I even use <em>f1_score</em> for a dataset of such a structure?</li>\n<li>is it always reasonable to use 0.5 threshold for mapping probabilities to labels when using XGBoost for binary classification?</li>\n</ul>\n\n<p><strong>Update.</strong> I see that topic draws some interest. Below is the Python code to reproduce red/green experiment using XGBoost. It actually outputs the expected probabilities:</p>\n\n<pre><code>from xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\nX0_0 = np.zeros(180) # red - 0\nY0_0 = np.zeros(180)\n\nX0_1 = np.zeros(20) # red - 1\nY0_1 = np.ones(20)\n\nX1_0 = np.ones(300) # green - 0\nY1_0 = np.zeros(300)\n\nX1_1 = np.ones(100) # green  - 1\nY1_1 = np.ones(100)\n\nX = np.concatenate((X0_0, X0_1, X1_0, Y1_1))\nY = np.concatenate((Y0_0, Y0_1, Y1_0, Y1_1))\n\n# reshaping into 2-dim array\nX = X.reshape(-1, 1)\n\nimport xgboost as xgb\n\nxgb_dmat = xgb.DMatrix(X_train, label=y_train)\n\nparam = {'max_depth': 1,\n         'eta': 0.01,\n         'objective': 'binary:logistic',\n         'eval_metric': 'error',\n         'nthread': 4}\n\nmodel = xgb.train(param, xg_mat, 400)\n\nX0_sample = np.array([[0]])\nX1_sample = np.array([[1]])\n\nprint('P(1 | red), predicted: ' + str(model.predict(xgb.DMatrix(X0_sample))))\nprint('P(1 | green), predicted: ' + str(model.predict(xgb.DMatrix(X1_sample))))\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>P(1 | red), predicted: [ 0.1073855]\nP(1 | green), predicted: [ 0.24398108]\n</code></pre>\n <decision-trees><xgboost><p>You have to decide what you want to maximize.</p>\n\n<p>Classifying by comparing the probability to 0.5 is appropriate if you want to maximize accuracy.  It's not appropriate if you want to maximize the f1 metric.</p>\n\n<p>If you want to maximize accuracy, always predicting zero <em>is</em> the optimal classifier.</p>\n\n<p>Alternatively, given a probability score $p$, another option is to randomly flip a biased coin; with probability $p$, output classification 1, otherwise output classification 0.  This doesn't always predict zero.  However it's probably not actually any better in any useful way.</p>\n\n<p>If you want to maximize f1 metric, one approach is to train your classifier to predict a probability, then choose a threshold that maximizes the f1 score.  The threshold probably won't be 0.5.</p>\n\n<p>Another option is to understand the cost of type I errors vs type II errors, and then assign class weights accordingly.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "17857",
                "question_votes:": "8",
                "question_text:": "<p>I am working on a highly-imbalanced binary-labeled dataset, where number of <em>true</em> labels is just 7% from the whole dataset. But some combination of features could yield higher than average number of ones in a subset.</p>\n\n<p>E.g. we have the following dataset with a single feature (color):</p>\n\n<blockquote>\n  <p>180 red samples \u2014  0</p>\n  \n  <p>20 red samples \u2014 1</p>\n  \n  <p>300 green samples \u2014 0</p>\n  \n  <p>100 green samples \u2014 1</p>\n</blockquote>\n\n<p>We can build a simple decision tree:</p>\n\n<pre><code>                      (color)\n\n                red /       \\ green\n\n P(1 | red) = 0.1              P(1 | green) = 0.25\n</code></pre>\n\n<blockquote>\n  <p>P(1) = 0.2 for the overall dataset</p>\n</blockquote>\n\n<p>If I run XGBoost on this dataset it can predict probabilities no larger that 0.25. Which means, that if I make a decision at 0.5 threshold:</p>\n\n<ul>\n<li>0 - P &lt; 0.5</li>\n<li>1 - P >= 0.5</li>\n</ul>\n\n<p>Then I will always get all samples labeled as <em>zeroes</em>. Hope that I clearly described the problem.</p>\n\n<p>Now, on the initial dataset I am getting the following plot (threshold at x-axis):</p>\n\n<p><a href=\"https://i.stack.imgur.com/XYiDR.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/XYiDR.png\" alt=\"enter image description here\"></a></p>\n\n<p>Having maximum of <em>f1_score</em> at threshold = 0.1. Now I have two questions:</p>\n\n<ul>\n<li>should I even use <em>f1_score</em> for a dataset of such a structure?</li>\n<li>is it always reasonable to use 0.5 threshold for mapping probabilities to labels when using XGBoost for binary classification?</li>\n</ul>\n\n<p><strong>Update.</strong> I see that topic draws some interest. Below is the Python code to reproduce red/green experiment using XGBoost. It actually outputs the expected probabilities:</p>\n\n<pre><code>from xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\nX0_0 = np.zeros(180) # red - 0\nY0_0 = np.zeros(180)\n\nX0_1 = np.zeros(20) # red - 1\nY0_1 = np.ones(20)\n\nX1_0 = np.ones(300) # green - 0\nY1_0 = np.zeros(300)\n\nX1_1 = np.ones(100) # green  - 1\nY1_1 = np.ones(100)\n\nX = np.concatenate((X0_0, X0_1, X1_0, Y1_1))\nY = np.concatenate((Y0_0, Y0_1, Y1_0, Y1_1))\n\n# reshaping into 2-dim array\nX = X.reshape(-1, 1)\n\nimport xgboost as xgb\n\nxgb_dmat = xgb.DMatrix(X_train, label=y_train)\n\nparam = {'max_depth': 1,\n         'eta': 0.01,\n         'objective': 'binary:logistic',\n         'eval_metric': 'error',\n         'nthread': 4}\n\nmodel = xgb.train(param, xg_mat, 400)\n\nX0_sample = np.array([[0]])\nX1_sample = np.array([[1]])\n\nprint('P(1 | red), predicted: ' + str(model.predict(xgb.DMatrix(X0_sample))))\nprint('P(1 | green), predicted: ' + str(model.predict(xgb.DMatrix(X1_sample))))\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>P(1 | red), predicted: [ 0.1073855]\nP(1 | green), predicted: [ 0.24398108]\n</code></pre>\n",
                "tags": "<decision-trees><xgboost>",
                "answers": [
                    [
                        "17890",
                        "2",
                        "17857",
                        "",
                        "",
                        "<p>You have to decide what you want to maximize.</p>\n\n<p>Classifying by comparing the probability to 0.5 is appropriate if you want to maximize accuracy.  It's not appropriate if you want to maximize the f1 metric.</p>\n\n<p>If you want to maximize accuracy, always predicting zero <em>is</em> the optimal classifier.</p>\n\n<p>Alternatively, given a probability score $p$, another option is to randomly flip a biased coin; with probability $p$, output classification 1, otherwise output classification 0.  This doesn't always predict zero.  However it's probably not actually any better in any useful way.</p>\n\n<p>If you want to maximize f1 metric, one approach is to train your classifier to predict a probability, then choose a threshold that maximizes the f1 score.  The threshold probably won't be 0.5.</p>\n\n<p>Another option is to understand the cost of type I errors vs type II errors, and then assign class weights accordingly.</p>\n",
                        "",
                        "5"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7831",
            "_score": 4.991581,
            "_source": {
                "title": "How to use cluster analysis with grouped data so one cluster may only have not more than one item from each group?",
                "content": "How to use cluster analysis with grouped data so one cluster may only have not more than one item from each group? <p>I need to group items by their approximity to each other in multi (&lt;5) dimensional space. The items also have a categorical feature. I need to form groups (clusters) such that none of the records from the same category would appear in thr same cluster.  Is there a class of clustering algorithms that can do that? </p>\n\n<p>My way of thinking is to use custom distances that would measure two records in the same category further then ones in different categories. That works to some extent, but it does not guarantee satisfaction of the given requirement.</p>\n\n<p>A simple one dimension (x) + category (c) example:</p>\n\n<pre>\n    x       c\n0   0.80    0\n1   0.90    1\n2   0.10    0\n3   0.30    1\n4   0.20    0\n</pre>\n\n<p>The goal is to group records into two clusters [0, 1];and  [2 or 4, 3]; then record 4 or 2 respectively should remain outside of the second cluster because a record with c=0 is already present in the cluster.</p>\n\n<p>Any suggestions?</p>\n <clustering><p>You can write your own algorithm.  I drafted something up quickly. It can be significantly optimized. </p>\n\n<p>Let's make some random data</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nn = 9\nx = np.random.rand(n,2)\ny = np.zeros((n,))\ny[n//3:2*n//3] = 1\ny[2*n//3::] = 2\n\nplt.scatter(x[:,0], x[:,1], c=y)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/r4e1T.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/r4e1T.png\" alt=\"enter image description here\"></a></p>\n\n<p>Now let's get the interdistance of each of these points.</p>\n\n<pre><code>dists = np.asarray([np.linalg.norm(i-j) for i in x for j in x]).reshape(n,n)\n\nplt.imshow(dists)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/MrjFt.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/MrjFt.png\" alt=\"enter image description here\"></a></p>\n\n<p>We will make a list which will hold the radius of each circle for each point. For each point we will iterate over the other points by their relative nearness. If an associated label is not yet seen, add it to the temporary list. Otherwise, we end the function and take the average of the last distance and the current illegal point.</p>\n\n<pre><code>radii = []\n\nfor row in dists:\n    labels = []\n    dis = []\n    for i in np.argsort(row):\n        if y[i] not in labels:\n            labels.append(y[i])\n            dis = row[i]\n        else:\n            dis = (dis + row[i])/2\n            break\n    radii.append(dis)\n</code></pre>\n\n<p>Now we can plot these circles by </p>\n\n<pre><code>fig, ax = plt.subplots(figsize=(10,10))\n\nfor ix, i in enumerate(radii):\n    circle = plt.Circle((x[ix, 0], x[ix, 1]), i, color='b', fill=False, alpha = 0.5)\n    ax.add_artist(circle)\n\nplt.scatter(x[:,0], x[:,1], c=y)\nplt.xlim([-0.2,1.4])\nplt.ylim([-0.2,1.4])\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/RfqkO.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/RfqkO.png\" alt=\"enter image description here\"></a></p>\n\n<hr>\n\n<p>If we increase the number of datapoints $n$ we get</p>\n\n<p><a href=\"https://i.stack.imgur.com/qG3Tp.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/qG3Tp.png\" alt=\"enter image description here\"></a></p>\n<p>Use a constraint optimizer instead.</p>\n\n<p>Define your objective - what is a good result.</p>\n\n<p>Then define your constraints (all points in exactly one group, no duplicate labels in any group) and run it.</p>\n",
                "codes": [
                    [
                        "import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nn = 9\nx = np.random.rand(n,2)\ny = np.zeros((n,))\ny[n//3:2*n//3] = 1\ny[2*n//3::] = 2\n\nplt.scatter(x[:,0], x[:,1], c=y)\nplt.show()\n",
                        "dists = np.asarray([np.linalg.norm(i-j) for i in x for j in x]).reshape(n,n)\n\nplt.imshow(dists)\nplt.show()\n",
                        "radii = []\n\nfor row in dists:\n    labels = []\n    dis = []\n    for i in np.argsort(row):\n        if y[i] not in labels:\n            labels.append(y[i])\n            dis = row[i]\n        else:\n            dis = (dis + row[i])/2\n            break\n    radii.append(dis)\n",
                        "fig, ax = plt.subplots(figsize=(10,10))\n\nfor ix, i in enumerate(radii):\n    circle = plt.Circle((x[ix, 0], x[ix, 1]), i, color='b', fill=False, alpha = 0.5)\n    ax.add_artist(circle)\n\nplt.scatter(x[:,0], x[:,1], c=y)\nplt.xlim([-0.2,1.4])\nplt.ylim([-0.2,1.4])\nplt.show()\n"
                    ],
                    []
                ],
                "question_id:": "29052",
                "question_votes:": "3",
                "question_text:": "<p>I need to group items by their approximity to each other in multi (&lt;5) dimensional space. The items also have a categorical feature. I need to form groups (clusters) such that none of the records from the same category would appear in thr same cluster.  Is there a class of clustering algorithms that can do that? </p>\n\n<p>My way of thinking is to use custom distances that would measure two records in the same category further then ones in different categories. That works to some extent, but it does not guarantee satisfaction of the given requirement.</p>\n\n<p>A simple one dimension (x) + category (c) example:</p>\n\n<pre>\n    x       c\n0   0.80    0\n1   0.90    1\n2   0.10    0\n3   0.30    1\n4   0.20    0\n</pre>\n\n<p>The goal is to group records into two clusters [0, 1];and  [2 or 4, 3]; then record 4 or 2 respectively should remain outside of the second cluster because a record with c=0 is already present in the cluster.</p>\n\n<p>Any suggestions?</p>\n",
                "tags": "<clustering>",
                "answers": [
                    [
                        "29154",
                        "2",
                        "29052",
                        "",
                        "",
                        "<p>You can write your own algorithm.  I drafted something up quickly. It can be significantly optimized. </p>\n\n<p>Let's make some random data</p>\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nn = 9\nx = np.random.rand(n,2)\ny = np.zeros((n,))\ny[n//3:2*n//3] = 1\ny[2*n//3::] = 2\n\nplt.scatter(x[:,0], x[:,1], c=y)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/r4e1T.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/r4e1T.png\" alt=\"enter image description here\"></a></p>\n\n<p>Now let's get the interdistance of each of these points.</p>\n\n<pre><code>dists = np.asarray([np.linalg.norm(i-j) for i in x for j in x]).reshape(n,n)\n\nplt.imshow(dists)\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/MrjFt.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/MrjFt.png\" alt=\"enter image description here\"></a></p>\n\n<p>We will make a list which will hold the radius of each circle for each point. For each point we will iterate over the other points by their relative nearness. If an associated label is not yet seen, add it to the temporary list. Otherwise, we end the function and take the average of the last distance and the current illegal point.</p>\n\n<pre><code>radii = []\n\nfor row in dists:\n    labels = []\n    dis = []\n    for i in np.argsort(row):\n        if y[i] not in labels:\n            labels.append(y[i])\n            dis = row[i]\n        else:\n            dis = (dis + row[i])/2\n            break\n    radii.append(dis)\n</code></pre>\n\n<p>Now we can plot these circles by </p>\n\n<pre><code>fig, ax = plt.subplots(figsize=(10,10))\n\nfor ix, i in enumerate(radii):\n    circle = plt.Circle((x[ix, 0], x[ix, 1]), i, color='b', fill=False, alpha = 0.5)\n    ax.add_artist(circle)\n\nplt.scatter(x[:,0], x[:,1], c=y)\nplt.xlim([-0.2,1.4])\nplt.ylim([-0.2,1.4])\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/RfqkO.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/RfqkO.png\" alt=\"enter image description here\"></a></p>\n\n<hr>\n\n<p>If we increase the number of datapoints $n$ we get</p>\n\n<p><a href=\"https://i.stack.imgur.com/qG3Tp.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/qG3Tp.png\" alt=\"enter image description here\"></a></p>\n",
                        "",
                        "1"
                    ],
                    [
                        "29145",
                        "2",
                        "29052",
                        "",
                        "",
                        "<p>Use a constraint optimizer instead.</p>\n\n<p>Define your objective - what is a good result.</p>\n\n<p>Then define your constraints (all points in exactly one group, no duplicate labels in any group) and run it.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14756",
            "_score": 4.991581,
            "_source": {
                "title": "Computation of kernel matrix using radial basis kernel in svm",
                "content": "Computation of kernel matrix using radial basis kernel in svm <p>I want to compute a kernel matrix using RBF on my own. The training data is multidimensional. My query is whether we will apply\n<span class=\"math-container\">$$e^{-\\gamma(x-y)^2}$$</span>\nfor each dimension and then sum the values across all dimension?</p>\n <kernel><matrix><rbf><p>The kernel matrix <span class=\"math-container\">$K$</span> or <strong>Gram Matrix</strong> is a positive-semidefinite symmetric matrix that has the form:\n<span class=\"math-container\">$$ K(x_1,x_2,\\dots,x_n) = \n\\begin{vmatrix}\n\\langle x_1,x_1 \\rangle &amp; \\langle x_1,x_2 \\rangle &amp; \\dots &amp; \\langle x_1,x_n \\rangle \\\\\n\\langle x_2,x_1 \\rangle &amp; \\langle x_2,x_2 \\rangle &amp; \\dots &amp; \\langle x_2,x_n \\rangle \\\\\n\\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots \\\\\n\\langle x_n,x_1 \\rangle &amp; \\langle x_n,x_2 \\rangle &amp; \\dots &amp; \\langle x_n,x_n \\rangle \n\\end{vmatrix}\n$$</span></p>\n\n<p>Where <span class=\"math-container\">$\\langle a,b \\rangle$</span> detones the inner product/dot product of vectors <span class=\"math-container\">$a$</span> and <span class=\"math-container\">$b$</span> and <span class=\"math-container\">$\\{x_1,x_2,\\dots,x_n\\}$</span> is a set of vectors (in this case, training samples).</p>\n\n<p>In order to calculate the Gramian Matrix you will have to calculate the Inner Product using the Kernel Function. For a RBF kernel function <span class=\"math-container\">$\\kappa_{RBF}$</span> this can be done by</p>\n\n<p><span class=\"math-container\">$$K_{ij} = \\kappa_{RBF}(x_i,x_j) = e^{\\gamma D_{ist}(x_i,x_j)^2} $$</span></p>\n\n<p>where <span class=\"math-container\">$\\gamma$</span> is a function hyperparameter, <span class=\"math-container\">$K_{ij}$</span> is the element in row <span class=\"math-container\">$i$</span> and column <span class=\"math-container\">$j$</span> of the matrix <span class=\"math-container\">$K$</span> and <span class=\"math-container\">$ D_{ist}(x_i,x_j)$</span> is some distance between two vector measured in some vector space.</p>\n\n<p>Usually, the distance measure used is the <span class=\"math-container\">$L_2$</span> norm or <em>euclidean distance</em>. Remember that when computing the Kernel function you will use the square <span class=\"math-container\">$L_2$</span> norm, so there is no need to take the square root.</p>\n\n<p>There is a open library named <strong><a href=\"https://github.com/gmum/pykernels\" rel=\"nofollow noreferrer\">pykernels</a></strong> that has implementations to dozens of kernel functions. This here is the implementation for the RBF (or Gaussian) Kernel:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>class RBF(Kernel):\n    \"\"\"\n    Radial Basis Function kernel, defined as unnormalized Gaussian PDF\n        K(x, y) = e^(-g||x - y||^2)\n    where:\n        g = gamma\n    \"\"\"\n\n    def __init__(self, gamma=None):\n        self._gamma = gamma\n\n    def _compute(self, data_1, data_2):\n        if self._gamma is None:\n            # libSVM heuristics\n            self._gamma = 1./data_1.shape[1]\n\n        dists_sq = euclidean_dist_matrix(data_1, data_2)\n        return np.exp(-self._gamma * dists_sq)\n\n    def dim(self):\n        return np.inf\n</code></pre>\n\n<p>it uses the square distance define as:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def euclidean_dist_matrix(data_1, data_2):\n    \"\"\"\n    Returns matrix of pairwise, squared Euclidean distances\n    \"\"\"\n    norms_1 = (data_1 ** 2).sum(axis=1)\n    norms_2 = (data_2 ** 2).sum(axis=1)\n    return np.abs(norms_1.reshape(-1, 1) + norms_2 - 2 * np.dot(data_1, data_2.T))\n</code></pre>\n\n<p>The class is defined as a subclass of the Kernel class and has some methods to deal with kernel combinations.</p>\n\n<p><strong>Note</strong> that this is not the fastest way to implement euclidean distance, you <a href=\"https://stackoverflow.com/questions/4370975/python-numpy-euclidean-distance-calculation-between-matrices-of-row-vectors\">can do better</a> but this is a simple form to do it. also that \"np.abs\" should not be needed</p>\n\n<p><strong>Note 2</strong> that this <a href=\"https://stackoverflow.com/questions/47271662/what-is-the-fastest-way-to-compute-an-rbf-kernel-in-python\">SO Question has a lot of optimized version of RBF Kernel</a></p>\n",
                "codes": [
                    [
                        "class RBF(Kernel):\n    \"\"\"\n    Radial Basis Function kernel, defined as unnormalized Gaussian PDF\n        K(x, y) = e^(-g||x - y||^2)\n    where:\n        g = gamma\n    \"\"\"\n\n    def __init__(self, gamma=None):\n        self._gamma = gamma\n\n    def _compute(self, data_1, data_2):\n        if self._gamma is None:\n            # libSVM heuristics\n            self._gamma = 1./data_1.shape[1]\n\n        dists_sq = euclidean_dist_matrix(data_1, data_2)\n        return np.exp(-self._gamma * dists_sq)\n\n    def dim(self):\n        return np.inf\n",
                        "def euclidean_dist_matrix(data_1, data_2):\n    \"\"\"\n    Returns matrix of pairwise, squared Euclidean distances\n    \"\"\"\n    norms_1 = (data_1 ** 2).sum(axis=1)\n    norms_2 = (data_2 ** 2).sum(axis=1)\n    return np.abs(norms_1.reshape(-1, 1) + norms_2 - 2 * np.dot(data_1, data_2.T))\n"
                    ]
                ],
                "question_id:": "49420",
                "question_votes:": "1",
                "question_text:": "<p>I want to compute a kernel matrix using RBF on my own. The training data is multidimensional. My query is whether we will apply\n<span class=\"math-container\">$$e^{-\\gamma(x-y)^2}$$</span>\nfor each dimension and then sum the values across all dimension?</p>\n",
                "tags": "<kernel><matrix><rbf>",
                "answers": [
                    [
                        "49422",
                        "2",
                        "49420",
                        "",
                        "",
                        "<p>The kernel matrix <span class=\"math-container\">$K$</span> or <strong>Gram Matrix</strong> is a positive-semidefinite symmetric matrix that has the form:\n<span class=\"math-container\">$$ K(x_1,x_2,\\dots,x_n) = \n\\begin{vmatrix}\n\\langle x_1,x_1 \\rangle &amp; \\langle x_1,x_2 \\rangle &amp; \\dots &amp; \\langle x_1,x_n \\rangle \\\\\n\\langle x_2,x_1 \\rangle &amp; \\langle x_2,x_2 \\rangle &amp; \\dots &amp; \\langle x_2,x_n \\rangle \\\\\n\\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots \\\\\n\\langle x_n,x_1 \\rangle &amp; \\langle x_n,x_2 \\rangle &amp; \\dots &amp; \\langle x_n,x_n \\rangle \n\\end{vmatrix}\n$$</span></p>\n\n<p>Where <span class=\"math-container\">$\\langle a,b \\rangle$</span> detones the inner product/dot product of vectors <span class=\"math-container\">$a$</span> and <span class=\"math-container\">$b$</span> and <span class=\"math-container\">$\\{x_1,x_2,\\dots,x_n\\}$</span> is a set of vectors (in this case, training samples).</p>\n\n<p>In order to calculate the Gramian Matrix you will have to calculate the Inner Product using the Kernel Function. For a RBF kernel function <span class=\"math-container\">$\\kappa_{RBF}$</span> this can be done by</p>\n\n<p><span class=\"math-container\">$$K_{ij} = \\kappa_{RBF}(x_i,x_j) = e^{\\gamma D_{ist}(x_i,x_j)^2} $$</span></p>\n\n<p>where <span class=\"math-container\">$\\gamma$</span> is a function hyperparameter, <span class=\"math-container\">$K_{ij}$</span> is the element in row <span class=\"math-container\">$i$</span> and column <span class=\"math-container\">$j$</span> of the matrix <span class=\"math-container\">$K$</span> and <span class=\"math-container\">$ D_{ist}(x_i,x_j)$</span> is some distance between two vector measured in some vector space.</p>\n\n<p>Usually, the distance measure used is the <span class=\"math-container\">$L_2$</span> norm or <em>euclidean distance</em>. Remember that when computing the Kernel function you will use the square <span class=\"math-container\">$L_2$</span> norm, so there is no need to take the square root.</p>\n\n<p>There is a open library named <strong><a href=\"https://github.com/gmum/pykernels\" rel=\"nofollow noreferrer\">pykernels</a></strong> that has implementations to dozens of kernel functions. This here is the implementation for the RBF (or Gaussian) Kernel:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>class RBF(Kernel):\n    \"\"\"\n    Radial Basis Function kernel, defined as unnormalized Gaussian PDF\n        K(x, y) = e^(-g||x - y||^2)\n    where:\n        g = gamma\n    \"\"\"\n\n    def __init__(self, gamma=None):\n        self._gamma = gamma\n\n    def _compute(self, data_1, data_2):\n        if self._gamma is None:\n            # libSVM heuristics\n            self._gamma = 1./data_1.shape[1]\n\n        dists_sq = euclidean_dist_matrix(data_1, data_2)\n        return np.exp(-self._gamma * dists_sq)\n\n    def dim(self):\n        return np.inf\n</code></pre>\n\n<p>it uses the square distance define as:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def euclidean_dist_matrix(data_1, data_2):\n    \"\"\"\n    Returns matrix of pairwise, squared Euclidean distances\n    \"\"\"\n    norms_1 = (data_1 ** 2).sum(axis=1)\n    norms_2 = (data_2 ** 2).sum(axis=1)\n    return np.abs(norms_1.reshape(-1, 1) + norms_2 - 2 * np.dot(data_1, data_2.T))\n</code></pre>\n\n<p>The class is defined as a subclass of the Kernel class and has some methods to deal with kernel combinations.</p>\n\n<p><strong>Note</strong> that this is not the fastest way to implement euclidean distance, you <a href=\"https://stackoverflow.com/questions/4370975/python-numpy-euclidean-distance-calculation-between-matrices-of-row-vectors\">can do better</a> but this is a simple form to do it. also that \"np.abs\" should not be needed</p>\n\n<p><strong>Note 2</strong> that this <a href=\"https://stackoverflow.com/questions/47271662/what-is-the-fastest-way-to-compute-an-rbf-kernel-in-python\">SO Question has a lot of optimized version of RBF Kernel</a></p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15519",
            "_score": 4.78195,
            "_source": {
                "title": "Improving the results of CNN",
                "content": "Improving the results of CNN <p><strong>Edit 2</strong> I solved my problem. The issue was caused by the validation_generator. I used the method flow_from_directory with shuffle = true. By changing the value to false and calling the method validation_generator.reset() before model.predict_generator() for computing the confusion matrix solved my problem. The reset()-method seems to be very important.</p>\n\n<p><strong>Edit:</strong> I was able to isolate the problem a little. I noticed that evaluate_generator method returns the correct values from the training, e.g. [0.068286080902908, 0.9853515625]. However, the predict_generator() method behaves strangely. The results look like this:  </p>\n\n<p>[[8.8930092e-06 5.8127771e-04 3.8436747e-06 7.7528159e-07 9.9940526e-01]\n [1.4138629e-03 9.9854565e-01 5.4473304e-07 3.9719587e-05 1.8904993e-07]\n [9.0803866e-07 2.7020766e-05 7.9189061e-07 4.9350000e-09 9.9997127e-01]\n ...\n [5.0964586e-06 4.5610027e-04 2.6184430e-06 1.6962146e-07 9.9953604e-01]\n [2.9692460e-08 3.1284328e-10 4.7919415e-09 1.0000000e+00 1.4161311e-12]\n [2.1354626e-06 9.6519925e-06 1.9460406e-07 4.6475903e-09 9.9998796e-01]]</p>\n\n<p><strong>####</strong></p>\n\n<p>I did some image classification with a CNN. The Accuracy of the training and validation set are high and the losses for both of them are low. However, my confusion matrix does not have the typical diagonal from the upper left to lower right. If I understand the confusion matrix correctly, I have a lot of misclassifications. So, how can I improve my model to get better results?</p>\n\n<p>The distribution of samples each class is:</p>\n\n<p>early: 800\nhealthy: 749\nlate: 764\nleaf mold: 761\nyellow: 708 </p>\n\n<p>The Structure of the model: </p>\n\n<pre><code>model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(150, 150, \n3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Dropout(0.15))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization())\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.6))\nmodel.add(layers.Dense(150, activation='relu', \nkernel_regularizer=regularizers.l2(0.002)))\nmodel.add(layers.Dense(5, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\noptimizer=optimizers.Adam(lr=1e-3),\nmetrics=['acc'])\n</code></pre>\n\n<p>These are the accuracy and losses of the training:</p>\n\n<pre><code>Epoch 00067: val_loss did not improve from 0.08283\nEpoch 68/200\n230/230 [==============================] - 56s 243ms/step - loss: 0.0893 - \nacc: 0.9793 - val_loss: 0.0876 - val_acc: 0.9784\n\nEpoch 00068: val_loss did not improve from 0.08283\nEpoch 69/200\n230/230 [==============================] - 58s 250ms/step - loss: 0.0874 - \nacc: 0.9774 - val_loss: 0.1209 - val_acc: 0.9684\n\nEpoch 00069: val_loss did not improve from 0.08283\nEpoch 70/200\n230/230 [==============================] - 57s 246ms/step - loss: 0.0879 - \nacc: 0.9803 - val_loss: 0.1384 - val_acc: 0.9706\n\nEpoch 00070: val_loss did not improve from 0.08283\nEpoch 71/200\n230/230 [==============================] - 59s 257ms/step - loss: 0.0903 - \nacc: 0.9783 - val_loss: 0.1352 - val_acc: 0.9728\n\nEpoch 00071: val_loss did not improve from 0.08283\nEpoch 72/200\n230/230 [==============================] - 58s 250ms/step - loss: 0.0852 - \nacc: 0.9798 - val_loss: 0.1324 - val_acc: 0.9621\n\nEpoch 00072: val_loss did not improve from 0.08283\nEpoch 73/200\n230/230 [==============================] - 58s 250ms/step - loss: 0.0831 - \nacc: 0.9815 - val_loss: 0.1634 - val_acc: 0.9574\n\nEpoch 00073: val_loss did not improve from 0.08283\nEpoch 74/200\n230/230 [==============================] - 57s 246ms/step - loss: 0.0824 - \nacc: 0.9816 - val_loss: 0.1280 - val_acc: 0.9640\n\nEpoch 00074: val_loss did not improve from 0.08283\nEpoch 75/200\n230/230 [==============================] - 57s 247ms/step - loss: 0.0869 - \nacc: 0.9774 - val_loss: 0.0777 - val_acc: 0.9882\n\nEpoch 00075: val_loss improved from 0.08283 to 0.07765, saving model to \nC:/Users/xxx/Desktop/best_model_7.h5\nEpoch 76/200\n230/230 [==============================] - 56s 243ms/step - loss: 0.0739 - \nacc: 0.9851 - val_loss: 0.0683 - val_acc: 0.9851\n\nEpoch 00076: val_loss improved from 0.07765 to 0.06826, saving model to \nC:/Users/xxx/Desktop/best_model_7.h5\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/SQrDS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/SQrDS.png\" alt=\"Accuracy and losses\"></a>\n<a href=\"https://i.stack.imgur.com/7oEDq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/7oEDq.png\" alt=\"confusion matrix\"></a></p>\n <keras><cnn><image-classification><confusion-matrix><p>This is a bit strange... one problem may be that you do not have too many training samples. Do you use a pretrained model? If not, using a pretrained model can potentially improve classification accuracy (especially with limited training samples). \n<a href=\"https://keras.io/applications/\" rel=\"nofollow noreferrer\">https://keras.io/applications/</a></p>\n\n<p><strong>-Edit-</strong> This is a good sample code: <a href=\"https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.3-using-a-pretrained-convnet.ipynb\" rel=\"nofollow noreferrer\">https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.3-using-a-pretrained-convnet.ipynb</a></p>\n\n<p>Adjusted for multilass:</p>\n\n<pre><code>import keras\n\nfrom keras.applications import VGG16\n\nconv_base = VGG16(weights='imagenet',\n                  include_top=False,\n                  input_shape=(150, 150, 3))\n\nimport os\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\n\nbase_dir = 'C:/kerasimages'\n\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'val')\ntest_dir = os.path.join(base_dir, 'test')\n\ndatagen = ImageDataGenerator(rescale=1./255)\nbatch_size = 20\n\ndef extract_features(directory, sample_count):\n    features = np.zeros(shape=(sample_count, 4, 4, 512))\n    labels = np.zeros(shape=(sample_count))\n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='binary')\n    i = 0\n    for inputs_batch, labels_batch in generator:\n        features_batch = conv_base.predict(inputs_batch)\n        features[i * batch_size : (i + 1) * batch_size] = features_batch\n        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n        i += 1\n        if i * batch_size &gt;= sample_count:\n            # Note that since generators yield data indefinitely in a loop,\n            # we must `break` after every image has been seen once.\n            break\n    return features, labels\n\ntrain_features, train_labels = extract_features(train_dir, 2000)\nvalidation_features, validation_labels = extract_features(validation_dir, 1000)\ntest_features, test_labels = extract_features(test_dir, 1000)\n\nfrom keras.utils import to_categorical\nprint(train_labels)\nprint(train_labels.shape)\ntrain_labels = to_categorical(train_labels)\nprint(train_labels)\nprint(train_labels.shape)\nvalidation_labels = to_categorical(validation_labels)\ntest_labels = to_categorical(test_labels)\n\ntrain_features = np.reshape(train_features, (2000, 4 * 4 * 512))\nvalidation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\ntest_features = np.reshape(test_features, (1000, 4 * 4 * 512))\n\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\n\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\n# NUMBER OF CLASSES\nmodel.add(layers.Dense(3, activation='softmax'))\n\nmodel.summary()\n\nconv_base.trainable = False\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\n# Note that the validation data should not be augmented!\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        # This is the target directory\n        train_dir,\n        # All images will be resized to 150x150\n        target_size=(150, 150),\n        batch_size=20,\n        # Since we use categorical_crossentropy loss, we need binary labels\n        class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(150, 150),\n        batch_size=20,\n        class_mode='categorical')\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=2e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=30,\n      validation_data=validation_generator,\n      validation_steps=50,\n      verbose=2)\n\n\n#######################################\n# Fine tuning\n\n#conv_base.summary()\nconv_base.trainable = True\n\nset_trainable = False\nfor layer in conv_base.layers:\n    if layer.name == 'block5_conv1':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=100,\n      validation_data=validation_generator,\n      validation_steps=50)\n\nmodel.save('my_model_multiclass.hdf5')\n</code></pre>\n",
                "codes": [
                    [
                        "import keras\n\nfrom keras.applications import VGG16\n\nconv_base = VGG16(weights='imagenet',\n                  include_top=False,\n                  input_shape=(150, 150, 3))\n\nimport os\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\n\nbase_dir = 'C:/kerasimages'\n\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'val')\ntest_dir = os.path.join(base_dir, 'test')\n\ndatagen = ImageDataGenerator(rescale=1./255)\nbatch_size = 20\n\ndef extract_features(directory, sample_count):\n    features = np.zeros(shape=(sample_count, 4, 4, 512))\n    labels = np.zeros(shape=(sample_count))\n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='binary')\n    i = 0\n    for inputs_batch, labels_batch in generator:\n        features_batch = conv_base.predict(inputs_batch)\n        features[i * batch_size : (i + 1) * batch_size] = features_batch\n        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n        i += 1\n        if i * batch_size >= sample_count:\n            # Note that since generators yield data indefinitely in a loop,\n            # we must `break` after every image has been seen once.\n            break\n    return features, labels\n\ntrain_features, train_labels = extract_features(train_dir, 2000)\nvalidation_features, validation_labels = extract_features(validation_dir, 1000)\ntest_features, test_labels = extract_features(test_dir, 1000)\n\nfrom keras.utils import to_categorical\nprint(train_labels)\nprint(train_labels.shape)\ntrain_labels = to_categorical(train_labels)\nprint(train_labels)\nprint(train_labels.shape)\nvalidation_labels = to_categorical(validation_labels)\ntest_labels = to_categorical(test_labels)\n\ntrain_features = np.reshape(train_features, (2000, 4 * 4 * 512))\nvalidation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\ntest_features = np.reshape(test_features, (1000, 4 * 4 * 512))\n\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\n\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\n# NUMBER OF CLASSES\nmodel.add(layers.Dense(3, activation='softmax'))\n\nmodel.summary()\n\nconv_base.trainable = False\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\n# Note that the validation data should not be augmented!\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        # This is the target directory\n        train_dir,\n        # All images will be resized to 150x150\n        target_size=(150, 150),\n        batch_size=20,\n        # Since we use categorical_crossentropy loss, we need binary labels\n        class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(150, 150),\n        batch_size=20,\n        class_mode='categorical')\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=2e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=30,\n      validation_data=validation_generator,\n      validation_steps=50,\n      verbose=2)\n\n\n#######################################\n# Fine tuning\n\n#conv_base.summary()\nconv_base.trainable = True\n\nset_trainable = False\nfor layer in conv_base.layers:\n    if layer.name == 'block5_conv1':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=100,\n      validation_data=validation_generator,\n      validation_steps=50)\n\nmodel.save('my_model_multiclass.hdf5')\n"
                    ]
                ],
                "question_id:": "52065",
                "question_votes:": "1",
                "question_text:": "<p><strong>Edit 2</strong> I solved my problem. The issue was caused by the validation_generator. I used the method flow_from_directory with shuffle = true. By changing the value to false and calling the method validation_generator.reset() before model.predict_generator() for computing the confusion matrix solved my problem. The reset()-method seems to be very important.</p>\n\n<p><strong>Edit:</strong> I was able to isolate the problem a little. I noticed that evaluate_generator method returns the correct values from the training, e.g. [0.068286080902908, 0.9853515625]. However, the predict_generator() method behaves strangely. The results look like this:  </p>\n\n<p>[[8.8930092e-06 5.8127771e-04 3.8436747e-06 7.7528159e-07 9.9940526e-01]\n [1.4138629e-03 9.9854565e-01 5.4473304e-07 3.9719587e-05 1.8904993e-07]\n [9.0803866e-07 2.7020766e-05 7.9189061e-07 4.9350000e-09 9.9997127e-01]\n ...\n [5.0964586e-06 4.5610027e-04 2.6184430e-06 1.6962146e-07 9.9953604e-01]\n [2.9692460e-08 3.1284328e-10 4.7919415e-09 1.0000000e+00 1.4161311e-12]\n [2.1354626e-06 9.6519925e-06 1.9460406e-07 4.6475903e-09 9.9998796e-01]]</p>\n\n<p><strong>####</strong></p>\n\n<p>I did some image classification with a CNN. The Accuracy of the training and validation set are high and the losses for both of them are low. However, my confusion matrix does not have the typical diagonal from the upper left to lower right. If I understand the confusion matrix correctly, I have a lot of misclassifications. So, how can I improve my model to get better results?</p>\n\n<p>The distribution of samples each class is:</p>\n\n<p>early: 800\nhealthy: 749\nlate: 764\nleaf mold: 761\nyellow: 708 </p>\n\n<p>The Structure of the model: </p>\n\n<pre><code>model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(150, 150, \n3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Dropout(0.15))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization())\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.6))\nmodel.add(layers.Dense(150, activation='relu', \nkernel_regularizer=regularizers.l2(0.002)))\nmodel.add(layers.Dense(5, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\noptimizer=optimizers.Adam(lr=1e-3),\nmetrics=['acc'])\n</code></pre>\n\n<p>These are the accuracy and losses of the training:</p>\n\n<pre><code>Epoch 00067: val_loss did not improve from 0.08283\nEpoch 68/200\n230/230 [==============================] - 56s 243ms/step - loss: 0.0893 - \nacc: 0.9793 - val_loss: 0.0876 - val_acc: 0.9784\n\nEpoch 00068: val_loss did not improve from 0.08283\nEpoch 69/200\n230/230 [==============================] - 58s 250ms/step - loss: 0.0874 - \nacc: 0.9774 - val_loss: 0.1209 - val_acc: 0.9684\n\nEpoch 00069: val_loss did not improve from 0.08283\nEpoch 70/200\n230/230 [==============================] - 57s 246ms/step - loss: 0.0879 - \nacc: 0.9803 - val_loss: 0.1384 - val_acc: 0.9706\n\nEpoch 00070: val_loss did not improve from 0.08283\nEpoch 71/200\n230/230 [==============================] - 59s 257ms/step - loss: 0.0903 - \nacc: 0.9783 - val_loss: 0.1352 - val_acc: 0.9728\n\nEpoch 00071: val_loss did not improve from 0.08283\nEpoch 72/200\n230/230 [==============================] - 58s 250ms/step - loss: 0.0852 - \nacc: 0.9798 - val_loss: 0.1324 - val_acc: 0.9621\n\nEpoch 00072: val_loss did not improve from 0.08283\nEpoch 73/200\n230/230 [==============================] - 58s 250ms/step - loss: 0.0831 - \nacc: 0.9815 - val_loss: 0.1634 - val_acc: 0.9574\n\nEpoch 00073: val_loss did not improve from 0.08283\nEpoch 74/200\n230/230 [==============================] - 57s 246ms/step - loss: 0.0824 - \nacc: 0.9816 - val_loss: 0.1280 - val_acc: 0.9640\n\nEpoch 00074: val_loss did not improve from 0.08283\nEpoch 75/200\n230/230 [==============================] - 57s 247ms/step - loss: 0.0869 - \nacc: 0.9774 - val_loss: 0.0777 - val_acc: 0.9882\n\nEpoch 00075: val_loss improved from 0.08283 to 0.07765, saving model to \nC:/Users/xxx/Desktop/best_model_7.h5\nEpoch 76/200\n230/230 [==============================] - 56s 243ms/step - loss: 0.0739 - \nacc: 0.9851 - val_loss: 0.0683 - val_acc: 0.9851\n\nEpoch 00076: val_loss improved from 0.07765 to 0.06826, saving model to \nC:/Users/xxx/Desktop/best_model_7.h5\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/SQrDS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/SQrDS.png\" alt=\"Accuracy and losses\"></a>\n<a href=\"https://i.stack.imgur.com/7oEDq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/7oEDq.png\" alt=\"confusion matrix\"></a></p>\n",
                "tags": "<keras><cnn><image-classification><confusion-matrix>",
                "answers": [
                    [
                        "52083",
                        "2",
                        "52065",
                        "",
                        "",
                        "<p>This is a bit strange... one problem may be that you do not have too many training samples. Do you use a pretrained model? If not, using a pretrained model can potentially improve classification accuracy (especially with limited training samples). \n<a href=\"https://keras.io/applications/\" rel=\"nofollow noreferrer\">https://keras.io/applications/</a></p>\n\n<p><strong>-Edit-</strong> This is a good sample code: <a href=\"https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.3-using-a-pretrained-convnet.ipynb\" rel=\"nofollow noreferrer\">https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.3-using-a-pretrained-convnet.ipynb</a></p>\n\n<p>Adjusted for multilass:</p>\n\n<pre><code>import keras\n\nfrom keras.applications import VGG16\n\nconv_base = VGG16(weights='imagenet',\n                  include_top=False,\n                  input_shape=(150, 150, 3))\n\nimport os\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\n\nbase_dir = 'C:/kerasimages'\n\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'val')\ntest_dir = os.path.join(base_dir, 'test')\n\ndatagen = ImageDataGenerator(rescale=1./255)\nbatch_size = 20\n\ndef extract_features(directory, sample_count):\n    features = np.zeros(shape=(sample_count, 4, 4, 512))\n    labels = np.zeros(shape=(sample_count))\n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='binary')\n    i = 0\n    for inputs_batch, labels_batch in generator:\n        features_batch = conv_base.predict(inputs_batch)\n        features[i * batch_size : (i + 1) * batch_size] = features_batch\n        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n        i += 1\n        if i * batch_size &gt;= sample_count:\n            # Note that since generators yield data indefinitely in a loop,\n            # we must `break` after every image has been seen once.\n            break\n    return features, labels\n\ntrain_features, train_labels = extract_features(train_dir, 2000)\nvalidation_features, validation_labels = extract_features(validation_dir, 1000)\ntest_features, test_labels = extract_features(test_dir, 1000)\n\nfrom keras.utils import to_categorical\nprint(train_labels)\nprint(train_labels.shape)\ntrain_labels = to_categorical(train_labels)\nprint(train_labels)\nprint(train_labels.shape)\nvalidation_labels = to_categorical(validation_labels)\ntest_labels = to_categorical(test_labels)\n\ntrain_features = np.reshape(train_features, (2000, 4 * 4 * 512))\nvalidation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\ntest_features = np.reshape(test_features, (1000, 4 * 4 * 512))\n\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\n\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\n# NUMBER OF CLASSES\nmodel.add(layers.Dense(3, activation='softmax'))\n\nmodel.summary()\n\nconv_base.trainable = False\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\n# Note that the validation data should not be augmented!\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        # This is the target directory\n        train_dir,\n        # All images will be resized to 150x150\n        target_size=(150, 150),\n        batch_size=20,\n        # Since we use categorical_crossentropy loss, we need binary labels\n        class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(150, 150),\n        batch_size=20,\n        class_mode='categorical')\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=2e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=30,\n      validation_data=validation_generator,\n      validation_steps=50,\n      verbose=2)\n\n\n#######################################\n# Fine tuning\n\n#conv_base.summary()\nconv_base.trainable = True\n\nset_trainable = False\nfor layer in conv_base.layers:\n    if layer.name == 'block5_conv1':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=100,\n      validation_data=validation_generator,\n      validation_steps=50)\n\nmodel.save('my_model_multiclass.hdf5')\n</code></pre>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11984",
            "_score": 4.7606373,
            "_source": {
                "title": "Using categorial_crossentropy to train a model in keras",
                "content": "Using categorial_crossentropy to train a model in keras <p>I'm a novice in machine learning. I was following <a href=\"https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\" rel=\"nofollow noreferrer\">this</a> Keras blog to train image classifier using Keras. Though this blog only demonstrates how to train only two classes using binary_crossentropy, I was hoping to train a model using my own custom multi-class(6) image datasets using categorial_crossentropy along with one hot encoded vector. So, here is what I tried so far:</p>\n\n<pre><code>import os\nimport numpy as np\nfrom keras import applications\nfrom keras import Model\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.layers import Input\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nfrom keras import optimizers\nimport cv2\n\n\nimg_width, img_height = 150, 150\n\nclass_indics = 'class_indices.npy'\nbottleneck_train_path = 'bottleneck_features_train.npy'\nbottleneck_validation_path = 'bottleneck_features_validation.npy'\ntop_model_weights_path = 'bottleneck_fc_model.h5'\ntrain_data_dir = 'data/train'\nvalidation_data_dir = 'data/validation/'\n\nnb_train_samples = 4800\nnb_validation_samples = 1200\n\nepochs = 50\nbatch_size = 15\n\n\ndef generate_class_indics():\n    datagen = ImageDataGenerator(rescale=1. / 255)\n\n    generator_top = datagen.flow_from_directory(train_data_dir,\n                                                    target_size=(img_width, img_height),\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    shuffle=False)\n\n    # save the class indices to use later in predictions\n    np.save(class_indics, generator_top.class_indices)\n\ndef save_bottleneck_features():\n    print('Using of bottleneck feature on pretrained model started.')\n    datagen = ImageDataGenerator(rescale=1. / 255)\n\n    # build the VGG16 network\n    model = applications.VGG16(include_top=False, weights='imagenet')\n\n    generator = datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=False)\n    bottleneck_features_train = model.predict_generator(\n        generator, nb_train_samples // batch_size)\n    np.save(open(bottleneck_train_path, 'wb'),\n            bottleneck_features_train)\n\n    generator = datagen.flow_from_directory(\n        validation_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=False)\n    bottleneck_features_validation = model.predict_generator(\n        generator, nb_validation_samples // batch_size)\n    np.save(open(bottleneck_validation_path, 'wb'),\n            bottleneck_features_validation)\n    print('Using of bottleneck feature on pretrained model finished.')\n\n\ndef train_top_model():\n    print('Training of top model started.')\n    train_data = np.load(open(bottleneck_train_path, 'rb'))\n    train_labels = np.array(\n        [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n\n    validation_data = np.load(open(bottleneck_validation_path, 'rb'))\n    validation_labels = np.array(\n        [0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n\n    class_dictionary = np.load('class_indices.npy').item()\n    num_classes = len(class_dictionary)\n\n    model = Sequential()\n    model.add(Flatten(input_shape=train_data.shape[1:]))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.7))\n    model.add(Dense(num_classes, activation='softmax')) #sigmoid\n\n    model.compile(optimizer='rmsprop',\n                  loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n\n    model.fit(train_data, train_labels,\n              epochs=epochs,\n              batch_size=batch_size,\n              validation_data=(validation_data, validation_labels))\n    model.save_weights(top_model_weights_path)\n    print('Training of top model completed &amp; saved as: ',top_model_weights_path)\n\n\ndef fine_tune_pretrained_model():\n    print('Fine tuning of pretrain model started.')\n    # build the VGG16 network\n    input_tensor = Input(shape=(150, 150, 3))\n\n    base_model = applications.VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)\n\n    class_dictionary = np.load('class_indices.npy').item()\n    num_classes = len(class_dictionary)\n\n    # build a classifier model to put on top of the convolutional model\n    top_model = Sequential()\n    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n    top_model.add(Dense(256, activation='relu'))\n    top_model.add(Dropout(0.7))\n    top_model.add(Dense(num_classes, activation='softmax')) #sigmoid\n\n    # note that it is necessary to start with a fully-trained\n    # classifier, including the top classifier,\n    # in order to successfully do fine-tuning\n    top_model.load_weights(top_model_weights_path)\n\n    # add the model on top of the convolutional base\n    model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n\n    # set the first 25 layers (up to the last conv block)\n    # to non-trainable (weights will not be updated)\n    for layer in model.layers[:25]:\n        layer.trainable = False\n\n    # compile the model with a SGD/momentum optimizer\n    # and a very slow learning rate.\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n                  metrics=['categorical_accuracy'])\n\n    # prepare data augmentation configuration\n    train_datagen = ImageDataGenerator(\n        rescale=1. / 255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\n    test_datagen = ImageDataGenerator(rescale=1. / 255)\n\n    train_generator = train_datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode='categorical')\n\n    validation_generator = test_datagen.flow_from_directory(\n        validation_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode='categorical')\n\n    # fine-tune the model\n    model.fit_generator(\n        train_generator,\n        steps_per_epoch=nb_train_samples // batch_size, # samples_per_epoch=nb_train_samples,\n        epochs=epochs,\n        validation_data=validation_generator,\n        validation_steps=nb_validation_samples)\n\n    print('Fine tuning of pretrain model completed.')\n\nif __name__ == '__main__':\n\n    if not os.path.exists(class_indics):\n        generate_class_indics()\n\n    if not os.path.exists(bottleneck_train_path):\n        save_bottleneck_features()\n\n    if not os.path.exists(top_model_weights_path):\n        train_top_model()\n        fine_tune_pretrained_model()\n</code></pre>\n\n<p>When I ran this code, <code>save_bottleneck_features()</code> &amp; <code>train_top_model()</code> executed correctly, but when I tried to run <code>fine_tune_pretrained_model()</code> it gives me this error:</p>\n\n<blockquote>\n  <p>Traceback (most recent call last):   File\n  \"/home/appsbee/PycharmProjects/fruit-classification-master/fruit-classification-master/fruit_classification_new.py\",\n  line 266, in \n      fine_tune_pretrained_model() File \"/home/appsbee/PycharmProjects/fruit-classification-master/fruit-classification-master/fruit_classification_new.py\",\n  line 159, in fine_tune_pretrained_model\n      top_model.load_weights(top_model_weights_path)  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\", line\n  1166, in load_weights\n      f, self.layers, reshape=reshape)  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\", line\n  1036, in load_weights_from_hdf5_group\n      str(len(filtered_layers)) + ' layers.') ValueError: You are trying to load a weight file containing 3 layers into a model with 2 layers.</p>\n</blockquote>\n\n<p>But I can see no extra layer was added on <code>fine_tune_pretrained_model()</code>.<br>\nSo, why I am getting this error?\nAny help will be appreciated.</p>\n <machine-learning><python><deep-learning><keras><p>You dont actually need to define the model architecture and then load weights with <code>model.load_weights</code> API . You could instead ask Keras to load the model with architecture and weights from your h5 file: </p>\n\n<pre><code>model = keras.models.load_model('bottleneck_fc_model.h5')\n</code></pre>\n\n<p>and then view the architecture:</p>\n\n<pre><code>print(model.summary())\n</code></pre>\n\n<p>You can then use <code>model.add</code> API to add more layers on top.</p>\n\n<p>Of course you can use this only if you used <code>model.save</code> instead of <code>model.save_weights</code> earlier to save model after training.</p>\n",
                "codes": [
                    [
                        "model = keras.models.load_model('bottleneck_fc_model.h5')\n",
                        "print(model.summary())\n"
                    ]
                ],
                "question_id:": "42142",
                "question_votes:": "",
                "question_text:": "<p>I'm a novice in machine learning. I was following <a href=\"https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\" rel=\"nofollow noreferrer\">this</a> Keras blog to train image classifier using Keras. Though this blog only demonstrates how to train only two classes using binary_crossentropy, I was hoping to train a model using my own custom multi-class(6) image datasets using categorial_crossentropy along with one hot encoded vector. So, here is what I tried so far:</p>\n\n<pre><code>import os\nimport numpy as np\nfrom keras import applications\nfrom keras import Model\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.layers import Input\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nfrom keras import optimizers\nimport cv2\n\n\nimg_width, img_height = 150, 150\n\nclass_indics = 'class_indices.npy'\nbottleneck_train_path = 'bottleneck_features_train.npy'\nbottleneck_validation_path = 'bottleneck_features_validation.npy'\ntop_model_weights_path = 'bottleneck_fc_model.h5'\ntrain_data_dir = 'data/train'\nvalidation_data_dir = 'data/validation/'\n\nnb_train_samples = 4800\nnb_validation_samples = 1200\n\nepochs = 50\nbatch_size = 15\n\n\ndef generate_class_indics():\n    datagen = ImageDataGenerator(rescale=1. / 255)\n\n    generator_top = datagen.flow_from_directory(train_data_dir,\n                                                    target_size=(img_width, img_height),\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    shuffle=False)\n\n    # save the class indices to use later in predictions\n    np.save(class_indics, generator_top.class_indices)\n\ndef save_bottleneck_features():\n    print('Using of bottleneck feature on pretrained model started.')\n    datagen = ImageDataGenerator(rescale=1. / 255)\n\n    # build the VGG16 network\n    model = applications.VGG16(include_top=False, weights='imagenet')\n\n    generator = datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=False)\n    bottleneck_features_train = model.predict_generator(\n        generator, nb_train_samples // batch_size)\n    np.save(open(bottleneck_train_path, 'wb'),\n            bottleneck_features_train)\n\n    generator = datagen.flow_from_directory(\n        validation_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=False)\n    bottleneck_features_validation = model.predict_generator(\n        generator, nb_validation_samples // batch_size)\n    np.save(open(bottleneck_validation_path, 'wb'),\n            bottleneck_features_validation)\n    print('Using of bottleneck feature on pretrained model finished.')\n\n\ndef train_top_model():\n    print('Training of top model started.')\n    train_data = np.load(open(bottleneck_train_path, 'rb'))\n    train_labels = np.array(\n        [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n\n    validation_data = np.load(open(bottleneck_validation_path, 'rb'))\n    validation_labels = np.array(\n        [0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n\n    class_dictionary = np.load('class_indices.npy').item()\n    num_classes = len(class_dictionary)\n\n    model = Sequential()\n    model.add(Flatten(input_shape=train_data.shape[1:]))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.7))\n    model.add(Dense(num_classes, activation='softmax')) #sigmoid\n\n    model.compile(optimizer='rmsprop',\n                  loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n\n    model.fit(train_data, train_labels,\n              epochs=epochs,\n              batch_size=batch_size,\n              validation_data=(validation_data, validation_labels))\n    model.save_weights(top_model_weights_path)\n    print('Training of top model completed &amp; saved as: ',top_model_weights_path)\n\n\ndef fine_tune_pretrained_model():\n    print('Fine tuning of pretrain model started.')\n    # build the VGG16 network\n    input_tensor = Input(shape=(150, 150, 3))\n\n    base_model = applications.VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)\n\n    class_dictionary = np.load('class_indices.npy').item()\n    num_classes = len(class_dictionary)\n\n    # build a classifier model to put on top of the convolutional model\n    top_model = Sequential()\n    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n    top_model.add(Dense(256, activation='relu'))\n    top_model.add(Dropout(0.7))\n    top_model.add(Dense(num_classes, activation='softmax')) #sigmoid\n\n    # note that it is necessary to start with a fully-trained\n    # classifier, including the top classifier,\n    # in order to successfully do fine-tuning\n    top_model.load_weights(top_model_weights_path)\n\n    # add the model on top of the convolutional base\n    model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n\n    # set the first 25 layers (up to the last conv block)\n    # to non-trainable (weights will not be updated)\n    for layer in model.layers[:25]:\n        layer.trainable = False\n\n    # compile the model with a SGD/momentum optimizer\n    # and a very slow learning rate.\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n                  metrics=['categorical_accuracy'])\n\n    # prepare data augmentation configuration\n    train_datagen = ImageDataGenerator(\n        rescale=1. / 255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\n    test_datagen = ImageDataGenerator(rescale=1. / 255)\n\n    train_generator = train_datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode='categorical')\n\n    validation_generator = test_datagen.flow_from_directory(\n        validation_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode='categorical')\n\n    # fine-tune the model\n    model.fit_generator(\n        train_generator,\n        steps_per_epoch=nb_train_samples // batch_size, # samples_per_epoch=nb_train_samples,\n        epochs=epochs,\n        validation_data=validation_generator,\n        validation_steps=nb_validation_samples)\n\n    print('Fine tuning of pretrain model completed.')\n\nif __name__ == '__main__':\n\n    if not os.path.exists(class_indics):\n        generate_class_indics()\n\n    if not os.path.exists(bottleneck_train_path):\n        save_bottleneck_features()\n\n    if not os.path.exists(top_model_weights_path):\n        train_top_model()\n        fine_tune_pretrained_model()\n</code></pre>\n\n<p>When I ran this code, <code>save_bottleneck_features()</code> &amp; <code>train_top_model()</code> executed correctly, but when I tried to run <code>fine_tune_pretrained_model()</code> it gives me this error:</p>\n\n<blockquote>\n  <p>Traceback (most recent call last):   File\n  \"/home/appsbee/PycharmProjects/fruit-classification-master/fruit-classification-master/fruit_classification_new.py\",\n  line 266, in \n      fine_tune_pretrained_model() File \"/home/appsbee/PycharmProjects/fruit-classification-master/fruit-classification-master/fruit_classification_new.py\",\n  line 159, in fine_tune_pretrained_model\n      top_model.load_weights(top_model_weights_path)  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\", line\n  1166, in load_weights\n      f, self.layers, reshape=reshape)  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\", line\n  1036, in load_weights_from_hdf5_group\n      str(len(filtered_layers)) + ' layers.') ValueError: You are trying to load a weight file containing 3 layers into a model with 2 layers.</p>\n</blockquote>\n\n<p>But I can see no extra layer was added on <code>fine_tune_pretrained_model()</code>.<br>\nSo, why I am getting this error?\nAny help will be appreciated.</p>\n",
                "tags": "<machine-learning><python><deep-learning><keras>",
                "answers": [
                    [
                        "42160",
                        "2",
                        "42142",
                        "",
                        "",
                        "<p>You dont actually need to define the model architecture and then load weights with <code>model.load_weights</code> API . You could instead ask Keras to load the model with architecture and weights from your h5 file: </p>\n\n<pre><code>model = keras.models.load_model('bottleneck_fc_model.h5')\n</code></pre>\n\n<p>and then view the architecture:</p>\n\n<pre><code>print(model.summary())\n</code></pre>\n\n<p>You can then use <code>model.add</code> API to add more layers on top.</p>\n\n<p>Of course you can use this only if you used <code>model.save</code> instead of <code>model.save_weights</code> earlier to save model after training.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12148",
            "_score": 4.7606373,
            "_source": {
                "title": "Confusion about Entity Embeddings of Categorical Variables - Working Example!",
                "content": "Confusion about Entity Embeddings of Categorical Variables - Working Example! <p><strong>Problem Statement:</strong> I have problem making the <strong>Entity Embedding of Categorical Variable</strong> works for a simple dataset. I have followed the original <a href=\"https://github.com/entron/entity-embedding-rossmann\" rel=\"noreferrer\">github</a>, or <a href=\"https://arxiv.org/pdf/1604.06737.pdf\" rel=\"noreferrer\">paper</a>, or other blogposts[<a href=\"https://medium.com/@satnalikamayank12/on-learning-embeddings-for-categorical-data-using-keras-165ff2773fc9\" rel=\"noreferrer\">1</a>,<a href=\"https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526\" rel=\"noreferrer\">2</a>,or this <a href=\"https://towardsdatascience.com/decoded-entity-embeddings-of-categorical-variables-in-neural-networks-1d2468311635\" rel=\"noreferrer\">3]</a>, or this Kaggle <a href=\"https://www.kaggle.com/aquatic/entity-embedding-neural-net\" rel=\"noreferrer\">kernel</a>; still not working.</p>\n\n<p><strong>Data Part:</strong> I am using the <strong><a href=\"https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\" rel=\"noreferrer\">Ames Housing</a></strong> dataset as was hosted in Kaggle. I'm loading it in pandas dataframe as:</p>\n\n<pre><code>url = 'http://www.amstat.org/publications/jse/v19n3/decock/AmesHousing.xls'\n# Load the file into a Pandas DataFrame\ndata_df = pd.read_excel(url)\n</code></pre>\n\n<p>For simplicity, out of 81 independent features, I am ONLY taking the <em>Neighborhood</em>, which is categorical, and the <em>Gr Liv Area</em>, which is numerical. And <em>SalePrice</em>, which is our target. I also split the data into train, and test and normalize the numerical variables.</p>\n\n<pre><code>features = ['Neighborhood','Gr Liv Area']\ntarget = ['SalePrice']\ndata_df=data_df[features + target]\n\nX_train, y_train = data_df.iloc[:2000][features], data_df.iloc[:2000][target]\nX_test = data_df.iloc[2000:][features]\n\nX_train['Gr Liv Area']=StandardScaler().fit_transform(X_train['Gr Liv Area'].reshape(-1, 1)) \ny_train=StandardScaler().fit_transform(y_train) \n</code></pre>\n\n<p><strong>Embedding Neural Net:</strong>\nHere is the block of code where I am building the Entity Embedding Neural Net including both the categorical and numerical variables. In Entity Embedding, there is a particular hyperparamter that defines the embedding size (as we have in NLP). Here I am using of the <a href=\"https://medium.com/@satnalikamayank12/on-learning-embeddings-for-categorical-data-using-keras-165ff2773fc9\" rel=\"noreferrer\">above-mentioned blogpost</a> strategy to choose that.</p>\n\n<pre><code>input_models=[]\noutput_embeddings=[]\nnumerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n\nfor categorical_var in X_train.select_dtypes(include=['object']):\n\n  #Name of the categorical variable that will be used in the Keras Embedding layer\n  cat_emb_name= categorical_var.replace(\" \", \"\")+'_Embedding'\n\n  # Define the embedding_size\n  no_of_unique_cat  = X_train[categorical_var].nunique()\n  embedding_size = int(min(np.ceil((no_of_unique_cat)/2), 50 ))\n  vocab  = no_of_unique_cat+1\n\n  #One Embedding Layer for each categorical variable\n  input_model = Input(shape=(1,))\n  output_model = Embedding(vocab, embedding_size, name=cat_emb_name)(input_model)\n  output_model = Reshape(target_shape=(embedding_size,))(output_model)    \n\n  #Appending all the categorical inputs\n  input_models.append(input_model)\n\n  #Appending all the embeddings\n  output_embeddings.append(output_model)\n\n#Other non-categorical data columns (numerical). \n#I define single another network for the other columns and add them to our models list.\ninput_numeric = Input(shape=(len(X_train.select_dtypes(include=numerics).columns.tolist()),))\nembedding_numeric = Dense(64)(input_numeric) \ninput_models.append(input_numeric)\noutput_embeddings.append(embedding_numeric)\n\n#At the end we concatenate altogther and add other Dense layers\noutput = Concatenate()(output_embeddings)\noutput = Dense(500, kernel_initializer=\"uniform\")(output)\noutput = Activation('relu')(output)\noutput = Dense(256, kernel_initializer=\"uniform\")(output)\noutput = Activation('relu')(output)\noutput = Dense(1, activation='sigmoid')(output)\n\nmodel = Model(inputs=input_models, outputs=output)\nmodel.compile(loss='mean_squared_error', optimizer='Adam',metrics=['mse','mape'])\n</code></pre>\n\n<p>At the end, the model looks like this:\n<a href=\"https://i.stack.imgur.com/q9S0S.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/q9S0S.png\" alt=\"enter image description here\"></a></p>\n\n<p>This look OK to me, unless I'm missing sth. Anyway, when I'm training the model like below:</p>\n\n<pre><code>history  =  model.fit(X_train,y_train  , epochs =  200 , batch_size = 16, verbose= 2)\n</code></pre>\n\n<p>I get a rather usual keras error: </p>\n\n<pre><code>ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([['NAmes', 0.31507361227175135],\n       ['NAmes', -1.2242024755540366],\n       ['NAmes', -0.3472201781480285],\n       ...,\n</code></pre>\n\n<p>Then I looked more carefully at the original github or that Kaggle kernel, I noticed one has to <em>convert</em> the data to list format to match the network structure (<strong>still I am not sure I fully understand WHY!</strong>, see the <strong><em>preproc function</em></strong> there). Anyway, I convert my data to the list format like: </p>\n\n<pre><code>X_train_list = []\n\nfor i,column in enumerate(X_train.columns.tolist()):\n  X_train_list.append(X_train.values[..., [i]])\n</code></pre>\n\n<p>Now when trying to train once again this time using the list format of the data i.e. <em>X_train_list</em>:</p>\n\n<pre><code>history  =  model.fit(X_train_list,y_train  , epochs =  200 , batch_size = 16, verbose= 2)\n</code></pre>\n\n<p>This time it starts with the first Epoch, then immediately stops with the following error: </p>\n\n<pre><code>ValueError: could not convert string to float: 'Mitchel'\n</code></pre>\n\n<p>It is rather obvious that it complains about one of the categories of the only <em>Neighborhood</em> variable that I have not encoded! Sure I have not, I thought that was the whole purpose of the <strong>Entity Embedding</strong> that the networks initiates a random embedding weights and learn the best embedding of that categorical variable during optimization of the target. Super confused!! Any help is much appreciated.</p>\n <python><neural-network><keras><categorical-data><embeddings><p>For those who are interested, I've spent some time, finally figured out that the problem was the way one has to prepare the categorical encoding for the Entity Embedding suitable for a neural network architecture; unfortunately none of the examples provided in blogposts or Kaggle kernels were clear about this step! </p>\n\n<p>Here is <a href=\"https://github.com/mmortazavi/EntityEmbedding-Working_Example\" rel=\"noreferrer\"><strong>the link to the repository</strong></a> containing a Jupyter notebook demonstrating a step-by-step working example. Hope some may find it useful.</p>\n\n<p>P.S.: I have borrowed some of the functions from other people's work, kernels, that need to be referenced properly. Hopefully I will manage to update the notebook soon adding those refs. </p>\n",
                "codes": [
                    []
                ],
                "question_id:": "42730",
                "question_votes:": "5",
                "question_text:": "<p><strong>Problem Statement:</strong> I have problem making the <strong>Entity Embedding of Categorical Variable</strong> works for a simple dataset. I have followed the original <a href=\"https://github.com/entron/entity-embedding-rossmann\" rel=\"noreferrer\">github</a>, or <a href=\"https://arxiv.org/pdf/1604.06737.pdf\" rel=\"noreferrer\">paper</a>, or other blogposts[<a href=\"https://medium.com/@satnalikamayank12/on-learning-embeddings-for-categorical-data-using-keras-165ff2773fc9\" rel=\"noreferrer\">1</a>,<a href=\"https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526\" rel=\"noreferrer\">2</a>,or this <a href=\"https://towardsdatascience.com/decoded-entity-embeddings-of-categorical-variables-in-neural-networks-1d2468311635\" rel=\"noreferrer\">3]</a>, or this Kaggle <a href=\"https://www.kaggle.com/aquatic/entity-embedding-neural-net\" rel=\"noreferrer\">kernel</a>; still not working.</p>\n\n<p><strong>Data Part:</strong> I am using the <strong><a href=\"https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\" rel=\"noreferrer\">Ames Housing</a></strong> dataset as was hosted in Kaggle. I'm loading it in pandas dataframe as:</p>\n\n<pre><code>url = 'http://www.amstat.org/publications/jse/v19n3/decock/AmesHousing.xls'\n# Load the file into a Pandas DataFrame\ndata_df = pd.read_excel(url)\n</code></pre>\n\n<p>For simplicity, out of 81 independent features, I am ONLY taking the <em>Neighborhood</em>, which is categorical, and the <em>Gr Liv Area</em>, which is numerical. And <em>SalePrice</em>, which is our target. I also split the data into train, and test and normalize the numerical variables.</p>\n\n<pre><code>features = ['Neighborhood','Gr Liv Area']\ntarget = ['SalePrice']\ndata_df=data_df[features + target]\n\nX_train, y_train = data_df.iloc[:2000][features], data_df.iloc[:2000][target]\nX_test = data_df.iloc[2000:][features]\n\nX_train['Gr Liv Area']=StandardScaler().fit_transform(X_train['Gr Liv Area'].reshape(-1, 1)) \ny_train=StandardScaler().fit_transform(y_train) \n</code></pre>\n\n<p><strong>Embedding Neural Net:</strong>\nHere is the block of code where I am building the Entity Embedding Neural Net including both the categorical and numerical variables. In Entity Embedding, there is a particular hyperparamter that defines the embedding size (as we have in NLP). Here I am using of the <a href=\"https://medium.com/@satnalikamayank12/on-learning-embeddings-for-categorical-data-using-keras-165ff2773fc9\" rel=\"noreferrer\">above-mentioned blogpost</a> strategy to choose that.</p>\n\n<pre><code>input_models=[]\noutput_embeddings=[]\nnumerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n\nfor categorical_var in X_train.select_dtypes(include=['object']):\n\n  #Name of the categorical variable that will be used in the Keras Embedding layer\n  cat_emb_name= categorical_var.replace(\" \", \"\")+'_Embedding'\n\n  # Define the embedding_size\n  no_of_unique_cat  = X_train[categorical_var].nunique()\n  embedding_size = int(min(np.ceil((no_of_unique_cat)/2), 50 ))\n  vocab  = no_of_unique_cat+1\n\n  #One Embedding Layer for each categorical variable\n  input_model = Input(shape=(1,))\n  output_model = Embedding(vocab, embedding_size, name=cat_emb_name)(input_model)\n  output_model = Reshape(target_shape=(embedding_size,))(output_model)    \n\n  #Appending all the categorical inputs\n  input_models.append(input_model)\n\n  #Appending all the embeddings\n  output_embeddings.append(output_model)\n\n#Other non-categorical data columns (numerical). \n#I define single another network for the other columns and add them to our models list.\ninput_numeric = Input(shape=(len(X_train.select_dtypes(include=numerics).columns.tolist()),))\nembedding_numeric = Dense(64)(input_numeric) \ninput_models.append(input_numeric)\noutput_embeddings.append(embedding_numeric)\n\n#At the end we concatenate altogther and add other Dense layers\noutput = Concatenate()(output_embeddings)\noutput = Dense(500, kernel_initializer=\"uniform\")(output)\noutput = Activation('relu')(output)\noutput = Dense(256, kernel_initializer=\"uniform\")(output)\noutput = Activation('relu')(output)\noutput = Dense(1, activation='sigmoid')(output)\n\nmodel = Model(inputs=input_models, outputs=output)\nmodel.compile(loss='mean_squared_error', optimizer='Adam',metrics=['mse','mape'])\n</code></pre>\n\n<p>At the end, the model looks like this:\n<a href=\"https://i.stack.imgur.com/q9S0S.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/q9S0S.png\" alt=\"enter image description here\"></a></p>\n\n<p>This look OK to me, unless I'm missing sth. Anyway, when I'm training the model like below:</p>\n\n<pre><code>history  =  model.fit(X_train,y_train  , epochs =  200 , batch_size = 16, verbose= 2)\n</code></pre>\n\n<p>I get a rather usual keras error: </p>\n\n<pre><code>ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([['NAmes', 0.31507361227175135],\n       ['NAmes', -1.2242024755540366],\n       ['NAmes', -0.3472201781480285],\n       ...,\n</code></pre>\n\n<p>Then I looked more carefully at the original github or that Kaggle kernel, I noticed one has to <em>convert</em> the data to list format to match the network structure (<strong>still I am not sure I fully understand WHY!</strong>, see the <strong><em>preproc function</em></strong> there). Anyway, I convert my data to the list format like: </p>\n\n<pre><code>X_train_list = []\n\nfor i,column in enumerate(X_train.columns.tolist()):\n  X_train_list.append(X_train.values[..., [i]])\n</code></pre>\n\n<p>Now when trying to train once again this time using the list format of the data i.e. <em>X_train_list</em>:</p>\n\n<pre><code>history  =  model.fit(X_train_list,y_train  , epochs =  200 , batch_size = 16, verbose= 2)\n</code></pre>\n\n<p>This time it starts with the first Epoch, then immediately stops with the following error: </p>\n\n<pre><code>ValueError: could not convert string to float: 'Mitchel'\n</code></pre>\n\n<p>It is rather obvious that it complains about one of the categories of the only <em>Neighborhood</em> variable that I have not encoded! Sure I have not, I thought that was the whole purpose of the <strong>Entity Embedding</strong> that the networks initiates a random embedding weights and learn the best embedding of that categorical variable during optimization of the target. Super confused!! Any help is much appreciated.</p>\n",
                "tags": "<python><neural-network><keras><categorical-data><embeddings>",
                "answers": [
                    [
                        "44639",
                        "2",
                        "42730",
                        "",
                        "",
                        "<p>For those who are interested, I've spent some time, finally figured out that the problem was the way one has to prepare the categorical encoding for the Entity Embedding suitable for a neural network architecture; unfortunately none of the examples provided in blogposts or Kaggle kernels were clear about this step! </p>\n\n<p>Here is <a href=\"https://github.com/mmortazavi/EntityEmbedding-Working_Example\" rel=\"noreferrer\"><strong>the link to the repository</strong></a> containing a Jupyter notebook demonstrating a step-by-step working example. Hope some may find it useful.</p>\n\n<p>P.S.: I have borrowed some of the functions from other people's work, kernels, that need to be referenced properly. Hopefully I will manage to update the notebook soon adding those refs. </p>\n",
                        "",
                        "9"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "12984",
            "_score": 4.7606373,
            "_source": {
                "title": "Solving an ODE using neural networks (via Tensorflow)",
                "content": "Solving an ODE using neural networks (via Tensorflow) <p>I'm very new to deep learning (coming from a math PDE background), but I'm trying to solve some ODEs using a neural network (via tensorflow). I've solved some simple ones like <span class=\"math-container\">$u'(x)+u(x) = f(x)$</span> with no problem, but I'm trying something a bit harder now: <span class=\"math-container\">$u''(x) - xu(x) = 0$</span> with the initial conditions <span class=\"math-container\">$u(0)=A$</span> and <span class=\"math-container\">$u'(0)=B$</span>.</p>\n\n<p>I'm mostly following this <a href=\"https://arxiv.org/pdf/physics/9705023.pdf\" rel=\"nofollow noreferrer\">paper</a>, and my solution is written as <span class=\"math-container\">$u_{N}(x) = A + Bx + x^2N(x,w)$</span>, where <span class=\"math-container\">$N(x,w)$</span>` is the output of the neural net. The loss function I'm using is just the residual of the ODE in a mean square sense, so it's pretty crude: <span class=\"math-container\">$\\ell(x,w) = \\sum_{j=1}^{N} (u_{N}''(x) - xu_{N}(x))^{2}$</span>. I'm having a lot of trouble getting a good numerical solution to this particular equation. You can see a typical result below (orange is the exact solution, blue is my solution). <a href=\"https://i.stack.imgur.com/uDebm.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/uDebm.png\" alt=\"Orange line is the exact solution, blue line is the numerical solution\"></a> </p>\n\n<p>My current setup is just 2 hidden layers of 400 nodes each (one leaky ReLU and one ReLU) followed by a linear activation layer. My input data is an evenly spaced discretization of the domain. I'm using the Adam optimizer with a batch size of 32 and run for 400 epochs. I can't seem to capture the oscillating behavior in the left of the domain properly no matter what parameters I tweak. </p>\n\n<p>Does anyone have any suggestions for how to improve the result? I'm very very new to deep learning and neural networks. If it helps, my code is included below. I should also probably give credit to Emm and vijay m, <a href=\"https://stackoverflow.com/questions/48754467/function-approximation-tensorflow\">whose code for 1D approximation</a> was the base for my code</p>\n\n<pre><code># Load modules\nimport tensorflow as tf\nimport numpy as np\nimport math, random\nimport matplotlib.pyplot as plt\nfrom scipy import special\n\n######################################################################\n# Routine to solve u''(x) - x*u(x) = f(x), u(0)=A, u'(0)=B in the form\n#     u(x) = A + B*x + x^2*N(x,w)\n# where N(x,w) is the output of the neural network.\n######################################################################\n\n# Create the arrays x and y, where x is a discretization of the domain (a,b) and y is the source term f(x)\nN = 200\na = -6.0\nb = 2.0\nx = np.arange(a, b, (b-a)/N).reshape((N,1))\ny = np.zeros(N)\n\n# Boundary conditions\nA = 1.0\nB = 0.0\n\n# Define the number of neurons in each layer\nn_nodes_hl1 = 400\nn_nodes_hl2 = 400\n\n# Define the number of outputs and the learning rate\nn_classes = 1\nlearn_rate = 0.00003\n\n# Define input / output placeholders\nx_ph = tf.placeholder('float', [None, 1],name='input')\ny_ph = tf.placeholder('float')\n\n# Define standard deviation for the weights and biases\nhl_sigma = 0.02\n\n# Routine to compute the neural network (5 hidden layers)\ndef neural_network_model(data):\n    hidden_1_layer = {'weights': tf.Variable(name='w_h1',initial_value=tf.random_normal([1, n_nodes_hl1], stddev=hl_sigma)),\n                      'biases': tf.Variable(name='b_h1',initial_value=tf.random_normal([n_nodes_hl1], stddev=hl_sigma))}\n\n    hidden_2_layer = {'weights': tf.Variable(name='w_h2',initial_value=tf.random_normal([n_nodes_hl1, n_nodes_hl2], stddev=hl_sigma)),\n                      'biases': tf.Variable(name='b_h2',initial_value=tf.random_normal([n_nodes_hl2], stddev=hl_sigma))}\n\n    output_layer = {'weights': tf.Variable(name='w_o',initial_value=tf.random_normal([n_nodes_hl2, n_classes], stddev=hl_sigma)),\n                      'biases': tf.Variable(name='b_o',initial_value=tf.random_normal([n_classes], stddev=hl_sigma))}\n\n\n    # (input_data * weights) + biases\n    l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']), hidden_1_layer['biases'])\n    l1 = tf.nn.leaky_relu(l1)   \n\n    l2 = tf.add(tf.matmul(l1, hidden_2_layer['weights']), hidden_2_layer['biases'])\n    l2 = tf.nn.relu(l2)\n\n    output = tf.add(tf.matmul(l2, output_layer['weights']), output_layer['biases'], name='output')\n\n    return output\n\n\nbatch_size = 32\n\n# Feed batch data\ndef get_batch(inputX, inputY, batch_size):\n    duration = len(inputX)\n    for i in range(0,duration//batch_size):\n        idx = i*batch_size + np.random.randint(0,10,(1))[0]\n\n        yield inputX[idx:idx+batch_size], inputY[idx:idx+batch_size]\n\n\n# Routine to train the neural network\ndef train_neural_network_batch(x_ph, predict=False):\n    prediction = neural_network_model(x_ph)\n    pred_dx = tf.gradients(prediction, x_ph)\n    pred_dx2 = tf.gradients(tf.gradients(prediction, x_ph),x_ph)\n\n    # Compute u and its second derivative\n    u = A + B*x_ph + (x_ph*x_ph)*prediction\n    dudx2 = (x_ph*x_ph)*pred_dx2 + 2.0*x_ph*pred_dx + 2.0*x_ph*pred_dx + 2.0*prediction\n\n    # The cost function is just the residual of u''(x) - x*u(x) = 0, i.e. residual = u''(x)-x*u(x)\n    cost = tf.reduce_mean(tf.square(dudx2-x_ph*u - y_ph))\n    optimizer = tf.train.AdamOptimizer(learn_rate).minimize(cost)\n\n\n    # cycles feed forward + backprop\n    hm_epochs = 400\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n\n        # Train in each epoch with the whole data\n        for epoch in range(hm_epochs):\n\n            epoch_loss = 0\n            for step in range(N//batch_size):\n                for inputX, inputY in get_batch(x, y, batch_size):\n                    _, l = sess.run([optimizer,cost], feed_dict={x_ph:inputX, y_ph:inputY})\n                    epoch_loss += l\n            if epoch %10 == 0:\n                print('Epoch', epoch, 'completed out of', hm_epochs, 'loss:', epoch_loss)\n\n\n        # Predict a new input by adding a random number, to check whether the network has actually learned\n        x_valid = x + 0.0*np.random.normal(scale=0.1,size=(1))\n        return sess.run(tf.squeeze(prediction),{x_ph:x_valid}), x_valid\n\n\n# Train network\ntf.set_random_seed(42)\npred, time = train_neural_network_batch(x_ph)\n\n\nmypred = pred.reshape(N,1)\n\n# Compute Airy functions for exact solution\nai, aip, bi, bip = special.airy(time)\n\n# Numerical solution vs. exact solution\nfig = plt.figure()\nplt.plot(time, A + B*time + (time*time)*mypred)\nplt.plot(time, 0.5*(3.0**(1/6))*special.gamma(2/3)*(3**(1/2)*ai + bi))\nplt.show()\n</code></pre>\n <neural-network><deep-learning><tensorflow><ol>\n<li><p>Please avoid using piecewise linear activations for second or higher-order ODEs, as the second and higher-order derivatives of these functions are zero. Alternatively, Tanh activations might be a good option.</p></li>\n<li><p>I recommend using deeper networks. Based on my experience, depth can significantly improve the results when solving differential equations with neural networks.</p></li>\n</ol>\n",
                "codes": [
                    []
                ],
                "question_id:": "45015",
                "question_votes:": "4",
                "question_text:": "<p>I'm very new to deep learning (coming from a math PDE background), but I'm trying to solve some ODEs using a neural network (via tensorflow). I've solved some simple ones like <span class=\"math-container\">$u'(x)+u(x) = f(x)$</span> with no problem, but I'm trying something a bit harder now: <span class=\"math-container\">$u''(x) - xu(x) = 0$</span> with the initial conditions <span class=\"math-container\">$u(0)=A$</span> and <span class=\"math-container\">$u'(0)=B$</span>.</p>\n\n<p>I'm mostly following this <a href=\"https://arxiv.org/pdf/physics/9705023.pdf\" rel=\"nofollow noreferrer\">paper</a>, and my solution is written as <span class=\"math-container\">$u_{N}(x) = A + Bx + x^2N(x,w)$</span>, where <span class=\"math-container\">$N(x,w)$</span>` is the output of the neural net. The loss function I'm using is just the residual of the ODE in a mean square sense, so it's pretty crude: <span class=\"math-container\">$\\ell(x,w) = \\sum_{j=1}^{N} (u_{N}''(x) - xu_{N}(x))^{2}$</span>. I'm having a lot of trouble getting a good numerical solution to this particular equation. You can see a typical result below (orange is the exact solution, blue is my solution). <a href=\"https://i.stack.imgur.com/uDebm.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/uDebm.png\" alt=\"Orange line is the exact solution, blue line is the numerical solution\"></a> </p>\n\n<p>My current setup is just 2 hidden layers of 400 nodes each (one leaky ReLU and one ReLU) followed by a linear activation layer. My input data is an evenly spaced discretization of the domain. I'm using the Adam optimizer with a batch size of 32 and run for 400 epochs. I can't seem to capture the oscillating behavior in the left of the domain properly no matter what parameters I tweak. </p>\n\n<p>Does anyone have any suggestions for how to improve the result? I'm very very new to deep learning and neural networks. If it helps, my code is included below. I should also probably give credit to Emm and vijay m, <a href=\"https://stackoverflow.com/questions/48754467/function-approximation-tensorflow\">whose code for 1D approximation</a> was the base for my code</p>\n\n<pre><code># Load modules\nimport tensorflow as tf\nimport numpy as np\nimport math, random\nimport matplotlib.pyplot as plt\nfrom scipy import special\n\n######################################################################\n# Routine to solve u''(x) - x*u(x) = f(x), u(0)=A, u'(0)=B in the form\n#     u(x) = A + B*x + x^2*N(x,w)\n# where N(x,w) is the output of the neural network.\n######################################################################\n\n# Create the arrays x and y, where x is a discretization of the domain (a,b) and y is the source term f(x)\nN = 200\na = -6.0\nb = 2.0\nx = np.arange(a, b, (b-a)/N).reshape((N,1))\ny = np.zeros(N)\n\n# Boundary conditions\nA = 1.0\nB = 0.0\n\n# Define the number of neurons in each layer\nn_nodes_hl1 = 400\nn_nodes_hl2 = 400\n\n# Define the number of outputs and the learning rate\nn_classes = 1\nlearn_rate = 0.00003\n\n# Define input / output placeholders\nx_ph = tf.placeholder('float', [None, 1],name='input')\ny_ph = tf.placeholder('float')\n\n# Define standard deviation for the weights and biases\nhl_sigma = 0.02\n\n# Routine to compute the neural network (5 hidden layers)\ndef neural_network_model(data):\n    hidden_1_layer = {'weights': tf.Variable(name='w_h1',initial_value=tf.random_normal([1, n_nodes_hl1], stddev=hl_sigma)),\n                      'biases': tf.Variable(name='b_h1',initial_value=tf.random_normal([n_nodes_hl1], stddev=hl_sigma))}\n\n    hidden_2_layer = {'weights': tf.Variable(name='w_h2',initial_value=tf.random_normal([n_nodes_hl1, n_nodes_hl2], stddev=hl_sigma)),\n                      'biases': tf.Variable(name='b_h2',initial_value=tf.random_normal([n_nodes_hl2], stddev=hl_sigma))}\n\n    output_layer = {'weights': tf.Variable(name='w_o',initial_value=tf.random_normal([n_nodes_hl2, n_classes], stddev=hl_sigma)),\n                      'biases': tf.Variable(name='b_o',initial_value=tf.random_normal([n_classes], stddev=hl_sigma))}\n\n\n    # (input_data * weights) + biases\n    l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']), hidden_1_layer['biases'])\n    l1 = tf.nn.leaky_relu(l1)   \n\n    l2 = tf.add(tf.matmul(l1, hidden_2_layer['weights']), hidden_2_layer['biases'])\n    l2 = tf.nn.relu(l2)\n\n    output = tf.add(tf.matmul(l2, output_layer['weights']), output_layer['biases'], name='output')\n\n    return output\n\n\nbatch_size = 32\n\n# Feed batch data\ndef get_batch(inputX, inputY, batch_size):\n    duration = len(inputX)\n    for i in range(0,duration//batch_size):\n        idx = i*batch_size + np.random.randint(0,10,(1))[0]\n\n        yield inputX[idx:idx+batch_size], inputY[idx:idx+batch_size]\n\n\n# Routine to train the neural network\ndef train_neural_network_batch(x_ph, predict=False):\n    prediction = neural_network_model(x_ph)\n    pred_dx = tf.gradients(prediction, x_ph)\n    pred_dx2 = tf.gradients(tf.gradients(prediction, x_ph),x_ph)\n\n    # Compute u and its second derivative\n    u = A + B*x_ph + (x_ph*x_ph)*prediction\n    dudx2 = (x_ph*x_ph)*pred_dx2 + 2.0*x_ph*pred_dx + 2.0*x_ph*pred_dx + 2.0*prediction\n\n    # The cost function is just the residual of u''(x) - x*u(x) = 0, i.e. residual = u''(x)-x*u(x)\n    cost = tf.reduce_mean(tf.square(dudx2-x_ph*u - y_ph))\n    optimizer = tf.train.AdamOptimizer(learn_rate).minimize(cost)\n\n\n    # cycles feed forward + backprop\n    hm_epochs = 400\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n\n        # Train in each epoch with the whole data\n        for epoch in range(hm_epochs):\n\n            epoch_loss = 0\n            for step in range(N//batch_size):\n                for inputX, inputY in get_batch(x, y, batch_size):\n                    _, l = sess.run([optimizer,cost], feed_dict={x_ph:inputX, y_ph:inputY})\n                    epoch_loss += l\n            if epoch %10 == 0:\n                print('Epoch', epoch, 'completed out of', hm_epochs, 'loss:', epoch_loss)\n\n\n        # Predict a new input by adding a random number, to check whether the network has actually learned\n        x_valid = x + 0.0*np.random.normal(scale=0.1,size=(1))\n        return sess.run(tf.squeeze(prediction),{x_ph:x_valid}), x_valid\n\n\n# Train network\ntf.set_random_seed(42)\npred, time = train_neural_network_batch(x_ph)\n\n\nmypred = pred.reshape(N,1)\n\n# Compute Airy functions for exact solution\nai, aip, bi, bip = special.airy(time)\n\n# Numerical solution vs. exact solution\nfig = plt.figure()\nplt.plot(time, A + B*time + (time*time)*mypred)\nplt.plot(time, 0.5*(3.0**(1/6))*special.gamma(2/3)*(3**(1/2)*ai + bi))\nplt.show()\n</code></pre>\n",
                "tags": "<neural-network><deep-learning><tensorflow>",
                "answers": [
                    [
                        "47376",
                        "2",
                        "45015",
                        "",
                        "",
                        "<ol>\n<li><p>Please avoid using piecewise linear activations for second or higher-order ODEs, as the second and higher-order derivatives of these functions are zero. Alternatively, Tanh activations might be a good option.</p></li>\n<li><p>I recommend using deeper networks. Based on my experience, depth can significantly improve the results when solving differential equations with neural networks.</p></li>\n</ol>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "15822",
            "_score": 4.7606373,
            "_source": {
                "title": "Massive variation in results with tensorflow and keras",
                "content": "Massive variation in results with tensorflow and keras <p>I'm new to Tensorflow and Keras and I some background knowledge of how CNN's work.\nI'm using a basic sequential model based on the code by <a href=\"https://pythonprogramming.net/convolutional-neural-network-deep-learning-python-tensorflow-keras/\" rel=\"nofollow noreferrer\">https://pythonprogramming.net/convolutional-neural-network-deep-learning-python-tensorflow-keras/</a></p>\n\n<p>I have a problem where my results variation is very big. The first time I ran the model today I got around 90% accuracy. But the runs after that were around 25% which is as good as guessing since I have four classes.</p>\n\n<p><a href=\"https://i.stack.imgur.com/bQm2n.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/bQm2n.png\" alt=\"The results in Tensorboard\"></a></p>\n\n<p>Here's my code:</p>\n\n<pre><code>tf.reset_default_graph()\n\nbatch_size = 32\n\nlogdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n\nX = X/255.0\n\nmodel = Sequential()\n\nmodel.add(Conv2D(64, (3, 3), input_shape=X.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\n\nmodel.add(Dense(4))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n          optimizer='adam',\n          metrics=['accuracy'])\n\n\nwith tf.Session() as sess:\nmodel.fit(train_X, train_y, batch_size=batch_size, epochs=3, \nvalidation_split=0.1, callbacks=[tensorboard_callback], validation_data=(test_X, test_y))\n</code></pre>\n\n<p>Am I doing something completely wrong with the model? I do have quite a small dataset, just 1640 images. But why do some runs perform so good then?</p>\n <keras><tensorflow><cnn><variance><p>I commented previously, now some idea as an answer:</p>\n\n<p><strong>1)</strong> I think that the validation data may include \"lucky shots\" which match the trained patterns well in some cases. Also a small validation set can be a problem. As far as I know, validation data is the last X% of the data (in Keras). You can set <code>shuffle=True</code> to mix validation data or <code>False</code> to not mix it (as I understand). I would try this.\n<a href=\"https://github.com/keras-team/keras/issues/597\" rel=\"nofollow noreferrer\">https://github.com/keras-team/keras/issues/597</a></p>\n\n<p><strong>2)</strong> An option to get a good idea of how the model performs is cross validation. If you can afford it, train 3 or 5 or 10 models with different validation data and have a look at the average accuracy. Should give you also an idea of how volatile the results are.</p>\n\n<p><strong>3)</strong> You have a small sample. Thus, adding more validation data can be a problem. However, I would also try with 20%.</p>\n\n<p><strong>4)</strong> Since you have a small sample, the NN might have trouble getting all the relevant features. Instead of training a convnet from scratch, you can use a pretrained model. This has already learned a lot of features. Given a small sample, this could be THE way to go. Note that there are a number of different pretrained models which you can try.\n<a href=\"https://keras.io/applications/\" rel=\"nofollow noreferrer\">https://keras.io/applications/</a></p>\n\n<p><strong>5)</strong> Get more data (if possible).</p>\n\n<p>I recently used a pretrained model in a multiclass setting. Here is my code, which is a slightly modified version of a tutorial code by F. Chollet (<a href=\"https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.3-using-a-pretrained-convnet.ipynb\" rel=\"nofollow noreferrer\">https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.3-using-a-pretrained-convnet.ipynb</a>).</p>\n\n<pre><code>from keras.applications import VGG16\nimport os, datetime, statistics\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n###############################################\n# DIR with training images\nbase_dir = 'C:/kerasimages'\n# Number training images\nntrain = 2000\n# Number validation images\nnval  = 500\n# Batch size\nbatch_size = 20\n# Epochs fine tuning\nep = 600\n# Epochs first step\nep_first = 50\n# Number of classes (for training, output layer)\nnclasses = 22\n###############################################\n\nconv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'val')\n\ndatagen = ImageDataGenerator(rescale=1./255)\n\ndef extract_features(directory, sample_count):\n    features = np.zeros(shape=(sample_count, 4, 4, 512))\n    labels = np.zeros(shape=(sample_count))\n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='binary')\n    i = 0\n    for inputs_batch, labels_batch in generator:\n        features_batch = conv_base.predict(inputs_batch)\n        features[i * batch_size : (i + 1) * batch_size] = features_batch\n        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n        i += 1\n        if i * batch_size &gt;= sample_count:\n            break\n    return features, labels\n\n# Lables and features\ntrain_features, train_labels = extract_features(train_dir, ntrain)\nvalidation_features, validation_labels = extract_features(validation_dir, nval)\ntrain_labels = to_categorical(train_labels)\nvalidation_labels = to_categorical(validation_labels)\ntrain_features = np.reshape(train_features, (ntrain, 4 * 4 * 512))\nvalidation_features = np.reshape(validation_features, (nval, 4 * 4 * 512))\n\n#######################################\n# Model\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(2048, activation='relu'))#256\nmodel.add(Dropout(0.20))\nmodel.add(layers.Dense(1024, activation='relu'))#256\nmodel.add(Dropout(0.20))\nmodel.add(layers.Dense(512, activation='relu'))#256\nmodel.add(Dropout(0.20))\nmodel.add(layers.Dense(nclasses, activation='softmax'))\nconv_base.trainable = False\n\n#######################################\n# Data generators\ntrain_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='categorical')\n\n# Model compile / fit\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=2e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=ep_first,\n      validation_data=validation_generator,\n      validation_steps=50,\n      verbose=2)\n\n#######################################\n# Fine tuning\nconv_base.trainable = True\n\nset_trainable = False\nfor layer in conv_base.layers:\n    if layer.name == 'block5_conv1':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=ep,\n      validation_data=validation_generator,\n      validation_steps=50)\n</code></pre>\n",
                "codes": [
                    [
                        "from keras.applications import VGG16\nimport os, datetime, statistics\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n###############################################\n# DIR with training images\nbase_dir = 'C:/kerasimages'\n# Number training images\nntrain = 2000\n# Number validation images\nnval  = 500\n# Batch size\nbatch_size = 20\n# Epochs fine tuning\nep = 600\n# Epochs first step\nep_first = 50\n# Number of classes (for training, output layer)\nnclasses = 22\n###############################################\n\nconv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'val')\n\ndatagen = ImageDataGenerator(rescale=1./255)\n\ndef extract_features(directory, sample_count):\n    features = np.zeros(shape=(sample_count, 4, 4, 512))\n    labels = np.zeros(shape=(sample_count))\n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='binary')\n    i = 0\n    for inputs_batch, labels_batch in generator:\n        features_batch = conv_base.predict(inputs_batch)\n        features[i * batch_size : (i + 1) * batch_size] = features_batch\n        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n        i += 1\n        if i * batch_size >= sample_count:\n            break\n    return features, labels\n\n# Lables and features\ntrain_features, train_labels = extract_features(train_dir, ntrain)\nvalidation_features, validation_labels = extract_features(validation_dir, nval)\ntrain_labels = to_categorical(train_labels)\nvalidation_labels = to_categorical(validation_labels)\ntrain_features = np.reshape(train_features, (ntrain, 4 * 4 * 512))\nvalidation_features = np.reshape(validation_features, (nval, 4 * 4 * 512))\n\n#######################################\n# Model\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(2048, activation='relu'))#256\nmodel.add(Dropout(0.20))\nmodel.add(layers.Dense(1024, activation='relu'))#256\nmodel.add(Dropout(0.20))\nmodel.add(layers.Dense(512, activation='relu'))#256\nmodel.add(Dropout(0.20))\nmodel.add(layers.Dense(nclasses, activation='softmax'))\nconv_base.trainable = False\n\n#######################################\n# Data generators\ntrain_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='categorical')\n\n# Model compile / fit\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=2e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=ep_first,\n      validation_data=validation_generator,\n      validation_steps=50,\n      verbose=2)\n\n#######################################\n# Fine tuning\nconv_base.trainable = True\n\nset_trainable = False\nfor layer in conv_base.layers:\n    if layer.name == 'block5_conv1':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=ep,\n      validation_data=validation_generator,\n      validation_steps=50)\n"
                    ]
                ],
                "question_id:": "52761",
                "question_votes:": "",
                "question_text:": "<p>I'm new to Tensorflow and Keras and I some background knowledge of how CNN's work.\nI'm using a basic sequential model based on the code by <a href=\"https://pythonprogramming.net/convolutional-neural-network-deep-learning-python-tensorflow-keras/\" rel=\"nofollow noreferrer\">https://pythonprogramming.net/convolutional-neural-network-deep-learning-python-tensorflow-keras/</a></p>\n\n<p>I have a problem where my results variation is very big. The first time I ran the model today I got around 90% accuracy. But the runs after that were around 25% which is as good as guessing since I have four classes.</p>\n\n<p><a href=\"https://i.stack.imgur.com/bQm2n.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/bQm2n.png\" alt=\"The results in Tensorboard\"></a></p>\n\n<p>Here's my code:</p>\n\n<pre><code>tf.reset_default_graph()\n\nbatch_size = 32\n\nlogdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n\nX = X/255.0\n\nmodel = Sequential()\n\nmodel.add(Conv2D(64, (3, 3), input_shape=X.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\n\nmodel.add(Dense(4))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n          optimizer='adam',\n          metrics=['accuracy'])\n\n\nwith tf.Session() as sess:\nmodel.fit(train_X, train_y, batch_size=batch_size, epochs=3, \nvalidation_split=0.1, callbacks=[tensorboard_callback], validation_data=(test_X, test_y))\n</code></pre>\n\n<p>Am I doing something completely wrong with the model? I do have quite a small dataset, just 1640 images. But why do some runs perform so good then?</p>\n",
                "tags": "<keras><tensorflow><cnn><variance>",
                "answers": [
                    [
                        "52772",
                        "2",
                        "52761",
                        "",
                        "",
                        "<p>I commented previously, now some idea as an answer:</p>\n\n<p><strong>1)</strong> I think that the validation data may include \"lucky shots\" which match the trained patterns well in some cases. Also a small validation set can be a problem. As far as I know, validation data is the last X% of the data (in Keras). You can set <code>shuffle=True</code> to mix validation data or <code>False</code> to not mix it (as I understand). I would try this.\n<a href=\"https://github.com/keras-team/keras/issues/597\" rel=\"nofollow noreferrer\">https://github.com/keras-team/keras/issues/597</a></p>\n\n<p><strong>2)</strong> An option to get a good idea of how the model performs is cross validation. If you can afford it, train 3 or 5 or 10 models with different validation data and have a look at the average accuracy. Should give you also an idea of how volatile the results are.</p>\n\n<p><strong>3)</strong> You have a small sample. Thus, adding more validation data can be a problem. However, I would also try with 20%.</p>\n\n<p><strong>4)</strong> Since you have a small sample, the NN might have trouble getting all the relevant features. Instead of training a convnet from scratch, you can use a pretrained model. This has already learned a lot of features. Given a small sample, this could be THE way to go. Note that there are a number of different pretrained models which you can try.\n<a href=\"https://keras.io/applications/\" rel=\"nofollow noreferrer\">https://keras.io/applications/</a></p>\n\n<p><strong>5)</strong> Get more data (if possible).</p>\n\n<p>I recently used a pretrained model in a multiclass setting. Here is my code, which is a slightly modified version of a tutorial code by F. Chollet (<a href=\"https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.3-using-a-pretrained-convnet.ipynb\" rel=\"nofollow noreferrer\">https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.3-using-a-pretrained-convnet.ipynb</a>).</p>\n\n<pre><code>from keras.applications import VGG16\nimport os, datetime, statistics\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n###############################################\n# DIR with training images\nbase_dir = 'C:/kerasimages'\n# Number training images\nntrain = 2000\n# Number validation images\nnval  = 500\n# Batch size\nbatch_size = 20\n# Epochs fine tuning\nep = 600\n# Epochs first step\nep_first = 50\n# Number of classes (for training, output layer)\nnclasses = 22\n###############################################\n\nconv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'val')\n\ndatagen = ImageDataGenerator(rescale=1./255)\n\ndef extract_features(directory, sample_count):\n    features = np.zeros(shape=(sample_count, 4, 4, 512))\n    labels = np.zeros(shape=(sample_count))\n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='binary')\n    i = 0\n    for inputs_batch, labels_batch in generator:\n        features_batch = conv_base.predict(inputs_batch)\n        features[i * batch_size : (i + 1) * batch_size] = features_batch\n        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n        i += 1\n        if i * batch_size &gt;= sample_count:\n            break\n    return features, labels\n\n# Lables and features\ntrain_features, train_labels = extract_features(train_dir, ntrain)\nvalidation_features, validation_labels = extract_features(validation_dir, nval)\ntrain_labels = to_categorical(train_labels)\nvalidation_labels = to_categorical(validation_labels)\ntrain_features = np.reshape(train_features, (ntrain, 4 * 4 * 512))\nvalidation_features = np.reshape(validation_features, (nval, 4 * 4 * 512))\n\n#######################################\n# Model\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(2048, activation='relu'))#256\nmodel.add(Dropout(0.20))\nmodel.add(layers.Dense(1024, activation='relu'))#256\nmodel.add(Dropout(0.20))\nmodel.add(layers.Dense(512, activation='relu'))#256\nmodel.add(Dropout(0.20))\nmodel.add(layers.Dense(nclasses, activation='softmax'))\nconv_base.trainable = False\n\n#######################################\n# Data generators\ntrain_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='categorical')\n\n# Model compile / fit\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=2e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=ep_first,\n      validation_data=validation_generator,\n      validation_steps=50,\n      verbose=2)\n\n#######################################\n# Fine tuning\nconv_base.trainable = True\n\nset_trainable = False\nfor layer in conv_base.layers:\n    if layer.name == 'block5_conv1':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=ep,\n      validation_data=validation_generator,\n      validation_steps=50)\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5258",
            "_score": 4.752551,
            "_source": {
                "title": "train_test_split() error: Found input variables with inconsistent numbers of samples",
                "content": "train_test_split() error: Found input variables with inconsistent numbers of samples <p>Fairly new to Python but building out my first RF model based on some classification data. I've converted all of the labels into int64 numerical data and loaded into X and Y as a numpy array, but I am hitting an error when I am trying to train the models. </p>\n\n<p>Here is what my arrays look like:</p>\n\n<pre><code>&gt;&gt;&gt; X = np.array([[df.tran_cityname, df.tran_signupos, df.tran_signupchannel, df.tran_vmake, df.tran_vmodel, df.tran_vyear]])\n\n&gt;&gt;&gt; Y = np.array(df['completed_trip_status'].values.tolist())\n\n&gt;&gt;&gt; X\narray([[[   1,    1,    2,    3,    1,    1,    1,    1,    1,    3,    1,\n            3,    1,    1,    1,    1,    2,    1,    3,    1,    3,    3,\n            2,    3,    3,    1,    1,    1,    1],\n        [   0,    5,    5,    1,    1,    1,    2,    2,    0,    2,    2,\n            3,    1,    2,    5,    5,    2,    1,    2,    2,    2,    2,\n            2,    4,    3,    5,    1,    0,    1],\n        [   2,    2,    1,    3,    3,    3,    2,    3,    3,    2,    3,\n            2,    3,    2,    2,    3,    2,    2,    1,    1,    2,    1,\n            2,    2,    1,    2,    3,    1,    1],\n        [   0,    0,    0,   42,   17,    8,   42,    0,    0,    0,   22,\n            0,   22,    0,    0,   42,    0,    0,    0,    0,   11,    0,\n            0,    0,    0,    0,   28,   17,   18],\n        [   0,    0,    0,   70,  291,   88,  234,    0,    0,    0,  222,\n            0,  222,    0,    0,  234,    0,    0,    0,    0,   89,    0,\n            0,    0,    0,    0,   40,  291,  131],\n        [   0,    0,    0, 2016, 2016, 2006, 2014,    0,    0,    0, 2015,\n            0, 2015,    0,    0, 2015,    0,    0,    0,    0, 2015,    0,\n            0,    0,    0,    0, 2016, 2016, 2010]]])\n\n&gt;&gt;&gt; Y\narray(['NO', 'NO', 'NO', 'YES', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'NO',\n       'NO', 'YES', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO',\n       'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO'], \n      dtype='|S3')\n\n&gt;&gt;&gt; X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n</code></pre>\n\n<blockquote>\n  <p>Traceback (most recent call last):</p>\n\n<pre><code>  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/Library/Python/2.7/site-packages/sklearn/cross_validation.py\", line\n</code></pre>\n  \n  <p>2039, in train_test_split\n          arrays = indexable(*arrays)\n        File \"/Library/Python/2.7/site-packages/sklearn/utils/validation.py\", line\n  206, in indexable\n          check_consistent_length(*result)\n        File \"/Library/Python/2.7/site-packages/sklearn/utils/validation.py\", line\n  181, in check_consistent_length\n          \" samples: %r\" % [int(l) for l in lengths])</p>\n\n<pre><code>ValueError: Found input variables with inconsistent numbers of samples: [1, 29]\n</code></pre>\n</blockquote>\n <python><scikit-learn><sampling><p>You are running into that error because your <code>X</code> and <code>Y</code> don't have the same length (which is what <code>train_test_split</code> requires), i.e., <code>X.shape[0] != Y.shape[0]</code>. Given your current code:</p>\n\n<pre><code>&gt;&gt;&gt; X.shape\n(1, 6, 29)\n&gt;&gt;&gt; Y.shape\n(29,)\n</code></pre>\n\n<p>To fix this error:</p>\n\n<ol>\n<li>Remove the extra list from inside of <code>np.array()</code> when defining <code>X</code> or remove the extra dimension afterwards with the following command: <code>X = X.reshape(X.shape[1:])</code>. Now, the shape of <code>X</code> will be (6, 29).</li>\n<li>Transpose <code>X</code> by running <code>X = X.transpose()</code> to get equal number of samples in <code>X</code> and <code>Y</code>. Now, the shape of <code>X</code> will be (29, 6) and the shape of <code>Y</code> will be (29,).</li>\n</ol>\n<p>Isn't train_test_split expecting both <code>X</code> and <code>Y</code> to be a list of same length? Your X has length of 6 and Y has length of 29. May be try converting that to pandas dataframe (with 29x6 dimension) and try again? </p>\n\n<p>Given your data, it looks like you have 6 features. In that case, try to convert your <code>X</code> to have 29 rows and 6 columns. Then pass that dataframe to <code>train_test_split</code>. You can convert your list to dataframe using <code>pd.DataFrame.from_records</code>.</p>\n",
                "codes": [
                    [
                        ">>> X.shape\n(1, 6, 29)\n>>> Y.shape\n(29,)\n"
                    ],
                    []
                ],
                "question_id:": "20199",
                "question_votes:": "19",
                "question_text:": "<p>Fairly new to Python but building out my first RF model based on some classification data. I've converted all of the labels into int64 numerical data and loaded into X and Y as a numpy array, but I am hitting an error when I am trying to train the models. </p>\n\n<p>Here is what my arrays look like:</p>\n\n<pre><code>&gt;&gt;&gt; X = np.array([[df.tran_cityname, df.tran_signupos, df.tran_signupchannel, df.tran_vmake, df.tran_vmodel, df.tran_vyear]])\n\n&gt;&gt;&gt; Y = np.array(df['completed_trip_status'].values.tolist())\n\n&gt;&gt;&gt; X\narray([[[   1,    1,    2,    3,    1,    1,    1,    1,    1,    3,    1,\n            3,    1,    1,    1,    1,    2,    1,    3,    1,    3,    3,\n            2,    3,    3,    1,    1,    1,    1],\n        [   0,    5,    5,    1,    1,    1,    2,    2,    0,    2,    2,\n            3,    1,    2,    5,    5,    2,    1,    2,    2,    2,    2,\n            2,    4,    3,    5,    1,    0,    1],\n        [   2,    2,    1,    3,    3,    3,    2,    3,    3,    2,    3,\n            2,    3,    2,    2,    3,    2,    2,    1,    1,    2,    1,\n            2,    2,    1,    2,    3,    1,    1],\n        [   0,    0,    0,   42,   17,    8,   42,    0,    0,    0,   22,\n            0,   22,    0,    0,   42,    0,    0,    0,    0,   11,    0,\n            0,    0,    0,    0,   28,   17,   18],\n        [   0,    0,    0,   70,  291,   88,  234,    0,    0,    0,  222,\n            0,  222,    0,    0,  234,    0,    0,    0,    0,   89,    0,\n            0,    0,    0,    0,   40,  291,  131],\n        [   0,    0,    0, 2016, 2016, 2006, 2014,    0,    0,    0, 2015,\n            0, 2015,    0,    0, 2015,    0,    0,    0,    0, 2015,    0,\n            0,    0,    0,    0, 2016, 2016, 2010]]])\n\n&gt;&gt;&gt; Y\narray(['NO', 'NO', 'NO', 'YES', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'NO',\n       'NO', 'YES', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO',\n       'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO'], \n      dtype='|S3')\n\n&gt;&gt;&gt; X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n</code></pre>\n\n<blockquote>\n  <p>Traceback (most recent call last):</p>\n\n<pre><code>  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/Library/Python/2.7/site-packages/sklearn/cross_validation.py\", line\n</code></pre>\n  \n  <p>2039, in train_test_split\n          arrays = indexable(*arrays)\n        File \"/Library/Python/2.7/site-packages/sklearn/utils/validation.py\", line\n  206, in indexable\n          check_consistent_length(*result)\n        File \"/Library/Python/2.7/site-packages/sklearn/utils/validation.py\", line\n  181, in check_consistent_length\n          \" samples: %r\" % [int(l) for l in lengths])</p>\n\n<pre><code>ValueError: Found input variables with inconsistent numbers of samples: [1, 29]\n</code></pre>\n</blockquote>\n",
                "tags": "<python><scikit-learn><sampling>",
                "answers": [
                    [
                        "20203",
                        "2",
                        "20199",
                        "",
                        "",
                        "<p>You are running into that error because your <code>X</code> and <code>Y</code> don't have the same length (which is what <code>train_test_split</code> requires), i.e., <code>X.shape[0] != Y.shape[0]</code>. Given your current code:</p>\n\n<pre><code>&gt;&gt;&gt; X.shape\n(1, 6, 29)\n&gt;&gt;&gt; Y.shape\n(29,)\n</code></pre>\n\n<p>To fix this error:</p>\n\n<ol>\n<li>Remove the extra list from inside of <code>np.array()</code> when defining <code>X</code> or remove the extra dimension afterwards with the following command: <code>X = X.reshape(X.shape[1:])</code>. Now, the shape of <code>X</code> will be (6, 29).</li>\n<li>Transpose <code>X</code> by running <code>X = X.transpose()</code> to get equal number of samples in <code>X</code> and <code>Y</code>. Now, the shape of <code>X</code> will be (29, 6) and the shape of <code>Y</code> will be (29,).</li>\n</ol>\n",
                        "",
                        "14"
                    ],
                    [
                        "20202",
                        "2",
                        "20199",
                        "",
                        "",
                        "<p>Isn't train_test_split expecting both <code>X</code> and <code>Y</code> to be a list of same length? Your X has length of 6 and Y has length of 29. May be try converting that to pandas dataframe (with 29x6 dimension) and try again? </p>\n\n<p>Given your data, it looks like you have 6 features. In that case, try to convert your <code>X</code> to have 29 rows and 6 columns. Then pass that dataframe to <code>train_test_split</code>. You can convert your list to dataframe using <code>pd.DataFrame.from_records</code>.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7666",
            "_score": 4.752551,
            "_source": {
                "title": "Train new data to pre-trained model",
                "content": "Train new data to pre-trained model <p>Let's say I've trained my model and made my predictions. </p>\n\n<p>My question is... How can I append some new data to my pre-trained model without retrain the model from the beginning.</p>\n <machine-learning><python><deep-learning><p>I would say it depends upon the ML framework you are using. I have worked on Scikit and Tensorflow.</p>\n\n<p>Both works in a different way.</p>\n\n<p><strong>Scikit:</strong> </p>\n\n<ol>\n<li>partial_fit() is one way. If we call partial_fit() multiple times,\nframework will update the existing weights instead of\nre-initializing it again.</li>\n<li>warm_state is another way which is provided by many algo. For\nexample RandomForestRegressor(), it will add new estimators(new\ntress) which gets trained with new data we pass to it. Refer <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\" rel=\"nofollow noreferrer\">Scikit\nlink for more explanation</a></li>\n</ol>\n\n<p><strong>Tensorflow</strong>: Consider a basic TF code as mentioned below:</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.preprocessing import StandardScaler\nhousing = fetch_california_housing()\nm, n = housing.data.shape\ntarget = housing.target.reshape(-1,1)\nscaler = StandardScaler()\nscaled_housing_data = scaler.fit_transform(housing.data)\nhousing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\nn_epochs = 1000\nlearning_rate = 0.01\nX = tf.placeholder(shape = (None, n+1), dtype=tf.float32, name=\"X\")\ny = tf.placeholder(shape=(None,1), dtype=tf.float32, name=\"y\")\ntheta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\ny_pred = tf.matmul(X, theta, name=\"predictions\")\nerror = y_pred - y\nmse = tf.reduce_mean(tf.square(error), name=\"mse\")\ngradients = 2/m * tf.matmul(tf.transpose(X), error)\ntraining_op = tf.assign(theta, theta - learning_rate * gradients)\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    for epoch in range(n_epochs):\n        fn,wights, loss, pred, op = sess.run((error, theta, mse, y_pred,training_op), feed_dict={X:housing_data_plus_bias, y:target})\n        print(loss)\n    best_theta = theta.eval()\n    print(best_theta)\n</code></pre>\n\n<p>Consider I have trained and deployed this model(as a tf.saver() object). Now if I want to predict new values I have to feed my model with new <strong>X values</strong> and identify <strong>\"y_pred\".</strong>.\nThis process will not update my <strong>theta</strong>(weights) values(tensor graph, evaluate its dependent tensors only) and for prediction model will use existing <strong>theta</strong>.\nIn case I want to update <strong>theta</strong>, using the new samples, I have to evaluate <strong>training_op</strong>. </p>\n\n<p>In this way we can improve TF model later with the new data. </p>\n\n<p>Note: <strong>training_op</strong>, has a dependency on <strong>theta</strong> and <strong>gradient</strong>.</p>\n<p>I cannot comment yet. If you just load the model and use a fit method it will update the weights, not reinstance all the weights. It will just perform a number of weights update that you can chose, using the new data.</p>\n<p>It all depends on the specific algorithm you're using. Some of them support incremental learning, while others don't.</p>\n\n<p>For example, in the case of sci-kit learn, using <code>fit()</code> more than once on the same model will simply overwrite the model's weights each time (see <a href=\"http://scikit-learn.org/stable/tutorial/basic/tutorial.html#refitting-and-updating-parameters\" rel=\"nofollow noreferrer\">here</a> for more details). </p>\n\n<p>What you can do however, is look for algorithms that implement the <code>partial_fit</code> api, and use this to retrain your existing models - see <a href=\"http://scikit-learn.org/stable/modules/scaling_strategies.html#incremental-learning\" rel=\"nofollow noreferrer\">the documentation</a> for a list of algorithms that support incremental learning and thus implement this api.</p>\n\n<p>An alternative solution is to look for algorithms that support the <code>warm_start</code> parameter, e.g. <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">LogisticRegression</a>. Note that <code>warm_start</code> might also be influenced by other parameters, so you need to pay attention to their values, too - e.g. in the case of LogisticRegression, <code>warm_start</code> won't work if you use the <code>liblinear</code> solver (which is the default).</p>\n",
                "codes": [
                    [
                        "import numpy as np\nimport tensorflow as tf\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.preprocessing import StandardScaler\nhousing = fetch_california_housing()\nm, n = housing.data.shape\ntarget = housing.target.reshape(-1,1)\nscaler = StandardScaler()\nscaled_housing_data = scaler.fit_transform(housing.data)\nhousing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\nn_epochs = 1000\nlearning_rate = 0.01\nX = tf.placeholder(shape = (None, n+1), dtype=tf.float32, name=\"X\")\ny = tf.placeholder(shape=(None,1), dtype=tf.float32, name=\"y\")\ntheta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\ny_pred = tf.matmul(X, theta, name=\"predictions\")\nerror = y_pred - y\nmse = tf.reduce_mean(tf.square(error), name=\"mse\")\ngradients = 2/m * tf.matmul(tf.transpose(X), error)\ntraining_op = tf.assign(theta, theta - learning_rate * gradients)\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    for epoch in range(n_epochs):\n        fn,wights, loss, pred, op = sess.run((error, theta, mse, y_pred,training_op), feed_dict={X:housing_data_plus_bias, y:target})\n        print(loss)\n    best_theta = theta.eval()\n    print(best_theta)\n"
                    ],
                    [],
                    []
                ],
                "question_id:": "28512",
                "question_votes:": "3",
                "question_text:": "<p>Let's say I've trained my model and made my predictions. </p>\n\n<p>My question is... How can I append some new data to my pre-trained model without retrain the model from the beginning.</p>\n",
                "tags": "<machine-learning><python><deep-learning>",
                "answers": [
                    [
                        "53431",
                        "2",
                        "28512",
                        "",
                        "",
                        "<p>I would say it depends upon the ML framework you are using. I have worked on Scikit and Tensorflow.</p>\n\n<p>Both works in a different way.</p>\n\n<p><strong>Scikit:</strong> </p>\n\n<ol>\n<li>partial_fit() is one way. If we call partial_fit() multiple times,\nframework will update the existing weights instead of\nre-initializing it again.</li>\n<li>warm_state is another way which is provided by many algo. For\nexample RandomForestRegressor(), it will add new estimators(new\ntress) which gets trained with new data we pass to it. Refer <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\" rel=\"nofollow noreferrer\">Scikit\nlink for more explanation</a></li>\n</ol>\n\n<p><strong>Tensorflow</strong>: Consider a basic TF code as mentioned below:</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.preprocessing import StandardScaler\nhousing = fetch_california_housing()\nm, n = housing.data.shape\ntarget = housing.target.reshape(-1,1)\nscaler = StandardScaler()\nscaled_housing_data = scaler.fit_transform(housing.data)\nhousing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\nn_epochs = 1000\nlearning_rate = 0.01\nX = tf.placeholder(shape = (None, n+1), dtype=tf.float32, name=\"X\")\ny = tf.placeholder(shape=(None,1), dtype=tf.float32, name=\"y\")\ntheta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\ny_pred = tf.matmul(X, theta, name=\"predictions\")\nerror = y_pred - y\nmse = tf.reduce_mean(tf.square(error), name=\"mse\")\ngradients = 2/m * tf.matmul(tf.transpose(X), error)\ntraining_op = tf.assign(theta, theta - learning_rate * gradients)\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    for epoch in range(n_epochs):\n        fn,wights, loss, pred, op = sess.run((error, theta, mse, y_pred,training_op), feed_dict={X:housing_data_plus_bias, y:target})\n        print(loss)\n    best_theta = theta.eval()\n    print(best_theta)\n</code></pre>\n\n<p>Consider I have trained and deployed this model(as a tf.saver() object). Now if I want to predict new values I have to feed my model with new <strong>X values</strong> and identify <strong>\"y_pred\".</strong>.\nThis process will not update my <strong>theta</strong>(weights) values(tensor graph, evaluate its dependent tensors only) and for prediction model will use existing <strong>theta</strong>.\nIn case I want to update <strong>theta</strong>, using the new samples, I have to evaluate <strong>training_op</strong>. </p>\n\n<p>In this way we can improve TF model later with the new data. </p>\n\n<p>Note: <strong>training_op</strong>, has a dependency on <strong>theta</strong> and <strong>gradient</strong>.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "28517",
                        "2",
                        "28512",
                        "",
                        "",
                        "<p>I cannot comment yet. If you just load the model and use a fit method it will update the weights, not reinstance all the weights. It will just perform a number of weights update that you can chose, using the new data.</p>\n",
                        "",
                        "3"
                    ],
                    [
                        "38709",
                        "2",
                        "28512",
                        "",
                        "",
                        "<p>It all depends on the specific algorithm you're using. Some of them support incremental learning, while others don't.</p>\n\n<p>For example, in the case of sci-kit learn, using <code>fit()</code> more than once on the same model will simply overwrite the model's weights each time (see <a href=\"http://scikit-learn.org/stable/tutorial/basic/tutorial.html#refitting-and-updating-parameters\" rel=\"nofollow noreferrer\">here</a> for more details). </p>\n\n<p>What you can do however, is look for algorithms that implement the <code>partial_fit</code> api, and use this to retrain your existing models - see <a href=\"http://scikit-learn.org/stable/modules/scaling_strategies.html#incremental-learning\" rel=\"nofollow noreferrer\">the documentation</a> for a list of algorithms that support incremental learning and thus implement this api.</p>\n\n<p>An alternative solution is to look for algorithms that support the <code>warm_start</code> parameter, e.g. <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" rel=\"nofollow noreferrer\">LogisticRegression</a>. Note that <code>warm_start</code> might also be influenced by other parameters, so you need to pay attention to their values, too - e.g. in the case of LogisticRegression, <code>warm_start</code> won't work if you use the <code>liblinear</code> solver (which is the default).</p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "2151",
            "_score": 4.740744,
            "_source": {
                "title": "Balanced Linear SVM wins every class except One vs All",
                "content": "Balanced Linear SVM wins every class except One vs All <p>I am training a <em>normal</em> and a <em>balanced</em> <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\" rel=\"nofollow\">Linear SVM</a> using imbalance data, and testing both using F1-score.</p>\n\n<p><em>(By balanced Linear SVM, I mean that each observation has a weight inverse to its frequency, so that it \"oversamples\" from the minority class and \"undersamples\" from the majority class.)</em></p>\n\n<p>Not surprisingly, using a multi-class dataset and solving it individually as one-vs-rest binary problems, balanced Linear SVM beats unbalanced Linear SVM on every class:</p>\n\n<pre><code>                   normal vs balanced\ntarget 01 - scores: 0.272 vs 0.608\ntarget 02 - scores: 0.391 vs 0.587\ntarget 03 - scores: 0.433 vs 0.546\ntarget 04 - scores: 0.659 vs 0.655\ntarget 05 - scores: 0.000 vs 0.257\ntarget 06 - scores: 0.431 vs 0.475\ntarget 07 - scores: 0.000 vs 0.249\ntarget 08 - scores: 0.000 vs 0.053\ntarget 09 - scores: 0.576 vs 0.155\ntarget 10 - scores: 0.000 vs 0.550\nOneVsRest - scores: 0.565 vs 0.540\n</code></pre>\n\n<p>But when it comes to using a OneVsRest classifier (last row), the unbalanced Linear SVM beats the Linear SVM, using the average of the F1 scores. This happens to me in a lot of datasets.</p>\n\n<p>Here is the code I have used:</p>\n\n<pre><code># -*- coding: utf-8 -*-\n\nfrom sklearn.svm import LinearSVC\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.cross_validation import StratifiedShuffleSplit\nfrom sklearn.metrics import f1_score\nimport numpy as np\n\nd = np.loadtxt('yeast.csv', delimiter=',')\nX = d[:, 0:-1]\ny = d[:, -1]\n\nprint '                     none vs balanced'\nfor target in np.unique(y):\n    scores = [0] * 2\n    k = 6\n    for tr, ts in StratifiedShuffleSplit(y, k, 0.2):\n        for i, w in enumerate([None, 'balanced']):\n            _y = (y == target).astype(int)\n            yp = LinearSVC(class_weight=w).fit(X[tr], _y[tr]).predict(X[ts])\n            scores[i] += f1_score(_y[ts], yp) / k\n    print 'target %02d - scores: %.3f vs %.3f' % (target, scores[0], scores[1])\n\nscores = [0] * 2\nfor tr, ts in StratifiedShuffleSplit(y, k, 0.2):\n    for i, w in enumerate([None, 'balanced']):\n        m = OneVsRestClassifier(LinearSVC(class_weight=w))\n        yp = m.fit(X[tr], y[tr]).predict(X[ts])\n        scores[i] += f1_score(y[ts], yp, pos_label=None, average='weighted') / k\nprint 'OneVsRest - scores: %.3f vs %.3f' % (scores[0], scores[1])\n</code></pre>\n\n<p>As the dataset, I have used here <a href=\"https://archive.ics.uci.edu/ml/datasets/Yeast\" rel=\"nofollow\">Yeast</a> (UCI), for which a sklearn-ready version can be found <a href=\"https://www.dropbox.com/s/fgb0lgf665ney7z/yeast.csv?dl=1\" rel=\"nofollow\">here</a>.</p>\n\n<p>Results:</p>\n\n<pre><code>                     none vs balanced\ntarget 01 - scores: 0.241 vs 0.612\ntarget 02 - scores: 0.402 vs 0.604\ntarget 03 - scores: 0.444 vs 0.552\ntarget 04 - scores: 0.666 vs 0.650\ntarget 05 - scores: 0.000 vs 0.286\ntarget 06 - scores: 0.370 vs 0.500\ntarget 07 - scores: 0.000 vs 0.280\ntarget 08 - scores: 0.000 vs 0.082\ntarget 09 - scores: 0.563 vs 0.147\ntarget 10 - scores: 0.000 vs 0.511\nOneVsRest - scores: 0.567 vs 0.543\n</code></pre>\n\n<p>Isn't this surprisingly? I know that OneVsRest has a lot of ties, and so scores will be used, as determined by the distance to the separation hyperplane. Still, why does balanced Linear SVM loses the war when it keeps wining every battle?</p>\n\n<p><strong>EDIT:</strong> I think the fact that one model wins pretty much every \"battle\", but not the \"war\" is related to the fact that One Vs Rest uses confidence scores, and not the actual classification, which makes sense since it avoids ties, and when score[k1] > score[k2] we can assume it prefers k1 > k2. See <a href=\"https://en.wikipedia.org/wiki/Multiclass_classification#One-vs.-rest\" rel=\"nofollow\">wikipedia</a>.</p>\n <classification><scikit-learn><multiclass-classification><unbalanced-classes><p>I think the following synthetic example explains what is going on:</p>\n\n<pre><code>from sklearn.base import clone\nfrom sklearn.svm import SVC\nimport numpy as np\nfrom sklearn.datasets import make_blobs\n\nX, y = make_blobs(1000, centers=[[1, 1], [-1, -1], [1, -1]], cluster_std=0.8)\n\nmodels = [\n    ('normal', SVC()),\n    ('balanced', SVC(class_weight='balanced')),\n]\n\nimport matplotlib.pyplot as plot\nplot.ioff()\n\nfor i, (name, m) in enumerate(models):\n    for k in np.unique(y):\n        m = clone(m).fit(X, (y == k).astype(int))\n\n        xx, yy = np.meshgrid(np.arange(-3, 3, 0.1), np.arange(-3, 3, 0.1))\n        z = m.predict(np.c_[xx.ravel(), yy.ravel()])\n        z = z.reshape(xx.shape)\n        colors = ['blue', 'green', 'red']\n        plot.contour(xx, yy, z, colors=colors[k])\n    plot.scatter(X[:, 0], X[:, 1], c=y)\n    plot.title(name)\n    plot.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/REd4p.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/REd4p.png\" alt=\"normal SVM\"></a> <a href=\"https://i.stack.imgur.com/euDKR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/euDKR.png\" alt=\"balanced SVM\"></a></p>\n\n<p>The balanced SVM is clearly superior when considering each model individually, at least as measured by the F1 score, which punishes false positives and false negatives equally.</p>\n\n<p>But One-vs-Rest uses maximum score, which in this case is given by the distance to the decision hyperplane. It is not yet clear why this is worse in some cases, but clearly it is possible for one model to beat another for individual classes, but to lose for One-vs-Rest: how well the relative distances are modeled is what counts in One-vs-Rest.</p>\n",
                "codes": [
                    [
                        "from sklearn.base import clone\nfrom sklearn.svm import SVC\nimport numpy as np\nfrom sklearn.datasets import make_blobs\n\nX, y = make_blobs(1000, centers=[[1, 1], [-1, -1], [1, -1]], cluster_std=0.8)\n\nmodels = [\n    ('normal', SVC()),\n    ('balanced', SVC(class_weight='balanced')),\n]\n\nimport matplotlib.pyplot as plot\nplot.ioff()\n\nfor i, (name, m) in enumerate(models):\n    for k in np.unique(y):\n        m = clone(m).fit(X, (y == k).astype(int))\n\n        xx, yy = np.meshgrid(np.arange(-3, 3, 0.1), np.arange(-3, 3, 0.1))\n        z = m.predict(np.c_[xx.ravel(), yy.ravel()])\n        z = z.reshape(xx.shape)\n        colors = ['blue', 'green', 'red']\n        plot.contour(xx, yy, z, colors=colors[k])\n    plot.scatter(X[:, 0], X[:, 1], c=y)\n    plot.title(name)\n    plot.show()\n"
                    ]
                ],
                "question_id:": "10706",
                "question_votes:": "3",
                "question_text:": "<p>I am training a <em>normal</em> and a <em>balanced</em> <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\" rel=\"nofollow\">Linear SVM</a> using imbalance data, and testing both using F1-score.</p>\n\n<p><em>(By balanced Linear SVM, I mean that each observation has a weight inverse to its frequency, so that it \"oversamples\" from the minority class and \"undersamples\" from the majority class.)</em></p>\n\n<p>Not surprisingly, using a multi-class dataset and solving it individually as one-vs-rest binary problems, balanced Linear SVM beats unbalanced Linear SVM on every class:</p>\n\n<pre><code>                   normal vs balanced\ntarget 01 - scores: 0.272 vs 0.608\ntarget 02 - scores: 0.391 vs 0.587\ntarget 03 - scores: 0.433 vs 0.546\ntarget 04 - scores: 0.659 vs 0.655\ntarget 05 - scores: 0.000 vs 0.257\ntarget 06 - scores: 0.431 vs 0.475\ntarget 07 - scores: 0.000 vs 0.249\ntarget 08 - scores: 0.000 vs 0.053\ntarget 09 - scores: 0.576 vs 0.155\ntarget 10 - scores: 0.000 vs 0.550\nOneVsRest - scores: 0.565 vs 0.540\n</code></pre>\n\n<p>But when it comes to using a OneVsRest classifier (last row), the unbalanced Linear SVM beats the Linear SVM, using the average of the F1 scores. This happens to me in a lot of datasets.</p>\n\n<p>Here is the code I have used:</p>\n\n<pre><code># -*- coding: utf-8 -*-\n\nfrom sklearn.svm import LinearSVC\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.cross_validation import StratifiedShuffleSplit\nfrom sklearn.metrics import f1_score\nimport numpy as np\n\nd = np.loadtxt('yeast.csv', delimiter=',')\nX = d[:, 0:-1]\ny = d[:, -1]\n\nprint '                     none vs balanced'\nfor target in np.unique(y):\n    scores = [0] * 2\n    k = 6\n    for tr, ts in StratifiedShuffleSplit(y, k, 0.2):\n        for i, w in enumerate([None, 'balanced']):\n            _y = (y == target).astype(int)\n            yp = LinearSVC(class_weight=w).fit(X[tr], _y[tr]).predict(X[ts])\n            scores[i] += f1_score(_y[ts], yp) / k\n    print 'target %02d - scores: %.3f vs %.3f' % (target, scores[0], scores[1])\n\nscores = [0] * 2\nfor tr, ts in StratifiedShuffleSplit(y, k, 0.2):\n    for i, w in enumerate([None, 'balanced']):\n        m = OneVsRestClassifier(LinearSVC(class_weight=w))\n        yp = m.fit(X[tr], y[tr]).predict(X[ts])\n        scores[i] += f1_score(y[ts], yp, pos_label=None, average='weighted') / k\nprint 'OneVsRest - scores: %.3f vs %.3f' % (scores[0], scores[1])\n</code></pre>\n\n<p>As the dataset, I have used here <a href=\"https://archive.ics.uci.edu/ml/datasets/Yeast\" rel=\"nofollow\">Yeast</a> (UCI), for which a sklearn-ready version can be found <a href=\"https://www.dropbox.com/s/fgb0lgf665ney7z/yeast.csv?dl=1\" rel=\"nofollow\">here</a>.</p>\n\n<p>Results:</p>\n\n<pre><code>                     none vs balanced\ntarget 01 - scores: 0.241 vs 0.612\ntarget 02 - scores: 0.402 vs 0.604\ntarget 03 - scores: 0.444 vs 0.552\ntarget 04 - scores: 0.666 vs 0.650\ntarget 05 - scores: 0.000 vs 0.286\ntarget 06 - scores: 0.370 vs 0.500\ntarget 07 - scores: 0.000 vs 0.280\ntarget 08 - scores: 0.000 vs 0.082\ntarget 09 - scores: 0.563 vs 0.147\ntarget 10 - scores: 0.000 vs 0.511\nOneVsRest - scores: 0.567 vs 0.543\n</code></pre>\n\n<p>Isn't this surprisingly? I know that OneVsRest has a lot of ties, and so scores will be used, as determined by the distance to the separation hyperplane. Still, why does balanced Linear SVM loses the war when it keeps wining every battle?</p>\n\n<p><strong>EDIT:</strong> I think the fact that one model wins pretty much every \"battle\", but not the \"war\" is related to the fact that One Vs Rest uses confidence scores, and not the actual classification, which makes sense since it avoids ties, and when score[k1] > score[k2] we can assume it prefers k1 > k2. See <a href=\"https://en.wikipedia.org/wiki/Multiclass_classification#One-vs.-rest\" rel=\"nofollow\">wikipedia</a>.</p>\n",
                "tags": "<classification><scikit-learn><multiclass-classification><unbalanced-classes>",
                "answers": [
                    [
                        "10845",
                        "2",
                        "10706",
                        "",
                        "",
                        "<p>I think the following synthetic example explains what is going on:</p>\n\n<pre><code>from sklearn.base import clone\nfrom sklearn.svm import SVC\nimport numpy as np\nfrom sklearn.datasets import make_blobs\n\nX, y = make_blobs(1000, centers=[[1, 1], [-1, -1], [1, -1]], cluster_std=0.8)\n\nmodels = [\n    ('normal', SVC()),\n    ('balanced', SVC(class_weight='balanced')),\n]\n\nimport matplotlib.pyplot as plot\nplot.ioff()\n\nfor i, (name, m) in enumerate(models):\n    for k in np.unique(y):\n        m = clone(m).fit(X, (y == k).astype(int))\n\n        xx, yy = np.meshgrid(np.arange(-3, 3, 0.1), np.arange(-3, 3, 0.1))\n        z = m.predict(np.c_[xx.ravel(), yy.ravel()])\n        z = z.reshape(xx.shape)\n        colors = ['blue', 'green', 'red']\n        plot.contour(xx, yy, z, colors=colors[k])\n    plot.scatter(X[:, 0], X[:, 1], c=y)\n    plot.title(name)\n    plot.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/REd4p.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/REd4p.png\" alt=\"normal SVM\"></a> <a href=\"https://i.stack.imgur.com/euDKR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/euDKR.png\" alt=\"balanced SVM\"></a></p>\n\n<p>The balanced SVM is clearly superior when considering each model individually, at least as measured by the F1 score, which punishes false positives and false negatives equally.</p>\n\n<p>But One-vs-Rest uses maximum score, which in this case is given by the distance to the decision hyperplane. It is not yet clear why this is worse in some cases, but clearly it is possible for one model to beat another for individual classes, but to lose for One-vs-Rest: how well the relative distances are modeled is what counts in One-vs-Rest.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7012",
            "_score": 4.740744,
            "_source": {
                "title": "How to check for overfitting with SVM and Iris Data?",
                "content": "How to check for overfitting with SVM and Iris Data? <p>I am using machine learning predictions for the sample iris dataset. For instance, I am using the support vector machines (SVMs) from <a href=\"http://scikit-learn.org/stable/modules/svm.html\" rel=\"nofollow noreferrer\">scikit-learn</a> in order to predict the accuracy. However, it returns an accuracy of 1.0. Here is the code I am using:</p>\n\n<pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=51)\nsvm_model = svm.SVC(kernel='linear', C=1, gamma='auto')\nsvm_model.fit(X_train,y_train)\npredictions = svm_model.predict(X_test)\naccuracy_score(predictions, y_test)\n</code></pre>\n\n<p>How to find out or to measure if this over-fitting or if the model is so good? I assume that its not over-fitting but what are the best ways to validate this?</p>\n <machine-learning><scikit-learn><overfitting><p>It might be a problem of over-fitting, or that by just doing a single train / test split isn't giving a reliable estimate of the generalizable error of your SVM.</p>\n\n<p>I'd recommend using <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\" rel=\"nofollow noreferrer\" title=\"KFold\">KFold</a> validation to check.</p>\n\n<pre><code>from sklearn.model_selection import KFold\nimport numpy as np\nacc_score = []\n\nkf = KFold(n_splits=5)\n\nfor train_index, test_index in kf.split(X):\n\nX_train, X_test = X[train_index], X[test_index]\ny_train, y_test = y[train_index], y[test_index]\n\nsvm_model.fit(X_train,y_train)\npredictions = svm_model.predict(X_test)\nacc_score.append(accuracy_score(predictions, y_test))\n\nnp.mean(acc_score)\n</code></pre>\n\n<p>Sorry, can't get the code formatting right. The lines from X_train to acc_score.append should be indented.</p>\n\n<p>If the average is still 1.0 then you've done good, but my gut feeling is that your high score is dependent on the cut of the data you're looking at.</p>\n<p>Based on <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\" rel=\"nofollow noreferrer\">here</a>, use <code>sklearn.model_selection.train_test_split(*arrays, **options)</code> in order to split your data into train and test. Train your model on train-split and use the <code>predict</code> method to see the performance on the test data. As an example take a look at the following code which splits the data to two separate groups.</p>\n\n<pre><code>import numpy as np\nfrom sklearn.model_selection import train_test_split\nX, y = np.arange(10).reshape((5, 2)), range(5)\nX\n\narray([[0, 1],\n       [2, 3],\n       [4, 5],\n       [6, 7],\n       [8, 9]])\n\nlist(y)\n[0, 1, 2, 3, 4]\n\n\nX_train, X_test, y_train, y_test = train_test_split(\n...     X, y, test_size=0.33, random_state=42)\n...\nX_train\narray([[4, 5],\n   [0, 1],\n   [6, 7]])\ny_train\n[2, 0, 3]\nX_test\narray([[2, 3],\n   [8, 9]])\ny_test\n[1, 4]\n\ntrain_test_split(y, shuffle=False)\n[[0, 1, 2], [3, 4]]\n</code></pre>\n<p>You check for hints of <strong>overfitting</strong> by using a <strong>training set</strong> and a <strong>test set</strong> (or a training, validation and test set). As others have mentioned, you can either <strong>split</strong> the data into training and test sets, or use <strong>cross-fold validation</strong> to get a more accurate assessment of your classifier's performance. </p>\n\n<p>Since your dataset is small, splitting your data into training and test sets isn't recommended. Use cross validation. </p>\n\n<p>This can be done using either the <strong>cross_validate</strong> or <strong>cross_val_score</strong> function; the latter providing <em>multiple</em> metrics for evaluation. In addition to <strong>test scores</strong> the latter also provides <strong>fit times</strong> and <strong>score times</strong>. </p>\n\n<p>Using your example; </p>\n\n<pre><code>from sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_iris\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score\n\niris = load_iris()\nX = iris.data[:, :5]  # we only take the first two features.\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=51)\nsvm_model = svm.SVC(kernel='linear', C=1, gamma='auto')\nsvm_model.fit(X_train,y_train)\npredictions = svm_model.predict(X_test)\naccuracy_score(predictions, y_test)\n</code></pre>\n\n<p>raw accuracy: 0.96666666666666667</p>\n\n<p>Using the <strong>cross_val_score</strong> function, and printing the <strong>mean score</strong> and <strong>95% confidence interval</strong> of the score estimate: </p>\n\n<pre><code>from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(svm_model, iris.data, iris.target, cv=5)\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n</code></pre>\n\n<p>Accuracy: 0.98 (+/- 0.03)</p>\n\n<p>Of course the iris dataset is a <em>toy example</em>. On larger real-world datasets you are likely to see your test error be higher than your training error, with cross-validation providing a lower accuracy than the raw number. </p>\n\n<p>So I wouldn't use the iris dataset to showcase overfitting. Choose a larger, messier dataset, and then you can start working towards reducing the <em>bias</em> and <em>variance</em> of the model (the \"causes\" of overfitting). </p>\n\n<p>Then you can start <em>exploring</em> tell-tale <strong>signs</strong> of whether it's a bias problem or a variance problem. See here:</p>\n\n<p><a href=\"https://www.quora.com/How-many-training-samples-are-needed-to-get-a-reliable-model-in-ML/answer/Sean-McClure-3?srid=zGgv\" rel=\"nofollow noreferrer\">https://www.quora.com/How-many-training-samples-are-needed-to-get-a-reliable-model-in-ML/answer/Sean-McClure-3?srid=zGgv</a></p>\n\n<p><a href=\"https://i.stack.imgur.com/eXCNE.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/eXCNE.jpg\" alt=\"enter image description here\"></a></p>\n",
                "codes": [
                    [
                        "from sklearn.model_selection import KFold\nimport numpy as np\nacc_score = []\n\nkf = KFold(n_splits=5)\n\nfor train_index, test_index in kf.split(X):\n\nX_train, X_test = X[train_index], X[test_index]\ny_train, y_test = y[train_index], y[test_index]\n\nsvm_model.fit(X_train,y_train)\npredictions = svm_model.predict(X_test)\nacc_score.append(accuracy_score(predictions, y_test))\n\nnp.mean(acc_score)\n"
                    ],
                    [
                        "import numpy as np\nfrom sklearn.model_selection import train_test_split\nX, y = np.arange(10).reshape((5, 2)), range(5)\nX\n\narray([[0, 1],\n       [2, 3],\n       [4, 5],\n       [6, 7],\n       [8, 9]])\n\nlist(y)\n[0, 1, 2, 3, 4]\n\n\nX_train, X_test, y_train, y_test = train_test_split(\n...     X, y, test_size=0.33, random_state=42)\n...\nX_train\narray([[4, 5],\n   [0, 1],\n   [6, 7]])\ny_train\n[2, 0, 3]\nX_test\narray([[2, 3],\n   [8, 9]])\ny_test\n[1, 4]\n\ntrain_test_split(y, shuffle=False)\n[[0, 1, 2], [3, 4]]\n"
                    ],
                    [
                        "from sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_iris\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score\n\niris = load_iris()\nX = iris.data[:, :5]  # we only take the first two features.\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=51)\nsvm_model = svm.SVC(kernel='linear', C=1, gamma='auto')\nsvm_model.fit(X_train,y_train)\npredictions = svm_model.predict(X_test)\naccuracy_score(predictions, y_test)\n",
                        "from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(svm_model, iris.data, iris.target, cv=5)\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
                    ]
                ],
                "question_id:": "26640",
                "question_votes:": "3",
                "question_text:": "<p>I am using machine learning predictions for the sample iris dataset. For instance, I am using the support vector machines (SVMs) from <a href=\"http://scikit-learn.org/stable/modules/svm.html\" rel=\"nofollow noreferrer\">scikit-learn</a> in order to predict the accuracy. However, it returns an accuracy of 1.0. Here is the code I am using:</p>\n\n<pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=51)\nsvm_model = svm.SVC(kernel='linear', C=1, gamma='auto')\nsvm_model.fit(X_train,y_train)\npredictions = svm_model.predict(X_test)\naccuracy_score(predictions, y_test)\n</code></pre>\n\n<p>How to find out or to measure if this over-fitting or if the model is so good? I assume that its not over-fitting but what are the best ways to validate this?</p>\n",
                "tags": "<machine-learning><scikit-learn><overfitting>",
                "answers": [
                    [
                        "26659",
                        "2",
                        "26640",
                        "",
                        "",
                        "<p>It might be a problem of over-fitting, or that by just doing a single train / test split isn't giving a reliable estimate of the generalizable error of your SVM.</p>\n\n<p>I'd recommend using <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\" rel=\"nofollow noreferrer\" title=\"KFold\">KFold</a> validation to check.</p>\n\n<pre><code>from sklearn.model_selection import KFold\nimport numpy as np\nacc_score = []\n\nkf = KFold(n_splits=5)\n\nfor train_index, test_index in kf.split(X):\n\nX_train, X_test = X[train_index], X[test_index]\ny_train, y_test = y[train_index], y[test_index]\n\nsvm_model.fit(X_train,y_train)\npredictions = svm_model.predict(X_test)\nacc_score.append(accuracy_score(predictions, y_test))\n\nnp.mean(acc_score)\n</code></pre>\n\n<p>Sorry, can't get the code formatting right. The lines from X_train to acc_score.append should be indented.</p>\n\n<p>If the average is still 1.0 then you've done good, but my gut feeling is that your high score is dependent on the cut of the data you're looking at.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "26646",
                        "2",
                        "26640",
                        "",
                        "",
                        "<p>Based on <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\" rel=\"nofollow noreferrer\">here</a>, use <code>sklearn.model_selection.train_test_split(*arrays, **options)</code> in order to split your data into train and test. Train your model on train-split and use the <code>predict</code> method to see the performance on the test data. As an example take a look at the following code which splits the data to two separate groups.</p>\n\n<pre><code>import numpy as np\nfrom sklearn.model_selection import train_test_split\nX, y = np.arange(10).reshape((5, 2)), range(5)\nX\n\narray([[0, 1],\n       [2, 3],\n       [4, 5],\n       [6, 7],\n       [8, 9]])\n\nlist(y)\n[0, 1, 2, 3, 4]\n\n\nX_train, X_test, y_train, y_test = train_test_split(\n...     X, y, test_size=0.33, random_state=42)\n...\nX_train\narray([[4, 5],\n   [0, 1],\n   [6, 7]])\ny_train\n[2, 0, 3]\nX_test\narray([[2, 3],\n   [8, 9]])\ny_test\n[1, 4]\n\ntrain_test_split(y, shuffle=False)\n[[0, 1, 2], [3, 4]]\n</code></pre>\n",
                        "",
                        ""
                    ],
                    [
                        "26666",
                        "2",
                        "26640",
                        "",
                        "",
                        "<p>You check for hints of <strong>overfitting</strong> by using a <strong>training set</strong> and a <strong>test set</strong> (or a training, validation and test set). As others have mentioned, you can either <strong>split</strong> the data into training and test sets, or use <strong>cross-fold validation</strong> to get a more accurate assessment of your classifier's performance. </p>\n\n<p>Since your dataset is small, splitting your data into training and test sets isn't recommended. Use cross validation. </p>\n\n<p>This can be done using either the <strong>cross_validate</strong> or <strong>cross_val_score</strong> function; the latter providing <em>multiple</em> metrics for evaluation. In addition to <strong>test scores</strong> the latter also provides <strong>fit times</strong> and <strong>score times</strong>. </p>\n\n<p>Using your example; </p>\n\n<pre><code>from sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_iris\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score\n\niris = load_iris()\nX = iris.data[:, :5]  # we only take the first two features.\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=51)\nsvm_model = svm.SVC(kernel='linear', C=1, gamma='auto')\nsvm_model.fit(X_train,y_train)\npredictions = svm_model.predict(X_test)\naccuracy_score(predictions, y_test)\n</code></pre>\n\n<p>raw accuracy: 0.96666666666666667</p>\n\n<p>Using the <strong>cross_val_score</strong> function, and printing the <strong>mean score</strong> and <strong>95% confidence interval</strong> of the score estimate: </p>\n\n<pre><code>from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(svm_model, iris.data, iris.target, cv=5)\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n</code></pre>\n\n<p>Accuracy: 0.98 (+/- 0.03)</p>\n\n<p>Of course the iris dataset is a <em>toy example</em>. On larger real-world datasets you are likely to see your test error be higher than your training error, with cross-validation providing a lower accuracy than the raw number. </p>\n\n<p>So I wouldn't use the iris dataset to showcase overfitting. Choose a larger, messier dataset, and then you can start working towards reducing the <em>bias</em> and <em>variance</em> of the model (the \"causes\" of overfitting). </p>\n\n<p>Then you can start <em>exploring</em> tell-tale <strong>signs</strong> of whether it's a bias problem or a variance problem. See here:</p>\n\n<p><a href=\"https://www.quora.com/How-many-training-samples-are-needed-to-get-a-reliable-model-in-ML/answer/Sean-McClure-3?srid=zGgv\" rel=\"nofollow noreferrer\">https://www.quora.com/How-many-training-samples-are-needed-to-get-a-reliable-model-in-ML/answer/Sean-McClure-3?srid=zGgv</a></p>\n\n<p><a href=\"https://i.stack.imgur.com/eXCNE.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/eXCNE.jpg\" alt=\"enter image description here\"></a></p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10058",
            "_score": 4.7365522,
            "_source": {
                "title": "Tensorflow CNN sometimes converges, sometimes not",
                "content": "Tensorflow CNN sometimes converges, sometimes not <p><em>originally asked on stackoverflow, deleted</em></p>\n\n<p>Im having trouble traing a convolutional neural network in tensorflow. When I start my program, sometimes the model learns nicely (cost/cross_entropy goes down, accuracy on training and testing data goes up) and appears to converge after 50-100 epochs.</p>\n\n<p>However sometimes the training seems to get stuck after only a couple (2-4) epochs. Cost hovers around the same value (1.25) and accuracies get stuck on the same values: 0.45970 for training data and 0.016666 for testing data. No changes were made to code or training data between runs.</p>\n\n<p>The \"good\" runs (when the model learns) converge to various final accuracies. On the other hand, every single \"bad\" run goes to the exact same accuracy: 0.45970.</p>\n\n<p>I have 330 000 training images (grayscale), converted to numpy arrays. The generator I use to create tensorflow dataset works such as it lists all files in the folder, then takes every N-th file from that list and feeds only those selected files to the dataset. Currently Im using every 100th file, which works out to 33 batches of 100 images for a total of 3300 training images. I have 4 classes and the number of samples of each class is: 904, 321, 558, 1517.</p>\n\n<p>I have tried using more training samples (33 000) and different learning rates but the result was the same. It is more often that the network has a bad run than a good run.</p>\n\n<p>The only thing I can imagine is different between individual runs is the random initialization of weights, but could it have such an effect? Especially considering that random weight initialization uses small stddev (0.03/0.01)? Or is there something wrong with my code?</p>\n\n<p>Accuracy/cost plots: \n<a href=\"https://i.stack.imgur.com/kv54d.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/kv54d.png\" alt=\"Graph of a bad run\"></a>\n<a href=\"https://i.stack.imgur.com/PdgcB.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PdgcB.png\" alt=\"Graph of a good run\"></a></p>\n\n<p>Code is in two files: main and stream_data.py, which handles loading images from disk.</p>\n\n<p>Main program:</p>\n\n<pre><code>from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport numpy as np\nimport os\nfrom timeit import default_timer as timer\nimport time\nimport stream_data as sd    #for reading train/eval data\n\ntf.logging.set_verbosity(tf.logging.INFO)\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}        \n\nepochs = 10000\nlearning_rate = 0.03\n\n#use every 100-th training image\nsd.generator_filenames_every_nth_train = 100\n#use every testing image\nsd.generator_filenames_every_nth_eval = 1\n\nbatch_size = 100\nbatch_size_eval = 100\n\n#num training and evaluation batches per epoch - this works out to 33 training batches of 100 images and 12 batches of 100 images for evaluation\nnum_train_samples = len(os.listdir(sd.path_to_train_files_npy_stream))\ntotal_batch = int(num_train_samples /( sd.generator_filenames_every_nth_train * batch_size))\nprint('Num training samples:', num_train_samples, 'Generator train skip:', sd.generator_filenames_every_nth_train,  'Num train batches:', total_batch)\n\nnum_eval_samples = len(os.listdir(sd.path_to_eval_files_npy_stream))\ntotal_batch_eval = int(num_eval_samples / (sd.generator_filenames_every_nth_eval * batch_size_eval))\nprint('Num eval samples:', num_eval_samples, 'Generator eval skip:', sd.generator_filenames_every_nth_eval, 'Num eval batches:', total_batch_eval)                      \n\n\ndef run_cnn():\n\n    #for logging results\n    log_accuracy_train=[]\n    log_accuracy_eval=[]\n    log_cross_entropy=[]    \n\n\n    # SET UP THE NETWORK\n    # declare the training data placeholders\n    x = tf.placeholder(tf.float32, [None, sd.image_width * sd.image_height * sd.num_channels_used], name='placeholder_x')\n    x_shaped = tf.reshape(x, [-1, sd.image_height, sd.image_width, sd.num_channels_used], name='placeholder_x_shaped')\n    y = tf.placeholder(tf.float32, [None, sd.num_output_classes], name='placeholder_y')\n\n    # create some convolutional layers\n    layer1 = create_new_conv_layer(x_shaped, 1, 10, [5, 5], [4, 4], [4,4], name='layer1')\n    layer2 = create_new_conv_layer(layer1, 10, 20, [5, 5], [5,5], [5,5], name='layer2')\n\n    # flatten the output ready for the fully connected output stage\n    flattened = tf.reshape(layer2, [-1, 17 * 66 * 20])\n\n    # setup some weights and bias values for this layer, then activate with ReLU\n    wd1 = tf.Variable(tf.truncated_normal([17 * 66 * 20, 50], stddev=0.03), name='wd1')\n    bd1 = tf.Variable(tf.truncated_normal([50], stddev=0.01), name='bd1')\n    dense_layer1 = tf.matmul(flattened, wd1) + bd1\n    dense_layer1 = tf.nn.relu(dense_layer1, name = 'dense1')\n\n    # another layer with softmax activations - this is output layer\n    wd2 = tf.Variable(tf.truncated_normal([50, sd.num_output_classes], stddev=0.03), name='wd2')\n    bd2 = tf.Variable(tf.truncated_normal([sd.num_output_classes], stddev=0.01), name='bd2')\n    dense_layer2 = tf.matmul(dense_layer1, wd2) + bd2\n    y_prediction = tf.nn.softmax(dense_layer2, name='y_prediction')\n\n    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=dense_layer2, labels=y), name='cross_entropy')\n\n    # add an optimizer\n    adam_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='adam_optimizer_var')\n    optimizer = adam_optimizer.minimize(cross_entropy, name='adam_optimizer_minimize')\n\n    # define an accuracy assessment operation\n    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_prediction, 1), name = 'correct_prediction')\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n\n    #define how to get batches\n    batch_xt, batch_yt, batch_ft = sd.get_inputs_train(batch_size)\n    batch_xe, batch_ye, batch_fe = sd.get_inputs_eval(batch_size_eval)\n\n    # setup the initialisation operator\n    init_op = tf.global_variables_initializer()\n\n\n    model_saver = tf.train.Saver(name='model_saver')\n\n    with tf.Session() as sess:\n        sess.run(init_op)           \n\n        #in each epoch, train all batches and then evaluate the network on testing data\n        for epoch in range(epochs):\n            avg_cost = 0\n            avg_accuracy = 0.0\n            print('Training batches in epoch', epoch)\n            for i in range(total_batch):\n                time_0 = timer()\n                #get training data\n                batch_x_np, batch_y_np, batch_f_np = sess.run([batch_xt, batch_yt, batch_ft])\n                time_1 = timer()\n                #train network\n                _, c, train_acc = sess.run([optimizer, cross_entropy, accuracy], feed_dict={x: batch_x_np, y: batch_y_np})                  \n                avg_cost += c / total_batch \n                avg_accuracy += train_acc / total_batch     \n                time_2 = timer()\n                print('Trained batch ', i, '/', total_batch, ' Time: {:.3f} :'.format(time_2 - time_0), '{:.3f},'.format(time_1 - time_0), '{:.3f}'.format(time_2 - time_1),'Acc: {:.3f}'.format(train_acc))\n            print('After train epoch:', epoch, \"train cost =\", \"{:.5f}\".format(avg_cost), 'Avg train accuracy: {:.5f}'.format(avg_accuracy))\n\n            #save cross correlation and accuracy after training one epoch\n            log_accuracy_train = np.append(log_accuracy_train, avg_accuracy)\n            log_cross_entropy = np.append(log_cross_entropy, avg_cost)\n            np.save('./results/train_cost.npy',  log_cross_entropy)\n            np.save('./results/train_accuracy.npy',  log_accuracy_train)\n\n            print('Saving model after epoch', epoch)\n            model_saver.save(sess, './models/merc_proper/model_merc_full', global_step = epoch, write_meta_graph = True)\n\n\n\n\n            #evaluating model on testing data\n            avg_accuracy=0.0\n            for i in range(total_batch_eval):       \n                time_0 = timer()\n                #get testing data\n                batch_x_np, batch_y_np, batch_f_np = sess.run([batch_xe, batch_ye, batch_fe])                               \n                time_1 = timer()\n                #feedforward and get accuracy\n                test_acc = sess.run(accuracy, feed_dict={x: batch_x_np, y: batch_y_np})\n                time_2 = timer()\n                avg_accuracy += test_acc/total_batch_eval\n                print(\"Epoch:\", (epoch), \"eval accuracy: {:.3f}\".format(test_acc), ' Time: {:.3f} :'.format(time_2 - time_0), '{:.3f},'.format(time_1 - time_0), '{:.3f}'.format(time_2 - time_1))\n            print('Average eval accuracy after epoch', epoch, ':', avg_accuracy)\n\n            #save accuracy on testing data after epoch\n            log_accuracy_eval = np.append(log_accuracy_eval, avg_accuracy)\n            np.save('./results/eval_accuracy.npy',  log_accuracy_eval)\n\n        print(\"\\nTraining complete!\")\n\n\n\ndef create_new_conv_layer(input_data, num_input_channels, num_filters, filter_shape, pool_shape, pool_stride, name):\n    # setup the filter input shape for tf.nn.conv_2d\n    conv_filt_shape = [filter_shape[0], filter_shape[1], num_input_channels, num_filters]\n\n    # initialise weights and bias for the filter\n    #orig mean=0, std=0.03\n    weights = tf.Variable(tf.truncated_normal(conv_filt_shape, mean=0.0, stddev=0.03), name=name+'_W')\n    bias = tf.Variable(tf.truncated_normal([num_filters]), name=name+'_b')\n\n    # setup the convolutional layer operation\n    out_layer = tf.nn.conv2d(input_data, weights, [1, 1, 1, 1], padding='SAME')\n\n    # add the bias\n    out_layer += bias\n\n    # apply a ReLU non-linear activation\n    out_layer = tf.nn.relu(out_layer)\n\n    # now perform max pooling\n    ksize = [1, pool_shape[0], pool_shape[1], 1]\n    strides = [1, pool_stride[0], pool_stride[1], 1]\n    out_layer = tf.nn.max_pool(out_layer, ksize=ksize, strides=strides, padding='SAME')\n\n    return out_layer\n\n\ndef stop(msg = None):\n    if(msg != None):\n        print(msg)\n    raw_input('Press ENTER to continue')\n\nif __name__ == \"__main__\":\n    run_cnn()\n</code></pre>\n\n<p>stream_data.py:</p>\n\n<pre><code>from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os   #listdir\nimport numpy as np\nimport tensorflow as tf\nfrom timeit import default_timer as timer\nimport pickle \nimport random\nimport copy\nfrom PIL import Image\nimport threading\n\n\n#resolution of images\nimage_width = 1320\nimage_height = 340\n#number of channels - images are grayscale\nnum_channels_raw = 1\nnum_channels_used = 1\n\n#how many images should be skipped - only every N-th image will be used\n#so if this is == 100, only every 100th image will be used\ngenerator_filenames_every_nth_train = 1\ngenerator_filenames_every_nth_eval = 1\n\nnum_output_classes = 4\npath_to_train_files_npy_stream = '/media/user/DiskNaData_1TB/data/merc/train_artificial_npy/'\npath_to_eval_files_npy_stream = '/media/user/DiskNaData_1TB/data/merc/eval_artificial_npy/'\n\n\ndef stop(msg = None):\n    if(msg != None):\n        print(msg)\n    raw_input('Press ENTER to continue')\n\n\n#generator that produces train/eval data\n#returns data (grayscale values), label(onehot) and filename (for debugging purposes)\n#reads list of all files in a folder, then skips some of them and only yields every N-th \ndef read_stream_files(path_to_files_npy_stream, every_nth):\n    files = os.listdir(path_to_files_npy_stream)    \n    for i in range(0, len(files), every_nth):\n        filename=files[i]\n        data = np.load(path_to_files_npy_stream + filename)\n\n        data=data.astype(float)\n        data=data / 255.0\n\n        label = int(filename[0:2])\n        #make one-hot \n        onehot = np.zeros(num_output_classes)\n        onehot[label] = 1\n        label=onehot\n        yield data, label, filename\n\n\n\ndef get_dataset_train():\n    generator = lambda: read_stream_files(path_to_train_files_npy_stream, generator_filenames_every_nth_train)\n    return tf.data.Dataset.from_generator(\n        generator, (tf.float32, tf.int32, tf.string), ((image_width*image_height*num_channels_used,), (num_output_classes, ), ()))\n\n\ndef get_dataset_eval():\n    generator = lambda: read_stream_files(path_to_eval_files_npy_stream, generator_filenames_every_nth_eval)\n    return tf.data.Dataset.from_generator(\n        generator, (tf.float32, tf.int32, tf.string), ((image_width*image_height*num_channels_used,), (num_output_classes, ), ()))\n\n\ndef get_inputs_train(batch_size):\n    dataset = get_dataset_train()  \n    dataset = dataset.shuffle(1000)\n    dataset = dataset.repeat()  # repeat indefinitely\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(3)\n    features, label, filename = dataset.make_one_shot_iterator().get_next()\n    return features, label, filename\n\n\ndef get_inputs_eval(batch_size):\n    dataset = get_dataset_eval()  # one of the above implementations\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.repeat()\n    dataset = dataset.prefetch(3)\n    features, label, filename = dataset.make_one_shot_iterator().get_next()\n    return features, label, filename\n</code></pre>\n <python><tensorflow><convnet>",
                "codes": [],
                "question_id:": "36525",
                "question_votes:": "2",
                "question_text:": "<p><em>originally asked on stackoverflow, deleted</em></p>\n\n<p>Im having trouble traing a convolutional neural network in tensorflow. When I start my program, sometimes the model learns nicely (cost/cross_entropy goes down, accuracy on training and testing data goes up) and appears to converge after 50-100 epochs.</p>\n\n<p>However sometimes the training seems to get stuck after only a couple (2-4) epochs. Cost hovers around the same value (1.25) and accuracies get stuck on the same values: 0.45970 for training data and 0.016666 for testing data. No changes were made to code or training data between runs.</p>\n\n<p>The \"good\" runs (when the model learns) converge to various final accuracies. On the other hand, every single \"bad\" run goes to the exact same accuracy: 0.45970.</p>\n\n<p>I have 330 000 training images (grayscale), converted to numpy arrays. The generator I use to create tensorflow dataset works such as it lists all files in the folder, then takes every N-th file from that list and feeds only those selected files to the dataset. Currently Im using every 100th file, which works out to 33 batches of 100 images for a total of 3300 training images. I have 4 classes and the number of samples of each class is: 904, 321, 558, 1517.</p>\n\n<p>I have tried using more training samples (33 000) and different learning rates but the result was the same. It is more often that the network has a bad run than a good run.</p>\n\n<p>The only thing I can imagine is different between individual runs is the random initialization of weights, but could it have such an effect? Especially considering that random weight initialization uses small stddev (0.03/0.01)? Or is there something wrong with my code?</p>\n\n<p>Accuracy/cost plots: \n<a href=\"https://i.stack.imgur.com/kv54d.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/kv54d.png\" alt=\"Graph of a bad run\"></a>\n<a href=\"https://i.stack.imgur.com/PdgcB.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PdgcB.png\" alt=\"Graph of a good run\"></a></p>\n\n<p>Code is in two files: main and stream_data.py, which handles loading images from disk.</p>\n\n<p>Main program:</p>\n\n<pre><code>from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport numpy as np\nimport os\nfrom timeit import default_timer as timer\nimport time\nimport stream_data as sd    #for reading train/eval data\n\ntf.logging.set_verbosity(tf.logging.INFO)\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}        \n\nepochs = 10000\nlearning_rate = 0.03\n\n#use every 100-th training image\nsd.generator_filenames_every_nth_train = 100\n#use every testing image\nsd.generator_filenames_every_nth_eval = 1\n\nbatch_size = 100\nbatch_size_eval = 100\n\n#num training and evaluation batches per epoch - this works out to 33 training batches of 100 images and 12 batches of 100 images for evaluation\nnum_train_samples = len(os.listdir(sd.path_to_train_files_npy_stream))\ntotal_batch = int(num_train_samples /( sd.generator_filenames_every_nth_train * batch_size))\nprint('Num training samples:', num_train_samples, 'Generator train skip:', sd.generator_filenames_every_nth_train,  'Num train batches:', total_batch)\n\nnum_eval_samples = len(os.listdir(sd.path_to_eval_files_npy_stream))\ntotal_batch_eval = int(num_eval_samples / (sd.generator_filenames_every_nth_eval * batch_size_eval))\nprint('Num eval samples:', num_eval_samples, 'Generator eval skip:', sd.generator_filenames_every_nth_eval, 'Num eval batches:', total_batch_eval)                      \n\n\ndef run_cnn():\n\n    #for logging results\n    log_accuracy_train=[]\n    log_accuracy_eval=[]\n    log_cross_entropy=[]    \n\n\n    # SET UP THE NETWORK\n    # declare the training data placeholders\n    x = tf.placeholder(tf.float32, [None, sd.image_width * sd.image_height * sd.num_channels_used], name='placeholder_x')\n    x_shaped = tf.reshape(x, [-1, sd.image_height, sd.image_width, sd.num_channels_used], name='placeholder_x_shaped')\n    y = tf.placeholder(tf.float32, [None, sd.num_output_classes], name='placeholder_y')\n\n    # create some convolutional layers\n    layer1 = create_new_conv_layer(x_shaped, 1, 10, [5, 5], [4, 4], [4,4], name='layer1')\n    layer2 = create_new_conv_layer(layer1, 10, 20, [5, 5], [5,5], [5,5], name='layer2')\n\n    # flatten the output ready for the fully connected output stage\n    flattened = tf.reshape(layer2, [-1, 17 * 66 * 20])\n\n    # setup some weights and bias values for this layer, then activate with ReLU\n    wd1 = tf.Variable(tf.truncated_normal([17 * 66 * 20, 50], stddev=0.03), name='wd1')\n    bd1 = tf.Variable(tf.truncated_normal([50], stddev=0.01), name='bd1')\n    dense_layer1 = tf.matmul(flattened, wd1) + bd1\n    dense_layer1 = tf.nn.relu(dense_layer1, name = 'dense1')\n\n    # another layer with softmax activations - this is output layer\n    wd2 = tf.Variable(tf.truncated_normal([50, sd.num_output_classes], stddev=0.03), name='wd2')\n    bd2 = tf.Variable(tf.truncated_normal([sd.num_output_classes], stddev=0.01), name='bd2')\n    dense_layer2 = tf.matmul(dense_layer1, wd2) + bd2\n    y_prediction = tf.nn.softmax(dense_layer2, name='y_prediction')\n\n    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=dense_layer2, labels=y), name='cross_entropy')\n\n    # add an optimizer\n    adam_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='adam_optimizer_var')\n    optimizer = adam_optimizer.minimize(cross_entropy, name='adam_optimizer_minimize')\n\n    # define an accuracy assessment operation\n    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_prediction, 1), name = 'correct_prediction')\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n\n    #define how to get batches\n    batch_xt, batch_yt, batch_ft = sd.get_inputs_train(batch_size)\n    batch_xe, batch_ye, batch_fe = sd.get_inputs_eval(batch_size_eval)\n\n    # setup the initialisation operator\n    init_op = tf.global_variables_initializer()\n\n\n    model_saver = tf.train.Saver(name='model_saver')\n\n    with tf.Session() as sess:\n        sess.run(init_op)           \n\n        #in each epoch, train all batches and then evaluate the network on testing data\n        for epoch in range(epochs):\n            avg_cost = 0\n            avg_accuracy = 0.0\n            print('Training batches in epoch', epoch)\n            for i in range(total_batch):\n                time_0 = timer()\n                #get training data\n                batch_x_np, batch_y_np, batch_f_np = sess.run([batch_xt, batch_yt, batch_ft])\n                time_1 = timer()\n                #train network\n                _, c, train_acc = sess.run([optimizer, cross_entropy, accuracy], feed_dict={x: batch_x_np, y: batch_y_np})                  \n                avg_cost += c / total_batch \n                avg_accuracy += train_acc / total_batch     \n                time_2 = timer()\n                print('Trained batch ', i, '/', total_batch, ' Time: {:.3f} :'.format(time_2 - time_0), '{:.3f},'.format(time_1 - time_0), '{:.3f}'.format(time_2 - time_1),'Acc: {:.3f}'.format(train_acc))\n            print('After train epoch:', epoch, \"train cost =\", \"{:.5f}\".format(avg_cost), 'Avg train accuracy: {:.5f}'.format(avg_accuracy))\n\n            #save cross correlation and accuracy after training one epoch\n            log_accuracy_train = np.append(log_accuracy_train, avg_accuracy)\n            log_cross_entropy = np.append(log_cross_entropy, avg_cost)\n            np.save('./results/train_cost.npy',  log_cross_entropy)\n            np.save('./results/train_accuracy.npy',  log_accuracy_train)\n\n            print('Saving model after epoch', epoch)\n            model_saver.save(sess, './models/merc_proper/model_merc_full', global_step = epoch, write_meta_graph = True)\n\n\n\n\n            #evaluating model on testing data\n            avg_accuracy=0.0\n            for i in range(total_batch_eval):       \n                time_0 = timer()\n                #get testing data\n                batch_x_np, batch_y_np, batch_f_np = sess.run([batch_xe, batch_ye, batch_fe])                               \n                time_1 = timer()\n                #feedforward and get accuracy\n                test_acc = sess.run(accuracy, feed_dict={x: batch_x_np, y: batch_y_np})\n                time_2 = timer()\n                avg_accuracy += test_acc/total_batch_eval\n                print(\"Epoch:\", (epoch), \"eval accuracy: {:.3f}\".format(test_acc), ' Time: {:.3f} :'.format(time_2 - time_0), '{:.3f},'.format(time_1 - time_0), '{:.3f}'.format(time_2 - time_1))\n            print('Average eval accuracy after epoch', epoch, ':', avg_accuracy)\n\n            #save accuracy on testing data after epoch\n            log_accuracy_eval = np.append(log_accuracy_eval, avg_accuracy)\n            np.save('./results/eval_accuracy.npy',  log_accuracy_eval)\n\n        print(\"\\nTraining complete!\")\n\n\n\ndef create_new_conv_layer(input_data, num_input_channels, num_filters, filter_shape, pool_shape, pool_stride, name):\n    # setup the filter input shape for tf.nn.conv_2d\n    conv_filt_shape = [filter_shape[0], filter_shape[1], num_input_channels, num_filters]\n\n    # initialise weights and bias for the filter\n    #orig mean=0, std=0.03\n    weights = tf.Variable(tf.truncated_normal(conv_filt_shape, mean=0.0, stddev=0.03), name=name+'_W')\n    bias = tf.Variable(tf.truncated_normal([num_filters]), name=name+'_b')\n\n    # setup the convolutional layer operation\n    out_layer = tf.nn.conv2d(input_data, weights, [1, 1, 1, 1], padding='SAME')\n\n    # add the bias\n    out_layer += bias\n\n    # apply a ReLU non-linear activation\n    out_layer = tf.nn.relu(out_layer)\n\n    # now perform max pooling\n    ksize = [1, pool_shape[0], pool_shape[1], 1]\n    strides = [1, pool_stride[0], pool_stride[1], 1]\n    out_layer = tf.nn.max_pool(out_layer, ksize=ksize, strides=strides, padding='SAME')\n\n    return out_layer\n\n\ndef stop(msg = None):\n    if(msg != None):\n        print(msg)\n    raw_input('Press ENTER to continue')\n\nif __name__ == \"__main__\":\n    run_cnn()\n</code></pre>\n\n<p>stream_data.py:</p>\n\n<pre><code>from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os   #listdir\nimport numpy as np\nimport tensorflow as tf\nfrom timeit import default_timer as timer\nimport pickle \nimport random\nimport copy\nfrom PIL import Image\nimport threading\n\n\n#resolution of images\nimage_width = 1320\nimage_height = 340\n#number of channels - images are grayscale\nnum_channels_raw = 1\nnum_channels_used = 1\n\n#how many images should be skipped - only every N-th image will be used\n#so if this is == 100, only every 100th image will be used\ngenerator_filenames_every_nth_train = 1\ngenerator_filenames_every_nth_eval = 1\n\nnum_output_classes = 4\npath_to_train_files_npy_stream = '/media/user/DiskNaData_1TB/data/merc/train_artificial_npy/'\npath_to_eval_files_npy_stream = '/media/user/DiskNaData_1TB/data/merc/eval_artificial_npy/'\n\n\ndef stop(msg = None):\n    if(msg != None):\n        print(msg)\n    raw_input('Press ENTER to continue')\n\n\n#generator that produces train/eval data\n#returns data (grayscale values), label(onehot) and filename (for debugging purposes)\n#reads list of all files in a folder, then skips some of them and only yields every N-th \ndef read_stream_files(path_to_files_npy_stream, every_nth):\n    files = os.listdir(path_to_files_npy_stream)    \n    for i in range(0, len(files), every_nth):\n        filename=files[i]\n        data = np.load(path_to_files_npy_stream + filename)\n\n        data=data.astype(float)\n        data=data / 255.0\n\n        label = int(filename[0:2])\n        #make one-hot \n        onehot = np.zeros(num_output_classes)\n        onehot[label] = 1\n        label=onehot\n        yield data, label, filename\n\n\n\ndef get_dataset_train():\n    generator = lambda: read_stream_files(path_to_train_files_npy_stream, generator_filenames_every_nth_train)\n    return tf.data.Dataset.from_generator(\n        generator, (tf.float32, tf.int32, tf.string), ((image_width*image_height*num_channels_used,), (num_output_classes, ), ()))\n\n\ndef get_dataset_eval():\n    generator = lambda: read_stream_files(path_to_eval_files_npy_stream, generator_filenames_every_nth_eval)\n    return tf.data.Dataset.from_generator(\n        generator, (tf.float32, tf.int32, tf.string), ((image_width*image_height*num_channels_used,), (num_output_classes, ), ()))\n\n\ndef get_inputs_train(batch_size):\n    dataset = get_dataset_train()  \n    dataset = dataset.shuffle(1000)\n    dataset = dataset.repeat()  # repeat indefinitely\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(3)\n    features, label, filename = dataset.make_one_shot_iterator().get_next()\n    return features, label, filename\n\n\ndef get_inputs_eval(batch_size):\n    dataset = get_dataset_eval()  # one of the above implementations\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.repeat()\n    dataset = dataset.prefetch(3)\n    features, label, filename = dataset.make_one_shot_iterator().get_next()\n    return features, label, filename\n</code></pre>\n",
                "tags": "<python><tensorflow><convnet>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17687",
            "_score": 4.5951185,
            "_source": {
                "title": "How to use Chi-square test in dataset with negative values",
                "content": "How to use Chi-square test in dataset with negative values <p>I could not fully explain the title. In order to use the Chi-square test in my dataset, I am finding the smallest value and add each cell with that value. (for example, the range of data here is [-8,11] so I added +8 to each cell and the range turned to [0,19]).</p>\n\n<p>dataValues variable is DataFrame type that holds my all data and contains ~2000 features, ~1000 rows, dataTargetEncoded variable is Array type that contains results as 0 and 1.</p>\n\n<pre><code>for i in range(len(dataValues.index)):\n    for j in range(len(dataValues.columns)):\n        dataValues.iat[i, j] += 8\n\n#fit chi2 and get results\nbestfeatures = SelectKBest(score_func=chi2, k=\"all\")\nfit = bestfeatures.fit(dataValues, dataTargetEncoded)\nfeat_importances = pd.Series(fit.scores_, index=dataValues.columns)\n\n#print top 10 feature\nprint(feat_importances.nlargest(10).index.values)\n\n# back to normal\nfor i in range(len(dataValues.index)):\n    for j in range(len(dataValues.columns)):\n        dataValues.iat[i, j] -= 8\n</code></pre>\n\n<p>But this causes performance problems. Another solution I'm thinking of is to normalize it. I wrote a function that looks like this:</p>\n\n<pre><code>def normalization(df):\n    from sklearn import preprocessing\n\n    x = df.values  # returns a numpy array\n    min_max_scaler = preprocessing.MinMaxScaler()\n    x_scaled = min_max_scaler.fit_transform(x)\n    df = pd.DataFrame(x_scaled, columns=df.columns)\n\nreturn df\n</code></pre>\n\n<p>My program has accelerated lots, but this time my accuracy has decreased. The feature selection process I have done with the first method produces 0.85 accuracy results, this time I am producing 0.70 accuracy.</p>\n\n<p>I want to get rid of this primitive method, but I also want accuracy to remain constant. How do I proceed? Thank you in advance</p>\n <machine-learning><python><optimization><p>First and foremost, it does not matter to the chi-square test whether your data is positive, negative, string or any other type, as long as it is discrete (or nicely binned). This is due to the fact that the chi-square test calculations are based on a <a href=\"https://en.wikipedia.org/wiki/Contingency_table#Example\" rel=\"nofollow noreferrer\">contingency table</a> and <em>not</em> your raw data. The documentation of <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html\" rel=\"nofollow noreferrer\">sklearn.feature_selection.chi2</a> and the related <a href=\"https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection\" rel=\"nofollow noreferrer\">usage example</a> are not clear on that at all. Not only that, but the two are not in concord regarding the type of input data (documentation says booleans or frequencies, whereas the example uses the raw iris dataset, which has quantities in centimeters), so this causes even more confusion. The reason why sklearn's chi-squared expects only non-negative features is most likely the <a href=\"https://github.com/scikit-learn/scikit-learn/blob/1495f6924/sklearn/feature_selection/univariate_selection.py#L224\" rel=\"nofollow noreferrer\">implementation</a>: the authors are relying on a row-by-row sum, which means that allowing negative values will produce the wrong result. Some hard-to-understand optimization is happening internally as well, so for the purposes of simple feature selection I would personally go with <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html\" rel=\"nofollow noreferrer\">scipy's implementation</a>.</p>\n\n<p>Since your data is not discrete, you will have to bin every feature into <em>some</em> number of nominal categories in order to perform the chi-squared test. Be aware that information loss takes place during this step regardless of your technique; your aim is to minimize it by finding an approach that best suits your data. You must also understand that the results cannot be taken as the absolute truth since the test is not designed for data of continuous nature. Another massive problem that will <em>definitely</em> mess with your feature selection process in general is that the number of features is larger than the number of observations. I would definitely recommend taking a look at <a href=\"https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition\" rel=\"nofollow noreferrer\">sklearn's decomposition methods</a> such as PCA to reduce the number of features, and if your features come in groups, you can try Multiple Factor Analysis (Python implementation available via <a href=\"https://github.com/MaxHalford/prince#multiple-factor-analysis-mfa\" rel=\"nofollow noreferrer\">prince</a>).</p>\n\n<p>Now that that's out of the way, let's go through an example of simple feature selection using the iris dataset. We will add a useless normally distributed variable to the constructed dataframe for comparison.</p>\n\n<pre><code>import numpy as np\nimport scipy as sp\nimport pandas as pd\n\nfrom sklearn import datasets, preprocessing as prep\n\niris = datasets.load_iris()\n\nX, y = iris['data'], iris['target']\ndf = pd.DataFrame(X, columns= iris['feature_names'])\ndf['useless_feature'] = np.random.normal(0, 5, len(df))\n</code></pre>\n\n<p>Now we have to bin the data. For value-based and quantile-based binning, you can use <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html\" rel=\"nofollow noreferrer\">pd.cut</a> and <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html\" rel=\"nofollow noreferrer\">pd.qcut</a>, respectively (this <a href=\"https://stackoverflow.com/questions/30211923/what-is-the-difference-between-pandas-qcut-and-pandas-cut\">great answer</a> explains the difference between the two), but sklearn's <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html\" rel=\"nofollow noreferrer\">KBinsDiscretizer</a> provides even more options. Here I'm using it for one-dimensional <a href=\"https://en.wikipedia.org/wiki/K-means_clustering#Algorithms\" rel=\"nofollow noreferrer\">k-means clustering</a> to create the bins (separate calculation for each feature):</p>\n\n<pre><code>def bin_by_kmeans(pd_series, n_bins):\n    binner = prep.KBinsDiscretizer(n_bins= n_bins, encode= 'ordinal', strategy= 'kmeans')\n    binner.fit(pd_series.values.reshape(-1, 1))\n    bin_edges = [\n        '({:.2f} .. {:.2f})'.format(left_edge, right_edge)\n        for left_edge, right_edge in zip(\n            binner.bin_edges_[0][:-1],\n            binner.bin_edges_[0][1:]\n        )\n    ]\n    return list(map(lambda b: bin_edges[int(b)], binner.transform(pd_series.values.reshape(-1, 1))))\n\ndf_binned = df.copy()\nfor f in df.columns:\n    df_binned[f] = bin_by_kmeans(df_binned[f], 5)\n</code></pre>\n\n<p>A good way to investigate how well your individual features are binned is by counting the number of data points in each bin (<code>df_binned['feature_name_here'].value_counts()</code>) and by printing out a <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html\" rel=\"nofollow noreferrer\">pd.crosstab</a> (contingency table) of the given feature and label columns.</p>\n\n<blockquote>\n  <p>An often quoted guideline for the validity of this calculation is that the test should be used only if the observed and expected frequencies in each cell are at least 5.</p>\n</blockquote>\n\n<p>So the <strong>more zeroes</strong> you see in the contingency table, the <strong>less accurate</strong> the chi-squared results will be. This will require a bit of manual tuning.</p>\n\n<p>Next comes the function that performs the chi-squared test for independence on two variables (<a href=\"https://machinelearningmastery.com/chi-squared-test-for-machine-learning/\" rel=\"nofollow noreferrer\">this tutorial</a> has very useful explanations, highly recommended read, code is pulled from there):</p>\n\n<pre><code>def get_chi_squared_results(series_A, series_B):\n    contingency_table = pd.crosstab(series_A, series_B)\n    chi2_stat, p_value, dof, expected_table = sp.stats.chi2_contingency(contingency_table)\n    threshold = sp.stats.chi2.ppf(0.95, dof)\n    return chi2_stat, threshold, p_value\n</code></pre>\n\n<p>The values to focus on are the statistic itself, the threshold, and its p-value. The threshold is obtained from a <a href=\"https://en.wikipedia.org/wiki/Quantile_function\" rel=\"nofollow noreferrer\">quantile function</a>. You can use these three to make the final assessment of individual feature-label tests:</p>\n\n<pre><code>print('{:&lt;20} {:&gt;12} {:&gt;12}\\t{:&lt;10} {:&lt;3}'.format('Feature', 'Chi2', 'Threshold', 'P-value', 'Is dependent?'))\nfor f in df.columns:\n    chi2_stat, threshold, p_value = get_chi_squared_results(df[f], y)\n    is_over_threshold = chi2_stat &gt;= threshold\n    is_result_significant = p_value &lt;= 0.05\n    print('{:&lt;20} {:&gt;12.2f} {:&gt;12.2f}\\t{:&lt;10.2f} {}'.format(\n        f, chi2_stat, threshold, p_value, (is_over_threshold and is_result_significant)\n    ))\n</code></pre>\n\n<p>In my case, the output looks like this:</p>\n\n<pre><code>Feature                      Chi2    Threshold  P-value    Is dependent?\nsepal length (cm)          156.27        88.25  0.00       True\nsepal width (cm)            89.55        60.48  0.00       True\npetal length (cm)          271.80       106.39  0.00       True\npetal width (cm)           271.75        58.12  0.00       True\nuseless_feature            300.00       339.26  0.46       False\n</code></pre>\n\n<p>In order to claim dependence between the two variables, the resulting statistic should be larger than the threshold value <strong>and</strong> the <a href=\"https://en.wikipedia.org/wiki/P-value#Definition_and_interpretation\" rel=\"nofollow noreferrer\">p-value</a> should be lower than 0.05. You can choose smaller p-values for higher confidence (you'd have to calculate the threshold from <code>sp.stats.chi2.ppf</code> accordingly), but 0.05 is the \"largest\" value needed for your results to be considered significant. As far as ordering of useful features goes, consider looking at the relative magnitude of the difference between the calculated statistic and the threshold for each feature.</p>\n<p>Chi-Sqaured statistic is a square of Z-statistic so I don't understand why it would matter if you have negative values in there.</p>\n",
                "codes": [
                    [
                        "import numpy as np\nimport scipy as sp\nimport pandas as pd\n\nfrom sklearn import datasets, preprocessing as prep\n\niris = datasets.load_iris()\n\nX, y = iris['data'], iris['target']\ndf = pd.DataFrame(X, columns= iris['feature_names'])\ndf['useless_feature'] = np.random.normal(0, 5, len(df))\n",
                        "def bin_by_kmeans(pd_series, n_bins):\n    binner = prep.KBinsDiscretizer(n_bins= n_bins, encode= 'ordinal', strategy= 'kmeans')\n    binner.fit(pd_series.values.reshape(-1, 1))\n    bin_edges = [\n        '({:.2f} .. {:.2f})'.format(left_edge, right_edge)\n        for left_edge, right_edge in zip(\n            binner.bin_edges_[0][:-1],\n            binner.bin_edges_[0][1:]\n        )\n    ]\n    return list(map(lambda b: bin_edges[int(b)], binner.transform(pd_series.values.reshape(-1, 1))))\n\ndf_binned = df.copy()\nfor f in df.columns:\n    df_binned[f] = bin_by_kmeans(df_binned[f], 5)\n",
                        "def get_chi_squared_results(series_A, series_B):\n    contingency_table = pd.crosstab(series_A, series_B)\n    chi2_stat, p_value, dof, expected_table = sp.stats.chi2_contingency(contingency_table)\n    threshold = sp.stats.chi2.ppf(0.95, dof)\n    return chi2_stat, threshold, p_value\n",
                        "print('{:<20} {:>12} {:>12}\\t{:<10} {:<3}'.format('Feature', 'Chi2', 'Threshold', 'P-value', 'Is dependent?'))\nfor f in df.columns:\n    chi2_stat, threshold, p_value = get_chi_squared_results(df[f], y)\n    is_over_threshold = chi2_stat >= threshold\n    is_result_significant = p_value <= 0.05\n    print('{:<20} {:>12.2f} {:>12.2f}\\t{:<10.2f} {}'.format(\n        f, chi2_stat, threshold, p_value, (is_over_threshold and is_result_significant)\n    ))\n",
                        "Feature                      Chi2    Threshold  P-value    Is dependent?\nsepal length (cm)          156.27        88.25  0.00       True\nsepal width (cm)            89.55        60.48  0.00       True\npetal length (cm)          271.80       106.39  0.00       True\npetal width (cm)           271.75        58.12  0.00       True\nuseless_feature            300.00       339.26  0.46       False\n"
                    ],
                    []
                ],
                "question_id:": "56747",
                "question_votes:": "",
                "question_text:": "<p>I could not fully explain the title. In order to use the Chi-square test in my dataset, I am finding the smallest value and add each cell with that value. (for example, the range of data here is [-8,11] so I added +8 to each cell and the range turned to [0,19]).</p>\n\n<p>dataValues variable is DataFrame type that holds my all data and contains ~2000 features, ~1000 rows, dataTargetEncoded variable is Array type that contains results as 0 and 1.</p>\n\n<pre><code>for i in range(len(dataValues.index)):\n    for j in range(len(dataValues.columns)):\n        dataValues.iat[i, j] += 8\n\n#fit chi2 and get results\nbestfeatures = SelectKBest(score_func=chi2, k=\"all\")\nfit = bestfeatures.fit(dataValues, dataTargetEncoded)\nfeat_importances = pd.Series(fit.scores_, index=dataValues.columns)\n\n#print top 10 feature\nprint(feat_importances.nlargest(10).index.values)\n\n# back to normal\nfor i in range(len(dataValues.index)):\n    for j in range(len(dataValues.columns)):\n        dataValues.iat[i, j] -= 8\n</code></pre>\n\n<p>But this causes performance problems. Another solution I'm thinking of is to normalize it. I wrote a function that looks like this:</p>\n\n<pre><code>def normalization(df):\n    from sklearn import preprocessing\n\n    x = df.values  # returns a numpy array\n    min_max_scaler = preprocessing.MinMaxScaler()\n    x_scaled = min_max_scaler.fit_transform(x)\n    df = pd.DataFrame(x_scaled, columns=df.columns)\n\nreturn df\n</code></pre>\n\n<p>My program has accelerated lots, but this time my accuracy has decreased. The feature selection process I have done with the first method produces 0.85 accuracy results, this time I am producing 0.70 accuracy.</p>\n\n<p>I want to get rid of this primitive method, but I also want accuracy to remain constant. How do I proceed? Thank you in advance</p>\n",
                "tags": "<machine-learning><python><optimization>",
                "answers": [
                    [
                        "57092",
                        "2",
                        "56747",
                        "",
                        "",
                        "<p>First and foremost, it does not matter to the chi-square test whether your data is positive, negative, string or any other type, as long as it is discrete (or nicely binned). This is due to the fact that the chi-square test calculations are based on a <a href=\"https://en.wikipedia.org/wiki/Contingency_table#Example\" rel=\"nofollow noreferrer\">contingency table</a> and <em>not</em> your raw data. The documentation of <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html\" rel=\"nofollow noreferrer\">sklearn.feature_selection.chi2</a> and the related <a href=\"https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection\" rel=\"nofollow noreferrer\">usage example</a> are not clear on that at all. Not only that, but the two are not in concord regarding the type of input data (documentation says booleans or frequencies, whereas the example uses the raw iris dataset, which has quantities in centimeters), so this causes even more confusion. The reason why sklearn's chi-squared expects only non-negative features is most likely the <a href=\"https://github.com/scikit-learn/scikit-learn/blob/1495f6924/sklearn/feature_selection/univariate_selection.py#L224\" rel=\"nofollow noreferrer\">implementation</a>: the authors are relying on a row-by-row sum, which means that allowing negative values will produce the wrong result. Some hard-to-understand optimization is happening internally as well, so for the purposes of simple feature selection I would personally go with <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html\" rel=\"nofollow noreferrer\">scipy's implementation</a>.</p>\n\n<p>Since your data is not discrete, you will have to bin every feature into <em>some</em> number of nominal categories in order to perform the chi-squared test. Be aware that information loss takes place during this step regardless of your technique; your aim is to minimize it by finding an approach that best suits your data. You must also understand that the results cannot be taken as the absolute truth since the test is not designed for data of continuous nature. Another massive problem that will <em>definitely</em> mess with your feature selection process in general is that the number of features is larger than the number of observations. I would definitely recommend taking a look at <a href=\"https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition\" rel=\"nofollow noreferrer\">sklearn's decomposition methods</a> such as PCA to reduce the number of features, and if your features come in groups, you can try Multiple Factor Analysis (Python implementation available via <a href=\"https://github.com/MaxHalford/prince#multiple-factor-analysis-mfa\" rel=\"nofollow noreferrer\">prince</a>).</p>\n\n<p>Now that that's out of the way, let's go through an example of simple feature selection using the iris dataset. We will add a useless normally distributed variable to the constructed dataframe for comparison.</p>\n\n<pre><code>import numpy as np\nimport scipy as sp\nimport pandas as pd\n\nfrom sklearn import datasets, preprocessing as prep\n\niris = datasets.load_iris()\n\nX, y = iris['data'], iris['target']\ndf = pd.DataFrame(X, columns= iris['feature_names'])\ndf['useless_feature'] = np.random.normal(0, 5, len(df))\n</code></pre>\n\n<p>Now we have to bin the data. For value-based and quantile-based binning, you can use <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html\" rel=\"nofollow noreferrer\">pd.cut</a> and <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html\" rel=\"nofollow noreferrer\">pd.qcut</a>, respectively (this <a href=\"https://stackoverflow.com/questions/30211923/what-is-the-difference-between-pandas-qcut-and-pandas-cut\">great answer</a> explains the difference between the two), but sklearn's <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html\" rel=\"nofollow noreferrer\">KBinsDiscretizer</a> provides even more options. Here I'm using it for one-dimensional <a href=\"https://en.wikipedia.org/wiki/K-means_clustering#Algorithms\" rel=\"nofollow noreferrer\">k-means clustering</a> to create the bins (separate calculation for each feature):</p>\n\n<pre><code>def bin_by_kmeans(pd_series, n_bins):\n    binner = prep.KBinsDiscretizer(n_bins= n_bins, encode= 'ordinal', strategy= 'kmeans')\n    binner.fit(pd_series.values.reshape(-1, 1))\n    bin_edges = [\n        '({:.2f} .. {:.2f})'.format(left_edge, right_edge)\n        for left_edge, right_edge in zip(\n            binner.bin_edges_[0][:-1],\n            binner.bin_edges_[0][1:]\n        )\n    ]\n    return list(map(lambda b: bin_edges[int(b)], binner.transform(pd_series.values.reshape(-1, 1))))\n\ndf_binned = df.copy()\nfor f in df.columns:\n    df_binned[f] = bin_by_kmeans(df_binned[f], 5)\n</code></pre>\n\n<p>A good way to investigate how well your individual features are binned is by counting the number of data points in each bin (<code>df_binned['feature_name_here'].value_counts()</code>) and by printing out a <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html\" rel=\"nofollow noreferrer\">pd.crosstab</a> (contingency table) of the given feature and label columns.</p>\n\n<blockquote>\n  <p>An often quoted guideline for the validity of this calculation is that the test should be used only if the observed and expected frequencies in each cell are at least 5.</p>\n</blockquote>\n\n<p>So the <strong>more zeroes</strong> you see in the contingency table, the <strong>less accurate</strong> the chi-squared results will be. This will require a bit of manual tuning.</p>\n\n<p>Next comes the function that performs the chi-squared test for independence on two variables (<a href=\"https://machinelearningmastery.com/chi-squared-test-for-machine-learning/\" rel=\"nofollow noreferrer\">this tutorial</a> has very useful explanations, highly recommended read, code is pulled from there):</p>\n\n<pre><code>def get_chi_squared_results(series_A, series_B):\n    contingency_table = pd.crosstab(series_A, series_B)\n    chi2_stat, p_value, dof, expected_table = sp.stats.chi2_contingency(contingency_table)\n    threshold = sp.stats.chi2.ppf(0.95, dof)\n    return chi2_stat, threshold, p_value\n</code></pre>\n\n<p>The values to focus on are the statistic itself, the threshold, and its p-value. The threshold is obtained from a <a href=\"https://en.wikipedia.org/wiki/Quantile_function\" rel=\"nofollow noreferrer\">quantile function</a>. You can use these three to make the final assessment of individual feature-label tests:</p>\n\n<pre><code>print('{:&lt;20} {:&gt;12} {:&gt;12}\\t{:&lt;10} {:&lt;3}'.format('Feature', 'Chi2', 'Threshold', 'P-value', 'Is dependent?'))\nfor f in df.columns:\n    chi2_stat, threshold, p_value = get_chi_squared_results(df[f], y)\n    is_over_threshold = chi2_stat &gt;= threshold\n    is_result_significant = p_value &lt;= 0.05\n    print('{:&lt;20} {:&gt;12.2f} {:&gt;12.2f}\\t{:&lt;10.2f} {}'.format(\n        f, chi2_stat, threshold, p_value, (is_over_threshold and is_result_significant)\n    ))\n</code></pre>\n\n<p>In my case, the output looks like this:</p>\n\n<pre><code>Feature                      Chi2    Threshold  P-value    Is dependent?\nsepal length (cm)          156.27        88.25  0.00       True\nsepal width (cm)            89.55        60.48  0.00       True\npetal length (cm)          271.80       106.39  0.00       True\npetal width (cm)           271.75        58.12  0.00       True\nuseless_feature            300.00       339.26  0.46       False\n</code></pre>\n\n<p>In order to claim dependence between the two variables, the resulting statistic should be larger than the threshold value <strong>and</strong> the <a href=\"https://en.wikipedia.org/wiki/P-value#Definition_and_interpretation\" rel=\"nofollow noreferrer\">p-value</a> should be lower than 0.05. You can choose smaller p-values for higher confidence (you'd have to calculate the threshold from <code>sp.stats.chi2.ppf</code> accordingly), but 0.05 is the \"largest\" value needed for your results to be considered significant. As far as ordering of useful features goes, consider looking at the relative magnitude of the difference between the calculated statistic and the threshold for each feature.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "56859",
                        "2",
                        "56747",
                        "",
                        "",
                        "<p>Chi-Sqaured statistic is a square of Z-statistic so I don't understand why it would matter if you have negative values in there.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17287",
            "_score": 4.5353684,
            "_source": {
                "title": "Pytorch - Loss is decreasing but Accuracy not",
                "content": "Pytorch - Loss is decreasing but Accuracy not <p>It seems loss is decreasing and the algorithm works fine. But accuracy doesn't decrease and stuck.</p>\n\n<pre><code>import numpy as np\nimport cv2\nfrom os import listdir\nfrom os.path import isfile, join\nfrom sklearn.utils import shuffle\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport torch.utils.data\n\nfile_path_0 = [f for f in listdir(\"data/0\") if isfile(join(\"data/0\", f))]\nfile_path_1 = [f for f in listdir(\"data/1\") if isfile(join(\"data/1\", f))]\n\ndata_x = []\ndata_y = []\n\nfor i in range(len(file_path_0)):\n    image = cv2.imread(\"data/0/\" + file_path_0[i])\n    # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    data_x.append(image)\n    data_y.append(0)\n\nfor i in range(len(file_path_1)):\n    image = cv2.imread(\"data/1/\" + file_path_1[i])\n    # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    data_x.append(image)\n    data_y.append(1)\n\ndata_x = np.array(data_x).astype(np.double) / 255\ndata_y = np.array(data_y).astype(np.double).reshape(-1, 1)\n\ndata_x, data_y = shuffle(data_x, data_y)\n\nt_data_x = torch.stack([torch.Tensor(i) for i in data_x])  # transform to torch tensors\nt_data_y = torch.stack([torch.tensor(i, dtype=torch.float) for i in data_y])\n\n##############################\n\nbatch_size = 10\n\nt_dataset = torch.utils.data.TensorDataset(t_data_x, t_data_y)  # create your dataset\n\ntrain_size = int(0.8 * len(t_dataset))\ntest_size = len(t_dataset) - train_size\ntrain_dataset, test_dataset = torch.utils.data.random_split(t_dataset, [train_size, test_size])\n\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)  # create your dataloader\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)  # create your dataloader\n\n\nclass Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n\n        self.conv1 = nn.Conv2d(720, 10, kernel_size=3)\n        self.conv2 = nn.Conv2d(10, 5, kernel_size=3)\n\n        self.mp1 = nn.MaxPool2d(5)\n\n        self.fc = nn.Linear(2550, 1)\n\n    def forward(self, x):\n        in_size = x.size(0)\n        x = F.relu(self.mp1(self.conv1(x)))\n        x = x.view(in_size, -1)  # Dense\n        x = self.fc(x)\n        x = F.sigmoid(x)\n\n        return x\n\n\nmodel = Net()\n\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\n\ndef train(epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_dataloader):\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.binary_cross_entropy(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 10 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_dataloader.dataset),\n                       100. * batch_idx / len(train_dataloader),\n                loss.data.item()))\n\n\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_dataloader:\n        data, target = Variable(data, requires_grad=True), Variable(target)\n        output = model(data)\n        # sum up batch loss\n        test_loss += F.binary_cross_entropy(output, target, size_average=False).data.item()\n        # get the index of the max log-probability\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred \\\n            .eq(target\n                .data\n                .view_as(pred).long()) \\\n            .cpu() \\\n            .sum()\n\n    test_loss /= len(test_dataloader.dataset)\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_dataloader.dataset),\n        100. * correct / len(test_dataloader.dataset)))\n\n\nfor epoch in range(1, 10):\n    train(epoch)\n    test()\n\n</code></pre>\n\n<blockquote>\n  <p>Train Epoch: 7 [0/249 (0%)]   Loss: 0.537067 Train Epoch: 7 [100/249\n  (40%)]    Loss: 0.597774 Train Epoch: 7 [200/249 (80%)]   Loss: 0.554897\n  Test set: Average loss: 0.5094, Accuracy: 37/63 (58%) Train Epoch: 8\n  [0/249 (0%)]  Loss: 0.481739 Train Epoch: 8 [100/249 (40%)]   Loss:\n  0.564388 Train Epoch: 8 [200/249 (80%)]   Loss: 0.517878 Test set: Average loss: 0.4522, Accuracy: 37/63 (58%) Train Epoch: 9 [0/249\n  (0%)] Loss: 0.420650 Train Epoch: 9 [100/249 (40%)]   Loss: 0.521278\n  Train Epoch: 9 [200/249 (80%)]    Loss: 0.480884 Test set: Average loss:\n  0.3944, Accuracy: 37/63 (58%)</p>\n</blockquote>\n <python><image-classification><pytorch><p>Such a difference in Loss and Accuracy happens. It's pretty normal. The accuracy just shows how much you got right out of your samples. So in your case, your accuracy was 37/63 in 9th epoch.</p>\n\n<p>When calculating loss, however, you also take into account how well your model is predicting the correctly predicted images. When the loss decreases but accuracy stays the same, you probably better predict the images you already predicted. Maybe your model was 80% sure that it got the right class at some inputs, now it gets it with 90%. Hope that makes sense.  </p>\n",
                "codes": [
                    []
                ],
                "question_id:": "55907",
                "question_votes:": "1",
                "question_text:": "<p>It seems loss is decreasing and the algorithm works fine. But accuracy doesn't decrease and stuck.</p>\n\n<pre><code>import numpy as np\nimport cv2\nfrom os import listdir\nfrom os.path import isfile, join\nfrom sklearn.utils import shuffle\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport torch.utils.data\n\nfile_path_0 = [f for f in listdir(\"data/0\") if isfile(join(\"data/0\", f))]\nfile_path_1 = [f for f in listdir(\"data/1\") if isfile(join(\"data/1\", f))]\n\ndata_x = []\ndata_y = []\n\nfor i in range(len(file_path_0)):\n    image = cv2.imread(\"data/0/\" + file_path_0[i])\n    # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    data_x.append(image)\n    data_y.append(0)\n\nfor i in range(len(file_path_1)):\n    image = cv2.imread(\"data/1/\" + file_path_1[i])\n    # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    data_x.append(image)\n    data_y.append(1)\n\ndata_x = np.array(data_x).astype(np.double) / 255\ndata_y = np.array(data_y).astype(np.double).reshape(-1, 1)\n\ndata_x, data_y = shuffle(data_x, data_y)\n\nt_data_x = torch.stack([torch.Tensor(i) for i in data_x])  # transform to torch tensors\nt_data_y = torch.stack([torch.tensor(i, dtype=torch.float) for i in data_y])\n\n##############################\n\nbatch_size = 10\n\nt_dataset = torch.utils.data.TensorDataset(t_data_x, t_data_y)  # create your dataset\n\ntrain_size = int(0.8 * len(t_dataset))\ntest_size = len(t_dataset) - train_size\ntrain_dataset, test_dataset = torch.utils.data.random_split(t_dataset, [train_size, test_size])\n\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)  # create your dataloader\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)  # create your dataloader\n\n\nclass Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n\n        self.conv1 = nn.Conv2d(720, 10, kernel_size=3)\n        self.conv2 = nn.Conv2d(10, 5, kernel_size=3)\n\n        self.mp1 = nn.MaxPool2d(5)\n\n        self.fc = nn.Linear(2550, 1)\n\n    def forward(self, x):\n        in_size = x.size(0)\n        x = F.relu(self.mp1(self.conv1(x)))\n        x = x.view(in_size, -1)  # Dense\n        x = self.fc(x)\n        x = F.sigmoid(x)\n\n        return x\n\n\nmodel = Net()\n\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\n\ndef train(epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_dataloader):\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.binary_cross_entropy(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 10 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_dataloader.dataset),\n                       100. * batch_idx / len(train_dataloader),\n                loss.data.item()))\n\n\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_dataloader:\n        data, target = Variable(data, requires_grad=True), Variable(target)\n        output = model(data)\n        # sum up batch loss\n        test_loss += F.binary_cross_entropy(output, target, size_average=False).data.item()\n        # get the index of the max log-probability\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred \\\n            .eq(target\n                .data\n                .view_as(pred).long()) \\\n            .cpu() \\\n            .sum()\n\n    test_loss /= len(test_dataloader.dataset)\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_dataloader.dataset),\n        100. * correct / len(test_dataloader.dataset)))\n\n\nfor epoch in range(1, 10):\n    train(epoch)\n    test()\n\n</code></pre>\n\n<blockquote>\n  <p>Train Epoch: 7 [0/249 (0%)]   Loss: 0.537067 Train Epoch: 7 [100/249\n  (40%)]    Loss: 0.597774 Train Epoch: 7 [200/249 (80%)]   Loss: 0.554897\n  Test set: Average loss: 0.5094, Accuracy: 37/63 (58%) Train Epoch: 8\n  [0/249 (0%)]  Loss: 0.481739 Train Epoch: 8 [100/249 (40%)]   Loss:\n  0.564388 Train Epoch: 8 [200/249 (80%)]   Loss: 0.517878 Test set: Average loss: 0.4522, Accuracy: 37/63 (58%) Train Epoch: 9 [0/249\n  (0%)] Loss: 0.420650 Train Epoch: 9 [100/249 (40%)]   Loss: 0.521278\n  Train Epoch: 9 [200/249 (80%)]    Loss: 0.480884 Test set: Average loss:\n  0.3944, Accuracy: 37/63 (58%)</p>\n</blockquote>\n",
                "tags": "<python><image-classification><pytorch>",
                "answers": [
                    [
                        "56342",
                        "2",
                        "55907",
                        "",
                        "",
                        "<p>Such a difference in Loss and Accuracy happens. It's pretty normal. The accuracy just shows how much you got right out of your samples. So in your case, your accuracy was 37/63 in 9th epoch.</p>\n\n<p>When calculating loss, however, you also take into account how well your model is predicting the correctly predicted images. When the loss decreases but accuracy stays the same, you probably better predict the images you already predicted. Maybe your model was 80% sure that it got the right class at some inputs, now it gets it with 90%. Hope that makes sense.  </p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5815",
            "_score": 4.3371677,
            "_source": {
                "title": "How do I calculate for each person in the network how many people agree with their opinion?",
                "content": "How do I calculate for each person in the network how many people agree with their opinion? <p>I have a signed bipartite graph in which the <strong>nodes</strong> are (1) students and (2) topics. An <strong>edge</strong> is drawn between a student and topic node if the student mentions their opinion about the topic in a short answer (i.e., some students have an opinion about one topic but not another). The <strong>valence</strong> of the edge indicates whether the opinion is positive or negative.</p>\n\n<p>My question is: how do I find out how many other students agree with a particular student? In terms of not just which topics they have an opinion on, but also what that opinion is (positive/negative).</p>\n\n<p>EDIT: Based on a comment below</p>\n\n<p>1) What exactly do you mean by agree? Should all existing opinions align or only those on a specific topic? What if one student has additional opinions about a topic? </p>\n\n<p>All existing opinions (including topics and the valence) should align. If a student gives an same opinion about the same topics as another, but happens to talk about another topic as well, that would not count as full agreement. Perhaps there is a way to calculate partial agreement as well?</p>\n\n<p>2) What exactly is your problem? Defining the characteristics is straightforward: Just count. Do you perhaps struggle with an algorithmic implementation? </p>\n\n<p>Algorithmic implementation is perhaps what I am going for. Since I have 100 students, it would be difficult to hand-count the number of peers that agree with them. So if there is a way to calculate a value for each student, that would be helpful.</p>\n <social-network-analysis><p>As a fast answer, you can represent each student as a vector with $K$ elements (where $K$ is the number of topics) and values $\\{+1, 0, -1\\}$, denoting positive/non-existent/negative opinion about this topic.</p>\n\n<p>Then, a simple measure of agreement between two students is the element-wise product between two student-vectors. That is the product will be:\n$similarity = \\sum_{i=1}^{K}st_1[i]*st_2[i]$, where $st_1,st_2$ are the student-vectors. Obviously, only the topics where both students have aligned opinions will boost the total [e.g. $1*1=1$ and $(-1)*(-1)=1]$, while misaligned opinions will decrease the sum. If any of the two students haven't expressed an opinion about a topic, then this topic won't matter in the sum.</p>\n\n<p>In that sense, you can find the most like-minded students to a specific student, as the ones with the highest $similarity$. If what you really need is a number of agreeing students for each unique student, then a threshold on the $similarity$ score can be set. The value of the threshold can be decided empirically from your data.</p>\n\n<p>This is easily implemented and if you are comfortable with coding, I could post a sample script in python. One thing to consider though, is in what format is the bipartite graph (a .csv, a graph file of some kind etc.).</p>\n\n<p>EDIT: MINOR EXAMPLE. Fetch example .csv file used from <a href=\"https://expirebox.com/download/dc66b2ff0111bf53e327635772902c6a.html\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\n\n# Change location of file according to your needs\nwith open('students_example.csv', 'r') as f:\n    df = pd.read_csv(f)\n# Print for visualization\nprint(df.head())\nprint(\"~\"*25)\n\n# Delete column containing the student_id\ndel df['Student_ID']\n# Parse the pandas DataFrame as matrix\nstudent_vectors = df.as_matrix()\n# The number of students at hand, let it be N.\nN_students = student_vectors.shape[0]\n# Initialize empty matrix of similarity between students\n# Its size will be NxN (each student with each other)\nsimilarity_scores = np.zeros((N_students, N_students))\n# Iterate over each student vector and calculate the\n# similarity with all students\nfor i, student in enumerate(student_vectors):\n    # Reshaping and transposing to get the dot product between each student\n    # And all the student vectors\n    similarity_scores[i,:] = np.dot(student.reshape(1,-1), student_vectors.T)\n# Fill the diagonal (that is the similarity of each student with him/herself)\n# with low similarity scores so as not to confuse them with other possibly\n# agreeing students\nnp.fill_diagonal(similarity_scores, -1000)\n\n# Random wanted student for example purposes\nwanted_id = 3\n# Print Students Opinion\nprint(\"Wanted Students Opinion:\")\nprint(df.loc[wanted_id].to_string())\nprint(\"~\"*25)\nprint(\"Most similar:(Student ID = %d)\"% np.argsort(similarity_scores[wanted_id,:])[::-1][0])\nprint df.loc[np.argsort(similarity_scores[wanted_id,:])[::-1][0]].to_string()\nprint(\"~\"*25)\nprint(\"Second most similar:(Student ID = %d)\"% np.argsort(similarity_scores[wanted_id,:])[::-1][1])\nprint df.loc[np.argsort(similarity_scores[wanted_id,:])[::-1][1]].to_string()\nprint(\"~\"*25)\n</code></pre>\n\n<p>If you follow the example, the output for the wanted student (with $student_{ID}=3$) with opinions: {Trump -1, Net Neutrality   -1,Vaccination 1, Obamacare -1}</p>\n\n<p>will give you two other students with the same opinions and their ids.</p>\n\n<p>You can modify the script to fit your needs accordingly.</p>\n\n<p>P.S.: Sorry for the messy code, it was written rather hastily. Also, i tried it with Python 2.7.</p>\n",
                "codes": [
                    [
                        "import pandas as pd\nimport numpy as np\n\n# Change location of file according to your needs\nwith open('students_example.csv', 'r') as f:\n    df = pd.read_csv(f)\n# Print for visualization\nprint(df.head())\nprint(\"~\"*25)\n\n# Delete column containing the student_id\ndel df['Student_ID']\n# Parse the pandas DataFrame as matrix\nstudent_vectors = df.as_matrix()\n# The number of students at hand, let it be N.\nN_students = student_vectors.shape[0]\n# Initialize empty matrix of similarity between students\n# Its size will be NxN (each student with each other)\nsimilarity_scores = np.zeros((N_students, N_students))\n# Iterate over each student vector and calculate the\n# similarity with all students\nfor i, student in enumerate(student_vectors):\n    # Reshaping and transposing to get the dot product between each student\n    # And all the student vectors\n    similarity_scores[i,:] = np.dot(student.reshape(1,-1), student_vectors.T)\n# Fill the diagonal (that is the similarity of each student with him/herself)\n# with low similarity scores so as not to confuse them with other possibly\n# agreeing students\nnp.fill_diagonal(similarity_scores, -1000)\n\n# Random wanted student for example purposes\nwanted_id = 3\n# Print Students Opinion\nprint(\"Wanted Students Opinion:\")\nprint(df.loc[wanted_id].to_string())\nprint(\"~\"*25)\nprint(\"Most similar:(Student ID = %d)\"% np.argsort(similarity_scores[wanted_id,:])[::-1][0])\nprint df.loc[np.argsort(similarity_scores[wanted_id,:])[::-1][0]].to_string()\nprint(\"~\"*25)\nprint(\"Second most similar:(Student ID = %d)\"% np.argsort(similarity_scores[wanted_id,:])[::-1][1])\nprint df.loc[np.argsort(similarity_scores[wanted_id,:])[::-1][1]].to_string()\nprint(\"~\"*25)\n"
                    ]
                ],
                "question_id:": "23018",
                "question_votes:": "1",
                "question_text:": "<p>I have a signed bipartite graph in which the <strong>nodes</strong> are (1) students and (2) topics. An <strong>edge</strong> is drawn between a student and topic node if the student mentions their opinion about the topic in a short answer (i.e., some students have an opinion about one topic but not another). The <strong>valence</strong> of the edge indicates whether the opinion is positive or negative.</p>\n\n<p>My question is: how do I find out how many other students agree with a particular student? In terms of not just which topics they have an opinion on, but also what that opinion is (positive/negative).</p>\n\n<p>EDIT: Based on a comment below</p>\n\n<p>1) What exactly do you mean by agree? Should all existing opinions align or only those on a specific topic? What if one student has additional opinions about a topic? </p>\n\n<p>All existing opinions (including topics and the valence) should align. If a student gives an same opinion about the same topics as another, but happens to talk about another topic as well, that would not count as full agreement. Perhaps there is a way to calculate partial agreement as well?</p>\n\n<p>2) What exactly is your problem? Defining the characteristics is straightforward: Just count. Do you perhaps struggle with an algorithmic implementation? </p>\n\n<p>Algorithmic implementation is perhaps what I am going for. Since I have 100 students, it would be difficult to hand-count the number of peers that agree with them. So if there is a way to calculate a value for each student, that would be helpful.</p>\n",
                "tags": "<social-network-analysis>",
                "answers": [
                    [
                        "23025",
                        "2",
                        "23018",
                        "",
                        "",
                        "<p>As a fast answer, you can represent each student as a vector with $K$ elements (where $K$ is the number of topics) and values $\\{+1, 0, -1\\}$, denoting positive/non-existent/negative opinion about this topic.</p>\n\n<p>Then, a simple measure of agreement between two students is the element-wise product between two student-vectors. That is the product will be:\n$similarity = \\sum_{i=1}^{K}st_1[i]*st_2[i]$, where $st_1,st_2$ are the student-vectors. Obviously, only the topics where both students have aligned opinions will boost the total [e.g. $1*1=1$ and $(-1)*(-1)=1]$, while misaligned opinions will decrease the sum. If any of the two students haven't expressed an opinion about a topic, then this topic won't matter in the sum.</p>\n\n<p>In that sense, you can find the most like-minded students to a specific student, as the ones with the highest $similarity$. If what you really need is a number of agreeing students for each unique student, then a threshold on the $similarity$ score can be set. The value of the threshold can be decided empirically from your data.</p>\n\n<p>This is easily implemented and if you are comfortable with coding, I could post a sample script in python. One thing to consider though, is in what format is the bipartite graph (a .csv, a graph file of some kind etc.).</p>\n\n<p>EDIT: MINOR EXAMPLE. Fetch example .csv file used from <a href=\"https://expirebox.com/download/dc66b2ff0111bf53e327635772902c6a.html\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\n\n# Change location of file according to your needs\nwith open('students_example.csv', 'r') as f:\n    df = pd.read_csv(f)\n# Print for visualization\nprint(df.head())\nprint(\"~\"*25)\n\n# Delete column containing the student_id\ndel df['Student_ID']\n# Parse the pandas DataFrame as matrix\nstudent_vectors = df.as_matrix()\n# The number of students at hand, let it be N.\nN_students = student_vectors.shape[0]\n# Initialize empty matrix of similarity between students\n# Its size will be NxN (each student with each other)\nsimilarity_scores = np.zeros((N_students, N_students))\n# Iterate over each student vector and calculate the\n# similarity with all students\nfor i, student in enumerate(student_vectors):\n    # Reshaping and transposing to get the dot product between each student\n    # And all the student vectors\n    similarity_scores[i,:] = np.dot(student.reshape(1,-1), student_vectors.T)\n# Fill the diagonal (that is the similarity of each student with him/herself)\n# with low similarity scores so as not to confuse them with other possibly\n# agreeing students\nnp.fill_diagonal(similarity_scores, -1000)\n\n# Random wanted student for example purposes\nwanted_id = 3\n# Print Students Opinion\nprint(\"Wanted Students Opinion:\")\nprint(df.loc[wanted_id].to_string())\nprint(\"~\"*25)\nprint(\"Most similar:(Student ID = %d)\"% np.argsort(similarity_scores[wanted_id,:])[::-1][0])\nprint df.loc[np.argsort(similarity_scores[wanted_id,:])[::-1][0]].to_string()\nprint(\"~\"*25)\nprint(\"Second most similar:(Student ID = %d)\"% np.argsort(similarity_scores[wanted_id,:])[::-1][1])\nprint df.loc[np.argsort(similarity_scores[wanted_id,:])[::-1][1]].to_string()\nprint(\"~\"*25)\n</code></pre>\n\n<p>If you follow the example, the output for the wanted student (with $student_{ID}=3$) with opinions: {Trump -1, Net Neutrality   -1,Vaccination 1, Obamacare -1}</p>\n\n<p>will give you two other students with the same opinions and their ids.</p>\n\n<p>You can modify the script to fit your needs accordingly.</p>\n\n<p>P.S.: Sorry for the messy code, it was written rather hastily. Also, i tried it with Python 2.7.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6295",
            "_score": 4.3371677,
            "_source": {
                "title": "Cleaning time series data",
                "content": "Cleaning time series data <p>I have a time series data about daily usage of a computer program, here is an example</p>\n\n<ul>\n<li>2017-11-10: <strong>0</strong></li>\n<li>2017-11-09: <strong>14</strong></li>\n<li>2017-11-08: <strong>0</strong></li>\n<li>2017-11-07: <strong>6</strong></li>\n<li>2017-11-06: <strong>102</strong></li>\n<li>2017-11-05: <strong>0</strong></li>\n<li>2017-11-04: <strong>0</strong></li>\n</ul>\n\n<p>As you can see 11-06 has a spike at 102. Due to our way of gathering this data, we know that data is probably erroneous and we are sure that 102 is not correct according other values.</p>\n\n<p>So we need to clean these dirty values.</p>\n\n<p>Is there a mathematical way to do this?\nIs there a python lib to help us?</p>\n <data-cleaning><p>Here is what I am using:</p>\n\n<pre><code>import numpy as np\nfrom sklearn.cluster import MeanShift, estimate_bandwidth\n\nx = [0,14,0,6,102,0,0]\n\nX = list(zip(x,np.zeros(len(x))))\nbandwidth = estimate_bandwidth(X, quantile=0.2)\nms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\nms.fit(X)\nlabels = ms.labels_\ncluster_centers = ms.cluster_centers_\n\nlabels_unique = np.unique(labels)\nn_clusters_ = len(labels_unique)\n\nX = np.array(X)\nfor k in range(n_clusters_):\n    my_members = labels == k\n    print(k, X[my_members, 0])\n</code></pre>\n\n<p>Source: <a href=\"http://scikit-learn.org/stable/auto_examples/cluster/plot_mean_shift.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/auto_examples/cluster/plot_mean_shift.html</a></p>\n<p>I think you have a few options:</p>\n\n<ul>\n<li>If you have a pre-set rule to exclude outliers, such as a hard-threshold at 100 which you know the data shouldn't exceed, then something as simple as <code>x = [e for e in x if e &lt; 100]</code> will do.</li>\n<li>If you have a parametric belief, such as any observation that falls beyond so many standard deviations from mean, or quartiles, are outliers; then you can implement the other answers that have been mentioned.</li>\n<li><p>Else, you can go for a clustering approach. Here I believe your first shot should be a k-means clustering. This is super easy to build and interpret. See my code below.</p>\n\n<p><code>x = [0,14,0,6,102,0,0]\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=2).fit(np.array(x).reshape(-1, 1))</code></p>\n\n<p><code>#First cluster:\nnp.array(x)[np.where(kmeans.labels_ == 0)]</code></p>\n\n<p><code>#Second cluster (outliers):\nnp.array(x)[np.where(kmeans.labels_ == 1)]</code></p></li>\n<li><p>K-means is known to be sensitive to outliers, hence a more robust method such as MeanShift, which you tried, is a good rival to k-means. I would run both, and stick with the result that makes better sense to me.</p></li>\n</ul>\n\n<p>Hope this helps!</p>\n<p>One solution is using <code>mean</code> and <code>variance</code> to detect outlires in your time-series. For example:</p>\n\n<pre><code>&gt;&gt; data=np.array([0,0,102,6,0,14,0])\n&gt;&gt; c = 1\n&gt;&gt; abs(data - np.mean(data)) &lt; c * np.std(data)\nOutput: array([ True,  True, False,  True,  True,  True,  True], dtype=bool)\n&gt;&gt; clean_data= data[abs(data - np.mean(data)) &lt; c * np.std(data)]\nOutput: array([ 0,  0,  6,  0, 14,  0])\n</code></pre>\n\n<p>you can play with <code>c</code> based on your requirement.</p>\n\n<p>Moreover, instead of using mean and variance of all the data, you can use this method for each section of your time-series separately (e.g. every 30 days). Because there might be different behavior in different time-intervals.</p>\n<p>I would use the Interquartile range (<span class=\"math-container\">$IQR$</span>), where the outliers are the values larger than <span class=\"math-container\">$Q3+1.5 \\times IQR$</span>, and the values less than <span class=\"math-container\">$Q1-1.5 \\times IQR$</span>, where <span class=\"math-container\">$Q1$</span> and <span class=\"math-container\">$Q3$</span> are the first and third quartiles, respectively. <a href=\"https://www.khanacademy.org/math/statistics-probability/summarizing-quantitative-data/box-whisker-plots/a/identifying-outliers-iqr-rule\" rel=\"nofollow noreferrer\">Here</a> is a good example. </p>\n<p>Usually, everyone is trying to remove the outlier which is there in data. Instead, you can replace those outliers with Median or Mean, which can give you better results and trend analysis.</p>\n\n<p>Some references: <a href=\"https://stackoverflow.com/questions/45386955/python-replacing-outliers-values-with-median-values\">Replacing outlier with median</a>, <a href=\"https://datascience.stackexchange.com/questions/33632/remove-local-outliers-from-dataframe-using-pandas\">Remove outlier from data frame</a></p>\n\n<p>In my project, have replaced outliers with the median, and it gave better results.</p>\n",
                "codes": [
                    [
                        "import numpy as np\nfrom sklearn.cluster import MeanShift, estimate_bandwidth\n\nx = [0,14,0,6,102,0,0]\n\nX = list(zip(x,np.zeros(len(x))))\nbandwidth = estimate_bandwidth(X, quantile=0.2)\nms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\nms.fit(X)\nlabels = ms.labels_\ncluster_centers = ms.cluster_centers_\n\nlabels_unique = np.unique(labels)\nn_clusters_ = len(labels_unique)\n\nX = np.array(X)\nfor k in range(n_clusters_):\n    my_members = labels == k\n    print(k, X[my_members, 0])\n"
                    ],
                    [
                        "x = [0,14,0,6,102,0,0]\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=2).fit(np.array(x).reshape(-1, 1))",
                        "#First cluster:\nnp.array(x)[np.where(kmeans.labels_ == 0)]",
                        "#Second cluster (outliers):\nnp.array(x)[np.where(kmeans.labels_ == 1)]"
                    ],
                    [
                        ">> data=np.array([0,0,102,6,0,14,0])\n>> c = 1\n>> abs(data - np.mean(data)) < c * np.std(data)\nOutput: array([ True,  True, False,  True,  True,  True,  True], dtype=bool)\n>> clean_data= data[abs(data - np.mean(data)) < c * np.std(data)]\nOutput: array([ 0,  0,  6,  0, 14,  0])\n"
                    ],
                    [],
                    []
                ],
                "question_id:": "24637",
                "question_votes:": "2",
                "question_text:": "<p>I have a time series data about daily usage of a computer program, here is an example</p>\n\n<ul>\n<li>2017-11-10: <strong>0</strong></li>\n<li>2017-11-09: <strong>14</strong></li>\n<li>2017-11-08: <strong>0</strong></li>\n<li>2017-11-07: <strong>6</strong></li>\n<li>2017-11-06: <strong>102</strong></li>\n<li>2017-11-05: <strong>0</strong></li>\n<li>2017-11-04: <strong>0</strong></li>\n</ul>\n\n<p>As you can see 11-06 has a spike at 102. Due to our way of gathering this data, we know that data is probably erroneous and we are sure that 102 is not correct according other values.</p>\n\n<p>So we need to clean these dirty values.</p>\n\n<p>Is there a mathematical way to do this?\nIs there a python lib to help us?</p>\n",
                "tags": "<data-cleaning>",
                "answers": [
                    [
                        "24639",
                        "2",
                        "24637",
                        "",
                        "",
                        "<p>Here is what I am using:</p>\n\n<pre><code>import numpy as np\nfrom sklearn.cluster import MeanShift, estimate_bandwidth\n\nx = [0,14,0,6,102,0,0]\n\nX = list(zip(x,np.zeros(len(x))))\nbandwidth = estimate_bandwidth(X, quantile=0.2)\nms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\nms.fit(X)\nlabels = ms.labels_\ncluster_centers = ms.cluster_centers_\n\nlabels_unique = np.unique(labels)\nn_clusters_ = len(labels_unique)\n\nX = np.array(X)\nfor k in range(n_clusters_):\n    my_members = labels == k\n    print(k, X[my_members, 0])\n</code></pre>\n\n<p>Source: <a href=\"http://scikit-learn.org/stable/auto_examples/cluster/plot_mean_shift.html\" rel=\"nofollow noreferrer\">http://scikit-learn.org/stable/auto_examples/cluster/plot_mean_shift.html</a></p>\n",
                        "",
                        "1"
                    ],
                    [
                        "24649",
                        "2",
                        "24637",
                        "",
                        "",
                        "<p>I think you have a few options:</p>\n\n<ul>\n<li>If you have a pre-set rule to exclude outliers, such as a hard-threshold at 100 which you know the data shouldn't exceed, then something as simple as <code>x = [e for e in x if e &lt; 100]</code> will do.</li>\n<li>If you have a parametric belief, such as any observation that falls beyond so many standard deviations from mean, or quartiles, are outliers; then you can implement the other answers that have been mentioned.</li>\n<li><p>Else, you can go for a clustering approach. Here I believe your first shot should be a k-means clustering. This is super easy to build and interpret. See my code below.</p>\n\n<p><code>x = [0,14,0,6,102,0,0]\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=2).fit(np.array(x).reshape(-1, 1))</code></p>\n\n<p><code>#First cluster:\nnp.array(x)[np.where(kmeans.labels_ == 0)]</code></p>\n\n<p><code>#Second cluster (outliers):\nnp.array(x)[np.where(kmeans.labels_ == 1)]</code></p></li>\n<li><p>K-means is known to be sensitive to outliers, hence a more robust method such as MeanShift, which you tried, is a good rival to k-means. I would run both, and stick with the result that makes better sense to me.</p></li>\n</ul>\n\n<p>Hope this helps!</p>\n",
                        "",
                        "4"
                    ],
                    [
                        "24638",
                        "2",
                        "24637",
                        "",
                        "",
                        "<p>One solution is using <code>mean</code> and <code>variance</code> to detect outlires in your time-series. For example:</p>\n\n<pre><code>&gt;&gt; data=np.array([0,0,102,6,0,14,0])\n&gt;&gt; c = 1\n&gt;&gt; abs(data - np.mean(data)) &lt; c * np.std(data)\nOutput: array([ True,  True, False,  True,  True,  True,  True], dtype=bool)\n&gt;&gt; clean_data= data[abs(data - np.mean(data)) &lt; c * np.std(data)]\nOutput: array([ 0,  0,  6,  0, 14,  0])\n</code></pre>\n\n<p>you can play with <code>c</code> based on your requirement.</p>\n\n<p>Moreover, instead of using mean and variance of all the data, you can use this method for each section of your time-series separately (e.g. every 30 days). Because there might be different behavior in different time-intervals.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "24640",
                        "2",
                        "24637",
                        "",
                        "",
                        "<p>I would use the Interquartile range (<span class=\"math-container\">$IQR$</span>), where the outliers are the values larger than <span class=\"math-container\">$Q3+1.5 \\times IQR$</span>, and the values less than <span class=\"math-container\">$Q1-1.5 \\times IQR$</span>, where <span class=\"math-container\">$Q1$</span> and <span class=\"math-container\">$Q3$</span> are the first and third quartiles, respectively. <a href=\"https://www.khanacademy.org/math/statistics-probability/summarizing-quantitative-data/box-whisker-plots/a/identifying-outliers-iqr-rule\" rel=\"nofollow noreferrer\">Here</a> is a good example. </p>\n",
                        "",
                        "1"
                    ],
                    [
                        "51498",
                        "2",
                        "24637",
                        "",
                        "",
                        "<p>Usually, everyone is trying to remove the outlier which is there in data. Instead, you can replace those outliers with Median or Mean, which can give you better results and trend analysis.</p>\n\n<p>Some references: <a href=\"https://stackoverflow.com/questions/45386955/python-replacing-outliers-values-with-median-values\">Replacing outlier with median</a>, <a href=\"https://datascience.stackexchange.com/questions/33632/remove-local-outliers-from-dataframe-using-pandas\">Remove outlier from data frame</a></p>\n\n<p>In my project, have replaced outliers with the median, and it gave better results.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7094",
            "_score": 4.3371677,
            "_source": {
                "title": "Can someone spot anything wrong with my LSTM forex model?",
                "content": "Can someone spot anything wrong with my LSTM forex model? <p>The model below reads in data from a csv file (date, open, high, low, close, volume), arranges the data and then builds a LSTM model trying to predict next day's close based on a number of previous days close values.</p>\n\n<p>However, validation accuracy is about 53.8% no matter if i...\n- change hyperparameters\n- make it a deep model\n- uses many more features than just close</p>\n\n<p><a href=\"https://i.stack.imgur.com/tRVvn.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/tRVvn.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>To test if I made a simple mistake I generated another data source that was a signal I created from adding sin, cosine and a little noise so that i KNEW a model should be able to be trained and it was. The model below got about 94% validation without any tuning.</p>\n\n<p>With that in mind. How come when I try to use it on actual data (eurusd 1-min data) it doesn't seem to work..?</p>\n\n<p>Anyone that sees an error or can point me in the right direction?</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\n\nfpath = 'Data/'\nfname = 'EURUSD_M1_1'\ndf = pd.read_csv(fpath + fname + '_clean.csv')\n# file contains date, open, high, low, close, volume\n\n# \"y\" is whether the next period's Close value is higher or lower than current Close value\noutlook = 1\ndf['y'] = df['Close']&lt;df['Close'].shift(-outlook)\n\n# Drop all NAN's\ndf.dropna(how=\"any\",inplace=True)\n\n# Get X and y. To keep it simple, just use Close\nX_df = df['Close']\n\n# \"y\" is whether the next period's Close value is higher or lower than current Close value\noutlook = 1\ny_df = df['Close']&lt;df['Close'].shift(-outlook)\n\n# Train/test split\ndef train_test_split(X_df,y_df,train_perc):\n    idx = int(train_perc/100*X_df.shape[0])\n    X_train_df = X_df.iloc[0:idx]\n    X_test_df = X_df.iloc[idx:]\n    y_train_df = y_df.iloc[0:idx]\n    y_test_df = y_df.iloc[idx:]\n    return X_train_df.as_matrix(), X_test_df.as_matrix(), y_train_df.as_matrix(), y_test_df.as_matrix()\n\nX_train_df, X_test_df, y_train, y_test = train_test_split(X_df,y_df,90)\n\n# Scaling\ndef scale(X):\n    Xmax = max(X)\n    Xmin = min(X)\n    return (X-Xmin)/(Xmax - Xmin)\n\nX_train_scaled = scale(X_train_df)\nX_test_scaled = scale(X_test_df)\n\n# Build the model\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense\n\n# ### Constants\nnum_time_steps = 5   # Num of steps in batch (also used for prediction steps into the future)\nnum_features = 1   # Number of features\nnum_neurons = 97\nnum_outputs = 1 # Just one output (True/False), predicted time series\nlearning_rate = 0.0001 # learning rate, 0.0001 default, but you can play with this\nnb_epochs = 10 # how many iterations to go through (training steps), you can play with this\nbatch_size = 32\n\n# Reshaping\nX_train_scaled = np.reshape(X_train_scaled,[-1,1])\nnb_samples_train = X_train_scaled.shape[0]  - num_time_steps\n\nX_train_scaled_reshaped = np.zeros((nb_samples_train, num_time_steps, num_features))\ny_train_reshaped = np.zeros((nb_samples_train))\n\nfor i in range(nb_samples_train):\n    y_position = i + num_time_steps\n    X_train_scaled_reshaped[i] = X_train_scaled[i:y_position]\n    y_train_reshaped[i] = y_train[y_position]\n\nmodel = Sequential()\n\nstacked = False\nif stacked == True:\n    model.add(LSTM(num_neurons, return_sequences=True, input_shape=(num_time_steps,num_features), activation='relu', dropout=0.5))\n    model.add(LSTM(num_neurons, activation='relu', dropout=0.5))\nelse:\n    model.add(LSTM(num_neurons, input_shape=(num_time_steps,num_features), activation='relu', dropout=0.5))\n\nmodel.add(Dense(units=num_outputs, activation='sigmoid'))\n\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(X_train_scaled_reshaped,\n                    y_train_reshaped,\n                    batch_size = batch_size,\n                    epochs = nb_epochs,\n                    validation_split=0.3)\n</code></pre>\n <lstm><p>What you are up against is this fundamental property of most tradable, liquid financial price series, and that is, they are Brownian Motion. In discrete time, it's also known as random walk.</p>\n\n<p>The most important property of Brownian Motion is that it's memoryless, whose mathematical expression is</p>\n\n<p>$E[p_{t+1} | p_{-{\\infty} : t}] = p_t$</p>\n\n<p>Recurrent neural net, particularly the LSTM flavor, is very powerful in capturing and modeling a long memory process. In fact, it was invented to deal with state that depends on itself many time steps ago (that famous LSTM paper was dated 20 yrs ago[1]). </p>\n\n<p>What you've demonstrated using RNN (assuming your code and training are free of bug) is precisely this property. Put it another way, there is no way to beat a fair coin in predicting tomorrow's FX price.</p>\n\n<p>Another perspective on your attempt. If such naive model could accurately predict FX time series, it would have been exploited by the whales in the hedge fund industry long ago and the opportunity would cease to exist.</p>\n\n<p>[1] Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8), 1735-1780. </p>\n",
                "codes": [
                    []
                ],
                "question_id:": "26871",
                "question_votes:": "2",
                "question_text:": "<p>The model below reads in data from a csv file (date, open, high, low, close, volume), arranges the data and then builds a LSTM model trying to predict next day's close based on a number of previous days close values.</p>\n\n<p>However, validation accuracy is about 53.8% no matter if i...\n- change hyperparameters\n- make it a deep model\n- uses many more features than just close</p>\n\n<p><a href=\"https://i.stack.imgur.com/tRVvn.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/tRVvn.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>To test if I made a simple mistake I generated another data source that was a signal I created from adding sin, cosine and a little noise so that i KNEW a model should be able to be trained and it was. The model below got about 94% validation without any tuning.</p>\n\n<p>With that in mind. How come when I try to use it on actual data (eurusd 1-min data) it doesn't seem to work..?</p>\n\n<p>Anyone that sees an error or can point me in the right direction?</p>\n\n<pre><code>import pandas as pd\nimport numpy as np\n\nfpath = 'Data/'\nfname = 'EURUSD_M1_1'\ndf = pd.read_csv(fpath + fname + '_clean.csv')\n# file contains date, open, high, low, close, volume\n\n# \"y\" is whether the next period's Close value is higher or lower than current Close value\noutlook = 1\ndf['y'] = df['Close']&lt;df['Close'].shift(-outlook)\n\n# Drop all NAN's\ndf.dropna(how=\"any\",inplace=True)\n\n# Get X and y. To keep it simple, just use Close\nX_df = df['Close']\n\n# \"y\" is whether the next period's Close value is higher or lower than current Close value\noutlook = 1\ny_df = df['Close']&lt;df['Close'].shift(-outlook)\n\n# Train/test split\ndef train_test_split(X_df,y_df,train_perc):\n    idx = int(train_perc/100*X_df.shape[0])\n    X_train_df = X_df.iloc[0:idx]\n    X_test_df = X_df.iloc[idx:]\n    y_train_df = y_df.iloc[0:idx]\n    y_test_df = y_df.iloc[idx:]\n    return X_train_df.as_matrix(), X_test_df.as_matrix(), y_train_df.as_matrix(), y_test_df.as_matrix()\n\nX_train_df, X_test_df, y_train, y_test = train_test_split(X_df,y_df,90)\n\n# Scaling\ndef scale(X):\n    Xmax = max(X)\n    Xmin = min(X)\n    return (X-Xmin)/(Xmax - Xmin)\n\nX_train_scaled = scale(X_train_df)\nX_test_scaled = scale(X_test_df)\n\n# Build the model\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense\n\n# ### Constants\nnum_time_steps = 5   # Num of steps in batch (also used for prediction steps into the future)\nnum_features = 1   # Number of features\nnum_neurons = 97\nnum_outputs = 1 # Just one output (True/False), predicted time series\nlearning_rate = 0.0001 # learning rate, 0.0001 default, but you can play with this\nnb_epochs = 10 # how many iterations to go through (training steps), you can play with this\nbatch_size = 32\n\n# Reshaping\nX_train_scaled = np.reshape(X_train_scaled,[-1,1])\nnb_samples_train = X_train_scaled.shape[0]  - num_time_steps\n\nX_train_scaled_reshaped = np.zeros((nb_samples_train, num_time_steps, num_features))\ny_train_reshaped = np.zeros((nb_samples_train))\n\nfor i in range(nb_samples_train):\n    y_position = i + num_time_steps\n    X_train_scaled_reshaped[i] = X_train_scaled[i:y_position]\n    y_train_reshaped[i] = y_train[y_position]\n\nmodel = Sequential()\n\nstacked = False\nif stacked == True:\n    model.add(LSTM(num_neurons, return_sequences=True, input_shape=(num_time_steps,num_features), activation='relu', dropout=0.5))\n    model.add(LSTM(num_neurons, activation='relu', dropout=0.5))\nelse:\n    model.add(LSTM(num_neurons, input_shape=(num_time_steps,num_features), activation='relu', dropout=0.5))\n\nmodel.add(Dense(units=num_outputs, activation='sigmoid'))\n\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(X_train_scaled_reshaped,\n                    y_train_reshaped,\n                    batch_size = batch_size,\n                    epochs = nb_epochs,\n                    validation_split=0.3)\n</code></pre>\n",
                "tags": "<lstm>",
                "answers": [
                    [
                        "26876",
                        "2",
                        "26871",
                        "",
                        "",
                        "<p>What you are up against is this fundamental property of most tradable, liquid financial price series, and that is, they are Brownian Motion. In discrete time, it's also known as random walk.</p>\n\n<p>The most important property of Brownian Motion is that it's memoryless, whose mathematical expression is</p>\n\n<p>$E[p_{t+1} | p_{-{\\infty} : t}] = p_t$</p>\n\n<p>Recurrent neural net, particularly the LSTM flavor, is very powerful in capturing and modeling a long memory process. In fact, it was invented to deal with state that depends on itself many time steps ago (that famous LSTM paper was dated 20 yrs ago[1]). </p>\n\n<p>What you've demonstrated using RNN (assuming your code and training are free of bug) is precisely this property. Put it another way, there is no way to beat a fair coin in predicting tomorrow's FX price.</p>\n\n<p>Another perspective on your attempt. If such naive model could accurately predict FX time series, it would have been exploited by the whales in the hedge fund industry long ago and the opportunity would cease to exist.</p>\n\n<p>[1] Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8), 1735-1780. </p>\n",
                        "",
                        "4"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4838",
            "_score": 4.239605,
            "_source": {
                "title": "RNN for classification giving vastly different results (Keras)",
                "content": "RNN for classification giving vastly different results (Keras) <p>I have a time series data (counts of number of infectious individuals per day), and I am using a SimpleRNN from Keras to classify each of these epidemics into one of eight possible classes.</p>\n\n<p>I used cross-validation to select the best number of hidden units, etc. My problem is that when I run the chosen model multiple times (that is, when I train the model multiple times with the same architecture), I get very different results. I'm guessing this is a problem of many local minima, but I'm not sure - it could just be a problem with training. How can I diagnose this? I've done the following:</p>\n\n<ul>\n<li><p>Removed the patience term - I thought I might not be training long enough, and the wildly different classification errors were due to that.</p></li>\n<li><p>Changed my activation functions to ReLUs instead of using the default tanh units - maybe there's some saturation going on.</p></li>\n<li><p>Changed my <code>load_data</code> function to scale the input data (which are integers).</p></li>\n</ul>\n\n<p>Can anyone think of anything else that I could do to try to figure out why the same code is giving me different classification errors?</p>\n\n<p>EDIT: More information - I'm using an RNN for an 8-class classification task. There are 200 observations per class in the test set. I obtain confusion matrices for each of the 10 runs shown in the code below. Here are two of the confusion matrices:</p>\n\n<pre><code>189,0,0,0,0,11,0,0\n0,197,0,0,0,3,0,0\n0,0,199,0,0,1,0,0\n1,0,0,195,0,0,0,4\n0,0,0,0,200,0,0,0\n26,0,0,0,0,174,0,0\n0,0,0,0,0,0,200,0\n0,0,0,0,0,0,5,195\n</code></pre>\n\n<p>That one's pretty good. It has an average classification error of 0.032. </p>\n\n<p>(EDIT 2) Here is a plot of the training and validation accuracy for the well-performing run:</p>\n\n<p><a href=\"https://i.stack.imgur.com/hz6VF.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/hz6VF.png\" alt=\"trainval0\"></a></p>\n\n<p>This one, however, is much worse (average classification error of 0.389):</p>\n\n<pre><code>192,0,0,0,0,8,0,0\n0,181,0,0,0,19,0,0\n44,3,106,39,3,5,0,0\n0,0,3,168,29,0,0,0\n0,7,0,0,193,0,0,0\n62,2,0,0,0,136,0,0\n32,33,49,35,31,20,0,0\n27,20,48,46,37,20,0,2\n</code></pre>\n\n<p>(EDIT 2) Here is a plot of the training and validation accuracy for the badly performing run (looks awful):</p>\n\n<p><a href=\"https://i.stack.imgur.com/Di3i8.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Di3i8.png\" alt=\"trainval1\"></a></p>\n\n<p>(EDIT 2) New thought: could this be because of bad initial conditions after all? Why else would some runs be good and some be so bad?</p>\n\n<p>Here is the code (EDITED to show the last two changes in the bullet points):</p>\n\n<pre><code>    #!/usr/bin/env python\n\n    import numpy as np\n    import pandas, math, sys, keras\n    from keras import optimizers\n    from keras.models import Sequential\n    from keras.layers import Dense, SimpleRNN\n    from keras.regularizers import l2\n    from keras.utils import np_utils\n    from keras.utils.np_utils import to_categorical\n\n  def load_data(train_file, test_file):\n        trainset = np.loadtxt(train_file, delimiter=\",\")\n\n        # split into input (X) and output (Y) variables\n        X = trainset[:, 0:(trainset.shape[1]-2)] \n        Y = (trainset[:,trainset.shape[1]-1]).astype(int) \n\n        scaler = MinMaxScaler(feature_range=(0, 1))\n        X_scaled = scaler.fit_transform(X)\n\n        y_binary = to_categorical(Y)\n\n        testset = np.loadtxt(test_file, delimiter=\",\")\n        X_test = testset[:,0:(testset.shape[1]-2)]\n        X_test_scaled = scaler.fit_transform(X_test)\n\n        Y_test = (testset[:,testset.shape[1]-1]).astype(int)\n\n        X_train = np.reshape(X, (X.shape[0], X.shape[1], 1))\n        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n\n        ytest_binary = to_categorical(Y_test)\n\n        return (X_train, y_binary, X_test, ytest_binary)\n\n    def get_confusion_matrix_one_hot(model_results, truth):\n        '''model_results and truth should be for one-hot format, i.e, have &gt;= 2 columns,\n        where truth is 0/1, and max along each row of model_results is model result\n        '''\n        assert model_results.shape == truth.shape\n        num_outputs = truth.shape[1]\n        confusion_matrix = np.zeros((num_outputs, num_outputs), dtype=np.int32)\n        predictions = np.argmax(model_results,axis=1)\n        assert len(predictions)==truth.shape[0]\n\n        for actual_class in range(num_outputs):\n            idx_examples_this_class = truth[:,actual_class]==1\n            prediction_for_this_class = predictions[idx_examples_this_class]\n            for predicted_class in range(num_outputs):\n                count = np.sum(prediction_for_this_class==predicted_class)\n                confusion_matrix[actual_class, predicted_class] = count\n        assert np.sum(confusion_matrix)==len(truth)\n        assert np.sum(confusion_matrix)==np.sum(truth)\n        return confusion_matrix\n\n    def rnn_repeat(X, Y, Xtest, Ytest, params_to_use, save_file=\"rnn_twolayer_acc_loss\", num_reps=10):\n\n        def rnn_model(hid_dim=10, ker_reg=0.01, rec_reg=0.01, optimizer=\"sgd\"):\n                model = Sequential()\n                model.add(SimpleRNN(units=hid_dim, activation='relu', input_shape = (X.shape[1], X.shape[2]), kernel_regularizer=l2(ker_reg), recurrent_regularizer = l2(rec_reg), return_sequences = False))\n                model.add(Dense(Y.shape[1], activation='softmax'))\n                model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n                print 'fitting a model'\n                return model\n\n        optim = params_to_use['optimizer']\n        ker_reg_best = params_to_use['ker_reg']\n        hid_val = params_to_use['hid_dim']\n        rec_reg_best = params_to_use['rec_reg']\n\n        #Need this for all classification errors\n        class_error = []\n\n        #X has 6400 examples, 800 of each class (8 classes). Take 20% of each class and make this the validation set.\n        to_take = np.random.choice(800, int(800*0.2), replace=False)\n        class_split = np.array_split(X, 8) #16 equal slices of 800 elements each\n        val_list = [x[to_take] for x in class_split]\n        big_list = [item for sublist in val_list for item in sublist]\n        val_X = np.asarray(big_list)\n        label_set = np.arange(0, 8) #0 to 15\n        val_Y = np.repeat(label_set, int(800*0.2))\n        val_Y = to_categorical(val_Y)\n\n        setdiffval = set(range(800)) - set(to_take)\n        setdiffval = list(setdiffval)\n\n        X_train_vals = [x[setdiffval] for x in class_split]\n        X_train = [item for sublist in X_train_vals for item in sublist]\n        X_train = np.asarray(X_train)\n        Y_train = np.repeat(label_set, int(800*0.8))\n        Y_train = to_categorical(Y_train)\n\n        for j in range(num_reps):\n            model = rnn_model(hid_dim=hid_val, ker_reg=ker_reg_best, rec_reg=rec_reg_best, optimizer=optim)\n            hist = model.fit(X_train, Y_train, validation_data=(val_X, val_Y), epochs=200)\n            h1 = hist.history\n            acc_ = np.asarray(h1['acc'])\n            loss_ = np.asarray(h1['loss'])\n            val_loss_ = np.asarray(h1['val_loss'])\n            val_acc_ = np.asarray(h1['val_acc'])\n\n            #Save the accuracy and loss\n            acc_and_loss = np.column_stack((acc_, loss_, val_acc_, val_loss_))\n            save_file_rnn = save_file + '_' + str(j) + '.txt'\n            with open(save_file_rnn, 'w') as f:\n                    np.savetxt(save_file_rnn, acc_and_loss, delimiter=\" \")\n            print 'saved file', save_file_rnn\n\n            #Run the final, trained model on the test set and return a confusion matrix\n            test_scores = model.evaluate(Xtest, Ytest) #evaluate returns the metric 'accuracy' on the test set\n            print 'eval_scores', test_scores[1]*100\n            predict = model.predict(Xtest) #I think predict returns the class probabilities\n            con_mat = get_confusion_matrix_one_hot(predict, Ytest)\n            print con_mat\n\n            #Save the confusion matrix\n            save_con_mat = 'confusionmatrix_rnn' + '_' + str(j) + '.txt'\n            np.savetxt(save_con_mat, con_mat, fmt='%i', delimiter=\",\")\n\n            #Get the classification error per class, and the average classification error\n            class_error_j = []\n            for i in range(0, con_mat.shape[1]): #for the number of classes\n                class_i_correct = float(con_mat[i][i])/float(sum(con_mat[i]))\n                class_error_j.append(1. - class_i_correct)\n\n            class_error_j.append(sum(class_error_j)/con_mat.shape[1]) #the average classification error\n            class_error.append(class_error_j) #each class's classification error, and the average classification error for this run\n\n        np.savetxt('class_error.txt', class_error, fmt = '%1.3f', delimiter=' ')\n\n        return 0\n\n    if __name__=='__main__':\n\n        X, Y, Xtest, Ytest = load_data('train.csv', 'test.csv')\n        best_params = {'rec_reg': 0.01, 'optimizer': 'adam', 'ker_reg': 0.1, 'hid_dim': 15} \n        rnn_repeat(X, Y, Xtest, Ytest, best_params)\n</code></pre>\n <classification><keras><rnn>",
                "codes": [],
                "question_id:": "18986",
                "question_votes:": "1",
                "question_text:": "<p>I have a time series data (counts of number of infectious individuals per day), and I am using a SimpleRNN from Keras to classify each of these epidemics into one of eight possible classes.</p>\n\n<p>I used cross-validation to select the best number of hidden units, etc. My problem is that when I run the chosen model multiple times (that is, when I train the model multiple times with the same architecture), I get very different results. I'm guessing this is a problem of many local minima, but I'm not sure - it could just be a problem with training. How can I diagnose this? I've done the following:</p>\n\n<ul>\n<li><p>Removed the patience term - I thought I might not be training long enough, and the wildly different classification errors were due to that.</p></li>\n<li><p>Changed my activation functions to ReLUs instead of using the default tanh units - maybe there's some saturation going on.</p></li>\n<li><p>Changed my <code>load_data</code> function to scale the input data (which are integers).</p></li>\n</ul>\n\n<p>Can anyone think of anything else that I could do to try to figure out why the same code is giving me different classification errors?</p>\n\n<p>EDIT: More information - I'm using an RNN for an 8-class classification task. There are 200 observations per class in the test set. I obtain confusion matrices for each of the 10 runs shown in the code below. Here are two of the confusion matrices:</p>\n\n<pre><code>189,0,0,0,0,11,0,0\n0,197,0,0,0,3,0,0\n0,0,199,0,0,1,0,0\n1,0,0,195,0,0,0,4\n0,0,0,0,200,0,0,0\n26,0,0,0,0,174,0,0\n0,0,0,0,0,0,200,0\n0,0,0,0,0,0,5,195\n</code></pre>\n\n<p>That one's pretty good. It has an average classification error of 0.032. </p>\n\n<p>(EDIT 2) Here is a plot of the training and validation accuracy for the well-performing run:</p>\n\n<p><a href=\"https://i.stack.imgur.com/hz6VF.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/hz6VF.png\" alt=\"trainval0\"></a></p>\n\n<p>This one, however, is much worse (average classification error of 0.389):</p>\n\n<pre><code>192,0,0,0,0,8,0,0\n0,181,0,0,0,19,0,0\n44,3,106,39,3,5,0,0\n0,0,3,168,29,0,0,0\n0,7,0,0,193,0,0,0\n62,2,0,0,0,136,0,0\n32,33,49,35,31,20,0,0\n27,20,48,46,37,20,0,2\n</code></pre>\n\n<p>(EDIT 2) Here is a plot of the training and validation accuracy for the badly performing run (looks awful):</p>\n\n<p><a href=\"https://i.stack.imgur.com/Di3i8.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Di3i8.png\" alt=\"trainval1\"></a></p>\n\n<p>(EDIT 2) New thought: could this be because of bad initial conditions after all? Why else would some runs be good and some be so bad?</p>\n\n<p>Here is the code (EDITED to show the last two changes in the bullet points):</p>\n\n<pre><code>    #!/usr/bin/env python\n\n    import numpy as np\n    import pandas, math, sys, keras\n    from keras import optimizers\n    from keras.models import Sequential\n    from keras.layers import Dense, SimpleRNN\n    from keras.regularizers import l2\n    from keras.utils import np_utils\n    from keras.utils.np_utils import to_categorical\n\n  def load_data(train_file, test_file):\n        trainset = np.loadtxt(train_file, delimiter=\",\")\n\n        # split into input (X) and output (Y) variables\n        X = trainset[:, 0:(trainset.shape[1]-2)] \n        Y = (trainset[:,trainset.shape[1]-1]).astype(int) \n\n        scaler = MinMaxScaler(feature_range=(0, 1))\n        X_scaled = scaler.fit_transform(X)\n\n        y_binary = to_categorical(Y)\n\n        testset = np.loadtxt(test_file, delimiter=\",\")\n        X_test = testset[:,0:(testset.shape[1]-2)]\n        X_test_scaled = scaler.fit_transform(X_test)\n\n        Y_test = (testset[:,testset.shape[1]-1]).astype(int)\n\n        X_train = np.reshape(X, (X.shape[0], X.shape[1], 1))\n        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n\n        ytest_binary = to_categorical(Y_test)\n\n        return (X_train, y_binary, X_test, ytest_binary)\n\n    def get_confusion_matrix_one_hot(model_results, truth):\n        '''model_results and truth should be for one-hot format, i.e, have &gt;= 2 columns,\n        where truth is 0/1, and max along each row of model_results is model result\n        '''\n        assert model_results.shape == truth.shape\n        num_outputs = truth.shape[1]\n        confusion_matrix = np.zeros((num_outputs, num_outputs), dtype=np.int32)\n        predictions = np.argmax(model_results,axis=1)\n        assert len(predictions)==truth.shape[0]\n\n        for actual_class in range(num_outputs):\n            idx_examples_this_class = truth[:,actual_class]==1\n            prediction_for_this_class = predictions[idx_examples_this_class]\n            for predicted_class in range(num_outputs):\n                count = np.sum(prediction_for_this_class==predicted_class)\n                confusion_matrix[actual_class, predicted_class] = count\n        assert np.sum(confusion_matrix)==len(truth)\n        assert np.sum(confusion_matrix)==np.sum(truth)\n        return confusion_matrix\n\n    def rnn_repeat(X, Y, Xtest, Ytest, params_to_use, save_file=\"rnn_twolayer_acc_loss\", num_reps=10):\n\n        def rnn_model(hid_dim=10, ker_reg=0.01, rec_reg=0.01, optimizer=\"sgd\"):\n                model = Sequential()\n                model.add(SimpleRNN(units=hid_dim, activation='relu', input_shape = (X.shape[1], X.shape[2]), kernel_regularizer=l2(ker_reg), recurrent_regularizer = l2(rec_reg), return_sequences = False))\n                model.add(Dense(Y.shape[1], activation='softmax'))\n                model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n                print 'fitting a model'\n                return model\n\n        optim = params_to_use['optimizer']\n        ker_reg_best = params_to_use['ker_reg']\n        hid_val = params_to_use['hid_dim']\n        rec_reg_best = params_to_use['rec_reg']\n\n        #Need this for all classification errors\n        class_error = []\n\n        #X has 6400 examples, 800 of each class (8 classes). Take 20% of each class and make this the validation set.\n        to_take = np.random.choice(800, int(800*0.2), replace=False)\n        class_split = np.array_split(X, 8) #16 equal slices of 800 elements each\n        val_list = [x[to_take] for x in class_split]\n        big_list = [item for sublist in val_list for item in sublist]\n        val_X = np.asarray(big_list)\n        label_set = np.arange(0, 8) #0 to 15\n        val_Y = np.repeat(label_set, int(800*0.2))\n        val_Y = to_categorical(val_Y)\n\n        setdiffval = set(range(800)) - set(to_take)\n        setdiffval = list(setdiffval)\n\n        X_train_vals = [x[setdiffval] for x in class_split]\n        X_train = [item for sublist in X_train_vals for item in sublist]\n        X_train = np.asarray(X_train)\n        Y_train = np.repeat(label_set, int(800*0.8))\n        Y_train = to_categorical(Y_train)\n\n        for j in range(num_reps):\n            model = rnn_model(hid_dim=hid_val, ker_reg=ker_reg_best, rec_reg=rec_reg_best, optimizer=optim)\n            hist = model.fit(X_train, Y_train, validation_data=(val_X, val_Y), epochs=200)\n            h1 = hist.history\n            acc_ = np.asarray(h1['acc'])\n            loss_ = np.asarray(h1['loss'])\n            val_loss_ = np.asarray(h1['val_loss'])\n            val_acc_ = np.asarray(h1['val_acc'])\n\n            #Save the accuracy and loss\n            acc_and_loss = np.column_stack((acc_, loss_, val_acc_, val_loss_))\n            save_file_rnn = save_file + '_' + str(j) + '.txt'\n            with open(save_file_rnn, 'w') as f:\n                    np.savetxt(save_file_rnn, acc_and_loss, delimiter=\" \")\n            print 'saved file', save_file_rnn\n\n            #Run the final, trained model on the test set and return a confusion matrix\n            test_scores = model.evaluate(Xtest, Ytest) #evaluate returns the metric 'accuracy' on the test set\n            print 'eval_scores', test_scores[1]*100\n            predict = model.predict(Xtest) #I think predict returns the class probabilities\n            con_mat = get_confusion_matrix_one_hot(predict, Ytest)\n            print con_mat\n\n            #Save the confusion matrix\n            save_con_mat = 'confusionmatrix_rnn' + '_' + str(j) + '.txt'\n            np.savetxt(save_con_mat, con_mat, fmt='%i', delimiter=\",\")\n\n            #Get the classification error per class, and the average classification error\n            class_error_j = []\n            for i in range(0, con_mat.shape[1]): #for the number of classes\n                class_i_correct = float(con_mat[i][i])/float(sum(con_mat[i]))\n                class_error_j.append(1. - class_i_correct)\n\n            class_error_j.append(sum(class_error_j)/con_mat.shape[1]) #the average classification error\n            class_error.append(class_error_j) #each class's classification error, and the average classification error for this run\n\n        np.savetxt('class_error.txt', class_error, fmt = '%1.3f', delimiter=' ')\n\n        return 0\n\n    if __name__=='__main__':\n\n        X, Y, Xtest, Ytest = load_data('train.csv', 'test.csv')\n        best_params = {'rec_reg': 0.01, 'optimizer': 'adam', 'ker_reg': 0.1, 'hid_dim': 15} \n        rnn_repeat(X, Y, Xtest, Ytest, best_params)\n</code></pre>\n",
                "tags": "<classification><keras><rnn>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4963",
            "_score": 4.0878716,
            "_source": {
                "title": "Predict sinus with keras feed forward neural network",
                "content": "Predict sinus with keras feed forward neural network <p>I have a very simple feed forward neural network with keras that should learn a sinus. Why is the predictive power so bad and what is generally the best way to pinpoint issues with a network?</p>\n\n<p>In the code below, I have one input neuron, 10 in the hidden layer, and one output. I would expect the network to perform much more accurately.</p>\n\n<pre><code>import numpy as np\nfrom keras.layers import Dense, Activation\nfrom keras.models import Sequential\n\nx = np.arange(100)\ny = np.sin(x)\n\nmodel = Sequential([\n    Dense(10, input_shape=(1,)),\n    Activation('sigmoid'),\n    Dense(1),\n    Activation('sigmoid')\n])\n\nmodel.compile(loss='mean_squared_error', optimizer='SGD', metrics=['accuracy'])\nmodel.fit(x, y, epochs=10, batch_size=1)\n\nscores = model.evaluate(x, y, verbose=0)\nprint(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n\nprint(model.predict(np.array([.5])))\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>  1/100 [..............................] - ETA: 0s - loss: 1.2016 - acc: 0.0000e+00\n 79/100 [======================&gt;.......] - ETA: 0s - loss: 0.4665 - acc: 0.0127    \n100/100 [==============================] - 0s - loss: 0.5044 - acc: 0.0100     \nBaseline Error: 99.00%\n[[ 0.35267803]]\n</code></pre>\n <tensorflow><keras><p>Accuracy is a metric meant for classification problems, look at the mean squared error instead. Your network is too small for a highly fluctuating function that you want to learn, if you divide your x by a smaller amount it would be easier to learn. Second of all, adding another layer and having an identity activation at the end will help quite a bit. Also taking batches bigger than 1 will make the gradient more stable. With a 1000 epochs I get to 0.00167 as mean squared error.</p>\n\n<pre><code>x = np.arange(200).reshape(-1,1) / 50\ny = np.sin(x)\n\nmodel = Sequential([\nDense(40, input_shape=(1,)),\nActivation('sigmoid'),\nDense(12),\nActivation('sigmoid'),\nDense(1)\n    ])\n\nmodel.compile(loss='mean_squared_error', optimizer='SGD', metrics=['mean_squared_error'])\n\nfor i in range(40):\n    model.fit(x, y, nb_epoch=25, batch_size=8, verbose=0)\n    predictions = model.predict(x)\n    print(np.mean(np.square(predictions - y)))\n</code></pre>\n\n<p>The biggest issue is that the signal in your original small dataset is very difficult to learn, you can see this when you plot it, it will just collapse to the mean.</p>\n<p>Keep in mind that the <strong>Accuracy</strong> measure is measuring whether the values are <em>Exactly The Same</em>. I.e. it is a classification measure, whereas approximating a sin curve is much better suited for measurement as a regression problem.</p>\n\n<p>That said:</p>\n\n<p>In evaluating the network's performance, what is the network actually doing? Let's take the network and perform a little visual analysis on its performance:</p>\n\n<pre><code>import matplotlib.pyplot as plt\npreds = model.predict(x)\nplt.plot(x, y, 'b', x, preds, 'r--')\nplt.ylabel('Y / Predicted Value')\nplt.xlabel('X Value')\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/e0acv.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/e0acv.png\" alt=\"enter image description here\"></a></p>\n\n<p>Hmm. The model seems to be minimizing error by simply getting closer and closer to guessing 0 for every value, rather than approximating the function. There are several hypotheses here to explain this. One is that the network is not complex enough to model the function. In order to test this, let's simplify the function- that is, let's bring the range down to one sine cycle:</p>\n\n<pre><code>x = np.arange(0, math.pi*2, 0.1)\ny = np.sin(x)\n</code></pre>\n\n<p>And try to train the network again:</p>\n\n<p><a href=\"https://i.stack.imgur.com/8HA7X.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/8HA7X.png\" alt=\"enter image description here\"></a></p>\n\n<p>Not wonderful, but a better fit, certainly.</p>\n\n<p>How about with <strong>100 epochs</strong> instead of 10?</p>\n\n<p><a href=\"https://i.stack.imgur.com/0Q6eS.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/0Q6eS.png\" alt=\"enter image description here\"></a></p>\n\n<p>How about with <strong>1000 epochs</strong>?</p>\n\n<p><a href=\"https://i.stack.imgur.com/Wk7qL.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/Wk7qL.png\" alt=\"enter image description here\"></a></p>\n\n<p>This is, of course, very interesting. After 1000 epochs, our networks is able to roughly approximate the downward curve from 1:0 ($\\pi/2$: $\\pi$) of the sine response, but not the initial upward curve 0:1 (0:$\\pi/2$) or the region in which the function is negative ($\\pi$:$2\\pi$).</p>\n\n<p>This result begs the question- what will it look like after <strong>10000 epochs</strong>?</p>\n\n<p><a href=\"https://i.stack.imgur.com/sxf00.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/sxf00.png\" alt=\"enter image description here\"></a></p>\n\n<p>Not significantly better. It looks like we'll have to change the architecture of the network (more layers, more neurons, and/or different activation functions) to improve beyond this point. </p>\n\n<p>To inform this architecture change, let's take a look at the sigmoid activation function:</p>\n\n<p><a href=\"https://i.stack.imgur.com/pp6kl.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/pp6kl.png\" alt=\"enter image description here\"></a></p>\n\n<p>Uh-oh. The value of this sigmoid function can only ever be in the range 0:1, and the range of the sin function is -1:1. </p>\n\n<p>To correct this, let's just normalize the sin response between 0 and 1:</p>\n\n<pre><code>y = (np.sin(x)+1)/2 \n</code></pre>\n\n<p>Now, the network performs much better than before after 1000 epochs:</p>\n\n<p><a href=\"https://i.stack.imgur.com/X0Nrk.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/X0Nrk.png\" alt=\"enter image description here\"></a></p>\n\n<p>And 10000:</p>\n\n<p><a href=\"https://i.stack.imgur.com/IxcxR.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/IxcxR.png\" alt=\"enter image description here\"></a></p>\n\n<p>After 100000 epochs, it's roughly perfect:</p>\n\n<p><a href=\"https://i.stack.imgur.com/dmbZb.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/dmbZb.png\" alt=\"enter image description here\"></a></p>\n\n<p>Even still, this advancement doesn't help much on the larger sin range (after 1000 epochs):</p>\n\n<pre><code>x = np.arange(0, 100, 1)\ny = (np.sin(x)+1)/2 \n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/6smI5.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/6smI5.png\" alt=\"enter image description here\"></a></p>\n\n<p>If we, however, take the model trained on a single sin curve and further train it on the larger range, we begin to see progress after 1000 epochs:</p>\n\n<pre><code>x = np.arange(0, 100, .1)\ny = (np.sin(x)+1)/2 \n\nmodel_copy = model\nmodel_copy.fit(x, y, epochs=1000, batch_size=8, verbose=0)\nmodel_copy_preds = model_copy.predict(x)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/UW8H2.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/UW8H2.png\" alt=\"enter image description here\"></a></p>\n\n<p>And more so after 10000 epochs:<a href=\"https://i.stack.imgur.com/cmQjw.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/cmQjw.png\" alt=\"enter image description here\"></a></p>\n\n<p>And more so, well into the third repetition after 100000 epochs:</p>\n\n<p><a href=\"https://i.stack.imgur.com/zDPgJ.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/zDPgJ.png\" alt=\"enter image description here\"></a></p>\n\n<p>So, with careful training, our network with a single layer of sigmoid activations appears to be learning to generalize the sin curve. Further investigation could find a limit to that generalization, certainly.</p>\n\n<p>For reproduction:</p>\n\n<pre><code>import numpy as np\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nimport matplotlib.pyplot as plt\nimport math\n\nx = np.arange(0, math.pi*2, .1)\ny = (np.sin(x)+1)/2 \n\nmodel = Sequential([\n    Dense(10, input_shape=(1,)),\n    Activation('sigmoid'),\n    Dense(1)\n])\n\nmodel.compile(loss='mean_squared_error', optimizer='SGD', metrics=['mean_squared_error'])\nmodel.fit(x, y, epochs=100000, batch_size=8, verbose=0)\n\npreds = model.predict(x)\n\nplt.plot(x, y, 'b', x, preds, 'r--')\nplt.ylabel('Y / Predicted Value')\nplt.xlabel('X Value')\nplt.show()\n\nx = np.arange(0, 100, .1)\ny = (np.sin(x)+1)/2 \n\nmodel_copy = model\nmodel_copy.fit(x, y, epochs=10000, batch_size=8, verbose=0)\nmodel_copy_preds = model_copy.predict(x)\n\nplt.plot(x, y, 'b', x, model_copy_preds, 'r--')\nplt.ylabel('Y / Predicted Value')\nplt.xlabel('X Value')\nplt.show()\n</code></pre>\n<p>My code...</p>\n\n<pre><code>from keras.models import Sequential\nfrom keras.layers import Dense\nimport numpy as np\nimport matplotlib.pylab as plt\n\n# Create dataset\nx = np.arange(0, np.pi * 2, 0.1)\ny = np.sin(x)\n\n# Some parameters\nACTIVE_FUN = 'tanh'\nBATCH_SIZE = 1\nVERBOSE=0\n\n# Create the model\nmodel = Sequential()\nmodel.add(Dense(5, input_shape=(1,), activation=ACTIVE_FUN))\nmodel.add(Dense(5, activation=ACTIVE_FUN))\nmodel.add(Dense(1, activation='linear'))\n\n# Compile the model\nmodel.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_squared_error'])\n\n# Fit the model\nmodel.fit(x, y, epochs=1000, batch_size=BATCH_SIZE, verbose=VERBOSE)\n\n# Evaluate the model\nscores = model.evaluate(x, y, verbose=VERBOSE)\nprint('%s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))\n\n# Make predictions\ny_pred = model.predict(x)\n\n# Plot\nplt.plot(x, y, color='blue', linewidth=1, markersize='1')\nplt.plot(x, y_pred, color='green', linewidth=1, markersize='1')\nplt.xlabel('Angle [rad]')\nplt.ylabel('sin(x)')\nplt.axis('tight')\nplt.show()\n</code></pre>\n",
                "codes": [
                    [
                        "x = np.arange(200).reshape(-1,1) / 50\ny = np.sin(x)\n\nmodel = Sequential([\nDense(40, input_shape=(1,)),\nActivation('sigmoid'),\nDense(12),\nActivation('sigmoid'),\nDense(1)\n    ])\n\nmodel.compile(loss='mean_squared_error', optimizer='SGD', metrics=['mean_squared_error'])\n\nfor i in range(40):\n    model.fit(x, y, nb_epoch=25, batch_size=8, verbose=0)\n    predictions = model.predict(x)\n    print(np.mean(np.square(predictions - y)))\n"
                    ],
                    [
                        "import matplotlib.pyplot as plt\npreds = model.predict(x)\nplt.plot(x, y, 'b', x, preds, 'r--')\nplt.ylabel('Y / Predicted Value')\nplt.xlabel('X Value')\nplt.show()\n",
                        "x = np.arange(0, math.pi*2, 0.1)\ny = np.sin(x)\n",
                        "y = (np.sin(x)+1)/2 \n",
                        "x = np.arange(0, 100, 1)\ny = (np.sin(x)+1)/2 \n",
                        "x = np.arange(0, 100, .1)\ny = (np.sin(x)+1)/2 \n\nmodel_copy = model\nmodel_copy.fit(x, y, epochs=1000, batch_size=8, verbose=0)\nmodel_copy_preds = model_copy.predict(x)\n",
                        "import numpy as np\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nimport matplotlib.pyplot as plt\nimport math\n\nx = np.arange(0, math.pi*2, .1)\ny = (np.sin(x)+1)/2 \n\nmodel = Sequential([\n    Dense(10, input_shape=(1,)),\n    Activation('sigmoid'),\n    Dense(1)\n])\n\nmodel.compile(loss='mean_squared_error', optimizer='SGD', metrics=['mean_squared_error'])\nmodel.fit(x, y, epochs=100000, batch_size=8, verbose=0)\n\npreds = model.predict(x)\n\nplt.plot(x, y, 'b', x, preds, 'r--')\nplt.ylabel('Y / Predicted Value')\nplt.xlabel('X Value')\nplt.show()\n\nx = np.arange(0, 100, .1)\ny = (np.sin(x)+1)/2 \n\nmodel_copy = model\nmodel_copy.fit(x, y, epochs=10000, batch_size=8, verbose=0)\nmodel_copy_preds = model_copy.predict(x)\n\nplt.plot(x, y, 'b', x, model_copy_preds, 'r--')\nplt.ylabel('Y / Predicted Value')\nplt.xlabel('X Value')\nplt.show()\n"
                    ],
                    [
                        "from keras.models import Sequential\nfrom keras.layers import Dense\nimport numpy as np\nimport matplotlib.pylab as plt\n\n# Create dataset\nx = np.arange(0, np.pi * 2, 0.1)\ny = np.sin(x)\n\n# Some parameters\nACTIVE_FUN = 'tanh'\nBATCH_SIZE = 1\nVERBOSE=0\n\n# Create the model\nmodel = Sequential()\nmodel.add(Dense(5, input_shape=(1,), activation=ACTIVE_FUN))\nmodel.add(Dense(5, activation=ACTIVE_FUN))\nmodel.add(Dense(1, activation='linear'))\n\n# Compile the model\nmodel.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_squared_error'])\n\n# Fit the model\nmodel.fit(x, y, epochs=1000, batch_size=BATCH_SIZE, verbose=VERBOSE)\n\n# Evaluate the model\nscores = model.evaluate(x, y, verbose=VERBOSE)\nprint('%s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))\n\n# Make predictions\ny_pred = model.predict(x)\n\n# Plot\nplt.plot(x, y, color='blue', linewidth=1, markersize='1')\nplt.plot(x, y_pred, color='green', linewidth=1, markersize='1')\nplt.xlabel('Angle [rad]')\nplt.ylabel('sin(x)')\nplt.axis('tight')\nplt.show()\n"
                    ]
                ],
                "question_id:": "19365",
                "question_votes:": "1",
                "question_text:": "<p>I have a very simple feed forward neural network with keras that should learn a sinus. Why is the predictive power so bad and what is generally the best way to pinpoint issues with a network?</p>\n\n<p>In the code below, I have one input neuron, 10 in the hidden layer, and one output. I would expect the network to perform much more accurately.</p>\n\n<pre><code>import numpy as np\nfrom keras.layers import Dense, Activation\nfrom keras.models import Sequential\n\nx = np.arange(100)\ny = np.sin(x)\n\nmodel = Sequential([\n    Dense(10, input_shape=(1,)),\n    Activation('sigmoid'),\n    Dense(1),\n    Activation('sigmoid')\n])\n\nmodel.compile(loss='mean_squared_error', optimizer='SGD', metrics=['accuracy'])\nmodel.fit(x, y, epochs=10, batch_size=1)\n\nscores = model.evaluate(x, y, verbose=0)\nprint(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n\nprint(model.predict(np.array([.5])))\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>  1/100 [..............................] - ETA: 0s - loss: 1.2016 - acc: 0.0000e+00\n 79/100 [======================&gt;.......] - ETA: 0s - loss: 0.4665 - acc: 0.0127    \n100/100 [==============================] - 0s - loss: 0.5044 - acc: 0.0100     \nBaseline Error: 99.00%\n[[ 0.35267803]]\n</code></pre>\n",
                "tags": "<tensorflow><keras>",
                "answers": [
                    [
                        "19368",
                        "2",
                        "19365",
                        "",
                        "",
                        "<p>Accuracy is a metric meant for classification problems, look at the mean squared error instead. Your network is too small for a highly fluctuating function that you want to learn, if you divide your x by a smaller amount it would be easier to learn. Second of all, adding another layer and having an identity activation at the end will help quite a bit. Also taking batches bigger than 1 will make the gradient more stable. With a 1000 epochs I get to 0.00167 as mean squared error.</p>\n\n<pre><code>x = np.arange(200).reshape(-1,1) / 50\ny = np.sin(x)\n\nmodel = Sequential([\nDense(40, input_shape=(1,)),\nActivation('sigmoid'),\nDense(12),\nActivation('sigmoid'),\nDense(1)\n    ])\n\nmodel.compile(loss='mean_squared_error', optimizer='SGD', metrics=['mean_squared_error'])\n\nfor i in range(40):\n    model.fit(x, y, nb_epoch=25, batch_size=8, verbose=0)\n    predictions = model.predict(x)\n    print(np.mean(np.square(predictions - y)))\n</code></pre>\n\n<p>The biggest issue is that the signal in your original small dataset is very difficult to learn, you can see this when you plot it, it will just collapse to the mean.</p>\n",
                        "",
                        "4"
                    ],
                    [
                        "19399",
                        "2",
                        "19365",
                        "",
                        "",
                        "<p>Keep in mind that the <strong>Accuracy</strong> measure is measuring whether the values are <em>Exactly The Same</em>. I.e. it is a classification measure, whereas approximating a sin curve is much better suited for measurement as a regression problem.</p>\n\n<p>That said:</p>\n\n<p>In evaluating the network's performance, what is the network actually doing? Let's take the network and perform a little visual analysis on its performance:</p>\n\n<pre><code>import matplotlib.pyplot as plt\npreds = model.predict(x)\nplt.plot(x, y, 'b', x, preds, 'r--')\nplt.ylabel('Y / Predicted Value')\nplt.xlabel('X Value')\nplt.show()\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/e0acv.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/e0acv.png\" alt=\"enter image description here\"></a></p>\n\n<p>Hmm. The model seems to be minimizing error by simply getting closer and closer to guessing 0 for every value, rather than approximating the function. There are several hypotheses here to explain this. One is that the network is not complex enough to model the function. In order to test this, let's simplify the function- that is, let's bring the range down to one sine cycle:</p>\n\n<pre><code>x = np.arange(0, math.pi*2, 0.1)\ny = np.sin(x)\n</code></pre>\n\n<p>And try to train the network again:</p>\n\n<p><a href=\"https://i.stack.imgur.com/8HA7X.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/8HA7X.png\" alt=\"enter image description here\"></a></p>\n\n<p>Not wonderful, but a better fit, certainly.</p>\n\n<p>How about with <strong>100 epochs</strong> instead of 10?</p>\n\n<p><a href=\"https://i.stack.imgur.com/0Q6eS.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/0Q6eS.png\" alt=\"enter image description here\"></a></p>\n\n<p>How about with <strong>1000 epochs</strong>?</p>\n\n<p><a href=\"https://i.stack.imgur.com/Wk7qL.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/Wk7qL.png\" alt=\"enter image description here\"></a></p>\n\n<p>This is, of course, very interesting. After 1000 epochs, our networks is able to roughly approximate the downward curve from 1:0 ($\\pi/2$: $\\pi$) of the sine response, but not the initial upward curve 0:1 (0:$\\pi/2$) or the region in which the function is negative ($\\pi$:$2\\pi$).</p>\n\n<p>This result begs the question- what will it look like after <strong>10000 epochs</strong>?</p>\n\n<p><a href=\"https://i.stack.imgur.com/sxf00.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/sxf00.png\" alt=\"enter image description here\"></a></p>\n\n<p>Not significantly better. It looks like we'll have to change the architecture of the network (more layers, more neurons, and/or different activation functions) to improve beyond this point. </p>\n\n<p>To inform this architecture change, let's take a look at the sigmoid activation function:</p>\n\n<p><a href=\"https://i.stack.imgur.com/pp6kl.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/pp6kl.png\" alt=\"enter image description here\"></a></p>\n\n<p>Uh-oh. The value of this sigmoid function can only ever be in the range 0:1, and the range of the sin function is -1:1. </p>\n\n<p>To correct this, let's just normalize the sin response between 0 and 1:</p>\n\n<pre><code>y = (np.sin(x)+1)/2 \n</code></pre>\n\n<p>Now, the network performs much better than before after 1000 epochs:</p>\n\n<p><a href=\"https://i.stack.imgur.com/X0Nrk.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/X0Nrk.png\" alt=\"enter image description here\"></a></p>\n\n<p>And 10000:</p>\n\n<p><a href=\"https://i.stack.imgur.com/IxcxR.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/IxcxR.png\" alt=\"enter image description here\"></a></p>\n\n<p>After 100000 epochs, it's roughly perfect:</p>\n\n<p><a href=\"https://i.stack.imgur.com/dmbZb.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/dmbZb.png\" alt=\"enter image description here\"></a></p>\n\n<p>Even still, this advancement doesn't help much on the larger sin range (after 1000 epochs):</p>\n\n<pre><code>x = np.arange(0, 100, 1)\ny = (np.sin(x)+1)/2 \n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/6smI5.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/6smI5.png\" alt=\"enter image description here\"></a></p>\n\n<p>If we, however, take the model trained on a single sin curve and further train it on the larger range, we begin to see progress after 1000 epochs:</p>\n\n<pre><code>x = np.arange(0, 100, .1)\ny = (np.sin(x)+1)/2 \n\nmodel_copy = model\nmodel_copy.fit(x, y, epochs=1000, batch_size=8, verbose=0)\nmodel_copy_preds = model_copy.predict(x)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/UW8H2.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/UW8H2.png\" alt=\"enter image description here\"></a></p>\n\n<p>And more so after 10000 epochs:<a href=\"https://i.stack.imgur.com/cmQjw.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/cmQjw.png\" alt=\"enter image description here\"></a></p>\n\n<p>And more so, well into the third repetition after 100000 epochs:</p>\n\n<p><a href=\"https://i.stack.imgur.com/zDPgJ.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/zDPgJ.png\" alt=\"enter image description here\"></a></p>\n\n<p>So, with careful training, our network with a single layer of sigmoid activations appears to be learning to generalize the sin curve. Further investigation could find a limit to that generalization, certainly.</p>\n\n<p>For reproduction:</p>\n\n<pre><code>import numpy as np\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nimport matplotlib.pyplot as plt\nimport math\n\nx = np.arange(0, math.pi*2, .1)\ny = (np.sin(x)+1)/2 \n\nmodel = Sequential([\n    Dense(10, input_shape=(1,)),\n    Activation('sigmoid'),\n    Dense(1)\n])\n\nmodel.compile(loss='mean_squared_error', optimizer='SGD', metrics=['mean_squared_error'])\nmodel.fit(x, y, epochs=100000, batch_size=8, verbose=0)\n\npreds = model.predict(x)\n\nplt.plot(x, y, 'b', x, preds, 'r--')\nplt.ylabel('Y / Predicted Value')\nplt.xlabel('X Value')\nplt.show()\n\nx = np.arange(0, 100, .1)\ny = (np.sin(x)+1)/2 \n\nmodel_copy = model\nmodel_copy.fit(x, y, epochs=10000, batch_size=8, verbose=0)\nmodel_copy_preds = model_copy.predict(x)\n\nplt.plot(x, y, 'b', x, model_copy_preds, 'r--')\nplt.ylabel('Y / Predicted Value')\nplt.xlabel('X Value')\nplt.show()\n</code></pre>\n",
                        "",
                        "8"
                    ],
                    [
                        "31844",
                        "2",
                        "19365",
                        "",
                        "",
                        "<p>My code...</p>\n\n<pre><code>from keras.models import Sequential\nfrom keras.layers import Dense\nimport numpy as np\nimport matplotlib.pylab as plt\n\n# Create dataset\nx = np.arange(0, np.pi * 2, 0.1)\ny = np.sin(x)\n\n# Some parameters\nACTIVE_FUN = 'tanh'\nBATCH_SIZE = 1\nVERBOSE=0\n\n# Create the model\nmodel = Sequential()\nmodel.add(Dense(5, input_shape=(1,), activation=ACTIVE_FUN))\nmodel.add(Dense(5, activation=ACTIVE_FUN))\nmodel.add(Dense(1, activation='linear'))\n\n# Compile the model\nmodel.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_squared_error'])\n\n# Fit the model\nmodel.fit(x, y, epochs=1000, batch_size=BATCH_SIZE, verbose=VERBOSE)\n\n# Evaluate the model\nscores = model.evaluate(x, y, verbose=VERBOSE)\nprint('%s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))\n\n# Make predictions\ny_pred = model.predict(x)\n\n# Plot\nplt.plot(x, y, color='blue', linewidth=1, markersize='1')\nplt.plot(x, y_pred, color='green', linewidth=1, markersize='1')\nplt.xlabel('Angle [rad]')\nplt.ylabel('sin(x)')\nplt.axis('tight')\nplt.show()\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4582",
            "_score": 4.034696,
            "_source": {
                "title": "MNIST Deep Neural Network using TensorFlow",
                "content": "MNIST Deep Neural Network using TensorFlow <p>I have been working on this code for a while and it gave me a lot of headache before I got it to work. It basically tries to use the mnist dataset to classify handwritten digits. I am not using the prepackaged mnist in TensorFlow because I want to learn preprocessing the data myself and for deeper understanding of TensorFlow. </p>\n\n<p>Its finally working but I would love it if someone with expertise could take a look at it and tell me what they think and if the results its producing are actually real stats or if its overfitting or not learning at all. </p>\n\n<p>It's giving me accuracy between 83% and 91% from the test dataset. </p>\n\n<p>the dataset I'm using is from <a href=\"https://pjreddie.com/projects/mnist-in-csv/\" rel=\"nofollow noreferrer\">https://pjreddie.com/projects/mnist-in-csv/</a> basically the two links on top of the page.</p>\n\n<p>here is the code:</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\nsess = tf.Session()\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\nwith tf.Session() as sess:\n    # lets load the file\n    train_file = 'mnist_train.csv'\n    test_file = 'mnist_test.csv'\n    #train_file = 'mnist_train_small.csv'\n    #test_file = 'mnist_test_small.csv'\n\n    train = np.loadtxt(train_file, delimiter=',')\n    test = np.loadtxt(test_file, delimiter=',')\n\n    x_train = train[:,1:785]\n    y_train = train[:,:1]\n\n    x_test = test[:,1:785]\n    y_test = test[:,:1]\n    print(x_test.shape)\n\n    # lets normalize the data\n    def normalize(input_data):\n        minimum = input_data.min(axis=0)\n        maximum = input_data.max(axis=0)\n        #normalized = (input_data - minimum) / ( maximum - minimum )\n        normalized = preprocessing.normalize(input_data, norm='l2')\n        return normalized\n\n    # convert to a onehot array \n    def one_hot(input_data):\n        one_hot = []\n        for item in input_data:\n            if item == 0.:\n                one_h = [1.,0.,0.,0.,0.,0.,0.,0.,0.,0.]\n            elif item == 1.:\n                one_h = [0.,1.,0.,0.,0.,0.,0.,0.,0.,0.]\n            elif item == 2.:\n                one_h = [0.,0.,1.,0.,0.,0.,0.,0.,0.,0.]\n            elif item == 3.:\n                one_h = [0.,0.,0.,1.,0.,0.,0.,0.,0.,0.]\n            elif item == 4.:\n                one_h = [0.,0.,0.,0.,1.,0.,0.,0.,0.,0.]\n            elif item == 5.:\n                one_h = [0.,0.,0.,0.,0.,1.,0.,0.,0.,0.]\n            elif item == 6.:\n                one_h = [0.,0.,0.,0.,0.,0.,1.,0.,0.,0.]\n            elif item == 7.:\n                one_h = [0.,0.,0.,0.,0.,0.,0.,1.,0.,0.]\n            elif item == 8.:\n                one_h = [0.,0.,0.,0.,0.,0.,0.,0.,1.,0.]\n            elif item == 9.:\n                one_h = [0.,0.,0.,0.,0.,0.,0.,0.,0.,1.]\n\n            one_hot.append(one_h)\n        one_hot = np.array(one_hot)\n        #one_hot = one_hot.reshape(len(one_hot),10,1)\n        #one_hot = one_hot.reshape(len(one_hot), 7,1)\n        #return tf.constant([one_hot])\n        return one_hot\n    def one_hot_tf(val):\n        indices = val\n        depth = 10\n        on_value = 1.0\n        off_value = 0.0\n        axis = -1\n        oh = tf.one_hot(indices, depth,\n                   on_value=on_value, off_value=off_value,\n                   axis=axis, dtype=tf.float32,\n                   name='ONEHOT')\n        return (oh)\n    x_train = normalize(x_train)\n    x_test =  normalize(x_test)\n    #    x_train = sess.run(tf.convert_to_tensor(x_train))\n    #    x_test =  sess.run(tf.convert_to_tensor(x_test))\n\n    '''\n    data_initializer = tf.placeholder(dtype=x_train.dtype,\n                                        shape=x_train.shape)\n    label_initializer = tf.placeholder(dtype=x_test.dtype,\n                                         shape=x_test.shape)\n    x_train= sess.run(tf.Variable(data_initializer, trainable=False, collections=[]))\n    x_test = sess.run(tf.Variable(label_initializer, trainable=False, collections=[]))\n    '''\n\n\n    y_test =  one_hot(y_test)\n    y_train =  one_hot(y_train)\n    print(y_test[:5])\n    #   y_test =  sess.run(one_hot_tf(y_test))\n    #   y_train =  sess.run(one_hot_tf(y_train))\n\n\n    # define the parameters\n    input_nodes = 784\n    output_nodes = 10\n    hl1_nodes = 500\n    hl2_nodes = 500\n    hl3_nodes = 500\n    epochs = 10\n    x = tf.placeholder(tf.float32, [None, input_nodes])\n    y = tf.placeholder(tf.float32)\n\n    # graphing\n    loss_rate = []\n\n\n    def nn(data):\n        layer1 = {'w':tf.Variable(tf.random_normal([input_nodes, hl1_nodes])),\n                  'b':tf.Variable(tf.random_normal([hl1_nodes]))}\n        layer2 = {'w':tf.Variable(tf.random_normal([hl1_nodes, hl2_nodes])),\n                  'b':tf.Variable(tf.random_normal([hl2_nodes]))}\n        layer3 = {'w':tf.Variable(tf.random_normal([hl2_nodes, hl3_nodes])),\n                  'b':tf.Variable(tf.random_normal([hl3_nodes]))}\n        output_layer = {'w':tf.Variable(tf.random_normal([hl3_nodes, output_nodes])),\n                  'b':tf.Variable(tf.random_normal([output_nodes]))}\n\n        l1 = tf.add(tf.matmul(data, layer1['w']), layer1['b'])\n        l1 = tf.nn.relu(l1)\n\n        l2 = tf.add(tf.matmul(l1, layer2['w']), layer2['b'])\n        l2 = tf.nn.relu(l2)\n\n        l3 = tf.add(tf.matmul(l2, layer3['w']), layer3['b'])\n        l3 = tf.nn.relu(l3)\n\n        output = tf.add(tf.matmul(l3, output_layer['w']), output_layer['b'])\n\n        return(output)\n\n\n    def train(x):\n        prediction = nn(x)\n        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n        optimizer = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n\n        init = tf.global_variables_initializer()\n        sess.run(init)\n\n        for epoch in range(epochs):\n            epochloss = 0\n            batch_size = 10\n            batches = 0\n            for batch in range(int(len(x_train)/batch_size)):\n                next_batch = batches+batch\n                _, c = sess.run([optimizer, loss], feed_dict={x:x_train[batches:next_batch, :], y:y_train[batches:next_batch, :]})\n                epochloss = epochloss + c\n                batches += batch\n                loss_rate.append(c)\n\n            print(\"Epoch \", epoch, \" / \", epochs, \" - Loss \", epochloss)\n\n        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n        print(\"Accuracy : \", accuracy.eval({x:x_test, y:y_test}))\n\n\n    train(x)\n\n    plt.plot(loss_rate)\n    plt.show()\n</code></pre>\n\n<p>The output of 3 different runs are:</p>\n\n<pre><code>=========== RESTART: /Users/macbookpro/Desktop/AI/tf/OWN/test3.py ===========\n(10000, 784)\n[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\nEpoch  0  /  5  - Loss  nan\nEpoch  1  /  5  - Loss  nan\nEpoch  2  /  5  - Loss  nan\nEpoch  3  /  5  - Loss  nan\nEpoch  4  /  5  - Loss  nan\nAccuracy :  0.9053\n\n=========== RESTART: /Users/macbookpro/Desktop/AI/tf/OWN/test3.py ===========\n(10000, 784)\n[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\nEpoch  0  /  5  - Loss  nan\nEpoch  1  /  5  - Loss  nan\nEpoch  2  /  5  - Loss  nan\nEpoch  3  /  5  - Loss  nan\nEpoch  4  /  5  - Loss  nan\nAccuracy :  0.8342\n\n=========== RESTART: /Users/macbookpro/Desktop/AI/tf/OWN/test3.py ===========\n(10000, 784)\n[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\nEpoch  0  /  5  - Loss  nan\nEpoch  1  /  5  - Loss  nan\nEpoch  2  /  5  - Loss  nan\nEpoch  3  /  5  - Loss  nan\nEpoch  4  /  5  - Loss  nan\nAccuracy :  0.9\n</code></pre>\n\n<p>---Update---\nI found the answer in rewriting the code as follows:</p>\n\n<pre><code>import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nsess = tf.Session()\n\nfile = \"mnist_train.csv\"\ndata = np.loadtxt(file, delimiter=',')\n\n\ny_vals = data[:,0:1]\nx_vals = data[:,1:785]\n\nseed = 3\ntf.set_random_seed(seed)\nnp.random.seed(seed)\nbatch_size = 90\n\n# split into 80/20 datasets, normalize between 0:1 with min max scaling\ntrain_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\n# up there we chose randomly 80% of the data\ntest_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n# up we chose the remaining 20% \nprint(test_indices)\n\nx_vals_train = x_vals[train_indices]\nx_vals_test = x_vals[test_indices]\ny_vals_train = y_vals[train_indices]\ny_vals_test = y_vals[test_indices]\n\ndef normalize_cols(m):\n    col_max = m.max(axis=0)\n    col_min = m.min(axis=0)\n    return (m-col_min)/(col_max - col_min)\nx_vals_train = np.nan_to_num(normalize_cols(x_vals_train))\nx_vals_test = np.nan_to_num(normalize_cols(x_vals_test))\n\n# function that initializes the weights and the biases \ndef init_weight(shape, std_dev):\n    weight = tf.Variable(tf.random_normal(shape, stddev=std_dev))\n    return(weight)\n\ndef init_bias(shape, std_dev):\n    bias= tf.Variable(tf.random_normal(shape, stddev=std_dev))\n    return(bias)\n\n# initialize placeholders. \nx_data = tf.placeholder(shape=[None, 784], dtype=tf.float32)\ny_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n\n\n# the fully connected layer will be used three times for all three hidden layers\ndef fully_connected(input_layer, weights, biases):\n    layer = tf.add(tf.matmul(input_layer, weights), biases)\n    return (tf.nn.relu(layer))\n\n# Now create the model for each layer and the output layer.\n# we will initialize a weight matrix, bias matrix and the fully connected layer\n# for this, we will use hidden layers of size 500, 500, and 10\n\n'''\nThis will mean many variables variables to fit. This is because between the data and the first hidden layer we have \n784*500+500 = 392,500 variables to change.\ncontinuing this way we will have end up with how many variables we have overall to fit\n'''\n\n# create first layer (500 hidden nodes)\nweight_1 = init_weight(shape=[784,500], std_dev=10.0)\nbias_1 = init_bias(shape=[500], std_dev=10.0)\nlayer_1 = fully_connected(x_data, weight_1, bias_1)\n\n# create second layer (5-- hidden nodes)\nweight_2 = init_weight(shape=[500,500], std_dev=10.0)\nbias_2 = init_bias(shape=[500], std_dev=10.0)\nlayer_2 = fully_connected(layer_1, weight_2, bias_2)\n\n# create third layer (10 hidden nodes)\nweight_3 = init_weight(shape=[500,10], std_dev=10.0)\nbias_3 = init_bias(shape=[10], std_dev=10.0)\nlayer_3 = fully_connected(layer_2, weight_3, bias_3)\n\n# create output layer (1 output value)\nweight_4 = init_weight(shape=[10,1], std_dev=10.0)\nbias_4 = init_bias(shape=[1], std_dev=10.0)\nfinal_output = fully_connected(layer_3, weight_4, bias_4)\n\n\n# define the loss function and the optimizer and initializing the model\nloss = tf.reduce_mean(tf.abs(y_target - final_output))\noptimizer = tf.train.AdamOptimizer(0.05)\ntrain_step = optimizer.minimize(loss)\n\ninit = tf.global_variables_initializer()\nsess.run(init)\n\n# we will now train our model 10 times, store train and test los, select a random batch size, \n# and print the status every 1 generation\n\n# initalize the loss vectors\nloss_vec = []\ntest_loss = []\nfor i in range(10):\n    # choose random indices for batch selection\n    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n    # get random batch\n    rand_x = x_vals_train[rand_index]\n    #rand_y = np.transpose(y_vals_train[rand_index])\n    rand_y = y_vals_train[rand_index] #???????????\n    # run the training step\n    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n    # get and store train loss\n    temp_loss = sess.run(loss, feed_dict={x_data:rand_x, y_target:rand_y})\n    loss_vec.append(temp_loss)\n    # get and store test loss \n    #test_temp_loss = sess.run(loss, feed_dict={x_data:x_vals_test, y_target:np.transpose([y_vals_test])})\n    test_temp_loss = sess.run(loss, feed_dict={x_data:x_vals_test, y_target:y_vals_test}) #???????\n    test_loss.append(test_temp_loss)\n    if(i+1) %1==0:\n        print('Generation: '+str(i+1)+\". Loss = \"+str(temp_loss))\n\nplt.plot(loss_vec, 'k-', label='Train Loss')\nplt.plot(test_loss, 'r--', label='Test Loss')\nplt.title('Loss Per generation ')\nplt.xlabel('Generation')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\nplt.show()\n</code></pre>\n\n<p>I commented most of it just so if someone stumbles here and needs some help they can understand whats going on.</p>\n <python><neural-network><deep-learning><tensorflow><p>Given that you have such high error on the test set and have so many hidden layers/nodes, it's quite possible that your model is overfitting. Try using dropout or weight decay to regularize the weights of your network.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "18071",
                "question_votes:": "1",
                "question_text:": "<p>I have been working on this code for a while and it gave me a lot of headache before I got it to work. It basically tries to use the mnist dataset to classify handwritten digits. I am not using the prepackaged mnist in TensorFlow because I want to learn preprocessing the data myself and for deeper understanding of TensorFlow. </p>\n\n<p>Its finally working but I would love it if someone with expertise could take a look at it and tell me what they think and if the results its producing are actually real stats or if its overfitting or not learning at all. </p>\n\n<p>It's giving me accuracy between 83% and 91% from the test dataset. </p>\n\n<p>the dataset I'm using is from <a href=\"https://pjreddie.com/projects/mnist-in-csv/\" rel=\"nofollow noreferrer\">https://pjreddie.com/projects/mnist-in-csv/</a> basically the two links on top of the page.</p>\n\n<p>here is the code:</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\nsess = tf.Session()\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\nwith tf.Session() as sess:\n    # lets load the file\n    train_file = 'mnist_train.csv'\n    test_file = 'mnist_test.csv'\n    #train_file = 'mnist_train_small.csv'\n    #test_file = 'mnist_test_small.csv'\n\n    train = np.loadtxt(train_file, delimiter=',')\n    test = np.loadtxt(test_file, delimiter=',')\n\n    x_train = train[:,1:785]\n    y_train = train[:,:1]\n\n    x_test = test[:,1:785]\n    y_test = test[:,:1]\n    print(x_test.shape)\n\n    # lets normalize the data\n    def normalize(input_data):\n        minimum = input_data.min(axis=0)\n        maximum = input_data.max(axis=0)\n        #normalized = (input_data - minimum) / ( maximum - minimum )\n        normalized = preprocessing.normalize(input_data, norm='l2')\n        return normalized\n\n    # convert to a onehot array \n    def one_hot(input_data):\n        one_hot = []\n        for item in input_data:\n            if item == 0.:\n                one_h = [1.,0.,0.,0.,0.,0.,0.,0.,0.,0.]\n            elif item == 1.:\n                one_h = [0.,1.,0.,0.,0.,0.,0.,0.,0.,0.]\n            elif item == 2.:\n                one_h = [0.,0.,1.,0.,0.,0.,0.,0.,0.,0.]\n            elif item == 3.:\n                one_h = [0.,0.,0.,1.,0.,0.,0.,0.,0.,0.]\n            elif item == 4.:\n                one_h = [0.,0.,0.,0.,1.,0.,0.,0.,0.,0.]\n            elif item == 5.:\n                one_h = [0.,0.,0.,0.,0.,1.,0.,0.,0.,0.]\n            elif item == 6.:\n                one_h = [0.,0.,0.,0.,0.,0.,1.,0.,0.,0.]\n            elif item == 7.:\n                one_h = [0.,0.,0.,0.,0.,0.,0.,1.,0.,0.]\n            elif item == 8.:\n                one_h = [0.,0.,0.,0.,0.,0.,0.,0.,1.,0.]\n            elif item == 9.:\n                one_h = [0.,0.,0.,0.,0.,0.,0.,0.,0.,1.]\n\n            one_hot.append(one_h)\n        one_hot = np.array(one_hot)\n        #one_hot = one_hot.reshape(len(one_hot),10,1)\n        #one_hot = one_hot.reshape(len(one_hot), 7,1)\n        #return tf.constant([one_hot])\n        return one_hot\n    def one_hot_tf(val):\n        indices = val\n        depth = 10\n        on_value = 1.0\n        off_value = 0.0\n        axis = -1\n        oh = tf.one_hot(indices, depth,\n                   on_value=on_value, off_value=off_value,\n                   axis=axis, dtype=tf.float32,\n                   name='ONEHOT')\n        return (oh)\n    x_train = normalize(x_train)\n    x_test =  normalize(x_test)\n    #    x_train = sess.run(tf.convert_to_tensor(x_train))\n    #    x_test =  sess.run(tf.convert_to_tensor(x_test))\n\n    '''\n    data_initializer = tf.placeholder(dtype=x_train.dtype,\n                                        shape=x_train.shape)\n    label_initializer = tf.placeholder(dtype=x_test.dtype,\n                                         shape=x_test.shape)\n    x_train= sess.run(tf.Variable(data_initializer, trainable=False, collections=[]))\n    x_test = sess.run(tf.Variable(label_initializer, trainable=False, collections=[]))\n    '''\n\n\n    y_test =  one_hot(y_test)\n    y_train =  one_hot(y_train)\n    print(y_test[:5])\n    #   y_test =  sess.run(one_hot_tf(y_test))\n    #   y_train =  sess.run(one_hot_tf(y_train))\n\n\n    # define the parameters\n    input_nodes = 784\n    output_nodes = 10\n    hl1_nodes = 500\n    hl2_nodes = 500\n    hl3_nodes = 500\n    epochs = 10\n    x = tf.placeholder(tf.float32, [None, input_nodes])\n    y = tf.placeholder(tf.float32)\n\n    # graphing\n    loss_rate = []\n\n\n    def nn(data):\n        layer1 = {'w':tf.Variable(tf.random_normal([input_nodes, hl1_nodes])),\n                  'b':tf.Variable(tf.random_normal([hl1_nodes]))}\n        layer2 = {'w':tf.Variable(tf.random_normal([hl1_nodes, hl2_nodes])),\n                  'b':tf.Variable(tf.random_normal([hl2_nodes]))}\n        layer3 = {'w':tf.Variable(tf.random_normal([hl2_nodes, hl3_nodes])),\n                  'b':tf.Variable(tf.random_normal([hl3_nodes]))}\n        output_layer = {'w':tf.Variable(tf.random_normal([hl3_nodes, output_nodes])),\n                  'b':tf.Variable(tf.random_normal([output_nodes]))}\n\n        l1 = tf.add(tf.matmul(data, layer1['w']), layer1['b'])\n        l1 = tf.nn.relu(l1)\n\n        l2 = tf.add(tf.matmul(l1, layer2['w']), layer2['b'])\n        l2 = tf.nn.relu(l2)\n\n        l3 = tf.add(tf.matmul(l2, layer3['w']), layer3['b'])\n        l3 = tf.nn.relu(l3)\n\n        output = tf.add(tf.matmul(l3, output_layer['w']), output_layer['b'])\n\n        return(output)\n\n\n    def train(x):\n        prediction = nn(x)\n        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n        optimizer = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n\n        init = tf.global_variables_initializer()\n        sess.run(init)\n\n        for epoch in range(epochs):\n            epochloss = 0\n            batch_size = 10\n            batches = 0\n            for batch in range(int(len(x_train)/batch_size)):\n                next_batch = batches+batch\n                _, c = sess.run([optimizer, loss], feed_dict={x:x_train[batches:next_batch, :], y:y_train[batches:next_batch, :]})\n                epochloss = epochloss + c\n                batches += batch\n                loss_rate.append(c)\n\n            print(\"Epoch \", epoch, \" / \", epochs, \" - Loss \", epochloss)\n\n        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n        print(\"Accuracy : \", accuracy.eval({x:x_test, y:y_test}))\n\n\n    train(x)\n\n    plt.plot(loss_rate)\n    plt.show()\n</code></pre>\n\n<p>The output of 3 different runs are:</p>\n\n<pre><code>=========== RESTART: /Users/macbookpro/Desktop/AI/tf/OWN/test3.py ===========\n(10000, 784)\n[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\nEpoch  0  /  5  - Loss  nan\nEpoch  1  /  5  - Loss  nan\nEpoch  2  /  5  - Loss  nan\nEpoch  3  /  5  - Loss  nan\nEpoch  4  /  5  - Loss  nan\nAccuracy :  0.9053\n\n=========== RESTART: /Users/macbookpro/Desktop/AI/tf/OWN/test3.py ===========\n(10000, 784)\n[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\nEpoch  0  /  5  - Loss  nan\nEpoch  1  /  5  - Loss  nan\nEpoch  2  /  5  - Loss  nan\nEpoch  3  /  5  - Loss  nan\nEpoch  4  /  5  - Loss  nan\nAccuracy :  0.8342\n\n=========== RESTART: /Users/macbookpro/Desktop/AI/tf/OWN/test3.py ===========\n(10000, 784)\n[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\nEpoch  0  /  5  - Loss  nan\nEpoch  1  /  5  - Loss  nan\nEpoch  2  /  5  - Loss  nan\nEpoch  3  /  5  - Loss  nan\nEpoch  4  /  5  - Loss  nan\nAccuracy :  0.9\n</code></pre>\n\n<p>---Update---\nI found the answer in rewriting the code as follows:</p>\n\n<pre><code>import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nsess = tf.Session()\n\nfile = \"mnist_train.csv\"\ndata = np.loadtxt(file, delimiter=',')\n\n\ny_vals = data[:,0:1]\nx_vals = data[:,1:785]\n\nseed = 3\ntf.set_random_seed(seed)\nnp.random.seed(seed)\nbatch_size = 90\n\n# split into 80/20 datasets, normalize between 0:1 with min max scaling\ntrain_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\n# up there we chose randomly 80% of the data\ntest_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n# up we chose the remaining 20% \nprint(test_indices)\n\nx_vals_train = x_vals[train_indices]\nx_vals_test = x_vals[test_indices]\ny_vals_train = y_vals[train_indices]\ny_vals_test = y_vals[test_indices]\n\ndef normalize_cols(m):\n    col_max = m.max(axis=0)\n    col_min = m.min(axis=0)\n    return (m-col_min)/(col_max - col_min)\nx_vals_train = np.nan_to_num(normalize_cols(x_vals_train))\nx_vals_test = np.nan_to_num(normalize_cols(x_vals_test))\n\n# function that initializes the weights and the biases \ndef init_weight(shape, std_dev):\n    weight = tf.Variable(tf.random_normal(shape, stddev=std_dev))\n    return(weight)\n\ndef init_bias(shape, std_dev):\n    bias= tf.Variable(tf.random_normal(shape, stddev=std_dev))\n    return(bias)\n\n# initialize placeholders. \nx_data = tf.placeholder(shape=[None, 784], dtype=tf.float32)\ny_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n\n\n# the fully connected layer will be used three times for all three hidden layers\ndef fully_connected(input_layer, weights, biases):\n    layer = tf.add(tf.matmul(input_layer, weights), biases)\n    return (tf.nn.relu(layer))\n\n# Now create the model for each layer and the output layer.\n# we will initialize a weight matrix, bias matrix and the fully connected layer\n# for this, we will use hidden layers of size 500, 500, and 10\n\n'''\nThis will mean many variables variables to fit. This is because between the data and the first hidden layer we have \n784*500+500 = 392,500 variables to change.\ncontinuing this way we will have end up with how many variables we have overall to fit\n'''\n\n# create first layer (500 hidden nodes)\nweight_1 = init_weight(shape=[784,500], std_dev=10.0)\nbias_1 = init_bias(shape=[500], std_dev=10.0)\nlayer_1 = fully_connected(x_data, weight_1, bias_1)\n\n# create second layer (5-- hidden nodes)\nweight_2 = init_weight(shape=[500,500], std_dev=10.0)\nbias_2 = init_bias(shape=[500], std_dev=10.0)\nlayer_2 = fully_connected(layer_1, weight_2, bias_2)\n\n# create third layer (10 hidden nodes)\nweight_3 = init_weight(shape=[500,10], std_dev=10.0)\nbias_3 = init_bias(shape=[10], std_dev=10.0)\nlayer_3 = fully_connected(layer_2, weight_3, bias_3)\n\n# create output layer (1 output value)\nweight_4 = init_weight(shape=[10,1], std_dev=10.0)\nbias_4 = init_bias(shape=[1], std_dev=10.0)\nfinal_output = fully_connected(layer_3, weight_4, bias_4)\n\n\n# define the loss function and the optimizer and initializing the model\nloss = tf.reduce_mean(tf.abs(y_target - final_output))\noptimizer = tf.train.AdamOptimizer(0.05)\ntrain_step = optimizer.minimize(loss)\n\ninit = tf.global_variables_initializer()\nsess.run(init)\n\n# we will now train our model 10 times, store train and test los, select a random batch size, \n# and print the status every 1 generation\n\n# initalize the loss vectors\nloss_vec = []\ntest_loss = []\nfor i in range(10):\n    # choose random indices for batch selection\n    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n    # get random batch\n    rand_x = x_vals_train[rand_index]\n    #rand_y = np.transpose(y_vals_train[rand_index])\n    rand_y = y_vals_train[rand_index] #???????????\n    # run the training step\n    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n    # get and store train loss\n    temp_loss = sess.run(loss, feed_dict={x_data:rand_x, y_target:rand_y})\n    loss_vec.append(temp_loss)\n    # get and store test loss \n    #test_temp_loss = sess.run(loss, feed_dict={x_data:x_vals_test, y_target:np.transpose([y_vals_test])})\n    test_temp_loss = sess.run(loss, feed_dict={x_data:x_vals_test, y_target:y_vals_test}) #???????\n    test_loss.append(test_temp_loss)\n    if(i+1) %1==0:\n        print('Generation: '+str(i+1)+\". Loss = \"+str(temp_loss))\n\nplt.plot(loss_vec, 'k-', label='Train Loss')\nplt.plot(test_loss, 'r--', label='Test Loss')\nplt.title('Loss Per generation ')\nplt.xlabel('Generation')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\nplt.show()\n</code></pre>\n\n<p>I commented most of it just so if someone stumbles here and needs some help they can understand whats going on.</p>\n",
                "tags": "<python><neural-network><deep-learning><tensorflow>",
                "answers": [
                    [
                        "18078",
                        "2",
                        "18071",
                        "",
                        "",
                        "<p>Given that you have such high error on the test set and have so many hidden layers/nodes, it's quite possible that your model is overfitting. Try using dropout or weight decay to regularize the weights of your network.</p>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5377",
            "_score": 3.9885585,
            "_source": {
                "title": "Find the consecutive zeros in a DataFrame and do a conditional replacement",
                "content": "Find the consecutive zeros in a DataFrame and do a conditional replacement <p>I have a dataset like this:</p>\n\n<h3>Sample Dataframe</h3>\n\n<pre><code>import pandas as pd\n\ndf = pd.DataFrame({\n    'names': ['A','B','C','D','E','F','G','H','I','J','K','L'],\n    'col1': [0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0],\n    'col2': [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]})\n</code></pre>\n\n<p>I'd like to replace some of the <code>0</code>'s in <code>col1</code> and <code>col2</code> with <code>1</code>'s, but not replace the <code>0</code>'s if three or more <code>0</code>'s are consecutive in the same column.  How can this be done with pandas?</p>\n\n<h3>Original Dataset:</h3>\n\n<pre><code>names   col1    col2\nA   0   0\nB   1   0\nC   0   0\nD   1   0\nE   1   1\nF   1   0\nG   0   1\nH   0   0\nI   0   1\nJ   1   0\nK   0   0\nL   0   0\n</code></pre>\n\n<h3>Desired Dataset:</h3>\n\n<pre><code>names   col1    col2\nA   1   0\nB   1   0\nC   1   0\nD   1   0\nE   1   1\nF   1   1\nG   0   1\nH   0   1\nI   0   1\nJ   1   0\nK   1   0\nL   1   0\n</code></pre>\n <python><pandas><dataframe><p>Consider the following approach:</p>\n\n<pre><code>def f(col, threshold=3):\n    mask = col.groupby((col != col.shift()).cumsum()).transform('count').lt(threshold)\n    mask &amp;= col.eq(0)\n    col.update(col.loc[mask].replace(0,1))\n    return col\n\nIn [79]: df.apply(f, threshold=3)\nOut[79]:\n       col1  col2\nnames\nA         1     0\nB         1     0\nC         1     0\nD         1     0\nE         1     1\nF         1     1\nG         0     1\nH         0     1\nI         0     1\nJ         1     0\nK         1     0\nL         1     0\n</code></pre>\n\n<p>Step by step:</p>\n\n<pre><code>In [84]: col = df['col2']\n\nIn [85]: col\nOut[85]:\nnames\nA    0\nB    0\nC    0\nD    0\nE    1\nF    0\nG    1\nH    0\nI    1\nJ    0\nK    0\nL    0\nName: col2, dtype: int64\n\nIn [86]: (col != col.shift()).cumsum()\nOut[86]:\nnames\nA    1\nB    1\nC    1\nD    1\nE    2\nF    3\nG    4\nH    5\nI    6\nJ    7\nK    7\nL    7\nName: col2, dtype: int32\n\nIn [87]: col.groupby((col != col.shift()).cumsum()).transform('count')\nOut[87]:\nnames\nA    4\nB    4\nC    4\nD    4\nE    1\nF    1\nG    1\nH    1\nI    1\nJ    3\nK    3\nL    3\nName: col2, dtype: int64\n\nIn [88]: col.groupby((col != col.shift()).cumsum()).transform('count').lt(3)\nOut[88]:\nnames\nA    False\nB    False\nC    False\nD    False\nE     True\nF     True\nG     True\nH     True\nI     True\nJ    False\nK    False\nL    False\nName: col2, dtype: bool\n\nIn [89]: col.groupby((col != col.shift()).cumsum()).transform('count').lt(3) &amp; col.eq(0)\nOut[89]:\nnames\nA    False\nB    False\nC    False\nD    False\nE    False\nF     True\nG    False\nH     True\nI    False\nJ    False\nK    False\nL    False\nName: col2, dtype: bool\n</code></pre>\n<p>You should use <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.shift.html\" rel=\"nofollow noreferrer\"><code>pandas.DataFrame.shift()</code></a> to find the pattern you need.</p>\n\n<h3>Code:</h3>\n\n\n\n<pre><code>def fill_zero_not_3(series):\n    zeros = (True, True, True)\n    runs = [tuple(x == 0 for x in r)\n            for r in zip(*(series.shift(i)\n                           for i in (-2, -1, 0, 1, 2)))]\n    need_fill = [(r[0:3] != zeros and r[1:4] != zeros and r[2:5] != zeros)\n                 for r in runs]\n    retval = series.copy()\n    retval[need_fill] = 1\n    return retval\n</code></pre>\n\n<h3>Test Code:</h3>\n\n<pre><code>import pandas as pd\n\ndf = pd.DataFrame({\n    'names': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'],\n    'col1': [0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0],\n    'col2': [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]}).set_index('names')\n\ndf['col1'] = fill_zero_not_3(df['col1'])\ndf['col2'] = fill_zero_not_3(df['col2'])\nprint(df)\n</code></pre>\n\n<h3>Results:</h3>\n\n<pre><code>       col1  col2\nnames            \nA         1     0\nB         1     0\nC         1     0\nD         1     0\nE         1     1\nF         1     1\nG         0     1\nH         0     1\nI         0     1\nJ         1     0\nK         1     0\nL         1     0\n</code></pre>\n<p>@Stephen Rauch 's answer is very smart, but it's slow when I applied it to a large dataset. Inspired by <a href=\"https://stackoverflow.com/questions/24885092/finding-the-consecutive-zeros-in-a-numpy-array\">this post</a>, I think I got a more efficient way to achieve the same goal.</p>\n\n<p><strong>The code:</strong></p>\n\n<pre><code>import pandas as pd\n\ndf = pd.DataFrame({\n    'names': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'],\n    'col1': [0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0],\n    'col2': [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]}).set_index('names')\n\nfor i in range(df.shape[1]):\n    iszero = np.concatenate(([0], np.equal(df.iloc[:, i].values, 0).view(np.int8), [0]))\n    absdiff = np.abs(np.diff(iszero))\n    zerorange = np.where(absdiff == 1)[0].reshape(-1, 2)\n    for j in range(len(zerorange)):\n        if zerorange[j][1] - zerorange[j][0] &lt; 3:\n            df.iloc[zerorange[j][0]:zerorange[j][1], i] = 1\nprint(df)\n</code></pre>\n\n<p><strong>Results:</strong></p>\n\n<pre><code>        col1  col2\nnames            \nA         1     0\nB         1     0\nC         1     0\nD         1     0\nE         1     1\nF         1     1\nG         0     1\nH         0     1\nI         0     1\nJ         1     0\nK         1     0\nL         1     0\n</code></pre>\n",
                "codes": [
                    [
                        "def f(col, threshold=3):\n    mask = col.groupby((col != col.shift()).cumsum()).transform('count').lt(threshold)\n    mask &= col.eq(0)\n    col.update(col.loc[mask].replace(0,1))\n    return col\n\nIn [79]: df.apply(f, threshold=3)\nOut[79]:\n       col1  col2\nnames\nA         1     0\nB         1     0\nC         1     0\nD         1     0\nE         1     1\nF         1     1\nG         0     1\nH         0     1\nI         0     1\nJ         1     0\nK         1     0\nL         1     0\n",
                        "In [84]: col = df['col2']\n\nIn [85]: col\nOut[85]:\nnames\nA    0\nB    0\nC    0\nD    0\nE    1\nF    0\nG    1\nH    0\nI    1\nJ    0\nK    0\nL    0\nName: col2, dtype: int64\n\nIn [86]: (col != col.shift()).cumsum()\nOut[86]:\nnames\nA    1\nB    1\nC    1\nD    1\nE    2\nF    3\nG    4\nH    5\nI    6\nJ    7\nK    7\nL    7\nName: col2, dtype: int32\n\nIn [87]: col.groupby((col != col.shift()).cumsum()).transform('count')\nOut[87]:\nnames\nA    4\nB    4\nC    4\nD    4\nE    1\nF    1\nG    1\nH    1\nI    1\nJ    3\nK    3\nL    3\nName: col2, dtype: int64\n\nIn [88]: col.groupby((col != col.shift()).cumsum()).transform('count').lt(3)\nOut[88]:\nnames\nA    False\nB    False\nC    False\nD    False\nE     True\nF     True\nG     True\nH     True\nI     True\nJ    False\nK    False\nL    False\nName: col2, dtype: bool\n\nIn [89]: col.groupby((col != col.shift()).cumsum()).transform('count').lt(3) & col.eq(0)\nOut[89]:\nnames\nA    False\nB    False\nC    False\nD    False\nE    False\nF     True\nG    False\nH     True\nI    False\nJ    False\nK    False\nL    False\nName: col2, dtype: bool\n"
                    ],
                    [
                        "def fill_zero_not_3(series):\n    zeros = (True, True, True)\n    runs = [tuple(x == 0 for x in r)\n            for r in zip(*(series.shift(i)\n                           for i in (-2, -1, 0, 1, 2)))]\n    need_fill = [(r[0:3] != zeros and r[1:4] != zeros and r[2:5] != zeros)\n                 for r in runs]\n    retval = series.copy()\n    retval[need_fill] = 1\n    return retval\n",
                        "import pandas as pd\n\ndf = pd.DataFrame({\n    'names': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'],\n    'col1': [0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0],\n    'col2': [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]}).set_index('names')\n\ndf['col1'] = fill_zero_not_3(df['col1'])\ndf['col2'] = fill_zero_not_3(df['col2'])\nprint(df)\n",
                        "       col1  col2\nnames            \nA         1     0\nB         1     0\nC         1     0\nD         1     0\nE         1     1\nF         1     1\nG         0     1\nH         0     1\nI         0     1\nJ         1     0\nK         1     0\nL         1     0\n"
                    ],
                    [
                        "import pandas as pd\n\ndf = pd.DataFrame({\n    'names': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'],\n    'col1': [0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0],\n    'col2': [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]}).set_index('names')\n\nfor i in range(df.shape[1]):\n    iszero = np.concatenate(([0], np.equal(df.iloc[:, i].values, 0).view(np.int8), [0]))\n    absdiff = np.abs(np.diff(iszero))\n    zerorange = np.where(absdiff == 1)[0].reshape(-1, 2)\n    for j in range(len(zerorange)):\n        if zerorange[j][1] - zerorange[j][0] < 3:\n            df.iloc[zerorange[j][0]:zerorange[j][1], i] = 1\nprint(df)\n",
                        "        col1  col2\nnames            \nA         1     0\nB         1     0\nC         1     0\nD         1     0\nE         1     1\nF         1     1\nG         0     1\nH         0     1\nI         0     1\nJ         1     0\nK         1     0\nL         1     0\n"
                    ]
                ],
                "question_id:": "20587",
                "question_votes:": "9",
                "question_text:": "<p>I have a dataset like this:</p>\n\n<h3>Sample Dataframe</h3>\n\n<pre><code>import pandas as pd\n\ndf = pd.DataFrame({\n    'names': ['A','B','C','D','E','F','G','H','I','J','K','L'],\n    'col1': [0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0],\n    'col2': [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]})\n</code></pre>\n\n<p>I'd like to replace some of the <code>0</code>'s in <code>col1</code> and <code>col2</code> with <code>1</code>'s, but not replace the <code>0</code>'s if three or more <code>0</code>'s are consecutive in the same column.  How can this be done with pandas?</p>\n\n<h3>Original Dataset:</h3>\n\n<pre><code>names   col1    col2\nA   0   0\nB   1   0\nC   0   0\nD   1   0\nE   1   1\nF   1   0\nG   0   1\nH   0   0\nI   0   1\nJ   1   0\nK   0   0\nL   0   0\n</code></pre>\n\n<h3>Desired Dataset:</h3>\n\n<pre><code>names   col1    col2\nA   1   0\nB   1   0\nC   1   0\nD   1   0\nE   1   1\nF   1   1\nG   0   1\nH   0   1\nI   0   1\nJ   1   0\nK   1   0\nL   1   0\n</code></pre>\n",
                "tags": "<python><pandas><dataframe>",
                "answers": [
                    [
                        "22105",
                        "2",
                        "20587",
                        "",
                        "",
                        "<p>Consider the following approach:</p>\n\n<pre><code>def f(col, threshold=3):\n    mask = col.groupby((col != col.shift()).cumsum()).transform('count').lt(threshold)\n    mask &amp;= col.eq(0)\n    col.update(col.loc[mask].replace(0,1))\n    return col\n\nIn [79]: df.apply(f, threshold=3)\nOut[79]:\n       col1  col2\nnames\nA         1     0\nB         1     0\nC         1     0\nD         1     0\nE         1     1\nF         1     1\nG         0     1\nH         0     1\nI         0     1\nJ         1     0\nK         1     0\nL         1     0\n</code></pre>\n\n<p>Step by step:</p>\n\n<pre><code>In [84]: col = df['col2']\n\nIn [85]: col\nOut[85]:\nnames\nA    0\nB    0\nC    0\nD    0\nE    1\nF    0\nG    1\nH    0\nI    1\nJ    0\nK    0\nL    0\nName: col2, dtype: int64\n\nIn [86]: (col != col.shift()).cumsum()\nOut[86]:\nnames\nA    1\nB    1\nC    1\nD    1\nE    2\nF    3\nG    4\nH    5\nI    6\nJ    7\nK    7\nL    7\nName: col2, dtype: int32\n\nIn [87]: col.groupby((col != col.shift()).cumsum()).transform('count')\nOut[87]:\nnames\nA    4\nB    4\nC    4\nD    4\nE    1\nF    1\nG    1\nH    1\nI    1\nJ    3\nK    3\nL    3\nName: col2, dtype: int64\n\nIn [88]: col.groupby((col != col.shift()).cumsum()).transform('count').lt(3)\nOut[88]:\nnames\nA    False\nB    False\nC    False\nD    False\nE     True\nF     True\nG     True\nH     True\nI     True\nJ    False\nK    False\nL    False\nName: col2, dtype: bool\n\nIn [89]: col.groupby((col != col.shift()).cumsum()).transform('count').lt(3) &amp; col.eq(0)\nOut[89]:\nnames\nA    False\nB    False\nC    False\nD    False\nE    False\nF     True\nG    False\nH     True\nI    False\nJ    False\nK    False\nL    False\nName: col2, dtype: bool\n</code></pre>\n",
                        "",
                        "8"
                    ],
                    [
                        "21612",
                        "2",
                        "20587",
                        "",
                        "",
                        "<p>You should use <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.shift.html\" rel=\"nofollow noreferrer\"><code>pandas.DataFrame.shift()</code></a> to find the pattern you need.</p>\n\n<h3>Code:</h3>\n\n\n\n<pre><code>def fill_zero_not_3(series):\n    zeros = (True, True, True)\n    runs = [tuple(x == 0 for x in r)\n            for r in zip(*(series.shift(i)\n                           for i in (-2, -1, 0, 1, 2)))]\n    need_fill = [(r[0:3] != zeros and r[1:4] != zeros and r[2:5] != zeros)\n                 for r in runs]\n    retval = series.copy()\n    retval[need_fill] = 1\n    return retval\n</code></pre>\n\n<h3>Test Code:</h3>\n\n<pre><code>import pandas as pd\n\ndf = pd.DataFrame({\n    'names': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'],\n    'col1': [0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0],\n    'col2': [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]}).set_index('names')\n\ndf['col1'] = fill_zero_not_3(df['col1'])\ndf['col2'] = fill_zero_not_3(df['col2'])\nprint(df)\n</code></pre>\n\n<h3>Results:</h3>\n\n<pre><code>       col1  col2\nnames            \nA         1     0\nB         1     0\nC         1     0\nD         1     0\nE         1     1\nF         1     1\nG         0     1\nH         0     1\nI         0     1\nJ         1     0\nK         1     0\nL         1     0\n</code></pre>\n",
                        "",
                        "4"
                    ],
                    [
                        "21998",
                        "2",
                        "20587",
                        "",
                        "",
                        "<p>@Stephen Rauch 's answer is very smart, but it's slow when I applied it to a large dataset. Inspired by <a href=\"https://stackoverflow.com/questions/24885092/finding-the-consecutive-zeros-in-a-numpy-array\">this post</a>, I think I got a more efficient way to achieve the same goal.</p>\n\n<p><strong>The code:</strong></p>\n\n<pre><code>import pandas as pd\n\ndf = pd.DataFrame({\n    'names': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'],\n    'col1': [0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0],\n    'col2': [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]}).set_index('names')\n\nfor i in range(df.shape[1]):\n    iszero = np.concatenate(([0], np.equal(df.iloc[:, i].values, 0).view(np.int8), [0]))\n    absdiff = np.abs(np.diff(iszero))\n    zerorange = np.where(absdiff == 1)[0].reshape(-1, 2)\n    for j in range(len(zerorange)):\n        if zerorange[j][1] - zerorange[j][0] &lt; 3:\n            df.iloc[zerorange[j][0]:zerorange[j][1], i] = 1\nprint(df)\n</code></pre>\n\n<p><strong>Results:</strong></p>\n\n<pre><code>        col1  col2\nnames            \nA         1     0\nB         1     0\nC         1     0\nD         1     0\nE         1     1\nF         1     1\nG         0     1\nH         0     1\nI         0     1\nJ         1     0\nK         1     0\nL         1     0\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6327",
            "_score": 3.9885585,
            "_source": {
                "title": "Using standard ML models for modeling a derivative when the data set only contains function values",
                "content": "Using standard ML models for modeling a derivative when the data set only contains function values <p>I want to model a process that is a function of time, $X(t)$. I have a data set which corresponds to a coarse sampling of the function values $X$ at different time points, $t_1, t_2, ...$. I have a analytic-derived model for the derivative $\\frac{dX}{dt}$ = $F(X(t),G(t))$ which has a couple tunable parameters in the (known) functions $F$ and $G$. I've been able to tune these models with the following process:</p>\n\n<ol>\n<li>Chose a set of parameters for the functions $F$ and $G$.</li>\n<li>Do a forward-Euler method from the earliest time in my data set to the ending point in my data set, generating the $X(t)$ which corresponds to the above parameters in $F$ and $G$.</li>\n<li>Use this $X(t)$, along with my measured data points to generate a model error.</li>\n<li>Use the above modeled error to go back to (1), iterating and doing an optimization over the parameters in the expression for $\\frac{dX}{dt}$ to minimize the error.</li>\n</ol>\n\n<p>Note that in the above I have to deal with the function itself and not the derivative because my measured data is on a coarser time grid than the derivative needs to be computed. For example, my derivative changes meaningfully on a scale of $\\Delta t$, but my data set might only have points every $5\\Delta t$ to $10 \\Delta t$. I cannot take the function values themselves from the data set and create a derivative myself because of this discrepancy in the time scales.</p>\n\n<p>Now this process works pretty well, and I'm able to achieve a pretty good error. However, I'm wondering if there's a better way to model the derivative $\\frac{dX}{dt}$ than this analytic model. For example, would a neural network or a regression tree be able to do a better job?</p>\n\n<p>My question is, how would I do this in a computationally efficient way? Let's take a neural network as an example. I'm used to having inputs and their associated outputs when training a NN with standard packages. But the problem is, if I want to model the derivative, I <em>don't</em> have the derivative as an output to train on. I only know the function values and have only been able to compute a error to minimize on through the forward Euler integration. Of course I could treat the NN parameters as I did with the parameters above, and do a brute force minimization on them, but I obviously lose a lot of the efficiency of backprop in doing so (or, if I was doing this with a decision tree, would lose the logic of how regression trees are normally optimized).</p>\n\n<p>Is there a better way for me to do this? Are there methods that exist to handle this problem? If anyone could point me in a fruitful direction it would be much appreciated. </p>\n <machine-learning><time-series><optimization><p>Honestly, this does not sound like a machine learning problem.\nI can think of two approaches:</p>\n\n<ul>\n<li>If you have an analytic model for $dX/dt$, you can integrate it over $t$ to obtain a model for $X$. Then find the parameters that minimize squared distance to the data (plus some regularization perhaps). A grid search might be sufficient.</li>\n<li>Use standard methods of interpolating a function, such as <a href=\"https://en.wikipedia.org/wiki/Spline_interpolation\" rel=\"nofollow noreferrer\">spline interpolation</a>. The advantage of this is that you get a smooth closed-form solution.</li>\n</ul>\n\n<p>Please also keep in mind that <em>the</em> derivative for a finite set of points $X(t_1), X(t_2), ..., X(t_n)$ does not exist. There are infinitely many functions that pass through all points (and almost all of them are not differentiable). In other words: You have to make additional assumptions on the function that you are looking for. With the methods above, you make these assumptions explicitly, which I think is better than burying them deep inside a machine learning algorithm.</p>\n<p>This is actually really easy to implement in any deep learning framework with automatic differentiation capability. </p>\n\n<p>You need two neural networks. One to approximate the $X$, another to approximate the $dX/dt$.</p>\n\n<ul>\n<li>The first step is easy. You have samples of input and target for $X$.\nJust follow the normal process to train you network to learn $X$</li>\n<li>For the second step is that you don't have the target values (i.e. gradient) directly. The trick is that you already got an approximator for $X$ from the first step, so use that to get your target for the second network. </li>\n</ul>\n\n<p>I am most familiar with <code>pytorch</code>, so I will use it as an example. </p>\n\n\n\n<pre><code>import torch\nfrom torch.nn import Sequential, Linear, ReLU\nfrom torch.autograd import Variable\nfrom torch.optim import Adam\nimport numpy as np\n\nx = np.linspace(0, 10, 101).reshape(-1, 1)\ny = np.sin(x) # Using sin as an example\n\nx = Variable(torch.Tensor(x), requires_grad=True) \ny = Variable(torch.Tensor(y), requires_grad=False)\n\nf = Sequential(....) # Build f approximator\nf_optimizer = Adam(f.parameters())\n\nfor epoch in range(1000):\n    loss= f(x) - y\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n# Build grad approximator\nf_grad = Sequential(....) \n\n# need a new optimizer to train f_grad\nf_optimizer = Adam(f_grad.parameters()) \n\nfor epoch in range(1000):\n    # Directly backprop from the output to the gradient of the f\n    model(x).backward() \n    loss= f_grad(x) - x.grad # x.grad is the grad of f w.r.t x\n    f_optimizer.zero_grad()\n    loss.backward()\n    f_optimizer.step()  \n\nf_grad # this is the gradient function you are looking for\n</code></pre>\n\n<p>(I don't have a machine with <code>pytorch</code> install at the moment, so don't expect the code to run with some debugging)</p>\n",
                "codes": [
                    [],
                    [
                        "import torch\nfrom torch.nn import Sequential, Linear, ReLU\nfrom torch.autograd import Variable\nfrom torch.optim import Adam\nimport numpy as np\n\nx = np.linspace(0, 10, 101).reshape(-1, 1)\ny = np.sin(x) # Using sin as an example\n\nx = Variable(torch.Tensor(x), requires_grad=True) \ny = Variable(torch.Tensor(y), requires_grad=False)\n\nf = Sequential(....) # Build f approximator\nf_optimizer = Adam(f.parameters())\n\nfor epoch in range(1000):\n    loss= f(x) - y\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n# Build grad approximator\nf_grad = Sequential(....) \n\n# need a new optimizer to train f_grad\nf_optimizer = Adam(f_grad.parameters()) \n\nfor epoch in range(1000):\n    # Directly backprop from the output to the gradient of the f\n    model(x).backward() \n    loss= f_grad(x) - x.grad # x.grad is the grad of f w.r.t x\n    f_optimizer.zero_grad()\n    loss.backward()\n    f_optimizer.step()  \n\nf_grad # this is the gradient function you are looking for\n"
                    ]
                ],
                "question_id:": "24739",
                "question_votes:": "3",
                "question_text:": "<p>I want to model a process that is a function of time, $X(t)$. I have a data set which corresponds to a coarse sampling of the function values $X$ at different time points, $t_1, t_2, ...$. I have a analytic-derived model for the derivative $\\frac{dX}{dt}$ = $F(X(t),G(t))$ which has a couple tunable parameters in the (known) functions $F$ and $G$. I've been able to tune these models with the following process:</p>\n\n<ol>\n<li>Chose a set of parameters for the functions $F$ and $G$.</li>\n<li>Do a forward-Euler method from the earliest time in my data set to the ending point in my data set, generating the $X(t)$ which corresponds to the above parameters in $F$ and $G$.</li>\n<li>Use this $X(t)$, along with my measured data points to generate a model error.</li>\n<li>Use the above modeled error to go back to (1), iterating and doing an optimization over the parameters in the expression for $\\frac{dX}{dt}$ to minimize the error.</li>\n</ol>\n\n<p>Note that in the above I have to deal with the function itself and not the derivative because my measured data is on a coarser time grid than the derivative needs to be computed. For example, my derivative changes meaningfully on a scale of $\\Delta t$, but my data set might only have points every $5\\Delta t$ to $10 \\Delta t$. I cannot take the function values themselves from the data set and create a derivative myself because of this discrepancy in the time scales.</p>\n\n<p>Now this process works pretty well, and I'm able to achieve a pretty good error. However, I'm wondering if there's a better way to model the derivative $\\frac{dX}{dt}$ than this analytic model. For example, would a neural network or a regression tree be able to do a better job?</p>\n\n<p>My question is, how would I do this in a computationally efficient way? Let's take a neural network as an example. I'm used to having inputs and their associated outputs when training a NN with standard packages. But the problem is, if I want to model the derivative, I <em>don't</em> have the derivative as an output to train on. I only know the function values and have only been able to compute a error to minimize on through the forward Euler integration. Of course I could treat the NN parameters as I did with the parameters above, and do a brute force minimization on them, but I obviously lose a lot of the efficiency of backprop in doing so (or, if I was doing this with a decision tree, would lose the logic of how regression trees are normally optimized).</p>\n\n<p>Is there a better way for me to do this? Are there methods that exist to handle this problem? If anyone could point me in a fruitful direction it would be much appreciated. </p>\n",
                "tags": "<machine-learning><time-series><optimization>",
                "answers": [
                    [
                        "28256",
                        "2",
                        "24739",
                        "",
                        "",
                        "<p>Honestly, this does not sound like a machine learning problem.\nI can think of two approaches:</p>\n\n<ul>\n<li>If you have an analytic model for $dX/dt$, you can integrate it over $t$ to obtain a model for $X$. Then find the parameters that minimize squared distance to the data (plus some regularization perhaps). A grid search might be sufficient.</li>\n<li>Use standard methods of interpolating a function, such as <a href=\"https://en.wikipedia.org/wiki/Spline_interpolation\" rel=\"nofollow noreferrer\">spline interpolation</a>. The advantage of this is that you get a smooth closed-form solution.</li>\n</ul>\n\n<p>Please also keep in mind that <em>the</em> derivative for a finite set of points $X(t_1), X(t_2), ..., X(t_n)$ does not exist. There are infinitely many functions that pass through all points (and almost all of them are not differentiable). In other words: You have to make additional assumptions on the function that you are looking for. With the methods above, you make these assumptions explicitly, which I think is better than burying them deep inside a machine learning algorithm.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "24742",
                        "2",
                        "24739",
                        "",
                        "",
                        "<p>This is actually really easy to implement in any deep learning framework with automatic differentiation capability. </p>\n\n<p>You need two neural networks. One to approximate the $X$, another to approximate the $dX/dt$.</p>\n\n<ul>\n<li>The first step is easy. You have samples of input and target for $X$.\nJust follow the normal process to train you network to learn $X$</li>\n<li>For the second step is that you don't have the target values (i.e. gradient) directly. The trick is that you already got an approximator for $X$ from the first step, so use that to get your target for the second network. </li>\n</ul>\n\n<p>I am most familiar with <code>pytorch</code>, so I will use it as an example. </p>\n\n\n\n<pre><code>import torch\nfrom torch.nn import Sequential, Linear, ReLU\nfrom torch.autograd import Variable\nfrom torch.optim import Adam\nimport numpy as np\n\nx = np.linspace(0, 10, 101).reshape(-1, 1)\ny = np.sin(x) # Using sin as an example\n\nx = Variable(torch.Tensor(x), requires_grad=True) \ny = Variable(torch.Tensor(y), requires_grad=False)\n\nf = Sequential(....) # Build f approximator\nf_optimizer = Adam(f.parameters())\n\nfor epoch in range(1000):\n    loss= f(x) - y\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n# Build grad approximator\nf_grad = Sequential(....) \n\n# need a new optimizer to train f_grad\nf_optimizer = Adam(f_grad.parameters()) \n\nfor epoch in range(1000):\n    # Directly backprop from the output to the gradient of the f\n    model(x).backward() \n    loss= f_grad(x) - x.grad # x.grad is the grad of f w.r.t x\n    f_optimizer.zero_grad()\n    loss.backward()\n    f_optimizer.step()  \n\nf_grad # this is the gradient function you are looking for\n</code></pre>\n\n<p>(I don't have a machine with <code>pytorch</code> install at the moment, so don't expect the code to run with some debugging)</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "4409",
            "_score": 3.834457,
            "_source": {
                "title": "Logistic regression GD implementation in Python",
                "content": "Logistic regression GD implementation in Python <p>I am implementing logistic regression in Python with the regularized loss function like this: </p>\n\n<p><a href=\"https://i.stack.imgur.com/MqJsv.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/MqJsv.png\" alt=\"enter image description here\"></a> But the gradient algorithm works bad. Read the bold text first, please! Just paste the code cell by cell</p>\n\n<pre><code>import numpy as np, scipy as sp, sklearn as sl\nfrom scipy import special as ss\nfrom sklearn.base import ClassifierMixin, BaseEstimator\nfrom sklearn.datasets import make_classification\nimport theano.tensor as T\n</code></pre>\n\n<p><strong>Here is the loss function: (scipy is to \"clip\" the logarithm's arg near <code>1</code></strong>)</p>\n\n<pre><code>def lossf(w, X, y, l1, l2):\n     w.resize((w.shape[0],1))\n     y.resize((y.shape[0],1))\n\n     lossf1 = np.sum(ss.log1p(1 + ss.expm1(np.multiply(-y, np.dot(X, w)))))\n     lossf2 = l2 * (np.dot(np.transpose(w), w))\n     lossf3 = l1 * sum(abs(w))\n     lossf = np.float(lossf1 + lossf2 + lossf3)\n     return lossf\n</code></pre>\n\n<p><strong>Here is the gradient function:(??PROBLEM HERE?? -see the end)</strong></p>\n\n<pre><code>def gradf(w, X, y, l1, l2):\n    w.resize((w.shape[0],1))\n    y.resize((y.shape[0],1))\n\n    gradw1 = l2 * 2 * w \n    gradw2 = l1 * np.sign(w)\n    gradw3 = np.multiply(-y,(2 + ss.expm1(np.multiply(-y, np.dot(X, w)))))\n    gradw3 = gradw3 / (2 + (ss.expm1((np.multiply(-y, np.dot(X, w))))))\n    gradw3 = np.sum(np.multiply(gradw3, X), axis=0)\n    gradw3.resize(gradw3.shape[0],1)\n    gradw = gradw1 + gradw2 + gradw3\n    gradw.resize(gradw.shape[0],)\n    return np.transpose(gradw)\n</code></pre>\n\n<p><strong>Here is my LR class:</strong></p>\n\n<pre><code>class LR(ClassifierMixin, BaseEstimator):\n    def __init__(self, lr=0.0001, l1=0.1, l2=0.1, num_iter=100, verbose=0):\n        self.l1 = l1\n        self.l2 = l2\n        self.w = None\n        self.lr = lr\n        self.verbose = verbose\n        self.num_iter = num_iter\n\ndef fit(self, X, y):        \n    n, d = X.shape \n    self.w = np.zeros(shape=(d,))\n    for i in range(self.num_iter):\n        g = gradf(self.w, X, y, self.l1, self.l2)\n        g.resize((g.shape[0],1))\n        self.w = self.w - g\n        print \"Loss: \", lossf(self.w, X, y, self.l1, self.l2)\n    return self\n\ndef predict_proba(self, X):\n    probs = 1/(2 + ss.expm1(np.dot(-X, self.w)))\n    return probs \n\ndef predict(self, X):\n    probs = self.predict_proba(X)\n    probs = np.sign(2 * probs - 1)\n    probs.resize((probs.shape[0],))\n    return probs \n</code></pre>\n\n<p><strong>Here are the tests:</strong></p>\n\n<pre><code>X, y = make_classification(n_features=100, n_samples=100)\ny = 2 * (y - 0.5)\nclf = LR(lr=0.000001, l1=0.1, l2=0.1, num_iter=10, verbose=0)\nclf = clf.fit(X, y)\nyp = clf.predict(X)\nyp.resize((100,1))\naccuracy = int(sum(y == yp))/len(y)\n</code></pre>\n\n<p><strong>This doesn't converge. But if I replace my <code>gradw3</code> with theano:</strong></p>\n\n<pre><code>gradw3 = get_gradw3(w,X,y)\n</code></pre>\n\n<p><strong>where:</strong></p>\n\n<pre><code>w,X,y = T.matrices(\"wXy\") \nlogloss = T.sum(T.log1p(1 + T.expm1(-y* T.dot(X, w)))) \nget_gradw3 = theano.function([w,X,y],T.grad(logloss,w).reshape(w.shape))\n</code></pre>\n\n<p><strong>it converges to 100% accuracy. That means, my gradw3 is implemented wrong, but I can't find a mistake.</strong></p>\n <python><logistic-regression><p>Actually, i have finally made it work. I dont know, what exactly was the crucial change, but here's the extract of my changes:</p>\n\n<ul>\n<li><p>replaced all <code>np.multiply</code> with <code>*</code></p></li>\n<li><p>Decreased learning rate and regulizers</p></li>\n<li>Applied <code>np.nan_to_num</code> to exponents</li>\n</ul>\n\n<p>So here is the final code:</p>\n\n<pre><code>def lossf(w, X, y, l1, l2):\n    w.resize((w.shape[0],1))\n    y.resize((y.shape[0],1))\n\n    lossf1 = np.sum(ss.log1p(1 + np.nan_to_num(ss.expm1(-y * np.dot(X, w)))))\n    lossf2 = l2 * (np.dot(np.transpose(w), w))\n    lossf3 = l1 * sum(abs(w))\n    lossf = np.float(lossf1 + lossf2 + lossf3)\n    return lossf\n\ndef gradf(w, X, y, l1, l2):\n    w.resize((w.shape[0],1))\n    y.resize((y.shape[0],1))\n\n    gradw1 = l2 * 2 * w \n    gradw2 = l1 * np.sign(w)\n    gradw3 = -y * (1 + np.nan_to_num(ss.expm1(-y * np.dot(X, w))))\n    gradw3 = gradw3 / (2 + np.nan_to_num(ss.expm1(-y * np.dot(X, w))))\n    gradw3 = np.sum(gradw3 * X, axis=0)\n    gradw3.resize(gradw3.shape[0],1)\n    gradw = gradw1 + gradw2 + gradw3\n    gradw.resize(gradw.shape[0],)\n    return np.transpose(gradw)\nclass LR(ClassifierMixin, BaseEstimator):\n    def __init__(self, lr=0.000001, l1=0.1, l2=0.1, num_iter=100, verbose=0):\n        self.l1 = l1\n        self.l2 = l2\n        self.w = None\n        self.lr = lr\n        self.verbose = verbose\n        self.num_iter = num_iter\n\n    def fit(self, X, y):       \n        n, d = X.shape \n        self.w = np.zeros(shape=(d,))\n        for i in range(self.num_iter):\n            print \"\\n\", \"Iteration \", i\n            g = gradf(self.w, X, y, self.l1, self.l2)\n            g.resize((g.shape[0],1))\n            self.w = self.w - g\n            print \"Loss: \", lossf(self.w, X, y, self.l1, self.l2)\n        return self\n\n    def predict_proba(self, X):\n        probs = 1/(2 + ss.expm1(np.dot(-X, self.w)))\n        return probs \n\n    def predict(self, X):\n        probs = self.predict_proba(X)\n        probs = np.sign(2 * probs - 1)\n        probs.resize((probs.shape[0],))\n        return probs \n</code></pre>\n",
                "codes": [
                    [
                        "def lossf(w, X, y, l1, l2):\n    w.resize((w.shape[0],1))\n    y.resize((y.shape[0],1))\n\n    lossf1 = np.sum(ss.log1p(1 + np.nan_to_num(ss.expm1(-y * np.dot(X, w)))))\n    lossf2 = l2 * (np.dot(np.transpose(w), w))\n    lossf3 = l1 * sum(abs(w))\n    lossf = np.float(lossf1 + lossf2 + lossf3)\n    return lossf\n\ndef gradf(w, X, y, l1, l2):\n    w.resize((w.shape[0],1))\n    y.resize((y.shape[0],1))\n\n    gradw1 = l2 * 2 * w \n    gradw2 = l1 * np.sign(w)\n    gradw3 = -y * (1 + np.nan_to_num(ss.expm1(-y * np.dot(X, w))))\n    gradw3 = gradw3 / (2 + np.nan_to_num(ss.expm1(-y * np.dot(X, w))))\n    gradw3 = np.sum(gradw3 * X, axis=0)\n    gradw3.resize(gradw3.shape[0],1)\n    gradw = gradw1 + gradw2 + gradw3\n    gradw.resize(gradw.shape[0],)\n    return np.transpose(gradw)\nclass LR(ClassifierMixin, BaseEstimator):\n    def __init__(self, lr=0.000001, l1=0.1, l2=0.1, num_iter=100, verbose=0):\n        self.l1 = l1\n        self.l2 = l2\n        self.w = None\n        self.lr = lr\n        self.verbose = verbose\n        self.num_iter = num_iter\n\n    def fit(self, X, y):       \n        n, d = X.shape \n        self.w = np.zeros(shape=(d,))\n        for i in range(self.num_iter):\n            print \"\\n\", \"Iteration \", i\n            g = gradf(self.w, X, y, self.l1, self.l2)\n            g.resize((g.shape[0],1))\n            self.w = self.w - g\n            print \"Loss: \", lossf(self.w, X, y, self.l1, self.l2)\n        return self\n\n    def predict_proba(self, X):\n        probs = 1/(2 + ss.expm1(np.dot(-X, self.w)))\n        return probs \n\n    def predict(self, X):\n        probs = self.predict_proba(X)\n        probs = np.sign(2 * probs - 1)\n        probs.resize((probs.shape[0],))\n        return probs \n"
                    ]
                ],
                "question_id:": "17565",
                "question_votes:": "3",
                "question_text:": "<p>I am implementing logistic regression in Python with the regularized loss function like this: </p>\n\n<p><a href=\"https://i.stack.imgur.com/MqJsv.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/MqJsv.png\" alt=\"enter image description here\"></a> But the gradient algorithm works bad. Read the bold text first, please! Just paste the code cell by cell</p>\n\n<pre><code>import numpy as np, scipy as sp, sklearn as sl\nfrom scipy import special as ss\nfrom sklearn.base import ClassifierMixin, BaseEstimator\nfrom sklearn.datasets import make_classification\nimport theano.tensor as T\n</code></pre>\n\n<p><strong>Here is the loss function: (scipy is to \"clip\" the logarithm's arg near <code>1</code></strong>)</p>\n\n<pre><code>def lossf(w, X, y, l1, l2):\n     w.resize((w.shape[0],1))\n     y.resize((y.shape[0],1))\n\n     lossf1 = np.sum(ss.log1p(1 + ss.expm1(np.multiply(-y, np.dot(X, w)))))\n     lossf2 = l2 * (np.dot(np.transpose(w), w))\n     lossf3 = l1 * sum(abs(w))\n     lossf = np.float(lossf1 + lossf2 + lossf3)\n     return lossf\n</code></pre>\n\n<p><strong>Here is the gradient function:(??PROBLEM HERE?? -see the end)</strong></p>\n\n<pre><code>def gradf(w, X, y, l1, l2):\n    w.resize((w.shape[0],1))\n    y.resize((y.shape[0],1))\n\n    gradw1 = l2 * 2 * w \n    gradw2 = l1 * np.sign(w)\n    gradw3 = np.multiply(-y,(2 + ss.expm1(np.multiply(-y, np.dot(X, w)))))\n    gradw3 = gradw3 / (2 + (ss.expm1((np.multiply(-y, np.dot(X, w))))))\n    gradw3 = np.sum(np.multiply(gradw3, X), axis=0)\n    gradw3.resize(gradw3.shape[0],1)\n    gradw = gradw1 + gradw2 + gradw3\n    gradw.resize(gradw.shape[0],)\n    return np.transpose(gradw)\n</code></pre>\n\n<p><strong>Here is my LR class:</strong></p>\n\n<pre><code>class LR(ClassifierMixin, BaseEstimator):\n    def __init__(self, lr=0.0001, l1=0.1, l2=0.1, num_iter=100, verbose=0):\n        self.l1 = l1\n        self.l2 = l2\n        self.w = None\n        self.lr = lr\n        self.verbose = verbose\n        self.num_iter = num_iter\n\ndef fit(self, X, y):        \n    n, d = X.shape \n    self.w = np.zeros(shape=(d,))\n    for i in range(self.num_iter):\n        g = gradf(self.w, X, y, self.l1, self.l2)\n        g.resize((g.shape[0],1))\n        self.w = self.w - g\n        print \"Loss: \", lossf(self.w, X, y, self.l1, self.l2)\n    return self\n\ndef predict_proba(self, X):\n    probs = 1/(2 + ss.expm1(np.dot(-X, self.w)))\n    return probs \n\ndef predict(self, X):\n    probs = self.predict_proba(X)\n    probs = np.sign(2 * probs - 1)\n    probs.resize((probs.shape[0],))\n    return probs \n</code></pre>\n\n<p><strong>Here are the tests:</strong></p>\n\n<pre><code>X, y = make_classification(n_features=100, n_samples=100)\ny = 2 * (y - 0.5)\nclf = LR(lr=0.000001, l1=0.1, l2=0.1, num_iter=10, verbose=0)\nclf = clf.fit(X, y)\nyp = clf.predict(X)\nyp.resize((100,1))\naccuracy = int(sum(y == yp))/len(y)\n</code></pre>\n\n<p><strong>This doesn't converge. But if I replace my <code>gradw3</code> with theano:</strong></p>\n\n<pre><code>gradw3 = get_gradw3(w,X,y)\n</code></pre>\n\n<p><strong>where:</strong></p>\n\n<pre><code>w,X,y = T.matrices(\"wXy\") \nlogloss = T.sum(T.log1p(1 + T.expm1(-y* T.dot(X, w)))) \nget_gradw3 = theano.function([w,X,y],T.grad(logloss,w).reshape(w.shape))\n</code></pre>\n\n<p><strong>it converges to 100% accuracy. That means, my gradw3 is implemented wrong, but I can't find a mistake.</strong></p>\n",
                "tags": "<python><logistic-regression>",
                "answers": [
                    [
                        "17660",
                        "2",
                        "17565",
                        "",
                        "",
                        "<p>Actually, i have finally made it work. I dont know, what exactly was the crucial change, but here's the extract of my changes:</p>\n\n<ul>\n<li><p>replaced all <code>np.multiply</code> with <code>*</code></p></li>\n<li><p>Decreased learning rate and regulizers</p></li>\n<li>Applied <code>np.nan_to_num</code> to exponents</li>\n</ul>\n\n<p>So here is the final code:</p>\n\n<pre><code>def lossf(w, X, y, l1, l2):\n    w.resize((w.shape[0],1))\n    y.resize((y.shape[0],1))\n\n    lossf1 = np.sum(ss.log1p(1 + np.nan_to_num(ss.expm1(-y * np.dot(X, w)))))\n    lossf2 = l2 * (np.dot(np.transpose(w), w))\n    lossf3 = l1 * sum(abs(w))\n    lossf = np.float(lossf1 + lossf2 + lossf3)\n    return lossf\n\ndef gradf(w, X, y, l1, l2):\n    w.resize((w.shape[0],1))\n    y.resize((y.shape[0],1))\n\n    gradw1 = l2 * 2 * w \n    gradw2 = l1 * np.sign(w)\n    gradw3 = -y * (1 + np.nan_to_num(ss.expm1(-y * np.dot(X, w))))\n    gradw3 = gradw3 / (2 + np.nan_to_num(ss.expm1(-y * np.dot(X, w))))\n    gradw3 = np.sum(gradw3 * X, axis=0)\n    gradw3.resize(gradw3.shape[0],1)\n    gradw = gradw1 + gradw2 + gradw3\n    gradw.resize(gradw.shape[0],)\n    return np.transpose(gradw)\nclass LR(ClassifierMixin, BaseEstimator):\n    def __init__(self, lr=0.000001, l1=0.1, l2=0.1, num_iter=100, verbose=0):\n        self.l1 = l1\n        self.l2 = l2\n        self.w = None\n        self.lr = lr\n        self.verbose = verbose\n        self.num_iter = num_iter\n\n    def fit(self, X, y):       \n        n, d = X.shape \n        self.w = np.zeros(shape=(d,))\n        for i in range(self.num_iter):\n            print \"\\n\", \"Iteration \", i\n            g = gradf(self.w, X, y, self.l1, self.l2)\n            g.resize((g.shape[0],1))\n            self.w = self.w - g\n            print \"Loss: \", lossf(self.w, X, y, self.l1, self.l2)\n        return self\n\n    def predict_proba(self, X):\n        probs = 1/(2 + ss.expm1(np.dot(-X, self.w)))\n        return probs \n\n    def predict(self, X):\n        probs = self.predict_proba(X)\n        probs = np.sign(2 * probs - 1)\n        probs.resize((probs.shape[0],))\n        return probs \n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6372",
            "_score": 3.834457,
            "_source": {
                "title": "Vanishing Gradient in a shallow network",
                "content": "Vanishing Gradient in a shallow network <p>I created an ANN in Python 3.  My backpropagation algorithm seems to work up to a point where the gradient becomes very small. I am familiar with the vanishing gradient problem, but I found that it only applies to really deep network; my simple test network is no such network.  It consists of an input layer (1 input node and bias), no hidden layers, and an output layer (1 output node).  <strong>How do I stop the gradient from vanishing?</strong> Here is the code:</p>\n\n<pre><code>import numpy as np\nfrom random import random\n\nclass Neural_Network(object):\n    def __init__(self):\n        # Create a simple deterministic network for testing\n\n        # Define Hyperparameters\n        self.inputLayerSize = 1\n        self.outputLayerSize = 1\n        self.hiddenLayerSize = 0\n        self.numHiddenLayer = 0\n        self.numExamples = 20\n        self.learningRate = 0.07 # LEARNING RATE\n        self.weightDecay = 0\n        # in -&gt; out\n        self.weights = [] # stores matrices of each layer of weights\n        self.z = [] # stores matrices of each layer of weighted sums\n        self.a = [] # stores matrices of each layer of activity \n        self.biases = [] # stores all biases\n        self.biasNodes = []\n\n        # Biases are matrices that are added to activity matrix\n        # Dimensions -&gt; numExamples_*hiddenLayerSize or numExamples_*outputLayerSize\n\n        # Biases for output layer\n        b = [0.5 for x in range(self.outputLayerSize)]\n        B = [b for x in range(self.numExamples)];\n        self.biases.append(np.mat(B))\n\n        # Bias nodes\n        b= [1 for x in range(self.numExamples)]\n        for i in range(self.numHiddenLayer+1):\n            self.biasNodes.append(np.mat(b).reshape([self.numExamples,1]))\n\n        # Weights (Parameters)\n        # Weight matrix between input and output layer\n        W = np.matrix(\"0.5\");\n        self.weights.append(W)\n\n\n\n    def setBatchSize(self, numExamples):\n        # Changes the number of rows (examples) for biases\n        if (self.numExamples &gt; numExamples):\n            self.biases = [b[:numExamples] for b in self.biases]\n\n    def hypTan(self, z):\n        # Apply hyperbolic tangent function\n        return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n\n    def hypTanPrime(self, z):\n        # Apply derivative hyperbolic tangent function\n        return 4/np.multiply((np.exp(z) + np.exp(-z)), (np.exp(z) + np.exp(-z)))\n\n\n    def forward(self, X):\n        # Propagate outputs through network\n        self.z = []\n        self.a = []\n\n        self.z.append(np.dot(X, self.weights[0]) + self.biases[0])\n        self.a.append(self.hypTan(self.z[0]))\n\n        yHat = self.a[-1]\n        return yHat\n\n    def backProp(self, X, y):\n        # Compute derivative wrt W\n        # out -&gt; in\n        dJdWb = [] # stores matrices of each dJdWb value \n        dJdW = [] # stores matrices of each dJdW (equal in size to self.weights[])\n        delta = [] # stores matrices of each backpropagating error\n        result = () # stores dJdW and dJdWb\n        self.yHat = self.forward(X)\n\n        # Quantifying Error\n        print(np.linalg.norm(y-self.yHat)/np.linalg.norm(y+self.yHat))\n\n\n        delta.insert(0,np.multiply(-(y-self.yHat), self.hypTanPrime(self.z[-1]))) # delta = (y-yHat)(sigmoidPrime(final layer unactivated))\n        dJdW.insert(0, np.dot(X.T, delta[0]) + (self.weightDecay*self.weights[-1]))\n        dJdWb.insert(0, np.dot(self.biasNodes[-1].T, delta[0]) + (self.weightDecay*self.biases[-1])) # you need to backpropagate to bias nodes\n\n\n        result = (dJdW, dJdWb)\n        return result\n\n    def train(self, X, y):\n        for t in range(10000):\n            dJ = self.backProp(X, y)\n            dJdW = dJ[0]\n            dJdWb = dJ[1]\n            for i in range(len(dJdW)):\n                print(\"dJdW:\", dJdW[i], sep = \" \", end = \"\\n\")\n                print(\"dJdWb:\", dJdWb[i], sep = \" \", end = \"\\n\\n\")\n                #print(\"Weights:\", self.weights[i]);\n                self.weights[i] -= self.learningRate*dJdW[i]\n                self.biases[i] -= self.learningRate*dJdWb[i]\n\n\n# Instantiating Neural Network\n\n\n# Instantiating Neural Network\n\nNN = Neural_Network() # create a deterministic NN for testing\nx = np.matrix(\"0.025; 0.05; 0.075; 0.1; 0.125; 0.15; 0.175; 0.2; 0.225; 0.25; 0.275; 0.3; 0.325; 0.35; 0.375; 0.4; 0.425; 0.45; 0.475; 0.5\")\ny = np.matrix(\"0.05; 0.1; 0.15; 0.2; 0.25; 0.3; 0.35; 0.4; 0.45; 0.5; 0.55; 0.6; 0.65; 0.7; 0.75; 0.8; 0.85; 0.9; 0.95; 1.0\")\n\n# Training\nprint(\"INPUT: \", end = '\\n')\nprint(x, end = '\\n\\n')\n\nprint(\"BEFORE TRAINING\", NN.forward(x), sep = '\\n', end = '\\n\\n')\nprint(\"ERROR: \")\nNN.train(x,y)\nprint(\"\\nAFTER TRAINING\", NN.forward(x), sep = '\\n', end = '\\n\\n')\n\nNN.setBatchSize(1) # changing settings to receive one input at a time\n\nwhile True:\n    inputs = input()\n    x = np.mat([float(i) for i in inputs.split(\" \")])\n    print(NN.forward(x))\n</code></pre>\n\n<p>When you run the program it will show the dJdW value (gradient values w.r.t weights) and dJWb values (gradient values w.r.t bias weights).  Then it will test the inputs on the newly trained network and print the outputs.  After that, you can give the network your own inputs (between 0 and 0.5 since i trained the network to multiply inputs by 2) and it will return outputs in console.  Please note that this is a highly simplified version of my real network.  I want to fix the problem here before adressing it in the full version.</p>\n <machine-learning><neural-network><algorithms><gradient-descent><backpropagation><p>This is not a \"vanishing gradient\" problem, it is just your network converging as designed.</p>\n\n<p>It is normal for gradients to become low as you approach convergence. In a really simple problem, like your linear regression, it is relatively easy to get a gradient of zero (within combined rounding errors). That is because, near a stationary point, gradients do approach zero. This can also be a weakness of gradient descent in general - learning will slow or halt near any stationary point, hence concerns about finding local minima as opposed to global minima.</p>\n\n<p>The way to check your gradients are correct is to test them against small weight deltas. Pick a set of weight parameters for the network. Calculate the gradients using your code. Then to test, take each weight in turn, change it by +/- $\\epsilon$ and use both variants to generate cost values, use them to estimate the gradient for that weight $\\frac{J_{+\\epsilon} - J_{-\\epsilon}}{2\\epsilon}$. Use this alternative (and much slower) gradient calculation to build up a second opinion of what <code>dJdW</code> should be. Then compare the two values. This process is often called <a href=\"http://ufldl.stanford.edu/wiki/index.php/Gradient_checking_and_advanced_optimization\" rel=\"nofollow noreferrer\">gradient checking</a>.</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "24875",
                "question_votes:": "1",
                "question_text:": "<p>I created an ANN in Python 3.  My backpropagation algorithm seems to work up to a point where the gradient becomes very small. I am familiar with the vanishing gradient problem, but I found that it only applies to really deep network; my simple test network is no such network.  It consists of an input layer (1 input node and bias), no hidden layers, and an output layer (1 output node).  <strong>How do I stop the gradient from vanishing?</strong> Here is the code:</p>\n\n<pre><code>import numpy as np\nfrom random import random\n\nclass Neural_Network(object):\n    def __init__(self):\n        # Create a simple deterministic network for testing\n\n        # Define Hyperparameters\n        self.inputLayerSize = 1\n        self.outputLayerSize = 1\n        self.hiddenLayerSize = 0\n        self.numHiddenLayer = 0\n        self.numExamples = 20\n        self.learningRate = 0.07 # LEARNING RATE\n        self.weightDecay = 0\n        # in -&gt; out\n        self.weights = [] # stores matrices of each layer of weights\n        self.z = [] # stores matrices of each layer of weighted sums\n        self.a = [] # stores matrices of each layer of activity \n        self.biases = [] # stores all biases\n        self.biasNodes = []\n\n        # Biases are matrices that are added to activity matrix\n        # Dimensions -&gt; numExamples_*hiddenLayerSize or numExamples_*outputLayerSize\n\n        # Biases for output layer\n        b = [0.5 for x in range(self.outputLayerSize)]\n        B = [b for x in range(self.numExamples)];\n        self.biases.append(np.mat(B))\n\n        # Bias nodes\n        b= [1 for x in range(self.numExamples)]\n        for i in range(self.numHiddenLayer+1):\n            self.biasNodes.append(np.mat(b).reshape([self.numExamples,1]))\n\n        # Weights (Parameters)\n        # Weight matrix between input and output layer\n        W = np.matrix(\"0.5\");\n        self.weights.append(W)\n\n\n\n    def setBatchSize(self, numExamples):\n        # Changes the number of rows (examples) for biases\n        if (self.numExamples &gt; numExamples):\n            self.biases = [b[:numExamples] for b in self.biases]\n\n    def hypTan(self, z):\n        # Apply hyperbolic tangent function\n        return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n\n    def hypTanPrime(self, z):\n        # Apply derivative hyperbolic tangent function\n        return 4/np.multiply((np.exp(z) + np.exp(-z)), (np.exp(z) + np.exp(-z)))\n\n\n    def forward(self, X):\n        # Propagate outputs through network\n        self.z = []\n        self.a = []\n\n        self.z.append(np.dot(X, self.weights[0]) + self.biases[0])\n        self.a.append(self.hypTan(self.z[0]))\n\n        yHat = self.a[-1]\n        return yHat\n\n    def backProp(self, X, y):\n        # Compute derivative wrt W\n        # out -&gt; in\n        dJdWb = [] # stores matrices of each dJdWb value \n        dJdW = [] # stores matrices of each dJdW (equal in size to self.weights[])\n        delta = [] # stores matrices of each backpropagating error\n        result = () # stores dJdW and dJdWb\n        self.yHat = self.forward(X)\n\n        # Quantifying Error\n        print(np.linalg.norm(y-self.yHat)/np.linalg.norm(y+self.yHat))\n\n\n        delta.insert(0,np.multiply(-(y-self.yHat), self.hypTanPrime(self.z[-1]))) # delta = (y-yHat)(sigmoidPrime(final layer unactivated))\n        dJdW.insert(0, np.dot(X.T, delta[0]) + (self.weightDecay*self.weights[-1]))\n        dJdWb.insert(0, np.dot(self.biasNodes[-1].T, delta[0]) + (self.weightDecay*self.biases[-1])) # you need to backpropagate to bias nodes\n\n\n        result = (dJdW, dJdWb)\n        return result\n\n    def train(self, X, y):\n        for t in range(10000):\n            dJ = self.backProp(X, y)\n            dJdW = dJ[0]\n            dJdWb = dJ[1]\n            for i in range(len(dJdW)):\n                print(\"dJdW:\", dJdW[i], sep = \" \", end = \"\\n\")\n                print(\"dJdWb:\", dJdWb[i], sep = \" \", end = \"\\n\\n\")\n                #print(\"Weights:\", self.weights[i]);\n                self.weights[i] -= self.learningRate*dJdW[i]\n                self.biases[i] -= self.learningRate*dJdWb[i]\n\n\n# Instantiating Neural Network\n\n\n# Instantiating Neural Network\n\nNN = Neural_Network() # create a deterministic NN for testing\nx = np.matrix(\"0.025; 0.05; 0.075; 0.1; 0.125; 0.15; 0.175; 0.2; 0.225; 0.25; 0.275; 0.3; 0.325; 0.35; 0.375; 0.4; 0.425; 0.45; 0.475; 0.5\")\ny = np.matrix(\"0.05; 0.1; 0.15; 0.2; 0.25; 0.3; 0.35; 0.4; 0.45; 0.5; 0.55; 0.6; 0.65; 0.7; 0.75; 0.8; 0.85; 0.9; 0.95; 1.0\")\n\n# Training\nprint(\"INPUT: \", end = '\\n')\nprint(x, end = '\\n\\n')\n\nprint(\"BEFORE TRAINING\", NN.forward(x), sep = '\\n', end = '\\n\\n')\nprint(\"ERROR: \")\nNN.train(x,y)\nprint(\"\\nAFTER TRAINING\", NN.forward(x), sep = '\\n', end = '\\n\\n')\n\nNN.setBatchSize(1) # changing settings to receive one input at a time\n\nwhile True:\n    inputs = input()\n    x = np.mat([float(i) for i in inputs.split(\" \")])\n    print(NN.forward(x))\n</code></pre>\n\n<p>When you run the program it will show the dJdW value (gradient values w.r.t weights) and dJWb values (gradient values w.r.t bias weights).  Then it will test the inputs on the newly trained network and print the outputs.  After that, you can give the network your own inputs (between 0 and 0.5 since i trained the network to multiply inputs by 2) and it will return outputs in console.  Please note that this is a highly simplified version of my real network.  I want to fix the problem here before adressing it in the full version.</p>\n",
                "tags": "<machine-learning><neural-network><algorithms><gradient-descent><backpropagation>",
                "answers": [
                    [
                        "24879",
                        "2",
                        "24875",
                        "",
                        "",
                        "<p>This is not a \"vanishing gradient\" problem, it is just your network converging as designed.</p>\n\n<p>It is normal for gradients to become low as you approach convergence. In a really simple problem, like your linear regression, it is relatively easy to get a gradient of zero (within combined rounding errors). That is because, near a stationary point, gradients do approach zero. This can also be a weakness of gradient descent in general - learning will slow or halt near any stationary point, hence concerns about finding local minima as opposed to global minima.</p>\n\n<p>The way to check your gradients are correct is to test them against small weight deltas. Pick a set of weight parameters for the network. Calculate the gradients using your code. Then to test, take each weight in turn, change it by +/- $\\epsilon$ and use both variants to generate cost values, use them to estimate the gradient for that weight $\\frac{J_{+\\epsilon} - J_{-\\epsilon}}{2\\epsilon}$. Use this alternative (and much slower) gradient calculation to build up a second opinion of what <code>dJdW</code> should be. Then compare the two values. This process is often called <a href=\"http://ufldl.stanford.edu/wiki/index.php/Gradient_checking_and_advanced_optimization\" rel=\"nofollow noreferrer\">gradient checking</a>.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "3477",
            "_score": 3.8221903,
            "_source": {
                "title": "Tensorflow RNN network with variable sequence length?",
                "content": "Tensorflow RNN network with variable sequence length? <p>I am currently trying to implemenent a RNN network for regression purposes, such that I can map a known input to a known output. \nThe problem in my case is that the input does not have static length, as it consist of samples of audio files, and the audio files have different length. But the output length is always consistent, and has length 14. </p>\n\n<p>It was due to this inconsistency of the input vector, I decided to use RNN in the first place. </p>\n\n<p>I am using tensorflow at the moment, and it seems like that there is no pretty way of handling this issue. I tried a hack solution based on this <a href=\"https://danijar.com/variable-sequence-lengths-in-tensorflow/\" rel=\"nofollow\">post</a> somehow ended with the same issue as in the begining. </p>\n\n<p>Here is my implementation: </p>\n\n<pre><code>import tensorflow as tf\nfrom tensorflow.models.rnn import rnn_cell\nfrom tensorflow.models.rnn import rnn\nimport numpy as np\nimport librosa\nimport glob\nimport matplotlib.pyplot as plt\nfrom os import listdir\nfrom os.path import isfile, join\nimport os\nfrom os import walk\nfrom os.path import splitext\nfrom os.path import join\nimport time\nrng = np.random\nnp.set_printoptions(threshold=np.nan)\nimport functools\n\nstart_time = time.time()\n\nprint \"Preprocessing\"\n\ndef lazy_property(function):\n    attribute = '_' + function.__name__\n\n    @property\n    @functools.wraps(function)\n    def wrapper(self):\n        if not hasattr(self, attribute):\n            setattr(self, attribute, function(self))\n        return getattr(self, attribute)\n    return wrapper\n## Class definition ##\nclass VariableSequenceLabelling:\n\n    def __init__(self, data, target, num_hidden=200, num_layers=3):\n        self.data = data\n        self.target = target\n        self._num_hidden = num_hidden\n        self._num_layers = num_layers\n        self.prediction\n        self.error\n        self.optimize\n\n    @lazy_property\n    def length(self):\n        used = tf.sign(tf.reduce_max(tf.abs(self.data), reduction_indices=2))\n        length = tf.reduce_sum(used, reduction_indices=1)\n        length = tf.cast(length, tf.int32)\n        return length\n\n    @lazy_property\n    def prediction(self):\n        # Recurrent network.\n        output, _ = tf.nn.dynamic_rnn(\n             rnn_cell.GRUCell(self._num_hidden),\n            self.data,\n            dtype=tf.float32,\n            sequence_length=self.length,\n        )\n        # Softmax layer.\n        max_length = int(self.target.get_shape()[1])\n        num_classes = int(self.target.get_shape()[2])\n        weight, bias = self._weight_and_bias(self._num_hidden, num_classes)\n        # Flatten to apply same weights to all time steps.\n        output = tf.reshape(output, [-1, self._num_hidden])\n        prediction = tf.nn.softmax(tf.matmul(output, weight) + bias)\n        prediction = tf.reshape(prediction, [-1, max_length, num_classes])\n        return prediction\n\n    @lazy_property\n    def cost(self):\n        # Compute cross entropy for each frame.\n        cross_entropy = self.target * tf.log(self.prediction)\n        cross_entropy = -tf.reduce_sum(cross_entropy, reduction_indices=2)\n        mask = tf.sign(tf.reduce_max(tf.abs(self.target), reduction_indices=2))\n        cross_entropy *= mask\n        # Average over actual sequence lengths.\n        cross_entropy = tf.reduce_sum(cross_entropy, reduction_indices=1)\n        cross_entropy /= tf.cast(self.length, tf.float32)\n        return tf.reduce_mean(cross_entropy)\n\n    @lazy_property\n    def optimize(self):\n        learning_rate = 0.0003\n        optimizer = tf.train.AdamOptimizer(learning_rate)\n        return optimizer.minimize(self.cost)\n\n    @lazy_property\n    def error(self):\n        mistakes = tf.not_equal(\n            tf.argmax(self.target, 2), tf.argmax(self.prediction, 2))\n        mistakes = tf.cast(mistakes, tf.float32)\n        mask = tf.sign(tf.reduce_max(tf.abs(self.target), reduction_indices=2))\n        mistakes *= mask\n        # Average over actual sequence lengths.\n        mistakes = tf.reduce_sum(mistakes, reduction_indices=1)\n        mistakes /= tf.cast(self.length, tf.float32)\n        return tf.reduce_mean(mistakes)\n\n    @staticmethod\n    def _weight_and_bias(in_size, out_size):\n        weight = tf.truncated_normal([in_size, out_size], stddev=0.01)\n        bias = tf.constant(0.1, shape=[out_size])\n        return tf.Variable(weight), tf.Variable(bias)\n\n#######################\n#Converting file to .wav from .sph file format... God dammit!!!\n\n#with open(train_filelist, 'r') as train_filelist, open(test_filelist, 'r') as test_filelist:\n    #train_mylist = train_filelist.read().splitlines()\n    #test_mylist = test_filelist.read().splitlines()\n    #for line in train_mylist:\n        #new_line = ' '.join(reversed(line))\n        #index_start = new_line.find('h')\n        #index_end = new_line.find('/')\n        #edited_line = ''.join(reversed(new_line[index_start+5:index_end])).strip().replace(\" \",\"\")\n        #new_file = edited_line + 'wav'\n        #os.system(line + ' &gt;&gt; ' + dnn_train + new_file)\n    #for line in test_mylist:\n        #new_line = ' '.join(reversed(line))\n        #index_start = new_line.find('h')\n        #index_end = new_line.find('/')\n        #edited_line = ''.join(reversed(new_line[index_start+5:index_end])).strip().replace(\" \",\"\")\n        #new_file = edited_line + 'wav'\n        #os.system(line + ' &gt;&gt; ' + dnn_test + new_file)\n\n\npath_train =  \"/home/JoeS/kaldi-trunk/egs/start/s5/data/train\"\npath_test =  \"/home/JoeS/kaldi-trunk/egs/start/s5/data/test\"\ndnn_train = \"/home/JoeS/kaldi-trunk/dnn/train/\"\ndnn_test = \"/home/JoeS/kaldi-trunk/dnn/test/\"\ndnn = \"/home/JoeS/kaldi-trunk/dnn/\"\npath  = \"/home/JoeS/kaldi-trunk/egs/start/s5/data/\"\nMFCC_dir = \"/home/JoeS/kaldi-trunk/egs/start/s5/mfcc/raw_mfcc_train.txt\"\n\ntrain_filelist = path_train+\"/wav_train.txt\"\ntest_filelist = path_test+\"/wav_test.txt\"\n\nos.chdir(path)\n\ndef binify(number):\n    divider = (36471330-10533580)/6\n    if number &gt;= divider*0 and number &lt; divider*1:\n        return 1\n    if number &gt;= divider*1 and number &lt; divider*2:\n        return 2\n    if number &gt;= divider*2 and number &lt; divider*3:\n        return 3\n    if number &gt;= divider*3 and number &lt; divider*4:\n        return 4\n    if number &gt;= divider*5 and number &lt; divider*6:\n        return 5\n    if number &gt;= divider*6:\n        return 6\n\ndef find_all(a_str, sub):\n    start = 0\n    while True:\n        start = a_str.find(sub, start)\n        if start == -1: return\n        yield start\n        start += len(sub) # use start += 1 to find overlapping matches\n\ndef load_sound_files(file_paths ,  names_input, data_input):\n    raw_sounds = []\n    names_output = []\n    data_output = []\n    class_output = []\n    for fp in file_paths:\n        X,sr = librosa.load(fp)\n        raw_sounds.append(X)\n        index = list(find_all(fp,'-'))\n        input_index = names_input.index(fp[index[1]+1:index[2]])\n        names_output.append(names_input[input_index])\n        data_output.append(data_input[input_index])\n        class_output.append(binify(data_input[input_index][0]))\n    return raw_sounds, names_output, data_output, class_output\n\ndef generate_list_of_names_data(file_path):\n    # Proprocess\n    # extract name and data\n    name = []\n    data = []\n    with open(MFCC_dir) as mfcc_feature_list:\n        content = [x.strip('\\n') for x in mfcc_feature_list.readlines()] # remove endlines\n        start_index_data = 0\n        end_index_data = 2\n        for number in range(0,42):\n            start = list(find_all(content[start_index_data],'['))[0]\n            end = list(find_all(content[end_index_data],']'))[0]\n            end_name = list(find_all(content[start_index_data],' '))[0]\n            substring_data = content[start_index_data][start+1 :]+content[end_index_data][: end]\n            substring_name = content[start_index_data][:end_name]\n            arr = np.array(substring_data.split(), dtype = float)\n            data.append(arr)\n            name.append(substring_name)\n            start_index_data = start_index_data + +3\n            end_index_data = end_index_data +3\n    return name, data\n\nfiles_train_path = [dnn_train+f for f in listdir(dnn_train) if isfile(join(dnn_train, f))]\nfiles_test_path = [dnn_test+f for f in listdir(dnn_test) if isfile(join(dnn_test, f))]\n\nfiles_train_name = [f for f in listdir(dnn_train) if isfile(join(dnn_train, f))]\nfiles_test_name = [f for f in listdir(dnn_test) if isfile(join(dnn_test, f))]\n\nos.chdir(dnn_train)\n\ntrain_name,train_data = generate_list_of_names_data(files_train_path)\ntrain_data, train_names, train_output_data, train_class_output = load_sound_files(files_train_path,train_name,train_data)\n\nmax_length = 0 ## Used for variable sequence input\n\nfor element in train_data:\n    if element.size &gt; max_length:\n        max_length = element.size\n\nNUM_EXAMPLES = len(train_data)/2\n\ntest_data = train_data[NUM_EXAMPLES:]\ntest_output = train_output_data[NUM_EXAMPLES:]\n\ntrain_data = train_data[:NUM_EXAMPLES]\ntrain_output = train_output_data[:NUM_EXAMPLES]\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n##-------------------MAIN----------------------------##\n\nif __name__ == '__main__':\n    data = tf.placeholder(tf.float32, [None, max_length, 1])\n    target = tf.placeholder(tf.float32, [None, 14, 1])\n    model = VariableSequenceLabelling(data, target)\n    sess = tf.Session()\n    sess.run(tf.initialize_all_variables())\n    for epoch in range(10):\n        for sample_set in range(100):\n            batch_train = train_data[sample_set]\n            batch_target = train_output[sample_set]\n            sess.run(model.optimize, {data: batch_train, target: batch_target})\n        test_set = test_data[epoch]\n        test_set_output = test_output[epoch]\n        error = sess.run(model.error, {data: test_set, target: test_set_output})\n        print('Epoch {:2d} error {:3.1f}%'.format(epoch + 1, 100 * error))\n</code></pre>\n\n<p>The error message I am receiving is that </p>\n\n<pre><code>Traceback (most recent call last):\n  File \"tensorflow_datapreprocess_mfcc_extraction_rnn.py\", line 239, in &lt;module&gt;\n    sess.run(model.optimize, {data: batch_train, target: batch_target})\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 340, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 553, in _run\n    % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\nValueError: Cannot feed value of shape (63945,) for Tensor u'Placeholder:0', which has shape '(?, 138915, 1)'\n</code></pre>\n\n<p>I guess debugging is more a stackoverflow question than a data science question, so instead of asking for help solving my issue regarding the code, would I like to know whether there is other framework which do natively support this, such I don't need to hack my solution.  I added my code such you know the structure of my input and output data.  It would be very appreciated if I could keep the structure. </p>\n <python><neural-network><regression><tensorflow><rnn><p>Since tensors can be only of a fixed size, you have to zero-pad your sequences (usually from the left) to the maximum occurring length with something like:</p>\n\n<pre><code>max_len = max([len(x) for x in sequences])\nsequences = [np.pad(x, (max_len - len(x), 0), 'constant', constant_values = (0.,0.)) for x in sequences]\n</code></pre>\n",
                "codes": [
                    [
                        "max_len = max([len(x) for x in sequences])\nsequences = [np.pad(x, (max_len - len(x), 0), 'constant', constant_values = (0.,0.)) for x in sequences]\n"
                    ]
                ],
                "question_id:": "14727",
                "question_votes:": "1",
                "question_text:": "<p>I am currently trying to implemenent a RNN network for regression purposes, such that I can map a known input to a known output. \nThe problem in my case is that the input does not have static length, as it consist of samples of audio files, and the audio files have different length. But the output length is always consistent, and has length 14. </p>\n\n<p>It was due to this inconsistency of the input vector, I decided to use RNN in the first place. </p>\n\n<p>I am using tensorflow at the moment, and it seems like that there is no pretty way of handling this issue. I tried a hack solution based on this <a href=\"https://danijar.com/variable-sequence-lengths-in-tensorflow/\" rel=\"nofollow\">post</a> somehow ended with the same issue as in the begining. </p>\n\n<p>Here is my implementation: </p>\n\n<pre><code>import tensorflow as tf\nfrom tensorflow.models.rnn import rnn_cell\nfrom tensorflow.models.rnn import rnn\nimport numpy as np\nimport librosa\nimport glob\nimport matplotlib.pyplot as plt\nfrom os import listdir\nfrom os.path import isfile, join\nimport os\nfrom os import walk\nfrom os.path import splitext\nfrom os.path import join\nimport time\nrng = np.random\nnp.set_printoptions(threshold=np.nan)\nimport functools\n\nstart_time = time.time()\n\nprint \"Preprocessing\"\n\ndef lazy_property(function):\n    attribute = '_' + function.__name__\n\n    @property\n    @functools.wraps(function)\n    def wrapper(self):\n        if not hasattr(self, attribute):\n            setattr(self, attribute, function(self))\n        return getattr(self, attribute)\n    return wrapper\n## Class definition ##\nclass VariableSequenceLabelling:\n\n    def __init__(self, data, target, num_hidden=200, num_layers=3):\n        self.data = data\n        self.target = target\n        self._num_hidden = num_hidden\n        self._num_layers = num_layers\n        self.prediction\n        self.error\n        self.optimize\n\n    @lazy_property\n    def length(self):\n        used = tf.sign(tf.reduce_max(tf.abs(self.data), reduction_indices=2))\n        length = tf.reduce_sum(used, reduction_indices=1)\n        length = tf.cast(length, tf.int32)\n        return length\n\n    @lazy_property\n    def prediction(self):\n        # Recurrent network.\n        output, _ = tf.nn.dynamic_rnn(\n             rnn_cell.GRUCell(self._num_hidden),\n            self.data,\n            dtype=tf.float32,\n            sequence_length=self.length,\n        )\n        # Softmax layer.\n        max_length = int(self.target.get_shape()[1])\n        num_classes = int(self.target.get_shape()[2])\n        weight, bias = self._weight_and_bias(self._num_hidden, num_classes)\n        # Flatten to apply same weights to all time steps.\n        output = tf.reshape(output, [-1, self._num_hidden])\n        prediction = tf.nn.softmax(tf.matmul(output, weight) + bias)\n        prediction = tf.reshape(prediction, [-1, max_length, num_classes])\n        return prediction\n\n    @lazy_property\n    def cost(self):\n        # Compute cross entropy for each frame.\n        cross_entropy = self.target * tf.log(self.prediction)\n        cross_entropy = -tf.reduce_sum(cross_entropy, reduction_indices=2)\n        mask = tf.sign(tf.reduce_max(tf.abs(self.target), reduction_indices=2))\n        cross_entropy *= mask\n        # Average over actual sequence lengths.\n        cross_entropy = tf.reduce_sum(cross_entropy, reduction_indices=1)\n        cross_entropy /= tf.cast(self.length, tf.float32)\n        return tf.reduce_mean(cross_entropy)\n\n    @lazy_property\n    def optimize(self):\n        learning_rate = 0.0003\n        optimizer = tf.train.AdamOptimizer(learning_rate)\n        return optimizer.minimize(self.cost)\n\n    @lazy_property\n    def error(self):\n        mistakes = tf.not_equal(\n            tf.argmax(self.target, 2), tf.argmax(self.prediction, 2))\n        mistakes = tf.cast(mistakes, tf.float32)\n        mask = tf.sign(tf.reduce_max(tf.abs(self.target), reduction_indices=2))\n        mistakes *= mask\n        # Average over actual sequence lengths.\n        mistakes = tf.reduce_sum(mistakes, reduction_indices=1)\n        mistakes /= tf.cast(self.length, tf.float32)\n        return tf.reduce_mean(mistakes)\n\n    @staticmethod\n    def _weight_and_bias(in_size, out_size):\n        weight = tf.truncated_normal([in_size, out_size], stddev=0.01)\n        bias = tf.constant(0.1, shape=[out_size])\n        return tf.Variable(weight), tf.Variable(bias)\n\n#######################\n#Converting file to .wav from .sph file format... God dammit!!!\n\n#with open(train_filelist, 'r') as train_filelist, open(test_filelist, 'r') as test_filelist:\n    #train_mylist = train_filelist.read().splitlines()\n    #test_mylist = test_filelist.read().splitlines()\n    #for line in train_mylist:\n        #new_line = ' '.join(reversed(line))\n        #index_start = new_line.find('h')\n        #index_end = new_line.find('/')\n        #edited_line = ''.join(reversed(new_line[index_start+5:index_end])).strip().replace(\" \",\"\")\n        #new_file = edited_line + 'wav'\n        #os.system(line + ' &gt;&gt; ' + dnn_train + new_file)\n    #for line in test_mylist:\n        #new_line = ' '.join(reversed(line))\n        #index_start = new_line.find('h')\n        #index_end = new_line.find('/')\n        #edited_line = ''.join(reversed(new_line[index_start+5:index_end])).strip().replace(\" \",\"\")\n        #new_file = edited_line + 'wav'\n        #os.system(line + ' &gt;&gt; ' + dnn_test + new_file)\n\n\npath_train =  \"/home/JoeS/kaldi-trunk/egs/start/s5/data/train\"\npath_test =  \"/home/JoeS/kaldi-trunk/egs/start/s5/data/test\"\ndnn_train = \"/home/JoeS/kaldi-trunk/dnn/train/\"\ndnn_test = \"/home/JoeS/kaldi-trunk/dnn/test/\"\ndnn = \"/home/JoeS/kaldi-trunk/dnn/\"\npath  = \"/home/JoeS/kaldi-trunk/egs/start/s5/data/\"\nMFCC_dir = \"/home/JoeS/kaldi-trunk/egs/start/s5/mfcc/raw_mfcc_train.txt\"\n\ntrain_filelist = path_train+\"/wav_train.txt\"\ntest_filelist = path_test+\"/wav_test.txt\"\n\nos.chdir(path)\n\ndef binify(number):\n    divider = (36471330-10533580)/6\n    if number &gt;= divider*0 and number &lt; divider*1:\n        return 1\n    if number &gt;= divider*1 and number &lt; divider*2:\n        return 2\n    if number &gt;= divider*2 and number &lt; divider*3:\n        return 3\n    if number &gt;= divider*3 and number &lt; divider*4:\n        return 4\n    if number &gt;= divider*5 and number &lt; divider*6:\n        return 5\n    if number &gt;= divider*6:\n        return 6\n\ndef find_all(a_str, sub):\n    start = 0\n    while True:\n        start = a_str.find(sub, start)\n        if start == -1: return\n        yield start\n        start += len(sub) # use start += 1 to find overlapping matches\n\ndef load_sound_files(file_paths ,  names_input, data_input):\n    raw_sounds = []\n    names_output = []\n    data_output = []\n    class_output = []\n    for fp in file_paths:\n        X,sr = librosa.load(fp)\n        raw_sounds.append(X)\n        index = list(find_all(fp,'-'))\n        input_index = names_input.index(fp[index[1]+1:index[2]])\n        names_output.append(names_input[input_index])\n        data_output.append(data_input[input_index])\n        class_output.append(binify(data_input[input_index][0]))\n    return raw_sounds, names_output, data_output, class_output\n\ndef generate_list_of_names_data(file_path):\n    # Proprocess\n    # extract name and data\n    name = []\n    data = []\n    with open(MFCC_dir) as mfcc_feature_list:\n        content = [x.strip('\\n') for x in mfcc_feature_list.readlines()] # remove endlines\n        start_index_data = 0\n        end_index_data = 2\n        for number in range(0,42):\n            start = list(find_all(content[start_index_data],'['))[0]\n            end = list(find_all(content[end_index_data],']'))[0]\n            end_name = list(find_all(content[start_index_data],' '))[0]\n            substring_data = content[start_index_data][start+1 :]+content[end_index_data][: end]\n            substring_name = content[start_index_data][:end_name]\n            arr = np.array(substring_data.split(), dtype = float)\n            data.append(arr)\n            name.append(substring_name)\n            start_index_data = start_index_data + +3\n            end_index_data = end_index_data +3\n    return name, data\n\nfiles_train_path = [dnn_train+f for f in listdir(dnn_train) if isfile(join(dnn_train, f))]\nfiles_test_path = [dnn_test+f for f in listdir(dnn_test) if isfile(join(dnn_test, f))]\n\nfiles_train_name = [f for f in listdir(dnn_train) if isfile(join(dnn_train, f))]\nfiles_test_name = [f for f in listdir(dnn_test) if isfile(join(dnn_test, f))]\n\nos.chdir(dnn_train)\n\ntrain_name,train_data = generate_list_of_names_data(files_train_path)\ntrain_data, train_names, train_output_data, train_class_output = load_sound_files(files_train_path,train_name,train_data)\n\nmax_length = 0 ## Used for variable sequence input\n\nfor element in train_data:\n    if element.size &gt; max_length:\n        max_length = element.size\n\nNUM_EXAMPLES = len(train_data)/2\n\ntest_data = train_data[NUM_EXAMPLES:]\ntest_output = train_output_data[NUM_EXAMPLES:]\n\ntrain_data = train_data[:NUM_EXAMPLES]\ntrain_output = train_output_data[:NUM_EXAMPLES]\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n##-------------------MAIN----------------------------##\n\nif __name__ == '__main__':\n    data = tf.placeholder(tf.float32, [None, max_length, 1])\n    target = tf.placeholder(tf.float32, [None, 14, 1])\n    model = VariableSequenceLabelling(data, target)\n    sess = tf.Session()\n    sess.run(tf.initialize_all_variables())\n    for epoch in range(10):\n        for sample_set in range(100):\n            batch_train = train_data[sample_set]\n            batch_target = train_output[sample_set]\n            sess.run(model.optimize, {data: batch_train, target: batch_target})\n        test_set = test_data[epoch]\n        test_set_output = test_output[epoch]\n        error = sess.run(model.error, {data: test_set, target: test_set_output})\n        print('Epoch {:2d} error {:3.1f}%'.format(epoch + 1, 100 * error))\n</code></pre>\n\n<p>The error message I am receiving is that </p>\n\n<pre><code>Traceback (most recent call last):\n  File \"tensorflow_datapreprocess_mfcc_extraction_rnn.py\", line 239, in &lt;module&gt;\n    sess.run(model.optimize, {data: batch_train, target: batch_target})\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 340, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 553, in _run\n    % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\nValueError: Cannot feed value of shape (63945,) for Tensor u'Placeholder:0', which has shape '(?, 138915, 1)'\n</code></pre>\n\n<p>I guess debugging is more a stackoverflow question than a data science question, so instead of asking for help solving my issue regarding the code, would I like to know whether there is other framework which do natively support this, such I don't need to hack my solution.  I added my code such you know the structure of my input and output data.  It would be very appreciated if I could keep the structure. </p>\n",
                "tags": "<python><neural-network><regression><tensorflow><rnn>",
                "answers": [
                    [
                        "14728",
                        "2",
                        "14727",
                        "",
                        "",
                        "<p>Since tensors can be only of a fixed size, you have to zero-pad your sequences (usually from the left) to the maximum occurring length with something like:</p>\n\n<pre><code>max_len = max([len(x) for x in sequences])\nsequences = [np.pad(x, (max_len - len(x), 0), 'constant', constant_values = (0.,0.)) for x in sequences]\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "5418",
            "_score": 3.5594153,
            "_source": {
                "title": "Keras -- Transfer learning -- changing Input tensor shape",
                "content": "Keras -- Transfer learning -- changing Input tensor shape <p><a href=\"https://stackoverflow.com/questions/42187425/how-to-change-input-shape-in-sequential-model-in-keras\">This post</a> seems to indicate that what I want to accomplish is not possible. However, I'm not convinced of this -- given what I've already done, I don't see why what I want to do can not be achieved...</p>\n\n<p>I have two image datasets where one has images of shape (480, 720, 3) while the other has images of shape (540, 960, 3).</p>\n\n<p>I initialized a model using the following code:</p>\n\n<pre><code>input = Input(shape=(480, 720, 3), name='image_input')\n\ninitial_model = VGG16(weights='imagenet', include_top=False)\n\nfor layer in initial_model.layers:\n    layer.trainable = False\n\nx = Flatten()(initial_model(input))\nx = Dense(1000, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Dense(1000, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Dense(14, activation='linear')(x)\n\nmodel = Model(inputs=input, outputs=x)\nmodel.compile(loss='mse', optimizer='adam', metrics=['mae'])\n</code></pre>\n\n<p>Now that I've trained this model on the former dataset, I'd like to pop the input tensor layer off and prepend the model with a new input tensor with a shape that matches the image dimensions of the latter dataset.</p>\n\n<pre><code>model = load_model('path/to/my/trained/model.h5')\nold_input = model.pop(0)\nnew_input = Input(shape=(540, 960, 3), name='image_input')\nx = model(new_input)\nm = Model(inputs=new_input, outputs=x)\nm.save('transfer_model.h5')\n</code></pre>\n\n<p>which yields this error:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/engine/topology.py\", line 2506, in save\n    save_model(self, filepath, overwrite, include_optimizer)\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/models.py\", line 106, in save_model\n    'config': model.get_config()\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/engine/topology.py\", line 2322, in get_config\n    layer_config = layer.get_config()\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/engine/topology.py\", line 2370, in get_config\n    new_node_index = node_conversion_map[node_key]\nKeyError: u'image_input_ib-0'\n</code></pre>\n\n<p>In the post that I linked, maz states that there is a dimension mismatch that prevents changing the input layer of a model -- if this was the case, then how is that I put a (480, 720, 3) input layer in front of the VGG16 model which expects (224, 224, 3) images? </p>\n\n<p>I think a more likely issue is that my former model's output is expecting something different than what I'm giving it based on what fchollet is saying in <a href=\"https://github.com/fchollet/keras/issues/2790\" rel=\"noreferrer\">this post</a>. I'm syntactically confused, but I believe the whole <code>x = Layer()(x)</code> segment is constructing the layer piece by piece from input->output and simply throwing a different input in front is breaking it.</p>\n\n<p>I really have no idea though...</p>\n\n<p>Can somebody please enlighten me how to accomplish what I'm trying to do or, if it's not possible, explain to me why not?</p>\n <keras><p>The output width and height of the output dimensions of the VGGnet are a fixed portion of the input width and height because the only layers that change those dimensions are the pooling layers. The number of channels in the output is fixed to the number of filters in the last convolutional layer. The flatten layer will reshape this to get one dimension with the shape:</p>\n\n<p><code>((input_width * x) * (input_height * x) * channels)</code></p>\n\n<p>where x is some decimal &lt; 1. </p>\n\n<p>The main point is that the shape of the input to the Dense layers is dependent on width and height of the input to the entire model. The shape input to the dense layer cannot change as this would mean adding or removing nodes from the neural network.</p>\n\n<p>One way to avoid this is to use a global pooling layer rather than a flatten layer (usually GlobalAveragePooling2D) this will find the average per channel causing the shape of the input to the Dense layers to just be <code>(channels,)</code> which is not dependant on the input shape to the whole model.</p>\n\n<p>Once this is done none of layers in the network are dependent on the width and height of the input so the input layer can be changed with something like</p>\n\n<pre><code>input_layer = InputLayer(input_shape=(480, 720, 3), name=\"input_1\")\nmodel.layers[0] = input_layer\n</code></pre>\n<p>Here is another solution, not specific to the VGG model. </p>\n\n<p>Note, that the weights of the dense layer cannot be copied (and will thus be newly initialized). This makes sense, because the shape of the weights differs in the old and the new model.</p>\n\n<pre><code>import keras\nimport numpy as np\n\ndef get_model():\n    old_input_shape = (20, 20, 3)\n    model = keras.models.Sequential()\n    model.add(keras.layers.Conv2D(9, (3, 3), padding=\"same\", input_shape=old_input_shape))\n    model.add(keras.layers.MaxPooling2D((2, 2)))\n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0001), metrics=['acc'], )\n    model.summary()\n    return model\n\ndef change_model(model, new_input_shape=(None, 40, 40, 3)):\n    # replace input shape of first layer\n    model._layers[1].batch_input_shape = new_input_shape\n\n    # feel free to modify additional parameters of other layers, for example...\n    model._layers[2].pool_size = (8, 8)\n    model._layers[2].strides = (8, 8)\n\n    # rebuild model architecture by exporting and importing via json\n    new_model = keras.models.model_from_json(model.to_json())\n    new_model.summary()\n\n    # copy weights from old model to new one\n    for layer in new_model.layers:\n        try:\n            layer.set_weights(model.get_layer(name=layer.name).get_weights())\n        except:\n            print(\"Could not transfer weights for layer {}\".format(layer.name))\n\n    # test new model on a random input image\n    X = np.random.rand(10, 40, 40, 3)\n    y_pred = new_model.predict(X)\n    print(y_pred)\n\n    return new_model\n\nif __name__ == '__main__':\n    model = get_model()\n    new_model = change_model(model)\n</code></pre>\n<p>You can do this by creating a new VGG16 model instance with the new input shape <code>new_shape</code> and copying over all the layer weights. The code is roughly</p>\n\n<pre><code>new_model = VGG16(weights=None, input_shape=new_shape, include_top=False)\nfor new_layer, layer in zip(new_model.layers[1:], model.layers[1:]):\n    new_layer.set_weights(layer.get_weights())\n</code></pre>\n",
                "codes": [
                    [
                        "input_layer = InputLayer(input_shape=(480, 720, 3), name=\"input_1\")\nmodel.layers[0] = input_layer\n"
                    ],
                    [
                        "import keras\nimport numpy as np\n\ndef get_model():\n    old_input_shape = (20, 20, 3)\n    model = keras.models.Sequential()\n    model.add(keras.layers.Conv2D(9, (3, 3), padding=\"same\", input_shape=old_input_shape))\n    model.add(keras.layers.MaxPooling2D((2, 2)))\n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0001), metrics=['acc'], )\n    model.summary()\n    return model\n\ndef change_model(model, new_input_shape=(None, 40, 40, 3)):\n    # replace input shape of first layer\n    model._layers[1].batch_input_shape = new_input_shape\n\n    # feel free to modify additional parameters of other layers, for example...\n    model._layers[2].pool_size = (8, 8)\n    model._layers[2].strides = (8, 8)\n\n    # rebuild model architecture by exporting and importing via json\n    new_model = keras.models.model_from_json(model.to_json())\n    new_model.summary()\n\n    # copy weights from old model to new one\n    for layer in new_model.layers:\n        try:\n            layer.set_weights(model.get_layer(name=layer.name).get_weights())\n        except:\n            print(\"Could not transfer weights for layer {}\".format(layer.name))\n\n    # test new model on a random input image\n    X = np.random.rand(10, 40, 40, 3)\n    y_pred = new_model.predict(X)\n    print(y_pred)\n\n    return new_model\n\nif __name__ == '__main__':\n    model = get_model()\n    new_model = change_model(model)\n"
                    ],
                    [
                        "new_model = VGG16(weights=None, input_shape=new_shape, include_top=False)\nfor new_layer, layer in zip(new_model.layers[1:], model.layers[1:]):\n    new_layer.set_weights(layer.get_weights())\n"
                    ]
                ],
                "question_id:": "21734",
                "question_votes:": "12",
                "question_text:": "<p><a href=\"https://stackoverflow.com/questions/42187425/how-to-change-input-shape-in-sequential-model-in-keras\">This post</a> seems to indicate that what I want to accomplish is not possible. However, I'm not convinced of this -- given what I've already done, I don't see why what I want to do can not be achieved...</p>\n\n<p>I have two image datasets where one has images of shape (480, 720, 3) while the other has images of shape (540, 960, 3).</p>\n\n<p>I initialized a model using the following code:</p>\n\n<pre><code>input = Input(shape=(480, 720, 3), name='image_input')\n\ninitial_model = VGG16(weights='imagenet', include_top=False)\n\nfor layer in initial_model.layers:\n    layer.trainable = False\n\nx = Flatten()(initial_model(input))\nx = Dense(1000, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Dense(1000, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Dense(14, activation='linear')(x)\n\nmodel = Model(inputs=input, outputs=x)\nmodel.compile(loss='mse', optimizer='adam', metrics=['mae'])\n</code></pre>\n\n<p>Now that I've trained this model on the former dataset, I'd like to pop the input tensor layer off and prepend the model with a new input tensor with a shape that matches the image dimensions of the latter dataset.</p>\n\n<pre><code>model = load_model('path/to/my/trained/model.h5')\nold_input = model.pop(0)\nnew_input = Input(shape=(540, 960, 3), name='image_input')\nx = model(new_input)\nm = Model(inputs=new_input, outputs=x)\nm.save('transfer_model.h5')\n</code></pre>\n\n<p>which yields this error:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/engine/topology.py\", line 2506, in save\n    save_model(self, filepath, overwrite, include_optimizer)\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/models.py\", line 106, in save_model\n    'config': model.get_config()\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/engine/topology.py\", line 2322, in get_config\n    layer_config = layer.get_config()\n  File \"/home/aicg2/.local/lib/python2.7/site-packages/keras/engine/topology.py\", line 2370, in get_config\n    new_node_index = node_conversion_map[node_key]\nKeyError: u'image_input_ib-0'\n</code></pre>\n\n<p>In the post that I linked, maz states that there is a dimension mismatch that prevents changing the input layer of a model -- if this was the case, then how is that I put a (480, 720, 3) input layer in front of the VGG16 model which expects (224, 224, 3) images? </p>\n\n<p>I think a more likely issue is that my former model's output is expecting something different than what I'm giving it based on what fchollet is saying in <a href=\"https://github.com/fchollet/keras/issues/2790\" rel=\"noreferrer\">this post</a>. I'm syntactically confused, but I believe the whole <code>x = Layer()(x)</code> segment is constructing the layer piece by piece from input->output and simply throwing a different input in front is breaking it.</p>\n\n<p>I really have no idea though...</p>\n\n<p>Can somebody please enlighten me how to accomplish what I'm trying to do or, if it's not possible, explain to me why not?</p>\n",
                "tags": "<keras>",
                "answers": [
                    [
                        "52310",
                        "2",
                        "21734",
                        "",
                        "",
                        "<p>The output width and height of the output dimensions of the VGGnet are a fixed portion of the input width and height because the only layers that change those dimensions are the pooling layers. The number of channels in the output is fixed to the number of filters in the last convolutional layer. The flatten layer will reshape this to get one dimension with the shape:</p>\n\n<p><code>((input_width * x) * (input_height * x) * channels)</code></p>\n\n<p>where x is some decimal &lt; 1. </p>\n\n<p>The main point is that the shape of the input to the Dense layers is dependent on width and height of the input to the entire model. The shape input to the dense layer cannot change as this would mean adding or removing nodes from the neural network.</p>\n\n<p>One way to avoid this is to use a global pooling layer rather than a flatten layer (usually GlobalAveragePooling2D) this will find the average per channel causing the shape of the input to the Dense layers to just be <code>(channels,)</code> which is not dependant on the input shape to the whole model.</p>\n\n<p>Once this is done none of layers in the network are dependent on the width and height of the input so the input layer can be changed with something like</p>\n\n<pre><code>input_layer = InputLayer(input_shape=(480, 720, 3), name=\"input_1\")\nmodel.layers[0] = input_layer\n</code></pre>\n",
                        "",
                        "1"
                    ],
                    [
                        "47246",
                        "2",
                        "21734",
                        "",
                        "",
                        "<p>Here is another solution, not specific to the VGG model. </p>\n\n<p>Note, that the weights of the dense layer cannot be copied (and will thus be newly initialized). This makes sense, because the shape of the weights differs in the old and the new model.</p>\n\n<pre><code>import keras\nimport numpy as np\n\ndef get_model():\n    old_input_shape = (20, 20, 3)\n    model = keras.models.Sequential()\n    model.add(keras.layers.Conv2D(9, (3, 3), padding=\"same\", input_shape=old_input_shape))\n    model.add(keras.layers.MaxPooling2D((2, 2)))\n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0001), metrics=['acc'], )\n    model.summary()\n    return model\n\ndef change_model(model, new_input_shape=(None, 40, 40, 3)):\n    # replace input shape of first layer\n    model._layers[1].batch_input_shape = new_input_shape\n\n    # feel free to modify additional parameters of other layers, for example...\n    model._layers[2].pool_size = (8, 8)\n    model._layers[2].strides = (8, 8)\n\n    # rebuild model architecture by exporting and importing via json\n    new_model = keras.models.model_from_json(model.to_json())\n    new_model.summary()\n\n    # copy weights from old model to new one\n    for layer in new_model.layers:\n        try:\n            layer.set_weights(model.get_layer(name=layer.name).get_weights())\n        except:\n            print(\"Could not transfer weights for layer {}\".format(layer.name))\n\n    # test new model on a random input image\n    X = np.random.rand(10, 40, 40, 3)\n    y_pred = new_model.predict(X)\n    print(y_pred)\n\n    return new_model\n\nif __name__ == '__main__':\n    model = get_model()\n    new_model = change_model(model)\n</code></pre>\n",
                        "",
                        ""
                    ],
                    [
                        "27391",
                        "2",
                        "21734",
                        "",
                        "",
                        "<p>You can do this by creating a new VGG16 model instance with the new input shape <code>new_shape</code> and copying over all the layer weights. The code is roughly</p>\n\n<pre><code>new_model = VGG16(weights=None, input_shape=new_shape, include_top=False)\nfor new_layer, layer in zip(new_model.layers[1:], model.layers[1:]):\n    new_layer.set_weights(layer.get_weights())\n</code></pre>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6258",
            "_score": 3.5594153,
            "_source": {
                "title": "What is a minimal setup to solve the CartPole-v0 with DQN?",
                "content": "What is a minimal setup to solve the CartPole-v0 with DQN? <p>I solved the <a href=\"https://gym.openai.com/envs/CartPole-v0/\" rel=\"nofollow noreferrer\">CartPole-v0</a> with a CEM agent pretty easily (<a href=\"https://martin-thoma.com/rl-agents/\" rel=\"nofollow noreferrer\">experiments and code</a>), but I struggle to find a setup which works with DQN.</p>\n\n<p>Do you know which parameters should be adjusted so that the mean reward is about 200 for this problem?</p>\n\n<h2>What I tried</h2>\n\n<ul>\n<li>Adjustments in the model: Deeper / less deep, neurons per layer</li>\n<li>Memory size (how many steps are stored for replay)</li>\n</ul>\n\n<h2>What I'm unsure about</h2>\n\n<ul>\n<li>How should I choose the memory? Is higher always better? - Some quick experiments indicate that there might be a sweet-spot - not too high, but also not too low. I have no idea how to figure out the region of that sweet spot.</li>\n<li>Window size: Having a window size of 1 seems to work well in this case. Bigger window sizes seem to be worse. Is there any indicator when to increase the Window size?</li>\n<li>How to deal with delayed rewards: Suppose the CartPole did not start upright, but down. Then it would only get rewards late. Would this be a case for increasing the window size?</li>\n</ul>\n\n<h2>My current code</h2>\n\n<p>I use <a href=\"https://github.com/matthiasplappert/keras-rl\" rel=\"nofollow noreferrer\">Keras-RL</a> for the model and <a href=\"https://github.com/openai/gym\" rel=\"nofollow noreferrer\">OpenAI gym</a> for the environment.</p>\n\n<p>Here is my code</p>\n\n<pre><code>#!/usr/bin/env python\n\nimport numpy as np\nimport gym\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten\nfrom keras.optimizers import Adam\n\nfrom rl.agents.dqn import DQNAgent\nfrom rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\nfrom rl.memory import EpisodeParameterMemory\n\n\ndef main(env_name, nb_steps):\n    # Get the environment and extract the number of actions.\n    env = gym.make(env_name)\n    np.random.seed(123)\n    env.seed(123)\n\n    nb_actions = env.action_space.n\n    input_shape = (1,) + env.observation_space.shape\n    model = create_nn_model(input_shape, nb_actions)\n\n    # Finally, we configure and compile our agent.\n    memory = EpisodeParameterMemory(limit=2000, window_length=1)\n\n    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1.,\n                                  value_min=.1, value_test=.05,\n                                  nb_steps=1000000)\n    agent = DQNAgent(model=model, nb_actions=nb_actions, policy=policy,\n                     memory=memory, nb_steps_warmup=50000,\n                     gamma=.99, target_model_update=10000,\n                     train_interval=4, delta_clip=1.)\n    agent.compile(Adam(lr=.00025), metrics=['mae'])\n    agent.fit(env, nb_steps=nb_steps, visualize=False, verbose=2)\n\n    # After training is done, we save the best weights.\n    agent.save_weights('dqn_{}_params.h5f'.format(env_name), overwrite=True)\n\n    # Finally, evaluate the agent\n    history = agent.test(env, nb_episodes=100, visualize=False)\n    rewards = np.array(history.history['episode_reward'])\n    print((\"Test rewards (#episodes={}): mean={:&gt;5.2f}, std={:&gt;5.2f}, \"\n           \"min={:&gt;5.2f}, max={:&gt;5.2f}\")\n          .format(len(rewards),\n                  rewards.mean(),\n                  rewards.std(),\n                  rewards.min(),\n                  rewards.max()))\n\n\ndef create_nn_model(input_shape, nb_actions):\n    \"\"\"\n    Create a neural network model which maps the input to actions.\n\n    Parameters\n    ----------\n    input_shape : tuple of int\n    nb_actoins : int\n\n    Returns\n    -------\n    model : keras Model object\n    \"\"\"\n    model = Sequential()\n    model.add(Flatten(input_shape=input_shape))\n    model.add(Dense(32))\n    model.add(Activation('relu'))\n    model.add(Dense(64))\n    model.add(Activation('relu'))\n    model.add(Dense(64))\n    model.add(Activation('relu'))\n    model.add(Dense(512))\n    model.add(Activation('relu'))\n    model.add(Dense(nb_actions))\n    model.add(Activation('linear'))\n    print(model.summary())\n    return model\n\n\ndef get_parser():\n    \"\"\"Get parser object.\"\"\"\n    from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n    parser = ArgumentParser(description=__doc__,\n                            formatter_class=ArgumentDefaultsHelpFormatter)\n    parser.add_argument(\"--env\",\n                        dest=\"environment\",\n                        help=\"OpenAI Gym environment\",\n                        metavar=\"ENVIRONMENT\",\n                        default=\"CartPole-v0\")\n    parser.add_argument(\"--steps\",\n                        dest=\"steps\",\n                        default=10000,\n                        type=int,\n                        help=\"how many steps is the model trained?\")\n    return parser\n\n\nif __name__ == \"__main__\":\n    args = get_parser().parse_args()\n    main(args.environment, args.steps)\n</code></pre>\n <reinforcement-learning><keras-rl><openai-gym><dqn><p>As previously stated in the comment, you could simply look at the example in the repository you're using.</p>\n\n<p>These are a couple of comments on your choices:</p>\n\n<ul>\n<li>A rule of thumb is to decrease the number of hidden units when going deeper in a dense NN. Instead, you do the opposite: you start with 32 hidden units and ends with 512 hidden units. Also, there is no need for so many hidden units. You could easily solve with 32 or 16 units for each hidden layer.</li>\n<li>Another rule of thumb: the deeper your NN is, the slower it is to learn. That saying, it learns faster if you put only one hidden layer with the same total number of units you use right now in your hidden layers. However, learn faster doesn't mean to learn better: usually, a deeper NN shows better results in the long term. Of course, it doesn't if you have thousands of hidden layers with only one unit each.</li>\n<li>the learning rate: the slower it is your NN to learn and a better result it will show in the long run but, what is the long run? This is a sort of trade-off because you cannot wait years to train a simple NN. I had good results with a learning rate of 1e-3 but this depends on the size of the network, how deep it is, what is your batch size, etc.</li>\n<li>memory and warmup steps: what is the purpose of having 50000 time-steps of warmup if you only store 2000? No sense. Also, for this kind of environment, you probably don't have any need for a warmup. On the other hand, have a bigger memory is almost always good. The only downside is usually only the space.</li>\n<li>target model update: are you really sure of that value? I think that you used it without looking at what it represents.</li>\n<li>policy: I think that you should use a policy built for q learning. there are a lot already implemented like <code>EpsGreedyQPolicy</code>, <code>GreedyQPolicy</code>, <code>BoltzmannQPolicy</code>, <code>MaxBoltzmannQPolicy</code>, and <code>BoltzmannGumbelQPolicy</code>.</li>\n</ul>\n\n<hr>\n\n<p>To conclude, look at the examples, they are not self-explanatory but are a good starting point. Modify them and look what it changes when you only change one parameter. After that, try to change the environment, because the cart-pole environment is very easy for a DQN. Mountain car environment is a good next step (but try to don't reshape the reward, otherwise is too easy).</p>\n\n<p>Happy learning!</p>\n",
                "codes": [
                    []
                ],
                "question_id:": "24513",
                "question_votes:": "3",
                "question_text:": "<p>I solved the <a href=\"https://gym.openai.com/envs/CartPole-v0/\" rel=\"nofollow noreferrer\">CartPole-v0</a> with a CEM agent pretty easily (<a href=\"https://martin-thoma.com/rl-agents/\" rel=\"nofollow noreferrer\">experiments and code</a>), but I struggle to find a setup which works with DQN.</p>\n\n<p>Do you know which parameters should be adjusted so that the mean reward is about 200 for this problem?</p>\n\n<h2>What I tried</h2>\n\n<ul>\n<li>Adjustments in the model: Deeper / less deep, neurons per layer</li>\n<li>Memory size (how many steps are stored for replay)</li>\n</ul>\n\n<h2>What I'm unsure about</h2>\n\n<ul>\n<li>How should I choose the memory? Is higher always better? - Some quick experiments indicate that there might be a sweet-spot - not too high, but also not too low. I have no idea how to figure out the region of that sweet spot.</li>\n<li>Window size: Having a window size of 1 seems to work well in this case. Bigger window sizes seem to be worse. Is there any indicator when to increase the Window size?</li>\n<li>How to deal with delayed rewards: Suppose the CartPole did not start upright, but down. Then it would only get rewards late. Would this be a case for increasing the window size?</li>\n</ul>\n\n<h2>My current code</h2>\n\n<p>I use <a href=\"https://github.com/matthiasplappert/keras-rl\" rel=\"nofollow noreferrer\">Keras-RL</a> for the model and <a href=\"https://github.com/openai/gym\" rel=\"nofollow noreferrer\">OpenAI gym</a> for the environment.</p>\n\n<p>Here is my code</p>\n\n<pre><code>#!/usr/bin/env python\n\nimport numpy as np\nimport gym\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten\nfrom keras.optimizers import Adam\n\nfrom rl.agents.dqn import DQNAgent\nfrom rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\nfrom rl.memory import EpisodeParameterMemory\n\n\ndef main(env_name, nb_steps):\n    # Get the environment and extract the number of actions.\n    env = gym.make(env_name)\n    np.random.seed(123)\n    env.seed(123)\n\n    nb_actions = env.action_space.n\n    input_shape = (1,) + env.observation_space.shape\n    model = create_nn_model(input_shape, nb_actions)\n\n    # Finally, we configure and compile our agent.\n    memory = EpisodeParameterMemory(limit=2000, window_length=1)\n\n    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1.,\n                                  value_min=.1, value_test=.05,\n                                  nb_steps=1000000)\n    agent = DQNAgent(model=model, nb_actions=nb_actions, policy=policy,\n                     memory=memory, nb_steps_warmup=50000,\n                     gamma=.99, target_model_update=10000,\n                     train_interval=4, delta_clip=1.)\n    agent.compile(Adam(lr=.00025), metrics=['mae'])\n    agent.fit(env, nb_steps=nb_steps, visualize=False, verbose=2)\n\n    # After training is done, we save the best weights.\n    agent.save_weights('dqn_{}_params.h5f'.format(env_name), overwrite=True)\n\n    # Finally, evaluate the agent\n    history = agent.test(env, nb_episodes=100, visualize=False)\n    rewards = np.array(history.history['episode_reward'])\n    print((\"Test rewards (#episodes={}): mean={:&gt;5.2f}, std={:&gt;5.2f}, \"\n           \"min={:&gt;5.2f}, max={:&gt;5.2f}\")\n          .format(len(rewards),\n                  rewards.mean(),\n                  rewards.std(),\n                  rewards.min(),\n                  rewards.max()))\n\n\ndef create_nn_model(input_shape, nb_actions):\n    \"\"\"\n    Create a neural network model which maps the input to actions.\n\n    Parameters\n    ----------\n    input_shape : tuple of int\n    nb_actoins : int\n\n    Returns\n    -------\n    model : keras Model object\n    \"\"\"\n    model = Sequential()\n    model.add(Flatten(input_shape=input_shape))\n    model.add(Dense(32))\n    model.add(Activation('relu'))\n    model.add(Dense(64))\n    model.add(Activation('relu'))\n    model.add(Dense(64))\n    model.add(Activation('relu'))\n    model.add(Dense(512))\n    model.add(Activation('relu'))\n    model.add(Dense(nb_actions))\n    model.add(Activation('linear'))\n    print(model.summary())\n    return model\n\n\ndef get_parser():\n    \"\"\"Get parser object.\"\"\"\n    from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n    parser = ArgumentParser(description=__doc__,\n                            formatter_class=ArgumentDefaultsHelpFormatter)\n    parser.add_argument(\"--env\",\n                        dest=\"environment\",\n                        help=\"OpenAI Gym environment\",\n                        metavar=\"ENVIRONMENT\",\n                        default=\"CartPole-v0\")\n    parser.add_argument(\"--steps\",\n                        dest=\"steps\",\n                        default=10000,\n                        type=int,\n                        help=\"how many steps is the model trained?\")\n    return parser\n\n\nif __name__ == \"__main__\":\n    args = get_parser().parse_args()\n    main(args.environment, args.steps)\n</code></pre>\n",
                "tags": "<reinforcement-learning><keras-rl><openai-gym><dqn>",
                "answers": [
                    [
                        "41931",
                        "2",
                        "24513",
                        "",
                        "",
                        "<p>As previously stated in the comment, you could simply look at the example in the repository you're using.</p>\n\n<p>These are a couple of comments on your choices:</p>\n\n<ul>\n<li>A rule of thumb is to decrease the number of hidden units when going deeper in a dense NN. Instead, you do the opposite: you start with 32 hidden units and ends with 512 hidden units. Also, there is no need for so many hidden units. You could easily solve with 32 or 16 units for each hidden layer.</li>\n<li>Another rule of thumb: the deeper your NN is, the slower it is to learn. That saying, it learns faster if you put only one hidden layer with the same total number of units you use right now in your hidden layers. However, learn faster doesn't mean to learn better: usually, a deeper NN shows better results in the long term. Of course, it doesn't if you have thousands of hidden layers with only one unit each.</li>\n<li>the learning rate: the slower it is your NN to learn and a better result it will show in the long run but, what is the long run? This is a sort of trade-off because you cannot wait years to train a simple NN. I had good results with a learning rate of 1e-3 but this depends on the size of the network, how deep it is, what is your batch size, etc.</li>\n<li>memory and warmup steps: what is the purpose of having 50000 time-steps of warmup if you only store 2000? No sense. Also, for this kind of environment, you probably don't have any need for a warmup. On the other hand, have a bigger memory is almost always good. The only downside is usually only the space.</li>\n<li>target model update: are you really sure of that value? I think that you used it without looking at what it represents.</li>\n<li>policy: I think that you should use a policy built for q learning. there are a lot already implemented like <code>EpsGreedyQPolicy</code>, <code>GreedyQPolicy</code>, <code>BoltzmannQPolicy</code>, <code>MaxBoltzmannQPolicy</code>, and <code>BoltzmannGumbelQPolicy</code>.</li>\n</ul>\n\n<hr>\n\n<p>To conclude, look at the examples, they are not self-explanatory but are a good starting point. Modify them and look what it changes when you only change one parameter. After that, try to change the environment, because the cart-pole environment is very easy for a DQN. Mountain car environment is a good next step (but try to don't reshape the reward, otherwise is too easy).</p>\n\n<p>Happy learning!</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "11886",
            "_score": 3.5594153,
            "_source": {
                "title": "Nearest Neighbors on mixed data types in high dimensions",
                "content": "Nearest Neighbors on mixed data types in high dimensions <p>I would like to be able to use nearest neighbors to attempt to find the most similar samples to a subclass of samples (think treated vs untreated) in a dataset with continuous, categorical, and text features.</p>\n\n<p>Toy data set:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder, QuantileTransformer\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import TruncatedSVD    \n\nnp.set_printoptions(suppress=True)\n\na = [20, 100, 10000, 500]\nb = [1, 2, 3, 2]\nc = ['dog', 'cat', 'foo', 'cat']\nd = ['apple apple fruit',\n     'mercedes bmw chevrolet',\n     'monster dragon snake',\n     'mercedes chevrolet bmw buick']\n\nz = [a,b,c,d]\n\nnames = {0: 'col1', 1:'col2', 2:'col3', 3:'col4'}\n\nX = pd.DataFrame(z).T\nX = X.rename(names, axis='columns')\nX\n</code></pre>\n\n<p>Will create:</p>\n\n<pre><code>   col1    col2 col3    col4\n0   20      1   dog     apple apple fruit\n1   100     2   cat     mercedes bmw chevrolet\n2   10000   3   foo     monster dragon snake\n3   500     2   cat     mercedes chevrolet bmw buick\n</code></pre>\n\n<p>As we can see, samples 1 and 3 are the most related. They have many of the same vocabulary, share two labels (col2 + col3) and considering the distribution of col1 they are fairly close together. We transform them into a feature array and ask for nearest neighbors like so:</p>\n\n<pre><code>numeric = ['col1']\nnumeric_transformer = Pipeline(steps=[('scaler', QuantileTransformer())])\n\ncat = ['col2', 'col3']\ncat_transformer = Pipeline(steps=[('onehot', OneHotEncoder())])\n\ntext = ['col4']\ntext_transformer = Pipeline(steps=[('tfidf', TfidfVectorizer()),\n                                   ('svd', TruncatedSVD(n_components=2))])\n\nprep = ColumnTransformer(transformers=[('num', numeric_transformer, numeric), \n                                       ('cat', cat_transformer, cat),\n                                       ('text', text_transformer, 'col4')], sparse_threshold=0)\n\nX_transformed = prep.fit_transform(X)\n\nnn = NearestNeighbors(n_neighbors=2)\nnn.fit(X_transformed)\n\nd, i = nn.kneighbors(X_transformed[1].reshape(1,-1))\ni\n</code></pre>\n\n<p>Correctly returns <code>array([[1, 3]], dtype=int64)</code> with the 1 indicating the self match and the 3 being the nearest neighbor. </p>\n\n<p>But on a real world dataset, across 100+ dimensions, should I be using a custom distance function? for nearest neighbors with sklearn, if the column was one of the ones that was text, we could use cosine distance, another distance across the high dimensional one hot encoded variables, and another distance calculation with real continuous transformed variables (col1). </p>\n\n<p>But is this....<strong>hacky</strong>? Is there some way to deal with the heterogenous data for nearest neighbors search without this? I worry that my decisions as to how to weight each of the three types of variables make the end results very subjective and open to criticism. </p>\n <machine-learning><python><scikit-learn><similarity><distance><p>Conceptually, there's no reason why this 'could' not work, but practically speaking, there are probably better approaches than using KNN.  </p>\n\n<p><strong>Suitability of KNN</strong></p>\n\n<p>One immediate problem with KNN is that each new instance must be compared to each existing reference instance before a class can be determined. As the number of reference instances increases, the time to classify a new instance increases.  With highly dimensional data, you're going to need a lot of reference instances.</p>\n\n<p><strong>Dimensionality of the Data</strong></p>\n\n<p>If you are set on using KNN, you will want to do everything you can to reduce the number of dimensions, particularly on the categorical columns.  In your example, you may be better off reducing the animals down to some larger groups, for example: [Pet, Domesticated, Wild] or biological family.  If not, once you encode the categorical values, you will maybe have thousands (to millions) of animal columns alone.  If you don't have many examples of each, you're going to match on everything but the animal because\n<span class=\"math-container\">$$Distance\\ between:\\ dog\\ and\\ cat = 1$$</span>\n<span class=\"math-container\">$$Distance\\ between:\\ dog\\ and\\ giraffe = 1$$</span>\nSo, this will mean other attributes in the data will likely be more similar, yet, they may be uninformative to the classification process.  For example, number of legs.</p>\n\n<p>On the positive side though, KNN may deal with the introduction of new attributes a little better than others because the classification is based on the currently available data, so adding a new column is not as big a deal as say adding a new column to a neural network, which will need to be retrained to be able to accept a new data set.</p>\n\n<p><strong>Conclusion</strong></p>\n\n<p>While there are other pros and cons to KNN and ways to optimize it for performance; based on your description of the data, and perhaps making a few assumptions, KNN does not sound like a good fit for your classification problem. </p>\n\n<p>Most models are going to perform better if you can reduce the number of dimensions, but if the number and nature of attributes is relatively static, I would start with something like a <code>Decision Tree</code>.  The benefit of starting with a decision tree is that you can get a feel for the importance of the columns to the class assigned.</p>\n<p>It's been a while since this but I did eventually get around to a solution:</p>\n\n<pre><code>from scipy.spatial.distance import euclidean, cosine, dice\n\ncat_vars = ['col2', 'col3']\nuniques = []\nfor c in cat_vars:\n    uniques.append(X[c].nunique()) \ncat_vars_width = sum(uniques)\ncon_vars = ['col1']\n\n# use a custom distance func to apply appropriate\n# distance calcs to specific columns\n\ncon_vars_indices = list(range(0, con_vars_width))\ncat_vars_indices = list(range(con_vars_width, con_vars_width + cat_vars_width))    \ntfidf_indices = list(range(con_vars_width + cat_vars_width, X_normal.shape[1]))\n\ndef custom_distance_maker(con_vars_indices, cat_vars_indices, tfidf_indices):\n    def custom_distance(x,y):\n         x_con = x[con_vars_indices]\n         y_con = y[con_vars_indices]\n         x_cat = x[cat_vars_indices]\n         y_cat = y[cat_vars_indices]\n         x_tfidf = x[tfidf_indices]\n         y_tfidf = y[tfidf_indices]\n\n         d_con = euclidean(x_con,y_con)\n         d_cat = dice(x_cat,y_cat)\n         d_tfidf = cosine(x_tfidf,y_tfidf)\n         return d_con + d_cat + d_tfidf\n    return custom_distance\n</code></pre>\n\n<p>So we use the knowledge of how many columns are going to be created by the one hot encoding and how many columns are just real continuous variables and apply distance calculations appropriate for those data types to that specific portion of the big array. It's slow but honestly gives some pretty good results that satisified my client. </p>\n\n<p>The custom distance function is easy enough to modify as well, allowing you to 'weight' the different variables you want to match on. For example, if you cared more about text matching, just multiply it in such a fashion as to magnify any differences in the cosine similarity search.</p>\n\n<p>I hope some one else finds this hacky solution useful for similarity searches in heterogenuous data. </p>\n",
                "codes": [
                    [],
                    [
                        "from scipy.spatial.distance import euclidean, cosine, dice\n\ncat_vars = ['col2', 'col3']\nuniques = []\nfor c in cat_vars:\n    uniques.append(X[c].nunique()) \ncat_vars_width = sum(uniques)\ncon_vars = ['col1']\n\n# use a custom distance func to apply appropriate\n# distance calcs to specific columns\n\ncon_vars_indices = list(range(0, con_vars_width))\ncat_vars_indices = list(range(con_vars_width, con_vars_width + cat_vars_width))    \ntfidf_indices = list(range(con_vars_width + cat_vars_width, X_normal.shape[1]))\n\ndef custom_distance_maker(con_vars_indices, cat_vars_indices, tfidf_indices):\n    def custom_distance(x,y):\n         x_con = x[con_vars_indices]\n         y_con = y[con_vars_indices]\n         x_cat = x[cat_vars_indices]\n         y_cat = y[cat_vars_indices]\n         x_tfidf = x[tfidf_indices]\n         y_tfidf = y[tfidf_indices]\n\n         d_con = euclidean(x_con,y_con)\n         d_cat = dice(x_cat,y_cat)\n         d_tfidf = cosine(x_tfidf,y_tfidf)\n         return d_con + d_cat + d_tfidf\n    return custom_distance\n"
                    ]
                ],
                "question_id:": "41859",
                "question_votes:": "",
                "question_text:": "<p>I would like to be able to use nearest neighbors to attempt to find the most similar samples to a subclass of samples (think treated vs untreated) in a dataset with continuous, categorical, and text features.</p>\n\n<p>Toy data set:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder, QuantileTransformer\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import TruncatedSVD    \n\nnp.set_printoptions(suppress=True)\n\na = [20, 100, 10000, 500]\nb = [1, 2, 3, 2]\nc = ['dog', 'cat', 'foo', 'cat']\nd = ['apple apple fruit',\n     'mercedes bmw chevrolet',\n     'monster dragon snake',\n     'mercedes chevrolet bmw buick']\n\nz = [a,b,c,d]\n\nnames = {0: 'col1', 1:'col2', 2:'col3', 3:'col4'}\n\nX = pd.DataFrame(z).T\nX = X.rename(names, axis='columns')\nX\n</code></pre>\n\n<p>Will create:</p>\n\n<pre><code>   col1    col2 col3    col4\n0   20      1   dog     apple apple fruit\n1   100     2   cat     mercedes bmw chevrolet\n2   10000   3   foo     monster dragon snake\n3   500     2   cat     mercedes chevrolet bmw buick\n</code></pre>\n\n<p>As we can see, samples 1 and 3 are the most related. They have many of the same vocabulary, share two labels (col2 + col3) and considering the distribution of col1 they are fairly close together. We transform them into a feature array and ask for nearest neighbors like so:</p>\n\n<pre><code>numeric = ['col1']\nnumeric_transformer = Pipeline(steps=[('scaler', QuantileTransformer())])\n\ncat = ['col2', 'col3']\ncat_transformer = Pipeline(steps=[('onehot', OneHotEncoder())])\n\ntext = ['col4']\ntext_transformer = Pipeline(steps=[('tfidf', TfidfVectorizer()),\n                                   ('svd', TruncatedSVD(n_components=2))])\n\nprep = ColumnTransformer(transformers=[('num', numeric_transformer, numeric), \n                                       ('cat', cat_transformer, cat),\n                                       ('text', text_transformer, 'col4')], sparse_threshold=0)\n\nX_transformed = prep.fit_transform(X)\n\nnn = NearestNeighbors(n_neighbors=2)\nnn.fit(X_transformed)\n\nd, i = nn.kneighbors(X_transformed[1].reshape(1,-1))\ni\n</code></pre>\n\n<p>Correctly returns <code>array([[1, 3]], dtype=int64)</code> with the 1 indicating the self match and the 3 being the nearest neighbor. </p>\n\n<p>But on a real world dataset, across 100+ dimensions, should I be using a custom distance function? for nearest neighbors with sklearn, if the column was one of the ones that was text, we could use cosine distance, another distance across the high dimensional one hot encoded variables, and another distance calculation with real continuous transformed variables (col1). </p>\n\n<p>But is this....<strong>hacky</strong>? Is there some way to deal with the heterogenous data for nearest neighbors search without this? I worry that my decisions as to how to weight each of the three types of variables make the end results very subjective and open to criticism. </p>\n",
                "tags": "<machine-learning><python><scikit-learn><similarity><distance>",
                "answers": [
                    [
                        "41868",
                        "2",
                        "41859",
                        "",
                        "",
                        "<p>Conceptually, there's no reason why this 'could' not work, but practically speaking, there are probably better approaches than using KNN.  </p>\n\n<p><strong>Suitability of KNN</strong></p>\n\n<p>One immediate problem with KNN is that each new instance must be compared to each existing reference instance before a class can be determined. As the number of reference instances increases, the time to classify a new instance increases.  With highly dimensional data, you're going to need a lot of reference instances.</p>\n\n<p><strong>Dimensionality of the Data</strong></p>\n\n<p>If you are set on using KNN, you will want to do everything you can to reduce the number of dimensions, particularly on the categorical columns.  In your example, you may be better off reducing the animals down to some larger groups, for example: [Pet, Domesticated, Wild] or biological family.  If not, once you encode the categorical values, you will maybe have thousands (to millions) of animal columns alone.  If you don't have many examples of each, you're going to match on everything but the animal because\n<span class=\"math-container\">$$Distance\\ between:\\ dog\\ and\\ cat = 1$$</span>\n<span class=\"math-container\">$$Distance\\ between:\\ dog\\ and\\ giraffe = 1$$</span>\nSo, this will mean other attributes in the data will likely be more similar, yet, they may be uninformative to the classification process.  For example, number of legs.</p>\n\n<p>On the positive side though, KNN may deal with the introduction of new attributes a little better than others because the classification is based on the currently available data, so adding a new column is not as big a deal as say adding a new column to a neural network, which will need to be retrained to be able to accept a new data set.</p>\n\n<p><strong>Conclusion</strong></p>\n\n<p>While there are other pros and cons to KNN and ways to optimize it for performance; based on your description of the data, and perhaps making a few assumptions, KNN does not sound like a good fit for your classification problem. </p>\n\n<p>Most models are going to perform better if you can reduce the number of dimensions, but if the number and nature of attributes is relatively static, I would start with something like a <code>Decision Tree</code>.  The benefit of starting with a decision tree is that you can get a feel for the importance of the columns to the class assigned.</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "46337",
                        "2",
                        "41859",
                        "",
                        "",
                        "<p>It's been a while since this but I did eventually get around to a solution:</p>\n\n<pre><code>from scipy.spatial.distance import euclidean, cosine, dice\n\ncat_vars = ['col2', 'col3']\nuniques = []\nfor c in cat_vars:\n    uniques.append(X[c].nunique()) \ncat_vars_width = sum(uniques)\ncon_vars = ['col1']\n\n# use a custom distance func to apply appropriate\n# distance calcs to specific columns\n\ncon_vars_indices = list(range(0, con_vars_width))\ncat_vars_indices = list(range(con_vars_width, con_vars_width + cat_vars_width))    \ntfidf_indices = list(range(con_vars_width + cat_vars_width, X_normal.shape[1]))\n\ndef custom_distance_maker(con_vars_indices, cat_vars_indices, tfidf_indices):\n    def custom_distance(x,y):\n         x_con = x[con_vars_indices]\n         y_con = y[con_vars_indices]\n         x_cat = x[cat_vars_indices]\n         y_cat = y[cat_vars_indices]\n         x_tfidf = x[tfidf_indices]\n         y_tfidf = y[tfidf_indices]\n\n         d_con = euclidean(x_con,y_con)\n         d_cat = dice(x_cat,y_cat)\n         d_tfidf = cosine(x_tfidf,y_tfidf)\n         return d_con + d_cat + d_tfidf\n    return custom_distance\n</code></pre>\n\n<p>So we use the knowledge of how many columns are going to be created by the one hot encoding and how many columns are just real continuous variables and apply distance calculations appropriate for those data types to that specific portion of the big array. It's slow but honestly gives some pretty good results that satisified my client. </p>\n\n<p>The custom distance function is easy enough to modify as well, allowing you to 'weight' the different variables you want to match on. For example, if you cared more about text matching, just multiply it in such a fashion as to magnify any differences in the cosine similarity search.</p>\n\n<p>I hope some one else finds this hacky solution useful for similarity searches in heterogenuous data. </p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14048",
            "_score": 3.5594153,
            "_source": {
                "title": "How correctly assign weights to minority class or samples in ANN?",
                "content": "How correctly assign weights to minority class or samples in ANN? <p>Having an imbalanced dataset. Abnormal class rate is %5. To handle with the problem I have gave extra weight to the abnormal class. However, It did not change anything. Here is my code: </p>\n\n<pre><code>from keras.models import Sequential\nfrom keras.layers.core import Dense, Activation\nimport pandas as pd\nimport io\nimport requests\nimport numpy as np\nfrom sklearn import metrics\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dense, Dropout, BatchNormalization\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import class_weight\nfrom keras import optimizers\nfrom keras.layers import Dropout\nfrom sklearn.preprocessing import normalize\nfrom sklearn.preprocessing import StandardScaler\nfrom keras import regularizers\nfrom sklearn.utils.class_weight import compute_sample_weight\n\n\ndef GenerateData(w,t,normal_size,abnormal_size):\n#w: window length\n#t: parameter of abnormal pattern (t=0.6/seperable, t=0.06/partially seperable, t=0.006/inseperable)\n    data1=[]\n    data2=[]\n    mu, sigma = 0, 1\n\n    for i in range(normal_size):\n        x=np.random.normal(mu, sigma, w)\n        data1.append(x)\n\n    for i in range(abnormal_size):\n        y=np.random.normal(mu, sigma, w)+t*(np.arange(w)+1)\n        data2.append(y)\n\n\n    data1=np.array(data1)\n    data2=np.array(data2)\n\n\n    data=np.concatenate((data1, data2), axis=0)\n\n    labels=np.concatenate((np.ones(normal_size),np.zeros(abnormal_size)),axis=0)\n    labels=labels.reshape(-1,1)\n\n    Final_Data=np.concatenate((data, labels), axis=1)\n    return Final_Data\n\nFinal_Data=GenerateData(20,0.06,950,50)\ndf=pd.DataFrame(Final_Data)\n\ndf = df.sample(frac=1).reset_index(drop=True)\n\nX=df.iloc[:,:-1]\ny=df.iloc[:,-1]\ny = to_categorical(y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform( X_train )\nX_test = scaler.transform( X_test )\n\nclass_weight = class_weight.compute_class_weight('balanced', np.unique(y[:,-1]),y[:,-1])\n#sample_weight = compute_sample_weight(class_weight='balanced', y=y_train)\n\nmodel = Sequential()\nmodel.add(Dense(8, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dense(y_train.shape[1],activation='softmax'))\nopt=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-3, amsgrad=False)\nmodel.compile(loss='categorical_crossentropy', optimizer=opt)\nmonitor = EarlyStopping(monitor='val_loss', min_delta=1e-8, patience=20, verbose=1, mode='auto')\ncheckpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=0, save_best_only=True)\nhistory=model.fit(X_train, y_train,validation_data=(X_test, y_test),verbose=2,class_weight=class_weight,callbacks=[monitor,checkpointer],epochs=2000)#classes are weighted\n#history=model.fit(X_train, y_train,validation_data=(X_test, y_test),verbose=2,sample_weight=sample_weight,callbacks=[monitor,checkpointer],epochs=2000)# samples are weighted\n#history=model.fit(X_train, y_train,validation_data=(X_test, y_test),verbose=2,callbacks=[monitor,checkpointer],epochs=2000)# no weighting\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n\nmodel.load_weights('best_weights.hdf5') # load weights from best model\n\n\n# Calculate accuracy\npred = model.predict(X_test)\npred = np.argmax(pred,axis=1)\n\ny_compare = np.argmax(y_test,axis=1) \nscore = metrics.accuracy_score(y_compare, pred)\nprint(\"Accuracy score: {}\".format(score))\n\ncnf_matrix = confusion_matrix(y_compare, pred)\n</code></pre>\n\n<p>Based on the <code>class_weight</code> function, class weights are <code>10</code> and <code>0.52</code> for the abnormal and normal class respectively. \nWhether given different weight or not did not change the performance of the model. Moreover, I have tried to give much more weight (1e+6) to abnormal class, but nothing changed. Model is not able to learn. </p>\n\n<p>Instead of <code>class_weight</code> method, I have tried <code>compute_sample_weight</code>, but nothing changed. </p>\n\n<p>So, what I am doing wrong or why the weighting strategy is not working properly in my case. </p>\n <python><classification><keras><class-imbalance><p>Although giving extra weight for handling imbalanced data-set is suggested, it's not a good way. I suggest you use an appropriate loss function for handling imbalanced data-set instead of giving weight to the abnormal class.</p>\n\n<p>There are many useful metrics which were introduced for evaluating the performance of classification methods for imbalanced data-sets. Some of them are <strong><a href=\"https://en.wikipedia.org/wiki/Cohen%27s_kappa\" rel=\"nofollow noreferrer\">Kappa</a></strong>, <strong><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.708.1668&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow noreferrer\">CEN</a></strong>, <strong><a href=\"https://link.springer.com/chapter/10.1007/978-3-319-94120-2_8\" rel=\"nofollow noreferrer\">MCEN</a></strong>, <strong><a href=\"https://en.wikipedia.org/wiki/Matthews_correlation_coefficient\" rel=\"nofollow noreferrer\">MCC</a></strong>, and <strong><a href=\"https://eva.fing.edu.uy/pluginfile.php/69453/mod_resource/content/1/7633-10048-1-PB.pdf\" rel=\"nofollow noreferrer\">DP</a></strong>.</p>\n\n<p>Disclaimer:</p>\n\n<p>If you use python, <strong><a href=\"https://github.com/sepandhaghighi/pycm\" rel=\"nofollow noreferrer\">PyCM</a></strong> module can help you to find out these metrics.</p>\n\n<p>Here is a simple code to get the recommended parameters from this module:</p>\n\n<pre><code>&gt;&gt;&gt; from pycm import *\n\n&gt;&gt;&gt; cm = ConfusionMatrix(matrix={\"Class1\": {\"Class1\": 1, \"Class2\":2}, \"Class2\": {\"Class1\": 0, \"Class2\": 5}})  \n\n&gt;&gt;&gt; print(cm.recommended_list)\n[\"Kappa\", \"SOA1(Landis &amp; Koch)\", \"SOA2(Fleiss)\", \"SOA3(Altman)\", \"SOA4(Cicchetti)\", \"CEN\", \"MCEN\", \"MCC\", \"J\", \"Overall J\", \"Overall MCC\", \"Overall CEN\", \"Overall MCEN\", \"AUC\", \"AUCI\", \"G\", \"DP\", \"DPI\", \"GI\"]\n</code></pre>\n\n<p>After that, each of these parameters you want to use as the loss function can be used as follows:</p>\n\n<pre><code>&gt;&gt;&gt; y_pred = model.predict      #the prediction of the implemented model\n\n&gt;&gt;&gt; y_actu = data.target        #data labels\n\n&gt;&gt;&gt; cm = ConfusionMatrix(y_actu, y_pred)\n\n&gt;&gt;&gt; loss = cm.Kappa             #or any other parameter (Example: cm.SOA1)\n</code></pre>\n<p>Note that there is a large fluctuation in the errors after each run.</p>\n\n<p>I have changed</p>\n\n<pre><code>class_weight = class_weight.compute_class_weight('balanced', np.unique(y[:,-1]),y[:,-1])\n</code></pre>\n\n<p>to</p>\n\n<pre><code>class_weight = np.array([1000, 1])\n</code></pre>\n\n<p>which resulted in <code>val_loss</code> around (0.09, 0.15)</p>\n\n<p>and to</p>\n\n<pre><code>class_weight = np.array([1, 1000])\n</code></pre>\n\n<p>which resulted in <code>val_loss</code> around (0.06, 0.1)</p>\n\n<p>So class weighting is working correctly and has an effect on the final result, but fluctuation is high. It is better to take an average on multiple runs. The negligible difference in test error simply means that weighting is not that important for this particular task.</p>\n",
                "codes": [
                    [
                        ">>> from pycm import *\n\n>>> cm = ConfusionMatrix(matrix={\"Class1\": {\"Class1\": 1, \"Class2\":2}, \"Class2\": {\"Class1\": 0, \"Class2\": 5}})  \n\n>>> print(cm.recommended_list)\n[\"Kappa\", \"SOA1(Landis & Koch)\", \"SOA2(Fleiss)\", \"SOA3(Altman)\", \"SOA4(Cicchetti)\", \"CEN\", \"MCEN\", \"MCC\", \"J\", \"Overall J\", \"Overall MCC\", \"Overall CEN\", \"Overall MCEN\", \"AUC\", \"AUCI\", \"G\", \"DP\", \"DPI\", \"GI\"]\n",
                        ">>> y_pred = model.predict      #the prediction of the implemented model\n\n>>> y_actu = data.target        #data labels\n\n>>> cm = ConfusionMatrix(y_actu, y_pred)\n\n>>> loss = cm.Kappa             #or any other parameter (Example: cm.SOA1)\n"
                    ],
                    [
                        "class_weight = class_weight.compute_class_weight('balanced', np.unique(y[:,-1]),y[:,-1])\n",
                        "class_weight = np.array([1000, 1])\n",
                        "class_weight = np.array([1, 1000])\n"
                    ]
                ],
                "question_id:": "47502",
                "question_votes:": "3",
                "question_text:": "<p>Having an imbalanced dataset. Abnormal class rate is %5. To handle with the problem I have gave extra weight to the abnormal class. However, It did not change anything. Here is my code: </p>\n\n<pre><code>from keras.models import Sequential\nfrom keras.layers.core import Dense, Activation\nimport pandas as pd\nimport io\nimport requests\nimport numpy as np\nfrom sklearn import metrics\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dense, Dropout, BatchNormalization\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import class_weight\nfrom keras import optimizers\nfrom keras.layers import Dropout\nfrom sklearn.preprocessing import normalize\nfrom sklearn.preprocessing import StandardScaler\nfrom keras import regularizers\nfrom sklearn.utils.class_weight import compute_sample_weight\n\n\ndef GenerateData(w,t,normal_size,abnormal_size):\n#w: window length\n#t: parameter of abnormal pattern (t=0.6/seperable, t=0.06/partially seperable, t=0.006/inseperable)\n    data1=[]\n    data2=[]\n    mu, sigma = 0, 1\n\n    for i in range(normal_size):\n        x=np.random.normal(mu, sigma, w)\n        data1.append(x)\n\n    for i in range(abnormal_size):\n        y=np.random.normal(mu, sigma, w)+t*(np.arange(w)+1)\n        data2.append(y)\n\n\n    data1=np.array(data1)\n    data2=np.array(data2)\n\n\n    data=np.concatenate((data1, data2), axis=0)\n\n    labels=np.concatenate((np.ones(normal_size),np.zeros(abnormal_size)),axis=0)\n    labels=labels.reshape(-1,1)\n\n    Final_Data=np.concatenate((data, labels), axis=1)\n    return Final_Data\n\nFinal_Data=GenerateData(20,0.06,950,50)\ndf=pd.DataFrame(Final_Data)\n\ndf = df.sample(frac=1).reset_index(drop=True)\n\nX=df.iloc[:,:-1]\ny=df.iloc[:,-1]\ny = to_categorical(y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform( X_train )\nX_test = scaler.transform( X_test )\n\nclass_weight = class_weight.compute_class_weight('balanced', np.unique(y[:,-1]),y[:,-1])\n#sample_weight = compute_sample_weight(class_weight='balanced', y=y_train)\n\nmodel = Sequential()\nmodel.add(Dense(8, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dense(y_train.shape[1],activation='softmax'))\nopt=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-3, amsgrad=False)\nmodel.compile(loss='categorical_crossentropy', optimizer=opt)\nmonitor = EarlyStopping(monitor='val_loss', min_delta=1e-8, patience=20, verbose=1, mode='auto')\ncheckpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=0, save_best_only=True)\nhistory=model.fit(X_train, y_train,validation_data=(X_test, y_test),verbose=2,class_weight=class_weight,callbacks=[monitor,checkpointer],epochs=2000)#classes are weighted\n#history=model.fit(X_train, y_train,validation_data=(X_test, y_test),verbose=2,sample_weight=sample_weight,callbacks=[monitor,checkpointer],epochs=2000)# samples are weighted\n#history=model.fit(X_train, y_train,validation_data=(X_test, y_test),verbose=2,callbacks=[monitor,checkpointer],epochs=2000)# no weighting\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n\nmodel.load_weights('best_weights.hdf5') # load weights from best model\n\n\n# Calculate accuracy\npred = model.predict(X_test)\npred = np.argmax(pred,axis=1)\n\ny_compare = np.argmax(y_test,axis=1) \nscore = metrics.accuracy_score(y_compare, pred)\nprint(\"Accuracy score: {}\".format(score))\n\ncnf_matrix = confusion_matrix(y_compare, pred)\n</code></pre>\n\n<p>Based on the <code>class_weight</code> function, class weights are <code>10</code> and <code>0.52</code> for the abnormal and normal class respectively. \nWhether given different weight or not did not change the performance of the model. Moreover, I have tried to give much more weight (1e+6) to abnormal class, but nothing changed. Model is not able to learn. </p>\n\n<p>Instead of <code>class_weight</code> method, I have tried <code>compute_sample_weight</code>, but nothing changed. </p>\n\n<p>So, what I am doing wrong or why the weighting strategy is not working properly in my case. </p>\n",
                "tags": "<python><classification><keras><class-imbalance>",
                "answers": [
                    [
                        "47532",
                        "2",
                        "47502",
                        "",
                        "",
                        "<p>Although giving extra weight for handling imbalanced data-set is suggested, it's not a good way. I suggest you use an appropriate loss function for handling imbalanced data-set instead of giving weight to the abnormal class.</p>\n\n<p>There are many useful metrics which were introduced for evaluating the performance of classification methods for imbalanced data-sets. Some of them are <strong><a href=\"https://en.wikipedia.org/wiki/Cohen%27s_kappa\" rel=\"nofollow noreferrer\">Kappa</a></strong>, <strong><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.708.1668&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow noreferrer\">CEN</a></strong>, <strong><a href=\"https://link.springer.com/chapter/10.1007/978-3-319-94120-2_8\" rel=\"nofollow noreferrer\">MCEN</a></strong>, <strong><a href=\"https://en.wikipedia.org/wiki/Matthews_correlation_coefficient\" rel=\"nofollow noreferrer\">MCC</a></strong>, and <strong><a href=\"https://eva.fing.edu.uy/pluginfile.php/69453/mod_resource/content/1/7633-10048-1-PB.pdf\" rel=\"nofollow noreferrer\">DP</a></strong>.</p>\n\n<p>Disclaimer:</p>\n\n<p>If you use python, <strong><a href=\"https://github.com/sepandhaghighi/pycm\" rel=\"nofollow noreferrer\">PyCM</a></strong> module can help you to find out these metrics.</p>\n\n<p>Here is a simple code to get the recommended parameters from this module:</p>\n\n<pre><code>&gt;&gt;&gt; from pycm import *\n\n&gt;&gt;&gt; cm = ConfusionMatrix(matrix={\"Class1\": {\"Class1\": 1, \"Class2\":2}, \"Class2\": {\"Class1\": 0, \"Class2\": 5}})  \n\n&gt;&gt;&gt; print(cm.recommended_list)\n[\"Kappa\", \"SOA1(Landis &amp; Koch)\", \"SOA2(Fleiss)\", \"SOA3(Altman)\", \"SOA4(Cicchetti)\", \"CEN\", \"MCEN\", \"MCC\", \"J\", \"Overall J\", \"Overall MCC\", \"Overall CEN\", \"Overall MCEN\", \"AUC\", \"AUCI\", \"G\", \"DP\", \"DPI\", \"GI\"]\n</code></pre>\n\n<p>After that, each of these parameters you want to use as the loss function can be used as follows:</p>\n\n<pre><code>&gt;&gt;&gt; y_pred = model.predict      #the prediction of the implemented model\n\n&gt;&gt;&gt; y_actu = data.target        #data labels\n\n&gt;&gt;&gt; cm = ConfusionMatrix(y_actu, y_pred)\n\n&gt;&gt;&gt; loss = cm.Kappa             #or any other parameter (Example: cm.SOA1)\n</code></pre>\n",
                        "",
                        "3"
                    ],
                    [
                        "47520",
                        "2",
                        "47502",
                        "",
                        "",
                        "<p>Note that there is a large fluctuation in the errors after each run.</p>\n\n<p>I have changed</p>\n\n<pre><code>class_weight = class_weight.compute_class_weight('balanced', np.unique(y[:,-1]),y[:,-1])\n</code></pre>\n\n<p>to</p>\n\n<pre><code>class_weight = np.array([1000, 1])\n</code></pre>\n\n<p>which resulted in <code>val_loss</code> around (0.09, 0.15)</p>\n\n<p>and to</p>\n\n<pre><code>class_weight = np.array([1, 1000])\n</code></pre>\n\n<p>which resulted in <code>val_loss</code> around (0.06, 0.1)</p>\n\n<p>So class weighting is working correctly and has an effect on the final result, but fluctuation is high. It is better to take an average on multiple runs. The negligible difference in test error simply means that weighting is not that important for this particular task.</p>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "1457",
            "_score": 3.5387764,
            "_source": {
                "title": "Trying to understand Logistic Regression Implementation",
                "content": "Trying to understand Logistic Regression Implementation <p>I'm currently using the following code as a starting point to deepen my understanding of regularized logistic regression.  As a first pass I'm just trying to do a binary classification on part of the iris data set.  </p>\n\n<p>One problem I think I have encountered is that the negative log-loss (computed with loss and stored in loss_vec) doesn't change much from one iteration to the next.</p>\n\n<p>Another challenge I am facing is trying to figure out how to plot the decision boundary once I have learned the logistic regression coefficients. Using the coefficients to plot the 0.5 decision boundary is way off.  This makes me think I have made a mistake somewhere</p>\n\n<p><a href=\"http://fa.bianp.net/blog/2013/numerical-optimizers-for-logistic-regression/\" rel=\"noreferrer\">http://fa.bianp.net/blog/2013/numerical-optimizers-for-logistic-regression/</a></p>\n\n\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model, datasets\n\n\niris = datasets.load_iris()\nX = iris.data[:, :2]  # we only take the first two features.\nY = iris.target\n\n\nX = X[:100,:]\nY = Y[:100]\n\ndef phi(t):\n    # logistic function, returns 1 / (1 + exp(-t))\n    idx = t &gt; 0\n    out = np.empty(t.size, dtype=np.float)\n    out[idx] = 1. / (1 + np.exp(-t[idx]))\n    exp_t = np.exp(t[~idx])\n    out[~idx] = exp_t / (1. + exp_t)\n    return out\n\n\ndef loss(x0, X, y, alpha):\n    # logistic loss function, returns Sum{-log(phi(t))}\n    #x0 is the weight vector w are the paramaters, c is the bias term\n    w, c = x0[:X.shape[1]], x0[-1]\n    z = X.dot(w) + c\n    yz = y * z\n    idx = yz &gt; 0\n    out = np.zeros_like(yz)\n    out[idx] = np.log(1 + np.exp(-yz[idx]))\n    out[~idx] = (-yz[~idx] + np.log(1 + np.exp(yz[~idx])))\n    out = out.sum() / X.shape[0] + .5 * alpha * w.dot(w)\n    return out\n\n\ndef gradient(x0, X, y, alpha):\n    # gradient of the logistic loss\n    w, c = x0[:X.shape[1]], x0[-1]\n    z = X.dot(w) + c\n    z = phi(y * z)\n    z0 = (z - 1) * y\n    grad_w = X.T.dot(z0) / X.shape[0] + alpha * w\n    grad_c = z0.sum() / X.shape[0]\n    return np.concatenate((grad_w, [grad_c]))\n\n\ndef bgd(X, y, alpha, max_iter):\n    step_sizes = np.array([100,10,1,.1,.01,.001,.0001,.00001])\n    iter_no = 0\n    x0 = np.random.random(X.shape[1] + 1) #initialize weight vector\n\n    #placeholder for coefficients to test against the loss function\n    next_thetas = np.zeros((step_sizes.shape[0],X.shape[1]+1) )   \n    J = loss(x0,X,y,alpha)\n    running_loss = []\n    while iter_no &lt; max_iter:\n        grad = gradient(x0,X,y,alpha)\n        next_thetas = -(np.outer(step_sizes,grad)-x0)\n        loss_vec = []\n        for i in range(np.shape(next_thetas)[0]):\n            loss_vec.append(loss(next_thetas[i],X,y,alpha))\n        ind = np.argmin(loss_vec)\n        x0 = next_thetas[ind]\n        if iter_no % 500 == 0:\n            running_loss.append(loss(x0,X,y,alpha))\n        iter_no += 1  \n    return next_thetas\n</code></pre>\n <python><logistic-regression><gradient-descent><p>There are several issues I see with the implementation. Some are just unnecessarily complicated ways of doing it, but some are genuine errors. </p>\n\n<p><strong>Primary takeaways</strong></p>\n\n<p>A: <em>Try to start from the math behind the model.</em> The logistic regression is a relatively simple one. Find the two equations you need and stick to them, replicate them letter by letter.</p>\n\n<p>B: <em>Vectorize.</em> It will save you a lot of unnecessary steps and computations, if you step back for a bit and think of the best vectorized implementation.</p>\n\n<p>C: <em>Write more comments in the code.</em> It will help those trying to help you. It will also help you understand each part better and maybe uncover errors yourself.</p>\n\n<p>Now let's go over the code step by step.</p>\n\n<p><strong>1. The sigmoid function</strong></p>\n\n<p>Is there a reason for such a complicate implementation in <code>phi(t)</code>? Assuming that <code>t</code> is a vector (a numpy array), then all you really need is:</p>\n\n<pre><code>def phi(t):\n   1. / (1. + np.exp(-t))\n</code></pre>\n\n<p>As <code>np.exp()</code> operates element-wise over arrays. Ideally, I'd implement it as a function that can also return its derivative (not necessary here, but might be handy if you try to implement a basic neural net with sigmoid activations):</p>\n\n<pre><code>def phi(t, dt = False):\n   if dt:\n      phi(t) * (1. - phi(t))\n   else:\n      1. / (1. + np.exp(-t))\n</code></pre>\n\n<p><strong>2. Cost function</strong></p>\n\n<p>Usually, the logistic cost function is defined as a log cost in the following way (vectorized): $ \\frac{1}{m} (-(y^T \\log{(\\phi(X\\theta))})-(1-y^T)(\\log{(1 - \\phi(X\\theta))}) + \\frac{\\lambda}{2m} \\theta^{1T}\\theta $  where $\\phi(z)$ is the logistic (sigmoid) function, $\\theta$ is the full parameter vector (including bias weight), $\\theta^1$ is parameter vector with $\\theta_1=0$ (by convention, bias is not regularized) and $\\lambda$ is the regularization parameter. </p>\n\n<p>What I really don't understand is the part where you multiply <code>y * z</code>. Assuming <code>y</code> is your label vector $y$, why are you multiplying it with your <code>z</code> before applying the sigmoid function? And why do you need to split the cost function into zeros and ones and calculate losses for either sample separately? \nI think the problem in your code really lies in this part: you must be erroneously multiplying $y$ with $X\\theta$ before applying $\\phi(.)$.</p>\n\n<p>Also, this bit here: <code>X.dot(w) + c</code>. So <code>c</code> is your bias parameter, right? Why are you adding it to every element of $X\\theta$? It shouldn't be added - it should be the first element of the vector $X\\theta$. Yes, you don't regularize it, but you need to use in the \"prediction\" part of the loss function.</p>\n\n<p>In your code, I also see the cost function as being overly complicated. Here's what I would try:</p>\n\n<pre><code>def loss(X,y,w,lam):\n   #calculate \"prediction\"\n   Z = np.dot(X,w)\n   #calculate cost without regularization\n   #shape of X is (m,n), shape of w is (n,1)\n   J = (1./len(X)) * (-np.dot(y.T, np.log(phi(Z))) * np.dot((1-y.T),np.log(1 - phi(Z))))\n   #add regularization\n   #temporary weight vector\n   w1 = copy.copy(w) #import copy to create a true copy\n   w1[0] = 0\n   J += (lam/(2.*len(X))) * np.dot(w1.T, w)\n   return J\n</code></pre>\n\n<p><strong>3. Gradient</strong></p>\n\n<p>Again, let's first go over the formula for the gradient of the logistic loss, again, vectorized: $\\frac{1}{m} ((\\phi(X\\theta) - y)^TX)^T + \\frac{\\lambda}{m}\\theta^1$.\nThis will return a vector of derivatives (i.e. gradient) for all parameters, regularized properly (without the bias term regularized).</p>\n\n<p>Here again, you've multiplied by $y$ way too soon: <code>phi(y * z)</code>. In fact, you shouldn't have multiplied by $y$ in gradient at all. </p>\n\n<p>This is what I would do for the gradient:</p>\n\n<pre><code>def gradient(X, y, w, lam):\n   #calculate the prediction\n   Z = np.dot(X,w)\n   #temporary weight vector\n   w1 = copy.copy(w) #import copy to create a true copy\n   w1[0] = 0\n   #calc gradient\n   grad = (1./len(X)) * (np.dot((phi(Z) - y).T,X).T) + (lam/len(X)) * w1\n   return grad\n</code></pre>\n\n<p>The actual gradient descent implementation seems ok to me, but because there are errors in the gradient and cost function implementations, it fails to deliver :/</p>\n\n<p>Hope this will help you get on track.</p>\n<p>Below is how you can implement gradient descent in Python:</p>\n\n<pre><code>def sigmoid(z):\n    s= 1/(1 + np.exp(-z))\n    return s\n\ndef propagate(w, b, X, Y):\n\n    m = X.shape[1]\n\n    A = sigmoid(np.dot(w.T,X)+b)                                     # compute activation\n\n    cost = -1/m * np.sum(Y * np.log(A) + (1-Y) * (np.log(1-A)))\n\n    dz= (1/m)*(A - Y)\n    dw = np.dot(X, dz.T)\n    db = np.sum(dz)\n\n\n    cost = np.squeeze(cost)\n    grads = {\"dw\": dw,\n             \"db\": db}\n\n    return grads, cost\n\n\ndef optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n\n    costs = []\n\n    for i in range(num_iterations):\n        m = X.shape[1]\n        grads,cost = propagate(w, b, X, Y)\n        b = b - learning_rate*grads[\"db\"]\n        w = w - learning_rate*grads[\"dw\"]\n        if i % 100 == 0:\n            costs.append(cost)\n        if print_cost and i % 100 == 0:\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n\n    params = {\"w\": w,\n              \"b\": b}\n    return params, grads, costs\n\n\n\ndef predict(w, b, X):\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n    A = sigmoid(np.dot(w.T,X)+ b)\n\n    for i in range(A.shape[1]):\n        x_exp = np.exp(A)\n        x_sum = np.sum(x_exp,axis=1,keepdims=True)\n        s = np.divide(x_exp,x_sum)\n\n    Y_prediction = 1. * (A &gt; 0.5)\n\n    return Y_prediction\n\n\n\ndef model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n    w, b = initialize_with_zeros(X_train.shape[0])\n\n    print(\"learning rate:\",learning_rate)\n\n    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost = False)\n\n    w = parameters[\"w\"]\n    b = parameters[\"b\"]\n\n    Y_prediction_train = predict(w,b,X_train)\n    Y_prediction_test = predict(w,b,X_test)\n    d = {\"costs\": costs,\n         \"Y_prediction_test\": Y_prediction_test, \n         \"Y_prediction_train\" : Y_prediction_train, \n         \"w\" : w, \n         \"b\" : b,\n         \"learning_rate\" : learning_rate,\n         \"num_iterations\": num_iterations}\n\n    return d\n\nd = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)\n</code></pre>\n",
                "codes": [
                    [
                        "def phi(t):\n   1. / (1. + np.exp(-t))\n",
                        "def phi(t, dt = False):\n   if dt:\n      phi(t) * (1. - phi(t))\n   else:\n      1. / (1. + np.exp(-t))\n",
                        "def loss(X,y,w,lam):\n   #calculate \"prediction\"\n   Z = np.dot(X,w)\n   #calculate cost without regularization\n   #shape of X is (m,n), shape of w is (n,1)\n   J = (1./len(X)) * (-np.dot(y.T, np.log(phi(Z))) * np.dot((1-y.T),np.log(1 - phi(Z))))\n   #add regularization\n   #temporary weight vector\n   w1 = copy.copy(w) #import copy to create a true copy\n   w1[0] = 0\n   J += (lam/(2.*len(X))) * np.dot(w1.T, w)\n   return J\n",
                        "def gradient(X, y, w, lam):\n   #calculate the prediction\n   Z = np.dot(X,w)\n   #temporary weight vector\n   w1 = copy.copy(w) #import copy to create a true copy\n   w1[0] = 0\n   #calc gradient\n   grad = (1./len(X)) * (np.dot((phi(Z) - y).T,X).T) + (lam/len(X)) * w1\n   return grad\n"
                    ],
                    [
                        "def sigmoid(z):\n    s= 1/(1 + np.exp(-z))\n    return s\n\ndef propagate(w, b, X, Y):\n\n    m = X.shape[1]\n\n    A = sigmoid(np.dot(w.T,X)+b)                                     # compute activation\n\n    cost = -1/m * np.sum(Y * np.log(A) + (1-Y) * (np.log(1-A)))\n\n    dz= (1/m)*(A - Y)\n    dw = np.dot(X, dz.T)\n    db = np.sum(dz)\n\n\n    cost = np.squeeze(cost)\n    grads = {\"dw\": dw,\n             \"db\": db}\n\n    return grads, cost\n\n\ndef optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n\n    costs = []\n\n    for i in range(num_iterations):\n        m = X.shape[1]\n        grads,cost = propagate(w, b, X, Y)\n        b = b - learning_rate*grads[\"db\"]\n        w = w - learning_rate*grads[\"dw\"]\n        if i % 100 == 0:\n            costs.append(cost)\n        if print_cost and i % 100 == 0:\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n\n    params = {\"w\": w,\n              \"b\": b}\n    return params, grads, costs\n\n\n\ndef predict(w, b, X):\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n    A = sigmoid(np.dot(w.T,X)+ b)\n\n    for i in range(A.shape[1]):\n        x_exp = np.exp(A)\n        x_sum = np.sum(x_exp,axis=1,keepdims=True)\n        s = np.divide(x_exp,x_sum)\n\n    Y_prediction = 1. * (A > 0.5)\n\n    return Y_prediction\n\n\n\ndef model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n    w, b = initialize_with_zeros(X_train.shape[0])\n\n    print(\"learning rate:\",learning_rate)\n\n    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost = False)\n\n    w = parameters[\"w\"]\n    b = parameters[\"b\"]\n\n    Y_prediction_train = predict(w,b,X_train)\n    Y_prediction_test = predict(w,b,X_test)\n    d = {\"costs\": costs,\n         \"Y_prediction_test\": Y_prediction_test, \n         \"Y_prediction_train\" : Y_prediction_train, \n         \"w\" : w, \n         \"b\" : b,\n         \"learning_rate\" : learning_rate,\n         \"num_iterations\": num_iterations}\n\n    return d\n\nd = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)\n"
                    ]
                ],
                "question_id:": "8657",
                "question_votes:": "6",
                "question_text:": "<p>I'm currently using the following code as a starting point to deepen my understanding of regularized logistic regression.  As a first pass I'm just trying to do a binary classification on part of the iris data set.  </p>\n\n<p>One problem I think I have encountered is that the negative log-loss (computed with loss and stored in loss_vec) doesn't change much from one iteration to the next.</p>\n\n<p>Another challenge I am facing is trying to figure out how to plot the decision boundary once I have learned the logistic regression coefficients. Using the coefficients to plot the 0.5 decision boundary is way off.  This makes me think I have made a mistake somewhere</p>\n\n<p><a href=\"http://fa.bianp.net/blog/2013/numerical-optimizers-for-logistic-regression/\" rel=\"noreferrer\">http://fa.bianp.net/blog/2013/numerical-optimizers-for-logistic-regression/</a></p>\n\n\n\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model, datasets\n\n\niris = datasets.load_iris()\nX = iris.data[:, :2]  # we only take the first two features.\nY = iris.target\n\n\nX = X[:100,:]\nY = Y[:100]\n\ndef phi(t):\n    # logistic function, returns 1 / (1 + exp(-t))\n    idx = t &gt; 0\n    out = np.empty(t.size, dtype=np.float)\n    out[idx] = 1. / (1 + np.exp(-t[idx]))\n    exp_t = np.exp(t[~idx])\n    out[~idx] = exp_t / (1. + exp_t)\n    return out\n\n\ndef loss(x0, X, y, alpha):\n    # logistic loss function, returns Sum{-log(phi(t))}\n    #x0 is the weight vector w are the paramaters, c is the bias term\n    w, c = x0[:X.shape[1]], x0[-1]\n    z = X.dot(w) + c\n    yz = y * z\n    idx = yz &gt; 0\n    out = np.zeros_like(yz)\n    out[idx] = np.log(1 + np.exp(-yz[idx]))\n    out[~idx] = (-yz[~idx] + np.log(1 + np.exp(yz[~idx])))\n    out = out.sum() / X.shape[0] + .5 * alpha * w.dot(w)\n    return out\n\n\ndef gradient(x0, X, y, alpha):\n    # gradient of the logistic loss\n    w, c = x0[:X.shape[1]], x0[-1]\n    z = X.dot(w) + c\n    z = phi(y * z)\n    z0 = (z - 1) * y\n    grad_w = X.T.dot(z0) / X.shape[0] + alpha * w\n    grad_c = z0.sum() / X.shape[0]\n    return np.concatenate((grad_w, [grad_c]))\n\n\ndef bgd(X, y, alpha, max_iter):\n    step_sizes = np.array([100,10,1,.1,.01,.001,.0001,.00001])\n    iter_no = 0\n    x0 = np.random.random(X.shape[1] + 1) #initialize weight vector\n\n    #placeholder for coefficients to test against the loss function\n    next_thetas = np.zeros((step_sizes.shape[0],X.shape[1]+1) )   \n    J = loss(x0,X,y,alpha)\n    running_loss = []\n    while iter_no &lt; max_iter:\n        grad = gradient(x0,X,y,alpha)\n        next_thetas = -(np.outer(step_sizes,grad)-x0)\n        loss_vec = []\n        for i in range(np.shape(next_thetas)[0]):\n            loss_vec.append(loss(next_thetas[i],X,y,alpha))\n        ind = np.argmin(loss_vec)\n        x0 = next_thetas[ind]\n        if iter_no % 500 == 0:\n            running_loss.append(loss(x0,X,y,alpha))\n        iter_no += 1  \n    return next_thetas\n</code></pre>\n",
                "tags": "<python><logistic-regression><gradient-descent>",
                "answers": [
                    [
                        "8663",
                        "2",
                        "8657",
                        "",
                        "",
                        "<p>There are several issues I see with the implementation. Some are just unnecessarily complicated ways of doing it, but some are genuine errors. </p>\n\n<p><strong>Primary takeaways</strong></p>\n\n<p>A: <em>Try to start from the math behind the model.</em> The logistic regression is a relatively simple one. Find the two equations you need and stick to them, replicate them letter by letter.</p>\n\n<p>B: <em>Vectorize.</em> It will save you a lot of unnecessary steps and computations, if you step back for a bit and think of the best vectorized implementation.</p>\n\n<p>C: <em>Write more comments in the code.</em> It will help those trying to help you. It will also help you understand each part better and maybe uncover errors yourself.</p>\n\n<p>Now let's go over the code step by step.</p>\n\n<p><strong>1. The sigmoid function</strong></p>\n\n<p>Is there a reason for such a complicate implementation in <code>phi(t)</code>? Assuming that <code>t</code> is a vector (a numpy array), then all you really need is:</p>\n\n<pre><code>def phi(t):\n   1. / (1. + np.exp(-t))\n</code></pre>\n\n<p>As <code>np.exp()</code> operates element-wise over arrays. Ideally, I'd implement it as a function that can also return its derivative (not necessary here, but might be handy if you try to implement a basic neural net with sigmoid activations):</p>\n\n<pre><code>def phi(t, dt = False):\n   if dt:\n      phi(t) * (1. - phi(t))\n   else:\n      1. / (1. + np.exp(-t))\n</code></pre>\n\n<p><strong>2. Cost function</strong></p>\n\n<p>Usually, the logistic cost function is defined as a log cost in the following way (vectorized): $ \\frac{1}{m} (-(y^T \\log{(\\phi(X\\theta))})-(1-y^T)(\\log{(1 - \\phi(X\\theta))}) + \\frac{\\lambda}{2m} \\theta^{1T}\\theta $  where $\\phi(z)$ is the logistic (sigmoid) function, $\\theta$ is the full parameter vector (including bias weight), $\\theta^1$ is parameter vector with $\\theta_1=0$ (by convention, bias is not regularized) and $\\lambda$ is the regularization parameter. </p>\n\n<p>What I really don't understand is the part where you multiply <code>y * z</code>. Assuming <code>y</code> is your label vector $y$, why are you multiplying it with your <code>z</code> before applying the sigmoid function? And why do you need to split the cost function into zeros and ones and calculate losses for either sample separately? \nI think the problem in your code really lies in this part: you must be erroneously multiplying $y$ with $X\\theta$ before applying $\\phi(.)$.</p>\n\n<p>Also, this bit here: <code>X.dot(w) + c</code>. So <code>c</code> is your bias parameter, right? Why are you adding it to every element of $X\\theta$? It shouldn't be added - it should be the first element of the vector $X\\theta$. Yes, you don't regularize it, but you need to use in the \"prediction\" part of the loss function.</p>\n\n<p>In your code, I also see the cost function as being overly complicated. Here's what I would try:</p>\n\n<pre><code>def loss(X,y,w,lam):\n   #calculate \"prediction\"\n   Z = np.dot(X,w)\n   #calculate cost without regularization\n   #shape of X is (m,n), shape of w is (n,1)\n   J = (1./len(X)) * (-np.dot(y.T, np.log(phi(Z))) * np.dot((1-y.T),np.log(1 - phi(Z))))\n   #add regularization\n   #temporary weight vector\n   w1 = copy.copy(w) #import copy to create a true copy\n   w1[0] = 0\n   J += (lam/(2.*len(X))) * np.dot(w1.T, w)\n   return J\n</code></pre>\n\n<p><strong>3. Gradient</strong></p>\n\n<p>Again, let's first go over the formula for the gradient of the logistic loss, again, vectorized: $\\frac{1}{m} ((\\phi(X\\theta) - y)^TX)^T + \\frac{\\lambda}{m}\\theta^1$.\nThis will return a vector of derivatives (i.e. gradient) for all parameters, regularized properly (without the bias term regularized).</p>\n\n<p>Here again, you've multiplied by $y$ way too soon: <code>phi(y * z)</code>. In fact, you shouldn't have multiplied by $y$ in gradient at all. </p>\n\n<p>This is what I would do for the gradient:</p>\n\n<pre><code>def gradient(X, y, w, lam):\n   #calculate the prediction\n   Z = np.dot(X,w)\n   #temporary weight vector\n   w1 = copy.copy(w) #import copy to create a true copy\n   w1[0] = 0\n   #calc gradient\n   grad = (1./len(X)) * (np.dot((phi(Z) - y).T,X).T) + (lam/len(X)) * w1\n   return grad\n</code></pre>\n\n<p>The actual gradient descent implementation seems ok to me, but because there are errors in the gradient and cost function implementations, it fails to deliver :/</p>\n\n<p>Hope this will help you get on track.</p>\n",
                        "",
                        "10"
                    ],
                    [
                        "22445",
                        "2",
                        "8657",
                        "",
                        "",
                        "<p>Below is how you can implement gradient descent in Python:</p>\n\n<pre><code>def sigmoid(z):\n    s= 1/(1 + np.exp(-z))\n    return s\n\ndef propagate(w, b, X, Y):\n\n    m = X.shape[1]\n\n    A = sigmoid(np.dot(w.T,X)+b)                                     # compute activation\n\n    cost = -1/m * np.sum(Y * np.log(A) + (1-Y) * (np.log(1-A)))\n\n    dz= (1/m)*(A - Y)\n    dw = np.dot(X, dz.T)\n    db = np.sum(dz)\n\n\n    cost = np.squeeze(cost)\n    grads = {\"dw\": dw,\n             \"db\": db}\n\n    return grads, cost\n\n\ndef optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n\n    costs = []\n\n    for i in range(num_iterations):\n        m = X.shape[1]\n        grads,cost = propagate(w, b, X, Y)\n        b = b - learning_rate*grads[\"db\"]\n        w = w - learning_rate*grads[\"dw\"]\n        if i % 100 == 0:\n            costs.append(cost)\n        if print_cost and i % 100 == 0:\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n\n    params = {\"w\": w,\n              \"b\": b}\n    return params, grads, costs\n\n\n\ndef predict(w, b, X):\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n    A = sigmoid(np.dot(w.T,X)+ b)\n\n    for i in range(A.shape[1]):\n        x_exp = np.exp(A)\n        x_sum = np.sum(x_exp,axis=1,keepdims=True)\n        s = np.divide(x_exp,x_sum)\n\n    Y_prediction = 1. * (A &gt; 0.5)\n\n    return Y_prediction\n\n\n\ndef model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n    w, b = initialize_with_zeros(X_train.shape[0])\n\n    print(\"learning rate:\",learning_rate)\n\n    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost = False)\n\n    w = parameters[\"w\"]\n    b = parameters[\"b\"]\n\n    Y_prediction_train = predict(w,b,X_train)\n    Y_prediction_test = predict(w,b,X_test)\n    d = {\"costs\": costs,\n         \"Y_prediction_test\": Y_prediction_test, \n         \"Y_prediction_train\" : Y_prediction_train, \n         \"w\" : w, \n         \"b\" : b,\n         \"learning_rate\" : learning_rate,\n         \"num_iterations\": num_iterations}\n\n    return d\n\nd = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)\n</code></pre>\n",
                        "",
                        "1"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "6937",
            "_score": 3.5387764,
            "_source": {
                "title": "how to calculate the output shape of conv2d_transpose?",
                "content": "how to calculate the output shape of conv2d_transpose? <p>Currently I code a GAN to generate MNIST numbers but the generator doesnt want to work. First I choose z with shape 100 per Batch, put into a layer to get into the shape (7,7, 256). Then conv2d_transpose layer\nto into 28, 28, 1. (which is basically a mnist pic) </p>\n\n<p>I have two questions \n1.) This code doesn't work for obvious. Do you have any clue, why?\n2.) I am very aware how transpose convolution works but I can't find any resource to calculate the output size given input, strides and kernel size specific to Tensorflow. The useful information I found is <a href=\"https://arxiv.org/pdf/1603.07285v1.pdf\" rel=\"nofollow noreferrer\">https://arxiv.org/pdf/1603.07285v1.pdf</a> but e.g. padding in Tensorflow works very different. Can you help me?</p>\n\n<pre><code>mb_size = 32 #Size of image batch to apply at each iteration.\nX_dim = 784\nz_dim = 100\nh_dim = 7*7*256\ndropoutRate = 0.7\nalplr = 0.2 #leaky Relu\n\n\ndef generator(z, G_W1, G_b1, keepProb, first_shape):\n\n    G_W1 = tf.Variable(xavier_init([z_dim, h_dim]))\n    G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))    \n\n\n    G_h1 = lrelu(tf.matmul(z, G_W1) + G_b1, alplr)\n    G_h1Drop = tf.nn.dropout(G_h1, keepProb)  # drop out\n\n    X = tf.reshape(G_h1Drop, shape=first_shape)\n    out = create_new_trans_conv_layer(X, 256, INPUT_CHANNEL, [3, 3], [2,2], \"transconv1\", [-1, 28, 28, 1])    \n    return out\n\n\n\n\n# new transposed cnn\ndef create_new_trans_conv_layer(input_data, num_input_channels, num_output_channels, filter_shape, stripe, name, output_shape):\n    # setup the filter input shape for tf.nn.conv_2d\n    conv_filt_shape = [filter_shape[0], filter_shape[1], num_output_channels, num_input_channels]\n\n\n    # initialise weights and bias for the filter\n    weights = tf.Variable(tf.truncated_normal(conv_filt_shape, stddev=0.03),\n                          name=name + '_W')\n    bias = tf.Variable(tf.truncated_normal([num_input_channels]), name=name + '_b')\n\n    # setup the convolutional layer operation\n    conv1 = tf.nn.conv2d_transpose(input_data, weights, output_shape, [1, stripe[0], stripe[1], 1], padding='SAME')\n\n    # add the bias\n    conv1 += bias\n\n    # apply a ReLU non-linear activation\n\n    conv1 = lrelu(conv1, alplr)\n\n    return conv1\n\n\n...\n\n\n    _, G_loss_curr = sess.run(\n        [G_solver, G_loss],\n        feed_dict={z: sample_z(mb_size, z_dim), keepProb: 1.0} #training generator\n</code></pre>\n <neural-network><tensorflow><convnet><gan><generative-models><p>Take a look at the <a href=\"https://github.com/tensorflow/tensorflow/blob/5912f51d580551e5cee2cfde4cb882594b4d3e60/tensorflow/python/keras/layers/convolutional.py#L607\" rel=\"nofollow noreferrer\">source code</a> for <code>tf.keras.Conv2DTranspose</code>, which calls the function <a href=\"https://github.com/tensorflow/tensorflow/blob/5912f51d580551e5cee2cfde4cb882594b4d3e60/tensorflow/python/keras/utils/conv_utils.py#L140\" rel=\"nofollow noreferrer\"><code>deconv_output_length</code></a> when calculating its output size. There's a subtle difference between the accepted answer and what you find here:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def deconv_output_length(input_length, filter_size, padding,\n                         output_padding=None, stride=0, dilation=1):\n  \"\"\"Determines output length of a transposed convolution given input length.\n  Arguments:\n      input_length: Integer.\n      filter_size: Integer.\n      padding: one of `\"same\"`, `\"valid\"`, `\"full\"`.\n      output_padding: Integer, amount of padding along the output dimension.\n          Can be set to `None` in which case the output length is inferred.\n      stride: Integer.\n      dilation: Integer.\n  Returns:\n      The output length (integer).\n  \"\"\"\n  assert padding in {'same', 'valid', 'full'}\n  if input_length is None:\n    return None\n\n  # Get the dilated kernel size\n  filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n\n  # Infer length if output padding is None, else compute the exact length\n  if output_padding is None:\n    if padding == 'valid':\n      # note the call to `max` below!\n      length = input_length * stride + max(filter_size - stride, 0)\n    elif padding == 'full':\n      length = input_length * stride - (stride + filter_size - 2)\n    elif padding == 'same':\n      length = input_length * stride\n\n  else:\n    if padding == 'same':\n      pad = filter_size // 2\n    elif padding == 'valid':\n      pad = 0\n    elif padding == 'full':\n      pad = filter_size - 1\n\n    length = ((input_length - 1) * stride + filter_size - 2 * pad +\n              output_padding)\n  return length\n</code></pre>\n\n<p>I added the comment above the call to <code>max</code>.</p>\n\n<p>The formula for <code>padding == 'valid'</code> is <code>H = H1 * stride + max(HF - stride)</code>, which only varies from @Manish P's answer when <code>stride &lt; HF</code>. This one got me into trouble, so I thought I'd post it here.</p>\n<p>Here is the correct formula for computing the size of the output with <code>tf.layers.conv2d_transpose()</code>:</p>\n\n<pre><code># Padding==Same:\nH = H1 * stride\n\n# Padding==Valid\nH = (H1-1) * stride + HF\n</code></pre>\n\n<p>where, <code>H</code> = output size, <code>H1</code> = input size, <code>HF</code> = height of filter</p>\n\n<pre><code>e.g., if `H1` = 7, Stride = 3, and Kernel size = 4, \n\nWith padding==\"same\", output size = 21, \nwith padding==\"valid\", output size = 22\n</code></pre>\n\n<p>To test this out (verified in tf 1.4.0):</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\nx = tf.placeholder(dtype=tf.float32, shape=(None, 7, 7, 32))\ndcout = tf.layers.conv2d_transpose(x, 64, 4, 3, padding=\"valid\")\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    xin = np.random.rand(1,7,7,32)\n    out = sess.run(dcout, feed_dict={x:xin})\n    print(out.shape)\n</code></pre>\n<p>The answers here give figures that work, but they don't mention that there are multiple possible output shapes for the convolution-transpose operation. Indeed, if the output shape was completely determined by the other parameters then there would be no need for it to be specified. </p>\n\n<p>The output size of a convolution operation is </p>\n\n<pre><code># padding==\"SAME\" \nconv_out = ceil(conv_in/stride)\n\n# padding==\"VALID\" \nconv_out = ceil((conv_in-k+1)/stride)    \n</code></pre>\n\n<p>where <code>conv_in</code> is the input size and <code>k</code> is the kernel size. In OP's link these padding methods are called 'half padding' and 'no padding' respectively. </p>\n\n<p>When calling </p>\n\n<p><code>tf.nn.conv2d_transpose(value, filter, output_shape, strides)</code> </p>\n\n<p>we need the <code>output_shape</code> parameter to be the shape of a tensor that, if convolved with <code>filter</code> and <code>strides</code>, would have produced a tensor of the same shape as <code>value</code>. Because of rounding, there are multiple such shapes when <code>stride&gt;1</code>. Specifically, we need </p>\n\n<pre><code>dconv_in-1 &lt;= (dconv_out-k)/s &lt;= dconv_in \n==&gt; \n(dconv_in-1)s + k &lt;= dconv_out &lt;= (dconv_in)s + k\n</code></pre>\n\n<p>If dconv_in = 7, k = 4, stride = 3</p>\n\n<pre><code># with SAME padding\ndconv_out = 19 or 20 or 21\n\n# with VALID padding\ndconv_out = 22 or 23 or 24\n</code></pre>\n\n<p>The <code>tf.layers</code> API automatically calculates an output_shape (which seems to be  the smallest possible for VALID padding and the largest possible for SAME padding). This is often convenient, but can also lead to shape mismatches if you are trying to recover the shape of a previously convolved tensor, eg in an autoencoder. For example</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\n\nk=22\ncin = tf.placeholder(tf.float32, shape=(None, k+1,k+1,64))\nw1 = tf.placeholder(tf.float32, shape=[4,4,64,32])\ncout = tf.nn.conv2d(cin, w1, strides=(1,3,3,1), padding=\"VALID\")               \nf_dict={cin:np.random.rand(1,k+1,k+1,64),\n        w1:np.random.rand(4,4,64,32)}\n\ndcout1 = tf.nn.conv2d_transpose(cout, w1, strides=(1,3,3,1), \n        padding=\"VALID\", output_shape=[1,k,k,64])\ndcout2 = tf.nn.conv2d_transpose(cout, w1, strides=(1,3,3,1), \n        padding=\"VALID\", output_shape=[1,k+1,k+1,64])\ndcout_layers = tf.layers.conv2d_transpose(cout, 64, 4, 3, padding=\"VALID\")\n\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n\n    inp_shape = sess.run(cin, feed_dict=f_dict).shape\n    conv_shape = sess.run(cout, feed_dict=f_dict).shape\n    lyrs_shape = sess.run(rcout, feed_dict=f_dict).shape\n    nn_shape1 = sess.run(dcout1, feed_dict=f_dict).shape\n    nn_shape2 = sess.run(dcout2, feed_dict=f_dict).shape\n\n\n    print(\"original input shape:\", inp_shape)\n    print(\"shape after convolution:\", conv_shape)\n    print(\"recovered output shape using tf.layers:\", lyrs_shape)\n    print(\"one possible recovered output shape using tf.nn:\", nn_shape1)\n    print(\"another possible recovered output shape using tf.nn:\", nn_shape2)\n</code></pre>\n\n<hr>\n\n<pre><code>&gt;&gt;&gt; original input shape: (1, 23, 23, 64)\n&gt;&gt;&gt; shape after convolution: (1, 8, 8, 32)\n&gt;&gt;&gt; recovered output shape using tf.layers: (1, 22, 22, 64)\n&gt;&gt;&gt; one possible recovered output shape using tf.nn: (1, 22, 22, 64)\n&gt;&gt;&gt; another possible recovered output shape using tf.nn: (1, 23, 23, 64)\n</code></pre>\n<p>Instead of using <code>tf.nn.conv2d_transpose</code> you can use <code>tf.layers.conv2d_transpose</code>\nIt is a wrapper layer and there is no need to input output shape or if you want to calculate output shape you can use the formula: </p>\n\n<pre><code>H = (H1 - 1)*stride + HF - 2*padding\nH - height of output image i.e H = 28 \nH1 - height of input image i.e H1 = 7 \nHF - height of filter \n</code></pre>\n",
                "codes": [
                    [
                        "def deconv_output_length(input_length, filter_size, padding,\n                         output_padding=None, stride=0, dilation=1):\n  \"\"\"Determines output length of a transposed convolution given input length.\n  Arguments:\n      input_length: Integer.\n      filter_size: Integer.\n      padding: one of `\"same\"`, `\"valid\"`, `\"full\"`.\n      output_padding: Integer, amount of padding along the output dimension.\n          Can be set to `None` in which case the output length is inferred.\n      stride: Integer.\n      dilation: Integer.\n  Returns:\n      The output length (integer).\n  \"\"\"\n  assert padding in {'same', 'valid', 'full'}\n  if input_length is None:\n    return None\n\n  # Get the dilated kernel size\n  filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n\n  # Infer length if output padding is None, else compute the exact length\n  if output_padding is None:\n    if padding == 'valid':\n      # note the call to `max` below!\n      length = input_length * stride + max(filter_size - stride, 0)\n    elif padding == 'full':\n      length = input_length * stride - (stride + filter_size - 2)\n    elif padding == 'same':\n      length = input_length * stride\n\n  else:\n    if padding == 'same':\n      pad = filter_size // 2\n    elif padding == 'valid':\n      pad = 0\n    elif padding == 'full':\n      pad = filter_size - 1\n\n    length = ((input_length - 1) * stride + filter_size - 2 * pad +\n              output_padding)\n  return length\n"
                    ],
                    [
                        "# Padding==Same:\nH = H1 * stride\n\n# Padding==Valid\nH = (H1-1) * stride + HF\n",
                        "e.g., if `H1` = 7, Stride = 3, and Kernel size = 4, \n\nWith padding==\"same\", output size = 21, \nwith padding==\"valid\", output size = 22\n",
                        "import tensorflow as tf\nimport numpy as np\n\nx = tf.placeholder(dtype=tf.float32, shape=(None, 7, 7, 32))\ndcout = tf.layers.conv2d_transpose(x, 64, 4, 3, padding=\"valid\")\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    xin = np.random.rand(1,7,7,32)\n    out = sess.run(dcout, feed_dict={x:xin})\n    print(out.shape)\n"
                    ],
                    [
                        "# padding==\"SAME\" \nconv_out = ceil(conv_in/stride)\n\n# padding==\"VALID\" \nconv_out = ceil((conv_in-k+1)/stride)    \n",
                        "dconv_in-1 <= (dconv_out-k)/s <= dconv_in \n==> \n(dconv_in-1)s + k <= dconv_out <= (dconv_in)s + k\n",
                        "# with SAME padding\ndconv_out = 19 or 20 or 21\n\n# with VALID padding\ndconv_out = 22 or 23 or 24\n",
                        "import tensorflow as tf\nimport numpy as np\n\n\nk=22\ncin = tf.placeholder(tf.float32, shape=(None, k+1,k+1,64))\nw1 = tf.placeholder(tf.float32, shape=[4,4,64,32])\ncout = tf.nn.conv2d(cin, w1, strides=(1,3,3,1), padding=\"VALID\")               \nf_dict={cin:np.random.rand(1,k+1,k+1,64),\n        w1:np.random.rand(4,4,64,32)}\n\ndcout1 = tf.nn.conv2d_transpose(cout, w1, strides=(1,3,3,1), \n        padding=\"VALID\", output_shape=[1,k,k,64])\ndcout2 = tf.nn.conv2d_transpose(cout, w1, strides=(1,3,3,1), \n        padding=\"VALID\", output_shape=[1,k+1,k+1,64])\ndcout_layers = tf.layers.conv2d_transpose(cout, 64, 4, 3, padding=\"VALID\")\n\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n\n    inp_shape = sess.run(cin, feed_dict=f_dict).shape\n    conv_shape = sess.run(cout, feed_dict=f_dict).shape\n    lyrs_shape = sess.run(rcout, feed_dict=f_dict).shape\n    nn_shape1 = sess.run(dcout1, feed_dict=f_dict).shape\n    nn_shape2 = sess.run(dcout2, feed_dict=f_dict).shape\n\n\n    print(\"original input shape:\", inp_shape)\n    print(\"shape after convolution:\", conv_shape)\n    print(\"recovered output shape using tf.layers:\", lyrs_shape)\n    print(\"one possible recovered output shape using tf.nn:\", nn_shape1)\n    print(\"another possible recovered output shape using tf.nn:\", nn_shape2)\n",
                        ">>> original input shape: (1, 23, 23, 64)\n>>> shape after convolution: (1, 8, 8, 32)\n>>> recovered output shape using tf.layers: (1, 22, 22, 64)\n>>> one possible recovered output shape using tf.nn: (1, 22, 22, 64)\n>>> another possible recovered output shape using tf.nn: (1, 23, 23, 64)\n"
                    ],
                    [
                        "H = (H1 - 1)*stride + HF - 2*padding\nH - height of output image i.e H = 28 \nH1 - height of input image i.e H1 = 7 \nHF - height of filter \n"
                    ]
                ],
                "question_id:": "26451",
                "question_votes:": "6",
                "question_text:": "<p>Currently I code a GAN to generate MNIST numbers but the generator doesnt want to work. First I choose z with shape 100 per Batch, put into a layer to get into the shape (7,7, 256). Then conv2d_transpose layer\nto into 28, 28, 1. (which is basically a mnist pic) </p>\n\n<p>I have two questions \n1.) This code doesn't work for obvious. Do you have any clue, why?\n2.) I am very aware how transpose convolution works but I can't find any resource to calculate the output size given input, strides and kernel size specific to Tensorflow. The useful information I found is <a href=\"https://arxiv.org/pdf/1603.07285v1.pdf\" rel=\"nofollow noreferrer\">https://arxiv.org/pdf/1603.07285v1.pdf</a> but e.g. padding in Tensorflow works very different. Can you help me?</p>\n\n<pre><code>mb_size = 32 #Size of image batch to apply at each iteration.\nX_dim = 784\nz_dim = 100\nh_dim = 7*7*256\ndropoutRate = 0.7\nalplr = 0.2 #leaky Relu\n\n\ndef generator(z, G_W1, G_b1, keepProb, first_shape):\n\n    G_W1 = tf.Variable(xavier_init([z_dim, h_dim]))\n    G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))    \n\n\n    G_h1 = lrelu(tf.matmul(z, G_W1) + G_b1, alplr)\n    G_h1Drop = tf.nn.dropout(G_h1, keepProb)  # drop out\n\n    X = tf.reshape(G_h1Drop, shape=first_shape)\n    out = create_new_trans_conv_layer(X, 256, INPUT_CHANNEL, [3, 3], [2,2], \"transconv1\", [-1, 28, 28, 1])    \n    return out\n\n\n\n\n# new transposed cnn\ndef create_new_trans_conv_layer(input_data, num_input_channels, num_output_channels, filter_shape, stripe, name, output_shape):\n    # setup the filter input shape for tf.nn.conv_2d\n    conv_filt_shape = [filter_shape[0], filter_shape[1], num_output_channels, num_input_channels]\n\n\n    # initialise weights and bias for the filter\n    weights = tf.Variable(tf.truncated_normal(conv_filt_shape, stddev=0.03),\n                          name=name + '_W')\n    bias = tf.Variable(tf.truncated_normal([num_input_channels]), name=name + '_b')\n\n    # setup the convolutional layer operation\n    conv1 = tf.nn.conv2d_transpose(input_data, weights, output_shape, [1, stripe[0], stripe[1], 1], padding='SAME')\n\n    # add the bias\n    conv1 += bias\n\n    # apply a ReLU non-linear activation\n\n    conv1 = lrelu(conv1, alplr)\n\n    return conv1\n\n\n...\n\n\n    _, G_loss_curr = sess.run(\n        [G_solver, G_loss],\n        feed_dict={z: sample_z(mb_size, z_dim), keepProb: 1.0} #training generator\n</code></pre>\n",
                "tags": "<neural-network><tensorflow><convnet><gan><generative-models>",
                "answers": [
                    [
                        "56200",
                        "2",
                        "26451",
                        "",
                        "",
                        "<p>Take a look at the <a href=\"https://github.com/tensorflow/tensorflow/blob/5912f51d580551e5cee2cfde4cb882594b4d3e60/tensorflow/python/keras/layers/convolutional.py#L607\" rel=\"nofollow noreferrer\">source code</a> for <code>tf.keras.Conv2DTranspose</code>, which calls the function <a href=\"https://github.com/tensorflow/tensorflow/blob/5912f51d580551e5cee2cfde4cb882594b4d3e60/tensorflow/python/keras/utils/conv_utils.py#L140\" rel=\"nofollow noreferrer\"><code>deconv_output_length</code></a> when calculating its output size. There's a subtle difference between the accepted answer and what you find here:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def deconv_output_length(input_length, filter_size, padding,\n                         output_padding=None, stride=0, dilation=1):\n  \"\"\"Determines output length of a transposed convolution given input length.\n  Arguments:\n      input_length: Integer.\n      filter_size: Integer.\n      padding: one of `\"same\"`, `\"valid\"`, `\"full\"`.\n      output_padding: Integer, amount of padding along the output dimension.\n          Can be set to `None` in which case the output length is inferred.\n      stride: Integer.\n      dilation: Integer.\n  Returns:\n      The output length (integer).\n  \"\"\"\n  assert padding in {'same', 'valid', 'full'}\n  if input_length is None:\n    return None\n\n  # Get the dilated kernel size\n  filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n\n  # Infer length if output padding is None, else compute the exact length\n  if output_padding is None:\n    if padding == 'valid':\n      # note the call to `max` below!\n      length = input_length * stride + max(filter_size - stride, 0)\n    elif padding == 'full':\n      length = input_length * stride - (stride + filter_size - 2)\n    elif padding == 'same':\n      length = input_length * stride\n\n  else:\n    if padding == 'same':\n      pad = filter_size // 2\n    elif padding == 'valid':\n      pad = 0\n    elif padding == 'full':\n      pad = filter_size - 1\n\n    length = ((input_length - 1) * stride + filter_size - 2 * pad +\n              output_padding)\n  return length\n</code></pre>\n\n<p>I added the comment above the call to <code>max</code>.</p>\n\n<p>The formula for <code>padding == 'valid'</code> is <code>H = H1 * stride + max(HF - stride)</code>, which only varies from @Manish P's answer when <code>stride &lt; HF</code>. This one got me into trouble, so I thought I'd post it here.</p>\n",
                        "",
                        ""
                    ],
                    [
                        "36847",
                        "2",
                        "26451",
                        "",
                        "",
                        "<p>Here is the correct formula for computing the size of the output with <code>tf.layers.conv2d_transpose()</code>:</p>\n\n<pre><code># Padding==Same:\nH = H1 * stride\n\n# Padding==Valid\nH = (H1-1) * stride + HF\n</code></pre>\n\n<p>where, <code>H</code> = output size, <code>H1</code> = input size, <code>HF</code> = height of filter</p>\n\n<pre><code>e.g., if `H1` = 7, Stride = 3, and Kernel size = 4, \n\nWith padding==\"same\", output size = 21, \nwith padding==\"valid\", output size = 22\n</code></pre>\n\n<p>To test this out (verified in tf 1.4.0):</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\nx = tf.placeholder(dtype=tf.float32, shape=(None, 7, 7, 32))\ndcout = tf.layers.conv2d_transpose(x, 64, 4, 3, padding=\"valid\")\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    xin = np.random.rand(1,7,7,32)\n    out = sess.run(dcout, feed_dict={x:xin})\n    print(out.shape)\n</code></pre>\n",
                        "",
                        "8"
                    ],
                    [
                        "44326",
                        "2",
                        "26451",
                        "",
                        "",
                        "<p>The answers here give figures that work, but they don't mention that there are multiple possible output shapes for the convolution-transpose operation. Indeed, if the output shape was completely determined by the other parameters then there would be no need for it to be specified. </p>\n\n<p>The output size of a convolution operation is </p>\n\n<pre><code># padding==\"SAME\" \nconv_out = ceil(conv_in/stride)\n\n# padding==\"VALID\" \nconv_out = ceil((conv_in-k+1)/stride)    \n</code></pre>\n\n<p>where <code>conv_in</code> is the input size and <code>k</code> is the kernel size. In OP's link these padding methods are called 'half padding' and 'no padding' respectively. </p>\n\n<p>When calling </p>\n\n<p><code>tf.nn.conv2d_transpose(value, filter, output_shape, strides)</code> </p>\n\n<p>we need the <code>output_shape</code> parameter to be the shape of a tensor that, if convolved with <code>filter</code> and <code>strides</code>, would have produced a tensor of the same shape as <code>value</code>. Because of rounding, there are multiple such shapes when <code>stride&gt;1</code>. Specifically, we need </p>\n\n<pre><code>dconv_in-1 &lt;= (dconv_out-k)/s &lt;= dconv_in \n==&gt; \n(dconv_in-1)s + k &lt;= dconv_out &lt;= (dconv_in)s + k\n</code></pre>\n\n<p>If dconv_in = 7, k = 4, stride = 3</p>\n\n<pre><code># with SAME padding\ndconv_out = 19 or 20 or 21\n\n# with VALID padding\ndconv_out = 22 or 23 or 24\n</code></pre>\n\n<p>The <code>tf.layers</code> API automatically calculates an output_shape (which seems to be  the smallest possible for VALID padding and the largest possible for SAME padding). This is often convenient, but can also lead to shape mismatches if you are trying to recover the shape of a previously convolved tensor, eg in an autoencoder. For example</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\n\nk=22\ncin = tf.placeholder(tf.float32, shape=(None, k+1,k+1,64))\nw1 = tf.placeholder(tf.float32, shape=[4,4,64,32])\ncout = tf.nn.conv2d(cin, w1, strides=(1,3,3,1), padding=\"VALID\")               \nf_dict={cin:np.random.rand(1,k+1,k+1,64),\n        w1:np.random.rand(4,4,64,32)}\n\ndcout1 = tf.nn.conv2d_transpose(cout, w1, strides=(1,3,3,1), \n        padding=\"VALID\", output_shape=[1,k,k,64])\ndcout2 = tf.nn.conv2d_transpose(cout, w1, strides=(1,3,3,1), \n        padding=\"VALID\", output_shape=[1,k+1,k+1,64])\ndcout_layers = tf.layers.conv2d_transpose(cout, 64, 4, 3, padding=\"VALID\")\n\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n\n    inp_shape = sess.run(cin, feed_dict=f_dict).shape\n    conv_shape = sess.run(cout, feed_dict=f_dict).shape\n    lyrs_shape = sess.run(rcout, feed_dict=f_dict).shape\n    nn_shape1 = sess.run(dcout1, feed_dict=f_dict).shape\n    nn_shape2 = sess.run(dcout2, feed_dict=f_dict).shape\n\n\n    print(\"original input shape:\", inp_shape)\n    print(\"shape after convolution:\", conv_shape)\n    print(\"recovered output shape using tf.layers:\", lyrs_shape)\n    print(\"one possible recovered output shape using tf.nn:\", nn_shape1)\n    print(\"another possible recovered output shape using tf.nn:\", nn_shape2)\n</code></pre>\n\n<hr>\n\n<pre><code>&gt;&gt;&gt; original input shape: (1, 23, 23, 64)\n&gt;&gt;&gt; shape after convolution: (1, 8, 8, 32)\n&gt;&gt;&gt; recovered output shape using tf.layers: (1, 22, 22, 64)\n&gt;&gt;&gt; one possible recovered output shape using tf.nn: (1, 22, 22, 64)\n&gt;&gt;&gt; another possible recovered output shape using tf.nn: (1, 23, 23, 64)\n</code></pre>\n",
                        "",
                        ""
                    ],
                    [
                        "29085",
                        "2",
                        "26451",
                        "",
                        "",
                        "<p>Instead of using <code>tf.nn.conv2d_transpose</code> you can use <code>tf.layers.conv2d_transpose</code>\nIt is a wrapper layer and there is no need to input output shape or if you want to calculate output shape you can use the formula: </p>\n\n<pre><code>H = (H1 - 1)*stride + HF - 2*padding\nH - height of output image i.e H = 28 \nH1 - height of input image i.e H1 = 7 \nHF - height of filter \n</code></pre>\n",
                        "",
                        "3"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "16594",
            "_score": 3.5387764,
            "_source": {
                "title": "Smart data split (train/eval) for Object Detection",
                "content": "Smart data split (train/eval) for Object Detection <p>I am looking for a smart way of splitting object detection data (images with labelled objects inside them) while taking into account the distribution of the objects themselves and not just the images.</p>\n\n<p>I have a dataset composed of many images. Each of these images has one or more objects inside, which are labelled. In order to train an object detection model, I need to perform the traditional train/eval split (in this case I don't need a test set). However, I have very specific requirements as for which labels should end up in each set.</p>\n\n<p>Concretely, I want to ensure that a minimum amount of samples per label ends up in the train and eval sets. For example, if I know that I only have 5 samples of cars, I want to ensure that at least 3 of these cars will be in the train set. Therefore, a simple random split of the images (E.g. 80/20) is not ideal, because it doesn't take into account the objects within each image and thus cannot enforce my constraints. For example, if only two images have cars, one with three and one with two, nothing will stop these two images to be in the train set, and thus I might not have any cars for evaluation!</p>\n\n<p>Naturally, these constraints could be impossible to achieve (if there is a single image were all cars are, it will not be possible to have cars in both train and eval), which is something the algorithm should manage. (i.e. giving the most optimal solution that complies with the requirements as best as it can).</p>\n\n<p>A few other complications:</p>\n\n<ul>\n<li>Each image can have any number of objects belonging to any number of labels, so adding an image to either set will affect the distribution of all labels it contains.</li>\n<li>As a result of the previous point, enforcing one constraint in one set can invalidate another in the other set (for the same label or even for a different one).</li>\n</ul>\n\n<p>Have you encountered this problem before? Any suggestions?</p>\n\n<p>Please let me know if more details are required and I will updated the post accordingly. Thanks in advance.</p>\n\n<p><strong>EDIT 1: Adding integer programming approach status</strong></p>\n\n<p>This is a working example of the current integer solution in Python, using <a href=\"https://www.cvxpy.org/\" rel=\"nofollow noreferrer\">cvxpy</a>:</p>\n\n<p><em>Needed libraries:</em></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport cvxpy\n</code></pre>\n\n<p><em>Example data:</em></p>\n\n<pre class=\"lang-py prettyprint-override\"><code># rows -&gt; classes, columns -&gt; images\nL = np.array([[2, 0, 0, 0, 3, 0, 8, 0, 0],\n              [0, 3, 0, 2, 0, 0, 0, 8, 0],\n              [0, 0, 2, 0, 0, 3, 0, 0, 8]])\nbig_L = np.vstack((np.hstack((L, np.zeros_like(L))),\n                   np.hstack((np.zeros_like(L), L))))\n\n# minimum examples per class for each set\nleft_min = [2, 2, 2]\nright_min = [2, 2, 2]\n\n# maximum examples per class for each set\nleft_max = [9, 9, 9]\nright_max = [2, 2, 2]\n\n# number of frames and classes\nnc, n = L.shape\n</code></pre>\n\n<p><em>Some variables needed to define constraints:</em></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>w = np.hstack((np.array(left_min), np.array(right_min))).T\nmax_w = np.hstack((np.array(left_max), np.array(right_max))).T\n\ns = cvxpy.Variable(2*n, boolean=True)\n\nbig_s = np.vstack((np.hstack((np.zeros((n, n)), np.eye(n))),\n                   np.hstack((np.eye(n), np.zeros((n, n))))))\n</code></pre>\n\n<p><em>Constraints:</em></p>\n\n<pre class=\"lang-py prettyprint-override\"><code># constraints\n# only one frame can be selected for each set\noutput_constraint_0 = (big_s @ s) + s &lt;= np.ones((2*n))\n\n# only one frame can be selected for each set\noutput_constraint_01 = (big_s @ s) + s &gt;= np.zeros((2*n))\n\n# all frames must be selected for either set\noutput_constraint_1 = cvxpy.sum(s) == cvxpy.Variable(n, integer=True)\n\n# result vector must be binary, only zeros or ones (and in between?) \noutput_constraint_2 = np.eye(2*n) @ s &lt;= np.ones(2*n)\noutput_constraint_3 = - np.eye(2*n) @ s &lt;= np.zeros(2*n)\n\n# sets have at least required quantities of examples per class\noutput_constraint_4 = big_L @ s - w &gt;= np.zeros((2*nc))\n\n# check that train has required (for now, we ignore eval numbers)\noutput_constraint_5 = big_L @ s - max_w &gt;= np.zeros((2*nc))\n\nconstraints = [output_constraint_0, output_constraint_01,\n               output_constraint_1, output_constraint_2,\n               output_constraint_3, output_constraint_4,\n               output_constraint_5]\n\n# Objective function\nobjective = cvxpy.norm((big_s @ s) + s - np.ones((2*n)))\n</code></pre>\n\n<p><em>Define problem and solve:</em></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>split_problem = cvxpy.Problem(cvxpy.Minimize(objective), constraints)\nsplit_problem.solve()\n</code></pre>\n\n<p><em>Get images indices for each set and assert results are as intended:</em></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>result = s.value.reshape((2, n))\nl = np.array([int(x) for x in np.round(s.value[:n])], dtype=np.int)\nr = np.array([int(x) for x in np.round(s.value[n:])], dtype=np.int)\n\nassert all(L @ l &gt;= left_min) and all(L @ l &gt;= left_max)\nassert all(L @ r &gt;= right_min) and all(L @ r &gt;= right_max)\n</code></pre>\n\n<p>While this solution works for simple cases such as the presented example dataset above, it does not work for real-life datasets, with much more complicated classes distribution. The problem is mainly with infeasible \"max number of examples\" constraints, which can be remedied by iterating through different train/eval fractions (e.g. 0.2, 0.3, 0.4, ...) and solving the problem for each of them, which can eventually reach a solution (in the worst case, eval fraction would be 1). Here we assume that if the problem is infeasible with an eval_fraction of x, there is an eval_fraction, y, bigger than x, that can make the problem solvable.</p>\n\n<p>Another complication is that the current solver we are using, namely \"ECOS_BB\" (more information <a href=\"https://www.cvxpy.org/tutorial/advanced/index.html\" rel=\"nofollow noreferrer\">here</a> and <a href=\"https://github.com/embotech/ecos#mixed-integer-socps-ecos_bb\" rel=\"nofollow noreferrer\">here</a>), is way too slow for big datasets, making it completely impractical for real usage. Additionally, cvxpy only uses a single CPU core, with the lack of processing speed that implies.</p>\n\n<p>So, the next step is to find a suitable solution that can process large, very heterogeneous datasets taking advantage of all hardware available and in a reasonable time.</p>\n <dataset><data><training><evaluation><object-detection><p>I guess I might as well put forward the integer program formulation alluded to in the comments.</p>\n\n<p>Let <span class=\"math-container\">$A=(a_{ij})$</span>, where <span class=\"math-container\">$a_{ij}$</span> is the number of object <span class=\"math-container\">$i$</span> in image <span class=\"math-container\">$j$</span>.  We have a binary variable <span class=\"math-container\">$x_j$</span> for each image <span class=\"math-container\">$j$</span>, a 1 indicating that we will include the image in the training set.  Then <span class=\"math-container\">$Ax$</span> is the vector whose <span class=\"math-container\">$i$</span>th entry is the number of object <span class=\"math-container\">$i$</span> included in the training set.  Putting a lower bound on <span class=\"math-container\">$Ax$</span> gives the lower bound desired in the training set, and putting an upper bound on it gives the complementary lower bound desired in the validation set.</p>\n\n<p>This doesn't use an objective function yet, so you could just ask for feasibility, or add something to optimize.</p>\n\n<p>If the integer program is infeasible, you could add and subtract new variables (I think I was wrong to call them \"slack variables\" in the comments?) from the bounds on <span class=\"math-container\">$Ax$</span>, and minimize the sum of those variables.  You'd be guaranteed a solution that way, could see how far off you are, and could see which objects are the problematic ones [for that solution anyway].</p>\n\n<p>EDIT: Unless I've misunderstood something, or you had a next step in mind, your MILP can be simplified quite a bit.  And here's what I had in mind for minimizing violations.  I've changed <code>L</code> and the bounds a bit to get an infeasible original problem.  (That's something I don't understand from your example: what are the four bounds?)  Setting <code>x</code> as binary, and <code>L</code> being nonnegative integers, we get for free that the outputs are nonnegative integers and the new <code>lr, ur</code> (\"lower/upper relaxation\") are integral, but we need to enforce nonegativity.  Finally, since you're already using a convex optimization software, I thought making the objective the square of the violations should yield \"nicer\" results.</p>\n\n<pre><code>import numpy as np\nimport cvxpy\n\nL = np.array([[2,3,0,3,0,8,4],\n              [3,0,2,0,0,0,4],\n              [0,2,5,1,3,0,2]])\nnc, n = L.shape\n\ntrain_mins = np.array([12,6,8])\nvalid_mins = np.array([7,3,4])\n\nx = cvxpy.Variable(n, boolean=True)\nlr = cvxpy.Variable(nc, nonneg=True)\nur = cvxpy.Variable(nc, nonneg=True)\n\nlb = (L @ x &gt;= train_mins.T - lr)\nub = (L @ x &lt;= (sum(L.T)-valid_mins).T + ur)\nconstraints = [lb, ub]\n\nobjective = (sum(lr)+sum(ur))**2\n\nproblem = cvxpy.Problem(cvxpy.Minimize(objective), constraints)\nproblem.solve()\n</code></pre>\n\n<p>(<a href=\"https://github.com/bmreiniger/datascience.stackexchange/blob/master/54450.ipynb\" rel=\"nofollow noreferrer\">https://github.com/bmreiniger/datascience.stackexchange/blob/master/54450.ipynb</a>)</p>\n\n<p>Assuming that's all right, it at least removes the need to iterate through different train/eval proportions.  (You could modify the upper and lower bounds and the relaxations/objective to put it more in terms of the train/eval proportions.)</p>\n\n<p>I'm not so familiar with different solvers.  A superficial glance suggests that <code>ECOS_BB</code> isn't actually built for MICP, so maybe backing the objective off to a linear one is a better idea.</p>\n",
                "codes": [
                    [
                        "import numpy as np\nimport cvxpy\n\nL = np.array([[2,3,0,3,0,8,4],\n              [3,0,2,0,0,0,4],\n              [0,2,5,1,3,0,2]])\nnc, n = L.shape\n\ntrain_mins = np.array([12,6,8])\nvalid_mins = np.array([7,3,4])\n\nx = cvxpy.Variable(n, boolean=True)\nlr = cvxpy.Variable(nc, nonneg=True)\nur = cvxpy.Variable(nc, nonneg=True)\n\nlb = (L @ x >= train_mins.T - lr)\nub = (L @ x <= (sum(L.T)-valid_mins).T + ur)\nconstraints = [lb, ub]\n\nobjective = (sum(lr)+sum(ur))**2\n\nproblem = cvxpy.Problem(cvxpy.Minimize(objective), constraints)\nproblem.solve()\n"
                    ]
                ],
                "question_id:": "54450",
                "question_votes:": "2",
                "question_text:": "<p>I am looking for a smart way of splitting object detection data (images with labelled objects inside them) while taking into account the distribution of the objects themselves and not just the images.</p>\n\n<p>I have a dataset composed of many images. Each of these images has one or more objects inside, which are labelled. In order to train an object detection model, I need to perform the traditional train/eval split (in this case I don't need a test set). However, I have very specific requirements as for which labels should end up in each set.</p>\n\n<p>Concretely, I want to ensure that a minimum amount of samples per label ends up in the train and eval sets. For example, if I know that I only have 5 samples of cars, I want to ensure that at least 3 of these cars will be in the train set. Therefore, a simple random split of the images (E.g. 80/20) is not ideal, because it doesn't take into account the objects within each image and thus cannot enforce my constraints. For example, if only two images have cars, one with three and one with two, nothing will stop these two images to be in the train set, and thus I might not have any cars for evaluation!</p>\n\n<p>Naturally, these constraints could be impossible to achieve (if there is a single image were all cars are, it will not be possible to have cars in both train and eval), which is something the algorithm should manage. (i.e. giving the most optimal solution that complies with the requirements as best as it can).</p>\n\n<p>A few other complications:</p>\n\n<ul>\n<li>Each image can have any number of objects belonging to any number of labels, so adding an image to either set will affect the distribution of all labels it contains.</li>\n<li>As a result of the previous point, enforcing one constraint in one set can invalidate another in the other set (for the same label or even for a different one).</li>\n</ul>\n\n<p>Have you encountered this problem before? Any suggestions?</p>\n\n<p>Please let me know if more details are required and I will updated the post accordingly. Thanks in advance.</p>\n\n<p><strong>EDIT 1: Adding integer programming approach status</strong></p>\n\n<p>This is a working example of the current integer solution in Python, using <a href=\"https://www.cvxpy.org/\" rel=\"nofollow noreferrer\">cvxpy</a>:</p>\n\n<p><em>Needed libraries:</em></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport cvxpy\n</code></pre>\n\n<p><em>Example data:</em></p>\n\n<pre class=\"lang-py prettyprint-override\"><code># rows -&gt; classes, columns -&gt; images\nL = np.array([[2, 0, 0, 0, 3, 0, 8, 0, 0],\n              [0, 3, 0, 2, 0, 0, 0, 8, 0],\n              [0, 0, 2, 0, 0, 3, 0, 0, 8]])\nbig_L = np.vstack((np.hstack((L, np.zeros_like(L))),\n                   np.hstack((np.zeros_like(L), L))))\n\n# minimum examples per class for each set\nleft_min = [2, 2, 2]\nright_min = [2, 2, 2]\n\n# maximum examples per class for each set\nleft_max = [9, 9, 9]\nright_max = [2, 2, 2]\n\n# number of frames and classes\nnc, n = L.shape\n</code></pre>\n\n<p><em>Some variables needed to define constraints:</em></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>w = np.hstack((np.array(left_min), np.array(right_min))).T\nmax_w = np.hstack((np.array(left_max), np.array(right_max))).T\n\ns = cvxpy.Variable(2*n, boolean=True)\n\nbig_s = np.vstack((np.hstack((np.zeros((n, n)), np.eye(n))),\n                   np.hstack((np.eye(n), np.zeros((n, n))))))\n</code></pre>\n\n<p><em>Constraints:</em></p>\n\n<pre class=\"lang-py prettyprint-override\"><code># constraints\n# only one frame can be selected for each set\noutput_constraint_0 = (big_s @ s) + s &lt;= np.ones((2*n))\n\n# only one frame can be selected for each set\noutput_constraint_01 = (big_s @ s) + s &gt;= np.zeros((2*n))\n\n# all frames must be selected for either set\noutput_constraint_1 = cvxpy.sum(s) == cvxpy.Variable(n, integer=True)\n\n# result vector must be binary, only zeros or ones (and in between?) \noutput_constraint_2 = np.eye(2*n) @ s &lt;= np.ones(2*n)\noutput_constraint_3 = - np.eye(2*n) @ s &lt;= np.zeros(2*n)\n\n# sets have at least required quantities of examples per class\noutput_constraint_4 = big_L @ s - w &gt;= np.zeros((2*nc))\n\n# check that train has required (for now, we ignore eval numbers)\noutput_constraint_5 = big_L @ s - max_w &gt;= np.zeros((2*nc))\n\nconstraints = [output_constraint_0, output_constraint_01,\n               output_constraint_1, output_constraint_2,\n               output_constraint_3, output_constraint_4,\n               output_constraint_5]\n\n# Objective function\nobjective = cvxpy.norm((big_s @ s) + s - np.ones((2*n)))\n</code></pre>\n\n<p><em>Define problem and solve:</em></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>split_problem = cvxpy.Problem(cvxpy.Minimize(objective), constraints)\nsplit_problem.solve()\n</code></pre>\n\n<p><em>Get images indices for each set and assert results are as intended:</em></p>\n\n<pre class=\"lang-py prettyprint-override\"><code>result = s.value.reshape((2, n))\nl = np.array([int(x) for x in np.round(s.value[:n])], dtype=np.int)\nr = np.array([int(x) for x in np.round(s.value[n:])], dtype=np.int)\n\nassert all(L @ l &gt;= left_min) and all(L @ l &gt;= left_max)\nassert all(L @ r &gt;= right_min) and all(L @ r &gt;= right_max)\n</code></pre>\n\n<p>While this solution works for simple cases such as the presented example dataset above, it does not work for real-life datasets, with much more complicated classes distribution. The problem is mainly with infeasible \"max number of examples\" constraints, which can be remedied by iterating through different train/eval fractions (e.g. 0.2, 0.3, 0.4, ...) and solving the problem for each of them, which can eventually reach a solution (in the worst case, eval fraction would be 1). Here we assume that if the problem is infeasible with an eval_fraction of x, there is an eval_fraction, y, bigger than x, that can make the problem solvable.</p>\n\n<p>Another complication is that the current solver we are using, namely \"ECOS_BB\" (more information <a href=\"https://www.cvxpy.org/tutorial/advanced/index.html\" rel=\"nofollow noreferrer\">here</a> and <a href=\"https://github.com/embotech/ecos#mixed-integer-socps-ecos_bb\" rel=\"nofollow noreferrer\">here</a>), is way too slow for big datasets, making it completely impractical for real usage. Additionally, cvxpy only uses a single CPU core, with the lack of processing speed that implies.</p>\n\n<p>So, the next step is to find a suitable solution that can process large, very heterogeneous datasets taking advantage of all hardware available and in a reasonable time.</p>\n",
                "tags": "<dataset><data><training><evaluation><object-detection>",
                "answers": [
                    [
                        "55740",
                        "2",
                        "54450",
                        "",
                        "",
                        "<p>I guess I might as well put forward the integer program formulation alluded to in the comments.</p>\n\n<p>Let <span class=\"math-container\">$A=(a_{ij})$</span>, where <span class=\"math-container\">$a_{ij}$</span> is the number of object <span class=\"math-container\">$i$</span> in image <span class=\"math-container\">$j$</span>.  We have a binary variable <span class=\"math-container\">$x_j$</span> for each image <span class=\"math-container\">$j$</span>, a 1 indicating that we will include the image in the training set.  Then <span class=\"math-container\">$Ax$</span> is the vector whose <span class=\"math-container\">$i$</span>th entry is the number of object <span class=\"math-container\">$i$</span> included in the training set.  Putting a lower bound on <span class=\"math-container\">$Ax$</span> gives the lower bound desired in the training set, and putting an upper bound on it gives the complementary lower bound desired in the validation set.</p>\n\n<p>This doesn't use an objective function yet, so you could just ask for feasibility, or add something to optimize.</p>\n\n<p>If the integer program is infeasible, you could add and subtract new variables (I think I was wrong to call them \"slack variables\" in the comments?) from the bounds on <span class=\"math-container\">$Ax$</span>, and minimize the sum of those variables.  You'd be guaranteed a solution that way, could see how far off you are, and could see which objects are the problematic ones [for that solution anyway].</p>\n\n<p>EDIT: Unless I've misunderstood something, or you had a next step in mind, your MILP can be simplified quite a bit.  And here's what I had in mind for minimizing violations.  I've changed <code>L</code> and the bounds a bit to get an infeasible original problem.  (That's something I don't understand from your example: what are the four bounds?)  Setting <code>x</code> as binary, and <code>L</code> being nonnegative integers, we get for free that the outputs are nonnegative integers and the new <code>lr, ur</code> (\"lower/upper relaxation\") are integral, but we need to enforce nonegativity.  Finally, since you're already using a convex optimization software, I thought making the objective the square of the violations should yield \"nicer\" results.</p>\n\n<pre><code>import numpy as np\nimport cvxpy\n\nL = np.array([[2,3,0,3,0,8,4],\n              [3,0,2,0,0,0,4],\n              [0,2,5,1,3,0,2]])\nnc, n = L.shape\n\ntrain_mins = np.array([12,6,8])\nvalid_mins = np.array([7,3,4])\n\nx = cvxpy.Variable(n, boolean=True)\nlr = cvxpy.Variable(nc, nonneg=True)\nur = cvxpy.Variable(nc, nonneg=True)\n\nlb = (L @ x &gt;= train_mins.T - lr)\nub = (L @ x &lt;= (sum(L.T)-valid_mins).T + ur)\nconstraints = [lb, ub]\n\nobjective = (sum(lr)+sum(ur))**2\n\nproblem = cvxpy.Problem(cvxpy.Minimize(objective), constraints)\nproblem.solve()\n</code></pre>\n\n<p>(<a href=\"https://github.com/bmreiniger/datascience.stackexchange/blob/master/54450.ipynb\" rel=\"nofollow noreferrer\">https://github.com/bmreiniger/datascience.stackexchange/blob/master/54450.ipynb</a>)</p>\n\n<p>Assuming that's all right, it at least removes the need to iterate through different train/eval proportions.  (You could modify the upper and lower bounds and the relaxations/objective to put it more in terms of the train/eval proportions.)</p>\n\n<p>I'm not so familiar with different solvers.  A superficial glance suggests that <code>ECOS_BB</code> isn't actually built for MICP, so maybe backing the objective off to a linear one is a better idea.</p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "10241",
            "_score": 3.3685355,
            "_source": {
                "title": "Tensorflow deep learning Weird Accuracy",
                "content": "Tensorflow deep learning Weird Accuracy <p>I want to build a model to classify images of a dataset( ASL signs alphabet ). </p>\n\n<p>The dataset is in a folder where each sub-folder contains the images of a class and the name of the class is the name the sub-folder. Each image is 200x200. </p>\n\n<p>I wrote two scripts. The first one to transform the dataset to TFrecords. Here it is : </p>\n\n<pre><code>import glob\nimport numpy as np\nfrom random import shuffle\nimport cv2\nfrom tqdm import tqdm\nimport tensorflow as tf\n\n#dataset file\ndataset_file=glob.glob(\"dataset/asl_alphabet_train/*\")\n\n\nfeatures_add=[]\nlabels=[]\nclasses_names=[]\nimg_size=100\n\n#getting the addess of each image and its label and the name of each class\n#the label will be the same as the index of the corresponding classe name : classes_names(label[i]) is the name of the classes of the image i \nfor i,f in enumerate(dataset_file):\n    classes_names.append(f[27:]) #\u00a0the name of the subfolders is the name of the class\n    subfolder_paths=glob.glob(f+\"/*\")\n    for j,sub_f in enumerate(subfolder_paths):\n        labels.append(i) # the label is the same for all the images in the subfolder\n        features_add.append(sub_f)\n\nfeatures_add=np.asarray(features_add)\nlabels=np.asarray(labels)\nclasses_names=np.asarray(classes_names)\n\n# shuffle the data \ntmp=list(zip(features_add, labels))\nshuffle(tmp)\nfeatures_add, labels=zip(*tmp)\n\n#Divide the data into 70% train, 20% validation and 10% test\ntrain_add=features_add[0:int(0.7*len(features_add))]\ntrain_labels=labels[0:int(0.7*len(features_add))]\n\nval_add=features_add[int(0.7*len(features_add)):int(0.9*len(features_add))]\nval_labels=labels[int(0.7*len(features_add)):int(0.9*len(features_add))]\n\ntest_add=features_add[int(0.9*len(features_add)):]\ntest_labels=labels[int(0.9*len(features_add)):]\n\ndef read_image(add):\n    #read an image\n    #no need to resize, all the images in this dataset are 200x200\n    #cv2 images in BGR, it doesn't really matter for our netword\n    img= cv2.imread(add)\n    img = cv2.resize(img, (img_size, img_size), interpolation=cv2.INTER_CUBIC)\n    img=img.astype(np.float32)#/255\n    #img = np.asarray(img)\n    return img\n\n\ndef _int64_feature(value):\n    #convert value to int64 using tf.train.Int64List and creature a feature using tf.train.Feature\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef _bytes_feature(value):\n    #convert value to bytes using tf.train.BytesList and creature a feature using tf.train.Feature\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef TFrecord_write(features_add,labes, name):\n    # data-&gt;FeatureSet-&gt;Example protocol-&gt; Serialized Example -&gt; tfRecord\n    with tf.python_io.TFRecordWriter(\"TFrecords/\"+name+\".tfrecords\") as writer: #\u00a0the TFwriter writer\n        print(\"writing the \"+name+\" TFrecord\")\n        for i,add in enumerate(tqdm(features_add)):\n            img_raw=read_image(add)\n            height=img_raw.shape[0]\n            width=img_raw.shape[1]\n            depth=img_raw.shape[2]\n            img_raw=img_raw.tostring()#\u00a0convert each image to bytes\n            example= tf.train.Example(\n                features=tf.train.Features(\n                    feature={\n                        'label': _int64_feature(int(labels[i])),\n                        'img_raw': _bytes_feature(tf.compat.as_bytes(img_raw))\n                    }))\n            writer.write(example.SerializeToString())\n\n#write the record\nTFrecord_write(train_add,train_labels,\"train\")\nTFrecord_write(val_add,val_labels,\"val\")\nTFrecord_write(test_add,test_labels,\"test\")\n</code></pre>\n\n<p>And the second script is where I read the TFrecords, define the model and train it, and the evaluate it. Here It's : </p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\nimport cv2\nfrom PIL import Image\nimport glob\nimport sys\nimport math\n\nbatch_size = 3\nimg_size = 100\nclasses_names = []\ndataset_file = glob.glob(\"dataset/asl_alphabet_train/*\")\n\n\nfor f in dataset_file:\n    classes_names.append(f[27:])  # \u00a0the name of the subfolders is the name of the class\nnum_classes = len(classes_names)\n\n\ndef parser(record):\n    # a parsing function to parse the tfrecords\n    keys_to_features = {\n        \"img_raw\": tf.FixedLenFeature([], tf.string),\n        \"label\": tf.FixedLenFeature([], tf.int64)\n\n    }\n    parsed = tf.parse_single_example(record,\n                                     keys_to_features)  # parsing one example from the example buffer from the tfrecord using the keys\n    image = tf.decode_raw(parsed[\"img_raw\"], tf.float32)  # decoding ( bytes -&gt; tf.float32)\n    image= tf.cast(image, tf.float32)\n    image = tf.reshape(image, shape=[img_size, img_size, 3])  # reshaping images\n    label = parsed[\"label\"]  # casting labels to int32\n    label = tf.one_hot(indices=label, depth=num_classes) # transform to one hot encoding\n    # with tf.Session() as session:\n    #     print(session.run(label))\n    return image, label\n\n\ndef input_fn(filenames, train_bool=True):\n    # from tfrecord to iterable data\n    dataset = tf.data.TFRecordDataset(filenames=filenames,\n                                      num_parallel_reads=40)  # instantiantion of an object from class TFRecordDataset\n    dataset = dataset.map(parser)  # maps a function to the dataset\n    if train_bool:\n        #dataset = dataset.shuffle(buffer_size=2048)\n        repeat = 1  # if in training mode allow reading data infinitely\n    else:\n        repeat = 1  # if in validation or test allow max 1 read\n    dataset = dataset.repeat(repeat)\n    dataset = dataset.batch(batch_size)  # \u00a0define bach size\n    # iterator= dataset.make_one_shot_iterator()#\u00a0making the iterator\n    # images_batch, labels_batch=iterator.get_next()# getting the data\n    # x= {'image': images_batch}\n    # y= labels_batch\n\n    return dataset  # x, y\n\ndef train_input_fn():\n    return input_fn(filenames=[\"TFrecords/train.tfrecords\"])\n\ndef val_input_fn():\n    return input_fn(filenames=[\"TFrecords/val.tfrecords\"],train_bool=False)\n\ndef test_input_fn():\n    return input_fn(filenames=[\"TFrecords/test.tfrecords\"])\n\ndef conv_layer_max2pool(Input, num_output_channels, conv_filter_size,conv_strides, pool_filter_size, pool_strides):\n    # a function to create convulional layers, parameters are :\n    #       num_output_channels : number of the output filters\n    #       conv_filters_size: size of the convolution filter it should be a 2-D tuple\n    #       conv-strides: strides of the convolution. It's assumes that the strides over the height are the same as over the width\n    #       pool_filter_strides: as the conv_filter_size but for the pooling filter\n    #       pool_strides: as the conv_strides but for the pooling\n\n    filter_shape= [conv_filter_size[0], conv_filter_size[1], Input.get_shape().as_list()[3], num_output_channels] #creating the shape of the filter to create the weights of the convolution\n    W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.01)) #creating the weights\n    conv= tf.nn.conv2d(Input, W, [1,conv_strides,conv_strides,1], padding=\"SAME\") #\u00a0creating the convolutional layer\n\n    bias=tf.Variable(tf.zeros([num_output_channels])) #\u00a0creating the biasis\n\n    conv=tf.nn.bias_add(conv, bias)\n    conv=tf.nn.relu(conv)\n\n    #max pooling\n    conv=tf.nn.max_pool(conv, [1, pool_filter_size[0], pool_filter_size[1], 1],[1, pool_strides, pool_strides, 1], padding=\"SAME\")\n\n    return conv\n\ndef model_fn(X, keep_prob):\n\n    conv1=conv_layer_max2pool(X,num_output_channels=64, conv_filter_size=(5,5), conv_strides=2, pool_filter_size=(2,2), pool_strides=2)\n\n    conv1= tf.nn.dropout(conv1, keep_prob)\n\n    conv2=conv_layer_max2pool(conv1,num_output_channels=128, conv_filter_size=(3,3), conv_strides=2, pool_filter_size=(2,2), pool_strides=2)\n\n    conv2= tf.nn.dropout(conv2, keep_prob)\n\n    # conv3 = conv_layer_max2pool(conv2, num_output_channels=128, conv_filter_size=(3, 3), conv_strides=2,\n    #                             pool_filter_size=(2, 2), pool_strides=2)\n    #\n    # conv4 = conv_layer_max2pool(conv3, num_output_channels=128, conv_filter_size=(2, 2), conv_strides=2,\n    #                             pool_filter_size=(2, 2), pool_strides=2)\n\n\n\n\n\n    flat_layer= tf.layers.flatten(conv2)\n\n    #FC layers\n\n    dense1=tf.layers.dense(flat_layer, 256, activation=tf.nn.relu)\n    dense2=tf.layers.dense(dense1, 128, activation=tf.nn.relu)\n    dense3=tf.layers.dense(dense2, 64, activation=tf.nn.relu)\n\n    #output layer\n    output=tf.layers.dense(dense3, num_classes)\n    return output\n\n\n#Remove previous weights, bias, inputs...\ntf.reset_default_graph()\n\n# place holdes for features, labels and keep_prob\nx=tf.placeholder(tf.float32, [None, img_size, img_size, 3] , name=\"X\")\ny=tf.placeholder(tf.int64, [None, num_classes], name=\"y\")\nkeep_prob=tf.placeholder(tf.float32, name=\"keep_prob\")\n\n\n#logits\nlogits= tf.identity(model_fn(x, keep_prob), name=\"logits\")\n\n# loss=\nloss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( labels=y, logits=logits))\n\n#optimizer\noptimizer=tf.train.AdamOptimizer().minimize(loss)\n\n#Accuracy\npred=tf.equal(tf.argmax(logits,1),tf.argmax(y,1))\naccuracy=tf.reduce_mean(tf.cast(pred,tf.float32), name=\"accuracy\")\n\n\ntrain_dataset= train_input_fn()\ntrain_iterator=train_dataset.make_initializable_iterator()\nfeatures, labels= train_iterator.get_next()\n\nvalid_dataset=val_input_fn()\nvalid_iterator=valid_dataset.make_initializable_iterator()\nvalid_features, valid_labels=valid_iterator.get_next()\n\n\nsave_model_path=\"Model/model0/\"\n\nepochs= 10\nkeep_probability=0.5\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    #num_images=train_input_fn().get_shape().as_list[0]\n    #training_cycle\n    for epoch in range(epochs):\n        #for _ in range(math.ceil(num_images/batch_size)):\n        sess.run(train_iterator.initializer)\n        sess.run(valid_iterator.initializer)\n        count=0\n        while True  :\n            try:\n                count += 1\n                img_batch, label_batch= sess.run([features,labels])\n                # print([classes_names[i] for i in label_batch])\n                # #input()\n                # for i,test in enumerate(img_batch):\n                #     #print(label_batch)#classes_names[label_batch[1]])\n                #     test2 = Image.fromarray(img_batch[i].astype('uint8'), 'RGB')\n                #     test2.show(test2)\n                #     input()\n                # print(\"next batch\")\n                sess.run(optimizer, feed_dict={x: img_batch, y: label_batch, keep_prob: keep_probability})\n                #print(\"batch number :\", count)\n            except tf.errors.OutOfRangeError:\n                break\n\n        print('Epoch {:&gt;2}: '.format(epoch+1),end='')\n        l = sess.run(loss, feed_dict={x: img_batch, y: label_batch, keep_prob: 1.0})\n        count=0\n        valid_accuracy=0\n        while True :\n            try:\n                valid_img_batch, valid_label_batch = sess.run([valid_features, valid_labels])\n                valid_accuracy+=sess.run(accuracy, feed_dict={x: valid_img_batch, y:valid_label_batch, keep_prob:1.0})\n            except  tf.errors.OutOfRangeError:\n                break\n            count+=1\n        valid_accuracy=valid_accuracy/count\n        print(\"The loss is : {0}, and the Validation Accuracy is: {1}\".format(l, valid_accuracy))\n\n    saver=tf.train.Saver()\n    saver_path=saver.save(sess,save_model_path)\n</code></pre>\n\n<p>The problem is , no matter how I change the model, no matter how I change the batch_size or even change the optimizer, and no matter how long I run the training I get always the same accuracy : arround 3%. </p>\n\n<p>I still can't figure it out why. \nCan you help? </p>\n\n<p>Thank you </p>\n <python><deep-learning><tensorflow>",
                "codes": [],
                "question_id:": "36985",
                "question_votes:": "1",
                "question_text:": "<p>I want to build a model to classify images of a dataset( ASL signs alphabet ). </p>\n\n<p>The dataset is in a folder where each sub-folder contains the images of a class and the name of the class is the name the sub-folder. Each image is 200x200. </p>\n\n<p>I wrote two scripts. The first one to transform the dataset to TFrecords. Here it is : </p>\n\n<pre><code>import glob\nimport numpy as np\nfrom random import shuffle\nimport cv2\nfrom tqdm import tqdm\nimport tensorflow as tf\n\n#dataset file\ndataset_file=glob.glob(\"dataset/asl_alphabet_train/*\")\n\n\nfeatures_add=[]\nlabels=[]\nclasses_names=[]\nimg_size=100\n\n#getting the addess of each image and its label and the name of each class\n#the label will be the same as the index of the corresponding classe name : classes_names(label[i]) is the name of the classes of the image i \nfor i,f in enumerate(dataset_file):\n    classes_names.append(f[27:]) #\u00a0the name of the subfolders is the name of the class\n    subfolder_paths=glob.glob(f+\"/*\")\n    for j,sub_f in enumerate(subfolder_paths):\n        labels.append(i) # the label is the same for all the images in the subfolder\n        features_add.append(sub_f)\n\nfeatures_add=np.asarray(features_add)\nlabels=np.asarray(labels)\nclasses_names=np.asarray(classes_names)\n\n# shuffle the data \ntmp=list(zip(features_add, labels))\nshuffle(tmp)\nfeatures_add, labels=zip(*tmp)\n\n#Divide the data into 70% train, 20% validation and 10% test\ntrain_add=features_add[0:int(0.7*len(features_add))]\ntrain_labels=labels[0:int(0.7*len(features_add))]\n\nval_add=features_add[int(0.7*len(features_add)):int(0.9*len(features_add))]\nval_labels=labels[int(0.7*len(features_add)):int(0.9*len(features_add))]\n\ntest_add=features_add[int(0.9*len(features_add)):]\ntest_labels=labels[int(0.9*len(features_add)):]\n\ndef read_image(add):\n    #read an image\n    #no need to resize, all the images in this dataset are 200x200\n    #cv2 images in BGR, it doesn't really matter for our netword\n    img= cv2.imread(add)\n    img = cv2.resize(img, (img_size, img_size), interpolation=cv2.INTER_CUBIC)\n    img=img.astype(np.float32)#/255\n    #img = np.asarray(img)\n    return img\n\n\ndef _int64_feature(value):\n    #convert value to int64 using tf.train.Int64List and creature a feature using tf.train.Feature\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef _bytes_feature(value):\n    #convert value to bytes using tf.train.BytesList and creature a feature using tf.train.Feature\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef TFrecord_write(features_add,labes, name):\n    # data-&gt;FeatureSet-&gt;Example protocol-&gt; Serialized Example -&gt; tfRecord\n    with tf.python_io.TFRecordWriter(\"TFrecords/\"+name+\".tfrecords\") as writer: #\u00a0the TFwriter writer\n        print(\"writing the \"+name+\" TFrecord\")\n        for i,add in enumerate(tqdm(features_add)):\n            img_raw=read_image(add)\n            height=img_raw.shape[0]\n            width=img_raw.shape[1]\n            depth=img_raw.shape[2]\n            img_raw=img_raw.tostring()#\u00a0convert each image to bytes\n            example= tf.train.Example(\n                features=tf.train.Features(\n                    feature={\n                        'label': _int64_feature(int(labels[i])),\n                        'img_raw': _bytes_feature(tf.compat.as_bytes(img_raw))\n                    }))\n            writer.write(example.SerializeToString())\n\n#write the record\nTFrecord_write(train_add,train_labels,\"train\")\nTFrecord_write(val_add,val_labels,\"val\")\nTFrecord_write(test_add,test_labels,\"test\")\n</code></pre>\n\n<p>And the second script is where I read the TFrecords, define the model and train it, and the evaluate it. Here It's : </p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\nimport cv2\nfrom PIL import Image\nimport glob\nimport sys\nimport math\n\nbatch_size = 3\nimg_size = 100\nclasses_names = []\ndataset_file = glob.glob(\"dataset/asl_alphabet_train/*\")\n\n\nfor f in dataset_file:\n    classes_names.append(f[27:])  # \u00a0the name of the subfolders is the name of the class\nnum_classes = len(classes_names)\n\n\ndef parser(record):\n    # a parsing function to parse the tfrecords\n    keys_to_features = {\n        \"img_raw\": tf.FixedLenFeature([], tf.string),\n        \"label\": tf.FixedLenFeature([], tf.int64)\n\n    }\n    parsed = tf.parse_single_example(record,\n                                     keys_to_features)  # parsing one example from the example buffer from the tfrecord using the keys\n    image = tf.decode_raw(parsed[\"img_raw\"], tf.float32)  # decoding ( bytes -&gt; tf.float32)\n    image= tf.cast(image, tf.float32)\n    image = tf.reshape(image, shape=[img_size, img_size, 3])  # reshaping images\n    label = parsed[\"label\"]  # casting labels to int32\n    label = tf.one_hot(indices=label, depth=num_classes) # transform to one hot encoding\n    # with tf.Session() as session:\n    #     print(session.run(label))\n    return image, label\n\n\ndef input_fn(filenames, train_bool=True):\n    # from tfrecord to iterable data\n    dataset = tf.data.TFRecordDataset(filenames=filenames,\n                                      num_parallel_reads=40)  # instantiantion of an object from class TFRecordDataset\n    dataset = dataset.map(parser)  # maps a function to the dataset\n    if train_bool:\n        #dataset = dataset.shuffle(buffer_size=2048)\n        repeat = 1  # if in training mode allow reading data infinitely\n    else:\n        repeat = 1  # if in validation or test allow max 1 read\n    dataset = dataset.repeat(repeat)\n    dataset = dataset.batch(batch_size)  # \u00a0define bach size\n    # iterator= dataset.make_one_shot_iterator()#\u00a0making the iterator\n    # images_batch, labels_batch=iterator.get_next()# getting the data\n    # x= {'image': images_batch}\n    # y= labels_batch\n\n    return dataset  # x, y\n\ndef train_input_fn():\n    return input_fn(filenames=[\"TFrecords/train.tfrecords\"])\n\ndef val_input_fn():\n    return input_fn(filenames=[\"TFrecords/val.tfrecords\"],train_bool=False)\n\ndef test_input_fn():\n    return input_fn(filenames=[\"TFrecords/test.tfrecords\"])\n\ndef conv_layer_max2pool(Input, num_output_channels, conv_filter_size,conv_strides, pool_filter_size, pool_strides):\n    # a function to create convulional layers, parameters are :\n    #       num_output_channels : number of the output filters\n    #       conv_filters_size: size of the convolution filter it should be a 2-D tuple\n    #       conv-strides: strides of the convolution. It's assumes that the strides over the height are the same as over the width\n    #       pool_filter_strides: as the conv_filter_size but for the pooling filter\n    #       pool_strides: as the conv_strides but for the pooling\n\n    filter_shape= [conv_filter_size[0], conv_filter_size[1], Input.get_shape().as_list()[3], num_output_channels] #creating the shape of the filter to create the weights of the convolution\n    W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.01)) #creating the weights\n    conv= tf.nn.conv2d(Input, W, [1,conv_strides,conv_strides,1], padding=\"SAME\") #\u00a0creating the convolutional layer\n\n    bias=tf.Variable(tf.zeros([num_output_channels])) #\u00a0creating the biasis\n\n    conv=tf.nn.bias_add(conv, bias)\n    conv=tf.nn.relu(conv)\n\n    #max pooling\n    conv=tf.nn.max_pool(conv, [1, pool_filter_size[0], pool_filter_size[1], 1],[1, pool_strides, pool_strides, 1], padding=\"SAME\")\n\n    return conv\n\ndef model_fn(X, keep_prob):\n\n    conv1=conv_layer_max2pool(X,num_output_channels=64, conv_filter_size=(5,5), conv_strides=2, pool_filter_size=(2,2), pool_strides=2)\n\n    conv1= tf.nn.dropout(conv1, keep_prob)\n\n    conv2=conv_layer_max2pool(conv1,num_output_channels=128, conv_filter_size=(3,3), conv_strides=2, pool_filter_size=(2,2), pool_strides=2)\n\n    conv2= tf.nn.dropout(conv2, keep_prob)\n\n    # conv3 = conv_layer_max2pool(conv2, num_output_channels=128, conv_filter_size=(3, 3), conv_strides=2,\n    #                             pool_filter_size=(2, 2), pool_strides=2)\n    #\n    # conv4 = conv_layer_max2pool(conv3, num_output_channels=128, conv_filter_size=(2, 2), conv_strides=2,\n    #                             pool_filter_size=(2, 2), pool_strides=2)\n\n\n\n\n\n    flat_layer= tf.layers.flatten(conv2)\n\n    #FC layers\n\n    dense1=tf.layers.dense(flat_layer, 256, activation=tf.nn.relu)\n    dense2=tf.layers.dense(dense1, 128, activation=tf.nn.relu)\n    dense3=tf.layers.dense(dense2, 64, activation=tf.nn.relu)\n\n    #output layer\n    output=tf.layers.dense(dense3, num_classes)\n    return output\n\n\n#Remove previous weights, bias, inputs...\ntf.reset_default_graph()\n\n# place holdes for features, labels and keep_prob\nx=tf.placeholder(tf.float32, [None, img_size, img_size, 3] , name=\"X\")\ny=tf.placeholder(tf.int64, [None, num_classes], name=\"y\")\nkeep_prob=tf.placeholder(tf.float32, name=\"keep_prob\")\n\n\n#logits\nlogits= tf.identity(model_fn(x, keep_prob), name=\"logits\")\n\n# loss=\nloss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( labels=y, logits=logits))\n\n#optimizer\noptimizer=tf.train.AdamOptimizer().minimize(loss)\n\n#Accuracy\npred=tf.equal(tf.argmax(logits,1),tf.argmax(y,1))\naccuracy=tf.reduce_mean(tf.cast(pred,tf.float32), name=\"accuracy\")\n\n\ntrain_dataset= train_input_fn()\ntrain_iterator=train_dataset.make_initializable_iterator()\nfeatures, labels= train_iterator.get_next()\n\nvalid_dataset=val_input_fn()\nvalid_iterator=valid_dataset.make_initializable_iterator()\nvalid_features, valid_labels=valid_iterator.get_next()\n\n\nsave_model_path=\"Model/model0/\"\n\nepochs= 10\nkeep_probability=0.5\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    #num_images=train_input_fn().get_shape().as_list[0]\n    #training_cycle\n    for epoch in range(epochs):\n        #for _ in range(math.ceil(num_images/batch_size)):\n        sess.run(train_iterator.initializer)\n        sess.run(valid_iterator.initializer)\n        count=0\n        while True  :\n            try:\n                count += 1\n                img_batch, label_batch= sess.run([features,labels])\n                # print([classes_names[i] for i in label_batch])\n                # #input()\n                # for i,test in enumerate(img_batch):\n                #     #print(label_batch)#classes_names[label_batch[1]])\n                #     test2 = Image.fromarray(img_batch[i].astype('uint8'), 'RGB')\n                #     test2.show(test2)\n                #     input()\n                # print(\"next batch\")\n                sess.run(optimizer, feed_dict={x: img_batch, y: label_batch, keep_prob: keep_probability})\n                #print(\"batch number :\", count)\n            except tf.errors.OutOfRangeError:\n                break\n\n        print('Epoch {:&gt;2}: '.format(epoch+1),end='')\n        l = sess.run(loss, feed_dict={x: img_batch, y: label_batch, keep_prob: 1.0})\n        count=0\n        valid_accuracy=0\n        while True :\n            try:\n                valid_img_batch, valid_label_batch = sess.run([valid_features, valid_labels])\n                valid_accuracy+=sess.run(accuracy, feed_dict={x: valid_img_batch, y:valid_label_batch, keep_prob:1.0})\n            except  tf.errors.OutOfRangeError:\n                break\n            count+=1\n        valid_accuracy=valid_accuracy/count\n        print(\"The loss is : {0}, and the Validation Accuracy is: {1}\".format(l, valid_accuracy))\n\n    saver=tf.train.Saver()\n    saver_path=saver.save(sess,save_model_path)\n</code></pre>\n\n<p>The problem is , no matter how I change the model, no matter how I change the batch_size or even change the optimizer, and no matter how long I run the training I get always the same accuracy : arround 3%. </p>\n\n<p>I still can't figure it out why. \nCan you help? </p>\n\n<p>Thank you </p>\n",
                "tags": "<python><deep-learning><tensorflow>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "14444",
            "_score": 3.3311458,
            "_source": {
                "title": "LSTM not converging",
                "content": "LSTM not converging <p>I am sorry if this questions is basic but I am quite new to NN in general. I am trying to build an LSTM to predict certain properties of a light curve (the output is 0 or 1). I build it in pytorch. Here is my code:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torch.optim as optim\nimport numpy as np\n\ntorch.manual_seed(1)\ntorch.cuda.set_device(0)\n\nfrom fastai.learner import *\n\nn_hidden = 64\nn_classes = 2\nbs = 1\n\nclass TESS_LSTM(nn.Module):\n    def __init__(self, nl):\n        super().__init__()\n        self.nl = nl\n        self.rnn = nn.LSTM(1, n_hidden, nl, dropout=0.01, bidirectional=True)\n        self.l_out = nn.Linear(n_hidden*2, n_classes)\n        self.init_hidden(bs)\n\n    def forward(self, input):\n        outp,h = self.rnn(input.view(len(input), bs, -1), self.h)\n        #self.h = repackage_var(h)\n        return F.log_softmax(self.l_out(outp),dim=2)\n\n    def init_hidden(self, bs):\n        self.h = (V(torch.zeros(self.nl*2, bs, n_hidden)),\n                  V(torch.zeros(self.nl*2, bs, n_hidden)))\n\nmodel = TESS_LSTM(2).cuda()\nloss_function = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nfor epoch in range(50):\n    model.zero_grad()\n    tag_scores = model(data_x)\n    loss = loss_function(tag_scores.reshape(len(data_x),n_classes), data_y.reshape(len(data_y)))\n    loss.backward()\n    optimizer.step()\n\n    if epoch%10==0:\n        print(\"Loss at epoch %d = \" %epoch, loss)\n</code></pre>\n\n<p>Also:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>\ndata_x = tensor([\n    [0.9995450377],\n    [0.9991207719],\n    [0.9986526966],\n    [1.0017241240],\n    [1.0016067028],\n    [1.0000480413],\n    [1.0016841888],\n    [1.0010652542],\n    [0.9991232157],\n    [1.0004128218],\n    [0.9986800551],\n    [1.0011130571],\n    [1.0001415014],\n    [1.0004080534],\n    [1.0016922951],\n    [1.0008358955],\n    [1.0001622438],\n    [1.0004277229],\n    [1.0011759996],\n    [1.0013391972],\n    [0.9995799065],\n    [1.0019282103],\n    [1.0006642342],\n    [1.0006272793],\n    [1.0011570454],\n    [1.0015332699],\n    [1.0011225939],\n    [1.0003337860],\n    [1.0014277697],\n    [1.0003565550],\n    [0.9989787340],\n    [1.0006136894],\n    [1.0003052950],\n    [1.0001049042],\n    [1.0020918846],\n    [0.9999115467],\n    [1.0006635189],\n    [1.0007561445],\n    [1.0016170740],\n    [1.0008252859],\n    [0.9997656345],\n    [1.0001330376],\n    [1.0017272234],\n    [1.0004107952],\n    [1.0012439489],\n    [0.9994274378],\n    [1.0014992952],\n    [1.0015807152],\n    [1.0004781485],\n    [1.0010997057],\n    [1.0011326075],\n    [1.0005493164],\n    [1.0014353991],\n    [0.9990324974],\n    [1.0012129545],\n    [0.9990709424],\n    [1.0006347895],\n    [1.0000327826],\n    [1.0005196333],\n    [1.0012207031],\n    [1.0003460646],\n    [1.0004434586],\n    [1.0003618002],\n    [1.0005420446],\n    [1.0005528927],\n    [1.0006977320],\n    [1.0005317926],\n    [1.0000808239],\n    [1.0005664825],\n    [0.9994245768],\n    [0.9999254942],\n    [1.0011985302],\n    [1.0009841919],\n    [0.9999029040],\n    [1.0014100075],\n    [1.0014085770],\n    [1.0005567074],\n    [1.0016088486],\n    [0.9997186661],\n    [0.9998687506],\n    [0.9988344908],\n    [0.9999858141],\n    [1.0004914999],\n    [1.0003308058],\n    [1.0001890659],\n    [1.0002681017],\n    [1.0029908419],\n    [1.0005286932],\n    [1.0004363060],\n    [0.9994311333],\n    [1.0011523962],\n    [1.0008679628],\n    [1.0014137030],\n    [0.9994244576],\n    [1.0003470182],\n    [1.0001592636],\n    [1.0002418756],\n    [0.9992931485],\n    [1.0016175508],\n    [1.0000959635],\n    [1.0005099773],\n    [1.0008889437],\n    [0.9998087287],\n    [0.9995828867],\n    [0.9997566342],\n    [1.0002474785],\n    [1.0010808706],\n    [1.0002821684],\n    [1.0013456345],\n    [1.0013040304],\n    [1.0010949373],\n    [1.0002720356],\n    [0.9996811152],\n    [1.0006061792],\n    [1.0012511015],\n    [0.9999302626],\n    [0.9985374212],\n    [1.0002642870],\n    [0.9996038675],\n    [1.0007606745],\n    [0.9992995858],\n    [1.0000385046],\n    [0.9997834563],\n    [1.0005996227],\n    [1.0006167889],\n    [1.0015753508],\n    [1.0010306835],\n    [0.9997833371],\n    [1.0010590553],\n    [1.0008200407],\n    [1.0008001328],\n    [1.0014072657],\n    [0.9994395375],\n    [0.9991182089],\n    [1.0011717081],\n    [1.0007920265],\n    [1.0011025667],\n    [1.0004047155],\n    [1.0017303228],\n    [1.0014981031],\n    [0.9995774031],\n    [0.9999650121],\n    [0.9992966652],\n    [1.0013586283],\n    [1.0003392696],\n    [1.0005040169],\n    [1.0008341074],\n    [1.0014744997],\n    [0.9996585250],\n    [1.0019916296],\n    [1.0007069111],\n    [1.0004591942],\n    [1.0004271269],\n    [0.9991059303],\n    [1.0003436804],\n    [0.9990482330],\n    [0.9980322123],\n    [0.9980198145],\n    [0.9966595173],\n    [0.9969686270],\n    [0.9977232814],\n    [0.9969192147],\n    [0.9962794185],\n    [0.9947851300],\n    [0.9946336746],\n    [0.9943053722],\n    [0.9946651459],\n    [0.9930071235],\n    [0.9940539598],\n    [0.9950682521],\n    [0.9947031140],\n    [0.9950703979],\n    [0.9945428371],\n    [0.9945927858],\n    [0.9937841296],\n    [0.9944553375],\n    [0.9929991364],\n    [0.9940859079],\n    [0.9930059314],\n    [0.9942978621],\n    [0.9950152636],\n    [0.9943225384],\n    [0.9934711456],\n    [0.9929080606],\n    [0.9934846163],\n    [0.9954113960],\n    [0.9925802350],\n    [0.9929560423],\n    [0.9933584929],\n    [0.9929228425],\n    [0.9930893779],\n    [0.9936142564],\n    [0.9943635464],\n    [0.9933300614],\n    [0.9925817847],\n    [0.9927681088],\n    [0.9930697680],\n    [0.9937900901],\n    [0.9919354320],\n    [0.9937084913],\n    [0.9951301217],\n    [0.9926426411],\n    [0.9933566451],\n    [0.9937180877],\n    [0.9922621250],\n    [0.9933888316],\n    [0.9936477542],\n    [0.9916112423],\n    [0.9943441153],\n    [0.9934164286],\n    [0.9949553013],\n    [0.9941871166],\n    [0.9933763146],\n    [0.9959306121],\n    [0.9930690527],\n    [0.9928541183],\n    [0.9936354756],\n    [0.9931223392],\n    [0.9936516881],\n    [0.9935654402],\n    [0.9932218790],\n    [0.9943401814],\n    [0.9931038022],\n    [0.9926875830],\n    [0.9928631186],\n    [0.9936705232],\n    [0.9939361215],\n    [0.9942125678],\n    [0.9939611554],\n    [0.9936586618],\n    [0.9933990240],\n    [0.9948219061],\n    [0.9940339923],\n    [0.9950091243],\n    [0.9952197671],\n    [0.9947227240],\n    [0.9935435653],\n    [0.9956403971],\n    [0.9943848252],\n    [0.9942221045],\n    [0.9960014224],\n    [0.9931004643],\n    [0.9960579872],\n    [0.9951166511],\n    [0.9964768291],\n    [0.9968702793],\n    [0.9967978597],\n    [0.9971982837],\n    [0.9977793097],\n    [0.9982623458],\n    [0.9988413453],\n    [1.0008778572],\n    [1.0013417006],\n    [1.0000336170],\n    [0.9979853630],\n    [0.9988892674],\n    [0.9994396567],\n    [1.0002176762],\n    [1.0017417669],\n    [1.0013097525],\n    [1.0011264086],\n    [1.0004124641],\n    [1.0003939867],\n    [0.9996479750],\n    [0.9995540380],\n    [1.0003930330],\n    [1.0016323328],\n    [1.0004589558],\n    [0.9996963739],\n    [0.9989817142],\n    [0.9998068213],\n    [1.0011200905],\n    [1.0006275177],\n    [1.0000452995],\n    [1.0012514591],\n    [1.0002357960],\n    [0.9993159175],\n    [1.0002738237],\n    [0.9994575381],\n    [0.9986617565],\n    [0.9982920289],\n    [0.9998571873],\n    [0.9996472597],\n    [1.0012613535],\n    [1.0015693903],\n    [0.9999635220],\n    [1.0006184578],\n    [1.0010757446],\n    [0.9988756776],\n    [1.0004955530],\n    [1.0011548996],\n    [1.0007628202],\n    [1.0006260872],\n    [0.9989725947],\n    [1.0013129711],\n    [0.9994829297],\n    [0.9998571873],\n    [0.9994959831],\n    [1.0007432699],\n    [0.9995724559],\n    [0.9999076724],\n    [0.9992097020],\n    [1.0011855364],\n    [0.9987785220],\n    [1.0010210276],\n    [0.9998293519],\n    [0.9996315837],\n    [0.9999501705],\n    [1.0001417398],\n    [1.0005141497],\n    [0.9993781447],\n    [1.0003532171],\n    [0.9999422431],\n    [1.0014258623],\n    [1.0012118816],\n    [0.9994109273],\n    [1.0019438267],\n    [1.0012354851],\n    [1.0009905100],\n    [1.0001032352],\n    [0.9999653101],\n    [0.9991906881],\n    [1.0004152060],\n    [0.9998226762],\n    [0.9999175668],\n    [0.9994540215],\n    [1.0000722408],\n    [1.0019129515],\n    [0.9997307658],\n    [0.9996227026],\n    [1.0011816025],\n    [0.9993667006],\n    [1.0010036230],\n    [0.9993645549],\n    [1.0004647970],\n    [0.9995272160],\n    [0.9989504814],\n    [0.9981039166],\n    [1.0006005764],\n    [0.9998896718],\n    [1.0004893541],\n    [0.9991874099],\n    [1.0005015135],\n    [0.9995905161],\n    [0.9990965128],\n    [1.0012912750],\n    [1.0004948378],\n    [1.0002779961],\n    [0.9988743067],\n    [1.0019037724],\n    [1.0006437302],\n    [0.9999380112],\n    [1.0001602173],\n    [0.9997741580],\n    [0.9988395572],\n    [0.9999371171],\n    [0.9989091754],\n    [0.9987531900],\n    [1.0003957748],\n    [0.9997722507],\n    [0.9988819361],\n    [0.9998422265],\n    [0.9986129999],\n    [0.9989410639],\n    [1.0016149282],\n    [0.9997441173],\n    [1.0002747774],\n    [0.9990793467],\n    [1.0006495714],\n    [1.0004252195],\n    [0.9997921586],\n    [0.9987344146],\n    [0.9998763800],\n    [0.9988097548],\n    [1.0007627010],\n    [1.0004670620],\n    [1.0007309914],\n    [0.9987894297],\n    [1.0000542402],\n    [1.0004990101],\n    [0.9999514818],\n    [0.9998412132],\n    [1.0000183582],\n    [1.0003197193],\n    [0.9991712570],\n    [0.9992188215],\n    [0.9986482859],\n    [1.0010583401],\n    [1.0011837482],\n    [0.9993829727],\n    [0.9995718002],\n    [0.9997168183],\n    [1.0017461777],\n    [0.9998381138],\n    [0.9990652204],\n    [1.0001449585],\n    [0.9998424053],\n    [1.0011798143],\n    [1.0013160706],\n    [0.9995942712],\n    [1.0001651049],\n    [1.0001466274],\n    [0.9982855320],\n    [0.9992064238],\n    [1.0009102821],\n    [0.9982813597],\n    [1.0000503063],\n    [0.9982630014],\n    [1.0017516613],\n    [0.9995808005],\n    [0.9989835620],\n    [1.0003046989],\n    [1.0019340515],\n    [0.9996930957],\n    [1.0000711679],\n    [1.0011881590],\n    [1.0009138584],\n    [1.0013902187],\n    [0.9994105101],\n    [0.9986224174],\n    [0.9995336533],\n    [1.0006912947],\n    [0.9995169044],\n    [0.9998968840],\n    [0.9989182949],\n    [0.9999300838],\n    [0.9991120696],\n    [0.9996063709],\n    [1.0008803606],\n    [1.0019868612],\n    [1.0004760027],\n    [0.9996407032],\n    [1.0011100769],\n    [1.0026890039],\n    [0.9996611476],\n    [0.9991108775],\n    [0.9982090592],\n    [1.0000833273],\n    [1.0015701056],\n    [0.9994426966],\n    [0.9999341369],\n    [1.0002813339],\n    [0.9998958707],\n    [1.0011670589],\n    [1.0009137392],\n    [0.9994600415],\n    [1.0010378361],\n    [1.0008393526],\n    [1.0013997555],\n    [0.9994245768],\n    [0.9995403886],\n    [0.9997746348],\n    [0.9997846484],\n    [1.0012620687],\n    [1.0009645224],\n    [0.9995513558],\n    [1.0008162260],\n    [1.0008013248],\n    [0.9990139604],\n    [1.0004394054],\n    [0.9991726875],\n    [1.0009342432],\n    [1.0008635521],\n    [1.0007735491],\n    [1.0013785362],\n    [0.9997245073],\n    [0.9989474416],\n    [0.9996470809],\n    [1.0008428097],\n    [1.0017400980],\n    [0.9994468689],\n    [0.9999369979],\n    [1.0007227659],\n    [1.0012919903],\n    [0.9981160164],\n    [0.9999316335],\n    [0.9997596741],\n    [1.0008264780],\n    [0.9994930029],\n    [1.0001339912],\n    [0.9998437166],\n    [0.9999112487],\n    [1.0001872778],\n    [1.0006663799],\n    [1.0007426739],\n    [1.0016776323],\n    [0.9996471405],\n    [0.9981047511],\n    [1.0007015467],\n    [1.0006203651],\n    [0.9987628460],\n    [0.9981441498],\n    [0.9981172085],\n    [0.9999507666],\n    [1.0002735853],\n    [1.0006685257],\n    [1.0001268387],\n    [1.0000184774],\n    [0.9998023510],\n    [1.0006322861]], device='cuda:0')\n</code></pre>\n\n<p>and </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>data_y = tensor([\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0]\n    ], device='cuda:0')\n</code></pre>\n\n<p>I read data_x and data_y from a file, so that's why I just pasted the values here. See the image below: 0 corresponds to blue and 1 to red.</p>\n\n<p>And this is the output:</p>\n\n<pre><code>Loss at epoch 0 =  tensor(0.6795, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)\nLoss at epoch 10 =  tensor(0.4872, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)\nLoss at epoch 20 =  tensor(0.4818, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)\nLoss at epoch 30 =  tensor(0.4834, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)\nLoss at epoch 40 =  tensor(0.4828, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)\n</code></pre>\n\n<p>I tried reducing and increasing the learning rate, trying SGD and RMSprop increasing the number of epochs, but the loss always stops at 0.48. This is part of the output of <code>model(data_x)</code>:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>tensor([[[-0.3617, -1.1924]],\n\n        [[-0.3046, -1.3373]],\n\n        [[-0.2696, -1.4424]],\n\n        [[-0.2477, -1.5169]],\n\n        [[-0.2345, -1.5654]],\n\n        [[-0.2262, -1.5971]],\n</code></pre>\n\n<p>And all the other values are similar to this. I expected at least that the LSTM will overfit my model, or at least predict 0 for everything (given that I have just few ones, the loss would still be pretty small). But instead it just predicts these numbers and I am not sure why it stops there. I tried any debugging method I know (which are not very many given my AI experience). How can I fix this?</p>\n\n<p><a href=\"https://i.stack.imgur.com/yncjc.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/yncjc.png\" alt=\"enter image description here\"></a></p>\n <lstm><pytorch><convergence>",
                "codes": [],
                "question_id:": "48569",
                "question_votes:": "2",
                "question_text:": "<p>I am sorry if this questions is basic but I am quite new to NN in general. I am trying to build an LSTM to predict certain properties of a light curve (the output is 0 or 1). I build it in pytorch. Here is my code:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torch.optim as optim\nimport numpy as np\n\ntorch.manual_seed(1)\ntorch.cuda.set_device(0)\n\nfrom fastai.learner import *\n\nn_hidden = 64\nn_classes = 2\nbs = 1\n\nclass TESS_LSTM(nn.Module):\n    def __init__(self, nl):\n        super().__init__()\n        self.nl = nl\n        self.rnn = nn.LSTM(1, n_hidden, nl, dropout=0.01, bidirectional=True)\n        self.l_out = nn.Linear(n_hidden*2, n_classes)\n        self.init_hidden(bs)\n\n    def forward(self, input):\n        outp,h = self.rnn(input.view(len(input), bs, -1), self.h)\n        #self.h = repackage_var(h)\n        return F.log_softmax(self.l_out(outp),dim=2)\n\n    def init_hidden(self, bs):\n        self.h = (V(torch.zeros(self.nl*2, bs, n_hidden)),\n                  V(torch.zeros(self.nl*2, bs, n_hidden)))\n\nmodel = TESS_LSTM(2).cuda()\nloss_function = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nfor epoch in range(50):\n    model.zero_grad()\n    tag_scores = model(data_x)\n    loss = loss_function(tag_scores.reshape(len(data_x),n_classes), data_y.reshape(len(data_y)))\n    loss.backward()\n    optimizer.step()\n\n    if epoch%10==0:\n        print(\"Loss at epoch %d = \" %epoch, loss)\n</code></pre>\n\n<p>Also:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>\ndata_x = tensor([\n    [0.9995450377],\n    [0.9991207719],\n    [0.9986526966],\n    [1.0017241240],\n    [1.0016067028],\n    [1.0000480413],\n    [1.0016841888],\n    [1.0010652542],\n    [0.9991232157],\n    [1.0004128218],\n    [0.9986800551],\n    [1.0011130571],\n    [1.0001415014],\n    [1.0004080534],\n    [1.0016922951],\n    [1.0008358955],\n    [1.0001622438],\n    [1.0004277229],\n    [1.0011759996],\n    [1.0013391972],\n    [0.9995799065],\n    [1.0019282103],\n    [1.0006642342],\n    [1.0006272793],\n    [1.0011570454],\n    [1.0015332699],\n    [1.0011225939],\n    [1.0003337860],\n    [1.0014277697],\n    [1.0003565550],\n    [0.9989787340],\n    [1.0006136894],\n    [1.0003052950],\n    [1.0001049042],\n    [1.0020918846],\n    [0.9999115467],\n    [1.0006635189],\n    [1.0007561445],\n    [1.0016170740],\n    [1.0008252859],\n    [0.9997656345],\n    [1.0001330376],\n    [1.0017272234],\n    [1.0004107952],\n    [1.0012439489],\n    [0.9994274378],\n    [1.0014992952],\n    [1.0015807152],\n    [1.0004781485],\n    [1.0010997057],\n    [1.0011326075],\n    [1.0005493164],\n    [1.0014353991],\n    [0.9990324974],\n    [1.0012129545],\n    [0.9990709424],\n    [1.0006347895],\n    [1.0000327826],\n    [1.0005196333],\n    [1.0012207031],\n    [1.0003460646],\n    [1.0004434586],\n    [1.0003618002],\n    [1.0005420446],\n    [1.0005528927],\n    [1.0006977320],\n    [1.0005317926],\n    [1.0000808239],\n    [1.0005664825],\n    [0.9994245768],\n    [0.9999254942],\n    [1.0011985302],\n    [1.0009841919],\n    [0.9999029040],\n    [1.0014100075],\n    [1.0014085770],\n    [1.0005567074],\n    [1.0016088486],\n    [0.9997186661],\n    [0.9998687506],\n    [0.9988344908],\n    [0.9999858141],\n    [1.0004914999],\n    [1.0003308058],\n    [1.0001890659],\n    [1.0002681017],\n    [1.0029908419],\n    [1.0005286932],\n    [1.0004363060],\n    [0.9994311333],\n    [1.0011523962],\n    [1.0008679628],\n    [1.0014137030],\n    [0.9994244576],\n    [1.0003470182],\n    [1.0001592636],\n    [1.0002418756],\n    [0.9992931485],\n    [1.0016175508],\n    [1.0000959635],\n    [1.0005099773],\n    [1.0008889437],\n    [0.9998087287],\n    [0.9995828867],\n    [0.9997566342],\n    [1.0002474785],\n    [1.0010808706],\n    [1.0002821684],\n    [1.0013456345],\n    [1.0013040304],\n    [1.0010949373],\n    [1.0002720356],\n    [0.9996811152],\n    [1.0006061792],\n    [1.0012511015],\n    [0.9999302626],\n    [0.9985374212],\n    [1.0002642870],\n    [0.9996038675],\n    [1.0007606745],\n    [0.9992995858],\n    [1.0000385046],\n    [0.9997834563],\n    [1.0005996227],\n    [1.0006167889],\n    [1.0015753508],\n    [1.0010306835],\n    [0.9997833371],\n    [1.0010590553],\n    [1.0008200407],\n    [1.0008001328],\n    [1.0014072657],\n    [0.9994395375],\n    [0.9991182089],\n    [1.0011717081],\n    [1.0007920265],\n    [1.0011025667],\n    [1.0004047155],\n    [1.0017303228],\n    [1.0014981031],\n    [0.9995774031],\n    [0.9999650121],\n    [0.9992966652],\n    [1.0013586283],\n    [1.0003392696],\n    [1.0005040169],\n    [1.0008341074],\n    [1.0014744997],\n    [0.9996585250],\n    [1.0019916296],\n    [1.0007069111],\n    [1.0004591942],\n    [1.0004271269],\n    [0.9991059303],\n    [1.0003436804],\n    [0.9990482330],\n    [0.9980322123],\n    [0.9980198145],\n    [0.9966595173],\n    [0.9969686270],\n    [0.9977232814],\n    [0.9969192147],\n    [0.9962794185],\n    [0.9947851300],\n    [0.9946336746],\n    [0.9943053722],\n    [0.9946651459],\n    [0.9930071235],\n    [0.9940539598],\n    [0.9950682521],\n    [0.9947031140],\n    [0.9950703979],\n    [0.9945428371],\n    [0.9945927858],\n    [0.9937841296],\n    [0.9944553375],\n    [0.9929991364],\n    [0.9940859079],\n    [0.9930059314],\n    [0.9942978621],\n    [0.9950152636],\n    [0.9943225384],\n    [0.9934711456],\n    [0.9929080606],\n    [0.9934846163],\n    [0.9954113960],\n    [0.9925802350],\n    [0.9929560423],\n    [0.9933584929],\n    [0.9929228425],\n    [0.9930893779],\n    [0.9936142564],\n    [0.9943635464],\n    [0.9933300614],\n    [0.9925817847],\n    [0.9927681088],\n    [0.9930697680],\n    [0.9937900901],\n    [0.9919354320],\n    [0.9937084913],\n    [0.9951301217],\n    [0.9926426411],\n    [0.9933566451],\n    [0.9937180877],\n    [0.9922621250],\n    [0.9933888316],\n    [0.9936477542],\n    [0.9916112423],\n    [0.9943441153],\n    [0.9934164286],\n    [0.9949553013],\n    [0.9941871166],\n    [0.9933763146],\n    [0.9959306121],\n    [0.9930690527],\n    [0.9928541183],\n    [0.9936354756],\n    [0.9931223392],\n    [0.9936516881],\n    [0.9935654402],\n    [0.9932218790],\n    [0.9943401814],\n    [0.9931038022],\n    [0.9926875830],\n    [0.9928631186],\n    [0.9936705232],\n    [0.9939361215],\n    [0.9942125678],\n    [0.9939611554],\n    [0.9936586618],\n    [0.9933990240],\n    [0.9948219061],\n    [0.9940339923],\n    [0.9950091243],\n    [0.9952197671],\n    [0.9947227240],\n    [0.9935435653],\n    [0.9956403971],\n    [0.9943848252],\n    [0.9942221045],\n    [0.9960014224],\n    [0.9931004643],\n    [0.9960579872],\n    [0.9951166511],\n    [0.9964768291],\n    [0.9968702793],\n    [0.9967978597],\n    [0.9971982837],\n    [0.9977793097],\n    [0.9982623458],\n    [0.9988413453],\n    [1.0008778572],\n    [1.0013417006],\n    [1.0000336170],\n    [0.9979853630],\n    [0.9988892674],\n    [0.9994396567],\n    [1.0002176762],\n    [1.0017417669],\n    [1.0013097525],\n    [1.0011264086],\n    [1.0004124641],\n    [1.0003939867],\n    [0.9996479750],\n    [0.9995540380],\n    [1.0003930330],\n    [1.0016323328],\n    [1.0004589558],\n    [0.9996963739],\n    [0.9989817142],\n    [0.9998068213],\n    [1.0011200905],\n    [1.0006275177],\n    [1.0000452995],\n    [1.0012514591],\n    [1.0002357960],\n    [0.9993159175],\n    [1.0002738237],\n    [0.9994575381],\n    [0.9986617565],\n    [0.9982920289],\n    [0.9998571873],\n    [0.9996472597],\n    [1.0012613535],\n    [1.0015693903],\n    [0.9999635220],\n    [1.0006184578],\n    [1.0010757446],\n    [0.9988756776],\n    [1.0004955530],\n    [1.0011548996],\n    [1.0007628202],\n    [1.0006260872],\n    [0.9989725947],\n    [1.0013129711],\n    [0.9994829297],\n    [0.9998571873],\n    [0.9994959831],\n    [1.0007432699],\n    [0.9995724559],\n    [0.9999076724],\n    [0.9992097020],\n    [1.0011855364],\n    [0.9987785220],\n    [1.0010210276],\n    [0.9998293519],\n    [0.9996315837],\n    [0.9999501705],\n    [1.0001417398],\n    [1.0005141497],\n    [0.9993781447],\n    [1.0003532171],\n    [0.9999422431],\n    [1.0014258623],\n    [1.0012118816],\n    [0.9994109273],\n    [1.0019438267],\n    [1.0012354851],\n    [1.0009905100],\n    [1.0001032352],\n    [0.9999653101],\n    [0.9991906881],\n    [1.0004152060],\n    [0.9998226762],\n    [0.9999175668],\n    [0.9994540215],\n    [1.0000722408],\n    [1.0019129515],\n    [0.9997307658],\n    [0.9996227026],\n    [1.0011816025],\n    [0.9993667006],\n    [1.0010036230],\n    [0.9993645549],\n    [1.0004647970],\n    [0.9995272160],\n    [0.9989504814],\n    [0.9981039166],\n    [1.0006005764],\n    [0.9998896718],\n    [1.0004893541],\n    [0.9991874099],\n    [1.0005015135],\n    [0.9995905161],\n    [0.9990965128],\n    [1.0012912750],\n    [1.0004948378],\n    [1.0002779961],\n    [0.9988743067],\n    [1.0019037724],\n    [1.0006437302],\n    [0.9999380112],\n    [1.0001602173],\n    [0.9997741580],\n    [0.9988395572],\n    [0.9999371171],\n    [0.9989091754],\n    [0.9987531900],\n    [1.0003957748],\n    [0.9997722507],\n    [0.9988819361],\n    [0.9998422265],\n    [0.9986129999],\n    [0.9989410639],\n    [1.0016149282],\n    [0.9997441173],\n    [1.0002747774],\n    [0.9990793467],\n    [1.0006495714],\n    [1.0004252195],\n    [0.9997921586],\n    [0.9987344146],\n    [0.9998763800],\n    [0.9988097548],\n    [1.0007627010],\n    [1.0004670620],\n    [1.0007309914],\n    [0.9987894297],\n    [1.0000542402],\n    [1.0004990101],\n    [0.9999514818],\n    [0.9998412132],\n    [1.0000183582],\n    [1.0003197193],\n    [0.9991712570],\n    [0.9992188215],\n    [0.9986482859],\n    [1.0010583401],\n    [1.0011837482],\n    [0.9993829727],\n    [0.9995718002],\n    [0.9997168183],\n    [1.0017461777],\n    [0.9998381138],\n    [0.9990652204],\n    [1.0001449585],\n    [0.9998424053],\n    [1.0011798143],\n    [1.0013160706],\n    [0.9995942712],\n    [1.0001651049],\n    [1.0001466274],\n    [0.9982855320],\n    [0.9992064238],\n    [1.0009102821],\n    [0.9982813597],\n    [1.0000503063],\n    [0.9982630014],\n    [1.0017516613],\n    [0.9995808005],\n    [0.9989835620],\n    [1.0003046989],\n    [1.0019340515],\n    [0.9996930957],\n    [1.0000711679],\n    [1.0011881590],\n    [1.0009138584],\n    [1.0013902187],\n    [0.9994105101],\n    [0.9986224174],\n    [0.9995336533],\n    [1.0006912947],\n    [0.9995169044],\n    [0.9998968840],\n    [0.9989182949],\n    [0.9999300838],\n    [0.9991120696],\n    [0.9996063709],\n    [1.0008803606],\n    [1.0019868612],\n    [1.0004760027],\n    [0.9996407032],\n    [1.0011100769],\n    [1.0026890039],\n    [0.9996611476],\n    [0.9991108775],\n    [0.9982090592],\n    [1.0000833273],\n    [1.0015701056],\n    [0.9994426966],\n    [0.9999341369],\n    [1.0002813339],\n    [0.9998958707],\n    [1.0011670589],\n    [1.0009137392],\n    [0.9994600415],\n    [1.0010378361],\n    [1.0008393526],\n    [1.0013997555],\n    [0.9994245768],\n    [0.9995403886],\n    [0.9997746348],\n    [0.9997846484],\n    [1.0012620687],\n    [1.0009645224],\n    [0.9995513558],\n    [1.0008162260],\n    [1.0008013248],\n    [0.9990139604],\n    [1.0004394054],\n    [0.9991726875],\n    [1.0009342432],\n    [1.0008635521],\n    [1.0007735491],\n    [1.0013785362],\n    [0.9997245073],\n    [0.9989474416],\n    [0.9996470809],\n    [1.0008428097],\n    [1.0017400980],\n    [0.9994468689],\n    [0.9999369979],\n    [1.0007227659],\n    [1.0012919903],\n    [0.9981160164],\n    [0.9999316335],\n    [0.9997596741],\n    [1.0008264780],\n    [0.9994930029],\n    [1.0001339912],\n    [0.9998437166],\n    [0.9999112487],\n    [1.0001872778],\n    [1.0006663799],\n    [1.0007426739],\n    [1.0016776323],\n    [0.9996471405],\n    [0.9981047511],\n    [1.0007015467],\n    [1.0006203651],\n    [0.9987628460],\n    [0.9981441498],\n    [0.9981172085],\n    [0.9999507666],\n    [1.0002735853],\n    [1.0006685257],\n    [1.0001268387],\n    [1.0000184774],\n    [0.9998023510],\n    [1.0006322861]], device='cuda:0')\n</code></pre>\n\n<p>and </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>data_y = tensor([\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0]\n    ], device='cuda:0')\n</code></pre>\n\n<p>I read data_x and data_y from a file, so that's why I just pasted the values here. See the image below: 0 corresponds to blue and 1 to red.</p>\n\n<p>And this is the output:</p>\n\n<pre><code>Loss at epoch 0 =  tensor(0.6795, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)\nLoss at epoch 10 =  tensor(0.4872, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)\nLoss at epoch 20 =  tensor(0.4818, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)\nLoss at epoch 30 =  tensor(0.4834, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)\nLoss at epoch 40 =  tensor(0.4828, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)\n</code></pre>\n\n<p>I tried reducing and increasing the learning rate, trying SGD and RMSprop increasing the number of epochs, but the loss always stops at 0.48. This is part of the output of <code>model(data_x)</code>:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>tensor([[[-0.3617, -1.1924]],\n\n        [[-0.3046, -1.3373]],\n\n        [[-0.2696, -1.4424]],\n\n        [[-0.2477, -1.5169]],\n\n        [[-0.2345, -1.5654]],\n\n        [[-0.2262, -1.5971]],\n</code></pre>\n\n<p>And all the other values are similar to this. I expected at least that the LSTM will overfit my model, or at least predict 0 for everything (given that I have just few ones, the loss would still be pretty small). But instead it just predicts these numbers and I am not sure why it stops there. I tried any debugging method I know (which are not very many given my AI experience). How can I fix this?</p>\n\n<p><a href=\"https://i.stack.imgur.com/yncjc.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/yncjc.png\" alt=\"enter image description here\"></a></p>\n",
                "tags": "<lstm><pytorch><convergence>",
                "answers": []
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "13438",
            "_score": 2.8256884,
            "_source": {
                "title": "How to label and detect the document text images",
                "content": "How to label and detect the document text images <p>This is what I mean as document text image:\n<a href=\"https://i.stack.imgur.com/zuEMc.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zuEMc.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>I want to label the texts in image as separate blocks and my model should detect these labels as classes. </p>\n\n<p><strong>NOTE:</strong></p>\n\n<p>This is how the end result should be like:<a href=\"https://i.stack.imgur.com/PxjXw.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PxjXw.png\" alt=\"enter image description here\"></a></p>\n\n<p>The labels like Block 1, Block 2, Block 3,.. should be Logo, Title, Date,.. Others, etc.</p>\n\n<p><strong>Work done:</strong></p>\n\n<p>First approach : I tried to implement this method via Object Detection, it didn't work. It didn't even detect any text.</p>\n\n<p>Second approach : Then I tried it using <a href=\"https://github.com/ZJULearning/pixel_link\" rel=\"nofollow noreferrer\">PixelLink</a>. As this model is build for scene text detection, it detected each and every text in the image. But this method can detect multiple lines of text if the threshold values are increased. \nBut I have no idea how do I add labels to the text blocks.</p>\n\n<pre><code>PIXEL_CLS_WEIGHT_all_ones = 'PIXEL_CLS_WEIGHT_all_ones' \nPIXEL_CLS_WEIGHT_bbox_balanced = 'PIXEL_CLS_WEIGHT_bbox_balanced'\nPIXEL_NEIGHBOUR_TYPE_4 = 'PIXEL_NEIGHBOUR_TYPE_4'\nPIXEL_NEIGHBOUR_TYPE_8 = 'PIXEL_NEIGHBOUR_TYPE_8'\n\nDECODE_METHOD_join = 'DECODE_METHOD_join'\n\n\ndef get_neighbours_8(x, y):\n    \"\"\"\n    Get 8 neighbours of point(x, y)\n    \"\"\"\n    return [(x - 1, y - 1), (x, y - 1), (x + 1, y - 1), \\\n        (x - 1, y),                 (x + 1, y),  \\\n        (x - 1, y + 1), (x, y + 1), (x + 1, y + 1)]\n\n\ndef get_neighbours_4(x, y):\n    return [(x - 1, y), (x + 1, y), (x, y + 1), (x, y - 1)]\n\n\ndef get_neighbours(x, y):\n    import config\n    neighbour_type = config.pixel_neighbour_type\n    if neighbour_type == PIXEL_NEIGHBOUR_TYPE_4:\n        return get_neighbours_4(x, y)\n    else:\n        return get_neighbours_8(x, y)\n\ndef get_neighbours_fn():\n    import config\n    neighbour_type = config.pixel_neighbour_type\n    if neighbour_type == PIXEL_NEIGHBOUR_TYPE_4:\n        return get_neighbours_4, 4\n    else:\n        return get_neighbours_8, 8\n\n\n\ndef is_valid_cord(x, y, w, h):\n    \"\"\"\n    Tell whether the 2D coordinate (x, y) is valid or not.\n    If valid, it should be on an h x w image\n    \"\"\"\n    return x &gt;=0 and x &lt; w and y &gt;= 0 and y &lt; h;\n\n#=====================Ground Truth Calculation Begin==================\ndef tf_cal_gt_for_single_image(xs, ys, labels):\n    pixel_cls_label, pixel_cls_weight,  \\\n    pixel_link_label, pixel_link_weight = \\\n        tf.py_func(\n                    cal_gt_for_single_image, \n                    [xs, ys, labels],\n                    [tf.int32, tf.float32, tf.int32, tf.float32]\n                   )\n    import config\n    score_map_shape = config.score_map_shape\n    num_neighbours = config.num_neighbours\n    h, w = score_map_shape\n    pixel_cls_label.set_shape(score_map_shape)\n    pixel_cls_weight.set_shape(score_map_shape)\n    pixel_link_label.set_shape([h, w, num_neighbours])\n    pixel_link_weight.set_shape([h, w, num_neighbours])\n    return pixel_cls_label, pixel_cls_weight, \\\n            pixel_link_label, pixel_link_weight\n\n\ndef cal_gt_for_single_image(normed_xs, normed_ys, labels):\n    \"\"\"\n    Args:\n        xs, ys: both in shape of (N, 4), \n            and N is the number of bboxes,\n            their values are normalized to [0,1]\n        labels: shape = (N,), only two values are allowed:\n                                                        -1: ignored\n                                                        1: text\n    Return:\n        pixel_cls_label\n        pixel_cls_weight\n        pixel_link_label\n        pixel_link_weight\n    \"\"\"\n    import config\n    score_map_shape = config.score_map_shape\n    pixel_cls_weight_method  = config.pixel_cls_weight_method\n    h, w = score_map_shape\n    text_label = config.text_label\n    ignore_label = config.ignore_label\n    background_label = config.background_label\n    num_neighbours = config.num_neighbours\n    bbox_border_width = config.bbox_border_width\n    pixel_cls_border_weight_lambda = config.pixel_cls_border_weight_lambda\n\n    # validate the args\n    assert np.ndim(normed_xs) == 2\n    assert np.shape(normed_xs)[-1] == 4\n    assert np.shape(normed_xs) == np.shape(normed_ys)\n    assert len(normed_xs) == len(labels)\n\n#     assert set(labels).issubset(set([text_label, ignore_label, background_label]))\n\n    num_positive_bboxes = np.sum(np.asarray(labels) == text_label)\n    # rescale normalized xys to absolute values\n    xs = normed_xs * w\n    ys = normed_ys * h\n\n    # initialize ground truth values\n    mask = np.zeros(score_map_shape, dtype = np.int32)\n    pixel_cls_label = np.ones(score_map_shape, dtype = np.int32) * background_label\n    pixel_cls_weight = np.zeros(score_map_shape, dtype = np.float32)\n\n    pixel_link_label = np.zeros((h, w, num_neighbours), dtype = np.int32)\n    pixel_link_weight = np.ones((h, w, num_neighbours), dtype = np.float32)\n\n    # find overlapped pixels, and consider them as ignored in pixel_cls_weight\n    # and pixels in ignored bboxes are ignored as well\n    # That is to say, only the weights of not ignored pixels are set to 1\n\n    ## get the masks of all bboxes\n    bbox_masks = []\n    pos_mask = mask.copy()\n    for bbox_idx, (bbox_xs, bbox_ys) in enumerate(zip(xs, ys)):\n        if labels[bbox_idx] == background_label:\n            continue\n\n        bbox_mask = mask.copy()\n\n        bbox_points = zip(bbox_xs, bbox_ys)\n        bbox_contours = util.img.points_to_contours(bbox_points)\n        util.img.draw_contours(bbox_mask, bbox_contours, idx = -1, \n                               color = 1, border_width = -1)\n\n        bbox_masks.append(bbox_mask)\n\n        if labels[bbox_idx] == text_label:\n            pos_mask += bbox_mask\n\n    # treat overlapped in-bbox pixels as negative, \n    # and non-overlapped  ones as positive\n    pos_mask = np.asarray(pos_mask == 1, dtype = np.int32)\n    num_positive_pixels = np.sum(pos_mask)\n\n    ## add all bbox_maskes, find non-overlapping pixels\n    sum_mask = np.sum(bbox_masks, axis = 0)\n    not_overlapped_mask = sum_mask == 1\n\n\n    ## gt and weight calculation\n    for bbox_idx, bbox_mask in enumerate(bbox_masks):\n        bbox_label = labels[bbox_idx]\n        if bbox_label == ignore_label:\n            # for ignored bboxes, only non-overlapped pixels are encoded as ignored \n            bbox_ignore_pixel_mask = bbox_mask * not_overlapped_mask\n            pixel_cls_label += bbox_ignore_pixel_mask * ignore_label\n            continue\n\n        if labels[bbox_idx] == background_label:\n            continue\n        # from here on, only text boxes left.\n\n        # for positive bboxes, all pixels within it and pos_mask are positive\n        bbox_positive_pixel_mask = bbox_mask * pos_mask\n        # background or text is encoded into cls gt\n        pixel_cls_label += bbox_positive_pixel_mask * bbox_label\n\n        # for the pixel cls weights, only positive pixels are set to ones\n        if pixel_cls_weight_method == PIXEL_CLS_WEIGHT_all_ones:\n            pixel_cls_weight += bbox_positive_pixel_mask\n        elif pixel_cls_weight_method == PIXEL_CLS_WEIGHT_bbox_balanced:\n            # let N denote num_positive_pixels\n            # weight per pixel = N /num_positive_bboxes / n_pixels_in_bbox\n            # so all pixel weights in this bbox sum to N/num_positive_bboxes\n            # and all pixels weights in this image sum to N, the same\n            # as setting all weights to 1\n            num_bbox_pixels = np.sum(bbox_positive_pixel_mask)\n            if num_bbox_pixels &gt; 0: \n                per_bbox_weight = num_positive_pixels * 1.0 / num_positive_bboxes\n                per_pixel_weight = per_bbox_weight / num_bbox_pixels\n                pixel_cls_weight += bbox_positive_pixel_mask * per_pixel_weight\n        else:\n            raise ValueError, 'pixel_cls_weight_method not supported:%s'\\\n                        %(pixel_cls_weight_method)\n\n\n        ## calculate the labels and weights of links\n        ### for all pixels in  bboxes, all links are positive at first\n        bbox_point_cords = np.where(bbox_positive_pixel_mask)\n        pixel_link_label[bbox_point_cords] = 1\n\n\n        ## the border of bboxes might be distored because of overlapping\n        ## so recalculate it, and find the border mask        \n        new_bbox_contours = util.img.find_contours(bbox_positive_pixel_mask)\n        bbox_border_mask = mask.copy()\n        util.img.draw_contours(bbox_border_mask, new_bbox_contours, -1, \n                   color = 1, border_width = bbox_border_width * 2 + 1)\n        bbox_border_mask *= bbox_positive_pixel_mask\n        bbox_border_cords = np.where(bbox_border_mask)\n\n        ## give more weight to the border pixels if configured\n        pixel_cls_weight[bbox_border_cords] *= pixel_cls_border_weight_lambda\n\n        ### change link labels according to their neighbour status\n        border_points = zip(*bbox_border_cords)\n        def in_bbox(nx, ny):\n            return bbox_positive_pixel_mask[ny, nx]\n\n        for y, x in border_points:\n            neighbours = get_neighbours(x, y)\n            for n_idx, (nx, ny) in enumerate(neighbours):\n                if not is_valid_cord(nx, ny, w, h) or not in_bbox(nx, ny):\n                    pixel_link_label[y, x, n_idx] = 0\n\n    pixel_cls_weight = np.asarray(pixel_cls_weight, dtype = np.float32)    \n    pixel_link_weight *= np.expand_dims(pixel_cls_weight, axis = -1)\n\n#     try:\n#         np.testing.assert_almost_equal(np.sum(pixel_cls_weight), num_positive_pixels, decimal = 1)\n#     except:\n#         print  num_positive_pixels, np.sum(pixel_cls_label), np.sum(pixel_cls_weight)\n#         import pdb\n#         pdb.set_trace()\n    return pixel_cls_label, pixel_cls_weight, pixel_link_label, pixel_link_weight\n\n#=====================Ground Truth Calculation End====================\n\n\n#============================Decode Begin=============================\n\ndef tf_decode_score_map_to_mask_in_batch(pixel_cls_scores, pixel_link_scores):\n    masks = tf.py_func(decode_batch, \n                       [pixel_cls_scores, pixel_link_scores], tf.int32)\n    b, h, w = pixel_cls_scores.shape.as_list()\n    masks.set_shape([b, h, w])\n    return masks\n\n\n\ndef decode_batch(pixel_cls_scores, pixel_link_scores, \n                 pixel_conf_threshold = None, link_conf_threshold = None):\n    import config\n\n    if pixel_conf_threshold is None:\n        pixel_conf_threshold = config.pixel_conf_threshold\n\n    if link_conf_threshold is None:\n        link_conf_threshold = config.link_conf_threshold\n\n    batch_size = pixel_cls_scores.shape[0]\n    batch_mask = []\n    for image_idx in xrange(batch_size):\n        image_pos_pixel_scores = pixel_cls_scores[image_idx, :, :]\n        image_pos_link_scores = pixel_link_scores[image_idx, :, :, :]    \n        mask = decode_image(\n            image_pos_pixel_scores, image_pos_link_scores, \n            pixel_conf_threshold, link_conf_threshold\n        )\n        batch_mask.append(mask)\n    return np.asarray(batch_mask, np.int32)\n\n# @util.dec.print_calling_in_short\n# @util.dec.timeit\ndef decode_image(pixel_scores, link_scores, \n                 pixel_conf_threshold, link_conf_threshold):\n    import config\n    if config.decode_method == DECODE_METHOD_join:\n        mask =  decode_image_by_join(pixel_scores, link_scores, \n                 pixel_conf_threshold, link_conf_threshold)\n        return mask\n    elif config.decode_method == DECODE_METHOD_border_split:\n        return decode_image_by_border(pixel_scores, link_scores, \n                 pixel_conf_threshold, link_conf_threshold)\n    else:\n        raise ValueError('Unknow decode method:%s'%(config.decode_method))\n\n\nimport pyximport; pyximport.install()    \nfrom pixel_link_decode import decode_image_by_join\n\ndef min_area_rect(cnt):\n    \"\"\"\n    Args:\n        xs: numpy ndarray with shape=(N,4). N is the number of oriented bboxes. 4 contains [x1, x2, x3, x4]\n        ys: numpy ndarray with shape=(N,4), [y1, y2, y3, y4]\n            Note that [(x1, y1), (x2, y2), (x3, y3), (x4, y4)] can represent an oriented bbox.\n    Return:\n        the oriented rects sorrounding the box, in the format:[cx, cy, w, h, theta]. \n    \"\"\"\n    rect = cv2.minAreaRect(cnt)\n    cx, cy = rect[0]\n    w, h = rect[1]\n    theta = rect[2]\n    box = [cx, cy, w, h, theta]\n    return box, w * h\n\ndef rect_to_xys(rect, image_shape):\n    \"\"\"Convert rect to xys, i.e., eight points\n    The `image_shape` is used to to make sure all points return are valid, i.e., within image area\n    \"\"\"\n    h, w = image_shape[0:2]\n    def get_valid_x(x):\n        if x &lt; 0:\n            return 0\n        if x &gt;= w:\n            return w - 1\n        return x\n\n    def get_valid_y(y):\n        if y &lt; 0:\n            return 0\n        if y &gt;= h:\n            return h - 1\n        return y\n\n    rect = ((rect[0], rect[1]), (rect[2], rect[3]), rect[4])\n    points = cv2.cv.BoxPoints(rect)\n    points = np.int0(points)\n    for i_xy, (x, y) in enumerate(points):\n        x = get_valid_x(x)\n        y = get_valid_y(y)\n        points[i_xy, :] = [x, y]\n    points = np.reshape(points, -1)\n    return points\n\n# @util.dec.print_calling_in_short\n# @util.dec.timeit\ndef mask_to_bboxes(mask, image_shape =  None, min_area = None, \n                   min_height = None, min_aspect_ratio = None):\n    import config\n    feed_shape = config.train_image_shape\n\n    if image_shape is None:\n        image_shape = feed_shape\n\n    image_h, image_w = image_shape[0:2]\n\n    if min_area is None:\n        min_area = config.min_area\n\n    if min_height is None:\n        min_height = config.min_height\n    bboxes = []\n    max_bbox_idx = mask.max()\n    mask = util.img.resize(img = mask, size = (image_w, image_h), \n                           interpolation = cv2.INTER_NEAREST)\n\n    for bbox_idx in xrange(1, max_bbox_idx + 1):\n        bbox_mask = mask == bbox_idx\n#         if bbox_mask.sum() &lt; 10:\n#             continue\n        cnts = util.img.find_contours(bbox_mask)\n        if len(cnts) == 0:\n            continue\n        cnt = cnts[0]\n        rect, rect_area = min_area_rect(cnt)\n\n        w, h = rect[2:-1]\n        if min(w, h) &lt; min_height:\n            continue\n\n        if rect_area &lt; min_area:\n            continue\n\n#         if max(w, h) * 1.0 / min(w, h) &lt; 2:\n#             continue\n        xys = rect_to_xys(rect, image_shape)\n        bboxes.append(xys)\n\n    return bboxes\n</code></pre>\n\n<p>Any suggestions?</p>\n\n<p>Is there any approach that is more suitable for the problem I'm trying to solve? </p>\n <neural-network><convolution><p>If you want something like that, you can try to test it with already existing &amp; online app like the following :</p>\n\n<p><a href=\"https://jinapdf.com/image-to-text-file.php\" rel=\"nofollow noreferrer\">https://jinapdf.com/image-to-text-file.php</a></p>\n\n<p>If this is what you want, you can create one :</p>\n\n<p>1) First locate boundaries for text</p>\n\n<p>2) Convert it to text</p>\n\n<p>This is quite complicated bu you can still use what is called OCR (Optical Character Recognition) and therefore search for it in github and use open source projects as a starter like the following : </p>\n\n<p><a href=\"https://github.com/prabhakar267/ocr-convert-image-to-text\" rel=\"nofollow noreferrer\">https://github.com/prabhakar267/ocr-convert-image-to-text</a></p>\n",
                "codes": [
                    []
                ],
                "question_id:": "45942",
                "question_votes:": "1",
                "question_text:": "<p>This is what I mean as document text image:\n<a href=\"https://i.stack.imgur.com/zuEMc.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zuEMc.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>I want to label the texts in image as separate blocks and my model should detect these labels as classes. </p>\n\n<p><strong>NOTE:</strong></p>\n\n<p>This is how the end result should be like:<a href=\"https://i.stack.imgur.com/PxjXw.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PxjXw.png\" alt=\"enter image description here\"></a></p>\n\n<p>The labels like Block 1, Block 2, Block 3,.. should be Logo, Title, Date,.. Others, etc.</p>\n\n<p><strong>Work done:</strong></p>\n\n<p>First approach : I tried to implement this method via Object Detection, it didn't work. It didn't even detect any text.</p>\n\n<p>Second approach : Then I tried it using <a href=\"https://github.com/ZJULearning/pixel_link\" rel=\"nofollow noreferrer\">PixelLink</a>. As this model is build for scene text detection, it detected each and every text in the image. But this method can detect multiple lines of text if the threshold values are increased. \nBut I have no idea how do I add labels to the text blocks.</p>\n\n<pre><code>PIXEL_CLS_WEIGHT_all_ones = 'PIXEL_CLS_WEIGHT_all_ones' \nPIXEL_CLS_WEIGHT_bbox_balanced = 'PIXEL_CLS_WEIGHT_bbox_balanced'\nPIXEL_NEIGHBOUR_TYPE_4 = 'PIXEL_NEIGHBOUR_TYPE_4'\nPIXEL_NEIGHBOUR_TYPE_8 = 'PIXEL_NEIGHBOUR_TYPE_8'\n\nDECODE_METHOD_join = 'DECODE_METHOD_join'\n\n\ndef get_neighbours_8(x, y):\n    \"\"\"\n    Get 8 neighbours of point(x, y)\n    \"\"\"\n    return [(x - 1, y - 1), (x, y - 1), (x + 1, y - 1), \\\n        (x - 1, y),                 (x + 1, y),  \\\n        (x - 1, y + 1), (x, y + 1), (x + 1, y + 1)]\n\n\ndef get_neighbours_4(x, y):\n    return [(x - 1, y), (x + 1, y), (x, y + 1), (x, y - 1)]\n\n\ndef get_neighbours(x, y):\n    import config\n    neighbour_type = config.pixel_neighbour_type\n    if neighbour_type == PIXEL_NEIGHBOUR_TYPE_4:\n        return get_neighbours_4(x, y)\n    else:\n        return get_neighbours_8(x, y)\n\ndef get_neighbours_fn():\n    import config\n    neighbour_type = config.pixel_neighbour_type\n    if neighbour_type == PIXEL_NEIGHBOUR_TYPE_4:\n        return get_neighbours_4, 4\n    else:\n        return get_neighbours_8, 8\n\n\n\ndef is_valid_cord(x, y, w, h):\n    \"\"\"\n    Tell whether the 2D coordinate (x, y) is valid or not.\n    If valid, it should be on an h x w image\n    \"\"\"\n    return x &gt;=0 and x &lt; w and y &gt;= 0 and y &lt; h;\n\n#=====================Ground Truth Calculation Begin==================\ndef tf_cal_gt_for_single_image(xs, ys, labels):\n    pixel_cls_label, pixel_cls_weight,  \\\n    pixel_link_label, pixel_link_weight = \\\n        tf.py_func(\n                    cal_gt_for_single_image, \n                    [xs, ys, labels],\n                    [tf.int32, tf.float32, tf.int32, tf.float32]\n                   )\n    import config\n    score_map_shape = config.score_map_shape\n    num_neighbours = config.num_neighbours\n    h, w = score_map_shape\n    pixel_cls_label.set_shape(score_map_shape)\n    pixel_cls_weight.set_shape(score_map_shape)\n    pixel_link_label.set_shape([h, w, num_neighbours])\n    pixel_link_weight.set_shape([h, w, num_neighbours])\n    return pixel_cls_label, pixel_cls_weight, \\\n            pixel_link_label, pixel_link_weight\n\n\ndef cal_gt_for_single_image(normed_xs, normed_ys, labels):\n    \"\"\"\n    Args:\n        xs, ys: both in shape of (N, 4), \n            and N is the number of bboxes,\n            their values are normalized to [0,1]\n        labels: shape = (N,), only two values are allowed:\n                                                        -1: ignored\n                                                        1: text\n    Return:\n        pixel_cls_label\n        pixel_cls_weight\n        pixel_link_label\n        pixel_link_weight\n    \"\"\"\n    import config\n    score_map_shape = config.score_map_shape\n    pixel_cls_weight_method  = config.pixel_cls_weight_method\n    h, w = score_map_shape\n    text_label = config.text_label\n    ignore_label = config.ignore_label\n    background_label = config.background_label\n    num_neighbours = config.num_neighbours\n    bbox_border_width = config.bbox_border_width\n    pixel_cls_border_weight_lambda = config.pixel_cls_border_weight_lambda\n\n    # validate the args\n    assert np.ndim(normed_xs) == 2\n    assert np.shape(normed_xs)[-1] == 4\n    assert np.shape(normed_xs) == np.shape(normed_ys)\n    assert len(normed_xs) == len(labels)\n\n#     assert set(labels).issubset(set([text_label, ignore_label, background_label]))\n\n    num_positive_bboxes = np.sum(np.asarray(labels) == text_label)\n    # rescale normalized xys to absolute values\n    xs = normed_xs * w\n    ys = normed_ys * h\n\n    # initialize ground truth values\n    mask = np.zeros(score_map_shape, dtype = np.int32)\n    pixel_cls_label = np.ones(score_map_shape, dtype = np.int32) * background_label\n    pixel_cls_weight = np.zeros(score_map_shape, dtype = np.float32)\n\n    pixel_link_label = np.zeros((h, w, num_neighbours), dtype = np.int32)\n    pixel_link_weight = np.ones((h, w, num_neighbours), dtype = np.float32)\n\n    # find overlapped pixels, and consider them as ignored in pixel_cls_weight\n    # and pixels in ignored bboxes are ignored as well\n    # That is to say, only the weights of not ignored pixels are set to 1\n\n    ## get the masks of all bboxes\n    bbox_masks = []\n    pos_mask = mask.copy()\n    for bbox_idx, (bbox_xs, bbox_ys) in enumerate(zip(xs, ys)):\n        if labels[bbox_idx] == background_label:\n            continue\n\n        bbox_mask = mask.copy()\n\n        bbox_points = zip(bbox_xs, bbox_ys)\n        bbox_contours = util.img.points_to_contours(bbox_points)\n        util.img.draw_contours(bbox_mask, bbox_contours, idx = -1, \n                               color = 1, border_width = -1)\n\n        bbox_masks.append(bbox_mask)\n\n        if labels[bbox_idx] == text_label:\n            pos_mask += bbox_mask\n\n    # treat overlapped in-bbox pixels as negative, \n    # and non-overlapped  ones as positive\n    pos_mask = np.asarray(pos_mask == 1, dtype = np.int32)\n    num_positive_pixels = np.sum(pos_mask)\n\n    ## add all bbox_maskes, find non-overlapping pixels\n    sum_mask = np.sum(bbox_masks, axis = 0)\n    not_overlapped_mask = sum_mask == 1\n\n\n    ## gt and weight calculation\n    for bbox_idx, bbox_mask in enumerate(bbox_masks):\n        bbox_label = labels[bbox_idx]\n        if bbox_label == ignore_label:\n            # for ignored bboxes, only non-overlapped pixels are encoded as ignored \n            bbox_ignore_pixel_mask = bbox_mask * not_overlapped_mask\n            pixel_cls_label += bbox_ignore_pixel_mask * ignore_label\n            continue\n\n        if labels[bbox_idx] == background_label:\n            continue\n        # from here on, only text boxes left.\n\n        # for positive bboxes, all pixels within it and pos_mask are positive\n        bbox_positive_pixel_mask = bbox_mask * pos_mask\n        # background or text is encoded into cls gt\n        pixel_cls_label += bbox_positive_pixel_mask * bbox_label\n\n        # for the pixel cls weights, only positive pixels are set to ones\n        if pixel_cls_weight_method == PIXEL_CLS_WEIGHT_all_ones:\n            pixel_cls_weight += bbox_positive_pixel_mask\n        elif pixel_cls_weight_method == PIXEL_CLS_WEIGHT_bbox_balanced:\n            # let N denote num_positive_pixels\n            # weight per pixel = N /num_positive_bboxes / n_pixels_in_bbox\n            # so all pixel weights in this bbox sum to N/num_positive_bboxes\n            # and all pixels weights in this image sum to N, the same\n            # as setting all weights to 1\n            num_bbox_pixels = np.sum(bbox_positive_pixel_mask)\n            if num_bbox_pixels &gt; 0: \n                per_bbox_weight = num_positive_pixels * 1.0 / num_positive_bboxes\n                per_pixel_weight = per_bbox_weight / num_bbox_pixels\n                pixel_cls_weight += bbox_positive_pixel_mask * per_pixel_weight\n        else:\n            raise ValueError, 'pixel_cls_weight_method not supported:%s'\\\n                        %(pixel_cls_weight_method)\n\n\n        ## calculate the labels and weights of links\n        ### for all pixels in  bboxes, all links are positive at first\n        bbox_point_cords = np.where(bbox_positive_pixel_mask)\n        pixel_link_label[bbox_point_cords] = 1\n\n\n        ## the border of bboxes might be distored because of overlapping\n        ## so recalculate it, and find the border mask        \n        new_bbox_contours = util.img.find_contours(bbox_positive_pixel_mask)\n        bbox_border_mask = mask.copy()\n        util.img.draw_contours(bbox_border_mask, new_bbox_contours, -1, \n                   color = 1, border_width = bbox_border_width * 2 + 1)\n        bbox_border_mask *= bbox_positive_pixel_mask\n        bbox_border_cords = np.where(bbox_border_mask)\n\n        ## give more weight to the border pixels if configured\n        pixel_cls_weight[bbox_border_cords] *= pixel_cls_border_weight_lambda\n\n        ### change link labels according to their neighbour status\n        border_points = zip(*bbox_border_cords)\n        def in_bbox(nx, ny):\n            return bbox_positive_pixel_mask[ny, nx]\n\n        for y, x in border_points:\n            neighbours = get_neighbours(x, y)\n            for n_idx, (nx, ny) in enumerate(neighbours):\n                if not is_valid_cord(nx, ny, w, h) or not in_bbox(nx, ny):\n                    pixel_link_label[y, x, n_idx] = 0\n\n    pixel_cls_weight = np.asarray(pixel_cls_weight, dtype = np.float32)    \n    pixel_link_weight *= np.expand_dims(pixel_cls_weight, axis = -1)\n\n#     try:\n#         np.testing.assert_almost_equal(np.sum(pixel_cls_weight), num_positive_pixels, decimal = 1)\n#     except:\n#         print  num_positive_pixels, np.sum(pixel_cls_label), np.sum(pixel_cls_weight)\n#         import pdb\n#         pdb.set_trace()\n    return pixel_cls_label, pixel_cls_weight, pixel_link_label, pixel_link_weight\n\n#=====================Ground Truth Calculation End====================\n\n\n#============================Decode Begin=============================\n\ndef tf_decode_score_map_to_mask_in_batch(pixel_cls_scores, pixel_link_scores):\n    masks = tf.py_func(decode_batch, \n                       [pixel_cls_scores, pixel_link_scores], tf.int32)\n    b, h, w = pixel_cls_scores.shape.as_list()\n    masks.set_shape([b, h, w])\n    return masks\n\n\n\ndef decode_batch(pixel_cls_scores, pixel_link_scores, \n                 pixel_conf_threshold = None, link_conf_threshold = None):\n    import config\n\n    if pixel_conf_threshold is None:\n        pixel_conf_threshold = config.pixel_conf_threshold\n\n    if link_conf_threshold is None:\n        link_conf_threshold = config.link_conf_threshold\n\n    batch_size = pixel_cls_scores.shape[0]\n    batch_mask = []\n    for image_idx in xrange(batch_size):\n        image_pos_pixel_scores = pixel_cls_scores[image_idx, :, :]\n        image_pos_link_scores = pixel_link_scores[image_idx, :, :, :]    \n        mask = decode_image(\n            image_pos_pixel_scores, image_pos_link_scores, \n            pixel_conf_threshold, link_conf_threshold\n        )\n        batch_mask.append(mask)\n    return np.asarray(batch_mask, np.int32)\n\n# @util.dec.print_calling_in_short\n# @util.dec.timeit\ndef decode_image(pixel_scores, link_scores, \n                 pixel_conf_threshold, link_conf_threshold):\n    import config\n    if config.decode_method == DECODE_METHOD_join:\n        mask =  decode_image_by_join(pixel_scores, link_scores, \n                 pixel_conf_threshold, link_conf_threshold)\n        return mask\n    elif config.decode_method == DECODE_METHOD_border_split:\n        return decode_image_by_border(pixel_scores, link_scores, \n                 pixel_conf_threshold, link_conf_threshold)\n    else:\n        raise ValueError('Unknow decode method:%s'%(config.decode_method))\n\n\nimport pyximport; pyximport.install()    \nfrom pixel_link_decode import decode_image_by_join\n\ndef min_area_rect(cnt):\n    \"\"\"\n    Args:\n        xs: numpy ndarray with shape=(N,4). N is the number of oriented bboxes. 4 contains [x1, x2, x3, x4]\n        ys: numpy ndarray with shape=(N,4), [y1, y2, y3, y4]\n            Note that [(x1, y1), (x2, y2), (x3, y3), (x4, y4)] can represent an oriented bbox.\n    Return:\n        the oriented rects sorrounding the box, in the format:[cx, cy, w, h, theta]. \n    \"\"\"\n    rect = cv2.minAreaRect(cnt)\n    cx, cy = rect[0]\n    w, h = rect[1]\n    theta = rect[2]\n    box = [cx, cy, w, h, theta]\n    return box, w * h\n\ndef rect_to_xys(rect, image_shape):\n    \"\"\"Convert rect to xys, i.e., eight points\n    The `image_shape` is used to to make sure all points return are valid, i.e., within image area\n    \"\"\"\n    h, w = image_shape[0:2]\n    def get_valid_x(x):\n        if x &lt; 0:\n            return 0\n        if x &gt;= w:\n            return w - 1\n        return x\n\n    def get_valid_y(y):\n        if y &lt; 0:\n            return 0\n        if y &gt;= h:\n            return h - 1\n        return y\n\n    rect = ((rect[0], rect[1]), (rect[2], rect[3]), rect[4])\n    points = cv2.cv.BoxPoints(rect)\n    points = np.int0(points)\n    for i_xy, (x, y) in enumerate(points):\n        x = get_valid_x(x)\n        y = get_valid_y(y)\n        points[i_xy, :] = [x, y]\n    points = np.reshape(points, -1)\n    return points\n\n# @util.dec.print_calling_in_short\n# @util.dec.timeit\ndef mask_to_bboxes(mask, image_shape =  None, min_area = None, \n                   min_height = None, min_aspect_ratio = None):\n    import config\n    feed_shape = config.train_image_shape\n\n    if image_shape is None:\n        image_shape = feed_shape\n\n    image_h, image_w = image_shape[0:2]\n\n    if min_area is None:\n        min_area = config.min_area\n\n    if min_height is None:\n        min_height = config.min_height\n    bboxes = []\n    max_bbox_idx = mask.max()\n    mask = util.img.resize(img = mask, size = (image_w, image_h), \n                           interpolation = cv2.INTER_NEAREST)\n\n    for bbox_idx in xrange(1, max_bbox_idx + 1):\n        bbox_mask = mask == bbox_idx\n#         if bbox_mask.sum() &lt; 10:\n#             continue\n        cnts = util.img.find_contours(bbox_mask)\n        if len(cnts) == 0:\n            continue\n        cnt = cnts[0]\n        rect, rect_area = min_area_rect(cnt)\n\n        w, h = rect[2:-1]\n        if min(w, h) &lt; min_height:\n            continue\n\n        if rect_area &lt; min_area:\n            continue\n\n#         if max(w, h) * 1.0 / min(w, h) &lt; 2:\n#             continue\n        xys = rect_to_xys(rect, image_shape)\n        bboxes.append(xys)\n\n    return bboxes\n</code></pre>\n\n<p>Any suggestions?</p>\n\n<p>Is there any approach that is more suitable for the problem I'm trying to solve? </p>\n",
                "tags": "<neural-network><convolution>",
                "answers": [
                    [
                        "45953",
                        "2",
                        "45942",
                        "",
                        "",
                        "<p>If you want something like that, you can try to test it with already existing &amp; online app like the following :</p>\n\n<p><a href=\"https://jinapdf.com/image-to-text-file.php\" rel=\"nofollow noreferrer\">https://jinapdf.com/image-to-text-file.php</a></p>\n\n<p>If this is what you want, you can create one :</p>\n\n<p>1) First locate boundaries for text</p>\n\n<p>2) Convert it to text</p>\n\n<p>This is quite complicated bu you can still use what is called OCR (Optical Character Recognition) and therefore search for it in github and use open source projects as a starter like the following : </p>\n\n<p><a href=\"https://github.com/prabhakar267/ocr-convert-image-to-text\" rel=\"nofollow noreferrer\">https://github.com/prabhakar267/ocr-convert-image-to-text</a></p>\n",
                        "",
                        ""
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "17656",
            "_score": 2.8256884,
            "_source": {
                "title": "Can machine learning learn a function like finding maximum from a list?",
                "content": "Can machine learning learn a function like finding maximum from a list? <p>I have an input which is a list and the output is the maximum of the elements of the input-list.</p>\n\n<p>Can machine learning learn such a function which always selects the maximum of the input-elements present in the input?</p>\n\n<p>This might seem as a pretty basic question but it might give me an understanding of what machine learning can do in general. Thanks!</p>\n <machine-learning><deep-learning><p>I will exclude educated designs from\nmy answer. <strong>No it is not possible</strong> to use an out of the box machine learning (ML) approach to <strong>fully</strong> represent the maximum function for <strong>arbitrary</strong> lists with arbitrary precision. ML is a data-based method and it is clear that you will not be able to approximate a function at regions where you do not have any data points. Hence, the space of possible observations (which is infinite) cannot be covered by finite observations.</p>\n\n<p>My statements have a theoretical foundation with Cybeko\u2019s Universal Approximation Theorem for neural networks. I will\nquote the theorem\nfrom\nWikipedia:</p>\n\n<blockquote>\n  <p>In the mathematical theory of artificial neural networks, the\n  universal approximation theorem states[1] that a feed-forward network\n  with a single hidden layer containing a finite number of neurons can\n  approximate continuous functions on compact subsets of <span class=\"math-container\">$\\mathbb{R}^n$</span>, under mild\n  assumptions on the activation function. The theorem thus states that\n  simple neural networks can represent a wide variety of interesting\n  functions when given appropriate parameters; however, it does not\n  touch upon the algorithmic learnability of those parameters.</p>\n</blockquote>\n\n<p>The most important part is the bounded subset of <span class=\"math-container\">$\\mathbb{R}^n$</span>. This additional statement restricts the application of approximating the maximum function for <span class=\"math-container\">$x\\in \\mathbb{R}$</span>. This restriction is manifesting itself in the poor fit of the model from the answer with the most upvotes.</p>\n\n<p>If your space of observations is compact then you might be able to approximate the maximum function with a finite data set. As the top voted answer made clear you should not reinvent the wheel!</p>\n<h2>Learning algorithms</h2>\n\n<p>Instead of learning a function as a calculation done by a feed-forward neural network, there's a whole research domain regarding learning <em>algorithms</em> from sample data. For example, one might use something like <a href=\"https://en.wikipedia.org/wiki/Neural_Turing_machine\" rel=\"nofollow noreferrer\">a Neural Turing Machine</a> or some other method where execution of an algorithm is controlled by machine learning at its decision points. Toy algoritms like finding a maximum, or sorting a list, or reversing a list, or filtering a list are commonly used as examples in algorithm learning research.</p>\n<p><strong>Yes.</strong>\nVery importantly, YOU decide the architecture of a machine learning solution. Architectures and training procedures don't write themselves; they must be designed or templated and the training follows as a means of discovering a parameterization of the architecture fitting to a set of data points.</p>\n\n<p>You can construct a very simple architecture that actually includes a maximum function:</p>\n\n<pre><code>net(x) = a * max(x) + b * min(x)\n</code></pre>\n\n<p>where <em>a</em> and <em>b</em> are learned parameters. </p>\n\n<p>Given enough training samples and a reasonable training routine, this very simple architecture will learn very quickly to set a to 1 and b to zero for your task.</p>\n\n<p>Machine learning often takes the form of entertaining multiple hypotheses about featurization and transformation of input data points, and learning to preserve only those hypotheses that are correlated with the target variable. The hypotheses are encoded explicitly in the architecture and sub-functions available in a parameterized algorithm, or as the assumptions encoded in a \"parameterless\" algorithm.</p>\n\n<p>For example, the choice to use dot products and nonlinearities as is common in vanilla neural network ML is somewhat arbitrary; it expresses the encompassing hypothesis that a function can be constructed using a predetermined compositional network structure of linear transformations and threshold functions. Different parameterizations of that network embody different hypotheses about which linear transformations to use. Any toolbox of functions can be used and a machine learner's job is to discover through differentiation or trial and error or some other repeatable signal which functions or features in its array best minimize an error metric. In the example given above, the learned network simply reduces to the maximum function itself, whereas an undifferentiated network could alternatively \"learn\" a minimum function. These functions can be expressed or approximated via other means, as in the linear or neural net regression function in another answer. In sum, it really depends on which functions or LEGO pieces you have in your ML architecture toolbox.</p>\n<p><em>Maybe</em>, but note that this is one of those cases where <em>machine learning is not the answer</em>. There is a tendency to try and shoehorn machine learning into cases where really, bog standard rules-based solutions are faster, simpler and just generally the right choice :P</p>\n\n<blockquote>\n  <p>Just because you can, doesn't mean you should</p>\n</blockquote>\n\n<p><strong>Edit</strong>: I originally wrote this as \"Yes, but note that...\" but then started to doubt myself, having never seen it done. I tried it out this afternoon and it's certainly doable:</p>\n\n<pre><code>import numpy as np\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Dropout\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import EarlyStopping\n\n# Create an input array of 50,000 samples of 20 random numbers each\nx = np.random.randint(0, 100, size=(50000, 20))\n\n# And a one-hot encoded target denoting the index of the maximum of the inputs\ny = to_categorical(np.argmax(x, axis=1), num_classes=20)\n\n# Split into training and testing datasets\nx_train, x_test, y_train, y_test = train_test_split(x, y)\n\n# Build a network, probaly needlessly complicated since it needs a lot of dropout to\n# perform even reasonably well.\n\ni = Input(shape=(20, ))\na = Dense(1024, activation='relu')(i)\nb = Dense(512, activation='relu')(a)\nba = Dropout(0.3)(b)\nc = Dense(256, activation='relu')(ba)\nd = Dense(128, activation='relu')(c)\no = Dense(20, activation='softmax')(d)\n\nmodel = Model(inputs=i, outputs=o)\n\nes = EarlyStopping(monitor='val_loss', patience=3)\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy')\n\nmodel.fit(x_train, y_train, epochs=15, batch_size=8, validation_data=[x_test, y_test], callbacks=[es])\n\nprint(np.where(np.argmax(model.predict(x_test), axis=1) == np.argmax(y_test, axis=1), 1, 0).mean())\n</code></pre>\n\n<p>Output is 0.74576, so it's correctly finding the max 74.5% of the time. I have no doubt that that could be improved, but as I say this is not a usecase I would recommend for ML.</p>\n\n<p><strong>EDIT 2</strong>: Actually I re-ran this this morning using sklearn's RandomForestClassifier and it performed significantly better:</p>\n\n<pre><code># instantiation of the arrays is identical\n\nrfc = RandomForestClassifier(n_estimators=1000, verbose=1)\nrfc.fit(x_train, y_train)\n\nyhat_proba = rfc.predict_proba(x_test)\n\n\n# We have some annoying transformations to do because this .predict_proba() call returns the data in a weird format of shape (20, 12500, 2).\n\nfor i in range(len(yhat_proba)):\n    yhat_proba[i] = yhat_proba[i][:, 1]\n\npyhat = np.reshape(np.ravel(yhat_proba), (12500,20), order='F')\n\nprint(np.where(np.argmax(pyhat, axis=1) == np.argmax(y_test, axis=1), 1, 0).mean())\n</code></pre>\n\n<p>And the score here is 94.4% of samples with the max correctly identified, which is pretty good indeed.</p>\n<p>Here's an expansion on my comment.  To preface, absolutely @DanScally is right that there's no reason to use ML for finding a maximum of a list.  But I think your \"it might give me an understanding of what machine learning can do in general\" is good enough reason to delve into this.</p>\n\n<p>You ask about more general machine learning, but I'll focus on neural networks.  In that context, we must first ask whether the actual functions produced by a neural network can approximate (or evaluate exactly) <span class=\"math-container\">$\\max$</span>, and only then can we further inquire whether any of the (common?) training methods can fit a NN approximating <span class=\"math-container\">$\\max$</span>.</p>\n\n<hr>\n\n<p>The comments, and @MachineLearner's answer brought up universal approximation theorems: on a <em>bounded domain</em>, a neural network can approximate any reasonably nice function like <span class=\"math-container\">$\\max$</span>, but we can't expect a priori to approximate <span class=\"math-container\">$\\max$</span> on arbitrary input, nor to exactly calculate <span class=\"math-container\">$\\max$</span> anywhere.</p>\n\n<p>But, it turns out that a neural network <strong>can exactly</strong> sort arbitrary input numbers.  Indeed, <span class=\"math-container\">$n$</span> <span class=\"math-container\">$n$</span>-bit integers can be sorted by a network with just two hidden layers of quadratic size.  <a href=\"https://core.ac.uk/download/pdf/4894171.pdf\" rel=\"nofollow noreferrer\">Depth Efficient Neural Networks for Division and Related Problems</a>, Theorem 7 on page 955; many thanks to @MaximilianJanisch in <a href=\"https://datascience.stackexchange.com/a/55593/55122\">this answer</a> for finding this reference.</p>\n\n<p>I'll briefly describe a simplification of the approach in that paper to produce the <span class=\"math-container\">$\\operatorname{argmax}$</span> function for <span class=\"math-container\">$n$</span> arbitrary distinct inputs.  The first hidden layer consists of <span class=\"math-container\">$\\binom{n}{2}$</span> neurons, each representing the indicator variable <span class=\"math-container\">$\\delta_{ij} = \\mathbf{1}(x_i &lt; x_j)$</span>, for <span class=\"math-container\">$i&lt;j$</span>.  These are easily built as <span class=\"math-container\">$x_j-x_i$</span> with a step indicator.  The next layer has <span class=\"math-container\">$n$</span> neurons, one for each input <span class=\"math-container\">$x_i$</span>; start with the sum <span class=\"math-container\">$\\sum_{j&lt;i} \\delta_{ji} + \\sum_{j&gt;i} (1-\\delta_{ij})$</span>; that is, the number of <span class=\"math-container\">$j$</span> such that <span class=\"math-container\">$x_i&gt;x_j$</span>, and hence the position of <span class=\"math-container\">$x_i$</span> in the sorted list.  To complete the argmax, just threshold this layer.<br>\nAt this point, if we could multiply, we'd get the actual maximum value pretty easily.  The solution in the paper is to use the binary representation of the numbers, at which point binary multiplication is the same as thresholded addition.  To just get the argmax, it suffices to have a simple linear function multiplying the <span class=\"math-container\">$i$</span>th indicator by <span class=\"math-container\">$i$</span> and summing.</p>\n\n<hr>\n\n<p>Finally, for the subsequent question: can we can train a NN into this state.  @DanScally got us started; maybe knowing the theoretical architecture can help us cheat into the solution?  (Note that if we can learn/approximate the particular set of weights above, the net will actually perform well outside the range of the training samples.)</p>\n\n<p><a href=\"https://github.com/bmreiniger/datascience.stackexchange/blob/master/56676.ipynb\" rel=\"nofollow noreferrer\">Notebook in github / Colab</a></p>\n\n<p>Changing things just a little bit, I get better testing score (0.838), and even testing on a sample outside the original training range gets a decent score (0.698).  Using inputs scaled to <span class=\"math-container\">$[-1,1]$</span> gets the test score up to 0.961, with an out-of-range score of 0.758.  But, I'm scoring with the same method as @DanScally, which seems a little dishonest: the identity function will score perfectly on this metric.  I also printed out a few coefficients to see whether anything close to the above described exact fit appears (not really); and a few raw outputs, which suggest the model is too timid in predicting a maximum, erring on the side of predicting that none of the inputs are the maximum.  Maybe modifying the objective could help, but at this point I've put in too much time already; if anyone cares to improve the approach, feel free to play (in Colab if you like) and let me know.</p>\n<p>Yes, even as simple machine learning as ordinary linear least squares can do this if you use some applied cleverness. </p>\n\n<p>(But most would consider this quite horrible overkill). </p>\n\n<p>(I will assume we want to find max of abs of input vector):</p>\n\n<ol>\n<li>Select a monotonically decreasing function of absolute value, for example <span class=\"math-container\">$$f(x) = \\frac{1}{x^2}$$</span></li>\n<li>Build diagonal matrix of <span class=\"math-container\">$f({\\bf r})$</span>. Let us call it <span class=\"math-container\">$\\bf C_r$</span></li>\n<li>Build vector full of ones <span class=\"math-container\">$\\bf S$</span>.</li>\n<li>Build and solve equation system <span class=\"math-container\">$(\\epsilon {\\bf I}+10^3{\\bf S}^t{\\bf S}+{\\bf C_r})^{-1}(10^3 {\\bf S}^t)$</span></li>\n<li>Let us call result vector <span class=\"math-container\">$\\bf p$</span>, it will be a probability measure (sums to 1), we can reweigh it nonlinearly, for example <span class=\"math-container\">$$p_i = \\frac{p_i^k}{\\sum|p_i|^k}$$</span></li>\n<li>Just calculate scalar product with index vector and round.</li>\n</ol>\n<p>Yes - Machine learning can learn to find the maximum in a list of numbers. </p>\n\n<p>Here is a simple example of learning to find the index of the maximum:</p>\n\n<pre><code>import numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Create training pairs where the input is a list of numbers and the output is the argmax\ntraining_data = np.random.rand(10_000, 5) # Each list is 5 elements; 10K examples\ntraining_targets = np.argmax(input_data, axis=1)\n\n# Train a descision tree with scikit-learn\nclf = DecisionTreeClassifier()\nclf.fit(input_data, targets)\n\n# Let's see if the trained model can correctly predict the argmax for new data\ntest_data = np.random.rand(1, 5)\nprediction = clf.predict(test_data)\nassert prediction == np.argmax(test_data) # The test passes - The model has learned argmax\n</code></pre>\n",
                "codes": [
                    [],
                    [],
                    [
                        "net(x) = a * max(x) + b * min(x)\n"
                    ],
                    [
                        "import numpy as np\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Dropout\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import EarlyStopping\n\n# Create an input array of 50,000 samples of 20 random numbers each\nx = np.random.randint(0, 100, size=(50000, 20))\n\n# And a one-hot encoded target denoting the index of the maximum of the inputs\ny = to_categorical(np.argmax(x, axis=1), num_classes=20)\n\n# Split into training and testing datasets\nx_train, x_test, y_train, y_test = train_test_split(x, y)\n\n# Build a network, probaly needlessly complicated since it needs a lot of dropout to\n# perform even reasonably well.\n\ni = Input(shape=(20, ))\na = Dense(1024, activation='relu')(i)\nb = Dense(512, activation='relu')(a)\nba = Dropout(0.3)(b)\nc = Dense(256, activation='relu')(ba)\nd = Dense(128, activation='relu')(c)\no = Dense(20, activation='softmax')(d)\n\nmodel = Model(inputs=i, outputs=o)\n\nes = EarlyStopping(monitor='val_loss', patience=3)\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy')\n\nmodel.fit(x_train, y_train, epochs=15, batch_size=8, validation_data=[x_test, y_test], callbacks=[es])\n\nprint(np.where(np.argmax(model.predict(x_test), axis=1) == np.argmax(y_test, axis=1), 1, 0).mean())\n",
                        "# instantiation of the arrays is identical\n\nrfc = RandomForestClassifier(n_estimators=1000, verbose=1)\nrfc.fit(x_train, y_train)\n\nyhat_proba = rfc.predict_proba(x_test)\n\n\n# We have some annoying transformations to do because this .predict_proba() call returns the data in a weird format of shape (20, 12500, 2).\n\nfor i in range(len(yhat_proba)):\n    yhat_proba[i] = yhat_proba[i][:, 1]\n\npyhat = np.reshape(np.ravel(yhat_proba), (12500,20), order='F')\n\nprint(np.where(np.argmax(pyhat, axis=1) == np.argmax(y_test, axis=1), 1, 0).mean())\n"
                    ],
                    [],
                    [],
                    [
                        "import numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Create training pairs where the input is a list of numbers and the output is the argmax\ntraining_data = np.random.rand(10_000, 5) # Each list is 5 elements; 10K examples\ntraining_targets = np.argmax(input_data, axis=1)\n\n# Train a descision tree with scikit-learn\nclf = DecisionTreeClassifier()\nclf.fit(input_data, targets)\n\n# Let's see if the trained model can correctly predict the argmax for new data\ntest_data = np.random.rand(1, 5)\nprediction = clf.predict(test_data)\nassert prediction == np.argmax(test_data) # The test passes - The model has learned argmax\n"
                    ]
                ],
                "question_id:": "56676",
                "question_votes:": "26",
                "question_text:": "<p>I have an input which is a list and the output is the maximum of the elements of the input-list.</p>\n\n<p>Can machine learning learn such a function which always selects the maximum of the input-elements present in the input?</p>\n\n<p>This might seem as a pretty basic question but it might give me an understanding of what machine learning can do in general. Thanks!</p>\n",
                "tags": "<machine-learning><deep-learning>",
                "answers": [
                    [
                        "56864",
                        "2",
                        "56676",
                        "",
                        "",
                        "<p>I will exclude educated designs from\nmy answer. <strong>No it is not possible</strong> to use an out of the box machine learning (ML) approach to <strong>fully</strong> represent the maximum function for <strong>arbitrary</strong> lists with arbitrary precision. ML is a data-based method and it is clear that you will not be able to approximate a function at regions where you do not have any data points. Hence, the space of possible observations (which is infinite) cannot be covered by finite observations.</p>\n\n<p>My statements have a theoretical foundation with Cybeko\u2019s Universal Approximation Theorem for neural networks. I will\nquote the theorem\nfrom\nWikipedia:</p>\n\n<blockquote>\n  <p>In the mathematical theory of artificial neural networks, the\n  universal approximation theorem states[1] that a feed-forward network\n  with a single hidden layer containing a finite number of neurons can\n  approximate continuous functions on compact subsets of <span class=\"math-container\">$\\mathbb{R}^n$</span>, under mild\n  assumptions on the activation function. The theorem thus states that\n  simple neural networks can represent a wide variety of interesting\n  functions when given appropriate parameters; however, it does not\n  touch upon the algorithmic learnability of those parameters.</p>\n</blockquote>\n\n<p>The most important part is the bounded subset of <span class=\"math-container\">$\\mathbb{R}^n$</span>. This additional statement restricts the application of approximating the maximum function for <span class=\"math-container\">$x\\in \\mathbb{R}$</span>. This restriction is manifesting itself in the poor fit of the model from the answer with the most upvotes.</p>\n\n<p>If your space of observations is compact then you might be able to approximate the maximum function with a finite data set. As the top voted answer made clear you should not reinvent the wheel!</p>\n",
                        "",
                        "2"
                    ],
                    [
                        "56798",
                        "2",
                        "56676",
                        "",
                        "",
                        "<h2>Learning algorithms</h2>\n\n<p>Instead of learning a function as a calculation done by a feed-forward neural network, there's a whole research domain regarding learning <em>algorithms</em> from sample data. For example, one might use something like <a href=\"https://en.wikipedia.org/wiki/Neural_Turing_machine\" rel=\"nofollow noreferrer\">a Neural Turing Machine</a> or some other method where execution of an algorithm is controlled by machine learning at its decision points. Toy algoritms like finding a maximum, or sorting a list, or reversing a list, or filtering a list are commonly used as examples in algorithm learning research.</p>\n",
                        "",
                        "4"
                    ],
                    [
                        "56725",
                        "2",
                        "56676",
                        "",
                        "",
                        "<p><strong>Yes.</strong>\nVery importantly, YOU decide the architecture of a machine learning solution. Architectures and training procedures don't write themselves; they must be designed or templated and the training follows as a means of discovering a parameterization of the architecture fitting to a set of data points.</p>\n\n<p>You can construct a very simple architecture that actually includes a maximum function:</p>\n\n<pre><code>net(x) = a * max(x) + b * min(x)\n</code></pre>\n\n<p>where <em>a</em> and <em>b</em> are learned parameters. </p>\n\n<p>Given enough training samples and a reasonable training routine, this very simple architecture will learn very quickly to set a to 1 and b to zero for your task.</p>\n\n<p>Machine learning often takes the form of entertaining multiple hypotheses about featurization and transformation of input data points, and learning to preserve only those hypotheses that are correlated with the target variable. The hypotheses are encoded explicitly in the architecture and sub-functions available in a parameterized algorithm, or as the assumptions encoded in a \"parameterless\" algorithm.</p>\n\n<p>For example, the choice to use dot products and nonlinearities as is common in vanilla neural network ML is somewhat arbitrary; it expresses the encompassing hypothesis that a function can be constructed using a predetermined compositional network structure of linear transformations and threshold functions. Different parameterizations of that network embody different hypotheses about which linear transformations to use. Any toolbox of functions can be used and a machine learner's job is to discover through differentiation or trial and error or some other repeatable signal which functions or features in its array best minimize an error metric. In the example given above, the learned network simply reduces to the maximum function itself, whereas an undifferentiated network could alternatively \"learn\" a minimum function. These functions can be expressed or approximated via other means, as in the linear or neural net regression function in another answer. In sum, it really depends on which functions or LEGO pieces you have in your ML architecture toolbox.</p>\n",
                        "",
                        "27"
                    ],
                    [
                        "56677",
                        "2",
                        "56676",
                        "",
                        "",
                        "<p><em>Maybe</em>, but note that this is one of those cases where <em>machine learning is not the answer</em>. There is a tendency to try and shoehorn machine learning into cases where really, bog standard rules-based solutions are faster, simpler and just generally the right choice :P</p>\n\n<blockquote>\n  <p>Just because you can, doesn't mean you should</p>\n</blockquote>\n\n<p><strong>Edit</strong>: I originally wrote this as \"Yes, but note that...\" but then started to doubt myself, having never seen it done. I tried it out this afternoon and it's certainly doable:</p>\n\n<pre><code>import numpy as np\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Dropout\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import EarlyStopping\n\n# Create an input array of 50,000 samples of 20 random numbers each\nx = np.random.randint(0, 100, size=(50000, 20))\n\n# And a one-hot encoded target denoting the index of the maximum of the inputs\ny = to_categorical(np.argmax(x, axis=1), num_classes=20)\n\n# Split into training and testing datasets\nx_train, x_test, y_train, y_test = train_test_split(x, y)\n\n# Build a network, probaly needlessly complicated since it needs a lot of dropout to\n# perform even reasonably well.\n\ni = Input(shape=(20, ))\na = Dense(1024, activation='relu')(i)\nb = Dense(512, activation='relu')(a)\nba = Dropout(0.3)(b)\nc = Dense(256, activation='relu')(ba)\nd = Dense(128, activation='relu')(c)\no = Dense(20, activation='softmax')(d)\n\nmodel = Model(inputs=i, outputs=o)\n\nes = EarlyStopping(monitor='val_loss', patience=3)\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy')\n\nmodel.fit(x_train, y_train, epochs=15, batch_size=8, validation_data=[x_test, y_test], callbacks=[es])\n\nprint(np.where(np.argmax(model.predict(x_test), axis=1) == np.argmax(y_test, axis=1), 1, 0).mean())\n</code></pre>\n\n<p>Output is 0.74576, so it's correctly finding the max 74.5% of the time. I have no doubt that that could be improved, but as I say this is not a usecase I would recommend for ML.</p>\n\n<p><strong>EDIT 2</strong>: Actually I re-ran this this morning using sklearn's RandomForestClassifier and it performed significantly better:</p>\n\n<pre><code># instantiation of the arrays is identical\n\nrfc = RandomForestClassifier(n_estimators=1000, verbose=1)\nrfc.fit(x_train, y_train)\n\nyhat_proba = rfc.predict_proba(x_test)\n\n\n# We have some annoying transformations to do because this .predict_proba() call returns the data in a weird format of shape (20, 12500, 2).\n\nfor i in range(len(yhat_proba)):\n    yhat_proba[i] = yhat_proba[i][:, 1]\n\npyhat = np.reshape(np.ravel(yhat_proba), (12500,20), order='F')\n\nprint(np.where(np.argmax(pyhat, axis=1) == np.argmax(y_test, axis=1), 1, 0).mean())\n</code></pre>\n\n<p>And the score here is 94.4% of samples with the max correctly identified, which is pretty good indeed.</p>\n",
                        "",
                        "36"
                    ],
                    [
                        "57382",
                        "2",
                        "56676",
                        "",
                        "",
                        "<p>Here's an expansion on my comment.  To preface, absolutely @DanScally is right that there's no reason to use ML for finding a maximum of a list.  But I think your \"it might give me an understanding of what machine learning can do in general\" is good enough reason to delve into this.</p>\n\n<p>You ask about more general machine learning, but I'll focus on neural networks.  In that context, we must first ask whether the actual functions produced by a neural network can approximate (or evaluate exactly) <span class=\"math-container\">$\\max$</span>, and only then can we further inquire whether any of the (common?) training methods can fit a NN approximating <span class=\"math-container\">$\\max$</span>.</p>\n\n<hr>\n\n<p>The comments, and @MachineLearner's answer brought up universal approximation theorems: on a <em>bounded domain</em>, a neural network can approximate any reasonably nice function like <span class=\"math-container\">$\\max$</span>, but we can't expect a priori to approximate <span class=\"math-container\">$\\max$</span> on arbitrary input, nor to exactly calculate <span class=\"math-container\">$\\max$</span> anywhere.</p>\n\n<p>But, it turns out that a neural network <strong>can exactly</strong> sort arbitrary input numbers.  Indeed, <span class=\"math-container\">$n$</span> <span class=\"math-container\">$n$</span>-bit integers can be sorted by a network with just two hidden layers of quadratic size.  <a href=\"https://core.ac.uk/download/pdf/4894171.pdf\" rel=\"nofollow noreferrer\">Depth Efficient Neural Networks for Division and Related Problems</a>, Theorem 7 on page 955; many thanks to @MaximilianJanisch in <a href=\"https://datascience.stackexchange.com/a/55593/55122\">this answer</a> for finding this reference.</p>\n\n<p>I'll briefly describe a simplification of the approach in that paper to produce the <span class=\"math-container\">$\\operatorname{argmax}$</span> function for <span class=\"math-container\">$n$</span> arbitrary distinct inputs.  The first hidden layer consists of <span class=\"math-container\">$\\binom{n}{2}$</span> neurons, each representing the indicator variable <span class=\"math-container\">$\\delta_{ij} = \\mathbf{1}(x_i &lt; x_j)$</span>, for <span class=\"math-container\">$i&lt;j$</span>.  These are easily built as <span class=\"math-container\">$x_j-x_i$</span> with a step indicator.  The next layer has <span class=\"math-container\">$n$</span> neurons, one for each input <span class=\"math-container\">$x_i$</span>; start with the sum <span class=\"math-container\">$\\sum_{j&lt;i} \\delta_{ji} + \\sum_{j&gt;i} (1-\\delta_{ij})$</span>; that is, the number of <span class=\"math-container\">$j$</span> such that <span class=\"math-container\">$x_i&gt;x_j$</span>, and hence the position of <span class=\"math-container\">$x_i$</span> in the sorted list.  To complete the argmax, just threshold this layer.<br>\nAt this point, if we could multiply, we'd get the actual maximum value pretty easily.  The solution in the paper is to use the binary representation of the numbers, at which point binary multiplication is the same as thresholded addition.  To just get the argmax, it suffices to have a simple linear function multiplying the <span class=\"math-container\">$i$</span>th indicator by <span class=\"math-container\">$i$</span> and summing.</p>\n\n<hr>\n\n<p>Finally, for the subsequent question: can we can train a NN into this state.  @DanScally got us started; maybe knowing the theoretical architecture can help us cheat into the solution?  (Note that if we can learn/approximate the particular set of weights above, the net will actually perform well outside the range of the training samples.)</p>\n\n<p><a href=\"https://github.com/bmreiniger/datascience.stackexchange/blob/master/56676.ipynb\" rel=\"nofollow noreferrer\">Notebook in github / Colab</a></p>\n\n<p>Changing things just a little bit, I get better testing score (0.838), and even testing on a sample outside the original training range gets a decent score (0.698).  Using inputs scaled to <span class=\"math-container\">$[-1,1]$</span> gets the test score up to 0.961, with an out-of-range score of 0.758.  But, I'm scoring with the same method as @DanScally, which seems a little dishonest: the identity function will score perfectly on this metric.  I also printed out a few coefficients to see whether anything close to the above described exact fit appears (not really); and a few raw outputs, which suggest the model is too timid in predicting a maximum, erring on the side of predicting that none of the inputs are the maximum.  Maybe modifying the objective could help, but at this point I've put in too much time already; if anyone cares to improve the approach, feel free to play (in Colab if you like) and let me know.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "56862",
                        "2",
                        "56676",
                        "",
                        "",
                        "<p>Yes, even as simple machine learning as ordinary linear least squares can do this if you use some applied cleverness. </p>\n\n<p>(But most would consider this quite horrible overkill). </p>\n\n<p>(I will assume we want to find max of abs of input vector):</p>\n\n<ol>\n<li>Select a monotonically decreasing function of absolute value, for example <span class=\"math-container\">$$f(x) = \\frac{1}{x^2}$$</span></li>\n<li>Build diagonal matrix of <span class=\"math-container\">$f({\\bf r})$</span>. Let us call it <span class=\"math-container\">$\\bf C_r$</span></li>\n<li>Build vector full of ones <span class=\"math-container\">$\\bf S$</span>.</li>\n<li>Build and solve equation system <span class=\"math-container\">$(\\epsilon {\\bf I}+10^3{\\bf S}^t{\\bf S}+{\\bf C_r})^{-1}(10^3 {\\bf S}^t)$</span></li>\n<li>Let us call result vector <span class=\"math-container\">$\\bf p$</span>, it will be a probability measure (sums to 1), we can reweigh it nonlinearly, for example <span class=\"math-container\">$$p_i = \\frac{p_i^k}{\\sum|p_i|^k}$$</span></li>\n<li>Just calculate scalar product with index vector and round.</li>\n</ol>\n",
                        "",
                        ""
                    ],
                    [
                        "56684",
                        "2",
                        "56676",
                        "",
                        "",
                        "<p>Yes - Machine learning can learn to find the maximum in a list of numbers. </p>\n\n<p>Here is a simple example of learning to find the index of the maximum:</p>\n\n<pre><code>import numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Create training pairs where the input is a list of numbers and the output is the argmax\ntraining_data = np.random.rand(10_000, 5) # Each list is 5 elements; 10K examples\ntraining_targets = np.argmax(input_data, axis=1)\n\n# Train a descision tree with scikit-learn\nclf = DecisionTreeClassifier()\nclf.fit(input_data, targets)\n\n# Let's see if the trained model can correctly predict the argmax for new data\ntest_data = np.random.rand(1, 5)\nprediction = clf.predict(test_data)\nassert prediction == np.argmax(test_data) # The test passes - The model has learned argmax\n</code></pre>\n",
                        "",
                        "7"
                    ]
                ]
            },
            "good_match": "True"
        },
        {
            "_index": "datascience_stackexchange",
            "_type": "_doc",
            "_id": "7002",
            "_score": 2.7117782,
            "_source": {
                "title": "Neural Network Performs Bad On MNIST",
                "content": "Neural Network Performs Bad On MNIST <p>I've been struggling with Neural Networks for a while now.\nI get the math behind backpropagation.</p>\n\n<p>Still as reference I'm using the formulas from <a href=\"https://www.youtube.com/watch?v=zpykfC4VnpM&amp;list=WL&amp;index=11&amp;t=635s\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<p><a href=\"https://i.stack.imgur.com/giZA8.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/giZA8.png\" alt=\"Screenshot of the formulas\"></a></p>\n\n<hr>\n\n<h2>The Network learns XOR:</h2>\n\n<p>Prediction After Training: [0.0003508415406266712] Expected: [0.0]</p>\n\n<hr>\n\n<h2>But basically doesn't learn anything on the MNIST dataset:</h2>\n\n<p>Error after n trainings examples:</p>\n\n<pre><code> - 0      Total Net Error:  4.3739634316135225 \n - 10000  Total Net Error:  0.4876292680858326\n - 20000  Total Net Error:  0.39989816082272944\n - 30000  Total Net Error:  0.49507443066631834\n - 40000  Total Net Error:  0.5483594859079792\n - 50000  Total Net Error:  0.5135921029479789\n - 59000  Total Net Error:  0.4686434346776871\n</code></pre>\n\n<p>[Prediction] [Expected]</p>\n\n<pre><code> - [0.047784337754445516]               [0]\n - [0.09444684951344406]                [0]\n - [0.0902378720783441]                 [0]\n - [0.09704810171673675]                [0]\n - [0.02940947956812051]                [0]\n - [0.12494839048272757]                [1]\n - [0.1512762065177885]                 [0]\n - [0.055847446615593155]               [0]\n - [0.22983410239796548]                [0]\n - [0.09162426430286492]                [0]\n</code></pre>\n\n<hr>\n\n<h2>The Old Code ( can be ignored )</h2>\n\n<p>I've broken the network down as much as possible. With no matrix or vector multiplication. Here the code for the different classes:</p>\n\n<pre><code>Main File:    \n\n    # Load Trainigs Data\n    rawImages, rawLabels, numImagePixels = get_data_and_labels(\"C:\\\\Users\\\\Robin\\\\Documents\\\\MNIST\\\\Images\\\\train-images.idx3-ubyte\", \"C:\\\\Users\\\\Robin\\\\Documents\\\\MNIST\\\\Labels\\\\train-labels.idx1-ubyte\")\n\n    # Prepare Data\n    print(\"Start Preparing Data\")\n    images = []\n    labels = []\n    for i in rawImages:\n        insert = []\n        for pixel in i:\n            insert.append(map0to1(pixel, 255))\n        images.append(insert)\n    for l in rawLabels:\n        y = [0] * 10\n        y[l] = 1\n        labels.append(y)\n    print(\"Finished Preparing Data\")\n\n\n    # Create Network\n    mnistNet = Network((numImagePixels, 16, 16, 10))\n\n    # Train\n    print(\"Start Training\")\n    for index in range(len(images)):\n        netError = mnistNet.train(images[index], labels[index])\n        if index % 10000 == 0:\n            print(index, \" Total Net Error: \", netError)\n\n\n    prediction = mnistNet.predict(images[0])\n    print(\"After Training The Network Predicted:\", prediction, \"Expected Was:\", labels[0])\n\n\n\nclass Network:\n\n    def __init__(self, topology):\n        # Make Layer List\n        self.layerList = []\n        # Make Input Layer\n        self.layerList.append(Layer(0, topology[0], 0))\n        # Make All Other Layers\n        for index in range(1, len(topology)):\n            self.layerList.append(Layer(index, topology[index], topology[index-1]))\n\n    def predict(self, x):\n        # Set x As Value Of Input Layer\n        self.layerList[0].setInput(x)\n        # Feed Through Network\n        for index in range(1, len(self.layerList)):\n            self.layerList[index].feedForward(self.layerList[index-1].getA())\n        # Return The Output Of The Last Layer\n        return self.layerList[-1].getA()\n\n\n    def train(self, x, y):\n        # Feed Through Network\n        prediction = self.predict(x)\n        # Container For The Calculated Layer Errors\n        errorsPerLayer = []\n        # Calculate Error Of The Output Layer\n        errorOutputLayer = listSubtract(prediction,y)\n        # Add The Error To The Container\n        errorsPerLayer.append(errorOutputLayer)\n        # Calculate The Total Error Of The Network\n        totalError = calcTotalError(errorOutputLayer)\n        # Calculate The Error Of The Hidden Layers\n        for layerNum in range(len(self.layerList)-2, 0, -1):\n            # Get The Error Of The Next Layer\n            errorOfNextLayer = errorsPerLayer[0]\n            # Forward The Calculation To The Next Layer, Which Returns The Weighted Error, By Giving It It's Error\n            weightedError = self.layerList[layerNum+1].calculateWeightedError(self.layerList[layerNum].getNeuronNum(), errorOfNextLayer)\n            # Forward The Calculation To The Current Layer, Which Returns The Error Of The Layer, By Giving It The Number Of Neurons In The Current Layer And The Weighted Error Of The Next Layer\n            currentLayerError = self.layerList[layerNum].calculateError(weightedError)\n            # Add The Just Calculated Error To The List\n            errorsPerLayer.insert(0, currentLayerError)\n        # Insert 0 As Error For The Input Layer, It's Not Important But That Way It's Size Matches The One Of The Layer List\n        errorsPerLayer.insert(0, 0)\n        # Update Weights And Biases\n        for layerNum in range(1, len(self.layerList)):\n            # Get The Output Of The Previous Layer\n            aOfPrevLayer = self.layerList[layerNum-1].getA()\n            # Forward The Error Of The Current Layer And The Output Of The Previous Layer To The Current Layer For Calculating Delta W\n            self.layerList[layerNum].updateWeightsAndBiases(errorsPerLayer[layerNum], aOfPrevLayer)\n\n        #print(\"The Network Predicted: \", prediction, \" Expected Was: \", y, \" The Error Of The Output Layer Is: \", errorOutputLayer)\n        # Return The Total Error Of The Network For Usage Outisde This Class\n        return totalError\n\n\n\n    def getNetworkInfo(self):\n        for layer in self.layerList:\n            print(layer.getLayerInfo())\n\n\n----------\n\n\n\n\n\nclass Layer:\n\n    def __init__(self, layerNum, numNeurons, numNeuronsPrevLayer):\n        self.neurons = []\n        # Set The Number Of The Layer\n        self.layerNum = layerNum\n        # Create The Neurons\n        for index in range(numNeurons):\n            self.neurons.append(Neuron(numNeuronsPrevLayer))\n        # Print Info\n        print(\"Layer \", layerNum, \" makes \", numNeurons, \" Neurons\", len(self.neurons))\n\n\n    def feedForward(self, aPrevLayer):\n        # Give It To The Neurono For Processing\n        for neuron in self.neurons:\n            neuron.feedForward(aPrevLayer)\n\n\n    def calculateWeightedError(self, numNeuronsCurrentLayer, errorOfNextLayer):\n        # The Container For The Weighted Error Of The Next Layer\n        weightedError = []\n        # The Calulation For Every Neuron Of The Current Layer One After Another\n        for neuronNum in range(numNeuronsCurrentLayer):\n            eSum = 0\n            # The Error Of The Neuron With The Neuron For Later Calculation\n            for e, n in zip(errorOfNextLayer, self.neurons):\n                # Forward The Calculation To The Current Neuron, By Giving It It's Error And The Connecting Neuron Num\n                eSum += n.weightError(e, neuronNum)\n            # Add The Summed And Weighted Error\n            weightedError.append(eSum)\n\n        # Return The Error Of The Current Layer\n        return weightedError\n\n\n    def calculateError(self, weightedError):\n        # The Container For The Error Of The Current Layer\n        errorOfCurrentLayer = []\n        # The Weighted Error For The Neuron With The Neruon\n        for wE, n in zip(weightedError, self.neurons):\n            # Add The Product Of The Weighted Error With The Z Of The Current Neuron Run To Sigmoid Prime\n            errorOfCurrentLayer.append(wE * sigmoidPrime(n.getZ()))\n        # Return The Error Of The Current Layer\n        return errorOfCurrentLayer\n\n\n    def updateWeightsAndBiases(self, errorOfCurrentLayer, aOfPrevLayer):\n        # The Error For The Neuron With The Neuron\n        for e, n in zip(errorOfCurrentLayer, self.neurons):\n            # Error Of Current Layer Is Equal To The Delta Of The Bias So Apply That\n            n.updateBias(e)\n            # Forward The Error And All The Activity Of The Previous Layer To The Current Neuron To Update It's Weights\n            n.updateWeights(e, aOfPrevLayer)\n\n    def setInput(self, x):\n        # Set It To Every Neuron\n        for neuron, val in zip(self.neurons, x):\n            neuron.setInput(val)\n\n    def getA(self):\n        aOfLayer = []\n        for neuron in self.neurons:\n            aOfLayer.append(neuron.getA())\n        return aOfLayer\n    def getNeuronNum(self):\n        return len(self.neurons)\n\n    def getLayerInfo(self):\n        return \"Layer( %i ), has %i Neurons\" % (self.layerNum, len(self.neurons))\n\n\n----------\n\n\n\nclass Neuron:\n\n\n    def __init__(self, numNeuronsPrevLayer):\n        self.a = 0\n        self.z = 0\n        self.b = 0.5\n        if numNeuronsPrevLayer != 0:\n            self.w = np.random.uniform(low = 0, high = 0.5, size=(numNeuronsPrevLayer,))\n\n    def feedForward(self, aPrevLayer):\n        # Reset Z\n        self.z = 0\n        # Calculate Z\n        for w, a in zip(self.w, aPrevLayer):\n            self.z += w*a\n        # Add Bias\n        self.z += self.b\n        # Calculate A\n        self.a = sigmoid(self.z)\n\n    def weightError(self, e, neuronNum):\n        # Weight Error With The Connecting Weight\n        return e * self.w[neuronNum]\n\n    def updateWeights(self, e, aOfPrevLayer):\n        # The Weight With The Matching Activity Of The Previous Layer\n        for index in range(len(self.w)):\n            # The Delta Of The Weight Is The Error Of That Neuron Mutliplied With The Through The Weight Connected Activiy Of The Previous Layer\n            self.w[index] -= e * aOfPrevLayer[index]\n\n    def updateBias(self, e):\n        # E Is The Delta Of The Bias1\n        self.b -= e\n\n    def setInput(self, x):\n        self.z = x\n        self.a = x\n\n    def getA(self):\n        return self.a\n    def getZ(self):\n        return self.z\n    def getB(self):\n        return self.b\n    def getW(self):\n        return self.w\n\n\n----------\n\n**helper functions**\n\n    def map0to1(val, valMax):\n        return val/valMax\n\n\n\n    def calcTotalError(errorOutputLayer):\n        totalError = 0\n        for e in errorOutputLayer:\n            totalError += e**2\n        totalError *= 0.5\n        return totalError\n\n\n\n    def listSubtract(list1, list2):\n        subbed = []\n        for l1, l2 in zip(list1, list2):\n            subbed.append(l1-l2)\n        return subbed\n</code></pre>\n\n<hr>\n\n<h2>The New Code</h2>\n\n<p>Main File</p>\n\n<pre><code>import random\nfrom network import *\nfrom mnistreader import *\n\n\ndef map0to1(val, valMax):\n    return val/valMax\n\n\n# THIS WORKS\n'''\ntrainX = [ [0.0,0.0], [1.0,0.0], [0.0,1.0], [1.0,1.0] ]\ntrainY = [ [ 0.0], [ 1.0 ], [ 1.0 ], [ 0.0 ] ]\n\n\n# Create Network\nxorNet = Network((2,2,1))\n\n# Train\nfor index in range(100000):\n    randIndex = random.randint(0, 3)\n    xorNet.train(trainX[randIndex], trainY[randIndex])\n\nprint(\"Prediction After Training:\", xorNet.predict(trainX[0]), \"Expected:\", trainY[0])\nprint(\"Prediction After Training:\", xorNet.predict(trainX[1]), \"Expected:\", trainY[1])\nprint(\"Prediction After Training:\", xorNet.predict(trainX[2]), \"Expected:\", trainY[2])\nprint(\"Prediction After Training:\", xorNet.predict(trainX[3]), \"Expected:\", trainY[3])\n'''\n\nmnistNet = Network((784, 30, 10))\n\n# Load Trainigs Data\nrawImages, rawLabels, numImagePixels = get_data_and_labels(\"C:\\\\Users\\\\Robin\\\\Documents\\\\MNIST\\\\Images\\\\train-images.idx3-ubyte\", \"C:\\\\Users\\\\Robin\\\\Documents\\\\MNIST\\\\Labels\\\\train-labels.idx1-ubyte\")\n\n# Prepare Data\nprint(\"Start Preparing Data\")\nimages = []\nlabels = []\nfor i in rawImages:\n    insert = []\n    for pixel in i:\n        insert.append(map0to1(pixel, 255))\n    images.append(insert)\nfor l in rawLabels:\n    y = [0] * 10\n    y[l] = 1\n    labels.append(y)\nprint(\"Finished Preparing Data\")\n\n\n# Define Variables\nlearningRate = 0.0001\nerror = 10\n\n# Training\nwhile error &gt; 0.1:\n    for tNum in range(len(images)):\n        error = mnistNet.train(images[tNum], labels[tNum], learningRate)\n    print(\"Error:\", error, \"\\n Prediction:\\n\", mnistNet.predict(images[1]), \"\\nExpected:\", rawLabels[1], \"\\n\\n\")\n\n# Test Prediction\nprint(\"For\", rawLabels[1], \"Predicted\\n\", mnistNet.predict(images[1]))\n</code></pre>\n\n<p>Network Class</p>\n\n<pre><code>import numpy as np\n\nfrom layer import *\nfrom transferfunction import *\n\n\n\n\n\nclass Network:\n\n\n\n    def __init__(self, shape):\n        # Save The Shape Of The Nework\n        self.shape = shape\n        # Create A List Of Layers\n        self.layers = []\n        # Create Input Layer\n        self.layers.append(Layer((shape[0],), layerType = 'Input'))\n        # Create Hidden Layers\n        for numNeurons, numNeuronsPrevLayer in zip(shape[1:], shape[:-2]):\n            self.layers.append(Layer((numNeurons, numNeuronsPrevLayer), layerType = 'Hidden'))\n        # Create Output Layer\n        self.layers.append(Layer((shape[-1], shape[-2]), layerType = 'Output'))\n\n\n\n\n    def predict(self, x):\n        # X Is A Row So Shape It To Be A Column\n        x = np.array(x).reshape(-1, 1)\n        # Set X To Be The Ouput Of The Input Layer\n        self.layers[0].setOutput(x)\n        # Feed Through Other Layers\n        for layerNum in range(1,len(self.layers)):\n            self.layers[layerNum].feedForward(self.layers[layerNum-1].getOutput())\n        # Return The Output Of The Output Layer\n        return self.layers[-1].getOutput()\n\n\n    def train(self, x, y, learningRate):\n        '''\n        1. Feed Forward\n        2. Calculate Error\n        3. Calulate Deltas\n        4. Apply Deltas\n\n        Error Output Layer = f'(z) * (prediction - target)\n        Error Hidden Layer = f'(z) * ( transposed weights next layer DOT error next layer )\n        Delta Bias         = learning rate * error\n        Delta Weights      = learning rate * ( error DOT transposed activity previous layer )\n\n        '''\n\n\n        # Feed Through Network\n        prediction = self.predict(x)\n        # Y Is A Row So Shape It To Be A Column\n        y = np.array(y).reshape(-1, 1)\n\n        # Calculate Error\n        error = prediction - y\n        # Calculate Total Error\n        totalError = 0.5 * np.sum(error**2)\n\n        # Create Container For The Deltas\n        deltas = []\n        # Calculate Delta For Output Layer\n        deltas.append( np.multiply(sigmoidPrime(self.layers[-1].getZ()), error) )\n        # Calculate Deltas For Every Hidden Layer\n        for layerNum in range(len(self.layers)-2, 0, -1):\n            # Compute The Weighted Error Of The Next Layer\n            weightedErrorOfNextLayer = np.dot(self.layers[layerNum+1].getW().T, deltas[0])\n            # Compute The Delta And Add It In Front\n            deltas.insert(0, np.multiply(sigmoidPrime(self.layers[layerNum].getZ()), weightedErrorOfNextLayer) )\n        # Insert Placeholder To Make Delta List As Big As The Layer List\n        deltas.insert(0, 0)\n\n        # For Numerical Grandient Checking Do\n        numericalGradients = self.performNumericalGradientChecking(x,y)\n\n        # Update Weights And Biases\n        for layerNum in range(1, len(self.layers)):\n            self.layers[layerNum].updateBias(deltas[layerNum], learningRate)\n            self.layers[layerNum].updateWeight(deltas[layerNum], self.layers[layerNum-1].getOutput(), learningRate, numericalGradients[layerNum-1])\n\n\n        # Show Information\n        #print('Network Predicted: \\n', prediction, '\\nTarget:\\n', y, '\\nError: ', totalError)\n        return totalError\n\n\n    def performNumericalGradientChecking(self, x, y):\n        # Container Saving All Current Weight Values\n        weightSave = []\n        # Save All The Weight Values\n        for layerNum in range(1, len(self.layers)):\n            weightSave.append(self.layers[layerNum].getW())\n\n        # Define Epsilon To Be A Small Number\n        epsilon = 1e-4\n\n        # Gradient Container\n        numericalGradients = []\n\n        #Perform The Check For Every Layer Therfore Every Set Of Weights\n        for layerNum in range(1, len(self.layers)):\n\n            # Feed Forward With Changed Weights(+epsilon), And Compute Cost\n            self.layers[layerNum].setW(weightSave[layerNum-1] + epsilon)\n            prediction = self.predict(x)\n            loss2 = 0.5 * np.sum ((prediction - y)**2)\n\n            # Feed Forward With Changed Weights(-epsilon), And Compute Cost\n            self.layers[layerNum].setW(weightSave[layerNum-1] - epsilon)\n            prediction = self.predict(x)\n            loss1 = 0.5 * np.sum ((prediction - y)**2)\n\n            # Reset Weight\n            self.layers[layerNum].setW(weightSave[layerNum-1])\n\n            # Calculate Numerical Loss\n            numericalGradient = (loss2 - loss1) / (2 * epsilon)\n\n            # Add The Numerical Grandient\n            numericalGradients.append(numericalGradient)\n\n        return numericalGradients\n\n    def __str__(self):\n        strBuff = ''\n        for layer in self.layers:\n            strBuff += layer.getInfo()\n        return strBuff\n</code></pre>\n\n<p>Layer Class</p>\n\n<pre><code>import numpy as np\n\nfrom transferfunction import *\n\n\nclass Layer:\n\n\n\n    def __init__(self, neurons, layerType = 'Hidden'):\n        ''' Neurons Is A Tuple Consisting Of [0]=NumNeurons And [1]=numNeuronsPrevLayer '''\n\n        # Remember The Type Of The Layer\n        self.layerType = layerType\n        # Remember How Many Neurons This Layer Has\n        self.neuronCount = neurons[0]\n        # Create Layer Based On Type\n        if layerType.lower() == 'input':\n            # Create Container For Input Data\n            self.a = []\n        elif layerType.lower() == 'hidden' or layerType.lower() == 'output':\n            # Create Container For Activation\n            self.z = []\n            # Create Container For Neurons Input\n            self.a = []\n            # Create Weights\n            self.w = np.random.uniform(low = 0.0, high = 0.4, size=(neurons[0], neurons[1]))\n            # Create Prev Delta Weight For Momentum\n            self.momentum = 0.3\n            self.prevDelta = np.full((neurons[0], neurons[1]), 0)\n            # Create Bias\n            self.b = np.full((neurons[0],1), 0, dtype=float)\n        else:\n            print('Wrong Type Of Layer Specified')\n\n\n    def feedForward(self, aPrevLayer):\n        self.z = np.dot(self.w, aPrevLayer) + self.b\n        self.a = sigmoid(self.z)\n\n    def updateBias(self, e, learningRate):\n        self.b -= learningRate * e\n    def updateWeight(self, e, aPrevLayer, learningRate, numericalGradient):\n        # Calulate The Delta Of The Weights\n        deltaW = np.dot(e, aPrevLayer.T)\n\n        # Compare DeltaW With The Numerical Grandient\n        check = np.linalg.norm(deltaW - numericalGradient) / np.linalg.norm(deltaW + numericalGradient)\n        # DEBUG\n        print(check)\n\n        # The Weight Change Is The Delta With The Addition Of The Momentum\n        self.w -= ( learningRate * deltaW ) + ( self.momentum * self.prevDelta)\n        # Save The Current DeltaW\n        self.prevDelta = deltaW\n\n\n\n\n\n    def getW(self):\n        return self.w\n    def getZ(self):\n        return self.z\n    def getOutput(self):\n        return self.a\n\n\n    def setOutput(self, x):\n        self.a = x\n    def setW(self, w):\n        self.w = w\n\n\n    def getInfo(self):\n        if self.layerType.lower() == 'input':\n            return 'Input Layer With ' + str(self.neuronCount) + ' Neurons\\n'\n        else:\n            return self.layerType + ' Layer With ' + str(self.neuronCount) + ' Neurons And Weights Of Shape: ' + str(self.w.shape) + ' With Biases Of Shape: ' + str(self.b.shape) + '\\n'\n</code></pre>\n\n<p>So my Question simply is: \"What's wrong?\"</p>\n\n<p>Problems:</p>\n\n<ol>\n<li><strong>Error gets stuck at 0.45</strong></li>\n<li>When using a hidden layer with 800 neurons I get the warning division by zero and all becomes NaN's from sigmoid prime</li>\n<li>Numerical gradient checking for the hidden Layer is: 1.0 and for the output layer: 0.995784895209. I know that is supposed to be a very small number. But on the second trainings example it creates a overflow error and becomes NaN's</li>\n</ol>\n\n<p><strong>Major Edit</strong>\nI'm truly grateful for all suggestions so far, I've updated the question using a vectorized form so it's easier to get an overview of what I'm doing here. \nI tried gradient checking now too, not sure if I implemented it right (used the tutorial by Welch Labs (<a href=\"https://youtu.be/pHMzNW8Agq4\" rel=\"nofollow noreferrer\">https://youtu.be/pHMzNW8Agq4</a>))\nI hope the Code is readable </p>\n <machine-learning><neural-network><deep-learning><p>You need to increase no of hidden units. The more the number, more extract feature your network builds. Be wise with it, as too many features will make it overfit and it won't generalize on new data.</p>\n<p>Your network has 28 x 28 = 784 (normal MNIST size) inputs, 16 + 16 hidden nodes and 10 outputs. This is not enough for an enough accurate model as a result. </p>\n\n<p>This <a href=\"https://stackoverflow.com/questions/45447740/neural-network-mnist-backpropagation-is-correct-but-training-test-accuracy-ver/45448307#45448307\">question</a> suggests to use 256 x 256 hidden nodes and <a href=\"https://en.wikipedia.org/wiki/MNIST_database\" rel=\"nofollow noreferrer\">Wikipedia page on MNIST</a> gives for 2-layer reference the values: 784-800-10 meaning 800 x 10 nodes. Wikipedia gives error rate 0.016 for that 800 x 10 solution.</p>\n\n<p><em>Sidenote: For 6-layer Deep Neural Network the numbers are : 784-2500-2000-1500-1000-500-10 so the new numbers I gave aren't that big. Of course the error rate on DNN is 0.0035 so it needs those layers.</em></p>\n\n<p><strong>edit:</strong></p>\n\n<blockquote>\n  <p>Do I have to change the learning rate which I now defined to be 0.3?</p>\n</blockquote>\n\n<p>Answer in <a href=\"https://stackoverflow.com/questions/45447740/neural-network-mnist-backpropagation-is-correct-but-training-test-accuracy-ver/45448307#45448307\">the referred question</a> says 0.0001 is more appropriate value. </p>\n\n<p><strong>Edit of question author</strong>\nI marked this as solved because now it is working. I implemented it again and after tweaking the hyperparameters it worked. So this is, in a way the solution to my problem. Because I asked why this problem occurs in the first place, my implementation error aside. </p>\n<p>I guess you are doing something wrong in your code. I guess its better to use <a href=\"https://www.coursera.org/learn/deep-neural-network/lecture/htA0l/gradient-checking\" rel=\"nofollow noreferrer\"><code>gradient checking</code></a> approach for figuring out whether the whole code has any problem or not. </p>\n\n<p>Based on the comments, if I want to show you exactly what happens, first take a look at <a href=\"https://www.coursera.org/learn/neural-networks/lecture/zO1Is/a-simple-example-of-learning-6-min\" rel=\"nofollow noreferrer\">here</a> which professor Hinton himself explains that what <code>MLPs</code> learn is like learning masks instead of learning the features of the inputs. For illustrating more you can take a look at <a href=\"https://datascience.stackexchange.com/a/26642/28175\">here</a> which shows that MLPs can learn what and I hope that you can expand it to higher dimensions, for your case 784 dimensions. If you use <code>MLPs</code> alone, you will face to the problem of something which is like masking. What <code>CNNs</code> try to find is feature. They try to find features which can be better explained by finding hierarchical features. You can also take a look at <a href=\"https://datascience.stackexchange.com/a/26291/28175\">here</a> which explains that using <code>CNNs</code> you try to find features, and after convolution layers, you use dense layers, <code>MLPs</code> which they try to classify the features. </p>\n\n<p><code>MLPs</code> are good for classifying <code>MNIST</code> data set but they are weak for generalizing unseen data. If your code works fine after using <em>gradient checking</em> try to use different hyper parameters which I guess our friend has explained so much well for you.</p>\n",
                "codes": [
                    [],
                    [],
                    []
                ],
                "question_id:": "26618",
                "question_votes:": "5",
                "question_text:": "<p>I've been struggling with Neural Networks for a while now.\nI get the math behind backpropagation.</p>\n\n<p>Still as reference I'm using the formulas from <a href=\"https://www.youtube.com/watch?v=zpykfC4VnpM&amp;list=WL&amp;index=11&amp;t=635s\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<p><a href=\"https://i.stack.imgur.com/giZA8.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/giZA8.png\" alt=\"Screenshot of the formulas\"></a></p>\n\n<hr>\n\n<h2>The Network learns XOR:</h2>\n\n<p>Prediction After Training: [0.0003508415406266712] Expected: [0.0]</p>\n\n<hr>\n\n<h2>But basically doesn't learn anything on the MNIST dataset:</h2>\n\n<p>Error after n trainings examples:</p>\n\n<pre><code> - 0      Total Net Error:  4.3739634316135225 \n - 10000  Total Net Error:  0.4876292680858326\n - 20000  Total Net Error:  0.39989816082272944\n - 30000  Total Net Error:  0.49507443066631834\n - 40000  Total Net Error:  0.5483594859079792\n - 50000  Total Net Error:  0.5135921029479789\n - 59000  Total Net Error:  0.4686434346776871\n</code></pre>\n\n<p>[Prediction] [Expected]</p>\n\n<pre><code> - [0.047784337754445516]               [0]\n - [0.09444684951344406]                [0]\n - [0.0902378720783441]                 [0]\n - [0.09704810171673675]                [0]\n - [0.02940947956812051]                [0]\n - [0.12494839048272757]                [1]\n - [0.1512762065177885]                 [0]\n - [0.055847446615593155]               [0]\n - [0.22983410239796548]                [0]\n - [0.09162426430286492]                [0]\n</code></pre>\n\n<hr>\n\n<h2>The Old Code ( can be ignored )</h2>\n\n<p>I've broken the network down as much as possible. With no matrix or vector multiplication. Here the code for the different classes:</p>\n\n<pre><code>Main File:    \n\n    # Load Trainigs Data\n    rawImages, rawLabels, numImagePixels = get_data_and_labels(\"C:\\\\Users\\\\Robin\\\\Documents\\\\MNIST\\\\Images\\\\train-images.idx3-ubyte\", \"C:\\\\Users\\\\Robin\\\\Documents\\\\MNIST\\\\Labels\\\\train-labels.idx1-ubyte\")\n\n    # Prepare Data\n    print(\"Start Preparing Data\")\n    images = []\n    labels = []\n    for i in rawImages:\n        insert = []\n        for pixel in i:\n            insert.append(map0to1(pixel, 255))\n        images.append(insert)\n    for l in rawLabels:\n        y = [0] * 10\n        y[l] = 1\n        labels.append(y)\n    print(\"Finished Preparing Data\")\n\n\n    # Create Network\n    mnistNet = Network((numImagePixels, 16, 16, 10))\n\n    # Train\n    print(\"Start Training\")\n    for index in range(len(images)):\n        netError = mnistNet.train(images[index], labels[index])\n        if index % 10000 == 0:\n            print(index, \" Total Net Error: \", netError)\n\n\n    prediction = mnistNet.predict(images[0])\n    print(\"After Training The Network Predicted:\", prediction, \"Expected Was:\", labels[0])\n\n\n\nclass Network:\n\n    def __init__(self, topology):\n        # Make Layer List\n        self.layerList = []\n        # Make Input Layer\n        self.layerList.append(Layer(0, topology[0], 0))\n        # Make All Other Layers\n        for index in range(1, len(topology)):\n            self.layerList.append(Layer(index, topology[index], topology[index-1]))\n\n    def predict(self, x):\n        # Set x As Value Of Input Layer\n        self.layerList[0].setInput(x)\n        # Feed Through Network\n        for index in range(1, len(self.layerList)):\n            self.layerList[index].feedForward(self.layerList[index-1].getA())\n        # Return The Output Of The Last Layer\n        return self.layerList[-1].getA()\n\n\n    def train(self, x, y):\n        # Feed Through Network\n        prediction = self.predict(x)\n        # Container For The Calculated Layer Errors\n        errorsPerLayer = []\n        # Calculate Error Of The Output Layer\n        errorOutputLayer = listSubtract(prediction,y)\n        # Add The Error To The Container\n        errorsPerLayer.append(errorOutputLayer)\n        # Calculate The Total Error Of The Network\n        totalError = calcTotalError(errorOutputLayer)\n        # Calculate The Error Of The Hidden Layers\n        for layerNum in range(len(self.layerList)-2, 0, -1):\n            # Get The Error Of The Next Layer\n            errorOfNextLayer = errorsPerLayer[0]\n            # Forward The Calculation To The Next Layer, Which Returns The Weighted Error, By Giving It It's Error\n            weightedError = self.layerList[layerNum+1].calculateWeightedError(self.layerList[layerNum].getNeuronNum(), errorOfNextLayer)\n            # Forward The Calculation To The Current Layer, Which Returns The Error Of The Layer, By Giving It The Number Of Neurons In The Current Layer And The Weighted Error Of The Next Layer\n            currentLayerError = self.layerList[layerNum].calculateError(weightedError)\n            # Add The Just Calculated Error To The List\n            errorsPerLayer.insert(0, currentLayerError)\n        # Insert 0 As Error For The Input Layer, It's Not Important But That Way It's Size Matches The One Of The Layer List\n        errorsPerLayer.insert(0, 0)\n        # Update Weights And Biases\n        for layerNum in range(1, len(self.layerList)):\n            # Get The Output Of The Previous Layer\n            aOfPrevLayer = self.layerList[layerNum-1].getA()\n            # Forward The Error Of The Current Layer And The Output Of The Previous Layer To The Current Layer For Calculating Delta W\n            self.layerList[layerNum].updateWeightsAndBiases(errorsPerLayer[layerNum], aOfPrevLayer)\n\n        #print(\"The Network Predicted: \", prediction, \" Expected Was: \", y, \" The Error Of The Output Layer Is: \", errorOutputLayer)\n        # Return The Total Error Of The Network For Usage Outisde This Class\n        return totalError\n\n\n\n    def getNetworkInfo(self):\n        for layer in self.layerList:\n            print(layer.getLayerInfo())\n\n\n----------\n\n\n\n\n\nclass Layer:\n\n    def __init__(self, layerNum, numNeurons, numNeuronsPrevLayer):\n        self.neurons = []\n        # Set The Number Of The Layer\n        self.layerNum = layerNum\n        # Create The Neurons\n        for index in range(numNeurons):\n            self.neurons.append(Neuron(numNeuronsPrevLayer))\n        # Print Info\n        print(\"Layer \", layerNum, \" makes \", numNeurons, \" Neurons\", len(self.neurons))\n\n\n    def feedForward(self, aPrevLayer):\n        # Give It To The Neurono For Processing\n        for neuron in self.neurons:\n            neuron.feedForward(aPrevLayer)\n\n\n    def calculateWeightedError(self, numNeuronsCurrentLayer, errorOfNextLayer):\n        # The Container For The Weighted Error Of The Next Layer\n        weightedError = []\n        # The Calulation For Every Neuron Of The Current Layer One After Another\n        for neuronNum in range(numNeuronsCurrentLayer):\n            eSum = 0\n            # The Error Of The Neuron With The Neuron For Later Calculation\n            for e, n in zip(errorOfNextLayer, self.neurons):\n                # Forward The Calculation To The Current Neuron, By Giving It It's Error And The Connecting Neuron Num\n                eSum += n.weightError(e, neuronNum)\n            # Add The Summed And Weighted Error\n            weightedError.append(eSum)\n\n        # Return The Error Of The Current Layer\n        return weightedError\n\n\n    def calculateError(self, weightedError):\n        # The Container For The Error Of The Current Layer\n        errorOfCurrentLayer = []\n        # The Weighted Error For The Neuron With The Neruon\n        for wE, n in zip(weightedError, self.neurons):\n            # Add The Product Of The Weighted Error With The Z Of The Current Neuron Run To Sigmoid Prime\n            errorOfCurrentLayer.append(wE * sigmoidPrime(n.getZ()))\n        # Return The Error Of The Current Layer\n        return errorOfCurrentLayer\n\n\n    def updateWeightsAndBiases(self, errorOfCurrentLayer, aOfPrevLayer):\n        # The Error For The Neuron With The Neuron\n        for e, n in zip(errorOfCurrentLayer, self.neurons):\n            # Error Of Current Layer Is Equal To The Delta Of The Bias So Apply That\n            n.updateBias(e)\n            # Forward The Error And All The Activity Of The Previous Layer To The Current Neuron To Update It's Weights\n            n.updateWeights(e, aOfPrevLayer)\n\n    def setInput(self, x):\n        # Set It To Every Neuron\n        for neuron, val in zip(self.neurons, x):\n            neuron.setInput(val)\n\n    def getA(self):\n        aOfLayer = []\n        for neuron in self.neurons:\n            aOfLayer.append(neuron.getA())\n        return aOfLayer\n    def getNeuronNum(self):\n        return len(self.neurons)\n\n    def getLayerInfo(self):\n        return \"Layer( %i ), has %i Neurons\" % (self.layerNum, len(self.neurons))\n\n\n----------\n\n\n\nclass Neuron:\n\n\n    def __init__(self, numNeuronsPrevLayer):\n        self.a = 0\n        self.z = 0\n        self.b = 0.5\n        if numNeuronsPrevLayer != 0:\n            self.w = np.random.uniform(low = 0, high = 0.5, size=(numNeuronsPrevLayer,))\n\n    def feedForward(self, aPrevLayer):\n        # Reset Z\n        self.z = 0\n        # Calculate Z\n        for w, a in zip(self.w, aPrevLayer):\n            self.z += w*a\n        # Add Bias\n        self.z += self.b\n        # Calculate A\n        self.a = sigmoid(self.z)\n\n    def weightError(self, e, neuronNum):\n        # Weight Error With The Connecting Weight\n        return e * self.w[neuronNum]\n\n    def updateWeights(self, e, aOfPrevLayer):\n        # The Weight With The Matching Activity Of The Previous Layer\n        for index in range(len(self.w)):\n            # The Delta Of The Weight Is The Error Of That Neuron Mutliplied With The Through The Weight Connected Activiy Of The Previous Layer\n            self.w[index] -= e * aOfPrevLayer[index]\n\n    def updateBias(self, e):\n        # E Is The Delta Of The Bias1\n        self.b -= e\n\n    def setInput(self, x):\n        self.z = x\n        self.a = x\n\n    def getA(self):\n        return self.a\n    def getZ(self):\n        return self.z\n    def getB(self):\n        return self.b\n    def getW(self):\n        return self.w\n\n\n----------\n\n**helper functions**\n\n    def map0to1(val, valMax):\n        return val/valMax\n\n\n\n    def calcTotalError(errorOutputLayer):\n        totalError = 0\n        for e in errorOutputLayer:\n            totalError += e**2\n        totalError *= 0.5\n        return totalError\n\n\n\n    def listSubtract(list1, list2):\n        subbed = []\n        for l1, l2 in zip(list1, list2):\n            subbed.append(l1-l2)\n        return subbed\n</code></pre>\n\n<hr>\n\n<h2>The New Code</h2>\n\n<p>Main File</p>\n\n<pre><code>import random\nfrom network import *\nfrom mnistreader import *\n\n\ndef map0to1(val, valMax):\n    return val/valMax\n\n\n# THIS WORKS\n'''\ntrainX = [ [0.0,0.0], [1.0,0.0], [0.0,1.0], [1.0,1.0] ]\ntrainY = [ [ 0.0], [ 1.0 ], [ 1.0 ], [ 0.0 ] ]\n\n\n# Create Network\nxorNet = Network((2,2,1))\n\n# Train\nfor index in range(100000):\n    randIndex = random.randint(0, 3)\n    xorNet.train(trainX[randIndex], trainY[randIndex])\n\nprint(\"Prediction After Training:\", xorNet.predict(trainX[0]), \"Expected:\", trainY[0])\nprint(\"Prediction After Training:\", xorNet.predict(trainX[1]), \"Expected:\", trainY[1])\nprint(\"Prediction After Training:\", xorNet.predict(trainX[2]), \"Expected:\", trainY[2])\nprint(\"Prediction After Training:\", xorNet.predict(trainX[3]), \"Expected:\", trainY[3])\n'''\n\nmnistNet = Network((784, 30, 10))\n\n# Load Trainigs Data\nrawImages, rawLabels, numImagePixels = get_data_and_labels(\"C:\\\\Users\\\\Robin\\\\Documents\\\\MNIST\\\\Images\\\\train-images.idx3-ubyte\", \"C:\\\\Users\\\\Robin\\\\Documents\\\\MNIST\\\\Labels\\\\train-labels.idx1-ubyte\")\n\n# Prepare Data\nprint(\"Start Preparing Data\")\nimages = []\nlabels = []\nfor i in rawImages:\n    insert = []\n    for pixel in i:\n        insert.append(map0to1(pixel, 255))\n    images.append(insert)\nfor l in rawLabels:\n    y = [0] * 10\n    y[l] = 1\n    labels.append(y)\nprint(\"Finished Preparing Data\")\n\n\n# Define Variables\nlearningRate = 0.0001\nerror = 10\n\n# Training\nwhile error &gt; 0.1:\n    for tNum in range(len(images)):\n        error = mnistNet.train(images[tNum], labels[tNum], learningRate)\n    print(\"Error:\", error, \"\\n Prediction:\\n\", mnistNet.predict(images[1]), \"\\nExpected:\", rawLabels[1], \"\\n\\n\")\n\n# Test Prediction\nprint(\"For\", rawLabels[1], \"Predicted\\n\", mnistNet.predict(images[1]))\n</code></pre>\n\n<p>Network Class</p>\n\n<pre><code>import numpy as np\n\nfrom layer import *\nfrom transferfunction import *\n\n\n\n\n\nclass Network:\n\n\n\n    def __init__(self, shape):\n        # Save The Shape Of The Nework\n        self.shape = shape\n        # Create A List Of Layers\n        self.layers = []\n        # Create Input Layer\n        self.layers.append(Layer((shape[0],), layerType = 'Input'))\n        # Create Hidden Layers\n        for numNeurons, numNeuronsPrevLayer in zip(shape[1:], shape[:-2]):\n            self.layers.append(Layer((numNeurons, numNeuronsPrevLayer), layerType = 'Hidden'))\n        # Create Output Layer\n        self.layers.append(Layer((shape[-1], shape[-2]), layerType = 'Output'))\n\n\n\n\n    def predict(self, x):\n        # X Is A Row So Shape It To Be A Column\n        x = np.array(x).reshape(-1, 1)\n        # Set X To Be The Ouput Of The Input Layer\n        self.layers[0].setOutput(x)\n        # Feed Through Other Layers\n        for layerNum in range(1,len(self.layers)):\n            self.layers[layerNum].feedForward(self.layers[layerNum-1].getOutput())\n        # Return The Output Of The Output Layer\n        return self.layers[-1].getOutput()\n\n\n    def train(self, x, y, learningRate):\n        '''\n        1. Feed Forward\n        2. Calculate Error\n        3. Calulate Deltas\n        4. Apply Deltas\n\n        Error Output Layer = f'(z) * (prediction - target)\n        Error Hidden Layer = f'(z) * ( transposed weights next layer DOT error next layer )\n        Delta Bias         = learning rate * error\n        Delta Weights      = learning rate * ( error DOT transposed activity previous layer )\n\n        '''\n\n\n        # Feed Through Network\n        prediction = self.predict(x)\n        # Y Is A Row So Shape It To Be A Column\n        y = np.array(y).reshape(-1, 1)\n\n        # Calculate Error\n        error = prediction - y\n        # Calculate Total Error\n        totalError = 0.5 * np.sum(error**2)\n\n        # Create Container For The Deltas\n        deltas = []\n        # Calculate Delta For Output Layer\n        deltas.append( np.multiply(sigmoidPrime(self.layers[-1].getZ()), error) )\n        # Calculate Deltas For Every Hidden Layer\n        for layerNum in range(len(self.layers)-2, 0, -1):\n            # Compute The Weighted Error Of The Next Layer\n            weightedErrorOfNextLayer = np.dot(self.layers[layerNum+1].getW().T, deltas[0])\n            # Compute The Delta And Add It In Front\n            deltas.insert(0, np.multiply(sigmoidPrime(self.layers[layerNum].getZ()), weightedErrorOfNextLayer) )\n        # Insert Placeholder To Make Delta List As Big As The Layer List\n        deltas.insert(0, 0)\n\n        # For Numerical Grandient Checking Do\n        numericalGradients = self.performNumericalGradientChecking(x,y)\n\n        # Update Weights And Biases\n        for layerNum in range(1, len(self.layers)):\n            self.layers[layerNum].updateBias(deltas[layerNum], learningRate)\n            self.layers[layerNum].updateWeight(deltas[layerNum], self.layers[layerNum-1].getOutput(), learningRate, numericalGradients[layerNum-1])\n\n\n        # Show Information\n        #print('Network Predicted: \\n', prediction, '\\nTarget:\\n', y, '\\nError: ', totalError)\n        return totalError\n\n\n    def performNumericalGradientChecking(self, x, y):\n        # Container Saving All Current Weight Values\n        weightSave = []\n        # Save All The Weight Values\n        for layerNum in range(1, len(self.layers)):\n            weightSave.append(self.layers[layerNum].getW())\n\n        # Define Epsilon To Be A Small Number\n        epsilon = 1e-4\n\n        # Gradient Container\n        numericalGradients = []\n\n        #Perform The Check For Every Layer Therfore Every Set Of Weights\n        for layerNum in range(1, len(self.layers)):\n\n            # Feed Forward With Changed Weights(+epsilon), And Compute Cost\n            self.layers[layerNum].setW(weightSave[layerNum-1] + epsilon)\n            prediction = self.predict(x)\n            loss2 = 0.5 * np.sum ((prediction - y)**2)\n\n            # Feed Forward With Changed Weights(-epsilon), And Compute Cost\n            self.layers[layerNum].setW(weightSave[layerNum-1] - epsilon)\n            prediction = self.predict(x)\n            loss1 = 0.5 * np.sum ((prediction - y)**2)\n\n            # Reset Weight\n            self.layers[layerNum].setW(weightSave[layerNum-1])\n\n            # Calculate Numerical Loss\n            numericalGradient = (loss2 - loss1) / (2 * epsilon)\n\n            # Add The Numerical Grandient\n            numericalGradients.append(numericalGradient)\n\n        return numericalGradients\n\n    def __str__(self):\n        strBuff = ''\n        for layer in self.layers:\n            strBuff += layer.getInfo()\n        return strBuff\n</code></pre>\n\n<p>Layer Class</p>\n\n<pre><code>import numpy as np\n\nfrom transferfunction import *\n\n\nclass Layer:\n\n\n\n    def __init__(self, neurons, layerType = 'Hidden'):\n        ''' Neurons Is A Tuple Consisting Of [0]=NumNeurons And [1]=numNeuronsPrevLayer '''\n\n        # Remember The Type Of The Layer\n        self.layerType = layerType\n        # Remember How Many Neurons This Layer Has\n        self.neuronCount = neurons[0]\n        # Create Layer Based On Type\n        if layerType.lower() == 'input':\n            # Create Container For Input Data\n            self.a = []\n        elif layerType.lower() == 'hidden' or layerType.lower() == 'output':\n            # Create Container For Activation\n            self.z = []\n            # Create Container For Neurons Input\n            self.a = []\n            # Create Weights\n            self.w = np.random.uniform(low = 0.0, high = 0.4, size=(neurons[0], neurons[1]))\n            # Create Prev Delta Weight For Momentum\n            self.momentum = 0.3\n            self.prevDelta = np.full((neurons[0], neurons[1]), 0)\n            # Create Bias\n            self.b = np.full((neurons[0],1), 0, dtype=float)\n        else:\n            print('Wrong Type Of Layer Specified')\n\n\n    def feedForward(self, aPrevLayer):\n        self.z = np.dot(self.w, aPrevLayer) + self.b\n        self.a = sigmoid(self.z)\n\n    def updateBias(self, e, learningRate):\n        self.b -= learningRate * e\n    def updateWeight(self, e, aPrevLayer, learningRate, numericalGradient):\n        # Calulate The Delta Of The Weights\n        deltaW = np.dot(e, aPrevLayer.T)\n\n        # Compare DeltaW With The Numerical Grandient\n        check = np.linalg.norm(deltaW - numericalGradient) / np.linalg.norm(deltaW + numericalGradient)\n        # DEBUG\n        print(check)\n\n        # The Weight Change Is The Delta With The Addition Of The Momentum\n        self.w -= ( learningRate * deltaW ) + ( self.momentum * self.prevDelta)\n        # Save The Current DeltaW\n        self.prevDelta = deltaW\n\n\n\n\n\n    def getW(self):\n        return self.w\n    def getZ(self):\n        return self.z\n    def getOutput(self):\n        return self.a\n\n\n    def setOutput(self, x):\n        self.a = x\n    def setW(self, w):\n        self.w = w\n\n\n    def getInfo(self):\n        if self.layerType.lower() == 'input':\n            return 'Input Layer With ' + str(self.neuronCount) + ' Neurons\\n'\n        else:\n            return self.layerType + ' Layer With ' + str(self.neuronCount) + ' Neurons And Weights Of Shape: ' + str(self.w.shape) + ' With Biases Of Shape: ' + str(self.b.shape) + '\\n'\n</code></pre>\n\n<p>So my Question simply is: \"What's wrong?\"</p>\n\n<p>Problems:</p>\n\n<ol>\n<li><strong>Error gets stuck at 0.45</strong></li>\n<li>When using a hidden layer with 800 neurons I get the warning division by zero and all becomes NaN's from sigmoid prime</li>\n<li>Numerical gradient checking for the hidden Layer is: 1.0 and for the output layer: 0.995784895209. I know that is supposed to be a very small number. But on the second trainings example it creates a overflow error and becomes NaN's</li>\n</ol>\n\n<p><strong>Major Edit</strong>\nI'm truly grateful for all suggestions so far, I've updated the question using a vectorized form so it's easier to get an overview of what I'm doing here. \nI tried gradient checking now too, not sure if I implemented it right (used the tutorial by Welch Labs (<a href=\"https://youtu.be/pHMzNW8Agq4\" rel=\"nofollow noreferrer\">https://youtu.be/pHMzNW8Agq4</a>))\nI hope the Code is readable </p>\n",
                "tags": "<machine-learning><neural-network><deep-learning>",
                "answers": [
                    [
                        "27112",
                        "2",
                        "26618",
                        "",
                        "",
                        "<p>You need to increase no of hidden units. The more the number, more extract feature your network builds. Be wise with it, as too many features will make it overfit and it won't generalize on new data.</p>\n",
                        "",
                        "1"
                    ],
                    [
                        "26621",
                        "2",
                        "26618",
                        "",
                        "",
                        "<p>Your network has 28 x 28 = 784 (normal MNIST size) inputs, 16 + 16 hidden nodes and 10 outputs. This is not enough for an enough accurate model as a result. </p>\n\n<p>This <a href=\"https://stackoverflow.com/questions/45447740/neural-network-mnist-backpropagation-is-correct-but-training-test-accuracy-ver/45448307#45448307\">question</a> suggests to use 256 x 256 hidden nodes and <a href=\"https://en.wikipedia.org/wiki/MNIST_database\" rel=\"nofollow noreferrer\">Wikipedia page on MNIST</a> gives for 2-layer reference the values: 784-800-10 meaning 800 x 10 nodes. Wikipedia gives error rate 0.016 for that 800 x 10 solution.</p>\n\n<p><em>Sidenote: For 6-layer Deep Neural Network the numbers are : 784-2500-2000-1500-1000-500-10 so the new numbers I gave aren't that big. Of course the error rate on DNN is 0.0035 so it needs those layers.</em></p>\n\n<p><strong>edit:</strong></p>\n\n<blockquote>\n  <p>Do I have to change the learning rate which I now defined to be 0.3?</p>\n</blockquote>\n\n<p>Answer in <a href=\"https://stackoverflow.com/questions/45447740/neural-network-mnist-backpropagation-is-correct-but-training-test-accuracy-ver/45448307#45448307\">the referred question</a> says 0.0001 is more appropriate value. </p>\n\n<p><strong>Edit of question author</strong>\nI marked this as solved because now it is working. I implemented it again and after tweaking the hyperparameters it worked. So this is, in a way the solution to my problem. Because I asked why this problem occurs in the first place, my implementation error aside. </p>\n",
                        "",
                        "11"
                    ],
                    [
                        "27039",
                        "2",
                        "26618",
                        "",
                        "",
                        "<p>I guess you are doing something wrong in your code. I guess its better to use <a href=\"https://www.coursera.org/learn/deep-neural-network/lecture/htA0l/gradient-checking\" rel=\"nofollow noreferrer\"><code>gradient checking</code></a> approach for figuring out whether the whole code has any problem or not. </p>\n\n<p>Based on the comments, if I want to show you exactly what happens, first take a look at <a href=\"https://www.coursera.org/learn/neural-networks/lecture/zO1Is/a-simple-example-of-learning-6-min\" rel=\"nofollow noreferrer\">here</a> which professor Hinton himself explains that what <code>MLPs</code> learn is like learning masks instead of learning the features of the inputs. For illustrating more you can take a look at <a href=\"https://datascience.stackexchange.com/a/26642/28175\">here</a> which shows that MLPs can learn what and I hope that you can expand it to higher dimensions, for your case 784 dimensions. If you use <code>MLPs</code> alone, you will face to the problem of something which is like masking. What <code>CNNs</code> try to find is feature. They try to find features which can be better explained by finding hierarchical features. You can also take a look at <a href=\"https://datascience.stackexchange.com/a/26291/28175\">here</a> which explains that using <code>CNNs</code> you try to find features, and after convolution layers, you use dense layers, <code>MLPs</code> which they try to classify the features. </p>\n\n<p><code>MLPs</code> are good for classifying <code>MNIST</code> data set but they are weak for generalizing unseen data. If your code works fine after using <em>gradient checking</em> try to use different hyper parameters which I guess our friend has explained so much well for you.</p>\n",
                        "",
                        "2"
                    ]
                ]
            },
            "good_match": "True"
        }
    ]
}